[{"content":"MongoDB 以 BSON (Binary JSON) 儲存資料 composite index prefix 如果有一個 index 是 (a, b)，那麼 (a) 也是有效的 index explain 用來看 query 的 execution plan cursor BasicCursor 會 scan 整個 collection，是個警訊 掃描的文件數量 nscanned 掃描的 index 數量 nscannedObjects 掃描的 document 數量 n 回傳的 document 數量 nscanned \u0026gt;= nscannedObjects \u0026gt;= n scanAndOrder 是否需要把文件都放在 memory 並排序 還會一次性回傳資料 hint 強制使用某個 index optimizer 挑選索引 第一階段 - 挑選最佳索引 最佳索引 包含所有的 filter 和 sort 的欄位 range filter 和 sort 的欄位必須在 equality filter 的後面 sort 的欄位必須在 range filter 的後面 如果有多個最佳索引就會隨便選一個 第二階段 - 透過實驗挑選索引 沒有最佳索引就會實驗判斷要選哪個，看看誰先找到指定數量的文件 換句話說，如果有多個索引，optimizer 會選 nscanned 最小的 MMAPv1 Mongo 一開始用的 storage engine _id 直接對應到 diskloc，也就是 disk 的偏移量 查找速度驚人，但是更新就要維護偏移量很費時 採用 database-level lock，Mongo 後來也只更新成 collection-level lock WiredTiger MongoDB 收購的 storage engine Document-level locking 可以做到 compression 5.2 之前 _id 會先被用來尋找 recordid，再用 recordid 去獲取 document recordid 是 clustered index 5.3 _id 變成 clustered index 之前 recordid 只有 64 位，但現在 _id 作為 primary key 有 12 bytes 對 secondary index 造成更大的負擔 Mongo 想達成跨機器和 shard 的唯一性 ","date":"2024-08-16T00:00:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/mongodb-%E7%AD%86%E8%A8%98/","title":"MongoDB 筆記"},{"content":"Estimation 要評估的指標 latency throughput capacity Database 估計 沒特別指定的話，可以預估 single relational database 可以處理 read \u0026amp; write 10K per second single relational database 的容量可以抓 3 TB redis 可以抓 100K，但是受限於 memory，可能抓 30GB 可以問的問題類型 總共有多少用戶？ 有多少活躍用戶？ 每個用戶平均每天使用多久？ Network Load Balancer type application load balancer (ALB) OSI layer 7 (Application layer) 可以根據 request header, URL, query string 來做 routing 可以 validate / terminate SSL network load balancer (NLB) OSI layer 4 (Transport layer) 可以根據 protocol (TCP, UDP, IP..), destination port etc 來做 routing 一般來說預設會 pass through SSL 比較適合應付高流量 strategy round robin 輪流 least connection resource-based 考慮每個 instance 的資源使用情況 weighted variants of the above 可以把上面說的各種情況多加入 weight 的考量 random 優點 resilience 可以關注到某個 instance down 了，自動把 request 轉到其他 instance scalability 後面的 instance 可以 horizontal scale 和 API Gateway 的差異 API Gateway 除了 load balancing 會有更多的功能，例如 rate limiting, authentication, authorization, request validation, caching, logging etc CDN (Content Delivery Network) 把靜態資源放到離使用者地理上比較近的地方，加速存取速度 html, css, js, image\u0026hellip; 這些資料不該頻繁改變 本質上是靜態資源的 cache types push 把新的資料推到 CDN 如果靜態資源很多，開銷會很大 pull lazy 當有 request 進來時，且 CDN 沒有該資源，才會去 origin server 拉資源 第一個 user 會比較慢 Maintain consistency 確保 unique bloom filter 因為存在 service 的 memory，有最高的 throughput，但是可能會有 false positive 不好讓多個 service 共用 Queue / Messaging 如果系統是 synchronous，可能會有 scalability 的問題 會被最慢的 component 所限制 (ex: payment service) role producer 產生 message consumer 處理 message 優點 buffer 應對 request spike 缺點 現在無法知道 message 被處理的情況，sychronous 可以直接得知成功與否 增加 latency model message queue 讓 queue 分配 message 給某個 consumer publisher / subscriber (pub/sub) 可能會有某個 event 想被 publish 給多個 consumer (subscribers) Protocol \u0026amp; Send/Receive data TCP UDP http websocket duplex (two-way) communication 只會建立一次 TCP connection load balancer 可以會遇到問題 long polling client 送 request 給 server，server 不會立刻 close connection，而是等待有新資料或 timeout 才回應 某些不能用 websocket 的情況下，可以用 long polling 來模擬 但是在一些框架或語言可能不好實作 gRPC RPC remote procedure call 把一些 service 包裝成像 local function 一樣，就可以像調用本地函式一樣使用 remote 的服務 google 開發的 RPC 框架 用 protobuf 作為 IDL (Interface Definition Language) binary protocol 非 readable，需要 encode / decode 但比 json 小 .proto file 定義 message 的格式 描述了 interface 長怎樣 protoc 用來 compile .proto file，根據指定的程式語言，產生 client / server code server 再實作 interface 用 http/2 來傳輸 不能用在 browser 適合用在內部服務之間的溝通 GraphQL 流程 User perspective 描述身為 user 期待看到什麼東西 這裡可以先簡單介紹這個 app 的大概邏輯，之後 marketplace 再針對不同 role 探討資料和使用情境 也可以詢問使用的平台 Marketplace 詢問要支援的用戶數量，以及活躍用戶數量 如果有多種用戶，也要分開討論 ex: 叫車服務會有司機和乘客 有更多角色後，可以開始根據角色討論他們的 perspective 取得一些數字 考慮 sotrage 以及 throughput 叫車服務範例 乘客總數量、活躍乘客數、每月乘客需求趟數 司機總數量、活躍司機數、單趟平均時間 throuput 活躍用戶 refresh rate 每個 user 平均打開 app 的次數 平均打開 app 會用多久 Rough design 探討資料的傳遞 根據不同 role 去講他們應該傳送什麼資料，用什麼協定，request 的頻率 (request per second) 討論的時候可以用 average，但是會有 peak time，可以考慮 X2, X4, X10 探討資料的儲存 要準備一些前提，比如假設單一資料庫每秒可以 insert 5K 筆資料 可以討論不同的 sharding 考慮怎樣存可以讓大小減少 評估這樣分是否可能導致 sharding uneven 怎樣的切法可以讓 query 盡量不要跨 shard 每個階段也可以探討 throughput 開始根據情境設計不同的 service 來表達他們的交互 Tips 查找 能不能用地理資訊來做 hashing 能不能用 geo index 工具 \u0026amp; 技術 headless browser 沒有 user interface 的 browser 但是依然有 rendering engine 和 js interpreter。可以用來得到最終的 html Cyclic redundancy check (CRC) 一般用在檢查封包是否有錯誤，但是我們也可以用來檢查某個檔案是否有被修改，好做 sync CQRS (Command Query Responsibility Segregation) 把 read 和 write 分開 一個 storage 針對 read 做 optimize，另一個 storage 針對 write 做 optimize Unique ID UUID 是 random 且 human-readable（不會有相近的 char，比如 0 和 O） 但是太長 可以用不同的 encoding 壓縮長度 因為 UUID 用的 charactor 是 0-9, a-f，所以可以用有更多種 charactor 的 encoding 來壓縮 BASE62 包含 0-9, a-z, A-Z BASE58 BASE62 但不包含容易混淆的 0, O, I, l BASE64 BASE62 但多了 +, / Other 每個 Phase 可以多和 interviewer 討論，確認走在正確的方向上 面對面試官給的數字可以嘗試為了好算向上抓一些 延遲任務 如果遇到因為某些原因需要晚點才能做某個任務，可以用 queue 來處理 Cache 除了用專門的 cache database 做，Server 自身也可以用 memory 來 cache 對於先搶先贏的系統不一定要追求公平，只要達成目標即可 對於搶票機制可以做 pre-populate，事先在 database 生好指定數量的票，這樣就可以只 lock 某個 row，不用 lock 整個 table ","date":"2024-08-03T00:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/system-design/","title":"System Design"},{"content":"Transaction 一個或多個操作的集合 一個 transaction 要不全部執行，要不全部不執行 就算在程式中沒顯式的寫 transaction，資料庫也會自動幫你包 transaction lifespan begin commit rollback Atomicity 一個 transaction 要不全部執行，要不全部不執行 在 commit 前不管因為任何理由失敗，都該 rollback Consistency 符合當初制定的規則 (ex: 設置的 foreign key 指向的資料一定要存在) referential integrity 保證 primary key 和 foreign key 之間的關係 Eventual consistency 最後一定會 consistent Isolation 一個 transaction 的執行不應該影響其他 transaction read phenomena dirty read 一個 transaction 讀到了另一個 transaction 已經寫了但還沒 commit 的資料。這個資料有可能被 commit 也有可能被 rollback non-repeatable read 一個 transaction 兩次讀取同個資料時，得到的資料不一樣因是因為有其他 transaction 更新了這個資料（已經 commit 了） 和 dirty read 不同的是，這個資料是已經 commit 的 phantom read 也是第一次和第二次讀取的資料不一樣，第二次發現多了額外的資料，這次是因為有其他 transaction 寫入了新的資料（並且 commit 了） 之所以要和 non-repeatable read 分開，是因為他這裡沒辦法簡單的靠鎖起來已經讀過的資料，因為你沒辦法鎖你本來看不到的資料 系統設計遇到這問題可以考慮用 pre-populate 的方式，把所有可能的資料都先創好，就可以個別鎖住 lost update 我更新了某筆資料，但是在 commit 之前，有其他 transaction 也更新了這筆資料，並且 commit。我再去讀取這筆資料時，發現我更新的資料就被覆蓋了 double booking problem 當兩個 transaction 同時搶更新同個資源就有可能遇到該問題 example 兩個 transaction 都先 select 再 update 他們兩個 select 都先看到有空位，然後一前一後更新，就會造成 double booking Isoaltion level 為了解決 read phenomena，資料庫提供了不同的隔離等級 不會影響自身 transaction 前面所 write 的資料 read uncommitted No isolation 可以看到其他 transaction 還沒 commit 的資料 所有的 read phenomena 都有可能發生 read committed 只能看到其他 transaction commit 的資料 許多資料庫的預設隔離等級 除了 dirty read 之外，其他 read phenomena 都有可能發生 repeatable read 確保同一筆資料在同一個 transaction 中讀取時，結果是一樣的 phantom read 還是有可能發生 snapshot 保證 transaction 得到的資料是一致的 只會看到 transaction 開始時的 snapshot read phenomena 都不會發生 好像不是所有資料庫都有這個隔離等級，也有些 repeatable read 就是用 snapshot 來實現的 比如 PostgreSQL 就是用 snapshot 來實現 repeatable read 但這不代表不會遇到問題，請參考 double booking problem serializable 最高隔離等級 保證所有 concurrent transaction 執行起來會和依序執行的效果一樣 如果 transaction 不會彼此影響，還是有可能會讓 transaction 並行執行 read phenomena 都不會發生 和要求 exclusive lock 相比，有可能實現方法是遇到衝突會 fail Durability 一旦 transaction 完成，資料應該要 persistent 完成的 transaction 會被記在 non-volatile storage durability technique Write ahead log (WAL) 先寫 log (寫你做了什麼操作，但不去真的改 disk 上對應的資料)，有空再修改 這樣一些修改就可以改在 memory，如果 crash 了，可以用 log 來 recover 而且考量硬碟限制，如果你想修改的資料遠小於硬碟可寫的最小單位，會很浪費 Asynchronous snapshot 在後台把 snapshot 寫到 disk ","date":"2024-07-21T00:00:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/database-acid/","title":"Database ACID"},{"content":"Database internal Storage concept Table Row_id 多數 database 會維護自己的 row_id 也叫做 tuple id Page 多個 row 會被存在一個 page 讀取不會只讀一個 row，而是一個或多個 page IO IO operation 指的是存取 disk 的操作 一個 IO 可能會獲得多個 page，也可能只是用 cache 的資料 Database 常常會利用 cache 來減少 IO 因此有些 query 很快，可能是因為有快取資料可用 Heap data structure 儲存整個 table 的資料 有些 database 會用 clustered index 來儲存，就不會有 heap Index data structure (b-tree) 一個有 pointer 來指向 heap 的資料結構 較流行的是 b-tree 可以對一個或多個 column 做 index index 可以告訴你要查詢的資料在哪個 page index 也會被儲存在 page Row-oriented vs Column-oriented Row-oriented database (row store) 每個 row 接著下個 row 來儲存 每次 IO 會獲得多個 row，每個都有所有的 column Col-oriented database (column store) 每個 column 接著下個 column 來儲存 比較好壓縮，也比較好做 aggregation，所以在一些分析資料的軟體會用到 Data structure B-tree Balanced data structure for fast search 限制 node 中的 element 同時存了 key 和 value range query 效率很差，因為要各別 random access B+Tree B-tree 的變形，和 B-tree 很像，不過 internal node 只存放 key，只有 leaf node 會存放 value internal node 因為現在只需要儲存 key，element size 比較小，所以可以存放更多 element leaf node 會用 linked list 串起來 適合 range query 通常一個 node 是一個 DBMS page LSM-tree Log-Structured Merge-Tree 都加在尾端，不會覆蓋原本的資料，對 SSD 有利 B-Tree 為了平衡會頻繁修改 有利於 insert Fragmentation 這裡是以 database 為出發點去看 fragmentation Internal fragmentation 一個 Page 中有很多空間是空的 External fragmentation 多個 Page 存放不是連續的。剩下的空間夠儲存新的資料，但是因為不連續，所以不能用 Database cursor 當資料庫有很大的結果集時，不可能一次把所有資料用網路傳給 client，用戶也沒有 memory 來存放所有資料 Server side / client side cursor Server side 一次只傳一部分資料給 client 但是要多次往返可能最後總時間會比較久 Client side 一次把所有資料傳給 client client 自己分批處理 對 network bandwidth 要求較大 可能沒有足夠的 memory Partitioning 把大 table 分成多個小 table Vertical vs Horizontal Vertical 根據 columns 拆成多個 partition 可以把不太常用又大的 column (比如 blob) 放到另外一個 partition 可以把他放在較慢的 disk，保留其他常存取的 column 在 SSD 也可以讓比較不常用的資料比較不容易進入 cache Horizontal 把 rows 拆成多個 partition 優點 用 single query 存取單一 partition 的速度更快 對某些 sequential scan 有幫助 可以把舊資料放在比較便宜的設備 缺點 如果要從一個 partition 移動資料到另一個 partition，效率很慢 對於效率很差的 query，可能會需要 scan 所有 partition，此時比掃描整個沒做 partition 的 table 還要慢 partition 可能會 unbalance Data types 這裡以 PostgreSQL 為例，列一小部分 設計 column 前可以先看有沒有合適的 data type Numeric 整數 浮點數 Serial 一種特殊的整數，會 auto increment Character char varchar 可變長度的字串，如果沒有設定長度，就是 text text bpchar 好像就是 varchar，但是 document 有寫 blank trimmed Date / Time Boolean Binary Geometric 特地寫這個是因為如果要用二維平面點，一般來說可能會用兩個 float，但是如果用 geometric 類有 point 可用 其他形狀也可存 UUID Enum 一個有限的字串集合 有序 按照建立時的順序 Database indexing 如果需要搜索的欄位沒做 index，那麼就會需要 scan 整個 table，直到找到 如果要求欄位做 like 之類的，那麼依然需要 scan 整個 table 搜索方法 table scan 如果掃描的範圍過大，Database 可能就會選擇該方法 通常會用 parallel 的方式搜尋，所以還是會快一些 index scan Index-only scan 也叫 covering index 需要的欄位在 index 裡面就有了，在這種情況不用去 heap 取，可以加速很多 但也要小心使 index 變得過大。如果 memory 不夠，又會用到 disk，拖垮效率 non-key column 可以用 include 把一些常常需要一起帶入的資訊放到 index 裡面 可以促成 index-only scan composite index 把多個 col 作為 key 做 index 在 PostgreSQL ，如果有一個 index 是 (a, b)，用靠左的 index 可以做 index scan，但是用靠右的就不行 Clustered index 也叫做 Index-Organized Table 資料圍繞 index 來組織 這也是為什麼 clustered index 只能有一個 沒特別指定的話，primary key 一般是 clustered index Primary key vs Secondary key primary key clusering 把 table 圍繞 primary key 來組織，但也有些 Database 不是這樣設計，比如 PostgreSQL 需要維持 order，但是如果我要根據 PK 取得小範圍內的資料，和不顧排序相比，就可能不用多次 IO Secondary key 不在乎原本 table 的 order，而是根據自訂的 key 來排序 但是會有另外一個結構去放 index，可以找到 row_id 設計差異 PostgreSQL 的 index 都指向 row，不管是 primary 還是 secondary 這樣 secondary index 就可以直接取資料，不用再跳一層 primary key 但是如果更新 row，會更新 row id，連帶影響要更新所有 secondary index，不管修改的欄位有沒有在這 index MySQL 的 secondary index 指向 primary key，primary key 指向 row 這樣 secondary index 就要先找到 primary key，再找到 row Distributed database Sharding 把 table 拆成多個 table，分散在不同的 database 分散式會帶來很多問題，比如要怎麼做 transaction 和 join? Horizontal partitioning vs sharding Horizontal partitioning 一個 table 拆成多個 table，但是還是在同一個 database 和 Horizontal partitioning 的差別 table 現在會分到不同的 database server 做 partition，client 不用管資料具體在哪個 partition，交給 DBMS 去處理。但是 sharding 就要 client 自己去處理 Database replication 透過 redundancy 來提高 reliability, tolerance, accessibility Master / Backup replication 也叫 master-slave replication 只有一個 master / leader，有一或多個 backup / standby 一寫多讀 Multi-master replication 多個 master，可以同時寫入 需要處理 conflict Sychronous vs Asynchronous replication Synchronous transaction 會被 blocked，直到所有的 backup 都寫入 有些 database 可以設定 First N 或是 any 完成就好 Asynchronous transaction 被寫入 master 後就算完成 Concurrency control strategy pessimistic 用各種 lock 來保證 isolation optimistic 不用 lock，真的有 transaction 衝突時就 fail Lock shared vs exclusive shared lock 可以被多個 transaction 同時持有 用在讀取，所以可以多個 transaction 同時讀取 在有 shared lock 的條件下，其他 transaction 也可以設置 shared lock exclusive lock 只能被一個 transaction 持有 他人不能讀取或寫入 PostgreSQL 有一個 SELECT ... FOR UPDATE 來取得 exclusive lock 當涉及的資料持有其中一種 lock 時，其他 transaction 都不能設置另外一種 lock Deadlock 多個 transaction 互相等待對方釋放 lock 多數 DBMS 會檢查 deadlock，並讓最後一個造成 deadlock 的 transaction rollback Two-phase locking (2PL) DBMS 為了實現 isolation 需要保證 conflict serializability (CSR)，2PL 可以保證這一點 two-phase growing phase 取得 lock shrinking phase 釋放 lock 強調一個 transaction 不能釋放 lock 後就再也無法取得 有可能造成 deadlock Database Engine 也叫 storage engine 或 embedded database 負責處理 CRUD 的 library DBMS 基於 engine 來提供更多功能 ORM Eager vs Lazy loading Eager 一次把所有相關的資料都讀取出來 如果 Teacher 有很多 Student，可能會一次把所有 Student 都讀取出來 Lazy 只有在需要的時候才讀取 但是可能會有很多次 IO Open session in view (OSIV) 一個 request 一個 database session 可以配合 lazy loading 來用 N+1 problem 一個 query 取得所有資料，然後再用每個資料的 id 來取得相關資料 這樣就會有 N+1 次 IO 第一次是從主表拿清單 接下來 N 次是從子表拿資料 Tips 盡量不要使用 offset 最 naive 的實現 pagination 的做法就是用 offset + limit。但是 offset 代表讀取並丟掉前面幾筆資料，所以他會多讀一堆沒用的資料 可以讓用戶那邊保存 id，where 設置 id 要大於多少來規避 offset Connection pool 維護一定數量的連接，避免每次都要建立連接 Idempotency key 用來確保一個 request 只會被執行一次 會生成一個唯一的 key，並且在 request 中帶上這個 key。執行操作後會把這個 key 存起來，下次再收到這個 key 時就不會再執行操作 可以用 ULID 而不用 UUID，因為 ULID 前面的 bit 有時間戳，可以用來排序 輸入的資料集中在相近的 page，還都加在尾端，可以減少 IO (相較隨機的 UUID) 不用被迫頻繁存取 disk。而且 UUID 的隨機性拉一堆 page 會導致 buffer 更容易被塞滿，而得強制寫入 disk consistent hashing 把 hash function 的結果分散在一個 hash ring 上 根據 hash function 的結果，看自己落在哪段範圍，配給指定的 server 這樣的好處是追加或是移除 server 時，只會影響一台 server 的資料 也可以追加到負載比較高的 server 附近 write amplification 寫入資料時，發現 disk 寫入的資料比你預期寫入的資料多很多 分很多不同 level，通常是在說 SSD 造成的 想更新的時候，更新的 page 會被標記為不能使用。會有另外一隻非同步程式定期處理這種 但是他會把整個 block 寫到新的地方，再把原地方設為 free，就為了那些不能再被使用的空間搬整個 block polymorphic association 一個 table 有多個關聯，但是這些關聯是不同的 table 某個 id column 會根據不同情況代表不同 table 的 id 可能可以節省空間 也可能因為這樣而沒辦法使用 foreign key 可以考慮拆成多個 column 或是多個 table ","date":"2024-07-21T00:00:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/database-%E4%B8%80%E8%88%AC%E7%AD%86%E8%A8%98/","title":"Database 一般筆記"},{"content":"Pipeline 名詞 Artifact 你需要用到的檔案，可能是 build 出來的檔案，或是跑測試用的專案 ex: .jar, .war Type Build pipeline Release pipeline azure-pipelines.yml 可以 create pipeline，在專案中加入該檔案，Azure DevOps 會自動偵測並執行 用於 build pipeline trigger 指定哪些 branch 有 push 時，要執行 pipeline Variables 可以設定變數，用在 yaml 中 Task 可以搜尋各種 task 來完成任務 copy files publish build artifacts Release pipeline 把 build 出來的 artifact，部署到指定的環境 artifact 上方的閃電，可以設置當有新的 artifact 時，自動觸發 release create release 執行 CI/CD Agent pool 可以加入自己的 agent，也就是自己的 server Board Work item Epic 一個非常 high level 的需求 Issue 把 Epic 拆成小的需求 在敏捷也可以稱為 User Story Task 再把 Issue 拆成更小的需求 Backlog PO 創建的 Issue，會在 Backlog 中 可以把 Issue 拖拉到 sprint 中 可以結合 git repo，把 commit 或 branch 關聯到 Issue Sprint 在這可以新增 sprint 也有 task board，列出所有 task 可以設置 task 的狀態以及指派人員 ","date":"2024-07-20T00:00:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/azure-devops-%E7%AD%86%E8%A8%98/","title":"Azure Devops 筆記"},{"content":"File Uploaded Vulnerability 防禦方法 不要允許使用者上傳任何可執行的檔案 檢查 file type 和 file extension file type 指的是 header 的 Content-Type 用某些套件分析檔案，並重新創建和重新命名檔案 Code Execution Vulnerability 允許攻擊者執行 OS command 防禦方法 不要使用危險的 function 透過 filter 檢查輸入 比如利用 regex File Inclusion Vulnerability LFI (Local File Inclusion) Vulnerability 攻擊者可以讀取伺服器上的任何檔案（包含 /var/www 外的檔案） 透過輸入讀其他檔案的時候沒有檢查檔案路徑 可以用來讀 /proc/self/environ，可能會存在一些可以透過 request 修改的變數。植入PHP 程式碼便有可能被執行 RFI (Remote File Inclusion) Vulnerability 和 LFI 類似，但是檔案來自外部 可以在當前 server 執行其他 server 的 php 程式碼 可以在其他 server 以 .txt 存 php file 防禦方法 避免 remote file inclusion php 的話可以關掉 allow_url_fopen 和 allow_url_include 避免 local file inclusion 用 static file inclusion，不要透過變數去取得檔案位置 SQL Injection 防禦方法 使用 prepared statement XSS (Cross Site Scripting) 允許攻擊者在網頁上執行 javascript code 執行在 client 端，不是 server 端 Main types Reflected XSS 用 URL 攻擊 Persistent/Stored XSS 攻擊的程式碼存在 database 或是某個 page DOM-based XSS 利用前面的方法，透過開發者不當操作 DOM 來攻擊 ex: 攻擊者透過 .innerHTML 放入 script tag Exploitation BeEF Framework 可以把目標 hook 到 beef 可以透過 beef 對被 hook 的目標做各種操作 防禦方法 盡量避免讓 user 的輸入直接顯示在網頁上 在 insert 到網頁前，escape 所有不信任的輸入 把這些 character 轉換成 HTML 用的格式 ex: \u0026lt; -\u0026gt; \u0026amp;lt; CSRF (Cross Site Request Forgery) 防禦方法 Anti CSRF token 生表單的時候也生一個 token，並記住，request 要帶上這個 token unpredictable can\u0026rsquo;t be reused 前後端分離 後端生 CORS 不要接受所有來源，讓前端取得 token 前端生 要發 request 的時候把 cookie 改成和 token 一樣的值 Backdoor msfvenom msfconsole Anti-Virus Principle Static Analysis 和已知的 malware 比對 可以利用 packers, encoders, abfuscators 來讓程式更加獨特 Dynamic(Heuristic) Analysis 在 sandbox 中執行，看他的行為 要幫程式增加安全的操作 延遲 Payload 執行的時間 ","date":"2024-06-28T00:00:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/web-security/","title":"Web Security"},{"content":"Terms Incremental vs Iterative Incremental 隨時間一步一步完成 Iterative 建立 prototype，然後不斷改進 Model type Linear/Predictive 有類似的專案經驗 有明確的流程 沒什麼可以改動的空間 Flexible/Adaptive 專案屬於 new idea 專案很有可能隨時間改變 Waterfall Model 像瀑布一樣，一個階段完成後才能進行下一個階段 Requirement -\u0026gt; Design -\u0026gt; Implementation -\u0026gt; Testing -\u0026gt; Deployment -\u0026gt; Maintenance 非常 predictive，沒有彈性 如果在 Testing 發現重大問題，可能要從 Requirement 重新開始 隨著進度推進，fix 成本增長很快 每一步都得考慮周密 用戶很晚才能看到結果 Incremental Model 在整個開發過程中多次完成軟體開發過程 每個子開發過程都有明確的目標 Agile 一種思維方法，不是模型 Manifesto Individuals and interactions over processes and tools 如果一組人決定要用一組新的工具，那他們應該有更高的優先權 過往的做法可能偏向使用過的工具 Working software over comprehensive documentation document 很重要，但是只有大量的 document 沒辦法讓客戶給出反饋 Customer collaboration over contract negotiation 強調和客戶的合作，而不是只在意合同上的項目 Responding to change over following a plan 瀑布式開發的缺點 現在的技術環境變化太快，Agile 希望在開發過程中能夠快速適應 傳統的開發方法考量到金錢損失，不太可能辦到。但透過小的 increment，可以在每個 increment 中朝正確的方向前進 軟體系統不可能被 100% 預測 系統可能不符合用戶要求 市場變化很快，Agile 可以在短時間內推出最小可行產品，先行推向市場 Kanban 會存在多張卡片 可以直觀看到某個欄位是否堆積大量工作 Properties Visualize workflow Limit work in progress Manage flow Make process policies explicit Improve collaboratively Principles Start with what you do now Agree to pursue incremental, evolutionary change 並非試著立刻改變所有事情 Respect the current process, roles, responsibilities \u0026amp; titles Encourage acts of leadership at all levels 這裡的 leadership 不一定指領導他人，也可以是激勵他人 欄位 Backlog Analyze Develop Test Release Scrum 可以利用 back-to-back testing 來確認沒有弄壞之前 sprint 的功能 roles Product Owner 決定要用什麼方式完成什麼事 與外部世界溝通的人，和利害關係人溝通 目標 最大化產品價值 價低成本、提高收益 職責 維護 open, healthy product backlog 回答產品相關問題 管理預算、release schedule 確保團隊價值，找出問題 Scrum Master 確保團隊遵守 Scrum 的規則，促成會議、解決衝突 Servant Leader 有一點領導，但和大家平等。促成團隊工作而不是指揮別人 目標 促成 Daily Standup 移除障礙 確保大家的心情 確保 Scurm values 團隊的調解人 Dev Team 包含工程師、設計師等等 目標 和 Product Owner 合作，create user stories 寫 code 和測試，確保符合預期 research, design, prototype 流程 product backlog 待完成的事情 可能的欄位 優先度 預計花費時間 誰來執行 spring planning meeting 決定要在這個 sprint 完成的事情 時間點會是 sprint 的第一天 目標 把 product backlog 轉換成 sprint backlog 職責 Scrum Master 促成會議 確保和準備會議地點 確保會議有在持續推進，好達成 timebox 如果有講太久的部分，可能稍後再排單獨會議 確保一切都和 sprint goal 一致 Product Owner 準備好 product backlog 澄清 product backlog 的細節 要準備好描述 acceptance criteria 比如搜索速度要多快？ Dev Team 協助判斷哪些任務可達成且符合 sprint goal sprint backlog 這個 sprint 要完成的事情 開發人員去自己選擇要做的事情 然後就會花 1-4 週完成一個 sprint Daily Scrum (Daily standup) 不該花太久，比如最多 15 分鐘 職責 Scrum Master 確保會議的進行，確保 timebox 紀錄關於目前障礙的筆記，規劃時間移除 Dev Team 回答問題 做了什麼 計畫做什麼 遇到什麼問題 sprint review 找 stakeholders 來看看這個 sprint 的成果 秀出 product increment product increment 意味著他本身就是一個完成的產品，經過測試且準備 release 任務 review sprint result 回顧那些任務做得好和不好 如果有事情沒完成，要解釋為什麼推遲 這個 sprint 有沒有達到目標 Discuss and demonstrate work product owner 全程記錄筆記 Update status of the project Collaborate on the plan ahead sprint retrospective 團隊討論這個 sprint 的問題，並且改進 常見方法 start-stop-continue 每個人說出一個想開始做的事情，一個想停止做的事情，一個想繼續做的事情 可以保持匿名 3-5-3 Structure 3 artifacts Sprint Backlog Product Backlog Product Increment 5 events Sprint Planning Daily Scrum The Sprint Sprint Review Sprint Retrospective 3 roles Product Owner Scrum Master Dev Team 可以再加上 5 values Focus Respect Commitment Courage Openness 3 pillars Transparency Inspection Adaptation ","date":"2024-06-27T02:00:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/software-development-model/","title":"Software Development Model"},{"content":"通用術語 Test data 用來測試系統的輸入 Test case 包含測試步驟, 預期結果, 測試資料 Oracle 理想的結果 Bug error 或是偏離預期的行為 用詞 failure 偏離預期的 event error 導致 failure 的 code part fault outcome Verification 確認系統是否符合 specifcation 這裡出問題是工程師的錯 Validation 確認系統是否符合使用者需求 這裡出問題代表產品目標有錯 Stub 用來代替其他 component 的 template，會回傳 hard-coded value Mock 用來代替其他 component 的 template，會回傳預先設定的值，而且會檢查調用的次數 Driver 用來執行 commands 還有初始化變數的 template Test coverage line coverage 根據程式碼實際執行的程式碼行數來計算 branch coverage 檢查程式碼是不是不同的可能都跑過 考慮 if, switch\u0026hellip; Testing Types Unit Testing 專注在測試 smallest unit of software 要 isolate unit，避免其他 unit 影響測試結果 用 dummy value Integration Testing 專注在測試 communication 和 architecture type non-incremental 一次測試所有 component，測試整個應用程式 Big Bang Testing incremental 每次新增一個 module，做一些測試，反覆執行 Top-Down Testing 從最上層開始，下面調用的部分用 stub 代替 Bottom-Up Testing 從最底層開始，上面呼叫的部分用 driver 代替 Back-to-Back Testing 把已知良好的版本和新版本比較 如果 output 一樣，就代表新版本舊的功能是正確的 可以是 incremental testing 的一部分 Black Box vs White Box Testing Black Box Testing 不需要知道內部結構 用 input 和 output 來測試 Boundary Value 測試高低邊界值，過了就假設中間都過了 Cause-Effect Graph 一種設計 Test Case 的方法 又稱為 fishbone diagram 不同的 cause 會導致不同的 effect 最後會有一個 table 來表示所有可能輸入的組合會對應到什麼結果 Pair-wise Testing 測試多個參數的可能組合 State-based Testing 測試不同狀態下的輸入，確認 state 改變的情形 White Box Testing 知道內部原理，嘗試測試程式碼本身 Control Flow Testing 寫涵蓋所有 branch condition 的 test case Data Flow Testing test case 要涵蓋所有的變數，包含 declaration 和 use ","date":"2024-06-27T00:01:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/testing/","title":"Testing"},{"content":"基礎概念 Container runtime CRI (Container Runtime Interface) Kubernetes 用來和 container runtime 互動的 interface 任何可以實現 CRI 的 container runtime 都可以用在 Kubernetes，比如 containerd 以前有幫 Docker 特別實現一個 CRI，叫做 Docker shim OCI (Open Container Initiative) 一個開放的 container image 和 runtime 的標準 他定義了 container image 和 container runtime 的格式 containerd 一個 container runtime，docker 底下所使用的 container runtime，現在已經與 docker 單獨出來開發維護 他實現了 CRI，所以可以用在 Kubernetes CLI ctr 如果你只裝 containerd，沒有裝 docker，就可以用這個來操作 containerd 能用的指令比較少 For Debugging nerdctl docker-like 的 CLI 很多指令可以把 docker 的指令換成 nerdctl 的指令 For general purpose crictl 用來操作符合 CRI 的 container runtime 的 CLI For Debugging Node Kubernetes 集群中的一台機器 過去叫做 Minion Cluster 由多個 Node 組成的集群 Node Type Master 控制整個集群的 Node Worker 其他非 Master 的 Node 叫做 Worker Node Master vs Worker Master 擁有的 Component API Server etcd Controller Scheduler Worker 擁有的 Component Container Runtime Kubelet Component 安裝 Kubernetes，實際上是安裝以下幾個 Component API Server front-end of the Kubernetes kubectl 是在和這裡溝通 etcd distributed key-value store 會實現 lock mechanism，確保沒有 conflict 預設聽 2379 port command line client etcdctl kubelet 在每個 node 上運行的 agent 負責確保 container 在 node 上如期運行 Container Runtime 用來 run container 的 underlying software Controller Manager 當 node、container、endpoint 掛掉的時候，他要負責監控和回應 底下有許多種的 Controller，負責監控還有作出應對處理 type Replication Controller 確保指定數量的 Pod 在任何時間都在運行 load balancing \u0026amp; scaling 後來被 ReplicaSet 取代 Node Controller 確保 node 在運行 設定固定間隔監測 node 的健康狀態 Scheduler 負責處理 node 間的 distributing work 會尋找新創的 container，並分配到 node 嘗試幫每個 pod 挑選最適合的 node two phase Filter 檢查 node 是否符合 pod 的需求 Rank 給 node 一個分數，選擇最高分的 node Pod Kubernetes 的最小單位 一個 Pod 封裝一個應用程式，可能包含一個或多個 container ReplicaSet 新版本的 Replication Controller yaml spec template 指定要創建的 Pod 的 template 把 pod 的 metadata 和 spec 都放在這裡 replicas 指定要創建的 Pod 的數量 selector 指定要選擇的 Pod 需要這個是因為 ReplicaSet 也可以管理那些不是他創建的 Pod matchLabels 指定要選擇的 Pod 的 label command kubectl scale --replicas=3 -f \u0026lt;file\u0026gt; scale up/down replicas 這樣不會修改檔案，所以檔案的如果原本是 2，檔案依然會寫 2，只是 replicas 會變成 3 kubectl scale --replicas=3 replicaset \u0026lt;name\u0026gt; scale up/down replicas kubectl edit replicaset \u0026lt;name\u0026gt; 想要 scale up/down replicas 也可以用這個，他會立刻生效 簡寫 rs Deployment 管理 ReplicaSet 和 Replica Controller yaml 和 ReplicaSet 很像，把 kind 從 ReplicaSet 改成 Deployment 就好 會自動創建 ReplicaSet 使用情境 Rolling update 想要更新每個 Pod，但不是同時更新，而是一個一個更新，確保不會有 downtime Rollback 如果更新失敗，可以回到之前的版本 Pause and Resume 當需要做 multiple changes，不想要一下指令就馬上做，可以先 pause，等所有指令下完再 resume rollout 創建 Deployment 的時候，會自動創建一個 rollout 創建一個 rollout 的時候，會自動創建一個 Deployment revision Deployment Strategy Recreate 先刪除所有舊的 Pod，再創建新的 Pod 中間會有 Application downtime Rolling Update 一個一個更新 Pod 這個是預設的 strategy command kubectl rollout status deployment \u0026lt;name\u0026gt; 查看 rollout 的狀態 kubectl rollout history deployment \u0026lt;name\u0026gt; 查看 rollout 的 history (revision) kubectl rollout undo deployment \u0026lt;name\u0026gt; 回到上一個 revision 簡寫 deploy Service 讓不同 group 的 Pod 互相通信 像一個 virtaul server，可以連接到一個或多個 Pod 每個 Node 都有一個 kube-proxy，他會檢查有沒有新的 service，並維護 iptables type NodePort 會在每個 node 上開一個 port，讓外部可以連進來 default valid port range: 30000-32767 yaml spec type ports port service 的 port targetPort pod 的 port 如果不設置，會用 port 的值 nodePort 如果不設置，會從 default port range 選一個 selector 指定要連接的 Pod 預設會用 load balancing，策略是 Random，像是一個內建的 load balancer 如果有在同個 cluster 跨 node 的情況，不需要其他設定，就可以創建一個跨 node 的 service，會幫他們都設同一個 nodePort ClusterIP 只有在 cluster 內部可以連進來 用來幫某一組的 pod 提供一個統一的界面並做轉發 不能依賴 internal IP，因為每個 pod 都有可能會 down 或 up yaml spec type ports port targetPort selector service 可以用 cluster IP 或是 service name 來連接 LoadBalancer 會在 cloud provider 上開一個 load balancer nodePort 的 load balancer 是在 node 內部的，現在是要幫多個 node 做 load balancing 這只有在 cloud provider 上才有 name 很重要，因為其他的 Pod 會用這個 name 來連接 (就像 domain name) 簡寫 svc YAML Kubernetes 的配置文件 root level properties apiVersion kind apiVersion Pod v1 Service v1 ReplicaSet apps/v1 Deployment apps/v1 kind Pod, Service, ReplicaSet, Deployment metadata name labels 可以加入任何 key-value pair spec specification section pod containers name image env: list of environment variables name value Tool kubectl kubectl 用來 deploy、inspect、manage application on a Kubernetes cluster commands kubectl run \u0026lt;name\u0026gt; --image=\u0026lt;image\u0026gt; 創建一個 Pod kubectl get pods 查看所有 Podllll -o wide 顯示更多資訊 column READY / 也可以用 kubectl get all 來查看 Pod、Service、ReplicaSet、Deployment kubectl describe pod \u0026lt;name\u0026gt; 查看 Pod 的詳細資訊 欄位 Node Pod 在哪個 Node 上運行，包含了 Node 的 IP IP Pod 的 IP kubectl delete pod \u0026lt;name\u0026gt; 刪除 Pod kubectl create -f \u0026lt;file\u0026gt; 根據 YAML file 創建 resource 如果 resource 已經存在，會報錯 kubectl apply -f \u0026lt;file\u0026gt; 根據 YAML file 創建 resource 如果 resource 已經存在，會更新 resource kubectl replace -f \u0026lt;file\u0026gt; 根據 YAML file 創建 resource 如果 resource 已經存在，會刪除舊的 resource，並創建新的 resource kubectl edit replicaset \u0026lt;name\u0026gt; 可以直接編輯 Replica Set 的 yaml 檔，但他不是一開始創建用的檔案，而是 Kubernetes 在 memory 暫時生成的 kubectl set image deployment \u0026lt;name\u0026gt; \u0026lt;container-name\u0026gt;=\u0026lt;new-image\u0026gt; 更新 Deployment 的 image 注意這裡是 Container name，不是 Pod name --record=true 會記錄每次的操作 用在 rollout 的時候，可以看到每次的操作，不然會顯示 minikube 用來在 local machine 上建立一個 single-node cluster kubeadm 用來在多個 node 上建立 cluster 在多個 node 上安裝 Kubernetes 流程 安裝 container runtime 安裝 kubeadm 初始化 master node 建立 pod network 加入 worker node Networking Cluster Networking 每個 Pod 都有自己的 IP 兩個不同屬於同一個 cluster 的 Pod 可能會有相同的 IP Kubernetes 要求所有的 Pod 要可以在不用 NAT 的情況下互相通信 所有的 container 和 node 都要可以在沒有 NAT 的情況下互相通信 可以用 Calico 等方案實現 他會把每個 node network 都設成不同的，底下的 pod IP 自然就不會重複 ","date":"2024-06-14T00:00:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/kubernetes-%E7%AD%86%E8%A8%98/","title":"Kubernetes 筆記"},{"content":"基礎概念 Module 把相關的 Component、Directive、Pipe、Service 等打包在一起的容器 Lazy Loading Component Angular 應用程式的基本組成單位 Pipe 用來轉換資料的工具，可以把字串格式化、日期格式化等 Directive 用來修改 DOM 元素的外觀或行為 比如說 ngIf、ngFor、ngStyle、ngClass 類型 Structural Directive: 修改 DOM 的結構 可以搭配 ng-container 不會產生額外的 DOM 元素，可以用在想要用 ngIf 和 ngFor 但不想產生額外元素的情況 *ngFor let item of items; index as i Attribute Directive: 修改 DOM 的屬性 Component Directive: 包含 template 的 directive Service 負責 API 請求、資料處理等工作 Dependency Injection @Injectable providedIn root: 全域共用 也可以在 component 的 providers 中設定要注入的 service Router 負責處理 URL 路由 routes path component guard ng g guard \u0026lt;guard-name\u0026gt; CanActivate CLI Command ng new my-app: 建立新的 Angular 專案 ng serve: 啟動開發伺服器 ng build: 打包專案 generate ng generate module my-module: 建立新的 Module ng generate component my-component: 建立新的 Component --module=app: 指定 Component 所屬的 Module ng generate service my-service: 建立新的 Service ng generate pipe my-pipe: 建立新的 Pipe ng generate directive my-directive: 建立新的 Directive Module NgModule declarations: 定義同一 Module 中的 Component、Directive、Pipe imports: 匯入其他 Module providers: 定義 Service bootstrap: 定義啟動的 Component exports: 定義要匯出的 Component、Directive、Pipe Component 包含元素 Template TypeScript Class .spec.ts: 測試檔 Selector: 定義 Component 的名稱 CSS Style standalone 新版 Angular 預設 app 使用 Standalone 模式，使 component 不再需要透過 NgModule 管理 Lifecycle Hooks ngOnChanges 當 Angular 重新綁定輸入屬性時調用 ngOnInit 當 Angular 初始化指令/元件時調用 在第一輪 ngOnChanges 後調用 只調用一次 使用場景 初始化資料（需要根據 @Input 變數） fetch data from API ngDoCheck 在 ngOnChange 和 ngOnInit 之後調用 ngAfterContentInit 在 Angular 把 ng-content 投影到 view 後調用 在第一個 ngDoCheck 之後調用 ngAfterContentChecked 在 ng-content 的內容變更後調用 ngAfterViewInit 在 Angular 初始化完 view 後調用 ngAfterViewChecked 在每次做完 view 的變更檢查後調用 ngOnDestroy 在 Angular 銷毀 directive/component 前調用 Component check 操作 update child component input binding update DOM interpolation update query list Sharing Data @Input 父元件傳遞資料給子元件 @Output 子元件傳遞資料給父元件 Binding Property Binding 用來設定 HTML 元素的屬性 用中括號 [] 包住屬性名稱 ex: \u0026lt;img [src]=\u0026quot;imageUrl\u0026quot;\u0026gt; Event Binding 用來設定 HTML 元素的事件 用小括號 () 包住事件名稱 ex: \u0026lt;button (click)=\u0026quot;onClick()\u0026quot;\u0026gt; $event: 可以取得事件物件 Two-way Binding 把屬性和事件綁定在一起 用中括號和小括號 [(ngModel)] 包住屬性名稱 ex: \u0026lt;input [(ngModel)]=\u0026quot;name\u0026quot;\u0026gt; ","date":"2024-05-24T00:00:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/angular-%E7%AD%86%E8%A8%98/","title":"Angular 筆記"},{"content":"Maven 專案管理工具 會先檢查 maven local repository 有沒有需要的 dependency，沒有的話就會去 maven central repository (remote repository) 下載 pom.xml project cooridnate groupId artifactId version plugin 和 dependency 的差別是，是用來執行某種 task 的 mvnw maven wrapper 在沒有安裝 maven 的環境下，會下載正確的 maven 版本 Spring IoC Invocation of Constructor 把物件交給 Spring 管理 loose coupling Dependency Injection Bean 給 Spring 管理的物件 創建方法 @Component 創建出的 Bean 名字是 class 的開頭轉小寫 注入方法 @Autowired 種類 field injection 不太推薦，不利於 unit test spring boot 會先建立所有 component，在逐一注入，使元件可能短暫處於初始化不完整狀態 constructor injection 最推薦 建立 bean 時就注入 確保 component 被使用時是處於完整的狀態 有利於 unit test，因為可以把設計好的 mock bean 從 constructor 傳入 spring 建議使用 constructor injection setter injection 用 setter 來注入 創好 component 後，再注入 限制 該 Class 也得是 Bean 會根據類型注入 bean 如果同時有多個同類型的 bean，會報錯，可以用 @Qualifier 指定要注入的 bean 名稱 @Qualifier 指定要注入的 bean 名稱 @Primary 如果有多個同類型的 bean，會優先注入這個 bean Cycle life @PostConstruct 創建 bean 後，就會執行這個方法 限制 必須是 public void 不能有參數 @PreDestroy bean 被銷毀前執行 限制 必須是 public void 不能有參數 Lazy Initialization 本來 beans 不管有沒有用都會被創建 @Lazy 只有在要使用時才會初始化 缺點是用 @RestController 的話，第一次 request 才會創建 可以在 application.properties 裡設定 spring.main.lazy-initialization=true，讓所有 beans 都變成 lazy initialization AOP Aspect Oriented Programming 透過 Aspect 統一處理不同方法的共同邏輯 要導入 aop 的 starter 只有 Bean 才能設置 @Aspect Annotation @Aspect 這個 class 是一個切面 @Before 加上切入點，就可以在切入點 (Pointcut) 的方法執行前執行 @After 在方法之後執行 @Around 在方法之前和之後都執行 常用的功能都已經被封裝好了，開發較少用到 AOP Run app use java -jar mvn clean package java -jar target/xxx.jar use mvn spring-boot:run mvn spring-boot:run 特性 Starter Spring Boot Starters 官方的 starter 命名是 spring-boot-starter-* 第三方的 starter 命名是 *-spring-boot-starter\n外部化配置 application.properties 重新啟動 jar 時會自動載入，不用改配置要重新 build jar 集中管理 @Value 可以注入到變數中 可以用 : 來設定預設值 限制 只能在 Bean 和 Configuration 中使用 YAML application.properties 寫多後，沒有層級辨識度 application.yml profiles 可以根據不同的環境來設定不同的配置 (dev, test, prod) application-{profile}.properties application-{profile}.yml spring.profiles.active 指定啟用的 profile jar -Dspring.profiles.active=dev 指定配置文件 cli --spring.config.location Config 資料夾 可以在 jar 目錄下建立 config 資料夾，放配置文件，不用輸入額外的 args 大致分類 core logging web security data actuator integration devtools test Dependency Management parent 寫了版本號，故 dependency 可以不用寫版本號 真的要指定的話，可以利用 maven 的就近原則 Auto Configuration Component Scan Spring Boot 會掃描主程式所在的 package 以及子 package 也可以在主程式上加以下註解來指定掃描的 package @SpringBootApplication(scanBasePackages = \u0026quot;com.example\u0026quot;) 所有 starter 都有 spring-boot-starter，spring-boot-starter 又有 spring-boot-autoconfigure，這個就是自動配置的地方 spring boot 默認掃描不到 spring-boot-autoconfigure 的所有配置類 (因為預設只掃描 Main Application Class 的 package)，但是 @SpringBootApplication 的 @EnableAutoConfiguration 會預設掃描 spring-boot-autoconfigure 的所有配置類 它們再依據 conditional annotation 來決定是否要啟用這個配置類 Common Annotations Spring Boot 放棄了 XML 配置，改用 Annotation 配置\nComponent registration @Configuration, @SpringBootConfiguration @Bean 有時候可能會想用第三方套件，此時可能不能修改套件的 code，這時候就可以用 @Configuration 來註冊 bean @Controller, @Service, @Repository, @Component 三層式架構 @Controller 用來處理請求 @Service 用來處理業務邏輯 @Repository 用來處理資料庫操作 @SpringBootApplication 由以下組成 @SpringBootConfiguration @EnableAutoConfiguration @ComponentScan Web @RestController @Controller + @ResponseBody @RequestMapping 設置 route Method @GetMapping @PostMapping @PutMapping @DeleteMapping @PatchMapping 取得參數 @RequestParam 取得 url 中的參數 @RequestBody 取得 request body 根據欄位名字調用對應的 setter @RequestHeader 取得 header @PathVariable 取得 route 中的參數 @Scope mode singleton 預設，共用一個 instance prototype 每次注入都創建新的 instance 可以用 proxy.mode = ScopedProxyMode.TARGET_CLASS，會變成每次調用 method 都創建新的 instance prototype 的元件生出後，spring 不會再管理，要自己管理生命週期，相當於 new 出物件的替代作法 預設是 lazy initialization request 每個 request 都有一個獨立的 instance request 指的是 HTTP request，從進入 controller 到離開 controller session 每個 session 都有一個獨立的 instance session 指的是 HTTP session，從進入 controller 到離開 controller Conditional Annotations 條件成立則觸發指定行為 ConditionalOn example ConditionalOnClass 如果 classpath 有指定的 class 才會觸發 ConditionalOnMissingClass 如果 classpath 沒有指定的 class 才會觸發 ConditionalOnBean 如果容器中有指定的 bean 才會觸發 ConditionalOnMissingBean 如果容器中沒有指定的 bean 才會觸發 Scenario 如果有某個 dependency，則創建某個 bean Property Binding 把任意 Bean 的 property 與配置文件 (application.properties) 中的 property 綁定 annotations @ConfigurationProperties prefix @EnableConfigurationProperties 如果 class 只有 @ConfigurationProperties，沒有 @Component，需要加這個 annotation 用在第三方 package 上，因為默認掃不到第三方的 @component Java JSON Data Binding 在 Java POJO 和 JSON 之間轉換 Spring 用 Jackson 來做轉換 Jackson 會 call getter, setter 來轉換 alias mapping marshalling serialization 輔助工具 Spring boot devtools Hot reload Spring Boot Actuator 公開用來 monitor 的 endpoint endpoints 都有固定前綴 /actuator /health 查看應用程式的 status /info 查看應用程式的 info /beans 查看所有 bean Logging Logging 選擇\nLogging API JCL SLF4J (Simple Logging Facade for Java) jboss-logging Logging implementation Logback Log4j2 JUL (java.util.logging) Spring Boot 預設使用 Logback 和 SLF4J spring-boot-starter 引用了 spring-boot-starter-logging\nLog Format Default example 1 2024-05-06T19:21:40.751+08:00 INFO 22932 --- [demo] [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat started on port 8080 (http) with context path \u0026#39;\u0026#39; 時間, 日誌等級, pid, 分割符, thread, logger, message Log Level Type (由低到高) ALL TRACE 一般不用 DEBUG INFO WARN ERROR FATAL OFF 會 print 出比設定的等級高的 log Log Configuration logging.level.*\n設定不同 package 的 log 等級 1 logging.level.com.example=DEBUG logging.group.\n把多個 package 放在一組，可以統一設定 預設有 web, sql 組 logging.file\n.name 檔名 歸檔 and 切割\n歸檔 每天單獨存 .logback.rolllingpolicy.file-name-pattern 切割 超過指定大小就切割 .logback.rolllingpolicy.max-file-size Filter 實做 javax.servlet.Filter，就能註冊為 spring 的 filter OncePerRequestFilter 保證一次 request 只會執行一次 doFilterInternal chain.doFilter(request, response) 這行之後代表後面的 filter 都執行完了 如果只有一個 filter，就代表 controller 執行完了 shouldNotFilter 可以設定不要執行的 url pattern 註冊 Filter 流程\n設定 @Configuration 加到 Bean \u0026lt;option\u0026gt; setUrlPatterns 只有符合 url pattern 的 request 才會經過這個 filter \u0026lt;option\u0026gt; setOrder 決定 filter 的順序 如果 filter 要取得 request 和 response 的內容，可以用 ContentCachingRequestWrapper 和 ContentCachingResponseWrapper 重新包裝\n因為原本的作法是用 stream 讀取資料，只能讀一次 @WebFilter\n屬於 Java servlet 而非 Spring 要在 application 補上 @ServletComponentScan 可以直接註冊 filter Spring Security 名詞 Authentication 認證 檢查是不是系統的使用者，以及是哪個使用者 Authorization 授權 檢查使用者有沒有權限做某件事 流程 filter chain\nexample UsernamePasswordAuthenticationFilter 檢查使用者名稱和密碼 ExceptionTranslationFilter 處理例外 FilterSecurityInterceptor 檢查授權 authorizeHttpRequests 設定哪些 request 需要什麼權限 example: JWT 驗證流程\n先透過 filter chain 經過 JWT filter 透過 UserDetailsService 取得使用者資訊 驗證使用者資訊 更新 SecurityContextHolder 用來判斷使用者是否已經通過 authentication Configuration @EnableWebSecurity 啟用 web security example 1 2 3 4 5 6 7 8 9 10 11 12 @Configuration @EnableWebSecurity public class SecurityConfig { @Bean public SecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception { http.authorizeHttpRequests((requests) -\u0026gt; { ((AuthorizeHttpRequestsConfigurer.AuthorizedUrl)requests.anyRequest()).authenticated(); }); http.httpBasic(Customizer.withDefaults()); return (SecurityFilterChain)http.build(); } } 把 Spring Boot 預設實作的 fitler chain 的 @Order 拿掉，這是決定誰的優先序高 也把 formLogin 拿掉，就不會有登入頁面 UserDetails 實現 UserDetailsService 的 Bean 可以被用來取得 UserDetails implements UserDetails getAuthorities getUsername getPassword isAccountNonExpired isAccountNonLocked isCredentialsNonExpired isEnabled SecurityContextHolder 用來存放 authentication CommandLineRunner 用來在 Spring Boot 啟動後執行一些任務 會在所有 bean 創建完後執行 JPA Jakarta Persistence API 以前叫 Java Persistence API 只是一個 specifcation，提供一組 interface，需要實作 包含了 Entity, EntityManager, Query, Transaction.. DataSource 用來連接資料庫 定義了連接資料庫的 info EntityManager 用來創建 query 的主要 component 需要 DataSource EntityManager vs JpaRepositroy EntityManager low-level control and flexibility JpaRepository high-level abstraction JPQL 基於 Entity name 和 fields 的 query language 不是基於資料庫的 column 或 table name，是基於 Entity 的名字，要注意區別 Data access object (DAO) common pattern 需要 JPA Entity Manager Config spring.jpa.hibernate.ddl-auto create 每次都會重新創建新的 table update 只會更新 table，不會刪除 create-drop 創建 table，然後刪除 validate 只會檢查 table 是否存在，不會創建 Annotation @Entity, @Table 也要記得寫 getter, setter @Entity 需要 public 或 protected 的無參數建構子 @Table 可選，可以設定 table 名稱 @Transient 不會被序列化，不會被存到資料庫 可用在可以單獨計算的欄位，比如用資料庫的生日可以算出年齡 @Transactional 用在 method 上，代表這個 method 是一個 transaction propagation 用在 method 上，被別的 transaction 調用應該怎麼處理，講 transaction 的傳播 REQUIRED 如果有外層 transaction 就用，沒有就創建一個 REQUIRES_NEW 無論有沒有外層 transaction，都創建一個新的，不受影響 NESTED 嵌套 transaction，如果外層 transaction rollback，內層也會 rollback 如果自己 rollback，外層不受影響 @Column 可以設定欄位名稱 這是可選的，沒有的話就是用變數名稱 @Id Primary key @GeneratedValue strategy AUTO 根據資料庫自動選擇 IDENTITY 用資料庫的 identity column SEQUENCE 用資料庫的 sequence Table 用 underlying table 來確保唯一性 UUID 用 UUID 來確保唯一性 @OneToMany, @ManyToOne 用來設定關聯 cascade 設定當 parent 被刪除時，child 要怎麼處理 CascadeType.ALL parent 被刪除時，child 也會被刪除 CascadeType.PERSIST parent 被刪除時，child 不會被刪除 Spring Data JPA 用特定語法，只需要定好 interface，不用 implement extends JpaRepository\u0026lt;Entity, ID\u0026gt; 第一個參數是 entity 第二個參數是 primary key 的型態 示範 findByXxx 用 XXX 的欄位來查詢 findByXXXLike 用 XXX 的欄位來模糊查詢 JpaRepository @Repository 用來標記 DAO extends JpaRepository\u0026lt;Entity, ID\u0026gt; 第一個參數是 entity 第二個參數是 entity 的 id 的型態 可以自定義方法 遵循命名規則，他會自己轉 SQL 也可以用 @Query 來自定義 SQL \u0026lt;?0\u0026gt; 代表第一個參數，以此類推 Hibernate 用來儲存 java object 到資料庫的框架 ORM Object Relational Mapping 用物件來操作資料庫 一種 JPA 的實作 背後用 JDBC 來操作資料庫 Spring Boot 預設用 Hibernate 來實作 JPA Validation field validation\n@NotEmpty @Min @Max @Valid\n用在 controller 上，才會自動檢查參數 Exception RuntimeException 繼承這個，可以設置 status, message, timestamp @ExceptionHandler 放在 Controller 中的 exception handler method 上，可以處理底下 method 丟出的 exception @ControllerAdvice 類似 interceptor/filter 可以 pre-process request, post-process response 可以用在 global exception handler Testing Integration Test 在 test class 前面的 annotation @RunWith(SpringRunner.class) @SpringBootTest @AutoConfigureMockMvc 測試開始時會在容器中創建 MockMvc 在 test method 前面加的 annotation @Test @Before, @After 在每個測試前後執行，可以用來清空資料庫和設置 header MockMvc 用來模擬 HTTP request example 1 2 3 4 5 6 7 8 9 @Autowired private MockMvc mockMvc; @Test public void test() throws Exception { mockMvc.perform(get(\u0026#34;/hello\u0026#34;)) .andExpect(status().isOk()) .andExpect(content().string(\u0026#34;Hello World\u0026#34;)); } 其他 Lombok @Getter, @Setter 生成 getter, setter @ToString 印出所有變數 @EqualsAndHashCode 生成 equals, hashCode Args @NoArgsConstructor 生成無參數建構子 @AllArgsConstructor 生成所有參數建構子 @RequiredArgsConstructor 只幫 final 變數生成建構子 @Data 同時用 @Getter, @Setter, @ToString, @EqualsAndHashCode, @RequiredArgsConstructor @Value 把所有變數都設成 final 同時用 @Getter, @ToString, @EqualsAndHashCode, @RequiredArgsConstructor 和 Spring boot 的 @Value 撞名 @Builder 生成 builder pattern @Slf4j 生成 log 變數 Jackson ObjectMapper 用來轉換物件和 JSON readValue 把 JSON 轉成物件 用 getter, setter 來判斷欄位 Annotation @JsonIgnore 不轉換 @JsonProperty 指定欄位名字 @JsonUnwrapped 把物件的欄位展開，從巢狀變成平面 @JsonInclude 設定要不要轉換 null 如果設定為 Include.NON_NULL，給 null 的話，就不會轉換 @JsonFormat 設定日期格式 ","date":"2024-05-06T00:00:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/spring-boot-%E7%AD%86%E8%A8%98/","title":"Spring Boot 筆記"},{"content":"paper: Memorizing Normality to Detect Anomaly: Memory-augmented Deep Autoencoder for Unsupervised Anomaly Detection\nAbstract autoencoder 在收到異常輸入的時，預期會生出較高的 reconstruction error。但是這個假設實際上並不總是發生。他有可能「泛化」的很好，導致異常的也可以正常重建。\n為了緩解這個問題，本文幫 auto-encoder 加上一個 memory 的機制。\n訓練階段，memory 要學習生成 normal data 的 prototypical elements。\n測試階段，learned memory 會被固定住，然後要根據 few selected memory 進行重建。\n對於異常輸入，這個重建出的東西就會比較像是 normal sample。這樣 reconstruction error 就會被增強。\nMemAE 是 free of assumption，所以可以用在各種不同的任務上。\nIntroduction AE 有可能「泛化」的很好，導致對於異常輸入也可以正常重建。如果 anomolies 和 normal pattern 有共享某些 composition pattern，或是 decoder 強到連 abnormal encoding 都可以重建，就可能發生這樣的狀況。\nMemAE 多了一個 memory module，從 encoder 出來的東西會被視作 query，用來把 memory 中最相關的元素取出，然後作 aggregation。\n作者還進一步提出了一個不同的 hard shrinkage operator，可以生出 sparsity of memory addressing weight。\n在訓練階段，會把 memory content 連同 encoder 和 decoder 一起訓練，透過 sparse addressing strategy，MemAE 可以有效地利用有限的 memory slot 來製造出 prototypical normal patterns，來製造出夠低的 reconstruction error。\n在測試階段，memory content 會被固定住，然後根據 few selected memory 來重建。因為 memory module 並不是基於某種特定資料的假設，所以可以用在各種不同的任務上。\nMemory-augmented Autoencoder Memory Module with Attention-based Sparse Addressing Attention for Memory Addressing attention weight $w_i$ $w_i=\\frac{exp(d(z,m_i))}{\\sum^{N}_{j=1}exp(d(z,m_j))}$ $d(\\cdot, \\cdot)$ 是 similarity measurement，這裡是 cosine similarity $d(z,m_i)=\\frac{zm_i^T}{||z|| \\text{ } ||m_i||}$ Hard Shrinkage for Sparse Addressing hard shrinkage $\\hat{w}_i=h(w_i;\\lambda)=\\begin{cases} w_i \u0026amp; \\text{if } w_i\u0026gt;\\lambda \\\\ 0 \u0026amp; \\text{otherwise} \\end{cases}$ 這東西不好做 backpropagation 改良版 $\\hat{w}_i=\\frac{max(w_i-\\lambda,0)}{|w_i-\\lambda|+\\epsilon}$ $max(\\cdot, 0)$ 就是 ReLU 根據實驗，把 $\\lambda$ 設在 [1/N, 3/N] 會得到還不錯的結果 shrinkage 後會再 normalize $\\hat{w}_i=\\hat{w}_i/||\\hat{w}||_1$ Sparse addressing 有助於鼓勵模型用更少但相關的 memory item 來表示 query。\n鼓勵 memory addressing 的 sparsity 是有益的，因為 memory M 被訓練來適應 sparse w。\n鼓勵 sparsity 也可以緩解異常樣本可以被很好的重建的問題。\nTraining 分成兩個 loss Reconstruction error $R(x^t, \\hat{x}^t)=||x^t-\\hat{x}^t||^2_2$ $l2-norm$ entropy of $\\hat{w}^t$ 用來進一步提升 sparsity $E(\\hat{w}^t)=\\sum^{T}_{i=1}-\\hat{w}_i \\cdot log(\\hat{w}_i)$ Combine $L(\\theta_e, \\theta_d, M)=\\frac{1}{T}\\sum^{T}_{t=1}(R(x^t, \\hat{x}^t)+\\alpha E(\\hat{w}^t))$ 根據實驗，$\\alpha$ 設成 0.0002 ","date":"2024-04-30T00:00:55+08:00","permalink":"https://roykesydon.github.io/Blog/p/memae-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"MemAE 論文閱讀"},{"content":" 有關名詞\n扇區: 最小的儲存單位 block: 一次讀取的最小單位，是多個連續的扇區 inode OS 用來記錄檔案的 metadata 每個文件的 inode number 是唯一的 可以用 ls -li 來看 inode number inode data 檔案的大小 擁有者 擁有者的 group 權限 修改時間 文件的實體指針，指向 block 格式化分區\n主分區 擴展分區 邏輯分區 默認分區 1~4 給主分區和擴展分區，邏輯分區從 5 開始 /dev/sda1、/dev/sda2 這種就是分區 fdisk\n小於 2TB 的磁碟，可以用 fdisk，但是大於 2TB 的磁碟，要用 parted，且要用 GPT fdisk -l 列出所有分區 fdisk /dev/sda 進入 fdisk n 新增分區 再設置 sector 的起始位置和結束位置 d 刪除分區 t 更改分區的 system id w 寫入並且離開 parted\nparted /dev/sda 進入 parted mklabel gpt 可以把 disk 轉成 GPT GPT 區分主分區和邏輯分區 mkpart primary \u0026lt;start\u0026gt; \u0026lt;end\u0026gt; 創建一個 primary partition，從 start 到 end (MB) 軟硬連結\n軟連結 ln -s \u0026lt;source\u0026gt; \u0026lt;destination\u0026gt; 如果刪除軟連結的檔案的話，不會影響原本的檔案 源文件刪除後，軟連結失效 支持資料夾 支持跨文件系統 硬連結 ln \u0026lt;source\u0026gt; \u0026lt;destination\u0026gt; 一般情況，inode 和檔案名稱是一對一的關係 軟連結 inode 號碼是不一樣的，代表是兩個個體，硬連結 inode 號碼是一樣的 刪除硬連結對源文件沒有影響 刪除源文件對硬連結沒有影響 但是如果刪除所有硬連結，文件的連結數變成 0，則文件會被刪除 不能對資料夾使用 不能跨文件系統 mkfs\n對分區進行格式化文件系統 fsck\nfile system check 檢查和修復文件系統 lsblk\nlsblk -f 列出所有分區的文件系統 vfs\nvirtual file system linux 可能有多種文件系統，在上面有一層 vfs，讓所有文件系統都可以通過一個統一的接口來訪問 Mount\n設備要 mount 才可以使用，給設備提供一個出入口 mount -l 列出所有已經 mount 的設備 -t 指定文件系統，不指定的話，會自動判斷 -o 一些有關於 mount 的參數 async 非同步讀寫，效率高，但是喪失安全性 sync 同步讀寫，效率低，但是讀寫安全 atime/noatime 是否要紀錄文件的訪問時間 -r read-only LVM\nlogical volume manager 把一個或多個硬碟在邏輯上進行合併，可以動態調整大小 硬盤的多個分區，由 LVM 統一管理為 volume group 名詞 PP: physical partition PV: physical volume 通常一個 PV 對應一個 PP PE: physical extends PV 中可以分配的最小單位，同一個 VG 中，所有 PV 的 PE 大小都是一樣的 VG: volume group 創建在 PV 上，可以劃分成多個 PV LV: logical volume 創建在 VG 上，可以動態擴容的分區 LE: logical extends LV 中的基本單位，一個 LE 對應一個 PE 創建 PP 階段 用 fdisk 格式化，修改 system id 為 8e (預設是 83) PV 階段 用 pvcreate, pvdisplay 把 linux 分區轉成 PV 指令 pvcreate /dev/sda /dev/sdb: 把 sda 和 sdb 轉成 PV 適用硬碟和分區 pvs: 查看 PV VG 階段 用 vgcreate, vgdisplay 創建 VG 指令 vgcreate vg1 /dev/sda /dev/sdb: 創建 VG vg1，用 sda 和 sdb vgs: 查看 VG vgextend vg1 /dev/sdc: 把 sdc 加入 vg1 vgdisplay: 查看 VG LV 階段 用 lvcreate, lvdisplay 創建 LV 把 VG 分成多個 LV 也要幫 LV 創建文件系統 指令 lvs: 查看 LV lvextend -L +1000G /dev/vg1/lv1: 把 lv1 增加 1000G ex4 可以不用 umount 還要 resize2fs /dev/vg1/lv1 來調整文件系統大小 可以用 df -h 來檢查 ","date":"2024-04-24T00:00:43+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E7%A3%81%E7%A2%9F%E7%AE%A1%E7%90%86/","title":"磁碟管理"},{"content":"paper: ReALM: Reference Resolution As Language Modeling\nAbstract Reference resolution 是一個重要的問題，對於理解和充分處理不同類型的 context 很重要。\nContext 包含 previous turns 和 non-conversational entities，比如使用者螢幕上的 entity，或是在背景執行的 entity。\nLLM 雖然在各種任務都很強大，但對於 reference resolution 的使用，特別是 non-conversational entities 方面，依然沒有充分利用。\n本文將展示如何引用 LLM 創建一個系統來處理不同類型的 reference，方法是展示如何把 reference resolution 轉換成 language modeling problem。 盡管螢幕上的 entity 傳統上不利於簡化成 text-only modality。\n對於 GPT-4，本文最小的模型實現了和 GPT-4 相當的性能，而更大的模型則大幅領先。\nIntroduction 人類的語言很長包含 ambiguous reference，比如「這個」、「那個」等等，這些 reference 需要根據 context 來解決。\n能夠能夠理解 context 對 conversational assistant 來說很重要。\n讓使用者能夠對螢幕上看到的內容發出查詢是確保語音助理可以提供 hands-free 體驗的第一步。\nSpeaker Dialogue User Show me pharmacies near me Agent Here is a list I found. Agent \u0026hellip; (list presented) User Call the one on Rainbow Rd. User Call the bottom one. User Call this number (present onscreen) Table 1: Sample Interactions between a user and an agent.\n以 Table 1 為例，如果沒有理解 context 的能力，agent 不可能完成查詢。\n照理來說，處理用戶的查詢需要多種類型的 context，Conversational context 和 on-screen context 就是兩個主要的例子。\n最近的 LLM 通常可以實現 End-to-End 的體驗，甚至可能可以消除包含 reference resolution 的多階段 piepline。\n但是在一些實際案例中，pipeline 有他的價值，考慮以下情境：\n在運算能力有限的設備上運作 (例如手機)\n由於功耗和延遲需求，單一大型 End-to-End 模型可能不適用。 需要與 API 整合的情境\n雖然存在可以用 LLM 編寫呼叫 API 的方法，但依然需要超大的模型還有對現有 pipeline 的徹底處理。 使用 focused model 可以允許現有的 reference resolution module 替換成更新的版本，而且由於系統是模組化的，可以改進能力和可解釋性。\n對於本文所考慮的任務，reference resolution 不只限定於 conversational context，還包含 on-screen entities，這些 entities 是使用者可以感知到的一部份，但是還未出現在對話歷史紀錄中。\n因此，盡管一些 LLM 可以 implicit 地處理 reference resolution，但是傳統的 NLP 任務 (比如 reference resolution) 仍然有價值。\n因此本文提倡用較小的語言模型，但針對 reference resolution 進行了專門且明確的 fine-tuning。\n然而這種語音助理會遇到最大的挑戰就是要怎麼讓 LM 「看」到螢幕。而且還要以有利於 LM 解析的方式對螢幕上的 entity 進行編碼，然後編碼還得足夠一致，讓 LM 可以成功執行 reference resolution。\n本文建議使用使用 parsed entity 及其位置來重件螢幕，以產生螢幕的純文字表示。\n然後螢幕上屬於 entity 的部分會被標記，以便 LM 能夠了解實體出現的位置及他們周圍的文字。\n據作者所知，這是第一個目標是從螢幕 encode context 的 LLM 工作。\nRelated Work and Motivation 解析螢幕上的 reference 是一個目前探索比較不足的領域。\n螢幕上的東西通常更加結構化和高度文字化，使的可以利用更輕的模型來轉換成文字。但雖然容易解析，分布和那種大型育訓練的基於圖像的系統不同，因為他們多半都用自然的現實圖片。\n此外那些模型的訓練成本通常都非常高，而且在這種大量文字的情境也表現不佳。 常用於文字理解的方法又常常依賴多個模組，比如 bounding box detection 和 OCR。\n聯合視覺 + 文字的模型在計算成本也更加昂貴。\n對於螢幕上的參考有一些相關工作，被用作本文的 baseline。\n然後他們有些缺點，在本文解決了這些缺點。\n他們的方法依賴專用的 「Category Module」來處理 type-based reference，每次建立新類型，都需要手動加入 Entity 此類 Module 將每種類別視為不同的，忽略了他們的相似性 依賴手工製作的規則，往往需要大量特徵工程，而且不 robust 不考慮語意相似性，也沒法對現實的理解和常識進行推理 這些方法會獨立地判斷實體和 Query 的關聯性，而不考慮其他所有的實體，查詢既不考慮整個螢幕也不考慮其他實體 Task 作者提了三種和使用者相關的 Entity:\nOn-screen Entities Conversational Entities 可能是來自上一輪的對話，也可能是 virtual assistant 產生的 Background Entities 來自後台 process 的相關實體，使用者不一定在螢幕上看的到，比如背景的音樂 本文將 reference resolution 作為 LLM 的 multiple choice task，預期輸出是用戶螢幕上顯示的其中一個 Entity。\n答案也可能是「None of these」。\nDatasets 每筆資料包含使用者查詢和 Entity list，還有與對應使用者查詢相關的 ground truth entity。\n每個實體又包含與其相關的訊息，比如與實體關聯的名稱和其他文字描述訊息。\n對於存在 on-screen context 的資料，context 以 Entity 的邊界框，圍繞它的物件清單還有周圍物件的屬性 (比如類型、文字內容、位置) 來提供\nDataset Train Set Test Set Conversational 2.3k 1.2k Synthetic 3.9k 1.1k On-screen 10.1k 1.9k Table 2: Dataset Sizes (Train Set and Test Set)\nConversational Data 收集使用者和 agent 的相關資料。\n評分者會看到帶有所提供 Entity 清單的截圖，並要求提供引用清單中任意挑選的 Entity 的 Query。\n比如，可能會給使用者看企業清單，使用者可能會說「Call the one on Main Street」。\nSynthetic Data 透過 template 去合成資料。\n有兩種 template:\nBase Template 包含 mentions, entities, possible slots Language Template 除了 Base 還會新增不同變體的 query On-screen Data 從存在電話、電子郵件和實際地址的各種網頁蒐集的。\n進行兩階段的 annotation：\n根據螢幕 extract query 評分者會收到一張帶有綠色方框和紅色方框的截圖，要把綠方框方類為電話、電子郵件或地址等等 然後要為綠框提供三個獨特的 query 根據 query 識別 entity 和 mention 前面蒐集的 query 會被一一展示給評分者，並帶有相應的截圖，但沒有 bounding box，還會提供所有 screen entity list 評分者要評估 query 是否包含給定的 visual entity，還有聽起來自不自然 此外，評分者還要從清單中選出 query 提及的 entity，還要標記它們在 query 的哪裡 Models MARRS 這個是 baseline，非 LLM，和前人的方法去做比較。\n前人的方法著重於螢幕上的 entity，MARRS 也傾向於 conversational 和 background entities。\n要注意的是，和其他通用的 LLM 相比，作者的 baseline 是專門為了 reference resolution 而設計的。\nChatGPT 作者考慮 GPT-3.5 和 GPT-4 作為另外一個 baseline。\n對於 GPT-3.5，輸入只包含 prompt。\n對於 GPT-4，因為他可以接受圖片的 context，所以為系統提供了螢幕截圖，發現可以有效提高其效能。\nOur Approach 作者遵循以下 pipeline 來微調模型 (FLAN-T5)\n向模型提供解析後的輸入，並用來微調。\n和 Baseline 不同，作者沒有在 FLAN-T5 上進行大規模的超參數搜索，而是堅持使用預設的參數。\nConversational References 作者假設 conversational references 有兩種：\nType-based 這種非常依賴要將 query 和 entity type 結合，好進行識別 比如「打給他」，可以知道要的是電話號碼，而不是地址 Descriptive 傾向於用唯一的實體屬性來標記他，比如「時代廣場的那個」 referenece 通常會同時依賴 type 和描述，比如「play the one from Abbey Road」和「directions to the one on Abbey Road」。\nOnscreen References 作者假設存在能夠解析螢幕文字以提取 Entity 的上游資料偵測器。\n為了以僅涉及文字的方式將其編碼到 LM 中，使用 Algorithm 2。\n直觀上，假設所有實體和周圍物件的位置都可以用它們各自的邊界框的中心來表示。\n然後從上到下對這些中心進行排序，並用 stable sort 從左到右排序。\n然後，所有在一個 margin 內的物件都會被視作在 same line，並用 tab 隔開。\n在 margin 下方外面的會被放在下一行，然後不斷重複。\nResults Model Conv Synth Screen Unseen MARRS 92.1 99.4 83.5 84.5 GPT-3.5 84.1 34.2 74.1 67.5 GPT-4 97.0 58.7 90.1 98.4 ReALM-80M 96.7 99.5 88.9 99.3 ReALM-250M 97.8 99.8 90.6 97.2 ReALM-1B 97.9 99.7 91.4 94.8 ReALM-3B 97.9 99.8 93.0 97.8 Table 3:\n預測正確的標準是要正確預測所有相關實體，不然就是錯的\n作者發現它們的方法贏 MARRS 和 GPT-3.5。 GPT-3.5 的餐數量還多出了幾個數量級。\n盡管模型相較 GPT-4 輕的多，但是性能大致相同。\n而且作者採用文字編碼的方法能夠讓模型和 GPT-4 幾乎同等效能，後者還提供了螢幕截圖。\n隨著模型加大，提升也很明顯，特別是 Screen，暗示任務本質上更加複雜。\nAnalysis $GPT-4 \\approx ReALM \u0026raquo; MARRS$ for new use-cases 測試了 zero-shot learning 的能力，Table 3 最後一個 column 就是在比較從未見過的資料集。 作者發現對於測試集，所有 LLM-based 的方法都贏過 Fine-tuned Model ReaLM \u0026gt; GPT-4 for domain-specific queries 作者發現 ReALM 因為有對 user requests 做 fine-tuning，所以更能理解 domain-specific questions，如下表 (Table 4) 1 2 3 4 5 6 7 User Request: Can you make it brighter? --- Entities Shown to User: 1. Type: Settings 2. Type: UserEntity | homeAutomationAccessoryName --- GPT-4 Prediction: 1 Ground Truth: 1, 2 Table 4\n","date":"2024-04-18T00:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/realm-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"ReALM 論文閱讀"},{"content":"paper: Exploiting Structural Consistency of Chest Anatomy for Unsupervised Anomaly Detection in Radiography Images\n個人前言 這篇文章提出了許多在 SQUID 論文有出現過的的內容，特別是有關於放射線成像的描述等等，建議先看過 SQUID，重複的論點不再提及。\nAbstract 提出一種簡單的 Space-aware Memory，用於修復放射線成像的異常。\n將異常檢定制定為 image reconstruction task，用 space-aware memory matrix 和 in-painting block 組成。\nRelated Work Our Previous Work 相對於 SQUID，本文有以下四點改進：\n引入了新的符號、公式和圖表，以及詳細的方法說明及學習目標 刪除 Memory Queue 和 Masked shortcut，簡化框架，還提高了效能 在三種放射線成像任務勝過其他 21 種 SOTA 方法 研究了 SimSID 對於 desease-free (訓練集中對異常資料的容忍) 的穩健性 SimSID Developing Space-aware and Hierarchical Memory Space-aware memory $\\hat{z}_{i,j}$ (augmented feature)\n$=\\displaystyle\\sum^N_{k=1}G(s^{k})M^k_{i,j}$\n$s^k$ 是做內積算出來的相似度\n$G(\\cdot)$ 是 Gumbel-softmax (用 SQUID 的 Gumbel Shrinkage)\n$Memory Matrix$ 被拆成多個 block，才有 $M_{i,j}$\nHierarchical memory 在 encoder 最深處使用一個 memory matrix (in-painting block) 不足以重建具有細節的高品質圖像。\n為了捕捉不同尺度的 anatomic patterns，提出在 generator 的多個 level 放置 space-aware memory。\n研究發現，太多的 memory 會導致過度的 information filtering，還會 degrade 模型，導致他只會保留最具代表性的 normal pattern，而不是所有需要的 pattern。\n這個問題可以透過添加 skip connection 來解決。\n從經驗發現三個 memory matrix 就已足夠。\nResults Benchmarking SimSID on Three Public Datasets 對於正常的情況， SimSID 可以在 memory 中找到相似的匹配，然後順利重建。\n對於異常，將偽造的正常特徵強加到異常特徵，就會產生矛盾。\n圖 7 繪製 Discriminator 的 heatmap 來指示出重建效果不佳的部分。\n","date":"2024-04-13T00:27:55+08:00","permalink":"https://roykesydon.github.io/Blog/p/simsid-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"SimSID 論文閱讀"},{"content":"paper: SQUID: Deep Feature In-Painting for Unsupervised Anomaly Detection\nAbstract Radiography imaging protocols (放射線成像協定) 會專注於特定的身體區域，因此會在患者間產生大量相似的照片。\n為了利用這種 structed information，作者提出了 Space-aware Memory Queues for In-painting and Detecting anomalies from radiography images (SQUID)，它可以把固有的人體結構分類為反覆出現的 pattern。\n在推理狀態下，它可以識別圖片中的異常情況。\n比較兩個 chest X-ray benchmark，SQUID 在非監督異常檢測上超越了 13 種 SOTA 方法至少 5 個百分點。\n作者還創建了一個新的資料集 (DigitAnatomy)，該資料集結合了胸腔解剖學中的 spatial correlation 和 consistent shape 這兩個特性。\nIntroduction 放射線成像和一般圖片的差別 一般的 photographic imaging 和 radiography imaging 是不同的。一般的圖片物體，我們會假設 translation invariance (平移不變性)，無論貓在左右，都是貓。但是在放射線成像中，結構的相對位置和方向是辨別正常和異常的重要特徵。 而且由於 radiography imaging protocols 以相當一致的方向評估患者，成像在不同的設備製造商、設施位置還有患者的情況下，都具有很大的相似性。像這樣反覆出現且一致的結構，有助於分析問題，是放射線成像的優勢。 有多項研究證明了許多先驗知識在增強深度學習模型性能上的優勢，比如添加 location features、修改目標函數還有約束相對於照片中 landmarks 的相對座標。\n想解決的問題\n多達 80% 的臨床錯誤是由於放射科醫生漏掉異常而造成。 本文想回答一個關鍵問題：有沒有辦法利用 anatomical patterns 的 consistency 和 spatial information，在沒有手動標註的情況下，加強深度學習模型的異常檢測能力？非監督的異常檢測只用健康的圖片進行訓練，不用疾病診斷或任何 label。 SQUID 解決辦法\n本文不像先前的異常檢測方法，本文把 task 制定為 in-painting task (圖像修復)，好利用放射線成像的外觀、位置、布局。\n作者提出了 SQUID，在訓練過程中，模型可以透過空間中經常出現的 anoatomical patterns 來動態維護一個 visual pattern dictionary。\n由於解剖學的 consistency，健康成像中的身體區域會呈現類似的 visual pattern，使 unique pattern 的數量是可控的。\n在推理階段，由於 dictionary 不存在 anomaly pattern，因此如果存在異常，產生的放射線成像會和現實有所差距。因此，模型可以透過區分修復任務的品質來識別異常。\n實驗假設\n異常檢測的成功基於兩個假設 資料中很少異常圖片 異常和正常有顯著不同 實驗\n在兩個大規模、公開的放射線成像資料集上實驗 ZhangLab 在非監督方面贏 SOTA 超過 5 個百分點 Stanford CheXpert 比最近的 13 種方法提高 10 個百分點 新資料集\n創建了 DigitAnatomy 資料集，闡明胸腔解剖結構的 spatial correlation 和 consistent shape。 貢獻總結\n在胸腔放射線成像的新非監督 SOTA 異常檢測方法 新的綜合資料集 發明新方法打敗主流非監督異常檢測方法 Related Work Anomaly detection in natural imaging 識別偏離正常資料分佈的罕見事件 由於異常樣本的缺乏，後來的工作都制定為非監督學習問題 大致分為兩類 reconstruction-based 恢復原始輸入並分析重建誤差 density-based 透過估計正常資料的分佈來預測異常 不過這些方法都沒辦法解釋可能的異常，本文透過維護 visual pattern memory 來解決這個問題 Anomaly detection in medical imaging 基於監督學習的方法多半用於檢測特定種類的異常，比如腫瘤 最近提出了一些無監督方法來檢測一般異常，和 GAN 有關，但是這些方法需要有關於異常種類的強大先驗知識和假設才能使增強有效 和一般的照片不同，Radiography imaging protocols 生成具一致性的圖片，異常的變化比較微妙 (subtle)，檢測起來更具挑戰，作者利用放射線成像的特性，大大提高檢測性能。 Memory networks 過往有一些有關於把 Memory modules 納入神經網路的研究，其中有採用到 Memory Matrix。本文克服了 Memory matrix 的侷限性，並提出一種有效且高效率的的 memory queue。 SQUID Overview Feature extraction\n把圖片切成 N x N 個 non-overlapping patches，然後餵入一個 encoder 做特徵提取，這裡是用 CNN 提取，但要用其他 backbone 也可以 Image reconstruction\n這裡會用 teacher 和 student generator teacher 直接用 encoder 的 feature 重建圖片 本質上是 auto-encoder 作為 regularizer 來避免 student generator 重複生成相同的正常圖片 student 使用 in-painting block 增強後的 feature 來重建，最後會被用在 discrimination 兩個 generator 會在每個 up-sampling level 用 knowledge distillation paradigm 來結合 Anomaly discrimination\n在 adversarial learning 後，使用 discriminator 來區分正常和異常 用 2 個 generator 來生成圖片，再用 discriminator 來區分，只有 student generator 會接收 discriminator 的梯度 Inventing Memory Queue as Dictionary Motivation Memory Matrix 被廣泛採用 Feature 會透過在 Memory matrix 做加權平均來強化 缺點 這樣的增強方法是對整張圖片的提出的特徵做的，丟棄了圖片中的 spatial information。導致他無法感知到放射線成像中的一致性結構 Space-aware memory 為了利用空間資訊，作者只將 patch 而不是整張圖片傳遞到 model，讓 patch 只能存取 Memory matrix 中對應到的區段，作者把這種策略稱為 Space-aware memory，而且還可以加快速度，因為不用存取整個 Memory matrix Memory queue 在 learning-based Memory matrix 中，normal patterns 是由 matrix 中的 learned basis 組合而成，但組合出來的東西和現實照片的特徵總會有分佈差距，使後續的影像生成變得困難 作者提出 memory queue，用來在訓練期間儲存真實的影像 feature，從而呈現和影像特徵相同的分佈。它在訓練期間會把先前看到的特徵直接複製到 queue Gumbel shrinkage 控制 memory matrix 中 activated pattern 的數量是有利的，但如果用 hard shrinkage threashold 會無法處理找不到合適 entry 的情況。一種自然的解法是讓梯度流過前 k 個相似的 entry，其餘的不更新。但這樣又會導致未啟動的 entry 無法接收任何梯度並更新，因此提出了 Gumbel shrinkage schema $w\u0026rsquo; = sg(hs(w,topk(w)) - \\phi(w)) + \\phi(w)$ $w$ 代表 feature 和 entry 的相似度 $sg(\\cdot)$ 代表 stop-gradient，不計算輸入的梯度 $hs(\\cdot, t)$ 代表 hard shrinkage，有個 threshold $t$ $\\phi(\\cdot)$ 代表 softmax 這樣保留了 top k 作為 w 的最終結果，又用 softmax 對所有 entry 進行更新 Formulating Anomaly Detection as In-painting Motivation\nImage in-painting 最初是用來恢復具有 neighboring context 的圖片區塊，因此根據此直覺，想把異常圖片修復成正常圖片來實現檢測 在修復像素的時候，特別是用深度網路，容易有 boundary artifacts，在 pixel 級別的修復中，這些 boundary artifacts 會導致大量誤報 artifact 中翻好像是「偽影」，就是重建的時候會呈現有點像棋盤的效應 作者選擇在 feature level 進行 in-painting，避開這問題 In-painting block\n會先把每個 patch $F_{1,1}$ ~ $F_{w,h}$ 都先找到最接近的 normal patterns $N_{1,1}$ ~ $N_{w,h}$ 因為 N 是之前訓練資料中提取的特徵組成的，不受當前輸入影像的影響。為了導入輸入圖片的特徵，作者把 F 和 N 用 transformer block 來結合 對於每個 patch $F_{i,j}$，會把其當作中心，用相鄰的 8 個 N patch 來重新定義 $F_{i,j}$，把這 8 個 N patch 作為 key 和 value，$F_{i,j}$ 作為 query 最後會在 in-painting block 的前後做 point-wise convolution (1x1) Masked shortcut\n實驗結果表明，直接做 residual connection 會降低修復的性能，作者採用 random binary mask 在 training 期間 gate shortcut feature $F\u0026rsquo;=(1-\\delta)\\cdot F + \\delta \\cdot inpaint(F)$ $\\delta$~$Bernoulli(\\rho)$ $\\rho$ gating probability 獲得 F\u0026rsquo; 後，原始的 F 會被更新進 memory 在推論階段，會 disable shortcut，使 $F\u0026rsquo;=inpaint(F)$ Anomaly Discrimination Discriminator 評估圖片現不現實，不現實表示異常 因為 Generator 只在正常圖片訓練，所以 Memory Queue 也只有 normal pattern 稍微總結 in-painting block 會把 patch 強化為相似的 normal feature student generator 會根據 \u0026ldquo;normal\u0026rdquo; feature 重建出 \u0026ldquo;normal\u0026rdquo; image 如果沒有異常的話，那 input 和重建的 image 在語意上應該相差很小 異常分數 $A$ 的算法 $A=\\phi(\\frac{D(G_s(E(I)))-\\mu}{\\sigma})$ $\\phi(\\cdot)$ 是 sigmoid function $\\mu$ 和 $\\sigma$ 是根據 training samples 算出的異常分數的平均值和標準差 Loss Function Generator $\\mathcal L_t = (I-G_t (E(I)))^2$ $\\mathcal L_s = (I-G_s (E(I)))^2$ Knowledge distillation $\\mathcal L_{dist} = \\sum_{l}^{i=1} (F^i_t-F^i_s)^2$ $l$ 是 levels of features Adversarial loss 類似 DCGAN $\\mathcal L_{gen} = log(1-D(G_s(E(I))))$ Discriminator $\\mathcal L_{dis} = log(D(I)) + log(1-D(G_s(E(I))))$ 把 real image 機率拉高，把 fake image 機率拉低 Total loss minimize generative loss $\\lambda_t \\mathcal L_t + \\lambda_s \\mathcal L_s + \\lambda_{dist} \\mathcal L_{dist} + \\lambda_{gen} \\mathcal L_{gen}$ maximize discriminative loss $\\lambda_{dis} \\mathcal L_{dis}$ Experiments New Benchmark 提出一個新資料集 - DigitAnatomy。。如果包含正確順序的阿拉伯數字 1~9 則視為正常，異常包括缺失、亂序、翻轉和 zero digit。\n該資料集對於放射線成像尤其有利，原因如下:\nspatial correlation and consistent shape 放射線成像要標記需要專業知識，但數字容易 debug 該資料集很容易就可以獲得模擬異常的 ground truth Public Benchmarks ZhangLab Chest X-ray 包含健康和肺炎的影像 訓練集 1349 張正常 3883 張異常 測試集 234 張正常 390 張異常 作者從訓練集隨機挑 200 張做為調整超參數的 validation set 影像都調整為 128x128 Stanford CheXpert 對 front-view PA 影像進行評估，共有 12 種異常 有 5249 張正常和 23671 張異常用作訓練 使用和 ZhangLab 相同的超參數 用訓練集的 250 張正常和 250 張異常進行測試 Baselines and Metrics 考慮 13 個主要的 baseline\n經典 UAD (unsupervised anomaly detection) Auto-encoder、VAE 醫學影像的 SOTA Ganomaly、f-AnoGAN、IF、SALAD 最近的 UAD MemAE、CutPaste、M-KD、PANDA、PaDiM、IGD 除非有特別註明，不然都是從頭獨立訓練至少三次\nResults Interpreting SQUID on DigitAnatomy 作者在 DigitAnatomy 的實驗中，故意注入異常到正常圖片中，測試模型是否可以重建正常圖片。\nSQUID 重建出的圖片比其他 baseline 有更多有意義的訊息，主要歸功於 space-aware memory，其產生獨特的 pattern，而且和空間訊息相關聯。\n一旦出現異常，in-painting block 會從字典中找出前 k 個相近的，把異常特徵增強到其對應的正常特徵，其他方法不具備此能力，所以他們重建出有缺陷的圖像。\nGAN 傾向於重建訓練樣本平均得到的影像。 MemAE 受益於 Memory matrix，表現較好，但對於缺失數字的異常效果不佳。\nBenchmarking SQUID on Chest Radiography Limitation 作者發現目前的 SQUID 沒辦法在像素層級精確定位異常。這可以理解，因為 SQUID 是一種非監督方法，不需要標註。\n那些像素級別的異常檢測會遭遇放大雜訊的影響，但是由於 SQUID 是在特徵層級進行的，比像素級別更加 robust。\nAblating Key Properties in SQUID Component study Hyper-parameter robustness Disease-free training requirement? 用於醫學異常檢測的非監督方法並不常見，因為所謂的 UAD 方法並不是「非監督」的，因為他們必須只在無疾病影像上作訓練。\n在實踐中，要獲得健康圖片需要 manual annotation。\n在訓練集中考慮 disease-free 從 100% - 50% 的情況，把 SQUID 的 robust 和另外三個 baseline 進行比較。\nSQUID 的 memory queue 可以自動忽略少數的 anatomical patterns。\n","date":"2024-03-31T00:27:55+08:00","permalink":"https://roykesydon.github.io/Blog/p/squid-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"🦑SQUID🦑 論文閱讀"},{"content":"Abstract 本文想在 manufacturing context 下開發一個 XR (extended reality) 架構，想用 XR 整合並改善傳統工作流程。\n該框架包含五個 iterative phase:\nRequirement analysis Solution selection data preparation system implementation system evaluation 此實驗也強調了 user-centered 的方法在開發有關製造業的 XR 系統的重要性。\nIntroduction 作者認為 XR 系統的整合對製造業的轉型很重要，有助於實現 Industry 4.0。\n盡管研究顯示 XR 在製造業中有巨大潛力，但工程師在日常生活中用 XR 的系統很少，顯示出整合 XR 到製造業是困難且具備挑戰性的。\n本研究想開發一個系統框架，支援未來 XR 系統在製造業的開發，而不是只停留在「wow effect」\nFrame of reference Extended Reality Classification 透過電腦實現的現實增強技術可以追溯到 1960s，在近年演變成多種子集，也因此產生不同術語，使人困惑。\n本文說的 XR 被用作總稱，代指所有以電腦為媒介的 Reality Technologies。\n區分不同系統的 XR 十分重要，這樣才能針對製造業中任何一個特定的應用作出正確的決策。\n一種常見的方法是 reality-virtuality continuum，把現實世界和虛擬世界放在兩端，根據靠近哪端進行區分。\n左端是現實世界，右端是虛擬世界。從左到右出現 augmented reality(AR)、mixed reality(MR) 和 virtual reality(VR)\nAugmented Reality (AR) 最廣泛的定義，有以下三個特徵 結合虛擬與現實 要可以 real-time 的互動 顯示在 3D 空間 用戶要依然可以看到周遭環境，並與之互動，同時獲得諸如文字或圖片的增強體驗 可透過 smart glass 或手機實現 Mixed Reality (MR) 可以定義為把現實世界和虛擬世界中的東西呈現在一起的應用程式，也就是 reality-virtuality continuum 上的任何位置 MR 比 AR 更進一步，不只希望虛擬物體疊加在現實世界上，還希望使用者可以像對待真實物體一樣和他們互動 為了實現 MR，需要一台整合了電腦、半透明玻璃、和感測器的耳機 某種意義上是更具沉浸感的 AR Virtual Reality (VR) 使用者完全沉浸在虛擬世界中，無法看到現實世界 有三種典型設定：獨立耳機、CAVE (房間是大型投影幕)、連接到電腦的頭戴式顯示器 最後一種已佔據主導地位 Hardware parameters for extended reality 深入了解硬體參數也很重要，會影響可用性\nField of View (FOV) 人類的 binocular FOV 大約是 114 度，XR 使用的螢幕具有類似的視野才會是理想的，確保用戶有無縫體驗 通常 AR 和 VR 的 FOV 會小的多，只有 30-60 度，每次呈現有限的虛擬內容，當需要渲染大型虛擬物件時就會有問題 由於 AR 和 MR 並不排斥現實世界，所以如果內容尺寸適當，不影響使用者感知 現今的 VR 頭戴裝置 FOV 大得多，落在 90-110 度之間 一些先進的模型甚至聲稱到 200 度，超過人類的 FOV 具有較小 FOV 的耳機會因為「tunnel vision effect」而分散用戶的注意力 Frame per Second (FPS) 對於 MR 或 AR，30-60 FPS 就足夠了，VR 則建議爭取到 90 由於使用者沉浸在電腦生成的內容，FPS 太低會導致 motion jitter，導致用戶產生 motion sickness FPS 不單由硬體決定，也由軟體決定 Software for extended reality 作者將其分為兩大類，基於「開放開發平台的方法」和基於「已有商業軟體的擴展方法」。開放式開發平台的優點是開發過程完全受控，可以根據個人需求訂製，但需要軟體工程方面的專業知識。\n當今製造業使用的成熟商業軟體也在擴大對 XR 功能的支援，因此，現有用戶可以毫不費力創建 XR 體驗。然而，使用此類軟體來探索 XR 新功能的自由度有限，因為它依賴軟體供應商的更新。\nOpen development platform 兩大主要平台是 Unity3D 和 Unreal Engine 4 Established commercial software 範例 Siemens 的 Plant Simulation 雖然缺乏更高程度的客製化自由度，但節省了創建通用功能的時間和成本 Research Approach 本文為了開發一個可以提高未來 XR 系統的可用性和接受度的框架，選擇了六個案例。\n它們各自採用了代表了不同公司製造活動的四個階段：design、training、operation、disruptive\nFramework development XR 系統整合框架的開發採用了 SDLC，也被稱作 application development life cycle，常被用在開發各種 IT 系統。 描述了系統設計人員和開發人員為了確保開發品質，需要遵循的多個階段活動。\n多年來，基於 SLDC 方法開發了各種模型和方法，比如瀑布式開發或是 Scrum。\n本研究中採用的 SDLC 階段如下：\nIdentifying problems Analyzing the needs Designing the system Developing and documenting Testing the system Implementing and maintenance Case 1 Background 要訓練人員維護機器\nResarch Process 有公司進行了案例研究，開發了一種支援小型工具箱維護任務的 AR 系統\nResult and conclusion 文本教學容易被忽略，以吸引人的物件符號改進。 最後問卷持正面態度。 但還是有一些可改進的點，比如需要連接電腦，在實際工廠車間並不方便。\nCase 2 ~ Case 6 時間問題暫不補\nThe proposed framework 針對上一節 SDLC 的案例總結和整合，結合了以使用者為中心的 XR 系統開發五步驟框架。\nStep 1: Understanding the requirements 聽起來很顯而易見，但實踐中常被跳過或淡化，導致不令人滿意的結果。 而且製造環境比一般用例場景更加複雜。\n全面了解需求是成功開發 XR 系統的重要第一步。 以使用者為中心的設計方法中，採用的比如 observation、stakeholder workshop、contextual inquiry、storyboard、prototyping adopted 都被證明在是別需求方面是有效的。\n應該要可以回答以下問題：\nWhat actions are taken? What support are used? What outcome are achieved? What main drawbacks are there? 回答上述問題後，就可以開發 storyboards 和 prototypes 了。\n此外，不只是開發者和負責人，最終用戶也要可以參與評估和回饋，直到最終的需求被解決。\nStep 2: Solution selection 通常是根據公司現有硬軟體來選擇，而不是根據哪種解決方案最能滿足要求，使選方案是個困難的決定。\nStep 3: Data preparation Step 4: System implementation Step 5: System evaluation Iteration 在完成所以提出的步驟後可以迭代，以小量的改進進行迭代，直到達成特定需求。\nFramework validation 該框架被用於一個真實案例，用來評估適用性。 此外，他還與六項先前的研究進行驗證，這些研究部分與提出的框架一致。\nThe empicial case 本文的框架被用於開發 VR 工具，好支援汽車公司的產品設計審查。\nRequirement analysis 是一家分布全球的汽車公司，研發中心在瑞典，工廠在中國。\n具體任務是對用於點焊的新型 fixtures 進行 design review。\n目前的做法依賴 CAD 軟體分布在不同地點的不同團隊之間來傳達理念。\n他還需要一個或多個原型，在最終安裝前進行驗證。\n主要缺點是，和原型實體相關的溝通十分冗長。\n此外，最終使用者 ( operators of fixtures) 缺發 CAD 設計的專業知識，導致他們無法參與設計。\n因此，提出了具體要求：\n適用於所有 stakeholder 的虛擬工具，可以直觀地視覺化新產品設計，並和新產品設計互動 多個 stakeholder 可以從不同的地點參與同一個 virtual session 所有 stakeholder 都可以口頭交流 virtual session 可以用圖像或影片形式記錄 每個 stakeholder 都要有個人化虛擬代表 要有主持人、與會者和觀眾等角色相關功能 Solution selection 選 VR 和 Unity3D\nData preparation System implementation System evaluation 進行兩次迭代開發，評估 VR 系統是否可以補充或甚至取代現有作法的可行性\nOutcome 開發了一個可以支援最多 20 個使用者從任何有網路的地方連線加入的應用程式。\nExternal Validation 作者挑了七篇有關的 XR 整合到製造業的研究，他們都採取了類似的方法，部分與提出的框架一致。\nConclusion 本文第一個貢獻是根據案例結果提出的框架，由五個迭代階段組成：\nRequirement analysis Solution selection Data preparation System implementation System evaluation 通過一個實際案例以及七項先前的研究進行了驗證，這些研究與提出的框架部分一致。\n該研究還會工業從業者提供了知識，有利他們採用 XR 技術做為 工業 4.0 的一部分。\n","date":"2024-03-30T00:00:01+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80a-framework-for-extended-reality-system-development-in-manufacturing/","title":"論文閱讀：A Framework for Extended Reality System Development in Manufacturing"},{"content":"paper: Matryoshka Representation Learning\nAbstract 想設計 flexible 的 representation 好適應不同的下游任務\nMRL 根據不同的 granularities 來 encode 資訊，並允許一個 single embedding 來適應下游任務的運算限制\nMRL 學習從 coarse-to-fine 的 representation，至少和獨立訓練低維度的 representation 有一樣的準確度\n在相同精準度下，MRL 的 embedding 縮小 14 倍\n在 ImageNet-1K 和 4K 上進行大規模檢索時，實際速度提升 14 倍\nlong-tail few-shot learning 的準確度提高 2%，並且和原有 representation 一樣 robust\n最後，作者證明 MRL 可以無縫地擴展到各種模式的網路規模資料集，包含 Vision, Vision + Language, 和 Language\nIntroduction deep representation 的 deployment 有兩個步驟：\n昂貴的 forward-pass 計算 representation representations 在下游的利用 (比如檢索) 在 web-scale 上，這種利用的成本蓋過了特徵計算成本\n常見的做法的 representation 的剛性迫使多個任務中使用高維嵌入向量\n人類對自然世界的感知是由粗到細的粒度\n然而，或許是基於梯度訓練的 inductive-bias，深度學習傾向於將「資訊」擴散到整個表示向量中\n通常透過訓練多個低維模型、聯合優化不同容量的子網路、事後壓縮，在現有的 fixed representation 上實現彈性\n這些技術中的每一種都難以滿足自適應大規模部屬的要求，基於開銷 / 維護考量等等\nMRL 以 nested 的方式來學習 O(log(d)) 個相同的高維向量、但不同 capacity 的 representation，因此被稱為 Matryoshka\nMatryoshka Representation 提高了大規模分類和檢索的效率，而不會顯著失去準確度\n本文重點關注在機器學習系統的兩個關鍵模組：大規模分類和檢索\n在分類上，作者使用 variable-size representations 結合 adaptive cascades 來顯著減少實現特定精度所需嵌入的平均維度\n例如，在 ImageNet-1K 上，MRL + Adaptive classification 在和 baseline 同精準度的情況下將 representation 縮小 14 倍\n對於檢索，先用 query embedding 一開始的 few dimensions 來減少 retrieval candidates，然後再用更多的 dimensions 來 re-rank retrieved set\nMRL 的檢索精確度和 single-shot retrieval 相當\n主要貢獻如下：\n提出了 MRL 來獲得 filexible 的 representation for adaptive deployment 使用 MRL 進行大規模分類和檢索，速度提高 14 倍而且一樣準確 可以在跨 modalities 還有可接受 web-scale 資料的情況下無縫調整 MRL 在其他下游任務的背景下進一步分析 MRL 的表示 Related Work Efficient Classification and Retrieval 在推理過程中，分類和檢索的效率可以從兩個方面研究：\n深度特徵的高但恆定的成本 隨著標籤空間和數據大小而變化的搜索成本 第一個問題可以透過不同的演算法設計高效的神經網路來解決\n但是，伴隨著強大的 featurizer，多數 scale 相關的問題出在 標籤數量(L)、資料大小(N)、或是表示維度(d) 這種 linear dependence 上\n讓 RAM, disk 和 CPU 都同時有巨大的壓力\n標籤數量在計算和 RAM 方面已經得到了很好的研究，可以透過 Approximate Nearest Neighbor Search (ANNS) 或 leveraging the underlying hierarchy 來解決\n在表示大小方面，降維、Hash 和特徵選擇等技術常用於緩解 O(d) 的增長規模，但代價是精確度的顯著降低\nANNS 使用戶可以從資料庫中取得和請求最相似的文件或圖片\n廣泛採用的 HNSW 可以讓 O(d log(N)) 和準確搜索 O(dN) 一樣精準，但代價是需要在 RAM 和 disk 承擔 graph-based index 的開銷\nMRL 解決對 d 的線性依賴問題，低維度的 Mayryoshka representations 和獨立訓練的 representations 一樣準確，而不需要多次昂貴的前向傳遞\nMatryoshka Representation Learning 有分兩種訓練方法：\nMatryoshka Representation Learning (MRL)\n在後面接 9 層 MLP，不是串聯，是並聯 比如 mlp(768,8)\u0026hellip;., mlp(768,2048) Efficient Matryoshka Representation Learning (MRL-E)\n在後面只接 1 層，然後取前面維度得到一個向量，以此類推 比如 mlp(768, 2048)，可能取前 16 維當一個向量，然後再取前 64 維當一個向量 ","date":"2024-02-26T00:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/mrl-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"MRL 論文閱讀"},{"content":"paper: REALM: Retrieval-Augmented Language Model Pre-Training\nAbstract 為了用更加模組化和可解釋的方式獲取知識，作者用 latent knowledge retriever 來加強語言模型的預訓練，latent knowledge retriever 允許模型檢索 large corpus 的 document，並在預訓練、微調和推理時使用。\nIntroduction 在諸如 BERT 的語言模型中，學到的 world knowledge 隱式地儲存在神經網路的參數中，使其很難確定儲存了哪些知識以及儲存在何處。而且儲存空間受網路大小限制，但訓練更大的網路可能非常昂貴\n本文為了以更加可解釋和模組化的方式獲取知識，提出了一個新穎的框架，Retrieval-Augmented Language Model (REALM) 預訓練，透過 learned textual knowledge retriever 來加強預訓練\n和把知識儲存在參數中的模型相比，該方法顯示地揭示 world knowledge 扮演的角色，做法是要求模型在推理過程中決定哪些知識來 retrieve，並用在推理階段\n在每次預測前，語言模型使用 retriever 在 large corpus 搜索文件，並用這些文件幫助預測\nEnd to End 的學習需要考慮整個檢索步驟，好進行反向傳播\nREALM 有個關鍵直覺，就是訓練 retriever 的時候用的是 unsupervised text 的 performance-based signal：\n一個可以提高語言模型複雜性的檢索是有幫助，且該被獎勵的 資訊不足的檢索應該受到懲罰 比如圖 Fig.1 找到的文件就該獲得獎勵\n作者將 retrieve-then-predict 的方法建模並視作 latent variable language model 並優化 marginal likelihood\n但在預訓練期間要訓練大規模的 retrieval module 成為問題，因為 Retriever 得為每個預訓練步驟考慮數百萬個候選文檔，而且必須根據決策反向傳播。為了解決這問題，作者建構了 retriever，以便快取和非同步更新每個文件的計算，並將最佳文件的選擇表示為 Maximum Inner Product Search (MIPS)\n透過在 Open-QA 任務上使用 REALM 預訓練的 model 來 finetune 進行評估，OpenQA 是最 knowledge-intensive 的任務之一\n作者挑了三個流行的 Open-QA benchmark，比如 NaturalQuestions-Open、WebQuestions、CuratedTrec，並和 SOTA Open-QA model 比較\n在三個基準都取得了 SOTA 的結果，absolute accuracy 明顯高於先前系統 4-16%\n也展示了 REALM 的 qualitative benefit，比如可解釋性和模組化\nBackground Open-domain question answering (Open-QA) OpenQA 的 open 是指模型不會接收到包含答案的預提供文件，和傳統的閱讀理解不同\nApproach REALM’s generative process 預訓練做 masked language modeling，微調的任務是 Open-QA\nModel architecture neural knowledge retriever 是 $p(z|x)$\nknowledge-augmented encoder 是 $p(y|z,x)$\nKnowledge Retriever $p(z|x)=\\frac{\\text{exp }f(x,z)}{\\sum_{z\u0026rsquo;}\\text{exp }f(x,z\u0026rsquo;)}$\n$f(x,z) = Embed_{input}(x)^T Embed_{doc}(z)$\n$join_{BERT}(x)=[CLS]x[SEP]$\n$join_{BERT}(x_1, x_2)=[CLS]x_1[SEP]x_2[SEP]$\n$Embed_{input}(x)=W_{input}BERT_{CLS}(join_{BERT}(x))$\n$Embed_{doc}(z)=W_{doc}BERT_{CLS}(join_{BERT}(z_{title}, z_{body}))$\nKnowledge-Augmented Encoder Finetune:\n$p(y|z,x) \\propto \\displaystyle\\sum_{s\\in S(z,y)}exp(MLP([h_{START(s)};h_{END(s)}]))$\n$h_{START(s)}=BERT_{START(s)}(join_{BERT}(x,z_{body}))$\n$h_{END(s)}=BERT_{END(s)}(join_{BERT}(x,z_{body}))$\nTraining 關鍵的計算挑戰是 $p(y|x)=\\sum_{z\\in Z}p(y|x,z)p(z,x)$，涉及到 Z knowledge corpus 中的 所有 document z，因此只取機率 $p(z|x)$ 最高的 top k 文件來求和，考量到多數文件的機率應該為 0，這是合理的\n但是依然需要一個有效的方法來尋找前 k 個文件\n前面的 $f(x,z)$ 是一個內積，可以用 Maximum Inner Product Search (MIPS) 演算法來尋找近似前 k 個文檔\n為了用 MIPS，要先用一種 embedding 函式來幫 z encode，但是如果更新了這個函式，資料結構和 $p(z|x)$ 又會不一致\n因此，每次對 embedding 函式更新後，search index 都會變 \u0026ldquo;stale\u0026rdquo; (陳舊)\n每隔數百個訓練步驟非同步重新 embed 和 index 所有 document 來刷新 index\nMIPS 的 index 在刷新之前會有點 stale，但它只用於挑選前 k 個文件\n結果證明，只要在恰當的刷新率下，還是可以穩定 optimize\nWhat does the retriever learn? 這裡展示了它如何獎勵提高預測準確性的檢索\n$\\triangledown \\text{log }p(y|x)=\\displaystyle\\sum_{z\\in Z}r(z)\\triangledown f(x,z)$\n$r(z)=[\\frac{p(y|z,x)}{p(y|x)}-1]p(z|x)$\n如果 $r(z)$ 是正的，會讓 f(x,z) 提高，否則減低\n$r(z)$ 只有在 $p(y|z,x)\u0026gt;p(y|x)$ 的情況下才會是正的\n$p(y|x)$ 是 $p(y|x,z)$ 在隨機取樣的情況下的期望值\n只要文檔 z 好過預期，就會持續正面更新\nInjecting inductive biases into pre-training 在發展 REALM 的過程中，作者發現幾個額外策略，可以進一步引導模型進行有意義的檢索\nSalient span masking 有一些 MLM span 只需要 local context，但作者想專注於 world knowledge\n所以作者會 mask 一些 salient span，比如「英國」、「1969 年 7 月」\n作者用在 CoNLL-2003 上訓練的 BERT-based tagger，來找出 named entities，並用正規表達式來找出日期\n結果表明這顯著優於其他 mask 策略\nNull document 雖然 Salient span masking 表現很好，但不是所有 mask 都需要 world knowledge\n透過向前 top k 文檔中多加一個空的文檔，允許在不需要檢索有空白選項\nProhibiting trivial retrievals 如果 mask 的句子來自文件 z，可以透過查看 z 中 x 的 unmasked 版本來輕鬆預測 y，使 p(z|x) 出現較大的梯度，如果這種情況太頻繁，會使 retriever 最終學會的東西偏向 exact match，而不會捕獲其他形式的相關性\n因此，在預訓練期間排除了 trivial candidate\nInitialization 在訓練開始時，如果 input 和 document 各自的 Embedding function 沒有良好的效能，會使檢索到的 z 和 x 無關\n會導致模型學習忽略檢索到的文件，檢索器就不會收到有意義的梯度，也無法改進\n為了避免 cold-start problem，作者採用 warm-start 方案，先以 Inverse Cloze Task (ICT) 這種簡單的目標來處理兩個 embedding function，給定一個句子，訓練模型檢索句子來自的文檔\nExperiments Open-QA Benchmarks 本文將重點放在問題作者不知道答案的資料集，比較能反映現實中的問題\nNaturalQuestions-Open 由自然發生的 google 查詢和答案組成，每個答案還帶有 answer type\n本文只用屬於 \u0026ldquo;short answer type\u0026rdquo; 的問題，最多有 5 個 token\nWebQuestions 從 Google Suggest API 收集的\nCuratedTrec 從 MSNSearch 和 AskJeeves 等網站上真實使用者查詢中提取的問答\nApproaches compared Retrieval-based Open-QA 最近的一些方法提出用 MIPS index 來實現可訓練的檢索\nORQA 與 REALM 類似\n但 REALM 提出了更新穎的模型預訓練步驟，並反向傳播到 MIPS index 中，而不用固定的 index\n上面指的應該是有關於非同步更新 index 的部分，還可以梯度更新\n值得注意的是，REALM 和 OrQA 的預訓練都是用 ICT 初始化的\nGeneration-based Open-QA Open-QA 的新興替代方案是將其建模為序列預測任務，只需對問題進行編碼，然後根據編碼逐個標記編碼答案\nGPT2 可以透過 sequence to sequence 直接產生答案，而不需要給指定的上下文，但可能由於缺乏 finetune 而沒有競爭力\n同時，T5 表明，直接生成答案而不從給定上下文中明確提取是可行的方法，但他們只在提供上下文文檔的閱讀理解任務上進行實驗\n為了和最具競爭力的 baseline 比較，本文與針對 Open-QA finetune 的 T5 進行比較\nImplementation Details Fine-tuning 文件被貪婪地分割成多達 288 個 BERT wordpieces 的 chunk，產生超過 1300 萬個 retrieval candidates\n在微調推理過程中，考慮前五個候選者\nPre-training 使用 BERT 的預設優化器在 64 個 Google Cloud TPU 上預訓練 20 萬步\nMIPS 在 16 個 TPU 上並行\nMain results REALM 在 table.1 明顯優於之前的所有方法\nREALM 最直接的比較是 ORQA，微調設定、超參數和訓練資料都相通\nREALM 對比 ORQA 的改進純粹是更好的預訓練方法\n而且本文表明他們的預訓練方法可以用在 single-corpus setting 或 seperate corpus setting\n兩者的差別在 X 和 Z 來源一不一樣\nAnalysis table.2 展現了去除 REALM 關鍵組件後的結果\n還展現了 finetune 前 gold answer 出現在前五個檢索中的頻率\nMasking scheme salient span masking 在先前標準的 BERT 訓練中尚未被證明具有影響力，但對於 REALM 至關重要\nMIPS index refresh rate 在預訓練期間，運行並行過程來重新 embed document 和重建 MIPS index\n導致每大約 500 個訓練步驟刷新一次 index\n為了證明頻繁刷新的重要性，也和較慢刷新率比較\ntable.2 顯示，stale index 可能會傷害模型，進一步減少這種過時性可以提供更好的最佳化\nDiscussion and Related Work Scalable grounded neural memory document index 可以被視為一種 memory，key 是 document embedding\n從這角度來看，本文的工作和 product key memory 有共同的動機，它能夠在記憶體網路中實現低於線性的存取\n一個主要的區別是本文的記憶體是有根據的，每個 memory 都和一個文檔相關聯，而不是和 unnamed value vector 相關聯\n這種程度的可解釋性對 Open-QA 至關重要，在這些應用程式中，用戶需要出處才能使預測答案值得信賴\nFuture Work ","date":"2024-01-05T00:00:13+08:00","permalink":"https://roykesydon.github.io/Blog/p/realm-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"REALM 論文閱讀"},{"content":"paper: Dense Passage Retrieval for Open-Domain Question Answering\nAbstract Open-domain question answering 依賴有效的 passage retrieval 來選擇 candidate context，傳統上用的 sparse vector space models，有 TF-IDF、BM25 等等\n本文顯示出檢索實際上可以只用 dense representation，embedding 是從少量的 question 和 passage 學到的，利用簡單的 dual-encoder framework\n在廣泛的 open-domain QA 資料集上，本文的 dense retriever 在 top-20 passage retrieval accuracy 上比 Lucene BM25 好 9%-19%\n並幫助作者的 end-to-end QA system 在 multiple open-domain QA benchmarks 上取得 SOTA\nIntroduction 早期閱讀理解模型提出了簡單的 two-stage framework：\n一個 context retriever 先選定一些 passage 子集合，其中某一些 passage 包含答案\n一個 machine reader，可以徹底檢查選出的 context 並找到答案\n盡管將 open-domain QA 簡化為 machine reading 是一個合理的策略，但是實際上經常看到嚴重的性能下降，顯示出需要改進 retrieval\nopen-domain QA 中的 retrieval 通常用 TF-IDF 或 BM25 來實現，可以透過 inverted index 有效地 match keywords，而且把 question 和 context 表示為 high-dimensional sparse vectors\n相反的，Dense latent semantic encoding 在設計上和 sparse representation 是互補的\n例如，由完全不同的 token 組成的兩個同義詞依然可以映射到接近的向量\nterm-based system 相較 dense retrieval system 很難將比如「壞人」和「惡棍」匹配\nDense encoding 也可以透過調整 embedding function 來學習，對於 task-specific 的 representation 提供了彈性\n透過特殊的 in-memory data structure 和 indexing scheme，可以用 maximum inner product search (MIPS) 來快速檢索\n然而，人們普遍認為學習良好的 dense vector representation 需要大量的 QA labeled pair\n因此，在 ORQA 之前，Dense retrieval 從沒被證明過可以在 open-domain QA 上贏過 TF-IDF 或 BM25\nORQA 提出了 ICT 來做額外的預訓練\n盡管 ORQA 證明了 dense retrieval 可以超越 BM25，在多個 open-domain QA 資料集上取得 SOTA，但他也存在兩個弱點：\nICT 預訓練是 compute-intensive，而且不確定 regular sentence 是否能很好的替代 objective function 中的 question\n由於 context encoder 沒有用 QA pair 進行 finetune，因此相應的 representation 可能不是最佳的\n在本文中，本文將解決一個問題 \u0026ndash; 我們是否可以只用 QA pair 來訓練更好的 dense embedding model，而不用額外的預訓練？\n利用現在的 standard BERT pre-trained model 以及 dual-encoder architecture，本文專注於用相對少量的 question and passage pair 來訓練 dense retriever\n經過一系列的 ablation study，本文的解決方案出奇的簡單\nembedding 可以用最大化 question 和 相關的 passage 的 inner product 來訓練\n作者的 Dense Passage Retrieval (DPR) 非常強大，不僅大幅優於 BM25，而且和 ORQA 相比，end-to-end QA 準確度也有大幅提升\n作者的貢獻有兩部分：\n作者證明在適當的設置下，只需在現有 question-passge pair 上 finetune question and passage encoder，就可以大幅超過 BM25，實驗結果也證明可能不用額外的預訓練\n作者證明了在 open-domain QA 的背景下，更高的 retrieval accuracy 可以轉化為更高的 end-to-end QA accuracy\n透過對 top retrived passage 使用 modern reader model，和幾個非常複雜的系統相比，作者在 open-retrieval setting 下的多個資料集取得了可比較或更好的結果\nBackground 本文研究的 open-domain QA 的描述如下：\n先給出一個事實性問題，不屬於特定主題，需要一個系統使用大量多樣化主題的 corpus 來回答\n更具體地說，作者假設 extractive QA setting，答案僅限於 corpus 中的一個或多個 passage 中出現的範圍\n假設有 D 個 documents，先把每個 document 拆成多個等長的 text passage，好做為 basic retrieval unit，最後得到 M 個 passage in corpus C\n每個 passage 可以被視作一個 token 序列\n對於 question q，則是要找到某段 passage 中的一串連續的 token 來回答\n值得注意的一點是，為了涵蓋盡可能廣泛的概念，corpus 的大小可能會從數百萬個文件到數十億個文件不等\n因此，任何 open-domain QA system 都需要一個高效的 retriever，可以在 reader 提取答案前選擇一小組相關的文本\nDense Passage Retriever (DPR) 作者的研究重點是改進 open-domain QA 的 retrieval component\n給定 M 個 passage，DPR 的目標是把所有 low-dimensional continuous space 的所有 passage 都給 index，使它可以有效地檢所和輸入問題相關的 top-k passage\nM 有可能非常大，比如本文有 21M 個 passage，而 k 通常很小，可能只有 20~100 個\nOverview 用 dense encoder $E_P(．)$ 和 $E_Q(．)$ 來分別 encode passage 和 question，在計算兩者的 inner product 來衡量相似度\n盡管確實存在測量 question 和 passage 之間更具表現力的模型形式，比如帶有 cross-attention 的 multi-layer networks，但是 similarity function 需要可以分解，才可以預先計算 passage 的 embedding\n大多數 decomposable similarity function 是 Euclidean distance (L2) 的變換\n比如，consine 是 unit vector 的 inner product，而 Mahalanobis distance 等同於在 transformed space 的 L2 distance\n由於 ablation study 表示其他相似含數的表現相當，因此選擇更簡單的內積函數，並透過學習更好的 encoder 來改善 dense passage retriever\nEncoder 本文採用兩個獨立的 BERT，並把 [CLS] token 的 representation 當作 output\nInference 推理階段，將 passage encoder $E_P$ 應用在所有 passage，並用 FAISS offline index\nFAISS 是一個非常高效的 open-source library，用在 similarity search 和 clustering of dense vectors，可以輕鬆應用在數十億個向量上\n在推論接段，計算 q 的 embedding，然後用 FAISS 來找到 top-k passages\nTraining 每一個 training instance 都包含問題 q，還有一個正 (相關) passage，以及 n 個負 (不相關) passages\nPositive and negative passages 對於檢索問題，正例通常明確可用，而反例則通常要從非常大的 pool 中選擇\n正例可能會在 QA 資料集給出，或是可以從答案找到，其他的段落預設情況下都可視為不相關\n在實踐中，如何選擇負例常被忽視，但對於學習 high-quality encoder 可能很關鍵\n考慮三種負例：\n隨機 Corpus 中隨機選擇 BM25 BM25 返回的 passage 不含答案，但包含最多 question token Gold positive 和 question 配對 第 2 和 3 種是在說拿其他問題的正例當負例\nIn-batch negatives 有 B 訓練實體，每個問題有 B-1 個 negative passage，只有 i = j 時，$(q_i, p_j)$ 是正例，其他都是負例\nin-batch negative 的技巧已被用在 full batch setting 和 mini-batch setting\n已被證明是學習 dual-encoder 的有效策略，可以增加訓練範例的數量\nExperimental Setup Wikipedia Data Pre-processing 用 DrQA 提供的預處理程式碼從 Wikipedia dump 中提取文章中乾淨的文字部分\n此步驟將刪除 semi-structured data，比如表格和 info-boxes\n接著將每天文章分成多個不相交的文字區塊，每個文字區塊由 100 個單字組成，作為 basic retrieval unit，最後會有 21,015,324 個 passage\n每個 passage 也帶有標題以及 [SEP]\nSelection of positive passages 由於 TREC, WebQuestions 和 TriviaQA 中只有 question-answer pair，因此使用 BM25 把包含答案最多的 passage 當作正例\n如果檢索到的前 100 篇文章中沒有答案，則該問題會被丟棄\nExperiments: Passage Retrieval Main Results SQuAD 表現較差有可能是因為 passage 和 question 存在高度詞彙重疊，給 BM25 帶來優勢，而且資料僅從 500 多篇 wiki 文章中蒐集，因此訓練範例的分佈存在極大的 bias\n當用多個資料集訓練時，TREC（裡面最小的資料集）獲益最多\nAblation Study on Model Training Sample efficiency In-batch negative training in-batch negative 可以顯著改善結果，還簡單且節省記憶體，可以重複使用 batch 中已經有的負例\n它會產生更多 pair，從而增加訓練資料的數量\nImpact of gold passages 做了 distant supervision，只有很小的影響，降低了 1 個點\nSimilarity and loss L2 和 inner product 的表現相當，兩個都比 cosine 好\n有一種流行的 ranking loss 叫做 triplet loss，但是在本文中，作者發現它的表現不會對結果產生太大影響\nCross-dataset generalization 為了測試泛化能力，只在 Natural Questions 上訓練，在較小的 WebQuestions 和 CuratedTREC 上測試，發現泛化能力很好，輸給 SOTA finetune model 3~5 個點，但仍大大優於 BM25 baseline\nExperiments: Question Answering Result Related Work Conclusion 證明了 dense retrieval 可以 outperform 甚至可能取代傳統的 sparse retrieval\n雖然簡單的 dual-encoder framework 可以達到很棒的效果，但作者顯示出要成功訓練也有一些關鍵因素\n此外，根據 empirical analysis 和 ablation study，更複雜的 model framework 或 similarity function 不一定能提供額外價值\n由於檢索性能的提高，在多個 open-domain QA benchmarks 上取得了 SOTA\n","date":"2023-12-28T00:00:13+08:00","permalink":"https://roykesydon.github.io/Blog/p/dpr-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"DPR 論文閱讀"},{"content":"paper: Latent Retrieval for Weakly Supervised Open Domain Question Answering\nAbstract 最近的工作常依賴於兩個假設，一個是對 supporting evidence 做 strong supervision，另一個是假設 blackbox information retrieval (IR) system 可以找到所有的 evidence candidates\n作者認為兩者都不是最理想的，因為 gold evidence 不總是可用，而且 QA 和 IR 有著根本上的不同\n作者首次證明，在沒有任何 IR 的情況下，可以從 question-answer pair 中共同學習 retriver 和 reader\n在這種 setting 下，來自 Wikipedia 的 evidence retrieval 被視作 latent variable\n由於 learn from scratch 不切實際，因此用 Inverse Cloze Task (ICT) 來預訓練 retriever\n作者對五個 QA 資料集進行評估\n在提問者已經知道答案的情況下，傳統的 IR 系統（比如 BM25）已足夠\n在使用者真正尋求答案的資料集上，作者顯示出 learned retrival 的重要性，在 exact match 上比 BM25 好 19 個點\nIntroduction 由於閱讀理解系統的發展，人們對 open domain question answering (QA) 的興趣重新燃起\n其中 evidence 得從 open corpus 取得，而不是直接從輸入給入\n現有的方法需要 blackbox IR system 來完成大部分繁重的工作，即使它無法對下遊任務進行微調\n在 DrQA 推廣的強監督環境中，他們也假設了一個訓練在 question-answer-evidence triple 上的閱讀理解模型\n在某些人提出的 weakly supervised setting 中，他們假設 IR system 提供 noisy gold evidence\n這些方法利用 IR system 來大幅減少搜尋空間\n然而 QA 和 IR 有著根本性的差異\n雖然 IR 關心的是 lexical 和 semantic matching，但 question 的定義並不具體，而且需要更多 language understanding，因為 user 在找的是未知資訊\n我們應該直接 用 QA data 學習 retrieve，而不是受限於 blackbox IR system\n在本文中，作者介紹了第一個 OpenRetrieval Question Answering system (ORQA) 框架\nORQA 學習從 open corpus retrieve evidence，並且只做 question-answer pair 的監督訓練\n雖然最近的工作在改進 evidence retrieval 上取得了巨大的進展，但是他們依然只是在 closed evidence set 下 rerank\nfully end-to-end 的挑戰是，open corpus 的 retrieval 必須被視為 latent variable，要 train from scratch 是不切實際的\nIR system 提供了一個合理但可能非最好的起點\n本文的一個關鍵是，如果用無監督 的 ICT 對 retriever 做預訓練，那 end-to-end learning 是有可能的\n在 ICT 中，一個句子被視作 pseudo-question，而它的 context 被視作 pseudo-evdience\n給定一個 pseudo-question，retriever 的目標是從 batch 中的 candidate 找出對應的 pseudo-evidence\nICT pretraining 提供了強大的初始化，使 ORQA 可以簡單地優化\n作者在五個 QA 資料集上進行了評估，在問題作者已知答案的資料集上 (SQuAD、TriviaQA)，檢索問題類似傳統的 IR，並且 BM25 是 SOTA retrieval\n在問題作者不知道答案的資料集上 (Natural Questions、WebQuestions、CuratedTrec)，作者顯示出 learned retrieval 的重要性，比 BM25 在 exact match 上好 6~19 個點\nOverview Task 在 open-domain QA 中，$q$ 是 question string，而 $a$ 是 answer string\n與閱讀理解不同，evidence 的來源是 modeling choice，而非 task definition 的一部分\nFormal Definitions Model 把一個 unstructured text corpus 切成 B 塊的 evidence text\n一個 answer derivation 是一個 pair $(b,s)$\n$1 \\le b \\le B$ 是 block 的 index\n$s$ 是 block $b$ 的 span\nscoring function $S(b,s,q)$ 用來計算 $(b,s)$ 對於 $q$ 的分數\n一般來說 scoring function 會被分解成 retrieval component $S_{retr}(b,q)$ 和 $S_{read}(b,s,q)$\n$S(b,s,q) = S_{retr}(b,q) + S_{read}(b,s,q)$ 在推論階段：\n$a^* = TEXT(argmax_{b,s} S(b,s,q))$ open-domain QA 的一個主要挑戰是 handling the scale\n作者在 English Wikipedia 上做實驗，包含超過 13M 個 blocks，每個 block 都有超過 2000 個可能的 spans\nExisting Pipelined Models 在現有的 retrieval-based open-domain QA 模型中，blackbox IR system 先選擇一組 closed set of evidence candidates\n然後 DrQA 之後的多數工作都用 TF-IDF 來挑選 candidate，並專注於閱讀理解或 reranking 的部分\nreading component $S_{read}(b,s,q)$ 是從 gold answer 學習的\n在最接近我們的方法的工作中，reader 是透過 weak supervision 學習的\nretrieval system 會啟發式（heuristically）地刪除 spurious ambiguities，並把清理後的結果視為 gold evidence\nOpen-Retrieval Question Answering (ORQA) $BERT(x_1, [x_2]) = \\{CLS: h_{CLS}, 1: h_1, 2: h_2,\u0026hellip;\\}$\nRetriever component $h_q = W_q BERT(q)[CLS]$ $h_b = W_b BERT(b)[CLS]$ $S_{retr}(b,q) = h_q^T h_b$ Reader component $h_{start} = BERT_R(q,b)[START(s)]$ $h_{end} = BERT_R(q,b)[END(s)]$ $S_{read}(b,s,q) = MLP([h_{start};h_{end}])$ Inference \u0026amp; Learning Challenges 上面的模型概念很簡單\n但推論和學習上具有挑戰性，因為：\nopen evidence corpus 有巨大的搜尋空間（超過 13M 個 blocks） 要如何在空間 navigate 是 latent 因此標準的 teacher forcing 不能用，latent variable 也不能用，因為存在大量 spuriously ambiguous derivations（比如答案是 \u0026ldquo;seven\u0026rdquo;，很多 evidence 都會有 \u0026ldquo;seven\u0026rdquo; 這個字眼）\n作者透過非監督預訓練來良好地初始化 retriever 來解決這些挑戰\n預訓練的 retriever 使作者能夠：\npre-encode Wikipedia blocks，從而在 finetune 階段實現動態且快速的 top-k retrieval\n使 retrieval 可以遠離 spuriously ambiguities 並偏向 supportive evidence\nInverse Cloze Task 作者提出的預訓練流程的目標是想讓 retriever 解決和 evidence retrieval for QA 相似的無監督任務\n直覺上，useful evidence 通常會討論問題中的 entities, events 和 relations\n還包含問題中不存在的額外資訊 (the answer)\nquestion-evidence pair 是 setence-context pair，句子的上下文在語意上是相關的，可以推論句子中缺少的資訊\n憑這種想法，作者建議使用 ICT 來預訓練 retriever\n在 standard cloze task 中，目標是根據上下文預測 masked-out text\n相反，ICT 要逆向預測，給定一個句子，預測上下文\n使用類似 downstream retrieval 的 discriminative objective：\n$P_{ICT}(b|q)=\\frac{exp(S_{retr}(b,q))}{\\sum_{b\u0026rsquo; \\in BATCH} exp(S_{retr}(b\u0026rsquo;,q))}$\n預測哪個上下文是 query 的\nICT 有個重點是，它要做的不僅僅是單字匹配，因為 evidence 中沒有 pseudo-question\n例如 fig.2 的 pseudo-question 完全沒有提及 zebra，但 retriever 要能夠選擇 zebra 的 context\n能夠從非指定的語言推論出語意是 QA 和傳統 IR 的差異\n然而作者也不想阻止 retriever 學習單字匹配，因為 lexical overlap 最終是一個非常有用的特徵\n因此，作者只在 90 % 的例子中把 sentence 從 context 中移除，鼓勵模型在需要的時候學習抽象表示，也在可用時學習 low-level word matching features\nICT 預訓練實現兩個主要目標：\n儘管預訓練的句子和微調時的 question 不匹配，但作者預期 zero-shot evidence retrieval performance 足以引導 latent variable 的學習\npretrained evidence blocks 和 downstream evidence blocks 間沒有這種不匹配的問題\n因此可預期 $BERT_{B}(b)$ 無須進一步訓練即可正常工作\n只有 question encoder 需要針對下遊資料微調\nInference 由於 fixed block encoder 已經為 retrieval 提供了有用的 representation，可以預先計算所有 block 的 encoding\n因此在微調的時候不需要對大量 evidence block 重新 encode，並且可以使用比如 locality-sensitive hashing 之類的現有工具來建立索引\n透過 pre-compiled index，推理遵循 standard beam-search\n檢索 top-k evidence block，並只計算這 k 個 block 的 reader score\nLearning 這邊太複雜，建議看原文\nExperimental Setup Open Domain QA Datasets 對 5 個現有 question answering 或閱讀理解資料集進行評估\n並非所有資料集的原始形式都是 open-domain QA，因此作者遵循 DrQA 的做法，轉成 open format\n每個 example 都有一個 single question 和一「組」 reference answer\nNatural Questions 包含了從 Google Search 的 aggregated queries 中的 question\n為了蒐集這個資料集的 open version，作者只保留 short answer 並丟棄 evidence document\n具有許多 token 的答案通常類似 extractive snippets 而不是 canonical answer，因此作者丟棄長度超過 5 個 token 的答案\nWebQuestions 包含從 Google Suggest API 抽取的問題\n答案是根據 Freebase 標註的，但是只保留 entities 的 string representation\nCuratedTrec 問題來自真實查詢的各種來源，比如 MSNSearch\nTriviaQA 從網路上抓的 question-answer pairs\n作者使用 unfiltered set 並捨棄 distanly supervised evidence\nSQuAD 被設計來用作閱讀理解，而不是 open-domain QA\n答案範圍是從 Wikipedia 的段落中選擇的，問題由 annotators 編寫，annotators 被指示提出問題，要由給定的 context 中的 span 來回答\nDataset Biases 在 Natural Questions、WebQuestions 和 CuratedTrec 中，提問者不知道答案，反映了真實的尋求問題的分佈\n但是，annotators 必須單獨找到正確的答案，因此需要 automatic tools，並可能會對這些工具的結果產生 bias\n在 TriviaQA 和 SQuAD 中，不需要 automatic tools，因為 annotators 是根據已知答案寫問題的\n然而這引入了另一組可能更成問題的 bias，就是撰寫問題並非出於資訊需求\n導致問題中有許多自然出現的問題中沒有的提示\n這在 SQuAD 中問題特別嚴重，使問題和 evidence 間人為地出現大量詞彙重疊\n但上述這些只是想表達資料集的屬性，而非可採取行動的批評，因為要取得大規模資料必定會遇到這些狀況，目前還不清楚如何在合理的成本下收集公正的資料集\nImplementation Details Evidence Corpus corpus 被分成最多 288 個單字的 chunk，並且保留 sentence boundaries\n導致有超過 13M 個 blocks\nMain Results Baselines BM25 BM25 是事實上的非監督搜索方法 SOTA 被證明對於傳統資訊檢索任務和 QA 的 evidence retrieval 任務都是 robust\nLanguage Models 非監督的 neural retrieval 對於傳統 IR 來說很難改進，但這裡視作比較的 baseline\n作者對 LM 進行實驗，並且這已被證明是 SOTA unsupervised representation\n我們與兩種廣泛使用的 128-dimensional representation 進行比較：\nNNLM context-independent embedding ELMO context-dependent bidirectional LSTM 就像 ICT 一樣，使用 alternate encoder 來預先計算 encoded evidence blocks 還有初始化經過 finetune 的 question encoding\n根據現有的 IR 文獻，還有 LM 沒有顯著優化 retrieval 的直覺，作者並不期望這些成為強大的 baseline，但是他們證明了將文本編碼為 128 維的難度\nResults 在提問者已經知道答案的資料集中\n證實壓縮到 128維的向量無法與 BM25 精確表示 evidence 中每個單字的能力相符\nSQuAD 的 dev 和 test 間的顯著下降反映了資料集中的某個特性 - 10 萬個問題僅源自 536 個文件\n因此，SQuAD 的好的檢索目標，會和訓練範例高度相關，違反了 IID 假設，使其不適合學習檢索\n因此，作者強烈建議對 end-to-end open-domain QA models 有興趣的人不再使用 SQuAD 進行訓練和評估\nAnalysis Strongly supervised comparison 為了證實作者的 BM25 Baseline 是 SOTA，提供了和 DrQA 的比較\nDrQA 的 reader 是 DocReader，用 TF-IDF 取得 top k documents\n還包括基於 TF-IDF retrieval 的 distant supervision\nBERTserini 的 reader 是一個基於 base BERT（類似作者的 reader），並用 BM25 搜索 top-k 個段落（像作者的 BM25 baseline）\n主要區別在 BERTserini 使用 Wikipedia 中的真實段落，而不是任意 block，從而由於長度不均導致更多 evidence blocks\n為了和這些強監督系統進行比較，作者在 SQuAD 上預訓練 reader\nMasking Rate in the Inverse Cloze Task pseudo-query 在 90% 的時間裡都從 evidence block 遮蔽\n如果總是屏蔽 pseudo-query，那麼 retriever 永遠不會知道 n-gram overlap 是一個強大的 retrieval signal，導致損失 10 個點\n如果從不屏蔽，問題就會簡化為記憶，導致不能很好地推廣到問題\nExample Predictions 發現 ORQA 在具有高度詞彙重疊的文本更加 robust\n但是由於 128 維向量的資訊有限\n很難精確地表示極為具體的概念，比如準確日期\n","date":"2023-12-25T00:00:13+08:00","permalink":"https://roykesydon.github.io/Blog/p/orqa-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"ORQA 論文閱讀"},{"content":"paper: Reading Wikipedia to Answer Open-Domain Questions\nAbstract 本文提出以 Wikipedia 為知識來源來解決 open-domain question answering 問題\n任何問題的答案都是 Wikipedia 中的一段文字\n這項挑戰結合了文件檢索和理解文字的能力\n本文的作法基於一個 search component，由 bigram hashing 和 TF-IDF matching 構成，並結合 RNN\n對多個 QA 資料集做的實驗表明：\n這兩個 components 對於現有的對應模塊具有高度競爭力 在他們的組合上使用 distant supervision 十分有效 Introduction 要把 wikipedia 當作知識來源，回答任何一個問題，都必須先從超過 5 百萬篇文章中找出少數相關的文章，並仔細掃描以找出答案。\n本文將這稱為 machine reading at scale (MRS)\n本文把 wikipedia 當作一個文章的集合，並且不依賴內部的 graph structure\n因此該方法是通用的，可以套到諸如新聞、網路論壇等等的資料集上\n本文開發了 DrQA，強大的維基百科問答系統，由以下部分組成：\nDocument Retriever 一個用 bigram hashing 和 TF-IDF matching 的 module 用於在給定問題的情況下，返回有效相關文章的子集 Document Reader RNN，用來 detect 文章中答案的位置 實驗表明 Document Retriever 的性能優於 Wikipedia 的內部搜尋引擎，Document Reader 在 SQuAD 上達到 SOTA\n此外，與 single task training 相比，作者表明 multitask learning 和 distant supervision 有助於提高模型的性能\nRelated Work 隨著 Knowledge Base (KB) 的發展，QA 出現了許多創新，但是 KB 具備固有限制（incompleteness, fixed schema），促使研究人員轉回從 raw text 中提取答案\n有些工作嘗試利用 multitask learning 來組合多個 QA 資料集，目標是：\n透過 task transfer 來實現跨資料集的改進 提供一個單一通用的系統，可以回答不同種類的問題，因為資料來源中不可避免地存在不同的資料分布 本文的工作在先 retrive 再 read 的 setting 下，沒有利用 KB，取得了正面成果\nDrQA 由兩個 Components 組成：\nDocument Retriever 用來尋找相關文章 Document Reader 用於從單一文件或一小部分文件提取答案 Document Retriever 遵循經典的 QA System，先用高效的 （非機器學習）的 document retrieval system 縮小搜索範圍，並專注於比較可能有關的文章\n與基於 ElasticSearch 的 Wikipedia Search API 相比，簡單的 inverted index lookup 和 term vector model scoring 表現的十分好\n文章和問題被表示為 TF-IDF weighted bag-of-words vectors\n作者考慮透過考慮 local word order 和 n-gram features 來進一步改善\n表現最佳的系統用 bigram counts，並利用 hashing 映射到 $2^{24}$ bins 來保持 speed 和 memory efficiency，用的是 unsigned murmur3 hash\nDocument Retriever 作為模型的第一部分，設定為對任何問題返回 5 個相關的文章\n這些文章再交由 Document Reader 來處理\nDocument Reader Paragraph encoding $p_i$ 是段落 $p$ 中的 token，期望 $p_i$ 可以被 encode 成帶有周圍資訊的向量\n採用的是 multi-layer bidirectional LSTM\n特徵向量 $p_i$ 由以下部分組成：\nWord embedding\n用 300 維的 Glove word embedding，固定大部分預訓練的 word embedding，只 finetune 最常見的 1000 個 question words，例如 what, how, which Exact match\n採用三個簡單的 binary features，用來表示 $p_i$ 是否與問題中的 question word $q$ 精確匹配，無論是原始形式、小寫，還是 lemma form Token features\n作者添加了一些 manual feature 好反應 $p_i$ 在 context 中的屬性，比如 part-of-speech (POS)、named entity recognition (NER) tags 和它的 (normalized) term frequency (TF) Aligned question embedding\n$f_{align}(p_i)=\\sum_j a_{i,j}E(q_j)$ $E$ 是 word embedding $a_{i,j}$ 是 attention score，計算 $p_i$ 和每個 $q_j$ 之間的 similarity Question encoding 這個比較簡單，只是在 word embedding 上加上一層 RNN，並把 hidden units 重新結合成一個向量\nPrediction 把 $\\{p_1,\u0026hellip;,p_m\\}$ 和 $q$ 作為 input，並個別單獨訓練兩個分類器預測開頭和結尾的位置\n具體來說，作者用 bilinear term 來計算每個 $p_i$ 和 $q$ 之間的相似度，並計算每個 $p_i$ 是開頭的機率和結尾的機率\n最後選擇最佳範圍，從 token $i$ 到 token $i'$\n$i \\le i\u0026rsquo; \\le i+15$\n並且使 $P_{start}(i) \\times P_{end}(i\u0026rsquo;)$ 最大化\nData 本文的工作依賴三種資料：\nWikipedia 尋找答案的來源 SQuAD 用來訓練和評估模型 另外三個 QA 資料集 (WebQuestions, CuratedTREC, WikiMovies) 用來測試模型在 Open-domain QA 上的泛化能力，並評估模型從 multitask learning 和 distant supervision 中獲益的程度 Wikipedia (Knowledge Source) 用 2016-12-21 dump2 的 English Wikipedia\n對於每頁，只提取文本，並刪除結構化的資料（lists and figures）\n丟棄 disambiguation pages, list, index 和 outline pages，保留了 5,075,182 篇文章\nSQuAD 使用兩個 evaluation metrics：\nExact string match (EM) F1 score 為了評估 open-domain QA 的能力，作者只有使用 SQuAD 的 QA pairs，要求系統在無法存取相關段落的情況下發現正確的 answer span\n不像標準的 SQuAD setting 會給出相關段落\nOpen-domain QA Evaluation Resources SQuAD 是目前可用的最大的 general purpose QA 資料集之一\n收集過程包括向每個 human annotator 展示一個段落，並寫一個問題\n因此，distribution 非常特定\n作者建議在其他 open-domain QA 資料集上評估系統，他們以不同的方式建構\nCuratedTREC 使用大版本，包含 TREC 1999, 2000, 2001 和 2002 的 2180 個問題\nWebQuestions 這資料集旨在回答 Freebase KB 的問題\n透過 Google Suggest API 抓問題，再用 Amazon Mechanical Turk 來獲取答案\n作者用 entity names 把每個 answer 轉成答案，以便不引入 Freebase IDs\nWikiMovies 包含對電影領域的 96k 個問答對\nDistantly Supervised Data 上面說的資料集除了 SQuAD 都沒有相關段落，因此不能直接訓練 Document Reader\n追隨之前已有的利用 distant supervision (DS) 來做 relation extraction 的工作，作者用一個程式自動把段落和此類訓練範例做相關聯\n對每個問答對使用以下過程來建立訓練集：\n首先，對問題用 Document Retriever 找到前 5 個相關的段落\n與已知答案沒有 exact match 的段落都被直接丟棄\n短於 25 個字元或長於 1500 個字元的段落也被丟棄\n如果在問題中找到 named entity，不包含該 named entity 的段落也被丟棄\n對於每個 retrived page 的每個段落，使用 question 和 20 token window 間的 unigram 和 bigram overlap 來計算相似度，保留重疊度最高的前五個段落\n將找到的每個 pair 加入到 DS 訓練集中\n大約一半的 DS 範例來自 SQuAD 以外的頁面\nExperiments Finding Relevant Articles 先檢查 Retriever 在所有 QA 資料集上的性能\n計算 ration 是根據特定的問題，考慮這些問題對應的文本在前 5 個相關文章中的比例\n結果表明，比 Wikipedia Search 還更好，尤其是使用 bigram hashing 的情況下\nReader Evaluation on SQuAD Implementation details 使用 h=128 的 3 層雙向 LSTM，來做 paragraph encoding 和 question encoding\n使用 Stanford CoreNLP 來做 tokenization 並生成 lemma, part-of-speech 和 named entity tags\nOptimizer 使用 Adamax\nDropout rate 為 0.3\nResult and analysis 作者的系統可以在 SQuAD 上達到 SOTA\n做了 ablation study，結果表明所有功能都會影響性能\n有趣的是，單獨沒有 $f_{alignd}$ 或 $f_{exact_match}$ 對性能不會有極大的影響，但兩個都沒有就會急遽下降\nFull Wikipedia Question Answering 比較三個版本的 DrQA：\nSQuAD 只在 SQuAD 上訓練，並用於所有評估資料集 Fine-tune (DS) 先在 SQuAD 上預訓練，在用 DS 訓練集對每個資料集進行微調 Multitask (DS) 在 SQuAD 和 DS 訓練集上聯合訓練 Results Conclusion 兩個明顯的 angles of attack：\n把多個段落直接納入 Document Reader 的訓練，因為他目前獨立訓練每個段落 實作一個 end-to-end training 的 pipeline，可以在一個模型中結合 Document Retriever 和 Document Reader ","date":"2023-12-25T00:00:12+08:00","permalink":"https://roykesydon.github.io/Blog/p/drqa-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"DrQA 論文閱讀"},{"content":"介紹 ChatGPT 的缺陷\n沒有一定時間後的資料 (當時) 沒有辦法連結外部私人資料 (e.g. Google Drive) LangChain 的優點\nIntegration 可以連結外部資料 Agency 讓 LLM 可以和環境互動，做出決策 Components 結構 Schema 對話 System: 對話的 context Human: 你的詢問 AI: AI 的回答 Document 儲存一段文字以集 metadata 的結構 Embedding OpenAIEmbeddings 可以把文字轉換成向量，預設是 1536 維 但是有最大長度限制 文字處理 Output Parser 讓模型重生你想要的格式，並轉換成你想要的結構，比如 json\n資料儲存 Indexes Document_loaders\n可以從不同的來源獲得資料 text_splitter\n把大量的文字切成多個 chunks retriever\n用來找到相近的文件 VectorStores\nChroma local storage 交互 PromptTemplate 用來往 String Template 填入變數 有些 Component 會和這個用法組合，所以不適合直接換成 f-string FewShotPromptTemplate 可以用自己準備的一些例子結合 PromptTemplate 來做 Few-shot learning 可以透過 FAISS 來找到最相近的例子 Chain 用在有多個有序的問題的情況\nmulti-step workflow\nVectorDBQA\n可以用在搜索 local 的向量資料庫 Instruction 結合 context 的模式 (Summarize)\n模式 Stuffing Map Reduce Refine Map-Rerank 說明 直接把 context 和 query 結合 把 Document 切成多塊 ，把每塊交給 LLM，轉換成 summary，反覆從這些 summary 生 summary 每次切一小塊，並且和先前的結果做 summary 讓每個 chunk 和 query 去生答案，並要模型對自己的答案評分，最後選分數高的 優點 只需 call 一次 API、涵蓋所有資料 可以餵入更大的文件、可以平行運算 可以餵入更大的文件 對於簡單的問題可能比較有效 缺點 容易達到 token 上限 call 多次 API、summary 的過程中會流失資訊 call 多次 API、summary 的過程中會流失資訊 沒有辦法結合多個 Document 的資訊 Agent 有些應用中，你可能不知道該遵循什麼流程來讓 LLM 完成任務，這時候你會需要讓 LLM 自行決定要採取哪些動作以及採取的順序 可以動態地利用 Chain verbose=True 的時候會印出思考過程 Tools 有比如 Google Search 之類的 Tool 可以結合應用 Memory ConversationChain 讓 Chain 和 Agent 可以保留之前的對話 ","date":"2023-12-18T00:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/langchain-%E7%AD%86%E8%A8%98/","title":"LangChain 筆記"},{"content":"paper: Learning Transferable Visual Models From Natural Language Supervision\nAbstract 現有的 SOTA CV system 可以經過訓練預測一組固定的類別。 但這種監督式的方法也受限了通用性，因為需要額外的 labeled data 來擴展。\n直接從 raw text 學習 image 是個有前途的替代方案。\n本文證明了「預測哪個是圖片的 caption」這種形式的預訓練是一種高效且可擴展的方法，可以從 internet 上蒐集的 4 億對資料從頭學習到 SOTA image representation。\n預訓練後，透過自然語言來引導，就可以在下游任務十線 zero-shot。\n本文對 30 個不同的現有電腦視覺資料集進行比較，可以在多數任務和監督式學習的 baseline 競爭，而且無須任資料集來做特別的訓練。\n例如在 ImageNet 上做 zero-shot 可以和 ResNet-50 取得相近的準確度。\nIntroduction and Motivating Work 直接從原始文本學習的預訓練方法在過去幾年徹底改變了 NLP。\nTask-agnostic (與下游任務無關) objectives，比如 autoregressive 和 masked language modeling，讓模型得以隨著 compute, model capacity, 和 data 規模的增長，使能力也逐步提升。\n在 \u0026ldquo;text-to-text\u0026rdquo; 這種輸入輸出形式的預訓練，使模型轉移到下游任務的時候，不用特地客製化 output head，或對資料集做特別地處理。\n這些結果表明，現代的預訓練方法在 web-scale 的文字集合的表現已經超過了用高品質的人為標記 NLP 資料集。\n然而在 CV 等領域，在 ImageNet 這種人為標記的資料集上做預訓練卻依然是標準做法。\n直接從網路文本學習的可擴展預訓練方法或許能在 CV 帶來類似的突破。\n以往有一些工作嘗試利用幾乎無限量的原始文本而不是有限數量的 \u0026ldquo;gold-labels\u0026rdquo;， 但是這些方法都有一些妥協，比如都利用 softmax 來執行預測，使其沒辦法應付新類別，嚴重限制了 zero-shot 的能力。\n作者提了幾個弱監督學習的例子，他們利用額外的資料結合預訓練，來幫忙改善監督式學習的結果。\n也提了幾個和 CLIP 類似的工作 VirTex, ICMLM, ConVIRT，想利用 Transformer，從 Natural Language 中學習 image representation。\n這些 weakly supervised model 和最近從 NLP 學習 image representation 的方法有一個重大差異，規模。\n最近的一些研究，比如一些弱監督學習在數百萬到數十億張照片上訓練了多個 accelerator years。但是和 CLIP 相似的研究只在二十萬張圖片上訓練了幾天。\n本文將規模拉高，以縮短規模上的差距。\n作者在 internet 上蒐集了 4 億對圖片和文字的資料，做成新的資料集，並提出了 CLIP，ConVIRT 的簡化版本。\n作者在 30 幾個資料集上測試，基本上能和監督式的模型競爭。\n如果用 linear-probe，比公開可用的 SOTA ImageNet model 還更好。\nApproach Natural Language Supervision 核心想法是利用 natural language 來學習 perception。\n作者稱這不是一個新想法，但以往相似的方法的用語多樣，他介紹了四篇文章，但把從文字和圖片中學習 image representation 的方法個別稱為：無監督、自監督、弱監督、監督式。\n擴展 natural language supervision 比起圖像分類簡單的多，不必定好類別，再去標註每張照片的類別。\n而且 natural language supervision 還有個優勢，他不只能學習 image representation，還能將其和文字相關聯，使其更好做 zero-shot 的遷移。\nCreating a Sufficiently Large Dataset 現有工作主要用三個資料集:\nMS-COCO Visual Genome YFCC100M MS-COCO 和 Visual Genome 都是高品質的人為標記資料集，但是按照現代標準來看，它們很小，每個資料集大約有 100,000 張訓練照片。\n相較之下，作者舉了一個最近的研究，用了 3.5 Billion 張 Instagram 照片作為訓練資料。\nYFCC100M 是一個可能的替代方案，它有 100 million 張照片，但每張照片的 metadata 資料稀疏，而且良莠不齊。\n比如許多檔名是自動產生的，可能是時間，或是相機的參數。\n經過過濾，保留帶有自然語言的標題或描述的圖像，資料集縮小了 6 倍，只剩 15000 萬張照片，和 ImageNet 的大小相當。\nnatural language supervision 的一個主要動機是網路上公開著大量這種形式的 data。 由於現有資料集沒有反映這種可能性，因此只考慮這些資料集會低估這方面研究的潛力。\n所以作者建立了一個新的包含 400 million pairs 的資料集，從網路上各種公開的來源蒐集的。\n為了盡可能涵蓋所有的 visual concepts，作者在建構資料集的時候準備了 50 萬組特定的 query，每組 query 最多包含 20,000 個 pair，來進行 class balance。\n產生的資料集的總字數和 GPT-2 用的 WebText 差不多。\n將此資料集稱為 WIT，全名是 WebImageText。\nSelecting an Efficient Pre-Training Method 最先進的 CV System 需要大量的計算。\n作者舉了兩個計算量都非常恐怖的模型，而且他們只能預測 1000 個 ImageNet 的類別。 其中一個花了 19 個 GPU years，另一個花了 33 個 TPUv3 core-years。 乍看之下，從自然語言中學習一組開放的視覺概念似乎令人生畏。\n但在作者努力的過程中，他們發現訓練效率是成功擴展自然語言監督的關鍵，也根據該指標選定最終的預訓練方法。\n最初的方法和 VirTex 相似，從頭開始訓練一個 CNN，和 text transformer 來預測 caption。\nFig.2 展示的 Transformer 語言模型的計算量是 ResNet-50 Image encoder 的兩倍。 預測 caption 比預測 caption 但採用詞袋的方式還慢三倍。\n這樣預測 caption 是一個困難的任務，同一張照片對應的 caption 可能出現的描述甚至有非常多種。 最近在 Contrastive representation learning 方面的研究發現 contrastive objectives 有不錯的表現。\n因此作者探索一種方法是，只預測文本和哪一個圖片配對，而不是預測確切的單字。\n因為資料集超級大，overfitting 的問題影響不大。\n此外，作者發現對於 encoder 的 representation，要轉換到 multi-model embedding space，只需要使用 linear projection 即可，不需要 non-linear，兩者之間差別不大。\nData augmentation 只有使用 random crop，而沒有使用其他的。\nChoosing and Scaling a Model 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # image_encoder - ResNet or Vision Transformer # text_encoder - CBOW or Text Transformer # I[n, h, w, c] - minibatch of aligned images # T[n, l] - minibatch of aligned texts # W_i[d_i, d_e] - learned proj of image to embed # W_t[d_t, d_e] - learned proj of text to embed # t - learned temperature parameter # extract feature representations of each modality I_f = image_encoder(I) #[n, d_i] T_f = text_encoder(T) #[n, d_t] # joint multimodal embedding [n, d_e] I_e = l2_normalize(np.dot(I_f, W_i), axis=1) T_e = l2_normalize(np.dot(T_f, W_t), axis=1) # scaled pairwise cosine similarities [n, n] logits = np.dot(I_e, T_e.T) * np.exp(t) # symmetric loss function labels = np.arange(n) loss_i = cross_entropy_loss(logits, labels, axis=0) loss_t = cross_entropy_loss(logits, labels, axis=1) loss = (loss_i + loss_t)/2 Experiments Prompt Engineering and Ensembling 一種常見的問題是 polysemy，一個單字可能有多種意思，比如 \u0026ldquo;boxer\u0026rdquo; 可能是一種狗，或是拳擊手。 如果一張圖片對應一個單字就會面臨這問題。\n另一種是 distribution gap，比如訓練用句子，但測試用單字。 為了緩解這問題，作者發現用 prompt template \u0026ldquo;A photo of a {label}.\u0026rdquo; 比直接用 label 好。\n光用這個 prompt template 就提高 1.3 % 在 ImageNet 上的準確度。\n如果可以給其他額外訊息會更有幫助，比如對於寵物的資料集，可以用 \u0026ldquo;A photo of a {label}, a type of pet.\u0026quot;。\n對於 OCR 資料集，作者發現在要識別的文字或數字前後加上引號可以提高效能。\n再來是 prompt ensembling，作者發現用多個 prompt template 來預測，然後綜合結果，可以提高效能。 作者用了 80 個 template。在 ImageNet 上比用單一的 prompt template 提高 3.5 % 的 performance。\n綜合考慮 prompt engineering 和 prompt ensembling，作者在 ImageNet 上的準確度提高大概 5%。\n這裡列幾個作者用的 prompt template: \u0026ldquo;a bad photo of a {}.\u0026rdquo; \u0026ldquo;a photo of many {}.\u0026rdquo; \u0026ldquo;a sculpture of a {}.\u0026rdquo; \u0026ldquo;a photo of the hard to see {}.\u0026rdquo; Analysis of Zero-Shot CLIP Performance 對於一般的物體分類的資料集，CLIP 表現較好。\n下面有些複雜、專門、抽象的任務，CLIP 則表現的很差，比如計算場景中有多少物體的 （CLEVRCounts）、衛星圖像分類（EuroSAT）或是 識別最近的汽車距離（KITTI Distance）\n對於這種特別難的任務，讓 CLIP 做 zero-shot 不太合理。 可能用 few-shot 的方式會比較好。\nBiT 是 google 為 Transfer Learning 設計的預訓練模型，在分類問題，Few-shot learning 上有良好的表現。\nRepresentation Learning 這節探討完全使用下游任務資料集而非 Zero-shot 或 few-shot 的情況。\n作者選用 linear-probe 而不是 finetune 來做下游任務的評估。\n因為他們的重點是開發與資料集無關的預訓練方法，finetune 有可能讓一個預訓練學習 representation 失敗的模型在微調過程中變好。 而 linear-probe 的限制可以凸顯這些失敗。\nComparison to Human Performance 再來是 CLIP 和人類相比的結果。 挑選了五個人在寵物資料集上比較的結果。\nData Overlap Analysis 可能會有人質疑，CLIP 的表現是因為訓練資料集和測試資料集有重疊。 但作者做了一些實驗，有些資料集完全沒有偵測到重疊。 對有重疊的做實驗，發現有重疊的對效果提升影響很小。\nLimitations CLIP 雖然可以和作為 Baseline 的 ResNet-50 打平手，但現在的 SOTA 遠高於該 Baseline。\n作者發現再繼續加大模型和資料是可以繼續提升性能的，但作者估計要達到現有的 SOTA 需要增加大概 1000 倍的計算量才能達到，使用現有的硬體是不可行的。\nCLIP 對細分類、抽象或更難的任務表現不好，作者相信還有許多任務是 CLIP 用 zero-shot 只能達到亂猜等級的。\nZero-Shot 的 CLIP 很難泛化到 out-of-distribution 的資料，比如在 MNIST 上只能達到 88% 的準確度。 作者發現預訓練資料幾乎沒有類似 MNIST 的圖片。\n盡管 CLIP 可以靈活應用各種 Zero-Shot 的分類，但基本上還是從你給定的分類選擇。 和真正靈活的方法（生成 image caption）相比，是重大的限制。\n一個值得嘗試的簡單想法是把 contrastive objective 和 generative objective，結合。\nCLIP 也沒有解決深度學習資料效率低下的問題，CLIP 訓練了 32 個 epoch，如果把預訓練期間的照片以一秒一張來呈現，需要 405 年。 把 CLIP 和 self-supervision 或者和 self-training 做結合是有前途的方向。\n雖然作者強調 Zero-Shot Learning，但是作者還是有反覆檢查下游任務測試集的表現，來調整 CLIP。 每次都用 ImageNet 來確認，並不算真正的 zero-shot 的情況。 如果能再創一個新的資料集，專門用來評估 zero-shot 遷移的能力會更恰當。\n爬下來的資料有可能帶有社會偏見。\n有一些複雜的任務很難用文字來傳達，雖然實際的訓練樣本有用，但 CLIP 並不會針對 few-shot 最佳化。有個違反直覺的結果，可以注意到在某些情況下，few-shot 不見得比 zero-shot 好。\n額外應用 圖片生成 StyleCLIP: Text-Driven Manipulation of StyleGAN Imagery 用文字引導生成圖片 CLIPDraw: Exploring Text-to-Drawing Synthesis through Language-Image Encoders 物件偵測 Open-Vocabulary Object Detection via Vision and Language Knowledge Distillation 將基礎類別再做細分類 OCR Contrastive Language-Image Forensic Search 搜索影片中有沒有文本描述的物體 筆記 prompt engineering prompt ensemble\n","date":"2023-11-21T01:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/clip-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"CLIP 論文閱讀"},{"content":"paper: PonderNet: Learning to Ponder\nAbstract CNN 在 CV 領域是首選，但基於 attention 的網路也在變流行。\n本文證明雖然 convolution 和 attention 都可以獲得良好的 performance，但皆非必須。\n本文提出了 MLP-Mixer，一種純 MLP 的架構，包含兩種 layer：\n將 MLP 獨立用在 patch mixing per-location features 將 MLP 用在 patches 之間。 mixing spatial information Introduction 本文提出了完全基於 MLP 的 MLP-Mixer ( 又簡稱 Mixer )，有競爭力卻概念和技術上都很簡單。\n有兩種 MLP layer：\nChannel-Mixing MLP\n用在每個 patch 上 讓不同 channel 之間的資訊互相交換 Token-Mixing MLP\n用在所有 patch 上 讓空間資訊互相交換 這兩者交錯出現，讓兩個輸入維度可以交互作用\n在極端情況下，本文的架構可以看做是一個非常特殊的 CNN，使用 1*1 卷積做 channel mixing，並用 single-channel 且 full receptive field 的 1D 卷積做 token mixing。\n反之則不然，因為經典的 CNN 並不是 Mixer 的特例。\n盡管很簡單，但 Mixer 卻取得有競爭力的結果。\n然而與 ViT 一樣，在一切特有的 CNN 架構下略有欠缺。\nMixer Architecture Mixer 的核心概念是想把\nmix features at a given spatial location mix features between different spatial locations 給分開來\n所有的 patch 都是用同一個 projection matrix\n注意 fig1 的 MLP2，他們共享同樣的參數，這樣綁定參數可以預防 C 和 S 增加時使架構增長過快。在 seperable convolution 中，不同通道使用不同的 kernel。不過作者這樣的選擇並不影響實際的 performance。\nMixer 的所有 Layer 都具備相同的輸入大小。\n這種「isotropic」的設計和 Transformer 或 RNN 比較像。\n與大多數具有 pyramidal structure 的 CNN 不同，它們在更深的層有更低的 resolution，但有更多 channel。\n不過上面只是探討典型的設計，也存在例外，比如 isotropic Resnet 或 pyramidal ViT。\n除了 MLP，Mixer 還有用到 LayerNorm 和 skip connection。\n但是 Mixer 沒有用到 positional encoding，因為 token-mixing MLP 本身就對位置敏感。\\\nExperiments Mixer 用中大型資料集預訓練，然後在一系列中小資料集上評估。\n目標不是拿到 SOTA，而是顯示出與 SOTA 的 CNN 和 attention-based model 相比，Mixer 有競爭力。\nFine-tuning 在 fine-tuning 時，用比預訓練時還要高的 resolution。 由於每個 patch 的 resolution 是固定的，這樣會導致有更多的 patches。\n對於這個問題，採用以下解法：\n我們原先預計吃 S 個 patch，現在我們由於輸入解析度更高，而且 patch 大小不變，所以我們得到一個比 S 還大的 $S\u0026rsquo;$。 所以我們在很多地方就需要比原先權重矩陣 W 還更大的 $W'$\n我們要把 $S\u0026rsquo;$ 拆成 $K^2$ 個長度為 $S$ 的 sequence，K 是整數。\n並且我們把 $W\u0026rsquo;$ 的 shape 改成 $(W.shape[0] * K^2, W.shape[1] * K^2)$\n然後我們把 $W\u0026rsquo;$ 作為 block-diagonal matrix 來初始化，把 $W$ copy 好幾份，放在 main diagonal 上。\n所有權重都用類似的處理方法。\n","date":"2023-10-30T00:27:55+08:00","permalink":"https://roykesydon.github.io/Blog/p/mlp-mixer-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"MLP-Mixer 論文閱讀"},{"content":"大致概念 屬於生成式 AI，一開始用在生成圖片，後來也有應用到諸如 NLP 等領域。\n下文稱呼原圖為 sprite。\n與 AutoEncoder 有點類似，先取得一張 sprite，隨著時間推進，每次都在圖片上加一層雜訊，反覆疊加，迭代多次後，就會得到一張難以看出原圖的雜訊。\n從 sprite 到只能看出是一團雜訊並非是一步到位的過程。一開始沒有雜訊時可以看出原本的 sprite，一個迭代後可能可以勉強看出原本的 sprite，再幾個迭代後可能也還能看出原本的 outline，經過許多次後才會變成完全辨識不了的雜訊。\n我們期望模型做的事情則是從 gaussian noise 逐步推回 sprite，同樣不是一步到位，而是讓模型預測上一個時間點的雜訊，相減後再逐步推回 sprite，這過程稱為 denoise。\nDDPM 實現 Diffusion 可能會有點 confusing，因為他實作上和上面說的不太相同。 在訓練的時候，我們會採樣三個東西：\n訓練圖片 (sprite) 雜訊 時間點 (t) 訓練階段的時候，我們會把「原始乾淨的圖片」和「雜訊」根據時間進行不同比例的相加 (混合)，t 越大，雜訊的比例越大。\n模型預測的目標是前面 sample 出的雜訊。\n這與前面說的概念相悖。按照前面的說法，對於時間點 t，應該是以一張加了 t-1 次雜訊的 sprite 作為輸入，再加上 t 所 sample 出的雜訊。\n現在實作卻是原始乾淨的 sprite 直接根據時間點混和某個雜訊。\n這背後的數學推導十分冗長，這裡不敘述，但需知道實作差異。\nInference 在推論階段的時候，每次 denoise 後需要把圖片和額外 sample 的 noise 相加。這個 noise 和前面的 noise 一樣，都是從 mean=0, std=1 的 gaussian distribution 中 sample 出來的。\n不加的話似乎還容易有 Mode Collapse 的現象。 看到一個說法是，模型喜歡吃圖片加上雜訊的圖像作為圖片，在圖片上加上 noise 似乎會更符合模型預期的輸入。\n看了李弘毅的影片，也有基於隨機性的觀點。\n生成式 Model 生成文章時永遠取機率最大的，不見得有更好的效果：\n有研究是讓 Model 選機率最大的，結果容易生出反覆跳針的文章。\n也有把人類寫的文章去餵給 Model 看，從他的角度看人類寫的下一個字的機率是多少，發現人類寫的文章很常出現一下機率高一下機率低的字。\n某篇語音合成的文章需要在推論階段「啟用」dropout 才可以有好的結果。\nDiffusion 也有可能成功的點是在於並非「一次到位」而是「N 次到位」。 從這樣的角度看，Diffusion 是 autoregressive 模型。\n類似的作法也有 Mask-Predict，大致概念是從原本都是 Mask 的情境開始，將一些信心高的預測留住，信心低的保持為 Mask，一步步預測出所有資訊。\n","date":"2023-10-23T00:27:55+08:00","permalink":"https://roykesydon.github.io/Blog/p/diffusion-%E5%85%A5%E9%96%80/","title":"Diffusion 入門"},{"content":"Creational patterns 關於 object creation 的 patterns。\nFactory Method 將不同 Product 定義一個共有的 Interface，並由子類別實作，透過工廠類別來產生實體。\n將建立 Product 的方法獨立出來，符合 Single Responsibility Principle。 可以輕易擴充新的 Product，而不用修改原本的程式碼，符合 Open-Closed Principle。\nAbstract Factory 相比 Factory Method，現在的情境是有多個 Product，而且每次都是使用同一系列的 Product。\nBuilder 對於建構一個複雜且具備多種組合的產品，可以透過建構巨大的建構函式或是覆蓋所有可能的子類別來解決。\n但都存在其問題，要不是大量的子類別，不然就是難以呼叫的建構函式。\n把建立物件的每個 component 獨立出來，並且切成多個可分開執行的 step。\n由 Builder 來負責生出每一個 component，Director 不是必需的，但有需要的話可以讓他幫忙調用 Builder 的 method，好在專案中重複使用。\nPrototype 使用在想要獲得某個對象的 clone 的情境。\n把 clone 的責任交給對象本身，而不是交給 Client。由對象本身提供 clone method。\nSingleton 確保某個類別只有一個 instance，並且提供一個 global access point。\n但是這樣違反了 Single Responsibility Principle，因為除了原本的功能外，還要負責管理自己的 instance。\nStructural patterns 探討如何組裝類別和物件成為更大的結構。\nAdapter 轉換某個對象的 interface 到另外一種 interface，讓另外一個 Object 可以理解他。 就像 XML 要轉到 JSON。\nBrdige 使用在需要在多個 orthogonal (independent) 的維度上擴展類別時的情境。 讓情況從難以計數的子類別數，變成多組功能聯合起來。\n拆成 abstraction (high-level control) 和 implementation (實際工作)， 由 abstraction 來控制 implementation，比如 GUI 來控制底下的 API\nComposite 用在某些層級結構。\n對於 Composite (Container)，不但實現 Component，也提供一個 list 來存放子 component。\n對 Composite 的操作，會被委託給子 component，不需要 client 擔心。\n就像指揮官只需要對高階軍官下命令。\nDecorator 當今天有多種同類型的東西，你可以能會同時用到多種子類別所形成的組合時，就可以用 Decorator。\n比如多種類型的 notification，你可能同時想要 FB 和 TG 的，或是只想要其中一個。 或是多件衣服，有超級多種的穿搭。\n但這是一層層的感覺，具有順序性。 Decorator 和 Component 都繼承同一個 interface。 就像是 Data data = new Encrypt(new Compress(new FileData()))。\n存在很難從 stack 中刪除特定 decorator 的缺點。\nFacade 為複雜的一堆子系統提供一個 Class，讓 client 可以使用他們關心的功能。 實際怎麼調用 client 無須知道。\n容易形成 god object。\nFlyweight 對於大量類似的物件，為求節省記憶體而誕生的 pattern。\n把物件的內容分成 intrinsic 和 extrinsic，intrinsic 是不會改變的 (unique)，而 extrinsic 是會改變的 (repeating)。\n讓 extrinsic 的東西用同一塊記憶體。\nProxy 用在多個服務想要調用某個重量級資源的情境下。\n存在多種 proxy 的應用類型，比如 cache 機制來加速資源的存取，並減少系統資源消耗。\nBehavioral patterns Chain of Responsibility 對於一系列檢查的情況，可以用這種作法，有兩種形式：\n一路檢查，檢查失敗則中斷請求。 每個 Handler 自行決定要不要處理該請求，要的話則不會往下傳。 這樣可能會最後沒人處理 就像網頁點擊事件，一層層元素往下問。\nCommand 把請求獨立出來，讓該請求可以被用作參數、佇列、撤銷行為等。\n比如多種不同的按鈕背後都執行同一個存檔功能。存檔就可以作為 command 獨立出來。 背後再根據這個 command 實施對應的業務邏輯。\nIterator 用來需要遍歷集合中元素的情境，把不同種類的遍歷行為細節隱藏起來。\n提供多種不同的 iterator，但遵循同一種 interface，讓使用者可以根據需要選擇 iterator。 對於不關心用哪種 iterator 的使用者，也能受益於 iterator 的 interface，而不必耦合於特定的演算法。\nMediator 禁止多個 component 間的直接溝通，迫使他們透過 mediator 來溝通，避免複雜的關係。 所有人只能透過 notify mediator 來溝通，mediator 根據 sender 和 event，來做出相應處理。\nMemento 讓你可以儲存和復原到先前的狀態。\n讓要儲存的對象自己生成 snapshot。\n建議存在名為 momento 的 special object，這個 object 不能讓除了 producer 外的其他 object 直接存取。 其他 object 只能透過 limited interface 來取得 metadata。\n這些限制讓 momento 可以交給其他 object 來管理，稱為 caretaker。\nObserver 定義 subscription 機制。\n有 interesting state 的 object 稱為 subject，但由於他也會通知其他人，所以又稱為 publisher。追蹤它的人稱為 Subscriber。\nState 用在類似 Finite-State Machine 的情況。\n該 pattern 把每個 state 獨立成一個 Class，把實際的行為委託給 state，而不是由 context (原始物件) 來控制。Context 只管切換 state。\nStrategy 把不同實現方法的演算法定義為遵循同一個 interface 的類別，讓使用者可以根據需要選擇演算法。\nTemplate Method 把演算法拆成多個步驟，讓子類別可以覆寫其中的步驟，但不改變演算法的結構。\nVisitor 讓我們可以把演算法從執行他們的 object 中分離出來。\n假設我們要對一堆繼承 client 屬性的公司新增 sendEmail 功能，如果我們在 client 新增 sendEmail 並且 override 每個子 class，就會違反 Single Responsibility Principle 和 Open-Closed Principle。\n要利用 Double-Dispatch，讓 Object 本身選擇該用的演算法。\n雖然這樣依然會修改到子 class，但這屬於微不足道的改變，而且可以讓之後新增的一些功能不用再去修改這些子 class。\n","date":"2023-10-10T00:00:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E8%A8%AD%E8%A8%88%E6%A8%A1%E5%BC%8F-desing-pattern/","title":"設計模式 Desing Pattern"},{"content":"提高查找相似向量的速度 任何非暴力搜尋的搜尋方法，都會一定程度上的降低搜索品質。 需要在搜索品質和速度進行 trade-off。\nK-Means 可用在將向量資料庫分群，以便縮小查找相似向量的範圍。\n迭代計算群心，直到收斂\n依據離群心的遠近分類\n問題 相近的向量有可能被分到不同群\n可以透過「用更多類，並搜索多個最近群」來緩解問題\n可以找其他 ANN (Approximate Nearest Neighbors) 演算法來面對該問題\n位置敏感哈希 (Locality Sensitive Hashing, LSH) 讓越相似的向量越容易碰撞，找相似向量就在同個 bucket 找\n實現方法 此處挑一種方式舉例，此處用隨機超平面舉例。\n可以在空間中隨機生成多個 (n-1) 維度的超平面，將兩邊分類為 0 和 1。 距離較遠的點對被切割開的機率會比距離較近的點對還大。 用這樣的方法，會讓相近的點對生出的 Hash 值較接近。\n問題 接近的向量有可能因為機率因素被分到不同 bucket 將向量分段，每段有匹配到同個 bucket 就視作候選項 減少查找相似向量的記憶體開銷 大量的高維向量會造成大量的記憶體開銷\nK-Means 把同一群的向量都用群心向量代替，是一種有損壓縮。\n問題 但這樣需要另外的空間來存取 codebook (向量對應表)，在某些情況不見得比原本的向量還省空間，甚至可能花更多。\nn 維的向量可能需要 $2^{\\frac{n}{2}}$ 的 class 才可以較好的分類 (來源未知)\n可以透過把高維向量切割成多個低維子向量個別處理再合併來緩解該問題。\n該方法稱為 Product Quntization (PQ)\n其他做法 NSW 六度分隔理論 (Six degrees of separation) 對於世界上兩個互不相識的人，只需要六個中間人就可以建立起連結。\n做法 我們想找對於某個目標向量而言最相似的向量。\n先隨機找一個點，找他的相鄰節點誰和目標向量最相近，並反覆此過程，直到所有相鄰節點都沒有自己離目標相近。\n六度分隔理論讓我們推測這過程可能很快就會結束。\n建立結構 我們得幫這些向量建立圖關係。\nDelaunay triangulation algorithm 可以用來建立圖關係 但靠 Delaunay triangulation algorithm，有可能隨機的向量和目標向量距離很遠，查找很慢。\nNSW 的實際做法是將所有向量隨機地放回圖中，並和最近的 k 個點連接。\n只看較短的連接，會發現和 Delaunay triangulation algorithm 產的圖相近，可以進行細粒度的查找。 只看較長的連接，則可達到快速導航的效果。\nHNSW 建立一個分層結構，越上層的點越稀疏、連線越長。\n和 NSW 相比，讓粗粒度到細粒度的導航過程更加穩定。\n但占用的記憶體空間更大。\n","date":"2023-10-06T00:27:55+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E6%9F%A5%E6%89%BE%E7%9B%B8%E4%BC%BC%E5%90%91%E9%87%8F/","title":"查找相似向量"},{"content":"Union-Find (DSU) 不同條件下的時間複雜度 待補 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 int find(int x) { if (f[x] == x) return x; else return f[x] = find(f[x]); } int merge(int x, int y) { f[find(x)] = find(y); } int main() { for (int i = 1; i \u0026lt;= n; i++) f[i] = i; x = find(x); y = find(y); if (x != y) { merge(x, y); } } Trie 1 2 3 4 5 6 7 8 9 10 11 class Node { public: int cnt; int id; Node* nxt[26]; Node() { cnt = 0; for (int i = 0; i \u0026lt; 26; i++) nxt[i] = nullptr; } }; Segment Tree 單點修改線段樹 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 #define pl(x) (x * 2 + 1) #define pr(x) (x * 2 + 2) void build(int index, int l, int r) { if (l == r) { tree[index] = arr[l]; return; } int mid = (l + r) / 2; build(pl(index), l, mid); build(pr(index), mid + 1, r); tree[index] = tree[pl(index)] * tree[pr(index)]; } void change(int index, int q, int l, int r, int \u0026amp;value) { if (l == r) { tree[index] = value; return; } int mid = (l + r) / 2; if (mid \u0026gt;= q) change(pl(index), q, l, mid, value); else change(pr(index), q, mid + 1, r, value); tree[index] = tree[pl(index)] * tree[pr(index)]; } void query(int index, int ql, int qr, int l, int r, int \u0026amp;ans) { if (ql \u0026lt;= l \u0026amp;\u0026amp; r \u0026lt;= qr) { ans *= tree[index]; return; } int mid = (l + r) / 2; if (ql \u0026lt;= mid) query(pl(index), ql, qr, l, mid, ans); if (mid \u0026lt; qr) query(pr(index), ql, qr, mid + 1, r, ans); } ","date":"2023-08-29T00:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E8%B3%87%E6%96%99%E7%B5%90%E6%A7%8B%E7%AD%86%E8%A8%98/","title":"資料結構筆記"},{"content":"Sorting Merge Sort 一直拆分兩邊最後再輪流 merge 起來，merge 時看兩邊開頭誰最小，依序放 都是 $O(nlogn)$ stable not in-place Quick sort 選定一個 pivot，用兩個指針從兩邊開始往中間找。當左指針找到比 pivot 大的數值，右指針找到比 pivot 小的數值後交換。直到兩個指針相遇，再把 pivot 換到中間，繼續兩邊處理\n最差會到 $O(n^2)$，平均 $O(nlogn)$\n選 pivot\n隨機選 Median of Three 選開頭、中間和結尾的中位數 Other Binary Exponentiation 快速冪 1 2 3 4 5 6 7 8 9 int qpow(int x, int m) { int ans = 1; while (m) { if (m \u0026amp; 1) ans *= x; x *= x; m \u0026gt;\u0026gt;= 1; } return ans; } Discretization 離散化 1 2 3 4 5 sort(vec.begin(), vec.end()); vec.resize(unique(vec.begin(), vec.end()) - vec.begin()); for (int i = 0; i \u0026lt; vec.size(); i++) { val[i] = lower_bound(vec.begin(), vec.end(), val[i]) - vec.begin(); } Ternary Search 三分搜 1 2 3 4 5 6 7 8 9 10 11 l = -10000.0; r = 10000.0; while (r - l \u0026gt; eps) { ml = (r - l) / 3.0 + l; mr = (r - l) * 2.0 / 3.0 + l; if (f(ml) \u0026gt; f(mr)) { l = ml; } else { r = mr; } } ","date":"2023-08-27T00:09:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E6%9C%AA%E5%88%86%E9%A1%9E%E6%BC%94%E7%AE%97%E6%B3%95-%E8%B3%87%E6%96%99%E7%B5%90%E6%A7%8B%E7%AD%86%E8%A8%98/","title":"未分類演算法 \u0026 資料結構筆記"},{"content":"Floyd-Warshall 1 2 3 4 for (int k = 0; k \u0026lt; nodeCount; k++) for (int i = 0; i \u0026lt; nodeCount; i++) for (int j = 0; j \u0026lt; nodeCount; j++) DP[i][j] = min(DP[i][j], DP[i][k]+ DP[k][j]); dijkstra 時間複雜度 $O((V+E)*log(E))$ 最差每條邊都要插入 heap 要取出 V 個點 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 class cmp { public: bool operator()(edge a,edge b) { if(a.weight\u0026lt;b.weight) return true; return false; } }; dis[a] = 0; priority_queue\u0026lt;edge, vector\u0026lt;edge\u0026gt;, cmp\u0026gt; pq; pq.push({a, 0}); while (!pq.empty()) { edge u = pq.top(); pq.pop(); if (!vis[u.to_node]) { vis[u.to_node] = 1; for (auto i : mp[u.to_node]) { if (dis[i.to_node] \u0026gt; dis[u.to_node] + i.weight) { dis[i.to_node] = dis[u.to_node] + i.weight; pq.push({i.to_node, dis[i.to_node]}); } } } } Topological Sorting 記得確認是不是 Directed Acyclic Graph BFS 是沒有前繼節點優先，DFS 是沒有後繼節點優先 用 BFS 的話就是把入度為 0 的點加入 Queue，一直維護該 Queue 1 2 3 4 5 6 7 8 9 10 void dfs(int u) { if (!vis[u]) { vis[u] = true; for (auto j : edge[u]) dfs(j); toposort.push_back(u); } } for (int i = 1; i \u0026lt;= n; i++) dfs(i); reverse(toposort.begin(), toposort.end()); 樹的直徑 兩次 DFS，第一次找到離任意點最遠的點，第二次從該點出發找到離他最遠的點，這兩個點之間的距離就是樹的直徑。\nLowest Common Ancestor 待補 Eulerian path 歐拉路徑 每條邊只能被訪問一次（一筆畫問題） 條件 除了兩個點外，其他都得為入度==出度。另外兩個點，最多有一個出度要比入度大一，最多有一個入度要比出度大一。（只能有 0 或 2 個奇點） 須為連通圖 視作無向圖的時候是否可以連到每個點 Matching Hungarian Algorithm 待補 最小點覆蓋等等 待補 ","date":"2023-08-27T00:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E5%9C%96%E8%AB%96%E7%AD%86%E8%A8%98/","title":"圖論筆記"},{"content":"簡介 Meta 在 2015 年公開的 API Query Language 常被用來和傳統的 REST API 比較，具備查詢更加靈活等特性 有在使用的公司 Facebook GitHub Twitter \u0026hellip; 和 REST API 的主要差別 Single Endpoint\n和 REST API 對於不同 resource 需要不同 endpoint 不同，GraphQL 對於所有 resource 都是從同一個 endpoint 進行存取 但 GraphQL 不能輕易地用 HTTP caching，因為現在只剩一種 URL 了 解決 Under-fetching 和 Over-fetching 問題\nUnder-fetching\n一個 API call 沒辦法取得所有想要的資料，需要多次 API call 假如要用 RESTful API 取得一個文章的作者，可能得先取得文章，再取得作者，這樣就需要兩次 API call 但 GraphQL 可以在一次 API call 中取得文章和作者，透過 nested query Over-fetching\n一個 API call 取得的資料比想要的還多，造成資源浪費 GraphQL 可以透過 query 定義只想取得的欄位 使用 和 RESTful API 不同，需要特別架個 GraphQL server，可以考慮用 Apollo Server\n要定義不同 Data type 的 schema、relationship，以及寫對應不同 query 的 resolver\nQuery 可能會是長這樣的東西\n1 2 3 4 5 6 7 8 9 10 11 query postQuery($id: ID!) { post(id: $id) { id title content author { id name } } } Mutation 新增、修改、刪除資料都屬於這塊\n1 2 3 4 5 6 7 8 9 10 11 query addPost($post: AddPostInput!) { addPost(post: $post) { id title content author { id name } } } ","date":"2023-08-22T00:00:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/graphql-%E7%B0%A1%E4%BB%8B/","title":"GraphQL 簡介"},{"content":"paper: End-to-End Object Detection with Transformers\nAbstract 作者把 object detection 視作一個 set prediction 問題。\n簡化了 pipeline，消除了許多 hand-designed components，比如 non-maximum suppression 和 anchor generation，這些 component 由我們對於任務的先驗知識構成。\n提出了一個新的目標函數，透過二分匹配（bipartite matching）進行預測，也用 Transformer encoder-decoder 架構。\n給予一組固定的 learned object query，DETR 可以推理 objects 和 globol image context 的關係，並「並行」輸出一組預測集。\nDETR 概念非常簡單。\nDETR 在 COCO 上和 Faster RCNN baseline 在準確度和 performance 上相當。\nDETR 可以很簡單地推廣到 Panoptic Segmentation。\nIntroduction 目標檢測的目標就是集合預測。\n但目前都用一些很間接的方式去做，像是用 proposals, anchors 或 window centers。\n但是這些方法性能明顯受限於後處理步驟，比如 non-maximum suppression，因為他們會產生大量冗餘的框。\n為了簡化 pipeline，作者提出了一種 End-to-End 的方法，以往也有一些嘗試，但他們要不添加了其他的先驗知識，不然就是在具有挑戰性的 benchmark 上表現不好。\n在 COCO 上和 Faster R-CNN 的性能相當，表現和速度都差不多。\nDETR 在大物體表現很好，可能是歸功於 Transformer non-local 的計算能力。 雖然 DETR 在小物體上表現倒不怎麼樣。\nDETR 需要超長的訓練時間，但 DETR 的設計理念可以拓展到 Panoptic Segmentation。\nRelated Work Set Prediction 沒有規範的深度學習模型可以直接預測集合。\n這些任務中的一個困難點是避免 near-dulicates（相近的重複檢測框） 當前多數檢測器用 NMS 來解決此問題，如果是 direct set prediction 就不用後處理。\nTransformers and Parallel Decoding Transformer 在各種地方表現出色，但推理成本令人望而生畏。\nObject detection 現在多數的目標檢測方法是基於一些初始的猜測，再去做預測。\n比如對於 two-stage 的方法，就是對於 proposals 往下做預測。\n對於 single-stage，初始猜測就是 anchors。\nSet-based loss 以前的一些作法比如 Learnable NMS 或 relation networks 都可以透過 attention 來處理不同預測之間的關係。\n用 direct set losses，他們不需要任何後處理。\n但是這些方法往往用額外的 hand-crafted context feature，比如 proposal box coordinates。作者尋找減少模型中先驗知識的方案。\nRecurrent detectors 以往有類似的工作，但他們是用 RNN。\nThe DETR model Object detection set prediction loss DETE 會給 N 個固定大小的集合預測。\n要解二分圖匹配，本文用 scipy 的 linear_sum_assignment 處理，他背後是匈牙利演算法。\n其實這種方法和 proposals 和 anchors 有差不多的作用，差別在於這裡會找一對一的匹配，而不用重複。\n目標函數：\n$L_{Hungarian}(y, \\text{\\^{y}}) = \\displaystyle\\sum^{N}_{i=1} [-log \\text{\\^{p}} $ $_{\\^{\\sigma}(i)}(c_i) + \\text{1}$ $_\\{$ $_{c_i \\neq \\text{\\o}}$ $_\\}$ $\\mathcal{L}$ $_{\\text{box}} (b_i, \\text{\\^{b}}$ $_{\\^{\\sigma}}(i))]$\n前面是分類的 loss，後面是 bounding box 的 loss。\n這邊有兩個改動，第一個是分類那邊不用 log，使值和 bounding box 的 loss 比較接近。\n另一個是 bounding box 那邊並不是用最常見的 L1，因為 L1 對於大的目標 loss 比較高，這裡除了 L1 還選用 generalized IoU loss，它在尺度上與 loss 無關。\nDETR architecture 用 CNN 從圖片抽特徵，拉直，餵給 Transformer encoder-decoder，得到一組預測集合。\n這裡 encoder 有助於特徵間彼此交互。\n訓練的時候，預測的框和 GT 做匹配，沒匹配到的就放到 \u0026ldquo;no object\u0026rdquo; class。\ndecoder 會餵入 object queries，這些是 learnable positional encodings。\nExperiments Ablations Number of encoder layers 作者透過改變 Encoder layer 的數量來評估 global imagelevel self-attention 的重要性。\n作者推論 encoder 可能對於判斷分開對象很重要，圖 3 可視化了最後一個 encoder layer 的 attention map。\nencoder 看似已經分離了 instance，可能簡化了 decoder 對於 object extraction 和 localization 的工作。\nNumber of decoder layers 在圖 6 做了 decoder 的注意力可視化，可以注意到觀察的注意力相當局部。\n推論是 encoder 主要分離實體，decoder 只需要關注四肢即可提取出對象的邊界和分類。\nAnalysis 圖 7 把 100 個預測槽中的 20 個做可視化。\n每個預測框代表一點，可以注意到不同的槽位會專注在不同區域。\n","date":"2023-08-10T00:27:55+08:00","permalink":"https://roykesydon.github.io/Blog/p/detr-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"DETR 論文閱讀"},{"content":"paper: BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\n現在回頭寫 BERT 論文筆記感覺有點怪，之前已經寫過什麼 RoBERTa 之類的。\n不過現在因應實驗室讀書會要求，還是看一下論文也寫一下筆記。\nAbstract 本文提出了 BERT，一種基於 Transformer Bidirectional Encoder 的語言表示模型。\nBERT 旨在透過 unlabeled text 進行 pretrain。\n因此，只需要一個額外的輸出層就可以對預訓練的 BERT 進行微調，在各種任務上取得 SOTA。\nIntroduction 「語言模型做預訓練」已被證明可以有效改善多種 NLP 任務。\n將預訓練模型應用在下游任務，有兩種策略：\nFeature-based 把 pretrained 的 representations 作為額外的特徵 Fine-tuning 根據特定任務引入額外參數，並簡單地微調所有參數 這兩種方法在預訓練期間共用同個 objective function，並用單向語言模型來學習 representation。\n作者認為當前的技術限制了預訓練的表示能力，特別是在 Fine-tuning 方法上。\n主要的問題在於語言模型是單向的，限制了預訓練期間可以使用的架構的選擇。這種單向的架構可能在一些任務有害，特別是對於那些需要兩個方向的 context 的任務。\n本文提出的 BERT 改善了現有的 Fine-tuning 方法，用 Transformer 的 Bidirectional Encoder 來訓練語言模型。\nBERT 透過受到 Cloze task（填空）啟發的 masked language model(MLM)，作為預訓練目標。MLM 隨機地遮蔽一些輸入的一些 token，目標是根據上下文來回推原詞，使 representation 可以融合左右兩邊的 context。\n除了 MLM，作者還利用 next sentence prediction（NSP）任務來訓練 BERT。\n本文貢獻如下：\nBERT 證明了雙向預訓練對 representation 的重要性。\nBERT 展現出預訓練的 representation 減少了許多針對 NLP 任務精心設計架構的需求。 BERT 是第一個基於 Fine-tuning，在大量 sentence-level 和 token-level 任務上取得 SOTA 的模型。\nBERT 推進了 11 個 NLP 任務的 SOTA。\nRelated Work Unsupervised Feature-based Approaches 學習廣泛適用的 representation of words 一直是活躍的研究領域，甚至在非神經網路的領域也是。\n預訓練的 word embeddings 與從頭訓練的 embedding 相比，有顯著改進。\n這些方法頁被推廣到 coarser granularities，像是 sentence embedding 或是 paragraph embedding。\n有研究證明 cloze task 提高了生成模型的 robustness。\nBERT 框架有兩步驟：\nPre-training 在不同的預訓練任務中，用 unlabeled data 來 fine-tune。 Fine-tuning 使用預訓練的參數初始化，在利用下游任務的 labeled data 對所有參數微調。 BERT 的一個特點是他具備跨不同任務的統一架構，預訓練架構和下游任務最終架構差異不大。\nModel Architecture\n本文表示方法\nL: Transformer 的層數 H: hidden size A: self-attention heads 的數量 model size\nBASE: L=12, H=768, A=12, 110M parameters 和 GPT 相同 LARGE: L=24, H=1024, A=16, 340M parameters Input/Output Representations\nInput representation 可以在 token sequence 中明確表示單個 sentence 和一對 sentence。\nsentence 可以是連續文本的任意範圍，而不是實際的句子。 sequence 是輸入的 token sequence，可以是單個 sentence 或是一對 sentence。 每個 sequence 的第一個 token 始終是特殊的分類 token \u0026ndash; [CLS] 對於兩個句子放在一個序列的情況，用 [SEP] 隔開 Token Embeddings\n作者使用 WordPiece embeddings，有 30000 個詞彙。 learned embedding\n對每個 token 添加這個東西，表示屬於 sentence A 還 sentence B Pre-training BERT Masked LM 直觀上，有理由相信深度的雙向模型會比單像串連起來的淺層模型更強大。\n不幸的是 standard condition language model 只能單向訓練，因為雙向會允許每個單詞「間接看到自己」。\n為了訓練 deep bidirectional representations，本文隨機遮蔽了一定比例的 tokens，並預測這些 token，這種方法稱為 masked language model，或常被稱為 cloze task。\n作者會用 [MASK] 做預訓練，但有個問題是 [MASK] 在 fine-tuning 期間不會出現，造成預訓練和微調之間的 mismatching，為了緩減這種情況，並不會總是用 [MASK] 替代 masked token。\n要替換 token 的時候，有 80% 的時間是 [MASK]，10% 是隨機 token，10% 是原本的 token。\nNext Sentence Prediction (NSP) 許多重要下游任務，比如 Question Answering (QA) 和 Natural Language Inference (NLI) 是基於兩個句子間的關係。\nNSP 就是為了理解句子間的關係而用的。\n每次挑句子 A 和 B 的時候，有 50% 的機會 B 是 A 的下一個句子，有 50% 是隨機的。\n針對 NSP 的預訓練對 QA 和 NLI 都很有用。\n預訓練資料 用 BookCorpus 和 English Wikipedia 來訓練 BERT。\n對於 English Wikipedia，只提取 text passages，忽略 lists, tables, headers。\n為了提取長的連續序列，用 document-level 的 corpus 而不是打亂的 sentence-level corpus 非常重要。\nAblation Studies Effect of Pre-training Tasks No NSP 只有 MLM LTR \u0026amp; No NSP Left-to-Right 只看左邊的 context 發現刪除 NSP 會顯著傷害對 QNLI 等資料集的性能。\nLTR 在所有任務上都比 MLM 差。\n雖然可以像 ELMo 單獨訓練 LTR 和 RTL，並且把他們結合起來\n但有以下缺點：\n比單向模型貴兩倍 對 QA 任務不直觀，因為 RTL 無法根據問題給出答案 不如深度雙向模型強大，因為其可以直接在每一層看到左右的 context Feature-based Approach with BERT 作者也研究了用 feature-based 的效果，發現具備競爭力。\n在他的實驗中，用預訓練 Transformer 的 top 4 隱藏層的 token 串街效果最好。\n","date":"2023-08-05T00:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/bert-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"BERT 論文閱讀"},{"content":"圖簡介 Graph\n表示 Entity (nodes) 間的 relations (edges) 組成 Vertex attributes (V) Edge attributes and directions (E) Global attributes (U) 下文簡稱 U, V, E 可以表示成圖的範例\nImages 相鄰 pixel 建無向邊 Text 詞和下一個詞建單向邊 Molecules 分子的連接處建無向邊 Social networks 人和人之間建無向邊 定義問題 種類 Graph-level Node-level Edge-level 個別講的是基於什麼東西做分類，比如對每個人（node）分類一個陣營，就算 Node-level 挑戰 儲存邊的關係 鄰接矩陣 在節點多的情況下佔用空間大，而且可能非常稀疏 同一張圖，換個點的順序後鄰接矩陣看起來就會不同 難以保證這些東西餵入神經網路後輸出相同 可以用兩個 list，一個儲存邊的向量，另一個是 Adjacency list，依序紀錄邊的關係 稀疏矩陣 難以用 GPU 運算 Graph Neural Network GNN 是對圖上所有屬性的 optimizable transformation，而且可以保持 graph symmetries (permutation invariances，把 node 排序後結果不變)\n下文用的 GNN 是 message passing neural network\ngraph-in, graph-out 不改變圖的 connectivity 最簡單的 GNN U, V, E 個別餵給不同的 MLP，組成一個 GNN 的 layer MLP 單獨餵入每一個點，不考慮連接訊息，保持了 graph symmetries 預測 假如要對每個頂點做預測，最後再加個全連接層分類 pooling 假如要對一個沒有向量的頂點做預測，我們可以用 pooling，蒐集相鄰邊和全局向量的資訊 對於沒有頂點資訊的圖，我們可以用 pooling layer 獲取全部點的資訊，再做分類 對於沒有邊資訊的圖，我們也可以用 pooling 去從相鄰點和全局向量獲得資訊 對於沒有全局向量的圖，我們可以用 pooling 去從全部的點或邊獲得資訊 缺陷 中間的 layer 沒有利用圖的訊息，都是各自進入各自的 MLP 做轉換 Passing messages 在做轉換前，先做一些 pooling\n匯聚頂點資訊 不是單單把點向量進行轉換，而是和相鄰的點一起做 aggregation 後再做轉換 如果 aggregation 是加總，和卷積有一點像，只不過是權重一樣的版本 匯聚頂點和邊的資訊 可以先把頂點匯聚給邊，再把邊匯聚回頂點，反之亦然 順序不同會導致不同結果 兩種方法可以一起同步做，交替更新 全局資訊 每次 layer 只看鄰居，要傳遞到遠的點須要走很多層 導入 master node (context vector)，他連接了所有的點和邊 相關主題 採樣\n考量到計算梯度可能需要儲存過多的中間資訊，可以考慮採樣一些點，只在子圖上做計算 Batch\n每個點鄰居各數不同，使做 batch 成為有挑戰性的問題。 Inductive Bias\ngraph symmetries Aggregation\n目前沒有一個最佳選擇 Graph Convolutional Network\nnode 是根據鄰居 node 去做某種 aggregate，事後再做更新 由於每次都看鄰居，假如有 k 層，可以把圖看做解 n 個子圖，每個子圖就是基於每個點去走 k 步所形成的 Graph Attention Network\n用 attention 決定其它點的權重，而不像 GCN 一樣把鄰居加起來 ","date":"2023-08-04T00:27:55+08:00","permalink":"https://roykesydon.github.io/Blog/p/gnn-%E4%BB%8B%E7%B4%B9/","title":"GNN 介紹"},{"content":"paper: Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset\nAbstract 目前的動作分類資料集 (UCF-101 和 HMDB-51) 的影片非常缺乏，使辨識「良好的影像架構」變得困難， 使多數方法在現有的小規模 benchmark 的表現差不多。為此本文根據新的 Kinetics Human Action Video dataset 對 SOTA 架構進行了重新評估。\nKinetics 有 400 個人類動作類別。每個類別有 400 個 clip。從 YouTube 上獲取的，而且每個 clip 來自 unique 的 youtube 影片。\n本文分析了當前架構在 Kinetics 上動作分類任務的表現，也評估 Kinetcis 用作預訓練的效果。\n本文提出了一種基於 2D ConvNet inflation 的 Two-Stream Inflated 3D ConvNet (I3D)。\nI3D 的擴展方法讓 ImageNet 上已經取得成功的架構可以被利用在解決影像任務上。\n結果表明，經過在 Kinetics 上預訓練後，I3D 在動作分類方面顯著提高了 SOTA，在 HMDB-51 上達到 80.9%，在 UCF-101 上達到 98.0%。\nIntroduction 在 ImageNet 上預訓練模型的效果很好，但在影片領域，預訓練成效一直是一個未知的問題。因為流行的動作識別 benchmark 都非常小，約略只有 10k 個影片。\nKinetics 有 400 個人類動作類別。每個類別有 400 個 clip，而且每個 clip 都來自一個 unique 的 Youtube 影片。\n本文實驗策略是在 Kinetics 上預訓練，再在 HMDB-51 和 USC-101 上微調，結果顯示出預訓練總是能提高性能，但提升多寡因架構而異。\n本文提出新架構，稱為「Two-Stream Inflated 3D ConvNets」(I3D)，建立在 SOTA 的影像分類架構上，並將 filters 和 pooling kernel 膨脹成 3D。\n基於 Inceptionv1 的 I3D 在 Knetics 上預訓練後，性能遠超過當前的 SOTA 架構。\n在本文的模型中，並沒有考慮更多經典方法，比如 bag-of-visual-words representation，但 Kinetics 是公開的，因此其他人可以進行後續研究。\nAction Classification Architectures 目前影片架構中的一些主要區別如下：\n卷積是 2D 還 3D 的 是否只是 RGB 影片，還是包含事先計算的 optical flow 對於 2D ConvNets，訊息是怎麼在 frame 之間傳遞的 這部分可以使用 temporally-recurrent layers，比如 LSTM，或是用隨時間的 feature aggregation 來完成。 在本文中，考慮了涵蓋大部分現有架構的模型子集：\n2D ConvNets 頂部有 LSTM 的 ConvNet 有兩種 stream fusion 的 two-stream networks 3D ConvNets C3D 由於參數維度較高，以及缺乏 labeled video data，以前的 3D ConvNet 相對較淺（最多 8 層）。\n本文發現諸如 VGG-16 和 ResNet 等很深的影像分類網路可以輕鬆擴展成 spatio-temporal feature extractors，並且他們的預訓練權重也可以提供有價值的初始化。\n本文也發現 two-stream 的作法依然有用。\nfig2. K 是影片中的 frame 的總數，N 是相鄰 frames 的子集合。\n上圖是本文實驗的五種架構，前四種是之前的做法，最後一種是提出的新作法。 上圖中除了 C3D 外都有用到 ImageNet 預訓練的模型。\n時間是根據 input 的 frame 換算出來的，fps 是 25，除了 LSTM 那個比較特別，因為 LSTM 那個是每 5 frame 取 1 frame，所以時間是 5 倍。\n之前的做法 ConvNet+LSTM\n有一種做法是把每個 frame 獨立餵給 2D Conv，然後再把預測做彙整，符合 bag of words image modeling 的精神，但這樣會忽略時間結構上的資訊，比如無法判斷開門或關門。\n所以最好在後面加一個 recurrent layer，所以這邊就用 Inception-V1 結合 LSTM。\n原始的影片 stream 是 25 fps，這邊每 5 frame 採樣一次。\n3D ConvNets\n和一般的卷積神經網路差不多，只是具有 spatio-temporal filters。\n但由於額外的 kernel 維度，相比 2D Conv 會有更多參數，也使他們更難訓練。\n而且這樣會無法發揮 ImageNet 預訓練的好處，因此之前的工作都定義了相對淺層的架構，並且從頭訓練。\nbenchmark 中的表現備受期待，但和 SOTA 比沒有競爭力，也因此成為本文實驗的良好候選者。\n本文用的是 C3D 的小變體，差異在於所有卷積層和 FC 層的後面都用了 BN。 而且在第一個 pooling layer 用的 stride 是 2，好減少記憶體的使用，比用更大的 batch，這在 BN 中非常重要。\nTwo-Stream Networks\nRoy：這裡由於比較複雜，我要改提 two-stream 的原始論文（Two-Stream Convolutional Networks for Action Recognition in Videos）說明這東西是什麼\n簡而言之就是分成兩個部分：\n空間資訊：\n用影片的一個 frame　經過卷積神經網路達成，這個 frame 用來提取影像中的物件資訊，比如打排球這動作可能辨識出排球就非常好判定，所以用某個 frame 來提取空間資訊。\n動作資訊：\n這邊用一連串的光流（optical flow）圖來達成，光流是物體（pixel）在兩個 frame 間的位移向量，估計方法有很多，這裡不一一舉例。\n上圖出自 Two-Stream Convolutional Networks for Action Recognition in Videos，圖 c 就是光流，具有兩個方向，指出像素的位移，圖 d 是水平方向的視覺化，圖 e 是垂直方向的視覺化。\n再把這些光流圖餵給卷積神經網路，用作動作資訊的判別。\n值得一提的是他是 late fusion，而且是用加權平均，不是像一般想的把特徵結合再做其他處理。\nThe New: Two-Stream Inflated 3D ConvNets 作者把成功的 2D 分類模型簡單地轉換為 3D\nInflating 做法是把方形的 filter 改成立方體，把 N x N 的 filter 改成 N x N x N 的 filter，但這只有架構上的參考。\nBootstraping 把權重也給轉換到 3D 架構的方法。\n作者觀察到影像可以透過反覆複製貼上來生出一個「不會動的無聊影片」， 透過這些影片，3D 模型可以透過這種方式在 ImageNet 上 implicitly pretrain，做法就是讓 3D filter 吃無聊影片的輸出和 2D filter 吃單一 frame 的輸出相同，做法如下：\n我們可以沿時間維度重複 2D filter N 次，把這權重給 3D filter，同時把權重除以 N，達到這種效果。\nPacing receptive field growth in space, time and network depth 以往在圖片上對水平和垂直軸的對待是平等的，pooling kernel 和 stride 都一樣。 使感受野在兩個維度上隨著模型越來越深，慢慢平等增長。\n但是時間軸用對稱的感受野不一定最好，而該取決於 frame rate 和 image dimensinos。 如果時間相對於空間增長太快，可能會混淆不同對象的邊緣，影響早期的特徵檢測。如果增長太慢，可能無法很好地捕捉場景動態。\n實驗中，輸入影片的 fps 是 25。\n作者發現在前兩個 max pooling layer 不在時間軸 pooling（透過用 1 x 3 x 3 的 kernel，並且時間軸的 stride 是 1），並在其他 max pooling layer 都用 symmetric kernels 和 stride 是有幫助的。\n最後的 average pooling layer 是用 2 x 7 x 7 的 kernel。\n作者用 64 frame 訓練，但用整個影片測試。（averaging predictions temporally）\n我想了一下，250 / 64 除不進，但是我看 code 發現他好像寬高 224 * 224 的照片會在最後經過 Average pool 後變成 1 * 1，所以他可以直接用 1 * 1 * 1 的卷積核把輸入通道改成分類數，再把時間軸的結果平均。\nTwo 3D Streams 分別訓練兩個網路，並在測試階段對預測進行平均。\n這邊作者說光流的演算法某種意義上是 recurrent（例如，對於 flow fields 進行 iterative optimization），我不太懂這邊是什麼意思，我想作者用的光流演算法應該是透過某種類似 EM 演算法那種不斷迭代去逼近數值的演算法，但作者提到「或許是因為缺乏 recurrence，我們發現雙流有價值」，我不太懂為什麼需要 recurrence 效果才會好。\n但結論是 two-stream 依然具備價值。\nImplementation Details 這邊講滿詳細的，有興趣可以去原文看。 只提一下幾點:\n光流演算法是用 TV-L1。 除了類似 C3D 的 3D ConvNet 都用使用 ImageNet 預訓練的 Inception-V1 作為 base network。 對於較短的影片，會重複循環以滿足模型的輸入介面 測試時會在中間剪裁 224 x 224 The Kinetics Human Action Video Dataset Kinetics 有 400 個人類動作類別。每個類別有 400 個 clip，而且每個 clip 都來自一個 unique 的 Youtube 影片，共有 24 萬個訓練影片。\n每個 clip 都大約 10 秒，而且沒有未剪的影片。\n測試集每個 class 包含 100 個 clip。\nExperimental Comparison of Architectures I3D 在所有資料集上都表現最好，甚至是在 UCF-101 和 HMDB-51 這種小資料集上也是如此，這意味著 ImageNet 預訓練的好處有成功擴展到 3D ConvNet。\n多數模型在 UCF 上都表現得比 Kinetics 上好，顯現出資料集的難度差距。\n但是在 HMDB 表現得較差，原因可能是 HMDB 故意弄得很難，作者有舉例，很多 clip 在完全相同的場景會有不同的動作。\n作者有提到說 I3D 特徵比較好遷移的一種解釋是它具備 high temporal resolution， I3D 在 25 fps 的影片中用 64 frames 做訓練，使它能捕捉動作的 fine-grained 時間結構。\nExperimental Evaluation of Features Kinetics 上做預訓練效果明顯比 ImageNet 好。\nDiscussion Kinetics 上的預訓練對於遷移學習有明顯好處，但對於其他影像任務，比如影像語義分割是否有好處仍待觀察。\n目前對於架構沒有全面探索，比如沒有採用 action tubes 或是 attention 機制。\n","date":"2023-07-23T00:27:55+08:00","permalink":"https://roykesydon.github.io/Blog/p/i3d-%E8%AB%96%E6%96%87/","title":"I3D 論文"},{"content":"Use Cases Cache 把常用的資料回傳，省略長時間的 IO 操作 Shared Session 在 stateless server 間共享 session Distributed lock 用在程式間想共用某種資源的時候 用 setnx (set if not exists) atomic Rate Limiter 用 increment 和 expiration 實現 快取常見策略 cache aside 先問 cache，沒有的話再問 db，並把 db 回傳的資料放到 cache read through client 只能存取到 cache，如果沒資料，cache 會去 db 拿資料 write through client 寫資料時，cache 會留一份資料，並把資料寫到 db write behind 和 write through 很像，但是不會立即寫到 db，會等到有更多的資料時，才一次寫到 db Feature NoSQL In-memory Key-Value Basic Command redis-server default port: 6379 redis-cli Access data set \u0026lt;key\u0026gt; \u0026lt;value\u0026gt;\nPretty much everything stored in Redis is going to be a type of string by default get \u0026lt;key\u0026gt;\ndel \u0026lt;key\u0026gt;\nexists \u0026lt;key\u0026gt;\nkeys \u0026lt;pattern\u0026gt;\nfind keys with certain pattern keys * get all keys flushall\nget rid of everything Expiration ttl \u0026lt;key\u0026gt;\nshow time to live \u0026ldquo;-1\u0026rdquo; for no expiration \u0026ldquo;-2\u0026rdquo; already expired expire \u0026lt;key\u0026gt; \u0026lt;second\u0026gt;\nsetex \u0026lt;key\u0026gt; \u0026lt;seconds\u0026gt; \u0026lt;value\u0026gt;\nset with expiration Data Structure List lpush/rpush \u0026lt;key\u0026gt; \u0026lt;value\u0026gt; lrange \u0026lt;key\u0026gt; \u0026lt;start index\u0026gt; \u0026lt;end index\u0026gt; \u0026lt;end index\u0026gt; can be -1 lpop/rpop \u0026lt;key\u0026gt; Set sadd \u0026lt;key\u0026gt; \u0026lt;value\u0026gt; smembers \u0026lt;key\u0026gt; srem \u0026lt;key\u0026gt; \u0026lt;value\u0026gt; remove Hash Key-value in Key-value\nhset \u0026lt;key\u0026gt; \u0026lt;field\u0026gt; \u0026lt;value\u0026gt; hget \u0026lt;key\u0026gt; \u0026lt;field\u0026gt; hgetall \u0026lt;key\u0026gt; get everything about \u0026lt;key\u0026gt; hdel hexists \u0026lt;key\u0026gt; \u0026lt;field\u0026gt; Redis doesn\u0026rsquo;t support nested hash struct 刪除過期 key 定期刪除 在固定間隔時間隨機抽 key 檢查並刪除\n惰性刪除 在訪問 key 的時候發現過期就刪除\nmaxmemory-policy (Eviction) 可以設定這些 policy，在記憶體依然額滿的情況下做對應的處理\nnoeviction allkeys-lru allkeys-lfu volatile-lru volatile-lfu allkeys-random volatile-random volatile-ttl 快取情境問題 快取雪崩 Cache Avalanche 某個時刻大量 cache 失效，使資料庫需要承擔很大的流量。 解法 幫 cache 加上額外的隨機過期時間 快取擊穿 Hotspot Invalid 某個 hotspot 的 cache 失效，使大量請求跑到資料庫 解法 讓 hotspot 永不過期 查詢資料庫的部分加上 lock 快取穿透 Cache Penetration client request 不存在的資料，因為同時不存在於 cache 和資料庫中，所以直接跑到資料庫 解法 在 application 先過濾掉非法請求 Bloom Filter 布隆過濾器 Persistence RDB 固定時間對所有資料做快照，memory dump 出來 recovery 比 AOF 快 save、bgsave AOF 紀錄操作流程 檔案比較肥 Rewrite 當 AOF 太大，Redis 會生一個新文件取代舊的，用最少操作生出目前的資料\n混合 在 AOF 重寫的時候也利用 RDB 前面是 RDB，後面是 AOF\nAvailability 主從同步 一主多從，把讀取壓力分擔到 slave 上\n哨兵模式 Sentinel 會有哨兵不斷地 Ping 主從伺服器，確認是否有異常\n如果哨兵是集群，有哨兵檢測到異常，會判斷某伺服器主觀下線，當有一定數量的哨兵投票認為伺服器不可能用，就會變成客觀下線，進行 failover\nCluster 分擔寫入壓力\nRedis 有 16384 個 slot，透過 hash 分配 key 到不同的 slot\n預設會另外用 port 16379 來讓節點間溝通\n可以混和主從同步達到高可用\n","date":"2023-06-05T00:00:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/redis/","title":"Redis"},{"content":"前言 軟體要對 domain 做 Modeling，呈現出 domain 裡的核心概念，才能滿足使用者需求，因此不乏與領域專家的討論\n寫這篇的時候我還沒嗑完 Eric 的聖經，可能嗑完了之後會回來修改\n通用語言 Ubiquitous Language 鑒於程式開發人員與領域專家熟悉知識的差異，會產生交流困難\n因此領域專家和開發團隊要訂定共同的語言，並且盡可能少用自己知道的術語\nUML UML 適合用在小型模型上，它擅長表達類別間的關係，但對於抽象概念卻沒那麼好傳達\n因此用 UML 建構模型時，理想上要添加額外的文字，傳達一些圖所不能表達的 behavior 和 constraint\n並且不能一次寫過於複雜，而是分塊處理\nLayered Architecture 分為四個概念層，只會往下調用，可能會跨層\n可以達到關注點分離 (separation of concerns)，提高各個方面的 cohesive\nUser Interface (Presentation Layer) 呈現給 user 的 UI，User 可能是另一個系統 Application Layer 不含 bussiness logic，指揮表達領域概念的物件來完成任務 Domain Layer 有關 domain 的資訊都在這裡，業務邏輯在此處理 表達業務概念、狀態、規則 劃分出這層是 Model-Driven Design 的關鍵 Infrastructure layer supporting library 保存業務狀態的技術細節在此實作 為前三個 layer 服務 Entity 具備 identity identity 在 status 經過改變後依然不變 追蹤 entity 需要高成本 mutable Value Object 沒有 identity 只關心 obejct 的 value 可以輕易創建丟棄 immutable (不變的) 如果想修改數值就創新的 可被共用 Service 有些動作不屬於某個 Entity 或 Value Object，因為它是跨物件的 Stateless 每個請求不互相影響 Aggregate 把複雜關聯的物件圈在一起考量 確保 consistency 和 inveraints consistency (一致性) 相關物件的資料一致 invariants (不變量) 資料改變時要維護的規則 Aggregate root 具備 global identity，其他內部 entity 只有 local identity 通常是 entity 擔任 外部只能存取它，不能存取 aggregate 的其他 entity 或 value obejct Factory 若創建 aggregate、entity、value object 的過程很複雜，或是涉及專業知識，就該用 factory 包起來 對於不複雜的情況，或是想控制更多細節，可以只依賴於簡單的建構函式 Repository 如果大家都直接存取資料庫的各種物件，會破壞原本精心設計的結構，破壞封裝性\nRepositoy 用來存取物件，封裝了資料庫操作\nDomain event Domain 中重要的事情 可以用在其他物件和 aggrgate 訂閱，讓 aggregate 通知他們 domain event 的發生 Anti-Pattern 應該避免的情形 Smart UI 超肥的萬能 UI Anemic Domain Model 貧血模型 只有 getter 和 setter，沒有業務邏輯的模型 Subdomain 把 domain 切分成小塊，理想上 subdomain 和 bounded context 有 one-to-one 的關係\nTypes core subdomain 和其他競爭者相比不同的部分，最核心的業務，比如搜尋引擎中的搜尋演算法 generic subdomain 大家都會弄的部分，比如登入系統 supporting subdomain 用來輔助 core subdomain 的部分，比如篩選網頁 Bounded Context 劃出 boundary，確保 boundary 內用的概念、規則皆一致 同個名詞可能出現在不同的 context，但有不同意思 Context Map 描述 BC 和 BC 間的關係\n上下游 (U/D) 上游提供下游 (下游依賴上游) Shared Kernel 兩個 BC 共用的部份 違反 BC 的基本原則，是一種例外設計 Customer-Supplier 一個子系統重度依賴另一個子系統 Conformist Customer 完全配合 Supplier Partnership 兩個 BC 互相合作，沒有以誰為主 一起成功或一起失敗 Anticorruption Layer (ACL) 開發系統和外部系統的中間層 可能出現在調用 legacy system 常用到 Facade 和 Adapter Open Host Service (OHS) 如果外部子系統要給一堆用戶端子系統調用，就得在所有用戶端子系統搞 ACL 外部系統做為服務提供，常會搭配 Published Language (PL) PL 是協定傳送資料的格式，比如 XML、JSON 或是 Protocol Buffer Pratical DDD The strangler migration 透過 Facade，把一些服務慢慢移植給新系統，最後取代 legacy ","date":"2023-05-22T00:00:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E9%A0%98%E5%9F%9F%E9%A9%85%E5%8B%95%E8%A8%AD%E8%A8%88-domain-driven-design/","title":"領域驅動設計 Domain-Driven Design"},{"content":"簡介 Timer 和 Counter 的差別是 Timer 是定期的數數\nTiming functions 定期對 CPU 發送 interrupt 產生準確時間的 delay 產生 pulses 或 periodic waveforms PWM 量測 duration STM32 Timer / Counter 從 Basic 到 Advanced，追加更多功能\nBasic TImer (Simple Timer)\n16 bit auto-reload register programmable pre-scaler 可以 output 到 DAC update event CNT=ARR(up-count) CNT=0 (down-count) reset CNT to 0 or ARR set UIF flag in status register update event interrupt 如果 enabled (UIE=1) UIF 被設置的時候發送訊號 $T_{EVENT}=Prescale \\times Count \\times T_{CK \\_ INT} \\\\ =(PSC+1)\\times(ARR+1)\\times T_{CK \\_ INT}$\n$T_{EVENT}$ 是兩次事件發生的間隔時間 PSC 是設定 (數值 - 1)，所以 Prescale 是 1 的話，要設 0 Control register\nCEN 是否啟用 counter UDIS 是否啟用 update event URS 設定產生 update event 的 source OPM 是否只算一次 counter 就停 ARPE 關於中途改 ARR 的 reload 設定 UIF interrupt General Purpose Timer\n16-bit or 32-bit auto-reload register use for a variety of puposes measuring lengths of input signals (Input Capture)\nInput Capture 測量 pulse width (高電位的時間) 或 period (一個週長) generating output waveforms (Output Compare and PWM Generation)\none pulse mode output Up to 4 independent channel Interrupt / DMA generation event counter overflow / underflow counter initialization trigger event input capture output compare Advanced Control Timer\n16-bit auto-reload register 特殊 timer\nlow power timer 可以用在比如睡眠狀態 補充 24 bits system timer (SysTick) reload 在 overflow 時回到 register 設定的數值 STM32 Timer 差異 可以去 Datasheet 找每個 Timer 的功能\nCounter resolution\n16/32 bit 決定能從 0 數到多少個 Counter Type\n決定能往上數或往下數或都可以 Prescaler factor\n可以把進來的數字先除以某個數，減緩速度 DMA request generation\n能否用 DMA access 記憶體 Capture / Compare channels\n一個 Timer 可能可以發多個訊號出去，並且經過多個 Compare register，比對不同 event functions Compare 和比對 register，比到了就送 event Capture 紀錄下 channel 的值 Complementary output\n有些馬達控制需要反向波，就要這個 Max interface clock (MHz) and Max timer clock (MHz)\n進去和出來的速度 System Clock - Clock tree Timer 源頭就是 clock\n有四種來源幫忙驅動 system clock (SYSCLK)\nHSI16 (high speed internal) 16 MHz RC oscillator clock MSI (multispeed internal) RC oscillator clock HSE (high speed external) oscillator clock, from 4 to 48 MHz PLL clock SYSCLK 往下接到 AHB，再接到 APB1、APB2\nFlash Read Access Latency 調整 clock 也要調整這部分 Register TIMx_CR1 control register TIMx_PSC 設定 prescale TIMx_ARR auto-reload register ","date":"2023-05-04T01:32:54+08:00","permalink":"https://roykesydon.github.io/Blog/p/stm32-timer-/-counter-%E4%BB%8B%E7%B4%B9/","title":"STM32 Timer / Counter 介紹"},{"content":"paper: Self-Instruct: Aligning Language Model with Self Generated Instructions\nAbstract 大型 \u0026ldquo;instruction-tuned\u0026rdquo; 語言模型 (經過微調好回應 instruction) 已經展現出在新任務上 zero-shot 的能力。\n然而他們嚴重依賴人工編寫的指令，在數量、多樣性和創造力上都受到了限制，阻礙了模型的通用性。\n作者介紹了 Self-Instruct 這個框架，可以透過自己生成的指令，來增強預訓練模型遵循指令的能力。\n將作者的方法應用在 GPT3，在 SuperNaturalInstructions 獲得了比原始模型高 33% 的改進，與使用 private user data 和 human annotations 的 $InstructGPT_{001}$ 性能相當。\n為了進一步評估，我們為新任務整理一組專家編寫的指令，並通過人工評估，顯示出使用 Self-Instruction 調整 GPT3 的性能大大優於使用現有公共指令資料集，只比 $InstructGPT_{001}$ 落後 5% 的差距。\nSelf-Instruct 提供一個幾乎 annotation-free 的方法，align 預訓練模型和 instructions，而且作者釋出了他們的大型合成資料集，以促進未來對 instruction tuning 的研究。\nIntroduction 最近的 NLP 文獻見證了「建構可以遵循自然語言指令的模型方面」的大量活動。\n這些發展由兩個關鍵部分組成：\n大型預訓練語言模型 (LM) 人工編寫的指令資料 PromptSource 和 SuperNaturalInstructions 是最近兩個著名的資料集。 他們透過大量手動註釋來收集指令，以建造 T0 和 T$k$-Instruct。\n然而這過程代價高昂，而且由於大多數人往往生成的都是流行的 NLP 任務，使其未能涵蓋真正多樣的任務，也不能涵蓋各種描述任務的不同方式，因此多樣性受侷限。\n鑒於這些限制，想要繼續提升 instruction-tuned models 的品質，需要幫 supervising instruction-tuned models 發展替代方案。\n本文介紹了 Self-Instruct，這是一種 semi-automated 的過程，用模型自身的 instructional signals 對 pretrained LM 進行 instruction-tuning。\n整個流程是一種 iterative bootstrapping algorithm，從手動編寫的 limited seed set 引導生成。\n在第一階段，模型要幫新任務生成指令。 利用現有的指令集合，創建更廣泛的指令，好定義 (通常是新的) 任務。\n對於新生成的指令集，框架為他們創建 input-output instances，稍後可以透過 supervising 用於 instruction tuning。\n最後，透過各種手段，在低品質和重複的指令加到 task pool 前，把他們修剪掉。\n可以重複這個流程非常多次，直到獲得大量任務。\n該模型的跌代過程中產生了大約 52K 個指令，與大約 85K 個 instance inputs 和 target outputs 配對 (有些相同的指令會對應多種輸入輸出)。\n作者觀察到生成的資料提供了各種有創意的任務，其中超過 50% 的任務和 seed instructions 的 ROUGE-L overlap 小於 0.3。\n基於上述結果，作者通過微調 GPT3 (和生成指令資料是同個模型) 建構了 $GPT3_{SELF-INST}$。\nSuperNI 的結果表明，$GPT3_{SELF-INST}$ 性能大大優於 GPT3 (原始模型)，高了 33.1%，幾乎和 $InstructGPT_{001}$ 的性能相當。\n此外，作者在新創建的的指令集上進行人工評估，$GPT3_{SELF-INST}$ 顯示出廣泛的指令遵循能力，優於在其他公開可用指令數據集上訓練的模型，只比 InstrcutGPT001 落後 5%。\n本文貢獻：\nSelf-Instruct：一種用最少的人工標記數據引導指令遵循能力的作法 通過大量的 instruction-tuning 實驗，證明了有效性。 發布了一個包含 52K 指令的大型綜合資料集，還有一組手動編寫的新任務，用於建構和評估未來的 instruction-following models。 Related Work Instruction-following language models 一系列工作顯示，使用 annotated \u0026ldquo;instructional\u0026rdquo; data，可以使普通語言模型遵循一般語言的指令。\n也顯示出 \u0026ldquo;instructional\u0026rdquo; data 的大小和多樣性直接影響模型的泛化能力。\n本文的工作目的在減少對人工註釋者的依賴。\nLanguage models for data generation and augmentation 許多工作依賴生成式 LM 來生成數據或做 augmentation。\n雖然作者的工作可被視為一種 augmentation，但和這些工作的差別在於不限於特定任務。\nSelf-Instruct 的一個明顯動機是引導出新的任務定義，而這些任務可能還未被 NLP 的研究者定義過。\nSelf-training 一種典型的 self-training 框架透過經過訓練的模型，幫 unlabeled 資料進行 label，然後用這些資料改進模型。\n雖然 Self-Instruct 和 self-training 有一些相似之處，但多數 self-training 的方法都假設了一個特定的目標任務。\n相比之下，Self-Instruct 從頭開始生出各種任務。\nKnowledge distillation 這邊我想不太通為什麼可以和 Knowledge distillation 扯上關係\nKnowledge distillation 通常涉及知識從較大模型到較小模型的轉移\nSelf-Instruct 也可以看做是 Knowledge distillation 的一種形式，但區別如下\ndistillation 的來源和目標是相同的，即模型的知識被 distill 到他自己 distill 的內容以 instruction task 的形式出現 Method 標記大規模指令資料對人類來說可能具有挑戰性，因為他需要\n創意，好提出新任務 為每個任務編寫 labeled instances 的專業知識 Defining Instruction Data 我們要生成的指令資料集包含 {$I_t$}，每個指令用自然語言定義了任務 $t$。\n每個任務都有一個或多個 input-output instances ($X_t,Y_t$)。\n給定 task instruction $I_t$，還有 instance x，模型 M 要生出 y：\n$M(I_t,x)=y, for (x,y) \\in (X_t,Y_t)$\n值得注意的是，instance input 和 instruction 沒有嚴格分界。\n比如 Instruction:\u0026ldquo;write an essay about school safety\u0026rdquo; x:\u0026quot;\u0026quot;，可以被改為 Instruction:\u0026ldquo;write an essay about the following topic\u0026rdquo; x:\u0026ldquo;school safety\u0026rdquo;\nAutomatic Instruction Data Generation 生成指令資料的 pipeline 分成四個步驟：\n指令生成 辨識指令是否是分類任務 用 input-first 或 output-first 做 instance generation 過濾掉低品質的資料 Instruction Generation Self-Instruct 是基於一個發現，也就是大型語言模型可以透過 context 中的現有指令，生出新穎的指令。\n為作者提供了一種從一小組人類編寫的指令中，使指令資料增長的做法。\n作者用他們編寫的 175 個任務 (每個任務 1 個 instruction 和 1 個 instance) 初始化 task pool。\n在每一個 step，作者從裡面 sample 8 個 instructions，作為 in-context 的範例。在這 8 個指令中，有 6 條來自人工編寫的任務，另外兩條來自前面步驟中模型生成的任務，以促進多樣性。\nClassification Task Identification 因為對於分類和非分類的任務，作者會採取兩種做法，所以作者使用來自 seed taks 的 12 條分類指令和 19 條非分類指令，讓 GPT3 透過 few-shot 來判別。\nInstance Generation 給予指令和他們的任務類別，作者獨立地為每條指令生成 instance。\n這具備挑戰性，原因在於他需要模型瞭解目標任務是什麼，根據指令找出需要那些額外的輸入內容，並生成他們。 (模型要根據 instruction 生出 instance input)\n作者發現，在 prompt 中放入其他包含 instruction-input-output 的任務範例的時候，模型可以實現這點。\n一種自然的方法是 Input-first Approach，可以要求語言模型先根據指令提出 input，再生出相應的 output。\n然而，這種方法在分類任務上，可能會偏向於生成某種 label。所以，對於分類任務，作者採用 Output-first Approach，先生成可能的 label，在每個 label 上再生成輸入。\nFiltering and Postprocessing 為了鼓勵多樣性，只有當新的指令和任何現有的指令的 ROUGE-L overlapping 小於 0.7 的時候，才會被添加到 task pool。\n還排除了一些包含了通常不能被 LM 處理的關鍵字 (e.g. images, pictures, graphs) 的指令。\n在為每個指令生成新的 instance 的時候，會過濾掉完全相同或者是輸入相同但輸出不同的 instance。\nFinetuning the LM to Follow Instructions 在創建大規模指令資料後，用這些資料對原始語言模型進行 fine-tune。\n為此，將 instruction 和 instance input 連接起來，作為 prompt，然後訓練模型透過標準的監督式學習進行微調。\n為了讓模型對不同的格式 robust，使用多個模板將指令和輸入 encode 在一起。\n例如，指令可以有或沒有 Task: 前墜、輸入可以有或沒有 Input: 前墜，或是中間可以有不同數量的換行之類的。\nSelf-Instruct Data from GPT3 作者透過 OpenAI API 訪問最大的 GPT3 (davinci)\nStatistics Diversity Quality Experimental Results $GPT3_{SELF-INST}$: fine-tuning GPT3 on its own instruction data 使用生出來的指令資料，對 GPT3 進行微調。\n微調是透過 OpenAI finetuning API\nBaselines Off-the-shelf language models T5-LM 和 GPT3 是普通 LM baselines (只有 pre-training，沒有額外 fine-tune)\n這些 baseline 將表明現成的 LM 在預訓練後，能夠立刻自然地遵循指令的程度。\nPublicly-available instruction-tuned models T0 和 $T_k$-Instruct 是兩個 instruction-tuned models。\n兩者都是從 T5 進行微調的，對這兩種模型，都使用具有 11B 參數的最大版本。\nInstruction-tuned GPT3 models 作者評估了 InstructGPT，它是 OpenAI 基於 GPT3 開發的。\n對於 SuperNI 的實驗，只與 text-davinci-001 engine 進行比較，因為更新的 engine 用最新的用戶資料，而且很可能已經看過 SuperNI。\n對於新編寫的指令，評估時則包含了 001、002 和 003，以確保完整性。\n為了進一步比較 Self-Instruct 在其他公開可用的指令訓練集資料，使用 PromptSource 和 SuperNI 的資料微調 GPT3，這些資料用於訓練 T0 和 $T_k$-Instruct 模型。\n分別簡稱為 T0 訓練和 SuperNI 訓練。\nExperiment 1: Zero-Shot Generalization on SUPERNI benchmark 首先以 zero-shot 的方式評估典型 NLP 任務遵循指令的能力。\nResults Experiment 2: Generalization to User-oriented Instructions on Novel Tasks 盡管 SuperNI 在現有的 NLP 任務具有全面性，多數的這些任務是初於研究理由提出的，而且偏向分類。\n為了更好的獲取指令遵循模型的實用價值，作者中的一部分人策劃了一組面向用戶應用的新指令集。\n他們先針對 Large LM 可能可以應用到的領域進行 brainstorm，並且制定與每個領域相關的 instruction 和 instance。\n總共創建了 252 條指令，每條指令有 1 個 instance。\nHuman evaluation setup 評估模型在這些不同任務的測試集上的表現極具挑戰性，因為不同的任務需要不同的專業知識。\n為了獲得更忠實的評價，作者請了 instructions 的作者對模型的預測結果進行評估。\n實施一個 four-level rating system：\nRating A 回覆有效且令人滿意 Rating B 回覆可接受，但存在可以改進的地方 Rating C 回覆相關，但在內容上有重大錯誤 Rating D 回覆不相關或無效，包含重複輸入的部分，完全無關的輸出。 Results 如果把 Rating B 以上視為有效，$GPT_{SELF-INST}$ 只和 $InstructGPT_{001}$ 相差 5%\nDiscussion and Limitation Why does SELF-INSTRUCT work? 值得反思的是，在最近成功的 instruction-tuning LMs 中，高品質的 human feedback 扮演的角色。\n這裡有兩個極端的假設：\nHuman feedback 是 instruction-tuning 中必要且不可或缺的角色，因為 LM 需要了解在預訓練過程中沒完全了解到的問題。\nHuman feedback 是 instruction-tuning 一個可選的方向，因為 LM 在預訓練就已經很熟悉指令了。\n雖然現實可能介於這兩個極端之間，作者推測可能更傾向於第二種假設，尤其是對於較大的模型。\n第二種，也是人類直覺，是 Self- Instruct 的關鍵動機，而且也從成功的結果獲得支持。\nBroader Impact 除了本文的直接關注點外，作者相信 Self-Instruct 可能有助於揭露各種 instruction tuning 模型 \u0026ldquo;幕後\u0026rdquo; 發生的事情。\n不幸的是，由於他們的資料集尚未發布，這種業界模型仍處於 API 牆之後。\n人們對其結構以及為何能展現令人印象深刻的能力知之甚少。\nLimitations of Self-Instruct Tail phenomena Self-Instruct 依賴於 LM，繼承 LM 的所有限制。\n最近的研究顯示出 tail phenomena 對 LM 的成功構成嚴峻的挑戰。\n換句話說，LM 的最大收益出現於語言中最頻繁出現的部分 (語言分佈的頭部)，而低頻率出現的上下文中獲得的收益最小。\n同樣的，在這項工作背景下，如果 Self-Instruct 大部分的收益偏向預訓練 corpus 中頻繁出現的任務或指令，那也不令人感到意外。\n因此，該方法在不常見和有創意的指令下，可能會顯現出脆弱性。\nDependence on large models 因為 Self-Instruct 依賴於從 LM 中提取初的 inductive bias，因此它可能適合 larger model。\n如果這是對的，這會對那些沒有大量計算資源的人造成阻礙。\nReinforcing LM biases 作者擔心這種迭代作法可能會產生意料之外的結果，比如將有問題的社會偏見放大。\n","date":"2023-04-30T00:00:12+08:00","permalink":"https://roykesydon.github.io/Blog/p/self-instruct-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"Self-Instruct 論文閱讀"},{"content":"Memory Map CPU 對 I/O 操作方法\nPort I/O 用特殊 CPU 指令 I/O 設備和記憶體不共享地址空間 Memory-Mapped I/O I/O 設備和記憶體共享地址空間 像一般控制記憶體 這塊記憶體具有四個責任\nCommand Status Output Data Input Data GPIO 結構 GPIO mode Open-Drain 由外部電壓決定輸出電壓 Output Register 是 0 會啟用 N-MOS，1 的話靠外部電壓推 好處是外部電壓可以自己決定 Push-Pull 由內部電壓決定輸出電壓 Output Register 是 0 或 1 會決定啟用 N-MOS 或是 P-MOS 有關 Register Clock enable register AHB2 peripheral clock enable regisetr (RCC_AHB2ENR) Control register GPIO port mode register GPIO port output type register GPIO port output speed register GPIO port pull-up/pull-down register Data register Output Input 使用 GPIO 先去 Memory map 找 Boudary address\n根據 table 確認要設置的數值\n設定 RCC enable\n把上面說的各種 Control register 設定好\n比如 PUPDR BSRR\n修改 ODR 會一次改到整個 GPIO port，若只要改某個 pin，可以用 BSRR Delay\nCPU 4 MHz 1 cycle = 0.25$\\mu$S 可以查每個組合語言指令要幾個 cycle 機械按鈕會有 Bouncing\nDebounce Hardware method 加上濾波電容 Software method 讀取後等待一段時間才再次讀取 連續讀取 N 次，看數值是否穩定改變 7-Segment COM 分共陽、共陰\n8 個七段顯示器就要吃掉 8 * 8 個 GPIO 接腳，可以每次只顯示一個，那只需要 8 個 GPIO 接腳，快速閃過\n也可用 Max 7219 控制，他有三個輸入 DIN、LOAD、CLK\nDIN 輸入資料 CLK 上升的時候採樣，最多 10 MHz LOAD(CS) 採用最後輸進去的 16 bits 最早的是 MSB ","date":"2023-04-26T01:32:54+08:00","permalink":"https://roykesydon.github.io/Blog/p/stm32-gpio-%E4%BB%8B%E7%B4%B9/","title":"STM32 GPIO 介紹"},{"content":"重構 在不改變軟體行為的情況下，對軟體內部構造進行改善\nCode Smell 也稱 Bad Smell，代表程式碼中需要重構的部分\nDuplicated Code 重複程式碼 在同個 Class Extract Method 在不同 Class Extract Class Long Method 用 Extract Method 拆解過長的 function Long Parameter List Preserve Whole Object 把來自同一物件的資料直接該物件取代 Introduce Parameter Object 把相關的資料包成一個 Object Large Class 一個 Class 有太多 fields / methods / lines Magic Number 特殊數值直接用數字表示，日後修改每個地方都要改 Lack of Comments 加註解的好時機：寫程式前寫上 Switch Statements 可利用「多型 (Polymorphism)」解決 Divergent Change 一個類別有太多改變的原因 盡量讓其遵守 SRP Shotgun Surgery 某個責任被分散到大量的 Class 身上，使修改其時要大量修改 Feature Envy 存取別的 Object 的 Data 的情形比自己的還頻繁 這方法可能應該屬於另一個 Object Data Clumps 常一起出現的資料群應該被單獨抽成一個 Class Primitive Obsession 過度使用基本類別，造成 Shotgun Surgery Message Chains Client 請求 A 物件，A 物件又請求 B 物件 Lazy Class 把冗員類別移除 Temporary Field Instance variable 只有在特殊情形才被使用，應該改為區域變數或參數 Inappropriate Intimacy Classes 間頻繁讀取對方資料 理解程式要同時看懂兩者 Alternative Classes with Different Interfaces 兩個 Class 具有功能相同、命名不同的 function 可汲取共同部分為 Super Class 來解決 ","date":"2023-04-25T14:26:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E9%87%8D%E6%A7%8B-refactoring/","title":"重構 Refactoring"},{"content":"說明 本文寫於 Swin Transformer 論文閱讀 之後，當時對 Relatvie position 的理解不夠清楚，本文將會做解釋，並附上原論文的筆記。\n以下將會先用長度為 3 的序列作為示範。\nAbsolute Position Encodings Absolute Position Encodings 的做法是把用某種方式生成或可學習的向量加在輸入，第一個位置用 $w_1$，第二個位置用 $w_2$，第三個位置用 $w_3$。\nRelative Position Encodings Relative Position Encodings 顧名思義，就是改用相對位置來做這些向量。\n上圖中，Position Encoding 的部分從 3 個向量變成 3*3 個向量，因為現在會以每個 token 為基準，生出 3 個相對位置向量。\n我們以 $w_0$，代表處於原點，$w_x$ 代表往右 $x$ 格，$w_{-x}$ 代表往左 $x$ 格，其中 $x$ 是正整數。\n第一個 row 有 $w_0$、$w_1$、$w_2$，意思是以第 0 個向量 (I) 為基準，他的位置是 $w_0$，對第 0 個向量來說，第 1 個向量 (like) 是 $w_1$，第 2 個向量 (cat) 是 $w_2$。\n輪流以 $n$ 個 token 為基準，就會生出 n*n 個相對位置向量，而不是原先的 n 個絕對位置向量。\n其中 $w_i$ 和 $w_j$ 如果 $i=j$，他們會共用同樣的 weight，上圖是以相同顏色表示。\n如果序列長度是 $n$，就會有 $2n-1$ 個向量要學。\nn*n 這個數量使其適合加入到 self-attention，原始論文的加入方式可以參考下方論文筆記，這邊晚點會介紹後續衍生的簡化版。\nSwin Transformer 如何導入 Relative Position Encodings Swin Transformer 是借鑒許多 CNN 架構，為了 CV 而經過修改的 vision transformer。\n其中一個重點是，他會在一小區塊的特徵圖上做 self-attention，而且是用 Relative Position Encodings。\n和剛剛的差別在於，現在要在二維空間做 Relative Position Encodings。\n假設有一張 2*2 的 feature map，我們先設定好 feature map 各個 token 的絕對位置座標。\n然後我們輪流把 feature map 的每一個 token 作為基準點，把 feature map 的每個 token 的座標減去基準點的座標，就可以得到相對位置座標。\n如果我們把四個相對位置座標各別攤平 (按照左上 -\u0026gt; 右上 -\u0026gt; 左下 -\u0026gt; 右下的順序)，並且從上到下排好，他會看起來如下圖。\n此時我們幾乎完成了相對位置的表，和剛剛序列一樣生出了 n*n 個相對位置。\n我們接下來要做的事情是把這個表給編號，把 (0, 0) 都編成某個數字，把 (1, 0) 都編成某個數字。\n在此之前，先考慮總共會有幾種可能的相對座標，對於邊長 $M$ 的 feature map (這裡 M=2)，因為兩軸可能的數字皆有 (2M-1) 種，共會有 (2M-1)*(2M-1) 種可能性，這裡等於 9。\n所以我們等等會把所有座標編為 0~8。\n想從座標生出編號 0~8 可以考慮把座標兩軸的數字相加，但由於有負數的存在，要先把兩軸的數字都變成非負整數，所以先把兩軸的座標都各別加 M-1。\n此時如果相加，會使 (2, 1) 和 (1, 2) 都對應到數字 3，所以我們先把 row 座標乘上 2M-1 再相加，此時就可以獲得一個 n*n 的 index table ，對應一組相對位置向量。\nSwin Transformer 是用簡化版的作法來引入相對位置，公式如下\n$Attention(Q,K,V)=SoftMax(QK^T/\\sqrt{d}+B)V$ $B$ 是 relative position bias，$B \\in R^{M^2 * M^2}$ $a_{ij}$ 是純量，不是向量，和原始論文不同 論文出處 paper: Self-Attention with Relative Position Representations\nAbstract 依賴於 attention 機制的 Transformer 在機器翻譯方面取得 SOTA，但在結構中沒有相對或絕對的位置資訊，他需要在輸入中添加絕對位置的資訊。\n因此本文提出一種替代方案，拓展 self-attention ，考慮相對位置的表示，並在一些任務中獲得更好的結果。\n值得一題的事，作者觀察到結合相對和絕對位置不會進一步提高翻譯品質。\n該機制可以拓展到任意 graph-labeled 的輸入\nIntroduction Non-recurrent models 不一定按順序考慮輸入元素，因此可能需要明確的 position encoding 才才能用序列順序。\n一種常見的方法是使用與輸入元素結合的 position encoding，以向模型傳達位置資訊。\n可以是 deterministic function，或是 learned representations。\nCNN 可以捕捉 kernel 的相對位置資訊，但被證明仍受益於 position encoding。\n對於既不使用卷積也不使用遞歸的 Transformer，結合位置信息的 representation 是一個特別重要的考慮因素，因為該模型在其他方面對序列排序完全不變。\n本文提出一種將相對位置合併到 Transformer 的 self-attention 的做法，即使完全換掉絕對位置編碼，也使兩個機器翻譯任務的品質有顯著提高。\nBackground 原始 self-attention\n$z_i=\\displaystyle\\sum_{j=1}^n\\alpha_{ij}(x_jW^V)$\n$\\alpha_{ij}=\\frac{\\text{exp } e_{ij}}{\\sum_{k=1}^n\\text{exp } e_{ik}}$\n$e_{ij}=\\frac{(x_iW^Q)(x_jW^K)^T}{\\sqrt{d_z}}$\nProposed Architecture Relation-aware Self-Attention 有兩個要引入 relative position 的地方，而且都是向量\n$z_i = \\displaystyle\\sum_{j=1}^n \\alpha_{ij}(x_jW^V+a_{ij}^V)$\n$e_{ij}=\\frac{x_iW^Q(x_jW^K+a_{ij}^K)^T}{\\sqrt{d_z}}$\nRelative Position Representations 可以引入 clip，把線性序列中，高於長度 k 的修剪成最大值\n$a_{ij}^K=w_{clip(j-i,k)}^K$ $a_{ij}^V=w_{clip(j-i,k)}^V$ $clip(x,k)=max(-k,min(k,x))$ Experiments Model Variations clipping 的實驗 V 和 K 的 ablation study ","date":"2023-04-24T01:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/relative-position-%E4%BB%8B%E7%B4%B9--%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"Relative Position 介紹 + 論文閱讀"},{"content":"paper: Swin Transformer: Hierarchical Vision Transformer using Shifted Windows\nAbstract 本文提出一個新的 vision Transformer，稱作 Swin Transformer，可以被用作 computer vision 中的 general-purpose backbone。\n把 Transformer 從 language 移到 vision 具備挑戰性，比如同一個 visual entity 在大小上具備很大的 variance。還有 high resolution 下 pixel 和 word 的數量差異太大。\n為了解決這些差異，作者提出 hierachical Transformer，用 shifted windows 來算出 representation。\nshifted windowing 透過把 self-attention 限制在 non-overlapping 的 local window 和允許 cross-windows connection 來提高效率。\n這種 hierarchical architecture 可以靈活地在各種 scale 下擴展 model，還可以對圖像大小有線性的計算時間複雜度。\nIntroduction ViT 把圖片打成 patch，每個 patch 是 16*16，feature maps 由 single low resolution 的輸入生成，而且由於自注意力始終都是在全局上計算的 (patch 和 patch 間做自注意力)，所以時間複雜度是 quadratic computation complexity。\nSwin Transformer 從小 patch 開始，並在更深的 Transformer layers 合併相鄰的 patches。\n有了這些 hierarchical feature maps，可以用在像是 FPN 或是 U-Net。\n一個 Swin Transformer 的關鍵設計因素是 shifted window。\n透過 bridge 不同 layer 的 windows 來提供他們連接。\nMethod Overall Architecture Patch Merging 原本特徵圖是 H * W * C 以上下 stride=2 行走，會得到四張 H/2 * W/2 * C concatenate 起來，變成 H/2 * W/2 * 4C 做 linear，變成 H/2 * W/2 * 2C Swin Transformer block Swin Transformer 是透過把 Transformer block 中的 multi-head self attention(MSA) 換成基於 shifted windows 的 module 構成。\nShifted Window based Self-Attention 標準的 Transformer 架構會算 global self-attention，計算所有 token 間彼此的關係，導致 quadratic complexity，使其不適用於需要大量 token 的許多 CV 問題\nSelf-attention in non-overlapped windows 原來的圖片會以 non-overlapping 的方式切割。\n假設每個 windows 有 M * M 個 patches，然後一張圖像有 h * w 塊 patches，計算複雜度如下：\n$\\Omega(MSA)=4hwC^2+2(hw)^2C$ $\\Omega(W-MSA)=4hwC^2+2M^2hwC$ Shifted window partitioning in successive blocks window-based self-attention module 缺乏了 windows 間彼此的連接，會限制模型能力。\n作者提出了一種 shifted window 的方法，保持 non-overlapping windows 的高效計算，同時引入 windows 間的連接。\n再兩個連續的 windows 間，會移動 $(⌊ \\frac{M}{2} ⌋, ⌊ \\frac{M}{2} ⌋)$\nEfficient batch computation for shifted configuration shifted window 有個問題是，會導致更多的 windows，從 $⌈ \\frac{h}{M} ⌉ * ⌈ \\frac{w}{M} ⌉$ 到 $(⌈ \\frac{h}{M} ⌉+1) * (⌈ \\frac{w}{M} ⌉+1)$，而且有些 window 會小於 M*M。\n這樣會導致無法把這些給壓成一個 batch 快速計算。\n一種 naive 的解法就是直接在外面加 zero padding，但會增加計算量，當 windows 數量較少時，計算量會變很可觀 (從 2 * 2 個 windows 變成 3 * 3 個 windows，增加了 2.25 倍)\n作者提出另外一種巧妙的做法，把一些部分挪移。\n但現在有些 window 裡有多個不該相互做 attention 的部分，所以要用 mask 的方式計算。\n不同 windows，做 self-attention 後，把不相干的部分做的 attention 減去一個很大的數值，最後再過 softmax。\n上圖來自作者在 github 提供的可視化\n最後再把它挪回原本的位置。\nRelative position bias 參考這個: https://blog.csdn.net/qq_37541097/article/details/121119988\nArchitecture Variants window size 預設是 M = 7\nquery dimension of each head 是 d = 32\nexpansion layer of each MLP is $\\alpha$ = 4\nC 是 first stage 的 hidden layers 的 channel numbers\nSwin-T\nC = 96 layer numbers = {2, 2, 6, 2} 大小和計算量是 Base 的大約 0.25 倍 complexity 接近 ResNet-50 Swin-S\nC = 96 layer numbers = {2, 2, 18, 2} 大小和計算量是 Base 的大約 0.5 倍 complexity 接近 ResNet-101 Swin-B\nC = 128 layer numbers = {2, 2, 18, 2} Swin-L\nC = 192 layer numbers = {2, 2, 18, 2} 大小和計算量是 Base 的大約 2 倍 Experiments Image Classification on ImageNet-1K Object Detection on COCO Semantic Segmentation on ADE20K Ablation Study Conclusion 基於 self-attention 的 shifted window 是 Swin Transformer 關鍵部分，被顯示出他在 CV 領域有效率且有效，並期望未來把它應用在 NLP。\n","date":"2023-04-14T01:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/swin-transformer-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"Swin Transformer 論文閱讀"},{"content":"介紹 試用 STM32 UART 功能\n會透過 RealTerm 和 STM32L476RG 溝通，並用 DMA 接收訊息\n根據 User manual，USART2 預設會連接 ST-LINK，要連接外部設備的話要修改 solder bridge\nioc 設置 Connectivity 可以設置 USART2 mode 從 disable 改選 Asynchronous Parameters Settings 可以設置各種資訊 Baud Rate Word Length Parity Stop Bits DMA Setting Add 一個 RX Mode 改成 circular，並打開 memory 的 increment address increment address 是因為資料是用 array 存 circular 是當資料滿了後，會回到 zero position NVIC Setting 設置 DMA 應該就會自動設置一個 interrupt，檢查一下 程式碼 發送\n1 2 uint8_t myTxData[13] = \u0026#34;Hello World\\r\\n\u0026#34;; HAL_UART_Transmit(\u0026amp;huart2, myTxData, 13, 10); 接收\n1 2 3 4 UART_HandleTypeDef huart2; // generated code uint8_t myRxData[20]; HAL_UART_Receive_DMA(\u0026amp;huart2, myRxData, 20); // 在 Init 後，在 main 中執行一次就好 interrupt\n在 hal_uart.c 有\n1 2 3 4 5 6 7 8 9 __weak void HAL_UART_RxCpltCallback(UART_HandleTypeDef *huart) { /* Prevent unused argument(s) compilation warning */ UNUSED(huart); /* NOTE : This function should not be modified, when the callback is needed, the HAL_UART_RxCpltCallback can be implemented in the user file. */ } 當 DMA 滿了就會呼叫這個 function\n實驗 1 2 3 4 5 6 7 8 9 10 void HAL_UART_RxCpltCallback(UART_HandleTypeDef *huart) { /* Prevent unused argument(s) compilation warning */ UNUSED(huart); /* NOTE : This function should not be modified, when the callback is needed, the HAL_UART_RxCpltCallback can be implemented in the user file. */ HAL_UART_Transmit(\u0026amp;huart2, myRxData, 20, 10); } 當 20 個 Bytes 儲存滿了就回傳資訊給電腦\nRealTerm Display 勾選 Half Duplex 發送的訊息會顯示綠色，接收的是黃色 Port 設置 Baud 和其他有的沒的 選 open Send EOL 可以勾選 CRLF 打一些文字後按 Send ASCII 結果 程式碼\n","date":"2023-04-09T01:32:54+08:00","permalink":"https://roykesydon.github.io/Blog/p/stm32-uart-%E5%AF%A6%E9%A9%97/","title":"STM32 UART 實驗"},{"content":"目的 本文會試用 GPIO output / input / interrupt\nGPIO 架構 Output 介紹 在 ioc 那邊選個 pin，選 GPIO_Output\n在左邊欄位 System Core 選擇 GPIO\n有五個欄位可以設定\nGPIO output level\n初始電位 GPIO mode\npush pull 和 open drain 位於架構圖下方那部分，push pull 可以用 PMOS 和 NMOS 來得到高低電位，open drain 會 disable PMOS，讓你可以在外面自己接上拉電阻 GPIO Pull-up/Pull-down\nMaximum output speed\nUser Label\n用完記得 ctrl+s 讓他 generate code\n1 2 3 4 5 6 7 8 9 /*Configure GPIO pin : PtPin */ GPIO_InitStruct.Pin = RED_LED_Pin; GPIO_InitStruct.Mode = GPIO_MODE_OUTPUT_PP; GPIO_InitStruct.Pull = GPIO_NOPULL; GPIO_InitStruct.Speed = GPIO_SPEED_FREQ_LOW; HAL_GPIO_Init(RED_LED_GPIO_Port, \u0026amp;GPIO_InitStruct); /*Configure GPIO pin Output Level */ HAL_GPIO_WritePin(RED_LED_GPIO_Port, RED_LED_Pin, GPIO_PIN_RESET); 1 2 3 4 HAL_GPIO_WritePin(RED_LED_GPIO_Port, RED_LED_Pin, GPIO_PIN_RESET); // 低電位 HAL_GPIO_WritePin(RED_LED_GPIO_Port, RED_LED_Pin, GPIO_PIN_SET); // 高電位 HAL_Delay(1000); //等一秒 HAL_GPIO_TogglePin(RED_LED_GPIO_Port, RED_LED_Pin) 根據架構圖左側，你可以透過修改 BSRR 來修改 ODR，達到修改輸出的效果，請見 Reference Manuals，實際上 HAL_GPIO_WritePin 也是這樣實現的\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 void HAL_GPIO_WritePin(GPIO_TypeDef* GPIOx, uint16_t GPIO_Pin, GPIO_PinState PinState) { /* Check the parameters */ assert_param(IS_GPIO_PIN(GPIO_Pin)); assert_param(IS_GPIO_PIN_ACTION(PinState)); if(PinState != GPIO_PIN_RESET) { GPIOx-\u0026gt;BSRR = (uint32_t)GPIO_Pin; } else { GPIOx-\u0026gt;BRR = (uint32_t)GPIO_Pin; } } Input 介紹 看架構圖上方，用 Schmitt trigger 取得高低電位資料，他有 upper threshold 和 lower threshold，而不是用 single threshold\n1 2 3 4 5 /*Configure GPIO pin : PtPin */ GPIO_InitStruct.Pin = GREEN_LED_INPUT_Pin; GPIO_InitStruct.Mode = GPIO_MODE_INPUT; GPIO_InitStruct.Pull = GPIO_NOPULL; HAL_GPIO_Init(GREEN_LED_INPUT_GPIO_Port, \u0026amp;GPIO_InitStruct); 1 uint8_t green_led_input = HAL_GPIO_ReadPin(GREEN_LED_INPUT_GPIO_Port, GREEN_LED_INPUT_Pin); Interrupt ioc 選個 pin，設定 GPIO_EXTI，這邊我選 B1(PC13)，也就是開發版上的藍色按鈕\n可以選 GPIO mode，這邊選 Falling Edge Trigger，值得一提的是他的設計是上拉電阻，所以這樣不是放開後觸發，是按下後觸發。\nioc 的 System Core 的 NVIC 還要把 EXTI line[15:10] interrupts 給 enabled，然後 Code generation 打開 Generate IRQ handler，還有 Call HAL handler。\n在 stm32l4xx_it.c 裡， 現在會有\n1 2 3 4 5 6 7 8 9 10 void EXTI15_10_IRQHandler(void) { /* USER CODE BEGIN EXTI15_10_IRQn 0 */ /* USER CODE END EXTI15_10_IRQn 0 */ HAL_GPIO_EXTI_IRQHandler(B1_Pin); /* USER CODE BEGIN EXTI15_10_IRQn 1 */ /* USER CODE END EXTI15_10_IRQn 1 */ } 這兩行各別是因為我們剛剛開的功能生的\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 void HAL_GPIO_EXTI_IRQHandler(uint16_t GPIO_Pin) { /* EXTI line interrupt detected */ if(__HAL_GPIO_EXTI_GET_IT(GPIO_Pin) != 0x00u) { __HAL_GPIO_EXTI_CLEAR_IT(GPIO_Pin); HAL_GPIO_EXTI_Callback(GPIO_Pin); } } __weak void HAL_GPIO_EXTI_Callback(uint16_t GPIO_Pin) { /* Prevent unused argument(s) compilation warning */ UNUSED(GPIO_Pin); /* NOTE: This function should not be modified, when the callback is needed, the HAL_GPIO_EXTI_Callback could be implemented in the user file */ } __weak 代表有同名 function 的話，就會採用沒 __weak prefix 的\n所以我們可以在 gpio.c 放下面的程式碼\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #include \u0026lt;stdbool.h\u0026gt; void HAL_GPIO_EXTI_Callback(uint16_t GPIO_Pin) { if(GPIO_Pin == B1_Pin){ static bool prev_val = false; if(prev_val == false){ HAL_GPIO_WritePin(RED_LED_GPIO_Port, RED_LED_Pin, GPIO_PIN_SET); prev_val = true; } else{ HAL_GPIO_WritePin(RED_LED_GPIO_Port, RED_LED_Pin, GPIO_PIN_RESET); prev_val = false; } } } 實驗 設定兩個輸入，一個輸出，一個 interrupt\n當按下按鈕時，切換紅色 LED 的亮滅，並且讓板子上的綠色 LED 輸出和紅色 LED 相反的結果\nB1(PC13、藍色按鈕) 按下去的時候，會發出 interrupt，並讓 RED_LED(PC10) 輸出和上次相反的電位，讓麵包版上的紅色 LED 亮滅，正極那邊接一條杜邦線給 GREEN_LED_INPUT (PC12)，並且 LD2(PA5、板子上的綠色 LED) 會輸出和紅色 LED 相反的結果。\n程式碼\n","date":"2023-04-02T01:32:54+08:00","permalink":"https://roykesydon.github.io/Blog/p/stm32-gpio-%E5%AF%A6%E9%A9%97/","title":"STM32 GPIO 實驗"},{"content":"使用的板子 STM32L476RG\n開發文件 開發前需要先去 ST 官網，根據你的板子載四個重要文件\nDatasheet 上圖是其中的 block diagram\nReference Manuals\nProgramming Manuals\nSchematic\n創建 project File -\u0026gt; New -\u0026gt; STM32 Project Board Selector 搜索 NUCLEO-L476RG，選取並 Next 設置 Project Name，其他不動，Next Copy only the necessary library files，Finish ioc 專案會有個 .ioc 檔，可以透過 GUI 生成設定 pin 的程式碼\n建議 Project Manager 的 Code Generator 勾選 Generate peripheral initialization as a pair \u0026lsquo;.c/.h\u0026rsquo; files per peripheral，開發起來比較方便\nCompile 點選上面的 hammer\nClock Configuration ioc 那邊還可以設置 clock\nExternal clock LSE 和 HSE 是 (Low / High Speed External)，你有 oscillator 的話可以自己弄\n你可以調 sysclk 或 peripheral clock\nProgramming 在 USER CODE section 寫上程式碼 這是由於生成程式碼的機制所致\n選取的部分可以按 F3，看他是從哪邊來的，或看 macro 之類的\n按下 alt + / 會出現自動補全的提示\nDEBUG 上面有個 BUG 符號的東西，旁邊的箭頭可以用 DEBUG 的設定\n又建 STM32 C/C++ Application，可以 New 新設定\nC/C++ Application 那邊選你 compile 的 elf 檔\nDebugger 開啟 ST-LINK S/N，並且掃描，如果你的電腦有接上 MCU，應該會直接找到\n","date":"2023-04-02T00:32:54+08:00","permalink":"https://roykesydon.github.io/Blog/p/stm32cubeide-%E5%9F%BA%E6%9C%AC%E9%96%8B%E7%99%BC%E4%BD%BF%E7%94%A8/","title":"STM32CubeIDE 基本開發使用"},{"content":"paper: GIT: A Generative Image-to-text Transformer for Vision and Language\n1 2 3 4 5 6 ██████╗ ██╗████████╗ ██╔════╝ ██║╚══██╔══╝ ██║ ███╗██║ ██║ ██║ ██║██║ ██║ ╚██████╔╝██║ ██║ ╚═════╝ ╚═╝ ╚═╝ Abstract 設計了一個 Generative Image-to-text Transformer，統一 vision-language tasks，像是 image/video captioning 或是問答。\n雖然 generative models 在預訓練和微調的時候是同樣的網路架構，現有的工作通常都包含複雜的架構 (uni/multi-modal encoder/decoder)， 而且依賴於外部模組，比如物件偵測或 optical character recognition (OCR)。\n在 GIT，我們簡化為 single language modeling task 下的一個 image encoder 和一個 text decoder。\n擴大了預訓練資料和模型大小以提高模型性能。\n在許多具有挑戰性的 benchmarks 上取得 SOTA。\n比如首次在 TextCpas 上超越人類的表現。\n提出了一種 generation-based image classification and scene text recognition 的新方案。\nIntroduction 近年來在 vision-language（VL）預訓練方面取得了巨大進展，特別是基於 image-text pairs 的大規模數據，例如 CLIP、Florence 和 SimVLM。\n學習到的 representation 很好的提高了下游任務的性能，比如 image captioning、visual question answering 和 image-text retrieval。\n在預訓練過程中，Masked Language Modeling (MLM) 和 Image-Text Matching (ITM) 被廣泛使用。\n然而這些 loss 和下游任務不同，必須做 task-specific adaptation。\n比如， image captioning 要移除 ITM，VQA 需要額外隨機初始的 MLP。\n為了減少這種差異，最近的研究試圖為預訓練模型設計 unified generative models 來預訓練，因為大多數 VL 的問題可以轉化為生成問題。\n這些方法通常利用 multi-modal encoder 和 text decoder，並精心設計 text input 和 text target。\n為了進一步推動這方向的研究，作者設計了一個簡單的 Generative Image-to-text Transformer，稱作 GIT，只包含一個 image encoder 和 text decoder。\n預訓練任務只是把輸入的圖像映射到相關聯的文字描述。\n盡管他很簡單，但還是在眾多具有挑戰性的 benchmark 取得 SOTA。\nimage encoder 是 Swin-like vision transformer，在大量的 image-text pairs 上做 pretrain，基於 contrastive task。\n這消除了現有許多方法中對 object detector 的依賴。\n為了將其擴展到影片領域，我們把多個 frame 的特徵 concatenate，作為 video 表示。\ntext decoder 是一個用來預測相關聯文字的 transformer。\n整個網路都是基於 language modeling task 來訓練。\n對於 VQA，input question 被看作 text prefix，並以 auto-regressive 的方法生出答案。\n此外，作者提出了一種 generation-based 的 ImageNet classification 新方案，預測標籤直接根據作者的生成模型，而不用預先定義詞彙表。\n我們的作法很簡單，但在擴大預訓練資料和模型大小後，成果驚人。\n主要貢獻如下：\n我們展示了 GIT，僅由一個 image encoder 和一個 text decoder 組成，透過 language modeling task，在 0.8 billion image-text pairs 上 pretrain。\n在 image/video captioning 和 QA 上，沒有基於 object detectors，object tags 和 OCR，就在多個任務上取得 SOTA。證明簡單的網路架構也可以透過 scaling 取得強大的性能。\n我們證明 GIT 雖然 pretrain 在 image-text pairs，也能在 video tasks 上取得 SOTA，不需要 video dedicated encoders。\n我們提出了一種新的 generation-based image classification 方案，在 ImageNet-1K 上，取得不錯的性能。\nRelated Work 在 VL pre-training 中，多 multi-task pre-training 被廣泛使用，賦予網路多種或增強的能力。\n比如，MLM 和 ITM 是廣泛採用的預訓練任務，最近也有研究加入 image-text contrastive loss。\n由於多數 VL 任務都可以表示成 text generation task，所以可以訓練一個生成模型來支持各種下游任務。\n輸入和輸出文本通常都會經過精心設計，以預訓練這樣的生成模型。\n對於 image representation，Faster RCNN 被大多數現有方法用來提取區域特徵。\n同時，也很容易以 end-to-end 的方法訓練整個網路。\n除了 feature map，object tags，也很常被用來方便 transformer 理解上下文，特別是 novel objects。\n對於與場景文本相關的任務，調用 OCR 以生成場景文本作為附加網路輸入。\n對於 text prediction，常用 transformer network，結合 cross-attention module 來融合 image tokens。\n或者只是單純 concatenate text tokens 和 image tokens，然後用 self-attention。\n在本文中，我們有 9 個不同的 benchmark，3 種不同模型大小和 3 種不同預訓練資料規模。\nGenerative Image-to-text Transformer Network Architecture image encoder 基於 contrastive pre-trained model。\n輸入是原始圖像，輸出是 compact 2D feature map，被 flatten 成 list of features。\n透過一個額外的 linear layer 和一個 layernorm layer，image features 被 project 到 D dimensions，也就是 text encoder 的 input。\n作者使用做 contrastive tasks pretraining 的 image encoder，因為最近的研究表明這種 image encoder 有更好的性能。\n在後面的章節，還觀察到 VL performence 明顯地隨著更強的 image encoder 而有所提升。 這和 object detection-based 的方法觀察到的結果一致。\nCoCa 的 concurrent work 統一了 contrastive task 和 the generation task，作為一個預訓練階段。\n作者的方法相當於是按順序分離兩個任務:\n用 contrastive task 訓練 image encoder 用 generation task pretrain image encoder 和 text decoder text decoder 是一個用於預測文本描述的 transformer module，由多個 transformer block 組成，每個 transformer block 由一個 self-attention layer 和 feed-forward layer 組成。\ntext 被 tokenize 和 embed 到 D dimensions，並添加 positional encoding 和 layernorm layer。\nimage features 和 text embeddings 被 concatenate 起來作為 transformer module 的輸入。\ntext 以 [BOS] 開始，並以 auto regressive 的方式 decode，直到 [EOS] 或 maximum steps。\nattention mask 根據上圖設計，使的 text token 只能依賴於前面的 text token 和 image token，而 image token 可以互相做 attention。\n這和 unidirectional attention mask 不同，unidirectional attention mask 並非每個 image token 都可以依賴於其他的 Image token。\n作者很好地初始化 image encoder，卻隨機初始化 text decoder。\n這種設計動機是基於[MiniVLM: A Smaller and Faster Vision-Language Model]，該研究隨機初始化顯示出與 BERT 初始化相似地性能。\n原因可能在於 BERT 地初始化無法理解圖像信號，這對於 VL 任務至關重要。\n[Flamingo: a Visual Language Model for Few-Shot Learning] 採用了類似的 image encoder + text decoder，但是他們的 decoder 經過 pretrain，並且有 freeze，好保留大型語言模型的泛化能力。\nGIT 的所有參數都會更新，以更好地適應 VL 的任務。\n另一種架構是 cross-attention-based 的 decoder，用於 incorporate image signals，而不是 concatenation 再用 self-attention。\n根據實驗，large-scale 的 pre-training，self-attention-based 會有更好的性能，小規模的則是 cross-attention-based。\n一個合理的解釋是，經過充分訓練，decoder 可以很好地處理圖像和文本，而且 image token 可以為了 text generation 更好地更新。\n而 cross-attention 讓 image token 沒辦法 attend 彼此。\nPre-training 訓練採用 language modeling (LM) loss。\n$I$ 是 image $y_i,i \\in $ { $ 1,\u0026hellip;,N $ } 是文字 token，$y_0$ 是 [BOS]，$y_{N+1}$ 是 [EOS] CE 是有 0.1 label smoothing 的 cross-entropy 另一種選擇是 MLM，在每個 epoch 中預測 15% 的輸入 token，要預測所有 token 至少需要 1 / 0.15 = 6.7 個 epochs，對於 LM，每個 epoch 都可以預測所有 token，對於大規模預訓練資料來說效率更高。\nablation studies 顯示出 LM 可以在有限的 epoch 內實現更好的性能。 在大規模訓練中，由於計算資訊的限制，只有兩個 epoch，所以選擇 LM。 與此同時，大部分最近的 large-scale language model 也是基於 LM。\n如果沒有圖像輸入，該模型將簡化為 decoder-only 的語言模型，架構類似於 GPT-3。\n因此，這種設計還可以利用 text-only 的資料來提升 scaled-up decoder 的能力，把這保留給未來的工作。\nFine-tuning 對於 image captioning，由於訓練數據格式和預訓練相同，所以用同樣的 LM task 來微調 GIT。 對於 visual question answering，問題和 GT 在微調的時候被看做 special caption，但 LM loss 僅用於答案和 [EOS]。\n推理過程中，question 被當作 caption 的 prefix，完成的部分是預測。\nVQAv2 現有的工作收集候選答案，再重構成分類問題，預測一次。 作者的工作有更多挑戰，因為是生成式的，需要生出至少兩個正確的 token，答案和 [EOS]。\n然而考慮到自由形式答案的好處，作者選擇了生成方法。\n由於生成模型的難度，VQAv2 比現有的判別工作略差。\n對於和 scene-text related VQA 任務，現有方法通常利用 OCR 生成 5 個 scene text 並用 dynamic pointer network 決定當前輸出應該是 OCR 還是 general text。\n但由於作者的方法不依賴於 OCR，因此也不依賴於 dynamic pointer network。\n根據實驗，作者發現模型透過大規模預訓練資料學會如何閱讀場景文本，並且作者的模型不是專門為了影片領域設計的，但可以透過簡單的架構更改就取得具有競爭力或甚至 SOTA 的成果，也就是作者可以從每個影片採樣多個 frame，並透過 image encoder 獨立地為每個 frame 編碼。 最後添加一個 learnable temporal embedding (初始化為 0)，並 concatenate sampled frames 的特徵。\n作者還用於圖片分類，把 class name 用於 caption。\n這和現有工作不一樣，現有工作通常先定義詞彙表，並用線性層預測每個類別的可能性。\n當新數據和新類別被添加到現有數據的時候，這種新一代的方案是有益的，因為這樣可以在不引入新參數的情況下對新數據進行訓練。\nExperiments Setting 收集 0.8B 的 image-text pairs 來預訓練。\nimage encoder 是根據 pre-trained contrastive model 初始化的。\nhidden dimension (D) = 768\ntext decoder 有 6 個 randomly-initialized transformer blocks\n共有 0.7b 的參數\nimage decoder 和 text encoder 的 learning rate 各別是 1e-5 和 5e-5，都 cosine decay 到 0\n推論階段 beam size 是 4，length penalty 是 0.6。\nSupplementary materials 展示了小模型變體 (GITB and GITL) 和更大模型 (GIT2) 的結果\nResults on Image Classification 輸出必須與類別名稱完全匹配，甚至考慮多或少的空格。\n由於不知道詞彙表，精確匹被準確度只有 1.93%，如果預測包含 GT 就對，那有 40.88%。\n通過微調每個類別只有 1 shot 或 5 shot，準確度會顯著提高， 表明只用少量訓練樣本，也可以輕鬆適應下游任務。\n與 Flamingo 相比，GIT 實現更高的準確度。\nFlamingo 在沒有參數更新的情況下進行小樣本學習，但需要額外的網路輸入，可能會增加推理成本。\n相比之下，GIT 透過一次 lightweight fine-tuning，推理過程中不需要這些 training shot。\nAnalysis Model and data scaling 對於網路架構，作者的模型被稱作 Huge，把 image encoder 換成 CLIP 的 ViT-B/16 和 ViT-L/14 的則是 Base 和 Large。\n可以看出較大的 image encoder 帶來的好處，但根據實驗， 作者發現很難有效地擴展 text decoder，原因可能是 LM 很難用 limited amount of text 來訓練。\n另一個可能的原因是 image encoder 負責 object recognition，而 decoder 負責以 NLP 的方法組織 object terms。 後一項任務可能很容易，因為大多數描述都遵循相似的模式，比如 Object + verb + subject，所以只要一個 small decoder，較大的 decoder 可能會增加學習難度。\nFlamingo 的研究顯示更大的 Decoder 可以提高性能，但是他們的 decoder 有 pretrain 過，而且在 VL 預訓練的時候 frozen，避開了如何有效訓練 decoder 的問題。\nLEMON 的 transformer 可以擴展到 32 層，可能是因為他們使用 MLM 而不是 LM，後者可能更加困難。\nScene text in pre-training data 為了瞭解 scene text comprehension 的能力，作者檢查了 pretrain data 有多少 image-text pairs 有 scene text。\n作者用 Microsoft Azure OCR API4 對一些資料做 OCR，然後把 OCR 結果和 associated text 做比對，只有包含長度超過 5 個字元的 OCR 結果才會算比對。 有 15% 的 CC12M 和 31% 的下載圖像(500K) 包含 scene text 描述。 由於任務是訓練預測 text，網路逐漸學會閱讀 scene text。\nConclusion Limitations 根據實驗，目前不清楚如何控制生成的 caption 以及如何在不更新參數的情況下執行 in-context learning，把這留給未來的工作。\nSocietal impact 該模型在大規模數據集上預訓練，不能保證數據不含 toxic language，可能會 poison output。\n其他 A.3 Network 講超參數\n","date":"2023-03-29T01:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/git-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"GIT 論文閱讀"},{"content":"paper: RoBERTa: A Robustly Optimized BERT Pretraining Approach\n1 2 3 4 5 6 ██████╗ ██████╗ ██████╗ ███████╗██████╗ ████████╗ █████╗ ██╔══██╗██╔═══██╗██╔══██╗██╔════╝██╔══██╗╚══██╔══╝██╔══██╗ ██████╔╝██║ ██║██████╔╝█████╗ ██████╔╝ ██║ ███████║ ██╔══██╗██║ ██║██╔══██╗██╔══╝ ██╔══██╗ ██║ ██╔══██║ ██║ ██║╚██████╔╝██████╔╝███████╗██║ ██║ ██║ ██║ ██║ ╚═╝ ╚═╝ ╚═════╝ ╚═════╝ ╚══════╝╚═╝ ╚═╝ ╚═╝ ╚═╝ ╚═╝ Abstract 發現 BERT 訓練不足，並且作者的模型在 4/9 的 GLUE 任務, RACE 和 SQuAD 取得 SOTA。\nIntroduction 自監督的訓練方法帶來了顯著的性能提升，但要確定這一堆方法中的哪些方面貢獻最大，具備挑戰性。\n訓練的計算量是昂貴的，使 fine-tune 受限，而且通常都是用不同大小的 private training data，使評估模型更加困難。\n作者提出了對 BERT 預訓練的 replication study，包括對超參數的調整，以及對訓練集大小的仔細評估。\n作者發現 BERT 訓練不足，並提出了一種改進方法，稱為 RoBERTa，可以達到或超過所有 post-BERT 的方法。\n修改如下:\n訓練模型的時間更長，batch 更大，用更多 data 移除 next sentence prediction objective 訓練更長的序列 動態地改變用於訓練資料的 masking pattern 貢獻:\n提出一組重要的 BERT 設計選擇和訓練策略 使用了新的 dataset，叫做 CCNEWS，並證明用更多的資料來預訓練，可以提高下游任務的表現 訓練表明，在正確的設計選擇下，pretrained masked language model 和其他最近的方法比，具有競爭力 Background 對 BERT 做回顧\nArchitecture L layers A self-attention heads H hidden dimension Training Objectives 預訓練的時候，BERT 有兩個目標: masked language modeling 和 next sentence prediction\nMasked Language Model (MLM) BERT 隨機選擇 15% 的 token 進行可能的替換\n80% 換成 [MASK]，10% 保持不變，10% 被選為一個隨便的 vocabulary token\nNext Sentence Prediction (NSP) 分類第二句是不是下一句，是二元分類。\n正例由提取連續的句子產生，負例由不同的片段配對產生。\n正例和負例以相等機率產生。\nOptimization Adam $\\beta_1$ = 0.9, $\\beta_2$ = 0.999, $\\epsilon$ = 1e-6 $L_2$ weight decay of 0.01 Learning rate 前 10,000 step warm up 到 1e-4，然後 linear decay 全部的 layer 和 attention weight 都 dropout 0.1 GELU 激活函數 1,000,000 次 update，batch size 256，序列長度 512 Data BERT 在 BookCorpus 和 English Wikipedia 混和的資料集上訓練，共有 16GB 的未壓縮文本\nExperimental Setup 描述對於 BERT 的 replication study 的實驗設置\nImplementation 作者用 FAIRSEQ 重新實現了 BERT。\n主要遵循 [Background-Optimization] 中的 BERT 原始超參數，但 peak learning rate 和 warmup step 除外，他們針對每個設置單獨調整。\n作者發現訓練對 Adam epsilon 非常敏感。\n作者發現設置 $\\beta_2$ = 0.98，在大 batch size 的情況下，可以提高訓練時的穩定性。\n用最多 512 個 token 預訓練。\n作者不會隨機注入短序列，也不會為前 90% 的更新縮短輸入的長度。\n作者只訓練 full-length 的 sequences。\nData BERT-style 的預訓練仰賴大量文本。\n已有研究證明增加數據量可以提高 end-task 的性能。\n已有一些研究，用比原始 BERT 更多樣更大的數據集，但不是所有的數據集都有公開。\n本研究用了五個不同大小和領域的英文文本，共有超過 160 GB 的未壓縮文本。\n使用以下數據集:\nBookCorpus + English Wikipedia BERT 原本使用的。 16 GB CC-News 作者從 CommonCrawl News dataset 的英文部分中蒐集，包含了 2016 年 9 月到 2019 年 2 月的 6300 萬篇英文新聞。 過濾後有 76 GB OpenWebText WebText 的開源重建版，從 Reddit 上至少有 3 個 upvotes 的 shared URLs 提取出的 Web 內容。 38 GB Stories 包含 CommonCrawl data 的一個子集合，經過過濾，以匹配 story-like style of Winograd schemas 31 GB Evaluation 使用以下三個 benchmarks 評估預訓練模型\nGLUE The General Language Understanding Evaluation\n用於評估自然語言理解的 9 個數據集的集合，任務被定義為 single-sentence 分類或 sentence-pair 分類任務。\nfinetune 的流程遵循原始 BERT paper\nSQuAD The Stanford Question Answering Dataset\n提供一段 context 以及一個問題\n具有兩個版本 V1.1 和 V2.0\nV1.1 context 總是包含一個答案 評估 V1.1 的時候，作者採用和 BERT 相同的 span prediction method V2.0 一些問題在提供的 context 中沒有回答，使任務更有挑戰性 評估 V2.0 的時候，作者會用一個額外的二元分類器預測問題是否可以回答，在評估的時候，只預測被分類為可回答的 RACE The ReAding Comprehension from Examinations 大型閱讀理解數據集，有超過 28,000 篇文章 以及將近 100,000 個問題 從中國的英文考試蒐集的，這些考試是為國中生和高中生設計的 每篇文章都與多個問題相關聯 對每個問題，要從四個選項中選出一個對的 context 比起其他閱讀理解的數據集要長，而且要推理的問題比例很大 Training Procedure Analysis 探討哪些選擇對成功預訓練 BERT 很重要。\n作者把架構固定，也就是訓練和$BERT_{BASE}$ (L=12, H=768, A=12, 110M params)一樣架構的 BERT models\nStatic vs. Dynamic Masking BERT 在 preprocessing 的時候處理 masking，產生單個 static mask。 作者為了避免在每個 epoch 都對每個 instance 用相同的 mask，將數據複製了 10 次，在 40 個 epochs 裡，以 10 種不同的方式 mask。所以一次訓練過程中，相同的 mask 會出現四次。\n作者會以上述策略和 Dynamic masking 進行比較，Dynamic masking 是在每次餵 model 前，才生成 mask。\n作者發現 Dynamic Masking 相比 static，要不是差不多，就是略好，基於結果和效率的優勢考量，其他實驗中都用 dynamic masking。\nModel Input Format and Next Sentence Prediction 原始的 BERT 預訓練中，兩個句子要不是同一個文件的連續句子(p = 0.5)，不然就是不同的 document 做採樣\n以往有研究指出移除 NSP 會損害性能，但也有研究質疑必要性，所以本文比較了幾種替代訓練格式：\nSEGMENT-PAIR+NSP 最原始的方法，每個 segment 可以有多個自然句子 SENTENCE-PAIR+NSP 只包含一對句子，由於輸入明顯少於 512 token，所以會增加 batch size 讓 token 總數和前者差不多 FULL-SENTENCES 包含從一個或多個文件中連續採樣的完整句子，可能會跨越文件邊界，在文件邊界間會加個額外的分隔符 移除了 NSP DOC-SENTENCES 和 FULL-SENTENCES 差不多，但不能跨越 document，在 document 尾巴的部分會容易少於 512，所以會動態增加 batch size，讓 token 總數和 FULL-SENTENCES 差不多 移除了 NSP 發現 DOC-SENTENCES 是最棒的，但由於 DOC-SENTENCES 會讓 batch sizes 大小可變，所以其他實驗會用 FULL-SENTENCES，比較好和其他相關工作比較。\nTraining with large batches 根據過去神經網路機器翻譯的工作，當 learning rate 適當增加的時候，用非常大的的 mini-bathces 可以提高 optimization 的速度和 end-task 性能。\n最近的研究也顯示 BERT 適用於 large batch training。\nText Encoding Byte-Pair Encoding (BPE) 是一種介於字符級別和詞級別表示之間的混合表示方法，它允許處理自然語言語料庫中常見的大詞彙量。\nBPE 不依賴於完整的單詞，而是依靠 subwords units，通過對訓練語料進行統計分析來提取這些 subwords units。\nBPE 詞彙表的大小通常在 10K-100K 的 subword units。\n在 \u0026ldquo;Language Models are Unsupervised Multitask Learners\u0026rdquo; 文中，提到了一種巧妙的 BPE 實現，不是用 unicode characters，而是用 bytes 作為 base subword units。可以生出 50K 大小的詞彙表，而且不用引入任何的 \u0026ldquo;unknown\u0026rdquo;。\n原始的 BERT 用 character-level BPE vocabulary，大小為 30K。\n本文考慮用 50K byte-level BPE vocabulary，而不對輸入做額外的 preprocessing 或 tokenization，\u0026ldquo;Language Models are Unsupervised Multitask Learners\u0026rdquo; 的研究顯示這些 Encoding 的方法在最終效能上並無太大差別，只在某些任務上 end-task performance 表現稍差。\n但作者相信 universal encoding scheme 的優勢超過了輕微的性能下降，其他實驗也會用這種邊碼方式。\nRoBERTa 整理上面說的改進。\nRoBERTa 用以下配置:\ndynamic masking FULL-SENTENCES without NSP loss large mini-batches larger byte-level BPE 此外，還調查了兩個之前的工作沒強調的重要因素:\n用於預訓練的 data 訓練過 data 的次數 為了把這些因素的重要性和其他模型選擇分隔開，先按照 $BERT_{LARGE}$ (L = 24, H = 1024, A = 16, 355M parameters) 訓練 RoBERTa。\n作者在 BOOKCORPUS plus WIKIPEDIA dataset 進行了 100K step 的預訓練。\n在控制 training data 的情況下， RoBERTa 比 $BERT_{LARGE}$ 的結果有大幅度的改進，重申了前面設計選擇的重要性。\n接下來，結合之前說的額外 dataset，並用相同的步數(100K) 訓練 RoBERTa，觀察到下游任務的性能進一步提高，驗證了數據大小和多樣性的重要性。\n最後，對 RoBERTa 做更長時間的預訓練，將步數提高到 300K 和 500K，再次觀察到下游任務性能顯著提升。\n作者也注意到，即使是他們訓練時間最長的模型，也不會 overfit 他們的數據。\n本文的其他部分在三個 benchmark 評估好壞: GLUE、SQuaD 和 RACE\nGLUE Results 雖然很多 GLUE 排行榜的提交都是 depend on multi-task finetuning，但作者的 submission 是 depends only on single-task finetuning。\n此外，對於 RTE、STS 和 MRPC，從 MNLI 的模型微調會比 baseline 的 RoBERTa 有幫助許多。\n在第一個設置 (single-task, dev) 中，RoBERTa 在所有 9 個 GLUE 任務 dev set 上都取得了最先進的結果。\n在第二個設置 (ensembles, test) 中，作者將 RoBERTa 提交到 GLUE 排行榜，並在 9 個任務中的 4 個上取得了 SOTA 和迄今為止的最高平均分。\n這令人興奮的地方在於，與多數 top submissions 不同，RoBERTa 不是 depend on multi-tasking finetuning\nConclusion 在預訓練 BERT 模型時，作者仔細評估了許多設計決策。\n作者發現，通過對模型進行更長時間的訓練、使用更大的批次處理更多的數據、去除 NSP、訓練更長的序列、dynamic masking，可以顯著提高性能。\n作者改進的預訓練程序，我們稱之為 RoBERTa，在 GLUE、RACE 和 SQuAD 上實現了 SOTA，而無需為 GLUE 進行多任務微調或為 SQuAD 提供額外的數據。\n這些結果說明了這些以前被忽視的設計決策的重要性，並表明 BERT 的預訓練目標與最近提出的替代方案相比仍然具有競爭力。\n","date":"2023-03-22T01:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/roberta-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"RoBERTa 論文閱讀"},{"content":"開發環境 IDE SW4STM32 支援 STM32 GCC C/C++ compiler GDB-based debugger 板子 STM32 Bucleo Board Cortex-M4 ST-LINK debugger Memories 1MB Flash 128KB SRAM Debug Interface JTAG Joint Test Action Group standard ASICs hardware debug interface SWD Serial Wire Debug 只從 JTAG 用 5 wires Bootup Code Reset\nBoot Loader\n0x00000000 的程式 把 CPU 重置 Reset handler\nStstem initialization C startup code\nApplication(main)\nMemory map 見官網 memory map\n只用到 SRAM 的 128KB(SRAM)，還有 Code 的 1MB(Flash)\nSections .data 儲存資料 .text 儲存程式碼 同 section 會放在一塊是為了設定 read-only 方便，比如 .text 的要靠硬體實現 read-only\n重要的額外文件 Linker Script 定義了不同 section 該存放的地方，以及 memory 相關定義 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 MEMORY { RAM (xrw)\t: ORIGIN = 0x20000000, LENGTH = 96K ROM (rx)\t: ORIGIN = 0x8000000, LENGTH = 1024K } SECTIONS { /* The program code and other data into ROM memory */ .text : { . = ALIGN(8); *(.text) /* .text sections (code) */ *(.text*) /* .text* sections (code) */ *(.glue_7) /* glue arm to thumb code */ *(.glue_7t) /* glue thumb to arm code */ *(.eh_frame) KEEP (*(.init)) KEEP (*(.fini)) . = ALIGN(8); _etext = .; /* define a global symbols at end of code */ } \u0026gt;ROM .data : { . = ALIGN(8); _sdata = .; /* create a global symbol at data start */ *(.data) /* .data sections */ *(.data*) /* .data* sections */ . = ALIGN(8); _edata = .; /* define a global symbol at data end */ } \u0026gt;RAM AT\u0026gt; ROM } Make File 描述如何編譯和連接的規則 把 startup 的 .s檔加進去 startup_stm32.s 編譯好後擺在 binary 頭的地方\nvector table\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 /****************************************************************************** * * The STM32L476RGTx vector table. Note that the proper constructs * must be placed on this to ensure that it ends up at physical address * 0x0000.0000. * ******************************************************************************/ .section .isr_vector,\u0026#34;a\u0026#34;,%progbits .type g_pfnVectors, %object .size g_pfnVectors, .-g_pfnVectors g_pfnVectors: .word _estack .word Reset_Handler .word NMI_Handler .word HardFault_Handler .word\tMemManage_Handler .word\tBusFault_Handler .word\tUsageFault_Handler .word\t0 .word\t0 .word\t0 .word\t0 .word\tSVC_Handler Reset_Handler 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 Reset_Handler: ldr r0, =_estack mov sp, r0 /* set stack pointer */ /* Copy the data segment initializers from flash to SRAM */ ldr r0, =_sdata ldr r1, =_edata ldr r2, =_sidata movs r3, #0 b LoopCopyDataInit LoopCopyDataInit: adds r4, r0, r3 cmp r4, r1 bcc CopyDataInit /* Zero fill the bss segment. */ ldr r2, =_sbss ldr r4, =_ebss movs r3, #0 b LoopFillZerobss LoopFillZerobss: cmp r2, r4 bcc FillZerobss /* Call the clock system intitialization function.*/ bl SystemInit /* Call static constructors */ bl __libc_init_array /* Call the application\u0026#39;s entry point.*/ bl main ARM Register ARM 的可存取暫存器為 R0-R15\nr13: Stack Pointer r14: Link Register r15: Program Counter r0~r7 是 low register r8~r15 是 high register 狀態暫存器\nCPSR (Current Processor Status Register) 用來儲存各種狀態，包含 condition flag，比如 negative, zero, carry, overflow carry: 無符號加法操作是否溢出 overflow: 有符號加法操作是否溢出 當兩個都為 1 或都為 0 代表運算沒問題 有多種模式，有些模式有自己獨立的 r 暫存器，並有 SPSR，用來在中斷發生時，把 CPSR 的資訊 copy 過去\nSpecial-purpose registers\nAPSR, IPSR, EPSR Assembly syntax UAL: Unified Assembler Language 自己去翻 instruction set Instructions class Branch instructions B, BL, BX,\u0026hellip; Data-processing instructions MOV, ADD, SUB, MUL,\u0026hellip; Load and store instructions LDR, STR,\u0026hellip; Status register access instructions MSR, MRS,\u0026hellip; Miscellaneous instructions Memory Barrier instructions Exception-Related instructions Pseudo instructions examples MOVS R0, #0x12\nR0=0x12 MOVS R1, #`A` R1=A(ASCII) NVIC_IRQ_SETEN EQU 0xE000E100\n宣告常數 NVIC_IRQ_SETEN，賦值 0xE000E100 LDR R0,=NVIC_IRQ_SETEN\n放 0xE000E100 進 R0 這不能改成 MOVS R0, #0xE000E100 ，因為每個 instruction 只有 32 個 bits，這勢必塞不下，必須從記憶體 load 進來 NVIC_IRQ0_ENABLE EQU 0x1\n宣告常數 NVIC_IRQ0_ENABLE，賦值 0x1 MOVS R1, #NVIC_IRQ0_ENABLE\nR1=0x1 STR R1, [R0]\n把 0x1 存到 0xE000E100，這裡可以 enable external interrupt IRQ#0 LDR rn [pc, #offset to literal pool]\nload register n with one word from the address [pc + offset] 最後的形式 Operand2 共有 12 bits 設計成 4 bits for rotate, 8 bits for Immediate ARM instrcution formats ADD vs ADDS 有 S 代表會去更新 status cond 根據之前的執行情況，判斷指令要不要執行 suffix Reverse Ordering Operations REV (Byte-Reverse Word) 把 4 個 Byte 全數反轉，用在一個是 Little-Endian 一個是 Big-Endian 的情況 Load and Store Instructions examples LDR r0, [r1] r0 = [r1] LDM r0, {r1, r2} r1 = [r0] r2 = [r0+4] STM r0, {r1, r2} [r0] = r1 [r0+4] = r2 Status Register Access Instructions 一般來說不太會用到，因為用 suffix 就可以看條件 MRS: Register = Status Register MRS r0, IPSR MSR: Status Register = Register MSR APSR, r0 If-Then-Else 用 CMP 和 conditional branches Example 1 2 CMP R0, #10 ;compare r0 to 10 BLE incr_counter ; if less or equal, then branch to incr_counter Branch Instructinos 能跳的距離受限於 operand 長度\nB-Branch 能跳 PC 的 +/- 2046 bytes BL-Branch and Link 能跳 PC 的 +/- 254 bytes Branch to subroutine 的時候，會把下一行指令放到 Link register 沒有 push 到 stack，所以要特別小心，register 是共用的， 可能要視情況自己放到 stack 比如要進兩層 function，可以用 push {r4-r6, LR} 和 POP {R4-R6, PC} 這種做法來保留參數 BX-Branch and exchange return Stack memory access PUSH\nSP = SP - N*4 POP\nSP = SP + N*4 Ascending/Descending\nstack 往哪個方向長 Empty/Full\nstack 指向下一個空的位置，還是最後一個 item 預設且常見的是 fully descending\nSTM 和 LDM 可以透過 suffix 來存到 stack\nexample STMFD r13!, {r4-r7} 把 r4 到 r7 push 到 stack Memory Barrier Instructions DMB, SDB, ISB 在下個指令前 sync memory data Function Call and Parameter Passing caller 和 callee 誰負責 backup 和 restore caller 負責 不管 callee 怎樣亂搞都行 但不知道 callee 要用哪些參數，全 backup 可能多此一舉 怎麼傳遞參數給 callee 常放在 stack，但這樣要透過 memory，相較 register 慢 怎麼 return value 給 caller 和上個問題差不多 ARM Procedure Call Standard 又稱 APCS，講不同的 register 的一種使用規範\nr0-r3 用來當參數和回傳 r4-r11 用來 local variable，callee 使用前可以先 backup r12-r15 特殊用途，沒事別亂動 ","date":"2023-03-21T01:32:54+08:00","permalink":"https://roykesydon.github.io/Blog/p/arm-%E7%B5%84%E5%90%88%E8%AA%9E%E8%A8%80%E4%BB%8B%E7%B4%B9/","title":"ARM 組合語言介紹"},{"content":"paper: PatentSBERTa: A Deep NLP based Hybrid Model for Patent Distance and Classification using Augmented SBERT\nAbstract 本研究提供了一個計算 patent-to-patent (p2p) technological similarity 的有效方法。\n並提出一個 hybrid framework，用於把 p2p 相似性的結果應用於 semantic search 和 automated patent classification。\n把 Sentence-BERT (SBERT) 用在 claims 上來作 embeddings。\n為了進一步提升 embedding 的品質，使用基於 SBERT 和 RoBERT 的 transformer model，然後再用 augmented approach 在 in-domain supervised patent claims data(相對於 out-domain) 來 fine-tune SBERT。\n用 KNN(Nearest Neighbors) 來根據 p2p similarity 分類模型。\nIntroduction 傳統上的 p2p 相似度是基於關鍵字、技術類別等 metadata 決定的，但近期 semantic-based 的方法也越來越受歡迎。\n目前遇到的問題 BERT 用來計算 p2p 相似性的成本很高 基於 generic text 的 pre-trained model 在遇到特定領域的專業術語時可能會遇到侷限。 在專利做 multi-label classification (MLC) 是個挑戰 貢獻 提供一個快速高效的框架，利用 Transformer 架構計算 p2p 相似度 透過 augmented SBERT，將 transformer model fine-tune 到 domain-specific language 提出一個基於 Transformer 和 傳統 ML 模型的混和架構，可以打敗 multi-label 和 multi-class 的專利分類 SOTA 模型 用簡單的 KNN 進行專利分類，提供了一種簡單的方法來檢查、理解和解釋模型的預測結果 Data Dataset Description 本研究使用 PatentsView dataset，PatentsView 平台建立在一個定期更新的 database 上。\ndataset 已用於之前類似的研究，比如 DeepPatent、PatentBERT。\n本研究使用了 2013-2017 的所有專利，這些專利至少要在 BigQuery 上有一條 claim。\n本研究的 record 有 1,492,294 項專利，並用 8% 作為測試集。\n此外，本研究刪除了有重複專利 ID 和 claim text 的 record。\nTextual Data: Patent Claims 本研究使用 claim 作為輸入。\nclaim 被認為是準備專利文件的初始框架，其他文件都是根據 claim 準備的， 因此，claim 比其他文件包含更全面和準確的訊息。\nclaim 具有層次結構，first claim 被視為該架構的主幹。\n本研究僅使用 first claim，但在以後的研究中，希望根據 tree structure 組合所有 claim，並計算 semantic similarity，並做多標籤分類。\n在研究樣本中， claim 平均有 17 個。\nclaim 的平均長度是 162，本研究中，BERT 的 max_seq_length 是 510。\nPatent Classification: CPC Classes CPC系統和IPC（國際專利分類）系統是最常用的兩種分類系統，CPC 是 IPC 系統的更具體和詳細的版本。\nCPC 具有用於分類的層次結構，包括 Section、Class、Subclass 和 Group， 在子類級別，CPC 有 667 個標籤。\n在數據集中我們有 663 個標籤，其中 159 個在數據集中的樣本少於 350 個，這種標籤分佈導致了 KNN 不好處理，一般來說，隨著 instance 數量的增加，我們可以提高模型的準確性。\nMethod and experimental setup Pretrained Language Models (LMs) 在 NLP 中變得十分流行。\n在 pairwise sentence semantic similarity，SBERT 和 BERT 是兩種具有顯著不同效果的方法。\nBERT 通常可以取得更好的性能，但在實際應用上來說太慢了。\nSBERT 在實際應用上表現還行，但需要 in-domain training data 並且 finetune。\n上圖是 Augmented SBERT In-domain approach。\nin-domain sentence pairs 透過 cross-encoder 來標記，假設有 n 個 in-domain sentences，會有 $C_2^n$ 組可能的組合。\n使用所有可能的組合並不會提高性能，所以要有正確的採樣策略，才可提升性能的同時也減少計算開銷。\n上圖那種結合 cross-encoder 和 bi-encoder 的作法被稱為 Augmented SBERT (AugSBERT)， 涉及以下三個步驟:\n用資料集 Fine-tune RoBERTa 以生出 cross-encoder 用 cross-encoder 來把未標記的資料標記，同時基於某種特定的採樣策略，從 652,653 種可能的組合中挑選 3432 組 把資料集 + 額外的 3432 組資料一起拿來訓練 SBERT Results P2P similarity and semantic search Patent Semantic Search (PSS) 是專利分析的基礎部分。\nTransformer 模型等語義相似性的解法是一種新解法，可以用來解決基於關鍵字的搜尋方法中， query terms 和專利內容不匹配的問題。\n為了評估模型的準確性，未來的研究中，作者希望通過 Mean Reciprocal Rank (MRR) 來評估分類結果。\nCPC Prediction Top-N 準確度等於 GT 與預測有最高概率的任何 N 個預測匹配的頻率， 所以 Top-5 就是最高的五個分類中一個就有中。\nConclusion 本文使用 augmented SBERT 獲得 SOTA 的專利文本 embedding。\n介紹了一種 augmented 的方法，把 SBERT 微調到適合 patent claims 的 domain。\nSBERT 的一個主要優點是可以有效率地獲得 embedding distance，使我們能夠為大的專利資料集建構 p2p similarity。\n雖然基於文本的 p2p similarity 的有用性已經在各種應用方面得到證明，但本文進一步證明作者的 transformer-based p2p similarity 可以被用在 SOTA 的專利分類。\n而且使用簡單的 KNN 方法，檢查他們可以使模型決策具備 understandable 和 explainable。\nLimitations \u0026amp; Future Research 未來希望用 Annoy(Approximate Nearest Neighbor Oh Yeah!) 來測試更大樣本的模型並比較結果。\nAnnoy(Approximate Nearest Neighbor Oh Yeah!) 是想尋找近似相似而不是精確相似的句子。\n","date":"2023-03-15T15:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/patentsberta-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"PatentSBERTa 論文閱讀"},{"content":"Normalization 目的 避免 redundent information 更容易 understand、enhance、extend 避免 anomalies 隨著 1NF ~ 5NF，有更多的 safety guarantee\n1NF 違反條件 用 row order 傳達資訊 mixing data types in single column 但 relational database 不會讓你這樣做 存在沒有 primary key 的 table repeating groups 同一個 column 有多個數值，或是在同一個 row 存多個同類型的數值。 ex : player item roy 1 item_1, 4 item_2 star 4 item_4 player item_type1 quantity1 item_type2 quantity2 roy item1 1 item2 4 star item_4 4 2NF 所有的 non-key attribute 都要 depend on 整個 PK 非正式定義，有點細微差異 functional dependency ex: {player_id, item_type} -\u0026gt; {item_Quantity} 3NF transitive dependency {A} -\u0026gt; {B} -\u0026gt; {C} 所有 non-key attribute 都要 depend on the whole key，不能 depend on 其他 non-key attribute Boyce-Codd Normal Form 所有 attribute 都要 depend on the whole key，不能 depend on 其他 non-key attribute 4NF multivalued dependency 不像 functional dependency，箭頭後方的那項可以有多個 value {Model} $\\twoheadrightarrow$ {Color} 一個 table 中的所有 multivalued dependency 必須依賴於 key 5NF 沒有 Join Dependency table 不能表示成其他 table join 起來的結果 ","date":"2023-03-14T10:26:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/database-normalization/","title":"Database Normalization"},{"content":"paper: Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks\nAbstract BERT 和 RoBERTa 在 semantic textual similarity (STS) 上太花時間，因為他需要將兩個句子都輸入網路，並且兩兩比對。\nSentence-BERT(SBERT) 對預訓練的 BERT 作了一些修改，透過 siamese 和 triplet network 的結構來生出有意義的 embeddings，使其最後可以透過 cosine-similarity 比較相似度。\nIntroduction SBERT 使 BERT 可以用於某些迄今為止不適用於 BERT 的任務，比如 large-scale semantic similarity comparison、clustering 還有 information retrieval via semantic search。\n以往的相關研究是把單個句子輸入 BERT，最後 average BERT output layer，或是使用第一個 output，但這樣會產生糟糕的 sentence embeddings。\nSentEval 是一個 evaluation toolkit for sentence embeddings\nRelated Work BERT 透過輸入兩個句子，以 [SEP] 隔開，可以在 STS 取得 SOTA。\n但這樣無法計算獨立的 sentence embedding，所以過往的研究人員把單個句子輸入 BERT，最後 average BERT output layer，或是使用第一個 output。\nModel SBERT 在 BERT / RoBERTa 的輸出中添加了 pooling，作者嘗試了三種策略，CLS-token 的輸出、所以輸出向量的平均、max-over-time of the output vectors，默認是 MEAN。\n實驗以下結構和目標函數:\nClassification Objective Function\nRegression Objective Function\n用 mean squared-error loss\nTriplet Objective Function\nTraining Details Dataset SNLI 結合 Multi-Genre NLI SNLI: 570,000 個 句子 pair，有三類，contradiction, eintailment, and neutral MultiNLI: 430,000 個句子 pair 3-way softmax Classification Objective Function 1-epoch batch-size: 16 Adam lr: 2e-5 warm-up: 超過 10% of the training data 默認 pooling 策略: MEAN Evaluation 學習一個複雜的回歸函數分析 STS 常是 SOTA，但是由於他是 pair-wise，遇到 combinatorial explosion，不好拓展。\n本文用 cosine-similarity 比較兩個 embeddings 的相似度，也用 negative Manhatten 和 negative Euclidean distances，但得到差不多的結果。\nConclusion 用 BERT 生出的 embeddings 不適合常見的相似度測量方法，比如 cosine-similarity。\n本文提出 SBERT 改進，在 siamese / triplet 網路架構中微調 BERT。\n用 RoBERTa 替換掉 BERT 並沒有什麼顯著改進。\n","date":"2023-03-12T10:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/sentence-bert-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"Sentence-BERT 論文閱讀"},{"content":"UML 類別圖 Relationship Dependency \u0026ldquo;uses-a\u0026rdquo; Association \u0026ldquo;knows-a\u0026rdquo; Composition \u0026ldquo;has-a\u0026rdquo; child 的存在依賴於 parent，若刪除 parent，child 也會隨之刪除 Aggregation \u0026ldquo;has-a\u0026rdquo; child 的存在獨立於 parent，若刪除 parent，child 不會隨之刪除 Inheritance \u0026ldquo;is-a\u0026rdquo; Implementation \u0026ldquo;can-do\u0026rdquo; 實現 interface other features Navigation 當兩個 class 都可以看到對方，就用沒箭頭的關聯線，否則有箭頭 Role Name 類別中的 Attribute Multiplicity 關聯端點上可以寫數量，代表物件個數 Self-Association 同個類別的物件彼此有關係 軟體設計原則 Encapsulate What Varies 把經常改變的程式碼封裝起來，使日後修改時不會影響其他區塊的程式碼 實際使用的情境，可以把常改變的東西放在 interface 後，使日後改變實作時不影響呼叫該 interface 的程式碼 Favor Composition over Inheritance Composition(組合)在很多情境可以取代掉 Inheritance(繼承)，甚至實現 Polymorphism(多型) 只有當 is-a 的情境出現，才用繼承比較好 Composition 使用起來更有彈性 SOLID 設計原則 Single Responsibility Principle, SRP 單一職責原則 A class should have only one reason to change. 可以把一個複雜的 module 拆成多個 Open-Close Principle, OCP 開放封閉原則 You should be able to extend the behavior of a system without having to modify that system. 要可以擴充，同時不修改到原系統 LiskovSubstitution Principle, LSP 里氏替換原則 父類別有的功能，子類別必須遵從，父類別的部分要可以直接替換成子類別 Interface Segregation Principle, ISP 介面隔離原則 No client should be forced to depend on methods it does not use 以 interface 來說，不該讓 module 實現它不需要的功能，可以把 interface 拆小 Dependency Inversion Principle, DIP 反向依賴原則 高階模組不應該依賴低階模組，兩者都應依賴抽象層 Modularity Coupling type Tight coupling Content coupling 一個模組依賴另一個模組的內部運作 ex: 一個模組直接存取另一個模組的變數，假設回傳的數值是公尺，如果另一個模組要修改成公分，就會影響到這個模組 可以用 getter 抽象出 getMeter()，這樣就不會直接存取變數 Common coupling 多個模組共同存取和修改同個 global data ex: 一個模組錯誤修改會導致其他人都壞掉 External coupling 多個模組直接存取同個 external I/O ex: API 要改就會全部都影響到 Medium coupling Control coupling 一個模組影響另一個模組的內部邏輯（比如說透過參數） ex: 參數要改個寫法就會影響一堆模組 Data-Sructure coupling 多個模組共同存取同個 data structure ex: Data structure 要改就會影響到其他模組 Loose coupling Data Coupling 兩個模組 share/pass 同樣的資料 Message Coupling 多個模組間透過 message 或是 command 來溝通 和 control coupling 的差別在於，並沒有去控制某個模組，只是叫他做某件事情 No Coupling 不是好的設計 模組間沒有關聯，或是有個超巨大的模組 Cohesion type Weak cohesion Coincidental cohesion 唯一的關聯是他們在同個檔案 ex: single file program Temporal cohesion 關聯的地方是他們在同個時間點被執行 ex: 「執行 shutdown 相關的活動」 Logical cohesion 活動間可以被歸類在同個 general category ex: Backup Controller，可能有很多地方需要 Backup Medium cohesion Procedureal cohesion command 間存在執行順序 ex: Clean car module 可能包含噴水、填表格、擦乾等等 但是 Clean car module 此處包含了操控財務資料的狀況 Communicational cohesion 所有的 activities 都支援相同的 input/output ex: 提取文章的作者、提取文章的標題、提取文章的內容 Sequential cohesion 某個 activities 的輸出是另一個 activities 的輸入，且具有順序性 Procedureal cohesion 和 Communicational cohesion 的結合 這個沒那麼糟糕 Strong cohesion Functional cohesion Module 只支援只和一個問題相關的 activities Object cohesion 所有的 activities 都只會修改一個 object ","date":"2023-03-08T14:26:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E8%BB%9F%E9%AB%94%E8%A8%AD%E8%A8%88-low-level/","title":"軟體設計 - Low Level"},{"content":"paper: PatentBERT: Patent Classification with Fine-Tuning a pre-trained BERT Model\nAbstract 把 fine-tune BERT 應用在專利分類上，當應用於超過 200 萬件專利的資料集時，該方法超越了結合 word-embedding 的 CNN 的 SOTA 作法。\n貢獻: 一個用預訓練的 BERT 去 fine-tune 的 SOTA 方法 一個叫做 USPTO-3M 的大型資料集，屬於 CPC subclass level，並提供 SQL 語句讓後續的研究者使用 與傳統觀念相反，只需要 claim 就足以完成分類任務 Introduction 專利分類是一個 multi-label 的分類任務。\n由於標籤的數量可能很大，所以是個具有挑戰性的任務。\n作者準備了一個基於 CPC 的新資料集，有超過三百萬項美國專利。\nCPC Cooperative Patent Classification 是 IPC 更具體和詳細的版本 可預見將取代 IPC 成為新的標準 只是由於 CLEP-IP 競賽，大部分論文都基於 IPC 資料集包含 1978 到 2009 提交的專利 IPC International Patent Classification 此外，作者的 dataset 基於 patent claims\npatent claims 重要性在過往被低估 在起草專利申請時，專利業者會先起草 patent claims 專利文件的其餘部分由 claim 做延伸 在專利法中，claims 定義了專利發明的界線，確定了專利權範圍 為使模型更簡單，只關注 patent claims，並且僅用第一項 claim。\n相關工作 過往有些研究只顯示了 precision，但沒有 F1 value 或 recall，難以公平比較。\n以 DeepPatent\nData 過往資料基於 CLEF-IP 或 patent offices。\n作者發現在 BigQuery 用 Google Patents Public Datasets 更容易。\n而且可用 SQL statements，作者認為比共享傳統資料集更好，原因如下:\nSeperation of concerns 如果資料包含前處理或後處理，其他研究人員需要不同操作時會很頭痛。 Clarity and flexibility SQL statement 精確且容易根據不同條件進行修改。 在和 DeepPatent 比較的時候，可以的話，會用 USPTO2M 進行測試，如果不行，才會合併來自 USPTO-3M 的資料，比如 USPTO-2M 沒有 claims 的情況。\n為了比較 claim 如何影響性能，將合併兩個資料集。\nMethod \u0026amp; Experimental Setup 用 BERT-Base 就可以打敗 DeepPatent。\n遵循 BERT Project 中給的 fine-tune 範例。\n為了 multilabel，用 sigmoid cross entropy with logits function 而不是用 softmax。\nConclusion 專利分類作為具有挑戰性的任務，幾十年來一直沒有令人滿意的表現。\n本文提出一個基於 fine-tune BERT 的方法，性能優於 DeepPatent。\n並且結果表明只用 patent claim 就可以完成分類任務。\n","date":"2023-03-02T16:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/patentbert-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"PatentBERT 論文閱讀"},{"content":"Process Scheduling 可能時機\nrunning -\u0026gt; waiting running -\u0026gt; ready waiting -\u0026gt; ready running -\u0026gt; terminate Process Scheduler\nPreemptive scheduler (Time slice) 可以被搶占 Non-Preemptive scheduler 又稱 cooperative scheduling 只可能出現在時機 1 或 4 Classification fo Processes(related to scheduling)\nInteractive Processes (50 - 150 ms) Batch Processes Real time Processes Hard Soft Classification of Processes(related to CPU usage)\nCPU Bound I/O Bound Standard Scheduling Algorithm FCFS SJF SRTF Priority Based Highest Response Ratio Next Round Robin Virtual RR Multi-Level Queue Scheduler Multi-Level Feed Back Queue Scheduler Rotating Staircase Deadline Scheduler UNIX SVR3 Scheduler 有 32 個 runqueue，每個 runqueue 負責 4 個 priority values\n128 Priority values\n0-49: Kernel 50-127: User $Priority_j=Base_j+CPU_j(i)+nice_j$\nBase: 0-127 $CPU_j(i) = DR * CPU_j(i-1)$ DR = $\\frac{1}{2}$ nice: -20 ~ +19 可以用 nice 和 renice 改 process nice value Schedtool Query \u0026amp; set per process scheduling parameters\nScheduling Policy Real time SCHED_RR SCHED_FIFO Conventional SCHED_NORMAL (default) SCHED_BATCH (CPU intensive) SCHED_ISO (unused) SCHED_IDLEPRIO (low pri jobs) Nice Value (-20 to +19) Static Priority (1-99) CPU affinity process 想運行在某個指定的 CPU 上，不被轉移到其他 CPU，才不會降低指定 CPU 的 cache 命中率 soft CPU affinity hard CPU affinity cpus_allowed 一個用來指定 CPU 的 mask 1 schedtool \u0026lt;PID\u0026gt; ","date":"2023-02-20T21:12:52+08:00","permalink":"https://roykesydon.github.io/Blog/p/process-scheduling/","title":"Process Scheduling"},{"content":"paper: Masked Autoencoders Are Scalable Vision Learners\nAbstract 這篇論文顯示出 MAE 是 CV 中的 scalable self-supervised learners。\nMAE 的方法很簡單\n隨機蓋住輸入影像的一些 patch 重建 missing pixels 具備兩個核心設計\n非對稱的 encoder-decoder 架構，encoder 只作用於可見的 patch 子集合(沒有 mask tokens)，lightweight decoder 則根據 latent representation 和 make tokens 來重建圖片。 當遮住高比例(比如 75%)的影像時，會得到一個 nontrivial 和 meaningful 的 self-supervisory task 結合這兩點設計，可以有效地訓練大模型。 以 ViT-Huge 用 ImageNet-1K 訓練(訓練集一百多萬張照片)可達到 87.8% 的準確度。\nIntroduction 在 CV 中，常需要大量 labeled images。 NLP 中，自監督預訓練處理了需要大量標註資料的問題。 masked autoencoders 是一種更 general 的 denoising autoencoders 的形式。 BERT 非常成功，autoencoding methods 在 CV 的研究卻落後 NLP，作者思考是什麼讓 masked autoencoding 在 CV 和 NLP 產生不同。 有以下觀點\n直到前陣子，CV 中的 CNN 是主流，但卷積層不好引入 mask tokens 或 positional embedding 這些 indicator。但這些可以透過 ViT 來解決，不應成為問題。 語言和視覺的 Information density 不同，語言是 highly semantic 和 information-dense，使填字本身不是很簡單的事情，但影像含有大量冗餘的訊息，缺失的部分比較好從相鄰的 patch 重建，比如直接插值，所以作者用一種簡單的策略，隨機 mask 很大一部分的 patch，創造一個具有挑戰性的自監督任務，強迫模型關注 global 的資訊。 關於 decoder，CV 還原 pixel，pixel 屬於 lower semantic level，NLP 還原 word，word 的 semantic information 較高。作者發現，雖然在 BERT 中，可以用簡單的 decoder 還原(一個 MLP)，但 CV 中 decoder 的設計就很重要。 基於以上觀點，作者提出 MAE，隨機遮住大量的 patch，並在 pixel space 重建失去的 patch。而且是非對稱 encoder-decoder 架構，encoder 只會看到可見的 patch，但 docoder 除了 latent representation，還會看到 mask tokens。這種設計在非常高的掩蓋率(比如 75%)下不但可以提高準確度，還可以讓 encoder 只處理較少比例(比如 25%)的 patch，將訓練時間減少 3 倍或更多，使 MAE 可以輕鬆擴展成更大的模型。\n在這樣的架構下，用 MAE 的 pre-training，可以訓練非常吃 data 的模型，比如 ViT-Large/-Huge，而只使用 ImageNet-1K。\n用 ImageNet-1K 在 vanilla ViT-Huge 上 fine-tune 可達到 87.8% 準確度，比以往只使用 ImageNet-1K 的結果都高。\n在 obejct detection、instance segmentation、semantic segmentation 上做 transfer learning 都達到不錯的效果，可以打敗用監督式預訓練模型的對手。\n相關工作 Autoencoding MAE 是一種 denoising autoencoding 的形式，但和 DAE 還是差別很大。 Masked image encoding iGPT、ViT、BEiT Approach Masking\n和 ViT 一樣，把圖片切成多個 patch，對於 patch 均勻隨機地採樣保留，剩下地遮住 MAE encoder\nViT 也有 positional embedding MAE decoder\nTransformer block 輸入 encoded visible patches mask tokens shared, learned vector 都會加入 positional embedding 用相較 encoder 輕量的解碼器，所有的 patch 由這個輕量的 decoder 處理，減少預訓練時間 Reconstruction target\ndecoder 的最後一層是 linear projection，之後再 reshape 成你要的 patch loss function mean squared error(MSE) 只算 masked patched 的 MSE，像 BERT Simple implementation\n先取得一系列 token(patch 做 linear projection + positional embedding) randomly shuffle，根據比例移除尾端一部份 encoding 後，尾端接上 mask tokens，並且 unshuffle 加上 positional embedding 後，給 decoder ImageNet Experiments 在 ImageNet-1K 上做自監督的預訓練，然後做\nend-to-end fine-tuning 所有參數都可改 linear probing 只改最後一層線性層 optimal masking ratio 意外地高，相比 BERT 只有 15%\n討論和結論 在 CV 實用的預訓練做法主流是監督式的，CV 中自監督的做法可能正跟著 NLP 的軌跡走。\n要仔細處理圖像和語言的區別，作者去除圖片中很可能不構成 semantic segment 的部分，而不是移除某個 object。\n","date":"2023-02-15T16:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/mae-%E8%AB%96%E6%96%87/","title":"MAE 論文"},{"content":"paper: An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale\nAbstract 在 CV 領域 transformer 表現有限，目前 attention 常常是和卷積神經網路一起用，或是用來把一些卷積層換成 self-attention，但整體架構不變。這篇論文想展現一個純 Transformer 可以直接在影像分類上表現很好。如果用大量資料作預訓練，再遷移到中小型的資料集，可以和 SOTA 的 CNN 表現得一樣好，還需要較少的訓練資源作訓練。\nIntroduction self-attention-based 架構，特別是 Transformer，已經是 NLP 的重要選擇。主流的作法是在大型文字資料集上作訓練，再針對小型任務資料集作 fine-tune。由於 Transformer 的計算效率高，還有可擴展性，可以 train 一些很大的 model，隨著 model 和資料集增大，目前還沒看出飽和的現象。\n然而在 CV，CNN 還是主流，一些工作嘗試用 self-attention 結合 CNN-like 的架構，比如把 feature map 當 transformer 的輸入，因為原始 pixel 太多，或甚至把卷積層全換成 self-attention，雖然後者理論上效率很高(原論文中有另外 cite 兩篇作法)，但因為他們做法特殊，在現代硬體上很難加速，所以無法很有效地擴展。在 large-scale 的影像識別上， ResNet-like 的架構還是 SOTA。\n該實驗直接把一個標準的 Transformer 作用於圖片上，只作最少的修改。把影像分成多個 patch，並把它們變成一系列的 linear embedding，當作 NLP 中的 tokens(words) 來處理。\n當在中型大小的資料集(e.g. ImageNet)上訓練，如果沒有 strong regularization，ViT 會略輸同等大小的 ResNets\n這篇論文在更大的資料集(14M-300M 的影像)上訓練，就打敗了 inductive bias。在大量資料上作預訓練就很讚。\nRelated Work 大型的 Transformer-based 模型常常是先在大資料集上預訓練然後根據任務 fine-tune，比如 BERT 和 GPT。\n要把 self-attention 用在 CV 上，最簡單的做法就是把每個 Pixel 當一個元素，但 self-attention 是平方複雜度，在現實的圖片很難應用。一個應用 Transformer 的做法是只把 self-attention 用在 local neighborhood，另外一個是用 Sparse Transformer，還有一堆特殊的方法，雖然表現不錯，但要用硬體加速起來不容易。\n另一個有關的模型是 iGPT，在 reduce image resolution 和 color space 後把 transformer 應用在 image pixels 上。它用非監督式訓練後，再 fine-tune 或做 linear probing(只更新最後的 linear layer) 分類任務，表現很好。\n已經有類似的工作了，抽取 patches of size 2 * 2，最後再接 full self-attention，基本上和 ViT 非常像，這篇論文進一步證明了作大規模的預訓練可以讓 Transformer 和 SOTA 的 CNN 相比，而且 ViT 因為 patch 比較大，可以處理 medium-resolution 的圖片。這問題是可預期的，因為 Transformer 缺少了一些 inductive biases。\ninductive biases 一些假設 比如 CNN 常有四個假設 locality translation invariance with pooling layers 平移不變性 translation equivariance f(g(x)) = g(f(x)) 卷積和平移的先後順序沒差 Method 模型盡可能類似原始 Transformer，這樣可以把一些 NLP 上成功的 Transformer 架構拿來用，還可以用一些很有效率的 implementation\nembedding 維度是 768 = 16 * 16 * 3 position embedding 的做法是 standard learnable 1D positional embeddings，就是 BERT 的做法，簡單來說就是生出一張可以訓練的表，(序列長度, embedding size)，作者也有嘗試其他方法，但發現成效差不多，比如 2D positional embedding，概念就是從生出(序列長度, embedding size)變成生出 2 個(sqrt(序列長度), embedding size)。\n[class] 的概念是 NLP 出來的，ResNet-like 的架構常見的做法也有通過 globally average-pooling (GAP)來生出向量，再接上分類器做預測。實驗發現直接在 transformer 的輸出做 GAP 和 [class] 都可以達到不錯的效果。\nConclusion 拿標準的 Transformer 來作 Image recognition，和以往用 self-attention 在 CV 的方法不一樣，除了一開始的 initial patch extraction，沒有引入其他影像特有的 inductive biases。直接把圖片當成是一系列的 patch，然後直接用 Transformer encoder 當一般 NLP 任務處理。在很多影像分類訓練集上表現得更好還在 pre-train 上相對便宜。\n還有一些值得挑戰的地方，比如把 ViT 應用在其他 CV 任務，比如 detection 和 segmentation。另一個挑戰是探索自監督預訓練的方法。這篇論文其實有實驗自監督，表現 OK，但和監督式還是有很大的落差。擴大 ViT 可能有更好的結果。\n","date":"2023-02-12T00:27:55+08:00","permalink":"https://roykesydon.github.io/Blog/p/vit-%E8%AB%96%E6%96%87/","title":"ViT 論文"},{"content":"Share information between processes 透過硬碟上的文件溝通 超慢 透過 kernel buffer 滿快的，但這樣要一直在 user mode 和 kernel mode 來回切換，因為kernel buffer 在 kernel space 透過 shared memory region shared memory region 在 user space Mechanisms Signals\nCommunication\nData transfer Byte Stream Pipes FIFOs(Named Pipes) stream sockets Message Passing SystemV MsgQ POSIX MsgQ datagram sockets Shared Memory SystemV S.M POSIX S.M Memory Mapping anonymous memory mapping memory mapped file Synchronization\nPipes Related processes parent-child sibling Executing on same machine 用法 cmd1 | cmd2 cmd1 不是輸出到 stdout，而是由 kernel 維護的 buffer，也就是 pipe cmd 不是從 stdin 獲取輸入，而是從 pipe 獲取 cmd1 | cmd2 | \u0026hellip; | cmdn Named Pipes / FIFOs Related / Unrelated processes\nExecuting on same machine\ncreat a FIFO\ncommands mkfifo mknod 嘗試寫入或讀取 FIFO 時，會被 redirect 到 pipe\nSignal Handling Signal Used by OS to notify running process some event has occured without the process needing to pull for that event process 收到 signal 後會先停止執行並執行 signal handler A process did something SIGSEGV(11), SIGFPE(8), SIGILL(4), SIGPIPE(13)\u0026hellip; A process wants to tell another process something SIGCHILD(17) child process terminated User sends sig to foreground processes Ctrl + C SIGINT(2) Ctrl + \\ SIGQUIT(3) Ctrl + Z SIGTSTP(20) disposition 決定 process 遇到 signal 時該怎麼處理\nTerm teminate process Ign ignore Core terminate the process and dump core Stop stop the process Cont continue the process if it is stopped Signal can\u0026rsquo;t not be caught SIGKILL(9) SIGSTOP(19) Commands trap\n可以 handle signal\nkill kill - L 可以看到 standard signal 和 real-time signal\nstandard signal 開頭是 SIG，realt-time signal 是 SIGRT\n","date":"2023-01-28T15:31:50+08:00","permalink":"https://roykesydon.github.io/Blog/p/ipc--inter-process-communication/","title":"IPC -- Inter-Process Communication"},{"content":"paper: Training language models to follow instructions with human feedback\nAbstract 把語言模型變大不代表他們會更好地遵循用戶的意圖。\n大的語言模型有可能會生成 untruthful, toxic, not helpful 的答案。\n該論文透過 fine-tuning with human feedback 來解決這問題。\n一開始準備一系列人工標註的 prompts，然後用這 dataset 對 GPT-3 做 fine-tune。\n接下來再蒐集一個 dataset，存放 rankings of model outputs，由人工判斷輸出好壞，再用 RL 把剛剛 fine-tune 過的 model 繼續 fine-tune。\n最後有 1.3B 參數的 InstructGPT 表現的結果比 175B 參數的 GPT-3 還好。\nIntroduction Large language models(LMs) 可以透過 \u0026ldquo;prompt\u0026rdquo; 來執行各種 NLP 任務。\n但這些模型也常有一些非目的性的行為，諸如捏造事實等等。\n原因是出在目標函數上，多數 LMs 的目標函數是根據網路上的文本生出下一個字詞。\n這和「根據使用者指令生出安全且有幫助的答案不同」。\n上述的差異使語言模型的目標是 misaligned。\n作者的目標是生出 helpful、 honest(沒有誤導性資訊)、harmless 的 model。\n具體作法，使用 reinforcement learning from human feedback(RLHF)。\n訓練步驟 結果 Labelers 明顯偏好 InstructGPT 的答案，勝過 GPT-3 的答案\nInstructGPT 的答案在 truthfulness 勝過 GPT-3 的答案\nInstructGPT 的答案在 toxicity 上小勝 GPT-3 的答案，但在 bias 上沒有\nMethods Dataset 標註人員寫很多 prompts\nPlain: 隨便寫任意任務 Few-shot: 想個 instruction，並寫 multiple query/response pairs for that instruction User-based: 根據一些申請使用 OpenAI API 的用戶，提出有關的 prompts 然後根據這個訓練初步模型，並把這個初步模型放到他們的 Playground 給用戶使用。\n再把用戶問的問題蒐集回來，並做篩選。\n訓練 SFT 的模型用 13k training prompts\n訓練 RM 的模型用 33k training prompts\n訓練 PPO 的模型用 31k training prompts\nModel Supervised fine-tuning(SFT)\n拿 GPT-3 去訓練 16 個 epochs 跑一個 epoch 就發現 overfitting，但發現訓練更多 epoches 對後面的 RM 有用，而且這個 model 也只是過渡產品 Reward modeling(RM)\n把 SFT 後面的 unembedding layer 去除掉，接上線性層，最後輸出一個 scalar reward\n用 6B RMs\n這模型會吃 prompt 和 response\n人工標記的是排序，不是分數\n對每個 prompt 生出 9 個答案\n原本是 4 個，但排 9 個花的時間可能不會到 4 個的兩倍，因為主要心力會花在讀 prompt。但標註訊息會多很多，因為都是兩兩比較。 而且在 loss 中最多只要丟入 RM 9 次，因為可以重用 Pairwise Ranking Loss\n對一個 prompt(假設是 x)，取出一對回覆(假設是 $y_w$ 和 $y_l$)，算出 RM(x, $y_w$) 和 RM(x, $y_l$)，假設 $y_w$ 比 $y_l$ 排序高，讓 RM(x, $y_w$) - RM(x, $y_l$) 的數值越大越好 Reinforcement learning(RL)\nPPO\n$\\beta$ 那項是 KL divergence $\\gamma$ 那項是不想要讓這 model 太專注在微調的任務，而失去原本在其他 NLP 任務也表現很好的功能。 $D_{pretrain}$ 是 pretraining distribution 如果 $\\gamma$ 為 0，在該實驗中叫做 PPO，否則，稱為 PPO-ptx Result ","date":"2023-01-27T17:39:12+08:00","permalink":"https://roykesydon.github.io/Blog/p/instructgpt/","title":"InstructGPT"},{"content":"介紹 一種用於自動化找超參數的方法，用在採樣昂貴而且是黑盒子的情況\n流程 取樣一些資料點 生出一個 Surrogate Model(可採用 Gaussian Process) 反覆做以下事情 用 Acquisition Function 挑選下一個要採樣的點 重新評估 Surrogate Model Gaussian Process 最終的 prediction 是一個 distribution 而不是單一個數字 生成方法需借助 kernel function，常用 RBF(Radial Basis Function)\n$K(x, x^{\u0026rsquo;}|\\tau)=\\sigma^2exp(-\\frac{1}{2}(\\frac{x-x^{\u0026rsquo;}}{l})^2)$\n$\\sigma$ 和 $l$ 是兩個可以調整的超參數\nAcquisition Function 可用超參數來調節 exploitation 和 exploitation\nUCB(Upper confidence bound) PI(probability of improvement) EI(Expected improvement) ","date":"2023-01-26T01:36:53+08:00","permalink":"https://roykesydon.github.io/Blog/p/bayesian-optimization/","title":"Bayesian Optimization"},{"content":"PPFDT per process file descriptor table 每個 process 都有 存放 file descriptors file descriptors 是一個唯一的整數，用來識別作業系統上的 open file 0, 1, 2 是 Standard input / ouput / error 大小受限於 OPEN_MAX，亦即能同時間能開的最多檔案數 Redirection Input redirection $ wc \u0026lt; /etc/passwd 把 wc 的 PPFDT 的 stdin 改成 /etc/passwd 如果是 $ wc /etc/passwd，則是在 PPFDT 追加 /etc/passwd Ouput redirection $ wc \u0026gt; f1 把 wc 的 PPFDT 的 stdout 改成 f1 Input \u0026amp; output redirection 兩個可以同時用\n$ cat \u0026lt; f1 \u0026gt; f2 \u0026gt;\u0026gt; 可以 append $ \u0026lt; f1 cat \u0026gt; f2 可以亂換位置 Error redirection $ find / -name f1 2\u0026gt; error 1\u0026gt; outputs 這樣就會把那些 Permission denied 的給到 errors，成功的給到 outputs 2\u0026gt;/dev/null /dev/null 會把丟進來的東西都丟棄 Copy Descripter 這兩者等價 $ cat f1 1\u0026gt;op_err 2\u0026gt;op_err $ cat f1 1\u0026gt;op_err 2\u0026gt;\u0026amp;1 make 2 a copy of 1 ","date":"2023-01-21T02:20:43+08:00","permalink":"https://roykesydon.github.io/Blog/p/io-redirection/","title":"IO Redirection"},{"content":"Compile C 4-steps pre-processing compilation assembly linking Types of Object Files Executable object file Relocatable object file Shared object file Core file Formats of Object Files a.out initial version of UNIX COFF SVR3 UNIX PE Win. NT ELF SVR4 Linux ELF format of a program ELF Header Program Header Table .text .rodata .data .bss .symtab .rel.text .rel.data .debug .line .strtab Section Header Table 可參考: http://ccckmit.wikidot.com/lk:elf\nProcess Instance of a program running on a computer\nProcess Control Block task_struct\nProcess Identification PID, PPID, SID, UID, EUID.. Process State Information Process Control Information ","date":"2023-01-21T00:08:25+08:00","permalink":"https://roykesydon.github.io/Blog/p/process-management/","title":"Process Management"},{"content":"Features Process control Variables Flow control Functions File \u0026amp; cmd name completions Cmd line editng Cmd history Command Mode Interactive Non- Interactive Command Type internal / Builtin command\n指令的程式碼是 shell 的一部分 e.g., cd, exit 不會產生 child process 有些 internal command，比如 echo, pwd，會 internal 和 external 都有實作 external command\n指令的程式碼在硬碟上的某個 binary file e.g., clear, ls 會產生 child process Common Commands 比較實用或常用的\ngrep\n找字詞\ngrep \u0026lt;string/pattern\u0026gt; -i 大小寫不敏感 -v 不包含關鍵字的 cut 找 column\n-f 找哪些 column -d 分隔符是什麼 比較兩個檔案\ncomm\n顯示 file1 獨有的列、 file2 獨有的列、file1 和 file2 共有的列\ncmp, diff\n回傳不一樣的列資訊\nunset\n把指定的變數移除掉\ntee\n吃 stdin 輸出到 stdout 和其他檔案\nless\n讀檔案用\nExpansions White space Control Operators ; 讓指令接著執行 \u0026amp; 放在結尾，讓指令在背景執行 \u0026amp;\u0026amp; logical AND || logical OR\n前面失敗才會跑後面\n# 註解用 \\ escape special characters 放結尾好換行繼續輸入 $? 一個特別的變數，有上個指令的 exit code Shell variables User defined Env var Shell history File Globing *, ?, [], -, ! ","date":"2023-01-19T23:00:02+08:00","permalink":"https://roykesydon.github.io/Blog/p/shell/","title":"Shell"},{"content":"GPT 本質上就是 Transformer 的 decoder\nGPT-1 paper: Improving Language Understanding by Generative Pre-Training\n用 semi-supervised，後來被歸為 self-supervised\nUnsupervised pre-training $L_1(U)=\\sum_i logP(u_i|u_{i-k},\u0026hellip;,u_{i-1};\\theta)$\n$U= \\{ u_1,\u0026hellip;,u_n \\}$\n$U$ 是一系列未標記的文本 token\n$k$ 是窗口大小\n模型大致架構 $h_0=UW_e+W_p$\n$h_1=transformer \\_ block(h_{i-1})\\forall i \\in[1,n]$\n$P(u)=softmax(h_nW^T_e)$\n$U=\\{u_{-k},\u0026hellip;,u_{-1}\\}$\nSupervised fine-tuning $P(y|x^1,\u0026hellip;,x^m)=softmax(h^m_lW_y)$\n$L2(C)=\\sum_{(x,y)}log P(y|x^1,\u0026hellip;,x^m)$\n$L_3(C)=L_2(C)+\\lambda*L_1(C)$\n$C$ 是 labeled 的資料集，微調基本上就是在後面加上線性層\n作者最大化 likelihood 的時候是用 $L_3$ 而非單純的 $L_2$\n微調應用範例 資料集 用 BooksCorpus 訓練出來的\n有超過 7000 本未出版的書\n模型結構 12 層 transformer 的 decoder 768 維 word embedding 12 個 attention heads 和 BERT BASE 比較 BERT 論文比較晚出，但 BASE 的模型架構和 GPT 有相似之處，\nBASE 是 12 層的 decoder，word embedding 和 attention head 的維度或數量和 GPT-1 相同\nGPT-2 paper: Language Models are Unsupervised Multitask Learner\nGPT-2 除了用更大的的模型和更大的資料集，把重點放在 zero-shot 上，雖然在 GPT-1 的論文就有提過 zero-shot\n資料集 這次做了一個叫做 WebText 的資料集，有百萬級別的網頁\nCommon Crawl 大型爬蟲專案，有大量網頁資料，但充斥了垃圾訊息\nWebText WebText 的資料來源是 reddit 上的外部連結，只要有至少三個 karma，就會被採納，由此取得品質較好的網頁資料。透過這種方法，取得了 4500 萬個連結。並用Dragnet (Peters \u0026amp; Lecocq, 2013) and Newspaper content extractors 把文字訊息從 HTML 中抓出來\n架構 和原本差不多，變成有 1.5B 參數的 Transformer decoder\nzero-shot 不需要下游任務的標記資料\n改把任務輸入進模型\n目前問題 現在的模型泛化能力不太好 Multitask learning 在 NLP 上不太常用，NLP 現在主流還是在預訓練模型上做微調以應對下游任務 對每個下游任務都得重新訓練模型 得蒐集 labeled 資料 結果 GPT-3 paper: Language Models are Few-Shot Learners\n摘要 有 175B 的參數，由於模型極大，要在子任務微調會成本很大，所以不做任何梯度更新 在很多 NLP 任務有傑出的成果 可以生出人類難以區分的新聞文章 目前有的問題 要在子任務微調，需要資料集 微調後在有些子任務上表現好不代表你預訓練模型一定泛化能力高 人類不需要大量 labeled 資料去完成小任務 評估方式 分為三種，few / one / zero-shot learning 架構 基本上 GPT-3 和 GPT-2 架構一樣\n相同 modified initialization pre-normalization reversible tokenization described therein 不同 把 Sparse Transformer 的一些修改拿過來用 GPT-3 Small 是 GPT-1 的大小 GPT-3 Medium 是 BERT Large 的大小 GPT-3 XL 和 GPT-2 相近，比較淺也比較寬\nBatch Size 大小 模型小的時候需要小一點，透過這種額外的 noise 來避免 overfitting(不確定是不是猜想)\n資料集 Common Crawl 架構比 GPT-2 大很多，所以回頭考慮這個資料集\n三步驟 先過濾，透過 reddit 那個高品質的資料集，來訓練一個模型分類高品質和低品質的網頁。 透過 LSH 演算法把相似的文本過濾掉 把一些已知高品質的資料集也加進來 這是一個 Batch 裡有 60% 來自 Common Crawl(filtered) 的意思 Wikipedia 雖然總量比較少，但也有 3% 的採樣率\n結果 計算量指數增長，loss 卻是線性的往下降\npaper 裡有很多任務的實驗結果，這邊就不附上了\nLimitations 在文本生成上還是比較弱，生很長的東西，可能會重複自己說過的話、失去連貫性、自相矛盾等等\n在有些雙向性的任務上可能表現更差\n影響 可能被用來散布不實消息、垃圾郵件等等 偏見 結論 在很多 NLP 任務可以做到接近 SOTA 微調模型的成果\n","date":"2023-01-19T01:50:07+08:00","permalink":"https://roykesydon.github.io/Blog/p/gpt-%E4%B8%89%E9%83%A8%E6%9B%B2/","title":"GPT 三部曲"},{"content":"VM A software implementation of a machine\nSystem VM 提供可以執行 GuestOS 的 complete system platform Process VM 像一個一般的 app 一樣在 hostOS 跑，支援單一個 process Hypervisor 又稱虛擬機器監視器（英語：virtual machine monitor，縮寫為VMM） 用來管理 VM\n允許多個 GuestOS 跑在 host computer\nType-1\nbare-metal hypervisors 直接在硬體上執行 Type-2\nhosted hypervisors 在 hostOS 上執行 directories Binary\ne.g., bin, sbin, lib, opt bin: 有關 user 的指令 sbin: 管理員會用的指令 opt: optional software，多數機器中這是空的 Configuration\ne.g., boot, etc, Data\ne.g., home, root, srv, media, mnt, temp In memory 字面上的意思，不在 hard disk，在 memory\ne.g., dev, proc, sys System Resources\ne.g., usr Variable Data\ne.g., var ","date":"2023-01-19T01:50:07+08:00","permalink":"https://roykesydon.github.io/Blog/p/linux-%E7%91%A3%E4%BA%8B/","title":"Linux 瑣事"}]