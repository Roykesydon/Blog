[{"content":"基礎概念 Node Kubernetes 集群中的一台機器 過去叫做 Minion Cluster 由多個 Node 組成的集群 Node Type Master 控制整個集群的 Node Worker 其他非 Master 的 Node 叫做 Worker Node Master vs Worker Master 擁有的 Component API Server etcd Controller Scheduler Worker 擁有的 Component Container Runtime Kubelet Component 安裝 Kubernetes，實際上是安裝以下幾個 Component API Server front-end of the Kubernetes etcd distributed key-value store 會實現 lock mechanism，確保沒有 conflict kubelet 在每個 node 上運行的 agent 負責確保 container 在 node 上如期運行 Container Runtime 用來 run container 的 underlying software Controller 當 node、container、endpoint 掛掉的時候，他要負責監控和回應 type Replication Controller 確保指定數量的 Pod 在任何時間都在運行 load balancing \u0026amp; scaling 後來被 ReplicaSet 取代 Scheduler 負責處理 node 間的 distributing work 會尋找新創的 container，並分配到 node Pod Kubernetes 的最小單位 一個 Pod 封裝一個應用程式，可能包含一個或多個 container ReplicaSet 新版本的 Replication Controller yaml spec template 指定要創建的 Pod 的 template 把 pod 的 metadata 和 spec 都放在這裡 replicas 指定要創建的 Pod 的數量 selector 指定要選擇的 Pod 需要這個是因為 ReplicaSet 也可以管理那些不是他創建的 Pod matchLabels 指定要選擇的 Pod 的 label command kubectl scale --replicas=3 -f \u0026lt;file\u0026gt; scale up/down replicas 這樣不會修改檔案，所以檔案的如果原本是 2，檔案依然會寫 2，只是 replicas 會變成 3 kubectl scale --replicas=3 replicaset \u0026lt;name\u0026gt; scale up/down replicas kubectl edit replicaset \u0026lt;name\u0026gt; 想要 scale up/down replicas 也可以用這個，他會立刻生效 簡寫 rs Deployment 管理 ReplicaSet 和 Replica Controller yaml 和 ReplicaSet 很像，把 kind 從 ReplicaSet 改成 Deployment 就好 會自動創建 ReplicaSet 使用情境 Rolling update 想要更新每個 Pod，但不是同時更新，而是一個一個更新，確保不會有 downtime Rollback 如果更新失敗，可以回到之前的版本 Pause and Resume 當需要做 multiple changes，不想要一下指令就馬上做，可以先 pause，等所有指令下完再 resume rollout 創建 Deployment 的時候，會自動創建一個 rollout 創建一個 rollout 的時候，會自動創建一個 Deployment revision Deployment Strategy Recreate 先刪除所有舊的 Pod，再創建新的 Pod 中間會有 Application downtime Rolling Update 一個一個更新 Pod 這個是預設的 strategy command kubectl rollout status deployment \u0026lt;name\u0026gt; 查看 rollout 的狀態 kubectl rollout history deployment \u0026lt;name\u0026gt; 查看 rollout 的 history (revision) kubectl rollout undo deployment \u0026lt;name\u0026gt; 回到上一個 revision 簡寫 deploy Service 讓不同 group 的 Pod 互相通信 像一個 virtaul server，可以連接到一個或多個 Pod type NodePort 會在每個 node 上開一個 port，讓外部可以連進來 default valid port range: 30000-32767 yaml spec type ports port service 的 port targetPort pod 的 port 如果不設置，會用 port 的值 nodePort 如果不設置，會從 default port range 選一個 selector 指定要連接的 Pod 預設會用 load balancing，策略是 Random，像是一個內建的 load balancer 如果有在同個 cluster 跨 node 的情況，不需要其他設定，就可以創建一個跨 node 的 service，會幫他們都設同一個 nodePort ClusterIP 只有在 cluster 內部可以連進來 用來幫某一組的 pod 提供一個統一的界面並做轉發 不能依賴 internal IP，因為每個 pod 都有可能會 down 或 up yaml spec type ports port targetPort selector service 可以用 cluster IP 或是 service name 來連接 LoadBalancer 會在 cloud provider 上開一個 load balancer nodePort 的 load balancer 是在 node 內部的，現在是要幫多個 node 做 load balancing 這只有在 cloud provider 上才有 name 很重要，因為其他的 Pod 會用這個 name 來連接 (就像 domain name) 簡寫 svc YAML Kubernetes 的配置文件 root level properties apiVersion kind apiVersion Pod v1 Service v1 ReplicaSet apps/v1 Deployment apps/v1 kind Pod, Service, ReplicaSet, Deployment metadata name labels 可以加入任何 key-value pair spec specification section pod containers name image env: list of environment variables name value Cloud two type of cluster Self hosted / Turnkey solutions 用來在自己的 server 上建立 cluster Hosted solutions / Managed solutions 用來在 cloud 上建立 cluster Hosted solutions Google Kubernetes Engine (GKE) Amazon Elastic Kubernetes Service (EKS) Azure Kubernetes Service (AKS) Tool kubectl kubectl 用來 deploy、inspect、manage application on a Kubernetes cluster commands kubectl run \u0026lt;name\u0026gt; --image=\u0026lt;image\u0026gt; 創建一個 Pod kubectl get pods 查看所有 Podllll -o wide 顯示更多資訊 column READY / 也可以用 kubectl get all 來查看 Pod、Service、ReplicaSet、Deployment kubectl describe pod \u0026lt;name\u0026gt; 查看 Pod 的詳細資訊 欄位 Node Pod 在哪個 Node 上運行，包含了 Node 的 IP IP Pod 的 IP kubectl delete pod \u0026lt;name\u0026gt; 刪除 Pod kubectl create -f \u0026lt;file\u0026gt; 根據 YAML file 創建 resource 如果 resource 已經存在，會報錯 kubectl apply -f \u0026lt;file\u0026gt; 根據 YAML file 創建 resource 如果 resource 已經存在，會更新 resource kubectl replace -f \u0026lt;file\u0026gt; 根據 YAML file 創建 resource 如果 resource 已經存在，會刪除舊的 resource，並創建新的 resource kubectl edit replicaset \u0026lt;name\u0026gt; 可以直接編輯 Replica Set 的 yaml 檔，但他不是一開始創建用的檔案，而是 Kubernetes 在 memory 暫時生成的 kubectl set image deployment \u0026lt;name\u0026gt; \u0026lt;container-name\u0026gt;=\u0026lt;new-image\u0026gt; 更新 Deployment 的 image 注意這裡是 Container name，不是 Pod name --record=true 會記錄每次的操作 用在 rollout 的時候，可以看到每次的操作，不然會顯示 minikube 用來在 local machine 上建立一個 single-node cluster kubeadm 用來在多個 node 上建立 cluster 在多個 node 上安裝 Kubernetes 流程 安裝 container runtime 安裝 kubeadm 初始化 master node 建立 pod network 加入 worker node Networking Cluster Networking 每個 Pod 都有自己的 IP 兩個不同屬於同一個 cluster 的 Pod 可能會有相同的 IP Kubernetes 要求所有的 Pod 要可以在不用 NAT 的情況下互相通信 所有的 container 和 node 都要可以在沒有 NAT 的情況下互相通信 可以用 Calico 等方案實現 他會把每個 node network 都設成不同的，底下的 pod IP 自然就不會重複 ","date":"2024-06-14T00:00:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/kubernetes-%E7%AD%86%E8%A8%98/","title":"Kubernetes 筆記"},{"content":"paper: Robust Packet Classification with Field Missing\nAbstract 隨著網路規模成長，由於資源限制，用戶有時候得放棄 packet classification 中的一些欄位。 此外，某些欄位在某些網路中並不總是可用。\n如果某些欄位遺失，傳統的 packet classification 方法就很難處理分類任務。\n本文提出了一個新穎的模型來建構一個 robust packet classification 系統。\n在分類氣的部分，作者採用 Recursive Flow Classification 來同步處理各種欄位。 然後用一個新的 worflow 來處理遺失欄位的問題。\n作者還設計了兩個 complementary bitmap model 來加速 packet 和 flow 的匹配，還有一個 buffer 機制來進一步提高分類準確度。\n實驗表明，當 field missing 機率低於 0.3 時，模型可以用 94% ~ 99.5% 的準確度對 packet 進行分類。\nIntroduction Packet classification 是將 packet 對應到 ruleset 並確定下一步處理方案的過程。 會先根據分類要求提取 packet 的欄位，然後對這些欄位匹配到優先序最高的 rule。\n然而，由於網路規模的增長，packet classification 變得越來越困難。\nfield missing 的情境： 用戶主動放棄欄位 比如，一個 protocol 包含了多個 field，而網路設備只關注齊中的某些 field。這樣就可以放棄某些 field 的提取和匹配，好得到更高的性能。 某些協定中的 optional field 也會導致此問題。 不可用的欄位 在一些 autonomous network 中，有些欄位可能來自外部設備（比如感測器） 因為來源資訊不穩定，可能會導致某些 field value 是 illegal 的，比如 undefined 或者 -1 比如一個 wireless receiver 可能會因為訊號干擾而無法取得訊號，所以把「訊號強度」設為 -1。對於網路設備，-1 會當作 legal，但我們無法用於分類。 上面的問題沒辦法被 router 偵測到，因為 packet 依然是 complete 和 legal 的。\n有三種傳統的 packet classification 方法：\ndecision tree tuple space recursive flow classification (RFC) 許多後來的模型都基於這些演算法。\n之前有學者意識到如今 packet classification 越來越困難，在考量 cost 以及 field 的可用性的情況下，他們嘗試用 flow information 去 recover packet，使製作一個 robust 且 flexible 的 packet classification 系統產生可能性。\n然而，該分類器最後沒有實現並用於 online case。\n考慮到 RFC 對於 field processing 有很明顯的獨立性，作者設計了一個基於 RFC 的 online robust packet classifier，可以處理 field missing 的情況。\n首先，作者用 RFC 處理帶有 miss fields 的封包，並且記錄 complete packet 的 flow information。 然後作者會把 field-missing packet 給分類到這些 flow，去猜 missing field 的值。\n差別在於，作者是用 bitmap 把 packet match 到 flow，並提出用兩個 bitmap model 來加速 packet 和 flow 的匹配。\n此外，由於資訊損失，所以分類失敗是不可避免的。透過設計一個 buffer 機制，有很大一部分的封包有很高的機率在 re-classification 後可以成功分類。\n最後本文設計了一些實驗去分析和評估參數。 在不同的的 field missing probability 下，作者的模型可以達到 93% ~ 99.5% 的準確度。\nProposed Model 分為三個 module：\nRFC processing module packet recovery module buffer module RFC Processing Module RFC 演算法會把 packet 的每個 field 獨立分類，先對每個 field 做 single constraint matching，然後再對他們做 \u0026ldquo;\u0026amp;\u0026rdquo; operation。\n對於 complete packet，把所有 fields 的結果組合在一起，可以得到 matching rule。\n但是如果有 filed missing，一些 \u0026ldquo;\u0026amp;\u0026rdquo; operation 就沒有辦法執行，導致這個過程被中斷。\n對於這種情況，作者會把中斷時有的所有 result 拿來組合出一個近似的結果，充分利用已知訊息，以便下一步可以更好地 recover packet。\nFig. 1 的 field C 是 missing 的，所以圖中 3 個灰色的方塊會沒辦法往下做 \u0026ldquo;\u0026amp;\u0026rdquo; operation。但是我們可以用這三個 result 做 \u0026ldquo;\u0026amp;\u0026rdquo; operation，得出 packet 可能會 hit rule 3。\nPacket Recovery Module 不管 packet 有沒有 missing field，RFC 的結果都是 bitmap (像是 0100100011)。bitmap 的 length 就是 ruleset 中 rule 的總數。第 i 個 bit 是 1，就代表當前的 constraint 可以 match 到第 i 個 rule。\n差別在於，對於 complete packet，bitmap 是準確的，對應的 rule 一定可以被 match 到。 而有 field missing 的 packet 的 bitmap 只是近似的，因為缺乏訊息，所以 constraint 被放鬆，因此，這樣的 bitmap 可能會有 false positive。bitmap 說有 1 的可能與 packet match 或不 match。\n不過如果有某個 bit 對應 0，則一定不可以 match。\n幸運的是，packet 在現有的網路中總是出現在 flow 裡。一個 packet 會帶有一個 field value，是 flow sequence number，被標作 $Seq_{pkt}$。他被用在相關的 flow 中，好排序 packet。\n屬於同一個 flow 中的 packet field value 應該要一樣。換句話說，當對 flow 中的 packet 分類的時候，他們的 RFC 輸出應該要一樣。\n所以，我們可以用一個 bitmap 來表示一個 flow。在這種情況下，recover packet (flow matching) 就變成了 search of bitmap。\nFig. 2 示範了用 bitmap 來實現 flow matching。\nfield-missing packet 近似出的結果在第一行。\n因為沒有 false negative，如果近似是 0，那有 1 的可以排除掉。\n然而還有個問題，就是 bitmap comparison 是一個很耗時的操作。作者提出了兩個 bitmap model 來加速這個過程。\nTree Model 做 BFS。\n如果 bitmap 遇到 1 的話就左右都要往下搜，如果遇到 0 的話就只需要往左搜。\n更新的話就是根據 flow 的 bitmap 繪製路徑，然後把 flow sequence number 加入到 leaf node。\nTable Model 這種 Model 被用來處理包含有大量的 1 的 bitmap。\n只需要訪問那些是 0 的 index，然後表上有的 flow 都排除掉即可。\n以 110100 為例，只需要訪問 3, 5, 6 這三個 index。 然後可以對應到 1, 2, 3, 4, 5, 8, 9 這些 flow。\n所以代表我們有可能的 flow 只有 6, 7, 10 這些剩下的。\n他的搜尋過程比更新過程慢得多。\n當有一個 complete packet 出現時，兩種 Model 都會更新，但當出現 field missing packet 時，會根據「1」的數量去選擇一種 Model 來匹配。\n它稍微增加了更新時間並顯著減少了匹配時間。\nBuffer Mechanism 無論用哪種 Model，最後會有三種 Case：\n沒有 match 到任何 flow 它可能是 flow 的第一個 packet，也可能是前面的 packet 都不完整，這種情況要放在 buffer 等待重新分類。 match 到一個 flow 由於忽略了一些 constraint，所以只找到一個 flow 不代表它一定正確。 可能會有一些封包被誤分類，通常是某些 flow 的前幾個 packet 被過早分類造成的。為了盡可能消除這種因素，會導入「Initial Range」，把 sequence number 小於某個 threshold 的 packet 給放在 buffer。 $Seq_{pkt} \u0026lt; L_e$ match 到多個 flow 這種情況可以視作分類失敗，但是 flow information 可以幫助我們進一步分類這些 packet。 比如 $Seq_{pkt}$ 不能夠和該 flow 現有的封包中的 maximum sequence number 差很多 如果 $Seq_{pkt}$ 是 64，三個 flow 的 maximum sequence number 分別是 108, 12, 60，那屬於第三個 flow 的機率比另外兩個高。 $|Seq_{max}-Seq_{pkt}|\u0026gt;\\Delta$ 會被濾掉 $\\Delta$ 是一個 predifined threshold 如果處理後的情況屬於 Case 1 或 Case 2，那就處理，否則就放到 buffer。 每個 packet 都有「maximum number of waiting packets」和「maximum number of waiting flows」的限制。\n當有新的 flow 被記錄，就會把 buffer 中的 packet 重新匹配。\n如果 packet 因為答到限制而被刪除時，也會被重新匹配。\n如果 packet 依然沒有命中任何 flow 或是有多種 flow，就會被丟棄，並記錄為匹配失敗。\nExperiments 作者從 Classbench 中選擇 1000 條 rule，並且每條 rule 選擇 100 個相關的 packet 用來生成 flow。\n然後根據 field missing probability 隨機刪除一些 field。\nClassification accuracy 是用正確分類的 packet 數量除以總 packet 數量。\nRecovery accuracy 是指 packet recovery module 的成功率。\n","date":"2024-06-02T00:00:01+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80robust-packet-classification-with-field-missing/","title":"論文閱讀：Robust Packet Classification with Field Missing"},{"content":"基礎概念 Module 把相關的 Component、Directive、Pipe、Service 等打包在一起的容器 Lazy Loading Component Angular 應用程式的基本組成單位 Pipe 用來轉換資料的工具，可以把字串格式化、日期格式化等 Directive 用來修改 DOM 元素的外觀或行為 比如說 ngIf、ngFor、ngStyle、ngClass 類型 Structural Directive: 修改 DOM 的結構 可以搭配 ng-container 不會產生額外的 DOM 元素，可以用在想要用 ngIf 和 ngFor 但不想產生額外元素的情況 *ngFor let item of items; index as i Attribute Directive: 修改 DOM 的屬性 Component Directive: 包含 template 的 directive Service 負責 API 請求、資料處理等工作 Dependency Injection @Injectable providedIn root: 全域共用 也可以在 component 的 providers 中設定要注入的 service Router 負責處理 URL 路由 routes path component guard ng g guard \u0026lt;guard-name\u0026gt; CanActivate CLI Command ng new my-app: 建立新的 Angular 專案 ng serve: 啟動開發伺服器 ng build: 打包專案 generate ng generate module my-module: 建立新的 Module ng generate component my-component: 建立新的 Component --module=app: 指定 Component 所屬的 Module ng generate service my-service: 建立新的 Service ng generate pipe my-pipe: 建立新的 Pipe ng generate directive my-directive: 建立新的 Directive Module NgModule declarations: 定義同一 Module 中的 Component、Directive、Pipe imports: 匯入其他 Module providers: 定義 Service bootstrap: 定義啟動的 Component exports: 定義要匯出的 Component、Directive、Pipe Component 包含元素 Template TypeScript Class .spec.ts: 測試檔 Selector: 定義 Component 的名稱 CSS Style standalone 新版 Angular 預設 app 使用 Standalone 模式，使 component 不再需要透過 NgModule 管理 Lifecycle Hooks ngOnChanges 當 Angular 重新綁定輸入屬性時調用 ngOnInit 當 Angular 初始化指令/元件時調用 在第一輪 ngOnChanges 後調用 只調用一次 使用場景 初始化資料（需要根據 @Input 變數） fetch data from API ngDoCheck 在 ngOnChange 和 ngOnInit 之後調用 ngAfterContentInit 在 Angular 把 ng-content 投影到 view 後調用 在第一個 ngDoCheck 之後調用 ngAfterContentChecked 在 ng-content 的內容變更後調用 ngAfterViewInit 在 Angular 初始化完 view 後調用 ngAfterViewChecked 在每次做完 view 的變更檢查後調用 ngOnDestroy 在 Angular 銷毀 directive/component 前調用 Component check 操作 update child component input binding update DOM interpolation update query list Sharing Data @Input 父元件傳遞資料給子元件 @Output 子元件傳遞資料給父元件 Binding Property Binding 用來設定 HTML 元素的屬性 用中括號 [] 包住屬性名稱 ex: \u0026lt;img [src]=\u0026quot;imageUrl\u0026quot;\u0026gt; Event Binding 用來設定 HTML 元素的事件 用小括號 () 包住事件名稱 ex: \u0026lt;button (click)=\u0026quot;onClick()\u0026quot;\u0026gt; $event: 可以取得事件物件 Two-way Binding 把屬性和事件綁定在一起 用中括號和小括號 [(ngModel)] 包住屬性名稱 ex: \u0026lt;input [(ngModel)]=\u0026quot;name\u0026quot;\u0026gt; ","date":"2024-05-24T00:00:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/angular-%E7%AD%86%E8%A8%98/","title":"Angular 筆記"},{"content":"Spring IoC Invocation of Constructor 把物件交給 Spring 管理 loose coupling Dependency Injection Bean 給 Spring 管理的物件 創建方法 @Component 創建出的 Bean 名字是 class 的開頭轉小寫 注入方法 @Autowired 種類 field injection spring boot 會先建立所有 component，在逐一注入，使元件可能短暫處於初始化不完整狀態 constructor injection 建立 bean 時就注入 確保 component 被使用時是處於完整的狀態 有利於 unit test，因為可以把設計好的 mock bean 從 constructor 傳入 spring 建議使用 constructor injection 限制 該 Class 也得是 Bean 會根據類型注入 bean 如果同時有多個同類型的 bean，會報錯，可以用 @Qualifier 指定要注入的 bean 名稱 @Qualifier 指定要注入的 bean 名稱 @Primary 如果有多個同類型的 bean，會優先注入這個 bean 初始化 @PostConstruct 創建 bean 後，就會執行這個方法 限制 必須是 public void 不能有參數 AOP Aspect Oriented Programming 透過 Aspect 統一處理不同方法的共同邏輯 要導入 aop 的 starter 只有 Bean 才能設置 @Aspect Annotation @Aspect 這個 class 是一個切面 @Before 加上切入點，就可以在切入點 (Pointcut) 的方法執行前執行 @After 在方法之後執行 @Around 在方法之前和之後都執行 常用的功能都已經被封裝好了，開發較少用到 AOP 特性 Starter Spring Boot Starters 官方的 starter 命名是 spring-boot-starter-* 第三方的 starter 命名是 *-spring-boot-starter\n外部化配置 application.properties 重新啟動 jar 時會自動載入，不用改配置要重新 build jar 集中管理 @Value 可以注入到變數中 可以用 : 來設定預設值 限制 只能在 Bean 和 Configuration 中使用 YAML application.properties 寫多後，沒有層級辨識度 application.yml profiles 可以根據不同的環境來設定不同的配置 (dev, test, prod) application-{profile}.properties application-{profile}.yml spring.profiles.active 指定啟用的 profile jar -Dspring.profiles.active=dev 指定配置文件 cli --spring.config.location Config 資料夾 可以在 jar 目錄下建立 config 資料夾，放配置文件，不用輸入額外的 args Dependency Management parent 寫了版本號，故 dependency 可以不用寫版本號 真的要指定的話，可以利用 maven 的就近原則 Auto Configuration Component Scan Spring Boot 會掃描主程式所在的 package 以及子 package 也可以在主程式上加以下註解來指定掃描的 package @SpringBootApplication(scanBasePackages = \u0026quot;com.example\u0026quot;) 所有 starter 都有 spring-boot-starter，spring-boot-starter 又有 spring-boot-autoconfigure，這個就是自動配置的地方 spring boot 默認掃描不到 spring-boot-autoconfigure 的所有配置類 (因為預設只掃描 Main Application Class 的 package)，但是 @SpringBootApplication 的 @EnableAutoConfiguration 會預設掃描 spring-boot-autoconfigure 的所有配置類 它們再依據 conditional annotation 來決定是否要啟用這個配置類 Common Annotations Spring Boot 放棄了 XML 配置，改用 Annotation 配置\nComponent registration @Configuration, @SpringBootConfiguration @Bean @Controller, @Service, @Repository, @Component 三層式架構 @Controller 用來處理請求 @Service 用來處理業務邏輯 @Repository 用來處理資料庫操作 @SpringBootApplication 由以下組成 @SpringBootConfiguration @EnableAutoConfiguration @ComponentScan Web @RestController @Controller + @ResponseBody @RequestMapping 設置 route Method @GetMapping @PostMapping @PutMapping @DeleteMapping @PatchMapping 取得參數 @RequestParam 取得 url 中的參數 @RequestBody 取得 request body 根據欄位名字調用對應的 setter @RequestHeader 取得 header @PathVariable 取得 route 中的參數 @Scope mode singleton 預設，共用一個 instance prototype 每次注入都創建新的 instance 可以用 proxy.mode = ScopedProxyMode.TARGET_CLASS，會變成每次調用 method 都創建新的 instance prototype 的元件生出後，spring 不會再管理，要自己管理生命週期，相當於 new 出物件的替代作法 request 每個 request 都有一個獨立的 instance request 指的是 HTTP request，從進入 controller 到離開 controller Conditional Annotations 條件成立則觸發指定行為 ConditionalOn example ConditionalOnClass 如果 classpath 有指定的 class 才會觸發 ConditionalOnMissingClass 如果 classpath 沒有指定的 class 才會觸發 ConditionalOnBean 如果容器中有指定的 bean 才會觸發 ConditionalOnMissingBean 如果容器中沒有指定的 bean 才會觸發 Scenario 如果有某個 dependency，則創建某個 bean Property Binding 把任意 Bean 的 property 與配置文件 (application.properties) 中的 property 綁定 annotations @ConfigurationProperties prefix @EnableConfigurationProperties 如果 class 只有 @ConfigurationProperties，沒有 @Component，需要加這個 annotation 用在第三方 package 上，因為默認掃不到第三方的 @component Logging Logging 選擇\nLogging API JCL SLF4J (Simple Logging Facade for Java) jboss-logging Logging implementation Logback Log4j2 JUL (java.util.logging) Spring Boot 預設使用 Logback 和 SLF4J spring-boot-starter 引用了 spring-boot-starter-logging\nLog Format Default example 1 2024-05-06T19:21:40.751+08:00 INFO 22932 --- [demo] [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat started on port 8080 (http) with context path \u0026#39;\u0026#39; 時間, 日誌等級, pid, 分割符, thread, logger, message Log Level Type (由低到高) ALL TRACE 一般不用 DEBUG INFO WARN ERROR FATAL OFF 會 print 出比設定的等級高的 log Log Configuration logging.level.*\n設定不同 package 的 log 等級 1 logging.level.com.example=DEBUG logging.group.\n把多個 package 放在一組，可以統一設定 預設有 web, sql 組 logging.file\n.name 檔名 歸檔 and 切割\n歸檔 每天單獨存 .logback.rolllingpolicy.file-name-pattern 切割 超過指定大小就切割 .logback.rolllingpolicy.max-file-size Filter 實做 javax.servlet.Filter，就能註冊為 spring 的 filter OncePerRequestFilter 保證一次 request 只會執行一次 doFilterInternal chain.doFilter(request, response) 這行之後代表後面的 filter 都執行完了 如果只有一個 filter，就代表 controller 執行完了 shouldNotFilter 可以設定不要執行的 url pattern 註冊 Filter 流程\n設定 @Configuration 加到 Bean 如果 filter 要取得 request 和 response 的內容，可以用 ContentCachingRequestWrapper 和 ContentCachingResponseWrapper 重新包裝\n因為原本的作法是用 stream 讀取資料，只能讀一次 @WebFilter\n屬於 Java servlet 而非 Spring 要在 application 補上 @ServletComponentScan 可以直接註冊 filter Spring Security 名詞 Authentication 認證 檢查是不是系統的使用者，以及是哪個使用者 Authorization 授權 檢查使用者有沒有權限做某件事 流程 filter chain\nexample UsernamePasswordAuthenticationFilter 檢查使用者名稱和密碼 ExceptionTranslationFilter 處理例外 FilterSecurityInterceptor 檢查授權 authorizeHttpRequests 設定哪些 request 需要什麼權限 example: JWT 驗證流程\n先透過 filter chain 經過 JWT filter 透過 UserDetailsService 取得使用者資訊 驗證使用者資訊 更新 SecurityContextHolder 用來判斷使用者是否已經通過 authentication Configuration @EnableWebSecurity 啟用 web security example 1 2 3 4 5 6 7 8 9 10 11 12 @Configuration @EnableWebSecurity public class SecurityConfig { @Bean public SecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception { http.authorizeHttpRequests((requests) -\u0026gt; { ((AuthorizeHttpRequestsConfigurer.AuthorizedUrl)requests.anyRequest()).authenticated(); }); http.httpBasic(Customizer.withDefaults()); return (SecurityFilterChain)http.build(); } } 把 Spring Boot 預設實作的 fitler chain 的 @Order 拿掉，這是決定誰的優先序高 也把 formLogin 拿掉，就不會有登入頁面 UserDetails 實現 UserDetailsService 的 Bean 可以被用來取得 UserDetails implements UserDetails getAuthorities getUsername getPassword isAccountNonExpired isAccountNonLocked isCredentialsNonExpired isEnabled SecurityContextHolder 用來存放 authentication JPA Java Persistence API Annotation @Entity, @Table 也要記得寫 getter, setter @Transient 不會被序列化，不會被存到資料庫 可用在可以單獨計算的欄位，比如用資料庫的生日可以算出年齡 @Transactional 語法範例 findByXxx 用 XXX 的欄位來查詢 findByXXXLike 用 XXX 的欄位來模糊查詢 Repository @Repository 用來標記 DAO extends JpaRepository\u0026lt;Entity, ID\u0026gt; 第一個參數是 entity 第二個參數是 entity 的 id 的型態 可以自定義方法 遵循命名規則，他會自己轉 SQL 也可以用 @Query 來自定義 SQL Validation field validation\n@NotEmpty @Min @Max @Valid\n用在 controller 上，才會自動檢查參數 Testing Integration Test 在 test class 前面的 annotation @RunWith(SpringRunner.class) @SpringBootTest @AutoConfigureMockMvc 測試開始時會在容器中創建 MockMvc 在 test method 前面加的 annotation @Test @Before, @After 在每個測試前後執行，可以用來清空資料庫和設置 header MockMvc 用來模擬 HTTP request example 1 2 3 4 5 6 7 8 9 @Autowired private MockMvc mockMvc; @Test public void test() throws Exception { mockMvc.perform(get(\u0026#34;/hello\u0026#34;)) .andExpect(status().isOk()) .andExpect(content().string(\u0026#34;Hello World\u0026#34;)); } 其他 Lombok @Getter, @Setter 生成 getter, setter @ToString 印出所有變數 @EqualsAndHashCode 生成 equals, hashCode Args @NoArgsConstructor 生成無參數建構子 @AllArgsConstructor 生成所有參數建構子 @RequiredArgsConstructor 只幫 final 變數生成建構子 @Data 同時用 @Getter, @Setter, @ToString, @EqualsAndHashCode, @RequiredArgsConstructor @Value 把所有變數都設成 final 同時用 @Getter, @ToString, @EqualsAndHashCode, @RequiredArgsConstructor 和 Spring boot 的 @Value 撞名 @Builder 生成 builder pattern @Slf4j 生成 log 變數 Jackson ObjectMapper 用來轉換物件和 JSON readValue 把 JSON 轉成物件 用 getter, setter 來判斷欄位 Annotation @JsonIgnore 不轉換 @JsonProperty 指定欄位名字 @JsonUnwrapped 把物件的欄位展開，從巢狀變成平面 @JsonInclude 設定要不要轉換 null 如果設定為 Include.NON_NULL，給 null 的話，就不會轉換 @JsonFormat 設定日期格式 ","date":"2024-05-06T00:00:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/spring-boot-%E7%AD%86%E8%A8%98/","title":"Spring Boot 筆記"},{"content":"paper: Memorizing Normality to Detect Anomaly: Memory-augmented Deep Autoencoder for Unsupervised Anomaly Detection\nAbstract autoencoder 在收到異常輸入的時，預期會生出較高的 reconstruction error。但是這個假設實際上並不總是發生。他有可能「泛化」的很好，導致異常的也可以正常重建。\n為了緩解這個問題，本文幫 auto-encoder 加上一個 memory 的機制。\n訓練階段，memory 要學習生成 normal data 的 prototypical elements。\n測試階段，learned memory 會被固定住，然後要根據 few selected memory 進行重建。\n對於異常輸入，這個重建出的東西就會比較像是 normal sample。這樣 reconstruction error 就會被增強。\nMemAE 是 free of assumption，所以可以用在各種不同的任務上。\nIntroduction AE 有可能「泛化」的很好，導致對於異常輸入也可以正常重建。如果 anomolies 和 normal pattern 有共享某些 composition pattern，或是 decoder 強到連 abnormal encoding 都可以重建，就可能發生這樣的狀況。\nMemAE 多了一個 memory module，從 encoder 出來的東西會被視作 query，用來把 memory 中最相關的元素取出，然後作 aggregation。\n作者還進一步提出了一個不同的 hard shrinkage operator，可以生出 sparsity of memory addressing weight。\n在訓練階段，會把 memory content 連同 encoder 和 decoder 一起訓練，透過 sparse addressing strategy，MemAE 可以有效地利用有限的 memory slot 來製造出 prototypical normal patterns，來製造出夠低的 reconstruction error。\n在測試階段，memory content 會被固定住，然後根據 few selected memory 來重建。因為 memory module 並不是基於某種特定資料的假設，所以可以用在各種不同的任務上。\nMemory-augmented Autoencoder Memory Module with Attention-based Sparse Addressing Attention for Memory Addressing attention weight $w_i$ $w_i=\\frac{exp(d(z,m_i))}{\\sum^{N}_{j=1}exp(d(z,m_j))}$ $d(\\cdot, \\cdot)$ 是 similarity measurement，這裡是 cosine similarity $d(z,m_i)=\\frac{zm_i^T}{||z|| \\text{ } ||m_i||}$ Hard Shrinkage for Sparse Addressing hard shrinkage $\\hat{w}_i=h(w_i;\\lambda)=\\begin{cases} w_i \u0026amp; \\text{if } w_i\u0026gt;\\lambda \\\\ 0 \u0026amp; \\text{otherwise} \\end{cases}$ 這東西不好做 backpropagation 改良版 $\\hat{w}_i=\\frac{max(w_i-\\lambda,0)}{|w_i-\\lambda|+\\epsilon}$ $max(\\cdot, 0)$ 就是 ReLU 根據實驗，把 $\\lambda$ 設在 [1/N, 3/N] 會得到還不錯的結果 shrinkage 後會再 normalize $\\hat{w}_i=\\hat{w}_i/||\\hat{w}||_1$ Sparse addressing 有助於鼓勵模型用更少但相關的 memory item 來表示 query。\n鼓勵 memory addressing 的 sparsity 是有益的，因為 memory M 被訓練來適應 sparse w。\n鼓勵 sparsity 也可以緩解異常樣本可以被很好的重建的問題。\nTraining 分成兩個 loss Reconstruction error $R(x^t, \\hat{x}^t)=||x^t-\\hat{x}^t||^2_2$ $l2-norm$ entropy of $\\hat{w}^t$ 用來進一步提升 sparsity $E(\\hat{w}^t)=\\sum^{T}_{i=1}-\\hat{w}_i \\cdot log(\\hat{w}_i)$ Combine $L(\\theta_e, \\theta_d, M)=\\frac{1}{T}\\sum^{T}_{t=1}(R(x^t, \\hat{x}^t)+\\alpha E(\\hat{w}^t))$ 根據實驗，$\\alpha$ 設成 0.0002 ","date":"2024-04-30T00:00:55+08:00","permalink":"https://roykesydon.github.io/Blog/p/memae-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"MemAE 論文閱讀"},{"content":" 有關名詞\n扇區: 最小的儲存單位 block: 一次讀取的最小單位，是多個連續的扇區 inode OS 用來記錄檔案的 metadata 每個文件的 inode number 是唯一的 可以用 ls -li 來看 inode number inode data 檔案的大小 擁有者 擁有者的 group 權限 修改時間 文件的實體指針，指向 block 格式化分區\n主分區 擴展分區 邏輯分區 默認分區 1~4 給主分區和擴展分區，邏輯分區從 5 開始 /dev/sda1、/dev/sda2 這種就是分區 fdisk\n小於 2TB 的磁碟，可以用 fdisk，但是大於 2TB 的磁碟，要用 parted，且要用 GPT fdisk -l 列出所有分區 fdisk /dev/sda 進入 fdisk n 新增分區 再設置 sector 的起始位置和結束位置 d 刪除分區 t 更改分區的 system id w 寫入並且離開 parted\nparted /dev/sda 進入 parted mklabel gpt 可以把 disk 轉成 GPT GPT 區分主分區和邏輯分區 mkpart primary \u0026lt;start\u0026gt; \u0026lt;end\u0026gt; 創建一個 primary partition，從 start 到 end (MB) 軟硬連結\n軟連結 ln -s \u0026lt;source\u0026gt; \u0026lt;destination\u0026gt; 如果刪除軟連結的檔案的話，不會影響原本的檔案 源文件刪除後，軟連結失效 支持資料夾 支持跨文件系統 硬連結 ln \u0026lt;source\u0026gt; \u0026lt;destination\u0026gt; 一般情況，inode 和檔案名稱是一對一的關係 軟連結 inode 號碼是不一樣的，代表是兩個個體，硬連結 inode 號碼是一樣的 刪除硬連結對源文件沒有影響 刪除源文件對硬連結沒有影響 但是如果刪除所有硬連結，文件的連結數變成 0，則文件會被刪除 不能對資料夾使用 不能跨文件系統 mkfs\n對分區進行格式化文件系統 fsck\nfile system check 檢查和修復文件系統 lsblk\nlsblk -f 列出所有分區的文件系統 vfs\nvirtual file system linux 可能有多種文件系統，在上面有一層 vfs，讓所有文件系統都可以通過一個統一的接口來訪問 Mount\n設備要 mount 才可以使用，給設備提供一個出入口 mount -l 列出所有已經 mount 的設備 -t 指定文件系統，不指定的話，會自動判斷 -o 一些有關於 mount 的參數 async 非同步讀寫，效率高，但是喪失安全性 sync 同步讀寫，效率低，但是讀寫安全 atime/noatime 是否要紀錄文件的訪問時間 -r read-only LVM\nlogical volume manager 把一個或多個硬碟在邏輯上進行合併，可以動態調整大小 硬盤的多個分區，由 LVM 統一管理為 volume group 名詞 PP: physical partition PV: physical volume 通常一個 PV 對應一個 PP PE: physical extends PV 中可以分配的最小單位，同一個 VG 中，所有 PV 的 PE 大小都是一樣的 VG: volume group 創建在 PV 上，可以劃分成多個 PV LV: logical volume 創建在 VG 上，可以動態擴容的分區 LE: logical extends LV 中的基本單位，一個 LE 對應一個 PE 創建 PP 階段 用 fdisk 格式化，修改 system id 為 8e (預設是 83) PV 階段 用 pvcreate, pvdisplay 把 linux 分區轉成 PV 指令 pvcreate /dev/sda /dev/sdb: 把 sda 和 sdb 轉成 PV 適用硬碟和分區 pvs: 查看 PV VG 階段 用 vgcreate, vgdisplay 創建 VG 指令 vgcreate vg1 /dev/sda /dev/sdb: 創建 VG vg1，用 sda 和 sdb vgs: 查看 VG vgextend vg1 /dev/sdc: 把 sdc 加入 vg1 vgdisplay: 查看 VG LV 階段 用 lvcreate, lvdisplay 創建 LV 把 VG 分成多個 LV 也要幫 LV 創建文件系統 指令 lvs: 查看 LV lvextend -L +1000G /dev/vg1/lv1: 把 lv1 增加 1000G ex4 可以不用 umount 還要 resize2fs /dev/vg1/lv1 來調整文件系統大小 可以用 df -h 來檢查 ","date":"2024-04-24T00:00:43+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E7%A3%81%E7%A2%9F%E7%AE%A1%E7%90%86/","title":"磁碟管理"},{"content":"paper: ReALM: Reference Resolution As Language Modeling\nAbstract Reference resolution 是一個重要的問題，對於理解和充分處理不同類型的 context 很重要。\nContext 包含 previous turns 和 non-conversational entities，比如使用者螢幕上的 entity，或是在背景執行的 entity。\nLLM 雖然在各種任務都很強大，但對於 reference resolution 的使用，特別是 non-conversational entities 方面，依然沒有充分利用。\n本文將展示如何引用 LLM 創建一個系統來處理不同類型的 reference，方法是展示如何把 reference resolution 轉換成 language modeling problem。 盡管螢幕上的 entity 傳統上不利於簡化成 text-only modality。\n對於 GPT-4，本文最小的模型實現了和 GPT-4 相當的性能，而更大的模型則大幅領先。\nIntroduction 人類的語言很長包含 ambiguous reference，比如「這個」、「那個」等等，這些 reference 需要根據 context 來解決。\n能夠能夠理解 context 對 conversational assistant 來說很重要。\n讓使用者能夠對螢幕上看到的內容發出查詢是確保語音助理可以提供 hands-free 體驗的第一步。\nSpeaker Dialogue User Show me pharmacies near me Agent Here is a list I found. Agent \u0026hellip; (list presented) User Call the one on Rainbow Rd. User Call the bottom one. User Call this number (present onscreen) Table 1: Sample Interactions between a user and an agent.\n以 Table 1 為例，如果沒有理解 context 的能力，agent 不可能完成查詢。\n照理來說，處理用戶的查詢需要多種類型的 context，Conversational context 和 on-screen context 就是兩個主要的例子。\n最近的 LLM 通常可以實現 End-to-End 的體驗，甚至可能可以消除包含 reference resolution 的多階段 piepline。\n但是在一些實際案例中，pipeline 有他的價值，考慮以下情境：\n在運算能力有限的設備上運作 (例如手機)\n由於功耗和延遲需求，單一大型 End-to-End 模型可能不適用。 需要與 API 整合的情境\n雖然存在可以用 LLM 編寫呼叫 API 的方法，但依然需要超大的模型還有對現有 pipeline 的徹底處理。 使用 focused model 可以允許現有的 reference resolution module 替換成更新的版本，而且由於系統是模組化的，可以改進能力和可解釋性。\n對於本文所考慮的任務，reference resolution 不只限定於 conversational context，還包含 on-screen entities，這些 entities 是使用者可以感知到的一部份，但是還未出現在對話歷史紀錄中。\n因此，盡管一些 LLM 可以 implicit 地處理 reference resolution，但是傳統的 NLP 任務 (比如 reference resolution) 仍然有價值。\n因此本文提倡用較小的語言模型，但針對 reference resolution 進行了專門且明確的 fine-tuning。\n然而這種語音助理會遇到最大的挑戰就是要怎麼讓 LM 「看」到螢幕。而且還要以有利於 LM 解析的方式對螢幕上的 entity 進行編碼，然後編碼還得足夠一致，讓 LM 可以成功執行 reference resolution。\n本文建議使用使用 parsed entity 及其位置來重件螢幕，以產生螢幕的純文字表示。\n然後螢幕上屬於 entity 的部分會被標記，以便 LM 能夠了解實體出現的位置及他們周圍的文字。\n據作者所知，這是第一個目標是從螢幕 encode context 的 LLM 工作。\nRelated Work and Motivation 解析螢幕上的 reference 是一個目前探索比較不足的領域。\n螢幕上的東西通常更加結構化和高度文字化，使的可以利用更輕的模型來轉換成文字。但雖然容易解析，分布和那種大型育訓練的基於圖像的系統不同，因為他們多半都用自然的現實圖片。\n此外那些模型的訓練成本通常都非常高，而且在這種大量文字的情境也表現不佳。 常用於文字理解的方法又常常依賴多個模組，比如 bounding box detection 和 OCR。\n聯合視覺 + 文字的模型在計算成本也更加昂貴。\n對於螢幕上的參考有一些相關工作，被用作本文的 baseline。\n然後他們有些缺點，在本文解決了這些缺點。\n他們的方法依賴專用的 「Category Module」來處理 type-based reference，每次建立新類型，都需要手動加入 Entity 此類 Module 將每種類別視為不同的，忽略了他們的相似性 依賴手工製作的規則，往往需要大量特徵工程，而且不 robust 不考慮語意相似性，也沒法對現實的理解和常識進行推理 這些方法會獨立地判斷實體和 Query 的關聯性，而不考慮其他所有的實體，查詢既不考慮整個螢幕也不考慮其他實體 Task 作者提了三種和使用者相關的 Entity:\nOn-screen Entities Conversational Entities 可能是來自上一輪的對話，也可能是 virtual assistant 產生的 Background Entities 來自後台 process 的相關實體，使用者不一定在螢幕上看的到，比如背景的音樂 本文將 reference resolution 作為 LLM 的 multiple choice task，預期輸出是用戶螢幕上顯示的其中一個 Entity。\n答案也可能是「None of these」。\nDatasets 每筆資料包含使用者查詢和 Entity list，還有與對應使用者查詢相關的 ground truth entity。\n每個實體又包含與其相關的訊息，比如與實體關聯的名稱和其他文字描述訊息。\n對於存在 on-screen context 的資料，context 以 Entity 的邊界框，圍繞它的物件清單還有周圍物件的屬性 (比如類型、文字內容、位置) 來提供\nDataset Train Set Test Set Conversational 2.3k 1.2k Synthetic 3.9k 1.1k On-screen 10.1k 1.9k Table 2: Dataset Sizes (Train Set and Test Set)\nConversational Data 收集使用者和 agent 的相關資料。\n評分者會看到帶有所提供 Entity 清單的截圖，並要求提供引用清單中任意挑選的 Entity 的 Query。\n比如，可能會給使用者看企業清單，使用者可能會說「Call the one on Main Street」。\nSynthetic Data 透過 template 去合成資料。\n有兩種 template:\nBase Template 包含 mentions, entities, possible slots Language Template 除了 Base 還會新增不同變體的 query On-screen Data 從存在電話、電子郵件和實際地址的各種網頁蒐集的。\n進行兩階段的 annotation：\n根據螢幕 extract query 評分者會收到一張帶有綠色方框和紅色方框的截圖，要把綠方框方類為電話、電子郵件或地址等等 然後要為綠框提供三個獨特的 query 根據 query 識別 entity 和 mention 前面蒐集的 query 會被一一展示給評分者，並帶有相應的截圖，但沒有 bounding box，還會提供所有 screen entity list 評分者要評估 query 是否包含給定的 visual entity，還有聽起來自不自然 此外，評分者還要從清單中選出 query 提及的 entity，還要標記它們在 query 的哪裡 Models MARRS 這個是 baseline，非 LLM，和前人的方法去做比較。\n前人的方法著重於螢幕上的 entity，MARRS 也傾向於 conversational 和 background entities。\n要注意的是，和其他通用的 LLM 相比，作者的 baseline 是專門為了 reference resolution 而設計的。\nChatGPT 作者考慮 GPT-3.5 和 GPT-4 作為另外一個 baseline。\n對於 GPT-3.5，輸入只包含 prompt。\n對於 GPT-4，因為他可以接受圖片的 context，所以為系統提供了螢幕截圖，發現可以有效提高其效能。\nOur Approach 作者遵循以下 pipeline 來微調模型 (FLAN-T5)\n向模型提供解析後的輸入，並用來微調。\n和 Baseline 不同，作者沒有在 FLAN-T5 上進行大規模的超參數搜索，而是堅持使用預設的參數。\nConversational References 作者假設 conversational references 有兩種：\nType-based 這種非常依賴要將 query 和 entity type 結合，好進行識別 比如「打給他」，可以知道要的是電話號碼，而不是地址 Descriptive 傾向於用唯一的實體屬性來標記他，比如「時代廣場的那個」 referenece 通常會同時依賴 type 和描述，比如「play the one from Abbey Road」和「directions to the one on Abbey Road」。\nOnscreen References 作者假設存在能夠解析螢幕文字以提取 Entity 的上游資料偵測器。\n為了以僅涉及文字的方式將其編碼到 LM 中，使用 Algorithm 2。\n直觀上，假設所有實體和周圍物件的位置都可以用它們各自的邊界框的中心來表示。\n然後從上到下對這些中心進行排序，並用 stable sort 從左到右排序。\n然後，所有在一個 margin 內的物件都會被視作在 same line，並用 tab 隔開。\n在 margin 下方外面的會被放在下一行，然後不斷重複。\nResults Model Conv Synth Screen Unseen MARRS 92.1 99.4 83.5 84.5 GPT-3.5 84.1 34.2 74.1 67.5 GPT-4 97.0 58.7 90.1 98.4 ReALM-80M 96.7 99.5 88.9 99.3 ReALM-250M 97.8 99.8 90.6 97.2 ReALM-1B 97.9 99.7 91.4 94.8 ReALM-3B 97.9 99.8 93.0 97.8 Table 3:\n預測正確的標準是要正確預測所有相關實體，不然就是錯的\n作者發現它們的方法贏 MARRS 和 GPT-3.5。 GPT-3.5 的餐數量還多出了幾個數量級。\n盡管模型相較 GPT-4 輕的多，但是性能大致相同。\n而且作者採用文字編碼的方法能夠讓模型和 GPT-4 幾乎同等效能，後者還提供了螢幕截圖。\n隨著模型加大，提升也很明顯，特別是 Screen，暗示任務本質上更加複雜。\nAnalysis $GPT-4 \\approx ReALM \u0026raquo; MARRS$ for new use-cases 測試了 zero-shot learning 的能力，Table 3 最後一個 column 就是在比較從未見過的資料集。 作者發現對於測試集，所有 LLM-based 的方法都贏過 Fine-tuned Model ReaLM \u0026gt; GPT-4 for domain-specific queries 作者發現 ReALM 因為有對 user requests 做 fine-tuning，所以更能理解 domain-specific questions，如下表 (Table 4) 1 2 3 4 5 6 7 User Request: Can you make it brighter? --- Entities Shown to User: 1. Type: Settings 2. Type: UserEntity | homeAutomationAccessoryName --- GPT-4 Prediction: 1 Ground Truth: 1, 2 Table 4\n","date":"2024-04-18T00:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/realm-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"ReALM 論文閱讀"},{"content":"paper: Exploiting Structural Consistency of Chest Anatomy for Unsupervised Anomaly Detection in Radiography Images\n個人前言 這篇文章提出了許多在 SQUID 論文有出現過的的內容，特別是有關於放射線成像的描述等等，建議先看過 SQUID，重複的論點不再提及。\nAbstract 提出一種簡單的 Space-aware Memory，用於修復放射線成像的異常。\n將異常檢定制定為 image reconstruction task，用 space-aware memory matrix 和 in-painting block 組成。\nRelated Work Our Previous Work 相對於 SQUID，本文有以下四點改進：\n引入了新的符號、公式和圖表，以及詳細的方法說明及學習目標 刪除 Memory Queue 和 Masked shortcut，簡化框架，還提高了效能 在三種放射線成像任務勝過其他 21 種 SOTA 方法 研究了 SimSID 對於 desease-free (訓練集中對異常資料的容忍) 的穩健性 SimSID Developing Space-aware and Hierarchical Memory Space-aware memory $\\hat{z}_{i,j}$ (augmented feature)\n$=\\displaystyle\\sum^N_{k=1}G(s^{k})M^k_{i,j}$\n$s^k$ 是做內積算出來的相似度\n$G(\\cdot)$ 是 Gumbel-softmax (用 SQUID 的 Gumbel Shrinkage)\n$Memory Matrix$ 被拆成多個 block，才有 $M_{i,j}$\nHierarchical memory 在 encoder 最深處使用一個 memory matrix (in-painting block) 不足以重建具有細節的高品質圖像。\n為了捕捉不同尺度的 anatomic patterns，提出在 generator 的多個 level 放置 space-aware memory。\n研究發現，太多的 memory 會導致過度的 information filtering，還會 degrade 模型，導致他只會保留最具代表性的 normal pattern，而不是所有需要的 pattern。\n這個問題可以透過添加 skip connection 來解決。\n從經驗發現三個 memory matrix 就已足夠。\nResults Benchmarking SimSID on Three Public Datasets 對於正常的情況， SimSID 可以在 memory 中找到相似的匹配，然後順利重建。\n對於異常，將偽造的正常特徵強加到異常特徵，就會產生矛盾。\n圖 7 繪製 Discriminator 的 heatmap 來指示出重建效果不佳的部分。\n","date":"2024-04-13T00:27:55+08:00","permalink":"https://roykesydon.github.io/Blog/p/simsid-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"SimSID 論文閱讀"},{"content":"paper: SQUID: Deep Feature In-Painting for Unsupervised Anomaly Detection\nAbstract Radiography imaging protocols (放射線成像協定) 會專注於特定的身體區域，因此會在患者間產生大量相似的照片。\n為了利用這種 structed information，作者提出了 Space-aware Memory Queues for In-painting and Detecting anomalies from radiography images (SQUID)，它可以把固有的人體結構分類為反覆出現的 pattern。\n在推理狀態下，它可以識別圖片中的異常情況。\n比較兩個 chest X-ray benchmark，SQUID 在非監督異常檢測上超越了 13 種 SOTA 方法至少 5 個百分點。\n作者還創建了一個新的資料集 (DigitAnatomy)，該資料集結合了胸腔解剖學中的 spatial correlation 和 consistent shape 這兩個特性。\nIntroduction 放射線成像和一般圖片的差別 一般的 photographic imaging 和 radiography imaging 是不同的。一般的圖片物體，我們會假設 translation invariance (平移不變性)，無論貓在左右，都是貓。但是在放射線成像中，結構的相對位置和方向是辨別正常和異常的重要特徵。 而且由於 radiography imaging protocols 以相當一致的方向評估患者，成像在不同的設備製造商、設施位置還有患者的情況下，都具有很大的相似性。像這樣反覆出現且一致的結構，有助於分析問題，是放射線成像的優勢。 有多項研究證明了許多先驗知識在增強深度學習模型性能上的優勢，比如添加 location features、修改目標函數還有約束相對於照片中 landmarks 的相對座標。\n想解決的問題\n多達 80% 的臨床錯誤是由於放射科醫生漏掉異常而造成。 本文想回答一個關鍵問題：有沒有辦法利用 anatomical patterns 的 consistency 和 spatial information，在沒有手動標註的情況下，加強深度學習模型的異常檢測能力？非監督的異常檢測只用健康的圖片進行訓練，不用疾病診斷或任何 label。 SQUID 解決辦法\n本文不像先前的異常檢測方法，本文把 task 制定為 in-painting task (圖像修復)，好利用放射線成像的外觀、位置、布局。\n作者提出了 SQUID，在訓練過程中，模型可以透過空間中經常出現的 anoatomical patterns 來動態維護一個 visual pattern dictionary。\n由於解剖學的 consistency，健康成像中的身體區域會呈現類似的 visual pattern，使 unique pattern 的數量是可控的。\n在推理階段，由於 dictionary 不存在 anomaly pattern，因此如果存在異常，產生的放射線成像會和現實有所差距。因此，模型可以透過區分修復任務的品質來識別異常。\n實驗假設\n異常檢測的成功基於兩個假設 資料中很少異常圖片 異常和正常有顯著不同 實驗\n在兩個大規模、公開的放射線成像資料集上實驗 ZhangLab 在非監督方面贏 SOTA 超過 5 個百分點 Stanford CheXpert 比最近的 13 種方法提高 10 個百分點 新資料集\n創建了 DigitAnatomy 資料集，闡明胸腔解剖結構的 spatial correlation 和 consistent shape。 貢獻總結\n在胸腔放射線成像的新非監督 SOTA 異常檢測方法 新的綜合資料集 發明新方法打敗主流非監督異常檢測方法 Related Work Anomaly detection in natural imaging 識別偏離正常資料分佈的罕見事件 由於異常樣本的缺乏，後來的工作都制定為非監督學習問題 大致分為兩類 reconstruction-based 恢復原始輸入並分析重建誤差 density-based 透過估計正常資料的分佈來預測異常 不過這些方法都沒辦法解釋可能的異常，本文透過維護 visual pattern memory 來解決這個問題 Anomaly detection in medical imaging 基於監督學習的方法多半用於檢測特定種類的異常，比如腫瘤 最近提出了一些無監督方法來檢測一般異常，和 GAN 有關，但是這些方法需要有關於異常種類的強大先驗知識和假設才能使增強有效 和一般的照片不同，Radiography imaging protocols 生成具一致性的圖片，異常的變化比較微妙 (subtle)，檢測起來更具挑戰，作者利用放射線成像的特性，大大提高檢測性能。 Memory networks 過往有一些有關於把 Memory modules 納入神經網路的研究，其中有採用到 Memory Matrix。本文克服了 Memory matrix 的侷限性，並提出一種有效且高效率的的 memory queue。 SQUID Overview Feature extraction\n把圖片切成 N x N 個 non-overlapping patches，然後餵入一個 encoder 做特徵提取，這裡是用 CNN 提取，但要用其他 backbone 也可以 Image reconstruction\n這裡會用 teacher 和 student generator teacher 直接用 encoder 的 feature 重建圖片 本質上是 auto-encoder 作為 regularizer 來避免 student generator 重複生成相同的正常圖片 student 使用 in-painting block 增強後的 feature 來重建，最後會被用在 discrimination 兩個 generator 會在每個 up-sampling level 用 knowledge distillation paradigm 來結合 Anomaly discrimination\n在 adversarial learning 後，使用 discriminator 來區分正常和異常 用 2 個 generator 來生成圖片，再用 discriminator 來區分，只有 student generator 會接收 discriminator 的梯度 Inventing Memory Queue as Dictionary Motivation Memory Matrix 被廣泛採用 Feature 會透過在 Memory matrix 做加權平均來強化 缺點 這樣的增強方法是對整張圖片的提出的特徵做的，丟棄了圖片中的 spatial information。導致他無法感知到放射線成像中的一致性結構 Space-aware memory 為了利用空間資訊，作者只將 patch 而不是整張圖片傳遞到 model，讓 patch 只能存取 Memory matrix 中對應到的區段，作者把這種策略稱為 Space-aware memory，而且還可以加快速度，因為不用存取整個 Memory matrix Memory queue 在 learning-based Memory matrix 中，normal patterns 是由 matrix 中的 learned basis 組合而成，但組合出來的東西和現實照片的特徵總會有分佈差距，使後續的影像生成變得困難 作者提出 memory queue，用來在訓練期間儲存真實的影像 feature，從而呈現和影像特徵相同的分佈。它在訓練期間會把先前看到的特徵直接複製到 queue Gumbel shrinkage 控制 memory matrix 中 activated pattern 的數量是有利的，但如果用 hard shrinkage threashold 會無法處理找不到合適 entry 的情況。一種自然的解法是讓梯度流過前 k 個相似的 entry，其餘的不更新。但這樣又會導致未啟動的 entry 無法接收任何梯度並更新，因此提出了 Gumbel shrinkage schema $w\u0026rsquo; = sg(hs(w,topk(w)) - \\phi(w)) + \\phi(w)$ $w$ 代表 feature 和 entry 的相似度 $sg(\\cdot)$ 代表 stop-gradient，不計算輸入的梯度 $hs(\\cdot, t)$ 代表 hard shrinkage，有個 threshold $t$ $\\phi(\\cdot)$ 代表 softmax 這樣保留了 top k 作為 w 的最終結果，又用 softmax 對所有 entry 進行更新 Formulating Anomaly Detection as In-painting Motivation\nImage in-painting 最初是用來恢復具有 neighboring context 的圖片區塊，因此根據此直覺，想把異常圖片修復成正常圖片來實現檢測 在修復像素的時候，特別是用深度網路，容易有 boundary artifacts，在 pixel 級別的修復中，這些 boundary artifacts 會導致大量誤報 artifact 中翻好像是「偽影」，就是重建的時候會呈現有點像棋盤的效應 作者選擇在 feature level 進行 in-painting，避開這問題 In-painting block\n會先把每個 patch $F_{1,1}$ ~ $F_{w,h}$ 都先找到最接近的 normal patterns $N_{1,1}$ ~ $N_{w,h}$ 因為 N 是之前訓練資料中提取的特徵組成的，不受當前輸入影像的影響。為了導入輸入圖片的特徵，作者把 F 和 N 用 transformer block 來結合 對於每個 patch $F_{i,j}$，會把其當作中心，用相鄰的 8 個 N patch 來重新定義 $F_{i,j}$，把這 8 個 N patch 作為 key 和 value，$F_{i,j}$ 作為 query 最後會在 in-painting block 的前後做 point-wise convolution (1x1) Masked shortcut\n實驗結果表明，直接做 residual connection 會降低修復的性能，作者採用 random binary mask 在 training 期間 gate shortcut feature $F\u0026rsquo;=(1-\\delta)\\cdot F + \\delta \\cdot inpaint(F)$ $\\delta$~$Bernoulli(\\rho)$ $\\rho$ gating probability 獲得 F\u0026rsquo; 後，原始的 F 會被更新進 memory 在推論階段，會 disable shortcut，使 $F\u0026rsquo;=inpaint(F)$ Anomaly Discrimination Discriminator 評估圖片現不現實，不現實表示異常 因為 Generator 只在正常圖片訓練，所以 Memory Queue 也只有 normal pattern 稍微總結 in-painting block 會把 patch 強化為相似的 normal feature student generator 會根據 \u0026ldquo;normal\u0026rdquo; feature 重建出 \u0026ldquo;normal\u0026rdquo; image 如果沒有異常的話，那 input 和重建的 image 在語意上應該相差很小 異常分數 $A$ 的算法 $A=\\phi(\\frac{D(G_s(E(I)))-\\mu}{\\sigma})$ $\\phi(\\cdot)$ 是 sigmoid function $\\mu$ 和 $\\sigma$ 是根據 training samples 算出的異常分數的平均值和標準差 Loss Function Generator $\\mathcal L_t = (I-G_t (E(I)))^2$ $\\mathcal L_s = (I-G_s (E(I)))^2$ Knowledge distillation $\\mathcal L_{dist} = \\sum_{l}^{i=1} (F^i_t-F^i_s)^2$ $l$ 是 levels of features Adversarial loss 類似 DCGAN $\\mathcal L_{gen} = log(1-D(G_s(E(I))))$ Discriminator $\\mathcal L_{dis} = log(D(I)) + log(1-D(G_s(E(I))))$ 把 real image 機率拉高，把 fake image 機率拉低 Total loss minimize generative loss $\\lambda_t \\mathcal L_t + \\lambda_s \\mathcal L_s + \\lambda_{dist} \\mathcal L_{dist} + \\lambda_{gen} \\mathcal L_{gen}$ maximize discriminative loss $\\lambda_{dis} \\mathcal L_{dis}$ Experiments New Benchmark 提出一個新資料集 - DigitAnatomy。。如果包含正確順序的阿拉伯數字 1~9 則視為正常，異常包括缺失、亂序、翻轉和 zero digit。\n該資料集對於放射線成像尤其有利，原因如下:\nspatial correlation and consistent shape 放射線成像要標記需要專業知識，但數字容易 debug 該資料集很容易就可以獲得模擬異常的 ground truth Public Benchmarks ZhangLab Chest X-ray 包含健康和肺炎的影像 訓練集 1349 張正常 3883 張異常 測試集 234 張正常 390 張異常 作者從訓練集隨機挑 200 張做為調整超參數的 validation set 影像都調整為 128x128 Stanford CheXpert 對 front-view PA 影像進行評估，共有 12 種異常 有 5249 張正常和 23671 張異常用作訓練 使用和 ZhangLab 相同的超參數 用訓練集的 250 張正常和 250 張異常進行測試 Baselines and Metrics 考慮 13 個主要的 baseline\n經典 UAD (unsupervised anomaly detection) Auto-encoder、VAE 醫學影像的 SOTA Ganomaly、f-AnoGAN、IF、SALAD 最近的 UAD MemAE、CutPaste、M-KD、PANDA、PaDiM、IGD 除非有特別註明，不然都是從頭獨立訓練至少三次\nResults Interpreting SQUID on DigitAnatomy 作者在 DigitAnatomy 的實驗中，故意注入異常到正常圖片中，測試模型是否可以重建正常圖片。\nSQUID 重建出的圖片比其他 baseline 有更多有意義的訊息，主要歸功於 space-aware memory，其產生獨特的 pattern，而且和空間訊息相關聯。\n一旦出現異常，in-painting block 會從字典中找出前 k 個相近的，把異常特徵增強到其對應的正常特徵，其他方法不具備此能力，所以他們重建出有缺陷的圖像。\nGAN 傾向於重建訓練樣本平均得到的影像。 MemAE 受益於 Memory matrix，表現較好，但對於缺失數字的異常效果不佳。\nBenchmarking SQUID on Chest Radiography Limitation 作者發現目前的 SQUID 沒辦法在像素層級精確定位異常。這可以理解，因為 SQUID 是一種非監督方法，不需要標註。\n那些像素級別的異常檢測會遭遇放大雜訊的影響，但是由於 SQUID 是在特徵層級進行的，比像素級別更加 robust。\nAblating Key Properties in SQUID Component study Hyper-parameter robustness Disease-free training requirement? 用於醫學異常檢測的非監督方法並不常見，因為所謂的 UAD 方法並不是「非監督」的，因為他們必須只在無疾病影像上作訓練。\n在實踐中，要獲得健康圖片需要 manual annotation。\n在訓練集中考慮 disease-free 從 100% - 50% 的情況，把 SQUID 的 robust 和另外三個 baseline 進行比較。\nSQUID 的 memory queue 可以自動忽略少數的 anatomical patterns。\n","date":"2024-03-31T00:27:55+08:00","permalink":"https://roykesydon.github.io/Blog/p/squid-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"🦑SQUID🦑 論文閱讀"},{"content":"Abstract 本文想在 manufacturing context 下開發一個 XR (extended reality) 架構，想用 XR 整合並改善傳統工作流程。\n該框架包含五個 iterative phase:\nRequirement analysis Solution selection data preparation system implementation system evaluation 此實驗也強調了 user-centered 的方法在開發有關製造業的 XR 系統的重要性。\nIntroduction 作者認為 XR 系統的整合對製造業的轉型很重要，有助於實現 Industry 4.0。\n盡管研究顯示 XR 在製造業中有巨大潛力，但工程師在日常生活中用 XR 的系統很少，顯示出整合 XR 到製造業是困難且具備挑戰性的。\n本研究想開發一個系統框架，支援未來 XR 系統在製造業的開發，而不是只停留在「wow effect」\nFrame of reference Extended Reality Classification 透過電腦實現的現實增強技術可以追溯到 1960s，在近年演變成多種子集，也因此產生不同術語，使人困惑。\n本文說的 XR 被用作總稱，代指所有以電腦為媒介的 Reality Technologies。\n區分不同系統的 XR 十分重要，這樣才能針對製造業中任何一個特定的應用作出正確的決策。\n一種常見的方法是 reality-virtuality continuum，把現實世界和虛擬世界放在兩端，根據靠近哪端進行區分。\n左端是現實世界，右端是虛擬世界。從左到右出現 augmented reality(AR)、mixed reality(MR) 和 virtual reality(VR)\nAugmented Reality (AR) 最廣泛的定義，有以下三個特徵 結合虛擬與現實 要可以 real-time 的互動 顯示在 3D 空間 用戶要依然可以看到周遭環境，並與之互動，同時獲得諸如文字或圖片的增強體驗 可透過 smart glass 或手機實現 Mixed Reality (MR) 可以定義為把現實世界和虛擬世界中的東西呈現在一起的應用程式，也就是 reality-virtuality continuum 上的任何位置 MR 比 AR 更進一步，不只希望虛擬物體疊加在現實世界上，還希望使用者可以像對待真實物體一樣和他們互動 為了實現 MR，需要一台整合了電腦、半透明玻璃、和感測器的耳機 某種意義上是更具沉浸感的 AR Virtual Reality (VR) 使用者完全沉浸在虛擬世界中，無法看到現實世界 有三種典型設定：獨立耳機、CAVE (房間是大型投影幕)、連接到電腦的頭戴式顯示器 最後一種已佔據主導地位 Hardware parameters for extended reality 深入了解硬體參數也很重要，會影響可用性\nField of View (FOV) 人類的 binocular FOV 大約是 114 度，XR 使用的螢幕具有類似的視野才會是理想的，確保用戶有無縫體驗 通常 AR 和 VR 的 FOV 會小的多，只有 30-60 度，每次呈現有限的虛擬內容，當需要渲染大型虛擬物件時就會有問題 由於 AR 和 MR 並不排斥現實世界，所以如果內容尺寸適當，不影響使用者感知 現今的 VR 頭戴裝置 FOV 大得多，落在 90-110 度之間 一些先進的模型甚至聲稱到 200 度，超過人類的 FOV 具有較小 FOV 的耳機會因為「tunnel vision effect」而分散用戶的注意力 Frame per Second (FPS) 對於 MR 或 AR，30-60 FPS 就足夠了，VR 則建議爭取到 90 由於使用者沉浸在電腦生成的內容，FPS 太低會導致 motion jitter，導致用戶產生 motion sickness FPS 不單由硬體決定，也由軟體決定 Software for extended reality 作者將其分為兩大類，基於「開放開發平台的方法」和基於「已有商業軟體的擴展方法」。開放式開發平台的優點是開發過程完全受控，可以根據個人需求訂製，但需要軟體工程方面的專業知識。\n當今製造業使用的成熟商業軟體也在擴大對 XR 功能的支援，因此，現有用戶可以毫不費力創建 XR 體驗。然而，使用此類軟體來探索 XR 新功能的自由度有限，因為它依賴軟體供應商的更新。\nOpen development platform 兩大主要平台是 Unity3D 和 Unreal Engine 4 Established commercial software 範例 Siemens 的 Plant Simulation 雖然缺乏更高程度的客製化自由度，但節省了創建通用功能的時間和成本 Research Approach 本文為了開發一個可以提高未來 XR 系統的可用性和接受度的框架，選擇了六個案例。\n它們各自採用了代表了不同公司製造活動的四個階段：design、training、operation、disruptive\nFramework development XR 系統整合框架的開發採用了 SDLC，也被稱作 application development life cycle，常被用在開發各種 IT 系統。 描述了系統設計人員和開發人員為了確保開發品質，需要遵循的多個階段活動。\n多年來，基於 SLDC 方法開發了各種模型和方法，比如瀑布式開發或是 Scrum。\n本研究中採用的 SDLC 階段如下：\nIdentifying problems Analyzing the needs Designing the system Developing and documenting Testing the system Implementing and maintenance Case 1 Background 要訓練人員維護機器\nResarch Process 有公司進行了案例研究，開發了一種支援小型工具箱維護任務的 AR 系統\nResult and conclusion 文本教學容易被忽略，以吸引人的物件符號改進。 最後問卷持正面態度。 但還是有一些可改進的點，比如需要連接電腦，在實際工廠車間並不方便。\nCase 2 ~ Case 6 時間問題暫不補\nThe proposed framework 針對上一節 SDLC 的案例總結和整合，結合了以使用者為中心的 XR 系統開發五步驟框架。\nStep 1: Understanding the requirements 聽起來很顯而易見，但實踐中常被跳過或淡化，導致不令人滿意的結果。 而且製造環境比一般用例場景更加複雜。\n全面了解需求是成功開發 XR 系統的重要第一步。 以使用者為中心的設計方法中，採用的比如 observation、stakeholder workshop、contextual inquiry、storyboard、prototyping adopted 都被證明在是別需求方面是有效的。\n應該要可以回答以下問題：\nWhat actions are taken? What support are used? What outcome are achieved? What main drawbacks are there? 回答上述問題後，就可以開發 storyboards 和 prototypes 了。\n此外，不只是開發者和負責人，最終用戶也要可以參與評估和回饋，直到最終的需求被解決。\nStep 2: Solution selection 通常是根據公司現有硬軟體來選擇，而不是根據哪種解決方案最能滿足要求，使選方案是個困難的決定。\nStep 3: Data preparation Step 4: System implementation Step 5: System evaluation Iteration 在完成所以提出的步驟後可以迭代，以小量的改進進行迭代，直到達成特定需求。\nFramework validation 該框架被用於一個真實案例，用來評估適用性。 此外，他還與六項先前的研究進行驗證，這些研究部分與提出的框架一致。\nThe empicial case 本文的框架被用於開發 VR 工具，好支援汽車公司的產品設計審查。\nRequirement analysis 是一家分布全球的汽車公司，研發中心在瑞典，工廠在中國。\n具體任務是對用於點焊的新型 fixtures 進行 design review。\n目前的做法依賴 CAD 軟體分布在不同地點的不同團隊之間來傳達理念。\n他還需要一個或多個原型，在最終安裝前進行驗證。\n主要缺點是，和原型實體相關的溝通十分冗長。\n此外，最終使用者 ( operators of fixtures) 缺發 CAD 設計的專業知識，導致他們無法參與設計。\n因此，提出了具體要求：\n適用於所有 stakeholder 的虛擬工具，可以直觀地視覺化新產品設計，並和新產品設計互動 多個 stakeholder 可以從不同的地點參與同一個 virtual session 所有 stakeholder 都可以口頭交流 virtual session 可以用圖像或影片形式記錄 每個 stakeholder 都要有個人化虛擬代表 要有主持人、與會者和觀眾等角色相關功能 Solution selection 選 VR 和 Unity3D\nData preparation System implementation System evaluation 進行兩次迭代開發，評估 VR 系統是否可以補充或甚至取代現有作法的可行性\nOutcome 開發了一個可以支援最多 20 個使用者從任何有網路的地方連線加入的應用程式。\nExternal Validation 作者挑了七篇有關的 XR 整合到製造業的研究，他們都採取了類似的方法，部分與提出的框架一致。\nConclusion 本文第一個貢獻是根據案例結果提出的框架，由五個迭代階段組成：\nRequirement analysis Solution selection Data preparation System implementation System evaluation 通過一個實際案例以及七項先前的研究進行了驗證，這些研究與提出的框架部分一致。\n該研究還會工業從業者提供了知識，有利他們採用 XR 技術做為 工業 4.0 的一部分。\n","date":"2024-03-30T00:00:01+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80a-framework-for-extended-reality-system-development-in-manufacturing/","title":"論文閱讀：A Framework for Extended Reality System Development in Manufacturing"},{"content":"paper: Matryoshka Representation Learning\nAbstract 想設計 flexible 的 representation 好適應不同的下游任務\nMRL 根據不同的 granularities 來 encode 資訊，並允許一個 single embedding 來適應下游任務的運算限制\nMRL 學習從 coarse-to-fine 的 representation，至少和獨立訓練低維度的 representation 有一樣的準確度\n在相同精準度下，MRL 的 embedding 縮小 14 倍\n在 ImageNet-1K 和 4K 上進行大規模檢索時，實際速度提升 14 倍\nlong-tail few-shot learning 的準確度提高 2%，並且和原有 representation 一樣 robust\n最後，作者證明 MRL 可以無縫地擴展到各種模式的網路規模資料集，包含 Vision, Vision + Language, 和 Language\nIntroduction deep representation 的 deployment 有兩個步驟：\n昂貴的 forward-pass 計算 representation representations 在下游的利用 (比如檢索) 在 web-scale 上，這種利用的成本蓋過了特徵計算成本\n常見的做法的 representation 的剛性迫使多個任務中使用高維嵌入向量\n人類對自然世界的感知是由粗到細的粒度\n然而，或許是基於梯度訓練的 inductive-bias，深度學習傾向於將「資訊」擴散到整個表示向量中\n通常透過訓練多個低維模型、聯合優化不同容量的子網路、事後壓縮，在現有的 fixed representation 上實現彈性\n這些技術中的每一種都難以滿足自適應大規模部屬的要求，基於開銷 / 維護考量等等\nMRL 以 nested 的方式來學習 O(log(d)) 個相同的高維向量、但不同 capacity 的 representation，因此被稱為 Matryoshka\nMatryoshka Representation 提高了大規模分類和檢索的效率，而不會顯著失去準確度\n本文重點關注在機器學習系統的兩個關鍵模組：大規模分類和檢索\n在分類上，作者使用 variable-size representations 結合 adaptive cascades 來顯著減少實現特定精度所需嵌入的平均維度\n例如，在 ImageNet-1K 上，MRL + Adaptive classification 在和 baseline 同精準度的情況下將 representation 縮小 14 倍\n對於檢索，先用 query embedding 一開始的 few dimensions 來減少 retrieval candidates，然後再用更多的 dimensions 來 re-rank retrieved set\nMRL 的檢索精確度和 single-shot retrieval 相當\n主要貢獻如下：\n提出了 MRL 來獲得 filexible 的 representation for adaptive deployment 使用 MRL 進行大規模分類和檢索，速度提高 14 倍而且一樣準確 可以在跨 modalities 還有可接受 web-scale 資料的情況下無縫調整 MRL 在其他下游任務的背景下進一步分析 MRL 的表示 Related Work Efficient Classification and Retrieval 在推理過程中，分類和檢索的效率可以從兩個方面研究：\n深度特徵的高但恆定的成本 隨著標籤空間和數據大小而變化的搜索成本 第一個問題可以透過不同的演算法設計高效的神經網路來解決\n但是，伴隨著強大的 featurizer，多數 scale 相關的問題出在 標籤數量(L)、資料大小(N)、或是表示維度(d) 這種 linear dependence 上\n讓 RAM, disk 和 CPU 都同時有巨大的壓力\n標籤數量在計算和 RAM 方面已經得到了很好的研究，可以透過 Approximate Nearest Neighbor Search (ANNS) 或 leveraging the underlying hierarchy 來解決\n在表示大小方面，降維、Hash 和特徵選擇等技術常用於緩解 O(d) 的增長規模，但代價是精確度的顯著降低\nANNS 使用戶可以從資料庫中取得和請求最相似的文件或圖片\n廣泛採用的 HNSW 可以讓 O(d log(N)) 和準確搜索 O(dN) 一樣精準，但代價是需要在 RAM 和 disk 承擔 graph-based index 的開銷\nMRL 解決對 d 的線性依賴問題，低維度的 Mayryoshka representations 和獨立訓練的 representations 一樣準確，而不需要多次昂貴的前向傳遞\nMatryoshka Representation Learning 有分兩種訓練方法：\nMatryoshka Representation Learning (MRL)\n在後面接 9 層 MLP，不是串聯，是並聯 比如 mlp(768,8)\u0026hellip;., mlp(768,2048) Efficient Matryoshka Representation Learning (MRL-E)\n在後面只接 1 層，然後取前面維度得到一個向量，以此類推 比如 mlp(768, 2048)，可能取前 16 維當一個向量，然後再取前 64 維當一個向量 ","date":"2024-02-26T00:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/mrl-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"MRL 論文閱讀"},{"content":"paper: REALM: Retrieval-Augmented Language Model Pre-Training\nAbstract 為了用更加模組化和可解釋的方式獲取知識，作者用 latent knowledge retriever 來加強語言模型的預訓練，latent knowledge retriever 允許模型檢索 large corpus 的 document，並在預訓練、微調和推理時使用。\nIntroduction 在諸如 BERT 的語言模型中，學到的 world knowledge 隱式地儲存在神經網路的參數中，使其很難確定儲存了哪些知識以及儲存在何處。而且儲存空間受網路大小限制，但訓練更大的網路可能非常昂貴\n本文為了以更加可解釋和模組化的方式獲取知識，提出了一個新穎的框架，Retrieval-Augmented Language Model (REALM) 預訓練，透過 learned textual knowledge retriever 來加強預訓練\n和把知識儲存在參數中的模型相比，該方法顯示地揭示 world knowledge 扮演的角色，做法是要求模型在推理過程中決定哪些知識來 retrieve，並用在推理階段\n在每次預測前，語言模型使用 retriever 在 large corpus 搜索文件，並用這些文件幫助預測\nEnd to End 的學習需要考慮整個檢索步驟，好進行反向傳播\nREALM 有個關鍵直覺，就是訓練 retriever 的時候用的是 unsupervised text 的 performance-based signal：\n一個可以提高語言模型複雜性的檢索是有幫助，且該被獎勵的 資訊不足的檢索應該受到懲罰 比如圖 Fig.1 找到的文件就該獲得獎勵\n作者將 retrieve-then-predict 的方法建模並視作 latent variable language model 並優化 marginal likelihood\n但在預訓練期間要訓練大規模的 retrieval module 成為問題，因為 Retriever 得為每個預訓練步驟考慮數百萬個候選文檔，而且必須根據決策反向傳播。為了解決這問題，作者建構了 retriever，以便快取和非同步更新每個文件的計算，並將最佳文件的選擇表示為 Maximum Inner Product Search (MIPS)\n透過在 Open-QA 任務上使用 REALM 預訓練的 model 來 finetune 進行評估，OpenQA 是最 knowledge-intensive 的任務之一\n作者挑了三個流行的 Open-QA benchmark，比如 NaturalQuestions-Open、WebQuestions、CuratedTrec，並和 SOTA Open-QA model 比較\n在三個基準都取得了 SOTA 的結果，absolute accuracy 明顯高於先前系統 4-16%\n也展示了 REALM 的 qualitative benefit，比如可解釋性和模組化\nBackground Open-domain question answering (Open-QA) OpenQA 的 open 是指模型不會接收到包含答案的預提供文件，和傳統的閱讀理解不同\nApproach REALM’s generative process 預訓練做 masked language modeling，微調的任務是 Open-QA\nModel architecture neural knowledge retriever 是 $p(z|x)$\nknowledge-augmented encoder 是 $p(y|z,x)$\nKnowledge Retriever $p(z|x)=\\frac{\\text{exp }f(x,z)}{\\sum_{z\u0026rsquo;}\\text{exp }f(x,z\u0026rsquo;)}$\n$f(x,z) = Embed_{input}(x)^T Embed_{doc}(z)$\n$join_{BERT}(x)=[CLS]x[SEP]$\n$join_{BERT}(x_1, x_2)=[CLS]x_1[SEP]x_2[SEP]$\n$Embed_{input}(x)=W_{input}BERT_{CLS}(join_{BERT}(x))$\n$Embed_{doc}(z)=W_{doc}BERT_{CLS}(join_{BERT}(z_{title}, z_{body}))$\nKnowledge-Augmented Encoder Finetune:\n$p(y|z,x) \\propto \\displaystyle\\sum_{s\\in S(z,y)}exp(MLP([h_{START(s)};h_{END(s)}]))$\n$h_{START(s)}=BERT_{START(s)}(join_{BERT}(x,z_{body}))$\n$h_{END(s)}=BERT_{END(s)}(join_{BERT}(x,z_{body}))$\nTraining 關鍵的計算挑戰是 $p(y|x)=\\sum_{z\\in Z}p(y|x,z)p(z,x)$，涉及到 Z knowledge corpus 中的 所有 document z，因此只取機率 $p(z|x)$ 最高的 top k 文件來求和，考量到多數文件的機率應該為 0，這是合理的\n但是依然需要一個有效的方法來尋找前 k 個文件\n前面的 $f(x,z)$ 是一個內積，可以用 Maximum Inner Product Search (MIPS) 演算法來尋找近似前 k 個文檔\n為了用 MIPS，要先用一種 embedding 函式來幫 z encode，但是如果更新了這個函式，資料結構和 $p(z|x)$ 又會不一致\n因此，每次對 embedding 函式更新後，search index 都會變 \u0026ldquo;stale\u0026rdquo; (陳舊)\n每隔數百個訓練步驟非同步重新 embed 和 index 所有 document 來刷新 index\nMIPS 的 index 在刷新之前會有點 stale，但它只用於挑選前 k 個文件\n結果證明，只要在恰當的刷新率下，還是可以穩定 optimize\nWhat does the retriever learn? 這裡展示了它如何獎勵提高預測準確性的檢索\n$\\triangledown \\text{log }p(y|x)=\\displaystyle\\sum_{z\\in Z}r(z)\\triangledown f(x,z)$\n$r(z)=[\\frac{p(y|z,x)}{p(y|x)}-1]p(z|x)$\n如果 $r(z)$ 是正的，會讓 f(x,z) 提高，否則減低\n$r(z)$ 只有在 $p(y|z,x)\u0026gt;p(y|x)$ 的情況下才會是正的\n$p(y|x)$ 是 $p(y|x,z)$ 在隨機取樣的情況下的期望值\n只要文檔 z 好過預期，就會持續正面更新\nInjecting inductive biases into pre-training 在發展 REALM 的過程中，作者發現幾個額外策略，可以進一步引導模型進行有意義的檢索\nSalient span masking 有一些 MLM span 只需要 local context，但作者想專注於 world knowledge\n所以作者會 mask 一些 salient span，比如「英國」、「1969 年 7 月」\n作者用在 CoNLL-2003 上訓練的 BERT-based tagger，來找出 named entities，並用正規表達式來找出日期\n結果表明這顯著優於其他 mask 策略\nNull document 雖然 Salient span masking 表現很好，但不是所有 mask 都需要 world knowledge\n透過向前 top k 文檔中多加一個空的文檔，允許在不需要檢索有空白選項\nProhibiting trivial retrievals 如果 mask 的句子來自文件 z，可以透過查看 z 中 x 的 unmasked 版本來輕鬆預測 y，使 p(z|x) 出現較大的梯度，如果這種情況太頻繁，會使 retriever 最終學會的東西偏向 exact match，而不會捕獲其他形式的相關性\n因此，在預訓練期間排除了 trivial candidate\nInitialization 在訓練開始時，如果 input 和 document 各自的 Embedding function 沒有良好的效能，會使檢索到的 z 和 x 無關\n會導致模型學習忽略檢索到的文件，檢索器就不會收到有意義的梯度，也無法改進\n為了避免 cold-start problem，作者採用 warm-start 方案，先以 Inverse Cloze Task (ICT) 這種簡單的目標來處理兩個 embedding function，給定一個句子，訓練模型檢索句子來自的文檔\nExperiments Open-QA Benchmarks 本文將重點放在問題作者不知道答案的資料集，比較能反映現實中的問題\nNaturalQuestions-Open 由自然發生的 google 查詢和答案組成，每個答案還帶有 answer type\n本文只用屬於 \u0026ldquo;short answer type\u0026rdquo; 的問題，最多有 5 個 token\nWebQuestions 從 Google Suggest API 收集的\nCuratedTrec 從 MSNSearch 和 AskJeeves 等網站上真實使用者查詢中提取的問答\nApproaches compared Retrieval-based Open-QA 最近的一些方法提出用 MIPS index 來實現可訓練的檢索\nORQA 與 REALM 類似\n但 REALM 提出了更新穎的模型預訓練步驟，並反向傳播到 MIPS index 中，而不用固定的 index\n上面指的應該是有關於非同步更新 index 的部分，還可以梯度更新\n值得注意的是，REALM 和 OrQA 的預訓練都是用 ICT 初始化的\nGeneration-based Open-QA Open-QA 的新興替代方案是將其建模為序列預測任務，只需對問題進行編碼，然後根據編碼逐個標記編碼答案\nGPT2 可以透過 sequence to sequence 直接產生答案，而不需要給指定的上下文，但可能由於缺乏 finetune 而沒有競爭力\n同時，T5 表明，直接生成答案而不從給定上下文中明確提取是可行的方法，但他們只在提供上下文文檔的閱讀理解任務上進行實驗\n為了和最具競爭力的 baseline 比較，本文與針對 Open-QA finetune 的 T5 進行比較\nImplementation Details Fine-tuning 文件被貪婪地分割成多達 288 個 BERT wordpieces 的 chunk，產生超過 1300 萬個 retrieval candidates\n在微調推理過程中，考慮前五個候選者\nPre-training 使用 BERT 的預設優化器在 64 個 Google Cloud TPU 上預訓練 20 萬步\nMIPS 在 16 個 TPU 上並行\nMain results REALM 在 table.1 明顯優於之前的所有方法\nREALM 最直接的比較是 ORQA，微調設定、超參數和訓練資料都相通\nREALM 對比 ORQA 的改進純粹是更好的預訓練方法\n而且本文表明他們的預訓練方法可以用在 single-corpus setting 或 seperate corpus setting\n兩者的差別在 X 和 Z 來源一不一樣\nAnalysis table.2 展現了去除 REALM 關鍵組件後的結果\n還展現了 finetune 前 gold answer 出現在前五個檢索中的頻率\nMasking scheme salient span masking 在先前標準的 BERT 訓練中尚未被證明具有影響力，但對於 REALM 至關重要\nMIPS index refresh rate 在預訓練期間，運行並行過程來重新 embed document 和重建 MIPS index\n導致每大約 500 個訓練步驟刷新一次 index\n為了證明頻繁刷新的重要性，也和較慢刷新率比較\ntable.2 顯示，stale index 可能會傷害模型，進一步減少這種過時性可以提供更好的最佳化\nDiscussion and Related Work Scalable grounded neural memory document index 可以被視為一種 memory，key 是 document embedding\n從這角度來看，本文的工作和 product key memory 有共同的動機，它能夠在記憶體網路中實現低於線性的存取\n一個主要的區別是本文的記憶體是有根據的，每個 memory 都和一個文檔相關聯，而不是和 unnamed value vector 相關聯\n這種程度的可解釋性對 Open-QA 至關重要，在這些應用程式中，用戶需要出處才能使預測答案值得信賴\nFuture Work ","date":"2024-01-05T00:00:13+08:00","permalink":"https://roykesydon.github.io/Blog/p/realm-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"REALM 論文閱讀"},{"content":"paper: Dense Passage Retrieval for Open-Domain Question Answering\nAbstract Open-domain question answering 依賴有效的 passage retrieval 來選擇 candidate context，傳統上用的 sparse vector space models，有 TF-IDF、BM25 等等\n本文顯示出檢索實際上可以只用 dense representation，embedding 是從少量的 question 和 passage 學到的，利用簡單的 dual-encoder framework\n在廣泛的 open-domain QA 資料集上，本文的 dense retriever 在 top-20 passage retrieval accuracy 上比 Lucene BM25 好 9%-19%\n並幫助作者的 end-to-end QA system 在 multiple open-domain QA benchmarks 上取得 SOTA\nIntroduction 早期閱讀理解模型提出了簡單的 two-stage framework：\n一個 context retriever 先選定一些 passage 子集合，其中某一些 passage 包含答案\n一個 machine reader，可以徹底檢查選出的 context 並找到答案\n盡管將 open-domain QA 簡化為 machine reading 是一個合理的策略，但是實際上經常看到嚴重的性能下降，顯示出需要改進 retrieval\nopen-domain QA 中的 retrieval 通常用 TF-IDF 或 BM25 來實現，可以透過 inverted index 有效地 match keywords，而且把 question 和 context 表示為 high-dimensional sparse vectors\n相反的，Dense latent semantic encoding 在設計上和 sparse representation 是互補的\n例如，由完全不同的 token 組成的兩個同義詞依然可以映射到接近的向量\nterm-based system 相較 dense retrieval system 很難將比如「壞人」和「惡棍」匹配\nDense encoding 也可以透過調整 embedding function 來學習，對於 task-specific 的 representation 提供了彈性\n透過特殊的 in-memory data structure 和 indexing scheme，可以用 maximum inner product search (MIPS) 來快速檢索\n然而，人們普遍認為學習良好的 dense vector representation 需要大量的 QA labeled pair\n因此，在 ORQA 之前，Dense retrieval 從沒被證明過可以在 open-domain QA 上贏過 TF-IDF 或 BM25\nORQA 提出了 ICT 來做額外的預訓練\n盡管 ORQA 證明了 dense retrieval 可以超越 BM25，在多個 open-domain QA 資料集上取得 SOTA，但他也存在兩個弱點：\nICT 預訓練是 compute-intensive，而且不確定 regular sentence 是否能很好的替代 objective function 中的 question\n由於 context encoder 沒有用 QA pair 進行 finetune，因此相應的 representation 可能不是最佳的\n在本文中，本文將解決一個問題 \u0026ndash; 我們是否可以只用 QA pair 來訓練更好的 dense embedding model，而不用額外的預訓練？\n利用現在的 standard BERT pre-trained model 以及 dual-encoder architecture，本文專注於用相對少量的 question and passage pair 來訓練 dense retriever\n經過一系列的 ablation study，本文的解決方案出奇的簡單\nembedding 可以用最大化 question 和 相關的 passage 的 inner product 來訓練\n作者的 Dense Passage Retrieval (DPR) 非常強大，不僅大幅優於 BM25，而且和 ORQA 相比，end-to-end QA 準確度也有大幅提升\n作者的貢獻有兩部分：\n作者證明在適當的設置下，只需在現有 question-passge pair 上 finetune question and passage encoder，就可以大幅超過 BM25，實驗結果也證明可能不用額外的預訓練\n作者證明了在 open-domain QA 的背景下，更高的 retrieval accuracy 可以轉化為更高的 end-to-end QA accuracy\n透過對 top retrived passage 使用 modern reader model，和幾個非常複雜的系統相比，作者在 open-retrieval setting 下的多個資料集取得了可比較或更好的結果\nBackground 本文研究的 open-domain QA 的描述如下：\n先給出一個事實性問題，不屬於特定主題，需要一個系統使用大量多樣化主題的 corpus 來回答\n更具體地說，作者假設 extractive QA setting，答案僅限於 corpus 中的一個或多個 passage 中出現的範圍\n假設有 D 個 documents，先把每個 document 拆成多個等長的 text passage，好做為 basic retrieval unit，最後得到 M 個 passage in corpus C\n每個 passage 可以被視作一個 token 序列\n對於 question q，則是要找到某段 passage 中的一串連續的 token 來回答\n值得注意的一點是，為了涵蓋盡可能廣泛的概念，corpus 的大小可能會從數百萬個文件到數十億個文件不等\n因此，任何 open-domain QA system 都需要一個高效的 retriever，可以在 reader 提取答案前選擇一小組相關的文本\nDense Passage Retriever (DPR) 作者的研究重點是改進 open-domain QA 的 retrieval component\n給定 M 個 passage，DPR 的目標是把所有 low-dimensional continuous space 的所有 passage 都給 index，使它可以有效地檢所和輸入問題相關的 top-k passage\nM 有可能非常大，比如本文有 21M 個 passage，而 k 通常很小，可能只有 20~100 個\nOverview 用 dense encoder $E_P(．)$ 和 $E_Q(．)$ 來分別 encode passage 和 question，在計算兩者的 inner product 來衡量相似度\n盡管確實存在測量 question 和 passage 之間更具表現力的模型形式，比如帶有 cross-attention 的 multi-layer networks，但是 similarity function 需要可以分解，才可以預先計算 passage 的 embedding\n大多數 decomposable similarity function 是 Euclidean distance (L2) 的變換\n比如，consine 是 unit vector 的 inner product，而 Mahalanobis distance 等同於在 transformed space 的 L2 distance\n由於 ablation study 表示其他相似含數的表現相當，因此選擇更簡單的內積函數，並透過學習更好的 encoder 來改善 dense passage retriever\nEncoder 本文採用兩個獨立的 BERT，並把 [CLS] token 的 representation 當作 output\nInference 推理階段，將 passage encoder $E_P$ 應用在所有 passage，並用 FAISS offline index\nFAISS 是一個非常高效的 open-source library，用在 similarity search 和 clustering of dense vectors，可以輕鬆應用在數十億個向量上\n在推論接段，計算 q 的 embedding，然後用 FAISS 來找到 top-k passages\nTraining 每一個 training instance 都包含問題 q，還有一個正 (相關) passage，以及 n 個負 (不相關) passages\nPositive and negative passages 對於檢索問題，正例通常明確可用，而反例則通常要從非常大的 pool 中選擇\n正例可能會在 QA 資料集給出，或是可以從答案找到，其他的段落預設情況下都可視為不相關\n在實踐中，如何選擇負例常被忽視，但對於學習 high-quality encoder 可能很關鍵\n考慮三種負例：\n隨機 Corpus 中隨機選擇 BM25 BM25 返回的 passage 不含答案，但包含最多 question token Gold positive 和 question 配對 第 2 和 3 種是在說拿其他問題的正例當負例\nIn-batch negatives 有 B 訓練實體，每個問題有 B-1 個 negative passage，只有 i = j 時，$(q_i, p_j)$ 是正例，其他都是負例\nin-batch negative 的技巧已被用在 full batch setting 和 mini-batch setting\n已被證明是學習 dual-encoder 的有效策略，可以增加訓練範例的數量\nExperimental Setup Wikipedia Data Pre-processing 用 DrQA 提供的預處理程式碼從 Wikipedia dump 中提取文章中乾淨的文字部分\n此步驟將刪除 semi-structured data，比如表格和 info-boxes\n接著將每天文章分成多個不相交的文字區塊，每個文字區塊由 100 個單字組成，作為 basic retrieval unit，最後會有 21,015,324 個 passage\n每個 passage 也帶有標題以及 [SEP]\nSelection of positive passages 由於 TREC, WebQuestions 和 TriviaQA 中只有 question-answer pair，因此使用 BM25 把包含答案最多的 passage 當作正例\n如果檢索到的前 100 篇文章中沒有答案，則該問題會被丟棄\nExperiments: Passage Retrieval Main Results SQuAD 表現較差有可能是因為 passage 和 question 存在高度詞彙重疊，給 BM25 帶來優勢，而且資料僅從 500 多篇 wiki 文章中蒐集，因此訓練範例的分佈存在極大的 bias\n當用多個資料集訓練時，TREC（裡面最小的資料集）獲益最多\nAblation Study on Model Training Sample efficiency In-batch negative training in-batch negative 可以顯著改善結果，還簡單且節省記憶體，可以重複使用 batch 中已經有的負例\n它會產生更多 pair，從而增加訓練資料的數量\nImpact of gold passages 做了 distant supervision，只有很小的影響，降低了 1 個點\nSimilarity and loss L2 和 inner product 的表現相當，兩個都比 cosine 好\n有一種流行的 ranking loss 叫做 triplet loss，但是在本文中，作者發現它的表現不會對結果產生太大影響\nCross-dataset generalization 為了測試泛化能力，只在 Natural Questions 上訓練，在較小的 WebQuestions 和 CuratedTREC 上測試，發現泛化能力很好，輸給 SOTA finetune model 3~5 個點，但仍大大優於 BM25 baseline\nExperiments: Question Answering Result Related Work Conclusion 證明了 dense retrieval 可以 outperform 甚至可能取代傳統的 sparse retrieval\n雖然簡單的 dual-encoder framework 可以達到很棒的效果，但作者顯示出要成功訓練也有一些關鍵因素\n此外，根據 empirical analysis 和 ablation study，更複雜的 model framework 或 similarity function 不一定能提供額外價值\n由於檢索性能的提高，在多個 open-domain QA benchmarks 上取得了 SOTA\n","date":"2023-12-28T00:00:13+08:00","permalink":"https://roykesydon.github.io/Blog/p/dpr-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"DPR 論文閱讀"},{"content":"paper: Latent Retrieval for Weakly Supervised Open Domain Question Answering\nAbstract 最近的工作常依賴於兩個假設，一個是對 supporting evidence 做 strong supervision，另一個是假設 blackbox information retrieval (IR) system 可以找到所有的 evidence candidates\n作者認為兩者都不是最理想的，因為 gold evidence 不總是可用，而且 QA 和 IR 有著根本上的不同\n作者首次證明，在沒有任何 IR 的情況下，可以從 question-answer pair 中共同學習 retriver 和 reader\n在這種 setting 下，來自 Wikipedia 的 evidence retrieval 被視作 latent variable\n由於 learn from scratch 不切實際，因此用 Inverse Cloze Task (ICT) 來預訓練 retriever\n作者對五個 QA 資料集進行評估\n在提問者已經知道答案的情況下，傳統的 IR 系統（比如 BM25）已足夠\n在使用者真正尋求答案的資料集上，作者顯示出 learned retrival 的重要性，在 exact match 上比 BM25 好 19 個點\nIntroduction 由於閱讀理解系統的發展，人們對 open domain question answering (QA) 的興趣重新燃起\n其中 evidence 得從 open corpus 取得，而不是直接從輸入給入\n現有的方法需要 blackbox IR system 來完成大部分繁重的工作，即使它無法對下遊任務進行微調\n在 DrQA 推廣的強監督環境中，他們也假設了一個訓練在 question-answer-evidence triple 上的閱讀理解模型\n在某些人提出的 weakly supervised setting 中，他們假設 IR system 提供 noisy gold evidence\n這些方法利用 IR system 來大幅減少搜尋空間\n然而 QA 和 IR 有著根本性的差異\n雖然 IR 關心的是 lexical 和 semantic matching，但 question 的定義並不具體，而且需要更多 language understanding，因為 user 在找的是未知資訊\n我們應該直接 用 QA data 學習 retrieve，而不是受限於 blackbox IR system\n在本文中，作者介紹了第一個 OpenRetrieval Question Answering system (ORQA) 框架\nORQA 學習從 open corpus retrieve evidence，並且只做 question-answer pair 的監督訓練\n雖然最近的工作在改進 evidence retrieval 上取得了巨大的進展，但是他們依然只是在 closed evidence set 下 rerank\nfully end-to-end 的挑戰是，open corpus 的 retrieval 必須被視為 latent variable，要 train from scratch 是不切實際的\nIR system 提供了一個合理但可能非最好的起點\n本文的一個關鍵是，如果用無監督 的 ICT 對 retriever 做預訓練，那 end-to-end learning 是有可能的\n在 ICT 中，一個句子被視作 pseudo-question，而它的 context 被視作 pseudo-evdience\n給定一個 pseudo-question，retriever 的目標是從 batch 中的 candidate 找出對應的 pseudo-evidence\nICT pretraining 提供了強大的初始化，使 ORQA 可以簡單地優化\n作者在五個 QA 資料集上進行了評估，在問題作者已知答案的資料集上 (SQuAD、TriviaQA)，檢索問題類似傳統的 IR，並且 BM25 是 SOTA retrieval\n在問題作者不知道答案的資料集上 (Natural Questions、WebQuestions、CuratedTrec)，作者顯示出 learned retrieval 的重要性，比 BM25 在 exact match 上好 6~19 個點\nOverview Task 在 open-domain QA 中，$q$ 是 question string，而 $a$ 是 answer string\n與閱讀理解不同，evidence 的來源是 modeling choice，而非 task definition 的一部分\nFormal Definitions Model 把一個 unstructured text corpus 切成 B 塊的 evidence text\n一個 answer derivation 是一個 pair $(b,s)$\n$1 \\le b \\le B$ 是 block 的 index\n$s$ 是 block $b$ 的 span\nscoring function $S(b,s,q)$ 用來計算 $(b,s)$ 對於 $q$ 的分數\n一般來說 scoring function 會被分解成 retrieval component $S_{retr}(b,q)$ 和 $S_{read}(b,s,q)$\n$S(b,s,q) = S_{retr}(b,q) + S_{read}(b,s,q)$ 在推論階段：\n$a^* = TEXT(argmax_{b,s} S(b,s,q))$ open-domain QA 的一個主要挑戰是 handling the scale\n作者在 English Wikipedia 上做實驗，包含超過 13M 個 blocks，每個 block 都有超過 2000 個可能的 spans\nExisting Pipelined Models 在現有的 retrieval-based open-domain QA 模型中，blackbox IR system 先選擇一組 closed set of evidence candidates\n然後 DrQA 之後的多數工作都用 TF-IDF 來挑選 candidate，並專注於閱讀理解或 reranking 的部分\nreading component $S_{read}(b,s,q)$ 是從 gold answer 學習的\n在最接近我們的方法的工作中，reader 是透過 weak supervision 學習的\nretrieval system 會啟發式（heuristically）地刪除 spurious ambiguities，並把清理後的結果視為 gold evidence\nOpen-Retrieval Question Answering (ORQA) $BERT(x_1, [x_2]) = \\{CLS: h_{CLS}, 1: h_1, 2: h_2,\u0026hellip;\\}$\nRetriever component $h_q = W_q BERT(q)[CLS]$ $h_b = W_b BERT(b)[CLS]$ $S_{retr}(b,q) = h_q^T h_b$ Reader component $h_{start} = BERT_R(q,b)[START(s)]$ $h_{end} = BERT_R(q,b)[END(s)]$ $S_{read}(b,s,q) = MLP([h_{start};h_{end}])$ Inference \u0026amp; Learning Challenges 上面的模型概念很簡單\n但推論和學習上具有挑戰性，因為：\nopen evidence corpus 有巨大的搜尋空間（超過 13M 個 blocks） 要如何在空間 navigate 是 latent 因此標準的 teacher forcing 不能用，latent variable 也不能用，因為存在大量 spuriously ambiguous derivations（比如答案是 \u0026ldquo;seven\u0026rdquo;，很多 evidence 都會有 \u0026ldquo;seven\u0026rdquo; 這個字眼）\n作者透過非監督預訓練來良好地初始化 retriever 來解決這些挑戰\n預訓練的 retriever 使作者能夠：\npre-encode Wikipedia blocks，從而在 finetune 階段實現動態且快速的 top-k retrieval\n使 retrieval 可以遠離 spuriously ambiguities 並偏向 supportive evidence\nInverse Cloze Task 作者提出的預訓練流程的目標是想讓 retriever 解決和 evidence retrieval for QA 相似的無監督任務\n直覺上，useful evidence 通常會討論問題中的 entities, events 和 relations\n還包含問題中不存在的額外資訊 (the answer)\nquestion-evidence pair 是 setence-context pair，句子的上下文在語意上是相關的，可以推論句子中缺少的資訊\n憑這種想法，作者建議使用 ICT 來預訓練 retriever\n在 standard cloze task 中，目標是根據上下文預測 masked-out text\n相反，ICT 要逆向預測，給定一個句子，預測上下文\n使用類似 downstream retrieval 的 discriminative objective：\n$P_{ICT}(b|q)=\\frac{exp(S_{retr}(b,q))}{\\sum_{b\u0026rsquo; \\in BATCH} exp(S_{retr}(b\u0026rsquo;,q))}$\n預測哪個上下文是 query 的\nICT 有個重點是，它要做的不僅僅是單字匹配，因為 evidence 中沒有 pseudo-question\n例如 fig.2 的 pseudo-question 完全沒有提及 zebra，但 retriever 要能夠選擇 zebra 的 context\n能夠從非指定的語言推論出語意是 QA 和傳統 IR 的差異\n然而作者也不想阻止 retriever 學習單字匹配，因為 lexical overlap 最終是一個非常有用的特徵\n因此，作者只在 90 % 的例子中把 sentence 從 context 中移除，鼓勵模型在需要的時候學習抽象表示，也在可用時學習 low-level word matching features\nICT 預訓練實現兩個主要目標：\n儘管預訓練的句子和微調時的 question 不匹配，但作者預期 zero-shot evidence retrieval performance 足以引導 latent variable 的學習\npretrained evidence blocks 和 downstream evidence blocks 間沒有這種不匹配的問題\n因此可預期 $BERT_{B}(b)$ 無須進一步訓練即可正常工作\n只有 question encoder 需要針對下遊資料微調\nInference 由於 fixed block encoder 已經為 retrieval 提供了有用的 representation，可以預先計算所有 block 的 encoding\n因此在微調的時候不需要對大量 evidence block 重新 encode，並且可以使用比如 locality-sensitive hashing 之類的現有工具來建立索引\n透過 pre-compiled index，推理遵循 standard beam-search\n檢索 top-k evidence block，並只計算這 k 個 block 的 reader score\nLearning 這邊太複雜，建議看原文\nExperimental Setup Open Domain QA Datasets 對 5 個現有 question answering 或閱讀理解資料集進行評估\n並非所有資料集的原始形式都是 open-domain QA，因此作者遵循 DrQA 的做法，轉成 open format\n每個 example 都有一個 single question 和一「組」 reference answer\nNatural Questions 包含了從 Google Search 的 aggregated queries 中的 question\n為了蒐集這個資料集的 open version，作者只保留 short answer 並丟棄 evidence document\n具有許多 token 的答案通常類似 extractive snippets 而不是 canonical answer，因此作者丟棄長度超過 5 個 token 的答案\nWebQuestions 包含從 Google Suggest API 抽取的問題\n答案是根據 Freebase 標註的，但是只保留 entities 的 string representation\nCuratedTrec 問題來自真實查詢的各種來源，比如 MSNSearch\nTriviaQA 從網路上抓的 question-answer pairs\n作者使用 unfiltered set 並捨棄 distanly supervised evidence\nSQuAD 被設計來用作閱讀理解，而不是 open-domain QA\n答案範圍是從 Wikipedia 的段落中選擇的，問題由 annotators 編寫，annotators 被指示提出問題，要由給定的 context 中的 span 來回答\nDataset Biases 在 Natural Questions、WebQuestions 和 CuratedTrec 中，提問者不知道答案，反映了真實的尋求問題的分佈\n但是，annotators 必須單獨找到正確的答案，因此需要 automatic tools，並可能會對這些工具的結果產生 bias\n在 TriviaQA 和 SQuAD 中，不需要 automatic tools，因為 annotators 是根據已知答案寫問題的\n然而這引入了另一組可能更成問題的 bias，就是撰寫問題並非出於資訊需求\n導致問題中有許多自然出現的問題中沒有的提示\n這在 SQuAD 中問題特別嚴重，使問題和 evidence 間人為地出現大量詞彙重疊\n但上述這些只是想表達資料集的屬性，而非可採取行動的批評，因為要取得大規模資料必定會遇到這些狀況，目前還不清楚如何在合理的成本下收集公正的資料集\nImplementation Details Evidence Corpus corpus 被分成最多 288 個單字的 chunk，並且保留 sentence boundaries\n導致有超過 13M 個 blocks\nMain Results Baselines BM25 BM25 是事實上的非監督搜索方法 SOTA 被證明對於傳統資訊檢索任務和 QA 的 evidence retrieval 任務都是 robust\nLanguage Models 非監督的 neural retrieval 對於傳統 IR 來說很難改進，但這裡視作比較的 baseline\n作者對 LM 進行實驗，並且這已被證明是 SOTA unsupervised representation\n我們與兩種廣泛使用的 128-dimensional representation 進行比較：\nNNLM context-independent embedding ELMO context-dependent bidirectional LSTM 就像 ICT 一樣，使用 alternate encoder 來預先計算 encoded evidence blocks 還有初始化經過 finetune 的 question encoding\n根據現有的 IR 文獻，還有 LM 沒有顯著優化 retrieval 的直覺，作者並不期望這些成為強大的 baseline，但是他們證明了將文本編碼為 128 維的難度\nResults 在提問者已經知道答案的資料集中\n證實壓縮到 128維的向量無法與 BM25 精確表示 evidence 中每個單字的能力相符\nSQuAD 的 dev 和 test 間的顯著下降反映了資料集中的某個特性 - 10 萬個問題僅源自 536 個文件\n因此，SQuAD 的好的檢索目標，會和訓練範例高度相關，違反了 IID 假設，使其不適合學習檢索\n因此，作者強烈建議對 end-to-end open-domain QA models 有興趣的人不再使用 SQuAD 進行訓練和評估\nAnalysis Strongly supervised comparison 為了證實作者的 BM25 Baseline 是 SOTA，提供了和 DrQA 的比較\nDrQA 的 reader 是 DocReader，用 TF-IDF 取得 top k documents\n還包括基於 TF-IDF retrieval 的 distant supervision\nBERTserini 的 reader 是一個基於 base BERT（類似作者的 reader），並用 BM25 搜索 top-k 個段落（像作者的 BM25 baseline）\n主要區別在 BERTserini 使用 Wikipedia 中的真實段落，而不是任意 block，從而由於長度不均導致更多 evidence blocks\n為了和這些強監督系統進行比較，作者在 SQuAD 上預訓練 reader\nMasking Rate in the Inverse Cloze Task pseudo-query 在 90% 的時間裡都從 evidence block 遮蔽\n如果總是屏蔽 pseudo-query，那麼 retriever 永遠不會知道 n-gram overlap 是一個強大的 retrieval signal，導致損失 10 個點\n如果從不屏蔽，問題就會簡化為記憶，導致不能很好地推廣到問題\nExample Predictions 發現 ORQA 在具有高度詞彙重疊的文本更加 robust\n但是由於 128 維向量的資訊有限\n很難精確地表示極為具體的概念，比如準確日期\n","date":"2023-12-25T00:00:13+08:00","permalink":"https://roykesydon.github.io/Blog/p/orqa-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"ORQA 論文閱讀"},{"content":"paper: Reading Wikipedia to Answer Open-Domain Questions\nAbstract 本文提出以 Wikipedia 為知識來源來解決 open-domain question answering 問題\n任何問題的答案都是 Wikipedia 中的一段文字\n這項挑戰結合了文件檢索和理解文字的能力\n本文的作法基於一個 search component，由 bigram hashing 和 TF-IDF matching 構成，並結合 RNN\n對多個 QA 資料集做的實驗表明：\n這兩個 components 對於現有的對應模塊具有高度競爭力 在他們的組合上使用 distant supervision 十分有效 Introduction 要把 wikipedia 當作知識來源，回答任何一個問題，都必須先從超過 5 百萬篇文章中找出少數相關的文章，並仔細掃描以找出答案。\n本文將這稱為 machine reading at scale (MRS)\n本文把 wikipedia 當作一個文章的集合，並且不依賴內部的 graph structure\n因此該方法是通用的，可以套到諸如新聞、網路論壇等等的資料集上\n本文開發了 DrQA，強大的維基百科問答系統，由以下部分組成：\nDocument Retriever 一個用 bigram hashing 和 TF-IDF matching 的 module 用於在給定問題的情況下，返回有效相關文章的子集 Document Reader RNN，用來 detect 文章中答案的位置 實驗表明 Document Retriever 的性能優於 Wikipedia 的內部搜尋引擎，Document Reader 在 SQuAD 上達到 SOTA\n此外，與 single task training 相比，作者表明 multitask learning 和 distant supervision 有助於提高模型的性能\nRelated Work 隨著 Knowledge Base (KB) 的發展，QA 出現了許多創新，但是 KB 具備固有限制（incompleteness, fixed schema），促使研究人員轉回從 raw text 中提取答案\n有些工作嘗試利用 multitask learning 來組合多個 QA 資料集，目標是：\n透過 task transfer 來實現跨資料集的改進 提供一個單一通用的系統，可以回答不同種類的問題，因為資料來源中不可避免地存在不同的資料分布 本文的工作在先 retrive 再 read 的 setting 下，沒有利用 KB，取得了正面成果\nDrQA 由兩個 Components 組成：\nDocument Retriever 用來尋找相關文章 Document Reader 用於從單一文件或一小部分文件提取答案 Document Retriever 遵循經典的 QA System，先用高效的 （非機器學習）的 document retrieval system 縮小搜索範圍，並專注於比較可能有關的文章\n與基於 ElasticSearch 的 Wikipedia Search API 相比，簡單的 inverted index lookup 和 term vector model scoring 表現的十分好\n文章和問題被表示為 TF-IDF weighted bag-of-words vectors\n作者考慮透過考慮 local word order 和 n-gram features 來進一步改善\n表現最佳的系統用 bigram counts，並利用 hashing 映射到 $2^{24}$ bins 來保持 speed 和 memory efficiency，用的是 unsigned murmur3 hash\nDocument Retriever 作為模型的第一部分，設定為對任何問題返回 5 個相關的文章\n這些文章再交由 Document Reader 來處理\nDocument Reader Paragraph encoding $p_i$ 是段落 $p$ 中的 token，期望 $p_i$ 可以被 encode 成帶有周圍資訊的向量\n採用的是 multi-layer bidirectional LSTM\n特徵向量 $p_i$ 由以下部分組成：\nWord embedding\n用 300 維的 Glove word embedding，固定大部分預訓練的 word embedding，只 finetune 最常見的 1000 個 question words，例如 what, how, which Exact match\n採用三個簡單的 binary features，用來表示 $p_i$ 是否與問題中的 question word $q$ 精確匹配，無論是原始形式、小寫，還是 lemma form Token features\n作者添加了一些 manual feature 好反應 $p_i$ 在 context 中的屬性，比如 part-of-speech (POS)、named entity recognition (NER) tags 和它的 (normalized) term frequency (TF) Aligned question embedding\n$f_{align}(p_i)=\\sum_j a_{i,j}E(q_j)$ $E$ 是 word embedding $a_{i,j}$ 是 attention score，計算 $p_i$ 和每個 $q_j$ 之間的 similarity Question encoding 這個比較簡單，只是在 word embedding 上加上一層 RNN，並把 hidden units 重新結合成一個向量\nPrediction 把 $\\{p_1,\u0026hellip;,p_m\\}$ 和 $q$ 作為 input，並個別單獨訓練兩個分類器預測開頭和結尾的位置\n具體來說，作者用 bilinear term 來計算每個 $p_i$ 和 $q$ 之間的相似度，並計算每個 $p_i$ 是開頭的機率和結尾的機率\n最後選擇最佳範圍，從 token $i$ 到 token $i'$\n$i \\le i\u0026rsquo; \\le i+15$\n並且使 $P_{start}(i) \\times P_{end}(i\u0026rsquo;)$ 最大化\nData 本文的工作依賴三種資料：\nWikipedia 尋找答案的來源 SQuAD 用來訓練和評估模型 另外三個 QA 資料集 (WebQuestions, CuratedTREC, WikiMovies) 用來測試模型在 Open-domain QA 上的泛化能力，並評估模型從 multitask learning 和 distant supervision 中獲益的程度 Wikipedia (Knowledge Source) 用 2016-12-21 dump2 的 English Wikipedia\n對於每頁，只提取文本，並刪除結構化的資料（lists and figures）\n丟棄 disambiguation pages, list, index 和 outline pages，保留了 5,075,182 篇文章\nSQuAD 使用兩個 evaluation metrics：\nExact string match (EM) F1 score 為了評估 open-domain QA 的能力，作者只有使用 SQuAD 的 QA pairs，要求系統在無法存取相關段落的情況下發現正確的 answer span\n不像標準的 SQuAD setting 會給出相關段落\nOpen-domain QA Evaluation Resources SQuAD 是目前可用的最大的 general purpose QA 資料集之一\n收集過程包括向每個 human annotator 展示一個段落，並寫一個問題\n因此，distribution 非常特定\n作者建議在其他 open-domain QA 資料集上評估系統，他們以不同的方式建構\nCuratedTREC 使用大版本，包含 TREC 1999, 2000, 2001 和 2002 的 2180 個問題\nWebQuestions 這資料集旨在回答 Freebase KB 的問題\n透過 Google Suggest API 抓問題，再用 Amazon Mechanical Turk 來獲取答案\n作者用 entity names 把每個 answer 轉成答案，以便不引入 Freebase IDs\nWikiMovies 包含對電影領域的 96k 個問答對\nDistantly Supervised Data 上面說的資料集除了 SQuAD 都沒有相關段落，因此不能直接訓練 Document Reader\n追隨之前已有的利用 distant supervision (DS) 來做 relation extraction 的工作，作者用一個程式自動把段落和此類訓練範例做相關聯\n對每個問答對使用以下過程來建立訓練集：\n首先，對問題用 Document Retriever 找到前 5 個相關的段落\n與已知答案沒有 exact match 的段落都被直接丟棄\n短於 25 個字元或長於 1500 個字元的段落也被丟棄\n如果在問題中找到 named entity，不包含該 named entity 的段落也被丟棄\n對於每個 retrived page 的每個段落，使用 question 和 20 token window 間的 unigram 和 bigram overlap 來計算相似度，保留重疊度最高的前五個段落\n將找到的每個 pair 加入到 DS 訓練集中\n大約一半的 DS 範例來自 SQuAD 以外的頁面\nExperiments Finding Relevant Articles 先檢查 Retriever 在所有 QA 資料集上的性能\n計算 ration 是根據特定的問題，考慮這些問題對應的文本在前 5 個相關文章中的比例\n結果表明，比 Wikipedia Search 還更好，尤其是使用 bigram hashing 的情況下\nReader Evaluation on SQuAD Implementation details 使用 h=128 的 3 層雙向 LSTM，來做 paragraph encoding 和 question encoding\n使用 Stanford CoreNLP 來做 tokenization 並生成 lemma, part-of-speech 和 named entity tags\nOptimizer 使用 Adamax\nDropout rate 為 0.3\nResult and analysis 作者的系統可以在 SQuAD 上達到 SOTA\n做了 ablation study，結果表明所有功能都會影響性能\n有趣的是，單獨沒有 $f_{alignd}$ 或 $f_{exact_match}$ 對性能不會有極大的影響，但兩個都沒有就會急遽下降\nFull Wikipedia Question Answering 比較三個版本的 DrQA：\nSQuAD 只在 SQuAD 上訓練，並用於所有評估資料集 Fine-tune (DS) 先在 SQuAD 上預訓練，在用 DS 訓練集對每個資料集進行微調 Multitask (DS) 在 SQuAD 和 DS 訓練集上聯合訓練 Results Conclusion 兩個明顯的 angles of attack：\n把多個段落直接納入 Document Reader 的訓練，因為他目前獨立訓練每個段落 實作一個 end-to-end training 的 pipeline，可以在一個模型中結合 Document Retriever 和 Document Reader ","date":"2023-12-25T00:00:12+08:00","permalink":"https://roykesydon.github.io/Blog/p/drqa-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"DrQA 論文閱讀"},{"content":"介紹 ChatGPT 的缺陷\n沒有一定時間後的資料 (當時) 沒有辦法連結外部私人資料 (e.g. Google Drive) LangChain 的優點\nIntegration 可以連結外部資料 Agency 讓 LLM 可以和環境互動，做出決策 Components 結構 Schema 對話 System: 對話的 context Human: 你的詢問 AI: AI 的回答 Document 儲存一段文字以集 metadata 的結構 Embedding OpenAIEmbeddings 可以把文字轉換成向量，預設是 1536 維 但是有最大長度限制 文字處理 Output Parser 讓模型重生你想要的格式，並轉換成你想要的結構，比如 json\n資料儲存 Indexes Document_loaders\n可以從不同的來源獲得資料 text_splitter\n把大量的文字切成多個 chunks retriever\n用來找到相近的文件 VectorStores\nChroma local storage 交互 PromptTemplate 用來往 String Template 填入變數 有些 Component 會和這個用法組合，所以不適合直接換成 f-string FewShotPromptTemplate 可以用自己準備的一些例子結合 PromptTemplate 來做 Few-shot learning 可以透過 FAISS 來找到最相近的例子 Chain 用在有多個有序的問題的情況\nmulti-step workflow\nVectorDBQA\n可以用在搜索 local 的向量資料庫 Instruction 結合 context 的模式 (Summarize)\n模式 Stuffing Map Reduce Refine Map-Rerank 說明 直接把 context 和 query 結合 把 Document 切成多塊 ，把每塊交給 LLM，轉換成 summary，反覆從這些 summary 生 summary 每次切一小塊，並且和先前的結果做 summary 讓每個 chunk 和 query 去生答案，並要模型對自己的答案評分，最後選分數高的 優點 只需 call 一次 API、涵蓋所有資料 可以餵入更大的文件、可以平行運算 可以餵入更大的文件 對於簡單的問題可能比較有效 缺點 容易達到 token 上限 call 多次 API、summary 的過程中會流失資訊 call 多次 API、summary 的過程中會流失資訊 沒有辦法結合多個 Document 的資訊 Agent 有些應用中，你可能不知道該遵循什麼流程來讓 LLM 完成任務，這時候你會需要讓 LLM 自行決定要採取哪些動作以及採取的順序 可以動態地利用 Chain verbose=True 的時候會印出思考過程 Tools 有比如 Google Search 之類的 Tool 可以結合應用 Memory ConversationChain 讓 Chain 和 Agent 可以保留之前的對話 ","date":"2023-12-18T00:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/langchain-%E7%AD%86%E8%A8%98/","title":"LangChain 筆記"},{"content":"paper: Learning Transferable Visual Models From Natural Language Supervision\nAbstract 現有的 SOTA CV system 可以經過訓練預測一組固定的類別。 但這種監督式的方法也受限了通用性，因為需要額外的 labeled data 來擴展。\n直接從 raw text 學習 image 是個有前途的替代方案。\n本文證明了「預測哪個是圖片的 caption」這種形式的預訓練是一種高效且可擴展的方法，可以從 internet 上蒐集的 4 億對資料從頭學習到 SOTA image representation。\n預訓練後，透過自然語言來引導，就可以在下游任務十線 zero-shot。\n本文對 30 個不同的現有電腦視覺資料集進行比較，可以在多數任務和監督式學習的 baseline 競爭，而且無須任資料集來做特別的訓練。\n例如在 ImageNet 上做 zero-shot 可以和 ResNet-50 取得相近的準確度。\nIntroduction and Motivating Work 直接從原始文本學習的預訓練方法在過去幾年徹底改變了 NLP。\nTask-agnostic (與下游任務無關) objectives，比如 autoregressive 和 masked language modeling，讓模型得以隨著 compute, model capacity, 和 data 規模的增長，使能力也逐步提升。\n在 \u0026ldquo;text-to-text\u0026rdquo; 這種輸入輸出形式的預訓練，使模型轉移到下游任務的時候，不用特地客製化 output head，或對資料集做特別地處理。\n這些結果表明，現代的預訓練方法在 web-scale 的文字集合的表現已經超過了用高品質的人為標記 NLP 資料集。\n然而在 CV 等領域，在 ImageNet 這種人為標記的資料集上做預訓練卻依然是標準做法。\n直接從網路文本學習的可擴展預訓練方法或許能在 CV 帶來類似的突破。\n以往有一些工作嘗試利用幾乎無限量的原始文本而不是有限數量的 \u0026ldquo;gold-labels\u0026rdquo;， 但是這些方法都有一些妥協，比如都利用 softmax 來執行預測，使其沒辦法應付新類別，嚴重限制了 zero-shot 的能力。\n作者提了幾個弱監督學習的例子，他們利用額外的資料結合預訓練，來幫忙改善監督式學習的結果。\n也提了幾個和 CLIP 類似的工作 VirTex, ICMLM, ConVIRT，想利用 Transformer，從 Natural Language 中學習 image representation。\n這些 weakly supervised model 和最近從 NLP 學習 image representation 的方法有一個重大差異，規模。\n最近的一些研究，比如一些弱監督學習在數百萬到數十億張照片上訓練了多個 accelerator years。但是和 CLIP 相似的研究只在二十萬張圖片上訓練了幾天。\n本文將規模拉高，以縮短規模上的差距。\n作者在 internet 上蒐集了 4 億對圖片和文字的資料，做成新的資料集，並提出了 CLIP，ConVIRT 的簡化版本。\n作者在 30 幾個資料集上測試，基本上能和監督式的模型競爭。\n如果用 linear-probe，比公開可用的 SOTA ImageNet model 還更好。\nApproach Natural Language Supervision 核心想法是利用 natural language 來學習 perception。\n作者稱這不是一個新想法，但以往相似的方法的用語多樣，他介紹了四篇文章，但把從文字和圖片中學習 image representation 的方法個別稱為：無監督、自監督、弱監督、監督式。\n擴展 natural language supervision 比起圖像分類簡單的多，不必定好類別，再去標註每張照片的類別。\n而且 natural language supervision 還有個優勢，他不只能學習 image representation，還能將其和文字相關聯，使其更好做 zero-shot 的遷移。\nCreating a Sufficiently Large Dataset 現有工作主要用三個資料集:\nMS-COCO Visual Genome YFCC100M MS-COCO 和 Visual Genome 都是高品質的人為標記資料集，但是按照現代標準來看，它們很小，每個資料集大約有 100,000 張訓練照片。\n相較之下，作者舉了一個最近的研究，用了 3.5 Billion 張 Instagram 照片作為訓練資料。\nYFCC100M 是一個可能的替代方案，它有 100 million 張照片，但每張照片的 metadata 資料稀疏，而且良莠不齊。\n比如許多檔名是自動產生的，可能是時間，或是相機的參數。\n經過過濾，保留帶有自然語言的標題或描述的圖像，資料集縮小了 6 倍，只剩 15000 萬張照片，和 ImageNet 的大小相當。\nnatural language supervision 的一個主要動機是網路上公開著大量這種形式的 data。 由於現有資料集沒有反映這種可能性，因此只考慮這些資料集會低估這方面研究的潛力。\n所以作者建立了一個新的包含 400 million pairs 的資料集，從網路上各種公開的來源蒐集的。\n為了盡可能涵蓋所有的 visual concepts，作者在建構資料集的時候準備了 50 萬組特定的 query，每組 query 最多包含 20,000 個 pair，來進行 class balance。\n產生的資料集的總字數和 GPT-2 用的 WebText 差不多。\n將此資料集稱為 WIT，全名是 WebImageText。\nSelecting an Efficient Pre-Training Method 最先進的 CV System 需要大量的計算。\n作者舉了兩個計算量都非常恐怖的模型，而且他們只能預測 1000 個 ImageNet 的類別。 其中一個花了 19 個 GPU years，另一個花了 33 個 TPUv3 core-years。 乍看之下，從自然語言中學習一組開放的視覺概念似乎令人生畏。\n但在作者努力的過程中，他們發現訓練效率是成功擴展自然語言監督的關鍵，也根據該指標選定最終的預訓練方法。\n最初的方法和 VirTex 相似，從頭開始訓練一個 CNN，和 text transformer 來預測 caption。\nFig.2 展示的 Transformer 語言模型的計算量是 ResNet-50 Image encoder 的兩倍。 預測 caption 比預測 caption 但採用詞袋的方式還慢三倍。\n這樣預測 caption 是一個困難的任務，同一張照片對應的 caption 可能出現的描述甚至有非常多種。 最近在 Contrastive representation learning 方面的研究發現 contrastive objectives 有不錯的表現。\n因此作者探索一種方法是，只預測文本和哪一個圖片配對，而不是預測確切的單字。\n因為資料集超級大，overfitting 的問題影響不大。\n此外，作者發現對於 encoder 的 representation，要轉換到 multi-model embedding space，只需要使用 linear projection 即可，不需要 non-linear，兩者之間差別不大。\nData augmentation 只有使用 random crop，而沒有使用其他的。\nChoosing and Scaling a Model 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # image_encoder - ResNet or Vision Transformer # text_encoder - CBOW or Text Transformer # I[n, h, w, c] - minibatch of aligned images # T[n, l] - minibatch of aligned texts # W_i[d_i, d_e] - learned proj of image to embed # W_t[d_t, d_e] - learned proj of text to embed # t - learned temperature parameter # extract feature representations of each modality I_f = image_encoder(I) #[n, d_i] T_f = text_encoder(T) #[n, d_t] # joint multimodal embedding [n, d_e] I_e = l2_normalize(np.dot(I_f, W_i), axis=1) T_e = l2_normalize(np.dot(T_f, W_t), axis=1) # scaled pairwise cosine similarities [n, n] logits = np.dot(I_e, T_e.T) * np.exp(t) # symmetric loss function labels = np.arange(n) loss_i = cross_entropy_loss(logits, labels, axis=0) loss_t = cross_entropy_loss(logits, labels, axis=1) loss = (loss_i + loss_t)/2 Experiments Prompt Engineering and Ensembling 一種常見的問題是 polysemy，一個單字可能有多種意思，比如 \u0026ldquo;boxer\u0026rdquo; 可能是一種狗，或是拳擊手。 如果一張圖片對應一個單字就會面臨這問題。\n另一種是 distribution gap，比如訓練用句子，但測試用單字。 為了緩解這問題，作者發現用 prompt template \u0026ldquo;A photo of a {label}.\u0026rdquo; 比直接用 label 好。\n光用這個 prompt template 就提高 1.3 % 在 ImageNet 上的準確度。\n如果可以給其他額外訊息會更有幫助，比如對於寵物的資料集，可以用 \u0026ldquo;A photo of a {label}, a type of pet.\u0026quot;。\n對於 OCR 資料集，作者發現在要識別的文字或數字前後加上引號可以提高效能。\n再來是 prompt ensembling，作者發現用多個 prompt template 來預測，然後綜合結果，可以提高效能。 作者用了 80 個 template。在 ImageNet 上比用單一的 prompt template 提高 3.5 % 的 performance。\n綜合考慮 prompt engineering 和 prompt ensembling，作者在 ImageNet 上的準確度提高大概 5%。\n這裡列幾個作者用的 prompt template: \u0026ldquo;a bad photo of a {}.\u0026rdquo; \u0026ldquo;a photo of many {}.\u0026rdquo; \u0026ldquo;a sculpture of a {}.\u0026rdquo; \u0026ldquo;a photo of the hard to see {}.\u0026rdquo; Analysis of Zero-Shot CLIP Performance 對於一般的物體分類的資料集，CLIP 表現較好。\n下面有些複雜、專門、抽象的任務，CLIP 則表現的很差，比如計算場景中有多少物體的 （CLEVRCounts）、衛星圖像分類（EuroSAT）或是 識別最近的汽車距離（KITTI Distance）\n對於這種特別難的任務，讓 CLIP 做 zero-shot 不太合理。 可能用 few-shot 的方式會比較好。\nBiT 是 google 為 Transfer Learning 設計的預訓練模型，在分類問題，Few-shot learning 上有良好的表現。\nRepresentation Learning 這節探討完全使用下游任務資料集而非 Zero-shot 或 few-shot 的情況。\n作者選用 linear-probe 而不是 finetune 來做下游任務的評估。\n因為他們的重點是開發與資料集無關的預訓練方法，finetune 有可能讓一個預訓練學習 representation 失敗的模型在微調過程中變好。 而 linear-probe 的限制可以凸顯這些失敗。\nComparison to Human Performance 再來是 CLIP 和人類相比的結果。 挑選了五個人在寵物資料集上比較的結果。\nData Overlap Analysis 可能會有人質疑，CLIP 的表現是因為訓練資料集和測試資料集有重疊。 但作者做了一些實驗，有些資料集完全沒有偵測到重疊。 對有重疊的做實驗，發現有重疊的對效果提升影響很小。\nLimitations CLIP 雖然可以和作為 Baseline 的 ResNet-50 打平手，但現在的 SOTA 遠高於該 Baseline。\n作者發現再繼續加大模型和資料是可以繼續提升性能的，但作者估計要達到現有的 SOTA 需要增加大概 1000 倍的計算量才能達到，使用現有的硬體是不可行的。\nCLIP 對細分類、抽象或更難的任務表現不好，作者相信還有許多任務是 CLIP 用 zero-shot 只能達到亂猜等級的。\nZero-Shot 的 CLIP 很難泛化到 out-of-distribution 的資料，比如在 MNIST 上只能達到 88% 的準確度。 作者發現預訓練資料幾乎沒有類似 MNIST 的圖片。\n盡管 CLIP 可以靈活應用各種 Zero-Shot 的分類，但基本上還是從你給定的分類選擇。 和真正靈活的方法（生成 image caption）相比，是重大的限制。\n一個值得嘗試的簡單想法是把 contrastive objective 和 generative objective，結合。\nCLIP 也沒有解決深度學習資料效率低下的問題，CLIP 訓練了 32 個 epoch，如果把預訓練期間的照片以一秒一張來呈現，需要 405 年。 把 CLIP 和 self-supervision 或者和 self-training 做結合是有前途的方向。\n雖然作者強調 Zero-Shot Learning，但是作者還是有反覆檢查下游任務測試集的表現，來調整 CLIP。 每次都用 ImageNet 來確認，並不算真正的 zero-shot 的情況。 如果能再創一個新的資料集，專門用來評估 zero-shot 遷移的能力會更恰當。\n爬下來的資料有可能帶有社會偏見。\n有一些複雜的任務很難用文字來傳達，雖然實際的訓練樣本有用，但 CLIP 並不會針對 few-shot 最佳化。有個違反直覺的結果，可以注意到在某些情況下，few-shot 不見得比 zero-shot 好。\n額外應用 圖片生成 StyleCLIP: Text-Driven Manipulation of StyleGAN Imagery 用文字引導生成圖片 CLIPDraw: Exploring Text-to-Drawing Synthesis through Language-Image Encoders 物件偵測 Open-Vocabulary Object Detection via Vision and Language Knowledge Distillation 將基礎類別再做細分類 OCR Contrastive Language-Image Forensic Search 搜索影片中有沒有文本描述的物體 筆記 prompt engineering prompt ensemble\n","date":"2023-11-21T01:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/clip-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"CLIP 論文閱讀"},{"content":"paper: PonderNet: Learning to Ponder\nAbstract CNN 在 CV 領域是首選，但基於 attention 的網路也在變流行。\n本文證明雖然 convolution 和 attention 都可以獲得良好的 performance，但皆非必須。\n本文提出了 MLP-Mixer，一種純 MLP 的架構，包含兩種 layer：\n將 MLP 獨立用在 patch mixing per-location features 將 MLP 用在 patches 之間。 mixing spatial information Introduction 本文提出了完全基於 MLP 的 MLP-Mixer ( 又簡稱 Mixer )，有競爭力卻概念和技術上都很簡單。\n有兩種 MLP layer：\nChannel-Mixing MLP\n用在每個 patch 上 讓不同 channel 之間的資訊互相交換 Token-Mixing MLP\n用在所有 patch 上 讓空間資訊互相交換 這兩者交錯出現，讓兩個輸入維度可以交互作用\n在極端情況下，本文的架構可以看做是一個非常特殊的 CNN，使用 1*1 卷積做 channel mixing，並用 single-channel 且 full receptive field 的 1D 卷積做 token mixing。\n反之則不然，因為經典的 CNN 並不是 Mixer 的特例。\n盡管很簡單，但 Mixer 卻取得有競爭力的結果。\n然而與 ViT 一樣，在一切特有的 CNN 架構下略有欠缺。\nMixer Architecture Mixer 的核心概念是想把\nmix features at a given spatial location mix features between different spatial locations 給分開來\n所有的 patch 都是用同一個 projection matrix\n注意 fig1 的 MLP2，他們共享同樣的參數，這樣綁定參數可以預防 C 和 S 增加時使架構增長過快。在 seperable convolution 中，不同通道使用不同的 kernel。不過作者這樣的選擇並不影響實際的 performance。\nMixer 的所有 Layer 都具備相同的輸入大小。\n這種「isotropic」的設計和 Transformer 或 RNN 比較像。\n與大多數具有 pyramidal structure 的 CNN 不同，它們在更深的層有更低的 resolution，但有更多 channel。\n不過上面只是探討典型的設計，也存在例外，比如 isotropic Resnet 或 pyramidal ViT。\n除了 MLP，Mixer 還有用到 LayerNorm 和 skip connection。\n但是 Mixer 沒有用到 positional encoding，因為 token-mixing MLP 本身就對位置敏感。\\\nExperiments Mixer 用中大型資料集預訓練，然後在一系列中小資料集上評估。\n目標不是拿到 SOTA，而是顯示出與 SOTA 的 CNN 和 attention-based model 相比，Mixer 有競爭力。\nFine-tuning 在 fine-tuning 時，用比預訓練時還要高的 resolution。 由於每個 patch 的 resolution 是固定的，這樣會導致有更多的 patches。\n對於這個問題，採用以下解法：\n我們原先預計吃 S 個 patch，現在我們由於輸入解析度更高，而且 patch 大小不變，所以我們得到一個比 S 還大的 $S\u0026rsquo;$。 所以我們在很多地方就需要比原先權重矩陣 W 還更大的 $W'$\n我們要把 $S\u0026rsquo;$ 拆成 $K^2$ 個長度為 $S$ 的 sequence，K 是整數。\n並且我們把 $W\u0026rsquo;$ 的 shape 改成 $(W.shape[0] * K^2, W.shape[1] * K^2)$\n然後我們把 $W\u0026rsquo;$ 作為 block-diagonal matrix 來初始化，把 $W$ copy 好幾份，放在 main diagonal 上。\n所有權重都用類似的處理方法。\n","date":"2023-10-30T00:27:55+08:00","permalink":"https://roykesydon.github.io/Blog/p/mlp-mixer-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"MLP-Mixer 論文閱讀"},{"content":"大致概念 屬於生成式 AI，一開始用在生成圖片，後來也有應用到諸如 NLP 等領域。\n下文稱呼原圖為 sprite。\n與 AutoEncoder 有點類似，先取得一張 sprite，隨著時間推進，每次都在圖片上加一層雜訊，反覆疊加，迭代多次後，就會得到一張難以看出原圖的雜訊。\n從 sprite 到只能看出是一團雜訊並非是一步到位的過程。一開始沒有雜訊時可以看出原本的 sprite，一個迭代後可能可以勉強看出原本的 sprite，再幾個迭代後可能也還能看出原本的 outline，經過許多次後才會變成完全辨識不了的雜訊。\n我們期望模型做的事情則是從 gaussian noise 逐步推回 sprite，同樣不是一步到位，而是讓模型預測上一個時間點的雜訊，相減後再逐步推回 sprite，這過程稱為 denoise。\nDDPM 實現 Diffusion 可能會有點 confusing，因為他實作上和上面說的不太相同。 在訓練的時候，我們會採樣三個東西：\n訓練圖片 (sprite) 雜訊 時間點 (t) 訓練階段的時候，我們會把「原始乾淨的圖片」和「雜訊」根據時間進行不同比例的相加 (混合)，t 越大，雜訊的比例越大。\n模型預測的目標是前面 sample 出的雜訊。\n這與前面說的概念相悖。按照前面的說法，對於時間點 t，應該是以一張加了 t-1 次雜訊的 sprite 作為輸入，再加上 t 所 sample 出的雜訊。\n現在實作卻是原始乾淨的 sprite 直接根據時間點混和某個雜訊。\n這背後的數學推導十分冗長，這裡不敘述，但需知道實作差異。\nInference 在推論階段的時候，每次 denoise 後需要把圖片和額外 sample 的 noise 相加。這個 noise 和前面的 noise 一樣，都是從 mean=0, std=1 的 gaussian distribution 中 sample 出來的。\n不加的話似乎還容易有 Mode Collapse 的現象。 看到一個說法是，模型喜歡吃圖片加上雜訊的圖像作為圖片，在圖片上加上 noise 似乎會更符合模型預期的輸入。\n看了李弘毅的影片，也有基於隨機性的觀點。\n生成式 Model 生成文章時永遠取機率最大的，不見得有更好的效果：\n有研究是讓 Model 選機率最大的，結果容易生出反覆跳針的文章。\n也有把人類寫的文章去餵給 Model 看，從他的角度看人類寫的下一個字的機率是多少，發現人類寫的文章很常出現一下機率高一下機率低的字。\n某篇語音合成的文章需要在推論階段「啟用」dropout 才可以有好的結果。\nDiffusion 也有可能成功的點是在於並非「一次到位」而是「N 次到位」。 從這樣的角度看，Diffusion 是 autoregressive 模型。\n類似的作法也有 Mask-Predict，大致概念是從原本都是 Mask 的情境開始，將一些信心高的預測留住，信心低的保持為 Mask，一步步預測出所有資訊。\n","date":"2023-10-23T00:27:55+08:00","permalink":"https://roykesydon.github.io/Blog/p/diffusion-%E5%85%A5%E9%96%80/","title":"Diffusion 入門"},{"content":"Creational patterns 關於 object creation 的 patterns。\nFactory Method 將不同 Product 定義一個共有的 Interface，並由子類別實作，透過工廠類別來產生實體。\n將建立 Product 的方法獨立出來，符合 Single Responsibility Principle。 可以輕易擴充新的 Product，而不用修改原本的程式碼，符合 Open-Closed Principle。\nAbstract Factory 相比 Factory Method，現在的情境是有多個 Product，而且每次都是使用同一系列的 Product。\nBuilder 對於建構一個複雜且具備多種組合的產品，可以透過建構巨大的建構函式或是覆蓋所有可能的子類別來解決。\n但都存在其問題，要不是大量的子類別，不然就是難以呼叫的建構函式。\n把建立物件的每個 component 獨立出來，並且切成多個可分開執行的 step。\n由 Builder 來負責生出每一個 component，Director 不是必需的，但有需要的話可以讓他幫忙調用 Builder 的 method，好在專案中重複使用。\nPrototype 使用在想要獲得某個對象的 clone 的情境。\n把 clone 的責任交給對象本身，而不是交給 Client。由對象本身提供 clone method。\nSingleton 確保某個類別只有一個 instance，並且提供一個 global access point。\n但是這樣違反了 Single Responsibility Principle，因為除了原本的功能外，還要負責管理自己的 instance。\nStructural patterns 探討如何組裝類別和物件成為更大的結構。\nAdapter 轉換某個對象的 interface 到另外一種 interface，讓另外一個 Object 可以理解他。 就像 XML 要轉到 JSON。\nBrdige 使用在需要在多個 orthogonal (independent) 的維度上擴展類別時的情境。 讓情況從難以計數的子類別數，變成多組功能聯合起來。\n拆成 abstraction (high-level control) 和 implementation (實際工作)， 由 abstraction 來控制 implementation，比如 GUI 來控制底下的 API\nComposite 用在某些層級結構。\n對於 Composite (Container)，不但實現 Component，也提供一個 list 來存放子 component。\n對 Composite 的操作，會被委託給子 component，不需要 client 擔心。\n就像指揮官只需要對高階軍官下命令。\nDecorator 當今天有多種同類型的東西，你可以能會同時用到多種子類別所形成的組合時，就可以用 Decorator。\n比如多種類型的 notification，你可能同時想要 FB 和 TG 的，或是只想要其中一個。 或是多件衣服，有超級多種的穿搭。\n但這是一層層的感覺，具有順序性。 Decorator 和 Component 都繼承同一個 interface。 就像是 Data data = new Encrypt(new Compress(new FileData()))。\n存在很難從 stack 中刪除特定 decorator 的缺點。\nFacade 為複雜的一堆子系統提供一個 Class，讓 client 可以使用他們關心的功能。 實際怎麼調用 client 無須知道。\n容易形成 god object。\nFlyweight 對於大量類似的物件，為求節省記憶體而誕生的 pattern。\n把物件的內容分成 intrinsic 和 extrinsic，intrinsic 是不會改變的 (unique)，而 extrinsic 是會改變的 (repeating)。\n讓 extrinsic 的東西用同一塊記憶體。\nProxy 用在多個服務想要調用某個重量級資源的情境下。\n存在多種 proxy 的應用類型，比如 cache 機制來加速資源的存取，並減少系統資源消耗。\nBehavioral patterns Chain of Responsibility 對於一系列檢查的情況，可以用這種作法，有兩種形式：\n一路檢查，檢查失敗則中斷請求。 每個 Handler 自行決定要不要處理該請求，要的話則不會往下傳。 這樣可能會最後沒人處理 就像網頁點擊事件，一層層元素往下問。\nCommand 把請求獨立出來，讓該請求可以被用作參數、佇列、撤銷行為等。\n比如多種不同的按鈕背後都執行同一個存檔功能。存檔就可以作為 command 獨立出來。 背後再根據這個 command 實施對應的業務邏輯。\nIterator 用來需要遍歷集合中元素的情境，把不同種類的遍歷行為細節隱藏起來。\n提供多種不同的 iterator，但遵循同一種 interface，讓使用者可以根據需要選擇 iterator。 對於不關心用哪種 iterator 的使用者，也能受益於 iterator 的 interface，而不必耦合於特定的演算法。\nMediator 禁止多個 component 間的直接溝通，迫使他們透過 mediator 來溝通，避免複雜的關係。 所有人只能透過 notify mediator 來溝通，mediator 根據 sender 和 event，來做出相應處理。\nMemento 讓你可以儲存和復原到先前的狀態。\n讓要儲存的對象自己生成 snapshot。\n建議存在名為 momento 的 special object，這個 object 不能讓除了 producer 外的其他 object 直接存取。 其他 object 只能透過 limited interface 來取得 metadata。\n這些限制讓 momento 可以交給其他 object 來管理，稱為 caretaker。\nObserver 定義 subscription 機制。\n有 interesting state 的 object 稱為 subject，但由於他也會通知其他人，所以又稱為 publisher。追蹤它的人稱為 Subscriber。\nState 用在類似 Finite-State Machine 的情況。\n該 pattern 把每個 state 獨立成一個 Class，把實際的行為委託給 state，而不是由 context (原始物件) 來控制。Context 只管切換 state。\nStrategy 把不同實現方法的演算法定義為遵循同一個 interface 的類別，讓使用者可以根據需要選擇演算法。\nTemplate Method 把演算法拆成多個步驟，讓子類別可以覆寫其中的步驟，但不改變演算法的結構。\nVisitor 讓我們可以把演算法從執行他們的 object 中分離出來。\n假設我們要對一堆繼承 client 屬性的公司新增 sendEmail 功能，如果我們在 client 新增 sendEmail 並且 override 每個子 class，就會違反 Single Responsibility Principle 和 Open-Closed Principle。\n要利用 Double-Dispatch，讓 Object 本身選擇該用的演算法。\n雖然這樣依然會修改到子 class，但這屬於微不足道的改變，而且可以讓之後新增的一些功能不用再去修改這些子 class。\n","date":"2023-10-10T00:00:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E8%A8%AD%E8%A8%88%E6%A8%A1%E5%BC%8F-desing-pattern/","title":"設計模式 Desing Pattern"},{"content":"提高查找相似向量的速度 任何非暴力搜尋的搜尋方法，都會一定程度上的降低搜索品質。 需要在搜索品質和速度進行 trade-off。\nK-Means 可用在將向量資料庫分群，以便縮小查找相似向量的範圍。\n迭代計算群心，直到收斂\n依據離群心的遠近分類\n問題 相近的向量有可能被分到不同群\n可以透過「用更多類，並搜索多個最近群」來緩解問題\n可以找其他 ANN (Approximate Nearest Neighbors) 演算法來面對該問題\n位置敏感哈希 (Locality Sensitive Hashing, LSH) 讓越相似的向量越容易碰撞，找相似向量就在同個 bucket 找\n實現方法 此處挑一種方式舉例，此處用隨機超平面舉例。\n可以在空間中隨機生成多個 (n-1) 維度的超平面，將兩邊分類為 0 和 1。 距離較遠的點對被切割開的機率會比距離較近的點對還大。 用這樣的方法，會讓相近的點對生出的 Hash 值較接近。\n問題 接近的向量有可能因為機率因素被分到不同 bucket 將向量分段，每段有匹配到同個 bucket 就視作候選項 減少查找相似向量的記憶體開銷 大量的高維向量會造成大量的記憶體開銷\nK-Means 把同一群的向量都用群心向量代替，是一種有損壓縮。\n問題 但這樣需要另外的空間來存取 codebook (向量對應表)，在某些情況不見得比原本的向量還省空間，甚至可能花更多。\nn 維的向量可能需要 $2^{\\frac{n}{2}}$ 的 class 才可以較好的分類 (來源未知)\n可以透過把高維向量切割成多個低維子向量個別處理再合併來緩解該問題。\n該方法稱為 Product Quntization (PQ)\n其他做法 NSW 六度分隔理論 (Six degrees of separation) 對於世界上兩個互不相識的人，只需要六個中間人就可以建立起連結。\n做法 我們想找對於某個目標向量而言最相似的向量。\n先隨機找一個點，找他的相鄰節點誰和目標向量最相近，並反覆此過程，直到所有相鄰節點都沒有自己離目標相近。\n六度分隔理論讓我們推測這過程可能很快就會結束。\n建立結構 我們得幫這些向量建立圖關係。\nDelaunay triangulation algorithm 可以用來建立圖關係 但靠 Delaunay triangulation algorithm，有可能隨機的向量和目標向量距離很遠，查找很慢。\nNSW 的實際做法是將所有向量隨機地放回圖中，並和最近的 k 個點連接。\n只看較短的連接，會發現和 Delaunay triangulation algorithm 產的圖相近，可以進行細粒度的查找。 只看較長的連接，則可達到快速導航的效果。\nHNSW 建立一個分層結構，越上層的點越稀疏、連線越長。\n和 NSW 相比，讓粗粒度到細粒度的導航過程更加穩定。\n但占用的記憶體空間更大。\n","date":"2023-10-06T00:27:55+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E6%9F%A5%E6%89%BE%E7%9B%B8%E4%BC%BC%E5%90%91%E9%87%8F/","title":"查找相似向量"},{"content":"Union-Find (DSU) 不同條件下的時間複雜度 待補 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 int find(int x) { if (f[x] == x) return x; else return f[x] = find(f[x]); } int merge(int x, int y) { f[find(x)] = find(y); } int main() { for (int i = 1; i \u0026lt;= n; i++) f[i] = i; x = find(x); y = find(y); if (x != y) { merge(x, y); } } Trie 1 2 3 4 5 6 7 8 9 10 11 class Node { public: int cnt; int id; Node* nxt[26]; Node() { cnt = 0; for (int i = 0; i \u0026lt; 26; i++) nxt[i] = nullptr; } }; Segment Tree 單點修改線段樹 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 #define pl(x) (x * 2 + 1) #define pr(x) (x * 2 + 2) void build(int index, int l, int r) { if (l == r) { tree[index] = arr[l]; return; } int mid = (l + r) / 2; build(pl(index), l, mid); build(pr(index), mid + 1, r); tree[index] = tree[pl(index)] * tree[pr(index)]; } void change(int index, int q, int l, int r, int \u0026amp;value) { if (l == r) { tree[index] = value; return; } int mid = (l + r) / 2; if (mid \u0026gt;= q) change(pl(index), q, l, mid, value); else change(pr(index), q, mid + 1, r, value); tree[index] = tree[pl(index)] * tree[pr(index)]; } void query(int index, int ql, int qr, int l, int r, int \u0026amp;ans) { if (ql \u0026lt;= l \u0026amp;\u0026amp; r \u0026lt;= qr) { ans *= tree[index]; return; } int mid = (l + r) / 2; if (ql \u0026lt;= mid) query(pl(index), ql, qr, l, mid, ans); if (mid \u0026lt; qr) query(pr(index), ql, qr, mid + 1, r, ans); } ","date":"2023-08-29T00:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E8%B3%87%E6%96%99%E7%B5%90%E6%A7%8B%E7%AD%86%E8%A8%98/","title":"資料結構筆記"},{"content":"Sorting Merge Sort 一直拆分兩邊最後再輪流 merge 起來，merge 時看兩邊開頭誰最小，依序放 都是 $O(nlogn)$ stable not in-place Quick sort 選定一個 pivot，用兩個指針從兩邊開始往中間找。當左指針找到比 pivot 大的數值，右指針找到比 pivot 小的數值後交換。直到兩個指針相遇，再把 pivot 換到中間，繼續兩邊處理\n最差會到 $O(n^2)$，平均 $O(nlogn)$\n選 pivot\n隨機選 Median of Three 選開頭、中間和結尾的中位數 Other Binary Exponentiation 快速冪 1 2 3 4 5 6 7 8 9 int qpow(int x, int m) { int ans = 1; while (m) { if (m \u0026amp; 1) ans *= x; x *= x; m \u0026gt;\u0026gt;= 1; } return ans; } Discretization 離散化 1 2 3 4 5 sort(vec.begin(), vec.end()); vec.resize(unique(vec.begin(), vec.end()) - vec.begin()); for (int i = 0; i \u0026lt; vec.size(); i++) { val[i] = lower_bound(vec.begin(), vec.end(), val[i]) - vec.begin(); } Ternary Search 三分搜 1 2 3 4 5 6 7 8 9 10 11 l = -10000.0; r = 10000.0; while (r - l \u0026gt; eps) { ml = (r - l) / 3.0 + l; mr = (r - l) * 2.0 / 3.0 + l; if (f(ml) \u0026gt; f(mr)) { l = ml; } else { r = mr; } } ","date":"2023-08-27T00:09:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E6%9C%AA%E5%88%86%E9%A1%9E%E6%BC%94%E7%AE%97%E6%B3%95-%E8%B3%87%E6%96%99%E7%B5%90%E6%A7%8B%E7%AD%86%E8%A8%98/","title":"未分類演算法 \u0026 資料結構筆記"},{"content":"Floyd-Warshall 1 2 3 4 for (int k = 0; k \u0026lt; nodeCount; k++) for (int i = 0; i \u0026lt; nodeCount; i++) for (int j = 0; j \u0026lt; nodeCount; j++) DP[i][j] = min(DP[i][j], DP[i][k]+ DP[k][j]); dijkstra 時間複雜度 $O((V+E)*log(E))$ 最差每條邊都要插入 heap 要取出 V 個點 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 class cmp { public: bool operator()(edge a,edge b) { if(a.weight\u0026lt;b.weight) return true; return false; } }; dis[a] = 0; priority_queue\u0026lt;edge, vector\u0026lt;edge\u0026gt;, cmp\u0026gt; pq; pq.push({a, 0}); while (!pq.empty()) { edge u = pq.top(); pq.pop(); if (!vis[u.to_node]) { vis[u.to_node] = 1; for (auto i : mp[u.to_node]) { if (dis[i.to_node] \u0026gt; dis[u.to_node] + i.weight) { dis[i.to_node] = dis[u.to_node] + i.weight; pq.push({i.to_node, dis[i.to_node]}); } } } } Topological Sorting 記得確認是不是 Directed Acyclic Graph BFS 是沒有前繼節點優先，DFS 是沒有後繼節點優先 用 BFS 的話就是把入度為 0 的點加入 Queue，一直維護該 Queue 1 2 3 4 5 6 7 8 9 10 void dfs(int u) { if (!vis[u]) { vis[u] = true; for (auto j : edge[u]) dfs(j); toposort.push_back(u); } } for (int i = 1; i \u0026lt;= n; i++) dfs(i); reverse(toposort.begin(), toposort.end()); 樹的直徑 兩次 DFS，第一次找到離任意點最遠的點，第二次從該點出發找到離他最遠的點，這兩個點之間的距離就是樹的直徑。\nLowest Common Ancestor 待補 Eulerian path 歐拉路徑 每條邊只能被訪問一次（一筆畫問題） 條件 除了兩個點外，其他都得為入度==出度。另外兩個點，最多有一個出度要比入度大一，最多有一個入度要比出度大一。（只能有 0 或 2 個奇點） 須為連通圖 視作無向圖的時候是否可以連到每個點 Matching Hungarian Algorithm 待補 最小點覆蓋等等 待補 ","date":"2023-08-27T00:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E5%9C%96%E8%AB%96%E7%AD%86%E8%A8%98/","title":"圖論筆記"},{"content":"簡介 Meta 在 2015 年公開的 API Query Language 常被用來和傳統的 REST API 比較，具備查詢更加靈活等特性 有在使用的公司 Facebook GitHub Twitter \u0026hellip; 和 REST API 的主要差別 Single Endpoint\n和 REST API 對於不同 resource 需要不同 endpoint 不同，GraphQL 對於所有 resource 都是從同一個 endpoint 進行存取 但 GraphQL 不能輕易地用 HTTP caching，因為現在只剩一種 URL 了 解決 Under-fetching 和 Over-fetching 問題\nUnder-fetching\n一個 API call 沒辦法取得所有想要的資料，需要多次 API call 假如要用 RESTful API 取得一個文章的作者，可能得先取得文章，再取得作者，這樣就需要兩次 API call 但 GraphQL 可以在一次 API call 中取得文章和作者，透過 nested query Over-fetching\n一個 API call 取得的資料比想要的還多，造成資源浪費 GraphQL 可以透過 query 定義只想取得的欄位 使用 和 RESTful API 不同，需要特別架個 GraphQL server，可以考慮用 Apollo Server\n要定義不同 Data type 的 schema、relationship，以及寫對應不同 query 的 resolver\nQuery 可能會是長這樣的東西\n1 2 3 4 5 6 7 8 9 10 11 query postQuery($id: ID!) { post(id: $id) { id title content author { id name } } } Mutation 新增、修改、刪除資料都屬於這塊\n1 2 3 4 5 6 7 8 9 10 11 query addPost($post: AddPostInput!) { addPost(post: $post) { id title content author { id name } } } ","date":"2023-08-22T00:00:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/graphql-%E7%B0%A1%E4%BB%8B/","title":"GraphQL 簡介"},{"content":"paper: End-to-End Object Detection with Transformers\nAbstract 作者把 object detection 視作一個 set prediction 問題。\n簡化了 pipeline，消除了許多 hand-designed components，比如 non-maximum suppression 和 anchor generation，這些 component 由我們對於任務的先驗知識構成。\n提出了一個新的目標函數，透過二分匹配（bipartite matching）進行預測，也用 Transformer encoder-decoder 架構。\n給予一組固定的 learned object query，DETR 可以推理 objects 和 globol image context 的關係，並「並行」輸出一組預測集。\nDETR 概念非常簡單。\nDETR 在 COCO 上和 Faster RCNN baseline 在準確度和 performance 上相當。\nDETR 可以很簡單地推廣到 Panoptic Segmentation。\nIntroduction 目標檢測的目標就是集合預測。\n但目前都用一些很間接的方式去做，像是用 proposals, anchors 或 window centers。\n但是這些方法性能明顯受限於後處理步驟，比如 non-maximum suppression，因為他們會產生大量冗餘的框。\n為了簡化 pipeline，作者提出了一種 End-to-End 的方法，以往也有一些嘗試，但他們要不添加了其他的先驗知識，不然就是在具有挑戰性的 benchmark 上表現不好。\n在 COCO 上和 Faster R-CNN 的性能相當，表現和速度都差不多。\nDETR 在大物體表現很好，可能是歸功於 Transformer non-local 的計算能力。 雖然 DETR 在小物體上表現倒不怎麼樣。\nDETR 需要超長的訓練時間，但 DETR 的設計理念可以拓展到 Panoptic Segmentation。\nRelated Work Set Prediction 沒有規範的深度學習模型可以直接預測集合。\n這些任務中的一個困難點是避免 near-dulicates（相近的重複檢測框） 當前多數檢測器用 NMS 來解決此問題，如果是 direct set prediction 就不用後處理。\nTransformers and Parallel Decoding Transformer 在各種地方表現出色，但推理成本令人望而生畏。\nObject detection 現在多數的目標檢測方法是基於一些初始的猜測，再去做預測。\n比如對於 two-stage 的方法，就是對於 proposals 往下做預測。\n對於 single-stage，初始猜測就是 anchors。\nSet-based loss 以前的一些作法比如 Learnable NMS 或 relation networks 都可以透過 attention 來處理不同預測之間的關係。\n用 direct set losses，他們不需要任何後處理。\n但是這些方法往往用額外的 hand-crafted context feature，比如 proposal box coordinates。作者尋找減少模型中先驗知識的方案。\nRecurrent detectors 以往有類似的工作，但他們是用 RNN。\nThe DETR model Object detection set prediction loss DETE 會給 N 個固定大小的集合預測。\n要解二分圖匹配，本文用 scipy 的 linear_sum_assignment 處理，他背後是匈牙利演算法。\n其實這種方法和 proposals 和 anchors 有差不多的作用，差別在於這裡會找一對一的匹配，而不用重複。\n目標函數：\n$L_{Hungarian}(y, \\text{\\^{y}}) = \\displaystyle\\sum^{N}_{i=1} [-log \\text{\\^{p}} $ $_{\\^{\\sigma}(i)}(c_i) + \\text{1}$ $_\\{$ $_{c_i \\neq \\text{\\o}}$ $_\\}$ $\\mathcal{L}$ $_{\\text{box}} (b_i, \\text{\\^{b}}$ $_{\\^{\\sigma}}(i))]$\n前面是分類的 loss，後面是 bounding box 的 loss。\n這邊有兩個改動，第一個是分類那邊不用 log，使值和 bounding box 的 loss 比較接近。\n另一個是 bounding box 那邊並不是用最常見的 L1，因為 L1 對於大的目標 loss 比較高，這裡除了 L1 還選用 generalized IoU loss，它在尺度上與 loss 無關。\nDETR architecture 用 CNN 從圖片抽特徵，拉直，餵給 Transformer encoder-decoder，得到一組預測集合。\n這裡 encoder 有助於特徵間彼此交互。\n訓練的時候，預測的框和 GT 做匹配，沒匹配到的就放到 \u0026ldquo;no object\u0026rdquo; class。\ndecoder 會餵入 object queries，這些是 learnable positional encodings。\nExperiments Ablations Number of encoder layers 作者透過改變 Encoder layer 的數量來評估 global imagelevel self-attention 的重要性。\n作者推論 encoder 可能對於判斷分開對象很重要，圖 3 可視化了最後一個 encoder layer 的 attention map。\nencoder 看似已經分離了 instance，可能簡化了 decoder 對於 object extraction 和 localization 的工作。\nNumber of decoder layers 在圖 6 做了 decoder 的注意力可視化，可以注意到觀察的注意力相當局部。\n推論是 encoder 主要分離實體，decoder 只需要關注四肢即可提取出對象的邊界和分類。\nAnalysis 圖 7 把 100 個預測槽中的 20 個做可視化。\n每個預測框代表一點，可以注意到不同的槽位會專注在不同區域。\n","date":"2023-08-10T00:27:55+08:00","permalink":"https://roykesydon.github.io/Blog/p/detr-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"DETR 論文閱讀"},{"content":"paper: BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\n現在回頭寫 BERT 論文筆記感覺有點怪，之前已經寫過什麼 RoBERTa 之類的。\n不過現在因應實驗室讀書會要求，還是看一下論文也寫一下筆記。\nAbstract 本文提出了 BERT，一種基於 Transformer Bidirectional Encoder 的語言表示模型。\nBERT 旨在透過 unlabeled text 進行 pretrain。\n因此，只需要一個額外的輸出層就可以對預訓練的 BERT 進行微調，在各種任務上取得 SOTA。\nIntroduction 「語言模型做預訓練」已被證明可以有效改善多種 NLP 任務。\n將預訓練模型應用在下游任務，有兩種策略：\nFeature-based 把 pretrained 的 representations 作為額外的特徵 Fine-tuning 根據特定任務引入額外參數，並簡單地微調所有參數 這兩種方法在預訓練期間共用同個 objective function，並用單向語言模型來學習 representation。\n作者認為當前的技術限制了預訓練的表示能力，特別是在 Fine-tuning 方法上。\n主要的問題在於語言模型是單向的，限制了預訓練期間可以使用的架構的選擇。這種單向的架構可能在一些任務有害，特別是對於那些需要兩個方向的 context 的任務。\n本文提出的 BERT 改善了現有的 Fine-tuning 方法，用 Transformer 的 Bidirectional Encoder 來訓練語言模型。\nBERT 透過受到 Cloze task（填空）啟發的 masked language model(MLM)，作為預訓練目標。MLM 隨機地遮蔽一些輸入的一些 token，目標是根據上下文來回推原詞，使 representation 可以融合左右兩邊的 context。\n除了 MLM，作者還利用 next sentence prediction（NSP）任務來訓練 BERT。\n本文貢獻如下：\nBERT 證明了雙向預訓練對 representation 的重要性。\nBERT 展現出預訓練的 representation 減少了許多針對 NLP 任務精心設計架構的需求。 BERT 是第一個基於 Fine-tuning，在大量 sentence-level 和 token-level 任務上取得 SOTA 的模型。\nBERT 推進了 11 個 NLP 任務的 SOTA。\nRelated Work Unsupervised Feature-based Approaches 學習廣泛適用的 representation of words 一直是活躍的研究領域，甚至在非神經網路的領域也是。\n預訓練的 word embeddings 與從頭訓練的 embedding 相比，有顯著改進。\n這些方法頁被推廣到 coarser granularities，像是 sentence embedding 或是 paragraph embedding。\n有研究證明 cloze task 提高了生成模型的 robustness。\nBERT 框架有兩步驟：\nPre-training 在不同的預訓練任務中，用 unlabeled data 來 fine-tune。 Fine-tuning 使用預訓練的參數初始化，在利用下游任務的 labeled data 對所有參數微調。 BERT 的一個特點是他具備跨不同任務的統一架構，預訓練架構和下游任務最終架構差異不大。\nModel Architecture\n本文表示方法\nL: Transformer 的層數 H: hidden size A: self-attention heads 的數量 model size\nBASE: L=12, H=768, A=12, 110M parameters 和 GPT 相同 LARGE: L=24, H=1024, A=16, 340M parameters Input/Output Representations\nInput representation 可以在 token sequence 中明確表示單個 sentence 和一對 sentence。\nsentence 可以是連續文本的任意範圍，而不是實際的句子。 sequence 是輸入的 token sequence，可以是單個 sentence 或是一對 sentence。 每個 sequence 的第一個 token 始終是特殊的分類 token \u0026ndash; [CLS] 對於兩個句子放在一個序列的情況，用 [SEP] 隔開 Token Embeddings\n作者使用 WordPiece embeddings，有 30000 個詞彙。 learned embedding\n對每個 token 添加這個東西，表示屬於 sentence A 還 sentence B Pre-training BERT Masked LM 直觀上，有理由相信深度的雙向模型會比單像串連起來的淺層模型更強大。\n不幸的是 standard condition language model 只能單向訓練，因為雙向會允許每個單詞「間接看到自己」。\n為了訓練 deep bidirectional representations，本文隨機遮蔽了一定比例的 tokens，並預測這些 token，這種方法稱為 masked language model，或常被稱為 cloze task。\n作者會用 [MASK] 做預訓練，但有個問題是 [MASK] 在 fine-tuning 期間不會出現，造成預訓練和微調之間的 mismatching，為了緩減這種情況，並不會總是用 [MASK] 替代 masked token。\n要替換 token 的時候，有 80% 的時間是 [MASK]，10% 是隨機 token，10% 是原本的 token。\nNext Sentence Prediction (NSP) 許多重要下游任務，比如 Question Answering (QA) 和 Natural Language Inference (NLI) 是基於兩個句子間的關係。\nNSP 就是為了理解句子間的關係而用的。\n每次挑句子 A 和 B 的時候，有 50% 的機會 B 是 A 的下一個句子，有 50% 是隨機的。\n針對 NSP 的預訓練對 QA 和 NLI 都很有用。\n預訓練資料 用 BookCorpus 和 English Wikipedia 來訓練 BERT。\n對於 English Wikipedia，只提取 text passages，忽略 lists, tables, headers。\n為了提取長的連續序列，用 document-level 的 corpus 而不是打亂的 sentence-level corpus 非常重要。\nAblation Studies Effect of Pre-training Tasks No NSP 只有 MLM LTR \u0026amp; No NSP Left-to-Right 只看左邊的 context 發現刪除 NSP 會顯著傷害對 QNLI 等資料集的性能。\nLTR 在所有任務上都比 MLM 差。\n雖然可以像 ELMo 單獨訓練 LTR 和 RTL，並且把他們結合起來\n但有以下缺點：\n比單向模型貴兩倍 對 QA 任務不直觀，因為 RTL 無法根據問題給出答案 不如深度雙向模型強大，因為其可以直接在每一層看到左右的 context Feature-based Approach with BERT 作者也研究了用 feature-based 的效果，發現具備競爭力。\n在他的實驗中，用預訓練 Transformer 的 top 4 隱藏層的 token 串街效果最好。\n","date":"2023-08-05T00:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/bert-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"BERT 論文閱讀"},{"content":"圖簡介 Graph\n表示 Entity (nodes) 間的 relations (edges) 組成 Vertex attributes (V) Edge attributes and directions (E) Global attributes (U) 下文簡稱 U, V, E 可以表示成圖的範例\nImages 相鄰 pixel 建無向邊 Text 詞和下一個詞建單向邊 Molecules 分子的連接處建無向邊 Social networks 人和人之間建無向邊 定義問題 種類 Graph-level Node-level Edge-level 個別講的是基於什麼東西做分類，比如對每個人（node）分類一個陣營，就算 Node-level 挑戰 儲存邊的關係 鄰接矩陣 在節點多的情況下佔用空間大，而且可能非常稀疏 同一張圖，換個點的順序後鄰接矩陣看起來就會不同 難以保證這些東西餵入神經網路後輸出相同 可以用兩個 list，一個儲存邊的向量，另一個是 Adjacency list，依序紀錄邊的關係 稀疏矩陣 難以用 GPU 運算 Graph Neural Network GNN 是對圖上所有屬性的 optimizable transformation，而且可以保持 graph symmetries (permutation invariances，把 node 排序後結果不變)\n下文用的 GNN 是 message passing neural network\ngraph-in, graph-out 不改變圖的 connectivity 最簡單的 GNN U, V, E 個別餵給不同的 MLP，組成一個 GNN 的 layer MLP 單獨餵入每一個點，不考慮連接訊息，保持了 graph symmetries 預測 假如要對每個頂點做預測，最後再加個全連接層分類 pooling 假如要對一個沒有向量的頂點做預測，我們可以用 pooling，蒐集相鄰邊和全局向量的資訊 對於沒有頂點資訊的圖，我們可以用 pooling layer 獲取全部點的資訊，再做分類 對於沒有邊資訊的圖，我們也可以用 pooling 去從相鄰點和全局向量獲得資訊 對於沒有全局向量的圖，我們可以用 pooling 去從全部的點或邊獲得資訊 缺陷 中間的 layer 沒有利用圖的訊息，都是各自進入各自的 MLP 做轉換 Passing messages 在做轉換前，先做一些 pooling\n匯聚頂點資訊 不是單單把點向量進行轉換，而是和相鄰的點一起做 aggregation 後再做轉換 如果 aggregation 是加總，和卷積有一點像，只不過是權重一樣的版本 匯聚頂點和邊的資訊 可以先把頂點匯聚給邊，再把邊匯聚回頂點，反之亦然 順序不同會導致不同結果 兩種方法可以一起同步做，交替更新 全局資訊 每次 layer 只看鄰居，要傳遞到遠的點須要走很多層 導入 master node (context vector)，他連接了所有的點和邊 相關主題 採樣\n考量到計算梯度可能需要儲存過多的中間資訊，可以考慮採樣一些點，只在子圖上做計算 Batch\n每個點鄰居各數不同，使做 batch 成為有挑戰性的問題。 Inductive Bias\ngraph symmetries Aggregation\n目前沒有一個最佳選擇 Graph Convolutional Network\nnode 是根據鄰居 node 去做某種 aggregate，事後再做更新 由於每次都看鄰居，假如有 k 層，可以把圖看做解 n 個子圖，每個子圖就是基於每個點去走 k 步所形成的 Graph Attention Network\n用 attention 決定其它點的權重，而不像 GCN 一樣把鄰居加起來 ","date":"2023-08-04T00:27:55+08:00","permalink":"https://roykesydon.github.io/Blog/p/gnn-%E4%BB%8B%E7%B4%B9/","title":"GNN 介紹"},{"content":"paper: Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset\nAbstract 目前的動作分類資料集 (UCF-101 和 HMDB-51) 的影片非常缺乏，使辨識「良好的影像架構」變得困難， 使多數方法在現有的小規模 benchmark 的表現差不多。為此本文根據新的 Kinetics Human Action Video dataset 對 SOTA 架構進行了重新評估。\nKinetics 有 400 個人類動作類別。每個類別有 400 個 clip。從 YouTube 上獲取的，而且每個 clip 來自 unique 的 youtube 影片。\n本文分析了當前架構在 Kinetics 上動作分類任務的表現，也評估 Kinetcis 用作預訓練的效果。\n本文提出了一種基於 2D ConvNet inflation 的 Two-Stream Inflated 3D ConvNet (I3D)。\nI3D 的擴展方法讓 ImageNet 上已經取得成功的架構可以被利用在解決影像任務上。\n結果表明，經過在 Kinetics 上預訓練後，I3D 在動作分類方面顯著提高了 SOTA，在 HMDB-51 上達到 80.9%，在 UCF-101 上達到 98.0%。\nIntroduction 在 ImageNet 上預訓練模型的效果很好，但在影片領域，預訓練成效一直是一個未知的問題。因為流行的動作識別 benchmark 都非常小，約略只有 10k 個影片。\nKinetics 有 400 個人類動作類別。每個類別有 400 個 clip，而且每個 clip 都來自一個 unique 的 Youtube 影片。\n本文實驗策略是在 Kinetics 上預訓練，再在 HMDB-51 和 USC-101 上微調，結果顯示出預訓練總是能提高性能，但提升多寡因架構而異。\n本文提出新架構，稱為「Two-Stream Inflated 3D ConvNets」(I3D)，建立在 SOTA 的影像分類架構上，並將 filters 和 pooling kernel 膨脹成 3D。\n基於 Inceptionv1 的 I3D 在 Knetics 上預訓練後，性能遠超過當前的 SOTA 架構。\n在本文的模型中，並沒有考慮更多經典方法，比如 bag-of-visual-words representation，但 Kinetics 是公開的，因此其他人可以進行後續研究。\nAction Classification Architectures 目前影片架構中的一些主要區別如下：\n卷積是 2D 還 3D 的 是否只是 RGB 影片，還是包含事先計算的 optical flow 對於 2D ConvNets，訊息是怎麼在 frame 之間傳遞的 這部分可以使用 temporally-recurrent layers，比如 LSTM，或是用隨時間的 feature aggregation 來完成。 在本文中，考慮了涵蓋大部分現有架構的模型子集：\n2D ConvNets 頂部有 LSTM 的 ConvNet 有兩種 stream fusion 的 two-stream networks 3D ConvNets C3D 由於參數維度較高，以及缺乏 labeled video data，以前的 3D ConvNet 相對較淺（最多 8 層）。\n本文發現諸如 VGG-16 和 ResNet 等很深的影像分類網路可以輕鬆擴展成 spatio-temporal feature extractors，並且他們的預訓練權重也可以提供有價值的初始化。\n本文也發現 two-stream 的作法依然有用。\nfig2. K 是影片中的 frame 的總數，N 是相鄰 frames 的子集合。\n上圖是本文實驗的五種架構，前四種是之前的做法，最後一種是提出的新作法。 上圖中除了 C3D 外都有用到 ImageNet 預訓練的模型。\n時間是根據 input 的 frame 換算出來的，fps 是 25，除了 LSTM 那個比較特別，因為 LSTM 那個是每 5 frame 取 1 frame，所以時間是 5 倍。\n之前的做法 ConvNet+LSTM\n有一種做法是把每個 frame 獨立餵給 2D Conv，然後再把預測做彙整，符合 bag of words image modeling 的精神，但這樣會忽略時間結構上的資訊，比如無法判斷開門或關門。\n所以最好在後面加一個 recurrent layer，所以這邊就用 Inception-V1 結合 LSTM。\n原始的影片 stream 是 25 fps，這邊每 5 frame 採樣一次。\n3D ConvNets\n和一般的卷積神經網路差不多，只是具有 spatio-temporal filters。\n但由於額外的 kernel 維度，相比 2D Conv 會有更多參數，也使他們更難訓練。\n而且這樣會無法發揮 ImageNet 預訓練的好處，因此之前的工作都定義了相對淺層的架構，並且從頭訓練。\nbenchmark 中的表現備受期待，但和 SOTA 比沒有競爭力，也因此成為本文實驗的良好候選者。\n本文用的是 C3D 的小變體，差異在於所有卷積層和 FC 層的後面都用了 BN。 而且在第一個 pooling layer 用的 stride 是 2，好減少記憶體的使用，比用更大的 batch，這在 BN 中非常重要。\nTwo-Stream Networks\nRoy：這裡由於比較複雜，我要改提 two-stream 的原始論文（Two-Stream Convolutional Networks for Action Recognition in Videos）說明這東西是什麼\n簡而言之就是分成兩個部分：\n空間資訊：\n用影片的一個 frame　經過卷積神經網路達成，這個 frame 用來提取影像中的物件資訊，比如打排球這動作可能辨識出排球就非常好判定，所以用某個 frame 來提取空間資訊。\n動作資訊：\n這邊用一連串的光流（optical flow）圖來達成，光流是物體（pixel）在兩個 frame 間的位移向量，估計方法有很多，這裡不一一舉例。\n上圖出自 Two-Stream Convolutional Networks for Action Recognition in Videos，圖 c 就是光流，具有兩個方向，指出像素的位移，圖 d 是水平方向的視覺化，圖 e 是垂直方向的視覺化。\n再把這些光流圖餵給卷積神經網路，用作動作資訊的判別。\n值得一提的是他是 late fusion，而且是用加權平均，不是像一般想的把特徵結合再做其他處理。\nThe New: Two-Stream Inflated 3D ConvNets 作者把成功的 2D 分類模型簡單地轉換為 3D\nInflating 做法是把方形的 filter 改成立方體，把 N x N 的 filter 改成 N x N x N 的 filter，但這只有架構上的參考。\nBootstraping 把權重也給轉換到 3D 架構的方法。\n作者觀察到影像可以透過反覆複製貼上來生出一個「不會動的無聊影片」， 透過這些影片，3D 模型可以透過這種方式在 ImageNet 上 implicitly pretrain，做法就是讓 3D filter 吃無聊影片的輸出和 2D filter 吃單一 frame 的輸出相同，做法如下：\n我們可以沿時間維度重複 2D filter N 次，把這權重給 3D filter，同時把權重除以 N，達到這種效果。\nPacing receptive field growth in space, time and network depth 以往在圖片上對水平和垂直軸的對待是平等的，pooling kernel 和 stride 都一樣。 使感受野在兩個維度上隨著模型越來越深，慢慢平等增長。\n但是時間軸用對稱的感受野不一定最好，而該取決於 frame rate 和 image dimensinos。 如果時間相對於空間增長太快，可能會混淆不同對象的邊緣，影響早期的特徵檢測。如果增長太慢，可能無法很好地捕捉場景動態。\n實驗中，輸入影片的 fps 是 25。\n作者發現在前兩個 max pooling layer 不在時間軸 pooling（透過用 1 x 3 x 3 的 kernel，並且時間軸的 stride 是 1），並在其他 max pooling layer 都用 symmetric kernels 和 stride 是有幫助的。\n最後的 average pooling layer 是用 2 x 7 x 7 的 kernel。\n作者用 64 frame 訓練，但用整個影片測試。（averaging predictions temporally）\n我想了一下，250 / 64 除不進，但是我看 code 發現他好像寬高 224 * 224 的照片會在最後經過 Average pool 後變成 1 * 1，所以他可以直接用 1 * 1 * 1 的卷積核把輸入通道改成分類數，再把時間軸的結果平均。\nTwo 3D Streams 分別訓練兩個網路，並在測試階段對預測進行平均。\n這邊作者說光流的演算法某種意義上是 recurrent（例如，對於 flow fields 進行 iterative optimization），我不太懂這邊是什麼意思，我想作者用的光流演算法應該是透過某種類似 EM 演算法那種不斷迭代去逼近數值的演算法，但作者提到「或許是因為缺乏 recurrence，我們發現雙流有價值」，我不太懂為什麼需要 recurrence 效果才會好。\n但結論是 two-stream 依然具備價值。\nImplementation Details 這邊講滿詳細的，有興趣可以去原文看。 只提一下幾點:\n光流演算法是用 TV-L1。 除了類似 C3D 的 3D ConvNet 都用使用 ImageNet 預訓練的 Inception-V1 作為 base network。 對於較短的影片，會重複循環以滿足模型的輸入介面 測試時會在中間剪裁 224 x 224 The Kinetics Human Action Video Dataset Kinetics 有 400 個人類動作類別。每個類別有 400 個 clip，而且每個 clip 都來自一個 unique 的 Youtube 影片，共有 24 萬個訓練影片。\n每個 clip 都大約 10 秒，而且沒有未剪的影片。\n測試集每個 class 包含 100 個 clip。\nExperimental Comparison of Architectures I3D 在所有資料集上都表現最好，甚至是在 UCF-101 和 HMDB-51 這種小資料集上也是如此，這意味著 ImageNet 預訓練的好處有成功擴展到 3D ConvNet。\n多數模型在 UCF 上都表現得比 Kinetics 上好，顯現出資料集的難度差距。\n但是在 HMDB 表現得較差，原因可能是 HMDB 故意弄得很難，作者有舉例，很多 clip 在完全相同的場景會有不同的動作。\n作者有提到說 I3D 特徵比較好遷移的一種解釋是它具備 high temporal resolution， I3D 在 25 fps 的影片中用 64 frames 做訓練，使它能捕捉動作的 fine-grained 時間結構。\nExperimental Evaluation of Features Kinetics 上做預訓練效果明顯比 ImageNet 好。\nDiscussion Kinetics 上的預訓練對於遷移學習有明顯好處，但對於其他影像任務，比如影像語義分割是否有好處仍待觀察。\n目前對於架構沒有全面探索，比如沒有採用 action tubes 或是 attention 機制。\n","date":"2023-07-23T00:27:55+08:00","permalink":"https://roykesydon.github.io/Blog/p/i3d-%E8%AB%96%E6%96%87/","title":"I3D 論文"},{"content":"前言 要弄 Hololens 2 的開發環境要一堆有的沒的麻煩東西，紀錄一下避免之後要重裝\n原本很怕版本對不上很麻煩，但實際用起來好像還好\n注意，這不是最小安裝，有些東西我不確定是不是必要的，但我怕麻煩就裝了\n後續請參考微軟的教學\n我個人的版本紀錄 (2023/07/03) Unity 2021.3.27f1 (LTS) MRTK 2.8.3 Visual Studio 2022 Mixed Reality OpenXR Plugin 1.8.0 作業系統要求 必須是 Windows 專業版以上，因為要用 Hyper-V 先去 BIOS 開 Virtualization Technology 開啟 Hyper-V 前置步驟 安裝 windows SDK\n聽說裝完最新的後，建議再多裝幾個版本 我個人只有裝最新的 安裝 visual studio\n好像會根據 MRTK 的版本有對應的版本要求，不能無腦裝最新 據說要選 「C++ 開發」和「通用 Windows 平台開發」 右邊好像還要選 USB 設備連接 C++ 通用 Windows 平台工具 安裝 Hololens 2 模擬器\n這是給 build 好的程式用的，不是在說 Unity Editor 裡面的手 安裝 Unity\n建議透過 Unity Hub 管理 Unity 版本 據說裝的 Unity 要裝以下兩個 module Universal Windows Platform Build Support Windows Build Support (IL2CPP) Windows 和 Hololens 都要開啟「開發者模式」\n下載 Mixed Reality Feature Tool\n注意看這不是 MRTK 這可以往 Unity 專案導入 MRTK 可以導入 MRTK 2.6 以後的工具包 創建專案 Unity 開個 3D 專案\nFile -\u0026gt; Build Settings 選擇 Universal Windows Platform 點選 Switch Platform 開啟 Mixed Reality Feature Tool\n針對專案安裝 MRTK 必裝\nMRTK Foundation Mixed Reality OpenXR Plugin 可選\nMRTK Examples Extensions Tools TestUtilities 剩下的看微軟專案建置教學，實在太多要弄了\n在模擬器上執行 這坑真的有夠多，我結合上 stack overflow 的解法，所用的步驟:\n要用管理員模式開 Visual Studio，不然有可能遇到權限問題\nVisual studio 要部屬程式的時候，會自己開一個 Hololens 2 Simulator，但他會開超久，然後造成 Timeout，無法部屬，部屬失敗後不要選繼續，也不要關掉模擬器\n這時候再看情況按 實心 / 空心綠色三角形 (without debugging)\n有可能可以 deploy，但運行時有問題，此時按紅色方塊終止，繼續綠色三角形，不要關掉模擬器\n","date":"2023-07-03T00:00:01+08:00","permalink":"https://roykesydon.github.io/Blog/p/hololens-2-%E9%96%8B%E7%99%BC%E7%92%B0%E5%A2%83%E8%A8%AD%E7%BD%AE/","title":"Hololens 2 開發環境設置"},{"content":"Use Cases Cache 把常用的資料回傳，省略長時間的 IO 操作 Shared Session 在 stateless server 間共享 session Distributed lock 用在程式間想共用某種資源的時候 用 setnx (set if not exists) atomic Rate Limiter 用 increment 和 expiration 實現 Feature NoSQL In-memory Key-Value Basic Command redis-server default port: 6379 redis-cli Access data set \u0026lt;key\u0026gt; \u0026lt;value\u0026gt;\nPretty much everything stored in Redis is going to be a type of string by default get \u0026lt;key\u0026gt;\ndel \u0026lt;key\u0026gt;\nexists \u0026lt;key\u0026gt;\nkeys \u0026lt;pattern\u0026gt;\nfind keys with certain pattern keys * get all keys flushall\nget rid of everything Expiration ttl \u0026lt;key\u0026gt;\nshow time to live \u0026ldquo;-1\u0026rdquo; for no expiration \u0026ldquo;-2\u0026rdquo; already expired expire \u0026lt;key\u0026gt; \u0026lt;second\u0026gt;\nsetex \u0026lt;key\u0026gt; \u0026lt;seconds\u0026gt; \u0026lt;value\u0026gt;\nset with expiration Data Structure List lpush/rpush \u0026lt;key\u0026gt; \u0026lt;value\u0026gt; lrange \u0026lt;key\u0026gt; \u0026lt;start index\u0026gt; \u0026lt;end index\u0026gt; \u0026lt;end index\u0026gt; can be -1 lpop/rpop \u0026lt;key\u0026gt; Set sadd \u0026lt;key\u0026gt; \u0026lt;value\u0026gt; smembers \u0026lt;key\u0026gt; srem \u0026lt;key\u0026gt; \u0026lt;value\u0026gt; remove Hash Key-value in Key-value\nhset \u0026lt;key\u0026gt; \u0026lt;field\u0026gt; \u0026lt;value\u0026gt; hget \u0026lt;key\u0026gt; \u0026lt;field\u0026gt; hgetall \u0026lt;key\u0026gt; get everything about \u0026lt;key\u0026gt; hdel hexists \u0026lt;key\u0026gt; \u0026lt;field\u0026gt; Redis doesn\u0026rsquo;t support nested hash struct 刪除過期 key 定期刪除 在固定間隔時間隨機抽 key 檢查並刪除\n惰性刪除 在訪問 key 的時候發現過期就刪除\nmaxmemory-policy (Eviction) 可以設定這些 policy，在記憶體依然額滿的情況下做對應的處理\nnoeviction allkeys-lru allkeys-lfu volatile-lru volatile-lfu allkeys-random volatile-random volatile-ttl 快取情境問題 快取雪崩 Cache Avalanche 某個時刻大量 cache 失效，使資料庫需要承擔很大的流量。 解法 幫 cache 加上額外的隨機過期時間 快取擊穿 Hotspot Invalid 某個 hotspot 的 cache 失效，使大量請求跑到資料庫 解法 讓 hotspot 永不過期 查詢資料庫的部分加上 lock 快取穿透 Cache Penetration client request 不存在的資料，因為同時不存在於 cache 和資料庫中，所以直接跑到資料庫 解法 在 application 先過濾掉非法請求 Bloom Filter 布隆過濾器 Persistence RDB 固定時間對所有資料做快照，memory dump 出來 recovery 比 AOF 快 save、bgsave AOF 紀錄操作流程 檔案比較肥 Rewrite 當 AOF 太大，Redis 會生一個新文件取代舊的，用最少操作生出目前的資料\n混合 在 AOF 重寫的時候也利用 RDB 前面是 RDB，後面是 AOF\nAvailability 主從同步 一主多從，把讀取壓力分擔到 slave 上\n哨兵模式 Sentinel 會有哨兵不斷地 Ping 主從伺服器，確認是否有異常\n如果哨兵是集群，有哨兵檢測到異常，會判斷某伺服器主觀下線，當有一定數量的哨兵投票認為伺服器不可能用，就會變成客觀下線，進行 failover\nCluster 分擔寫入壓力\nRedis 有 16384 個 slot，透過 hash 分配 key 到不同的 slot\n預設會另外用 port 16379 來讓節點間溝通\n可以混和主從同步達到高可用\n","date":"2023-06-05T00:00:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/redis/","title":"Redis"},{"content":"前言 軟體要對 domain 做 Modeling，呈現出 domain 裡的核心概念，才能滿足使用者需求，因此不乏與領域專家的討論\n寫這篇的時候我還沒嗑完 Eric 的聖經，可能嗑完了之後會回來修改\n通用語言 Ubiquitous Language 鑒於程式開發人員與領域專家熟悉知識的差異，會產生交流困難\n因此領域專家和開發團隊要訂定共同的語言，並且盡可能少用自己知道的術語\nUML UML 適合用在小型模型上，它擅長表達類別間的關係，但對於抽象概念卻沒那麼好傳達\n因此用 UML 建構模型時，理想上要添加額外的文字，傳達一些圖所不能表達的 behavior 和 constraint\n並且不能一次寫過於複雜，而是分塊處理\nLayered Architecture 分為四個概念層，只會往下調用，可能會跨層\n可以達到關注點分離 (separation of concerns)，提高各個方面的 cohesive\nUser Interface (Presentation Layer) 呈現給 user 的 UI，User 可能是另一個系統 Application Layer 不含 bussiness logic，指揮表達領域概念的物件來完成任務 Domain Layer 有關 domain 的資訊都在這裡，業務邏輯在此處理 表達業務概念、狀態、規則 劃分出這層是 Model-Driven Design 的關鍵 Infrastructure layer supporting library 保存業務狀態的技術細節在此實作 為前三個 layer 服務 Entity 具備 identity identity 在 status 經過改變後依然不變 追蹤 entity 需要高成本 mutable Value Object 沒有 identity 只關心 obejct 的 value 可以輕易創建丟棄 immutable (不變的) 如果想修改數值就創新的 可被共用 Service 有些動作不屬於某個 Entity 或 Value Object，因為它是跨物件的 Stateless 每個請求不互相影響 Aggregate 把複雜關聯的物件圈在一起考量 確保 consistency 和 inveraints consistency (一致性) 相關物件的資料一致 invariants (不變量) 資料改變時要維護的規則 Aggregate root 具備 global identity，其他內部 entity 只有 local identity 通常是 entity 擔任 外部只能存取它，不能存取 aggregate 的其他 entity 或 value obejct Factory 若創建 aggregate、entity、value object 的過程很複雜，或是涉及專業知識，就該用 factory 包起來 對於不複雜的情況，或是想控制更多細節，可以只依賴於簡單的建構函式 Repository 如果大家都直接存取資料庫的各種物件，會破壞原本精心設計的結構，破壞封裝性\nRepositoy 用來存取物件，封裝了資料庫操作\nDomain event Domain 中重要的事情 可以用在其他物件和 aggrgate 訂閱，讓 aggregate 通知他們 domain event 的發生 Anti-Pattern 應該避免的情形 Smart UI 超肥的萬能 UI Anemic Domain Model 貧血模型 只有 getter 和 setter，沒有業務邏輯的模型 Subdomain 把 domain 切分成小塊，理想上 subdomain 和 bounded context 有 one-to-one 的關係\nTypes core subdomain 和其他競爭者相比不同的部分，最核心的業務，比如搜尋引擎中的搜尋演算法 generic subdomain 大家都會弄的部分，比如登入系統 supporting subdomain 用來輔助 core subdomain 的部分，比如篩選網頁 Bounded Context 劃出 boundary，確保 boundary 內用的概念、規則皆一致 同個名詞可能出現在不同的 context，但有不同意思 Context Map 描述 BC 和 BC 間的關係\n上下游 (U/D) 上游提供下游 (下游依賴上游) Shared Kernel 兩個 BC 共用的部份 違反 BC 的基本原則，是一種例外設計 Customer-Supplier 一個子系統重度依賴另一個子系統 Conformist Customer 完全配合 Supplier Partnership 兩個 BC 互相合作，沒有以誰為主 一起成功或一起失敗 Anticorruption Layer (ACL) 開發系統和外部系統的中間層 可能出現在調用 legacy system 常用到 Facade 和 Adapter Open Host Service (OHS) 如果外部子系統要給一堆用戶端子系統調用，就得在所有用戶端子系統搞 ACL 外部系統做為服務提供，常會搭配 Published Language (PL) PL 是協定傳送資料的格式，比如 XML、JSON 或是 Protocol Buffer Pratical DDD The strangler migration 透過 Facade，把一些服務慢慢移植給新系統，最後取代 legacy ","date":"2023-05-22T00:00:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E9%A0%98%E5%9F%9F%E9%A9%85%E5%8B%95%E8%A8%AD%E8%A8%88-domain-driven-design/","title":"領域驅動設計 Domain-Driven Design"},{"content":"運算放大器 (Operational Amplifiers) 介紹 運算放大器 (Operational Amplifiers) 特性 類似於電壓控制電壓相依電源的電子元件 主動電路元件 用於執行加、減、乘、除、微分與積分等運數學運算的主動電路元件 由電阻、電晶體、電容和二極體等所構成的電子元件，但因內部電路的討論已超出範圍，先看作是電路模組 封裝形式 DIP 輸出電壓 $v_O$ $v_O=Av_d=A(v_2-v_1)$ $v_2$ 是非反相輸入 (noninverting input) $v_1$ 是反相輸入 (inverting input) $A$ 是開迴路電壓增益 (open-loop voltage gain) 是沒有任何從輸出到輸入的回授 (feedback) 時，運算放大器的增益 回授 負回授 (negative feedback) 輸出回授至反相輸入端 閉迴路增益 (closed-loop gain) 如果存在由輸出到輸入的回授，輸出電壓與輸入電壓的比例稱為閉迴路增益 對負回授電路而言，可以證明閉迴路增益和開迴路增益無關，因此運算放大器總是用於具回授的電路中 工作模式 正飽和區 $v_O=V_{CC}$ 線性區 $-V_{CC} \\leq v_O = Av_d \\leq V_{CC}$ 負飽和區 $v_O=-V_{CC}$ 符號 $v_O$ 是輸出電壓 $v_d$ 是輸入電壓差 理想運算放大器 (Ideal Op Amp) 假定運算放大器是理想的是符合實際的，因位目前絕大多數運算放大器都有很大的增益和輸入電阻 具有以下特性的運算放大器，稱為理想運算放大器 $A \\simeq \\inf$ 開迴路增益無窮大 $R_i \\simeq \\inf$ 輸入電阻無窮大 $R_O \\simeq 0$ 輸出電阻為零 特性 流入兩個輸入端的電流均為 0，因為輸入電阻無窮大，輸入端間開路 輸入端間的電壓差等於零，$v_d=v_2-v_1=0$ 反相放大器 (Inverting Amplifier) 對輸入信號放大的同時反轉極性 公式 $v_0=-\\frac{R_f}{R_1}v_i$ $R_f$ 是回授電阻 $R_1$ 是進到負回授節點前的電阻 非反相放大器 (Noninverting Amplifier) 提供正電壓增益的運算放大器電路\n公式\n$v_0=(1+\\frac{R_f}{R_1})v_i$ 電壓隨耦器 (voltage follewer)\n又稱單位增益放大器 (unity gain amplifier) 條件 $R_f=0 或 R_1=\\inf 或 (R_f=0 且 R_1=\\inf)$ 公式 $v_0=v_i$ 加法放大器 (Summing Amplifier) 將多個輸入結合，在輸出產生輸入的加權總合 公式 $v_O=-(\\frac{R_f}{R_1}v_1+\\frac{R_f}{R_2}v_2+\\frac{R_f}{R_3}v_3)$ 差動放大器 (Difference Amplifier) 放大兩個輸入信號的差而抑制兩個輸入的共模信號 (Common-mode signal)\n公式\n$v_O=\\frac{R_2(1+R_1/R_2)}{R1(1+R_3/R_4)}v_2-\\frac{R_2}{R_1}v_1$ 如果 $R_2=R_1$ 且 $R_3=R_4$，動差放大器為減法器 (subtractor)\n$v_O=v_2-v_1$ 串級運算放大器電路 (Cascaded Op Amp Circuits) 串級 兩個以上的運算放大器首尾相接，前一級的輸出是下一級的輸入 多個運算放大器串級時，每個電路都稱為一級 (stage) 運算放大器的優點 串級不會改變各自輸入-輸出 因為理想的運算放大器輸入電阻無窮大，輸出電阻為 0 總增益為個別增益的乘積 $A=A_1A_2A_3$ 數位-類比轉換器 (Digital-to-Analog Converter, DAC) DAC 把數位信號轉成類比信號 實現方法 二進位加權階梯電路 (binary weighted ladder) 把權重設計成二進位的加法放大器 輸入 最高位元 (most significant bit, MSB) 最低位元 (least significant bit, LSB) 儀表放大器 (Instrumentation Amplifiers) 差動放大器的延伸 電容器與電感器 介紹 電容器與電感器是能儲存能量的儲能元件 (storage element) 電容器 (Capacitors) 將能量儲存在電場中的被動元件\n由兩片導電板夾著絕緣體 (電介質) 組成\n公式\n$q=Cv$ q 是儲存的電荷量 C 是比例常數，又稱電容 (capacitance) 單位是法拉 (farad, F) C 不是由 q 和 v 決定 $C=\\frac{\\epsilon A}{d}$ $\\epsilon$ 是介電常數 $A$ 是導電極版的截面積 $d$ 是兩極板的間距 $v(t)=\\frac{1}{C}\\int_{t_0}^t i (\\tau)d\\tau + v(t_0)$ $w=\\frac{1}{2}Cv^2$ 電場儲存的能量 線性電容 (linear capacitor)\n滿足 $i=C\\frac{dv}{dt}$ 非線性電容 (nonlinear capacitor)\n電流電壓關係曲線非直線，不過多數電容是線性的 重要性質\n電容器在直流下工作，等同開路 電壓不隨時間改變的話電流是 0 電容器上的電壓必須是連續的 因為不連續變化的電壓需要無限大的電流 電容會反抗電壓的突然改變 理想電容器不消耗能量 實際的非理想電容器會並聯一個漏電阻，可高達 $100M \\Omega$，在多數情況可忽略不計 電容器串並聯 並聯 $C_{eq} = C_1 + C_2 + C_3 + \u0026hellip; + C_N$ 串聯 $\\frac{1}{C_{eq}} = \\frac{1}{C_{1}} + \\frac{1}{C_{2}} + \\frac{1}{C_{3}} + \u0026hellip; + \\frac{1}{C_{N}}$ 電感器 (Inductors) 將能量儲存於磁場中的被動元件\n公式\n$v=L\\frac{di}{dt}$ L 是比例常數，又稱為電感 (inductance) 單位是亨利 (henry, H) 由物理尺寸和結構決定 $i=\\frac{1}{L}\\int_{t_0}^t v (\\tau)d\\tau + i(t_0)$ $w=\\frac{1}{2}Li^2$ 儲存的能量 電感反應電感器反抗電流變化的特性\n線性電感 (linear inductor)\n滿足 $v=L\\frac{di}{dt}$ 非線性電感 (nonlinear inductor)\n$v$ 和 $di/dt$ 關係曲線非直線 重要性質\n在直流中，電感器等同短路 電感器上的電流必須是連續的 因為不連續變化的電流需要無限大的電壓 電容會反抗電流的突然改變 理想電感器不消耗能量 實際的非理想電容器會串聯一個繞線電阻 (winding resistance)，由製成電感的導電材料產生，通常很小。並由於線圈間的電容性耦合，也存在繞線電容 (winding capacitance) 電感器串並聯 串聯 $L_{eq} = L_1 + L_2 + L_3 + \u0026hellip; + L_N$ 並聯 $\\frac{1}{L_{eq}} = \\frac{1}{L_{1}} + \\frac{1}{L_{2}} + \\frac{1}{L_{3}} + \u0026hellip; + \\frac{1}{L_{N}}$ 應用 電感電容的特殊性質 能儲存能量，作為暫時的電壓源或電流源，可在短時間內產生大電流或電壓 電容器反抗電壓的突然改變、電感器反抗電流的突然改變 電容器和電感器對頻率很靈敏，可以區別不同頻率，這條用在交流電路中 積分器 (Integrator) 採用儲能元件的運算放大器組成的積分器，輸出訊號和輸入訊號的積分成正比 $v_0=-\\frac{1}{RC}\\int_0^tv_i(\\tau)d\\tau$ 微分器 (Differentiator) 採用儲能元件的運算放大器組成的微分器，輸出訊號和輸入訊號的變率成正比 $v_0=-RC\\frac{dv_i}{dt}$ 類比計算機 (Analog Computer) 由各種運算放大器綜合使用，可算出任意微分方程式\n","date":"2023-05-08T00:00:54+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E9%9B%BB%E8%B7%AF%E5%AD%B8-iii/","title":"電路學 - III"},{"content":"簡介 Timer 和 Counter 的差別是 Timer 是定期的數數\nTiming functions 定期對 CPU 發送 interrupt 產生準確時間的 delay 產生 pulses 或 periodic waveforms PWM 量測 duration STM32 Timer / Counter 從 Basic 到 Advanced，追加更多功能\nBasic TImer (Simple Timer)\n16 bit auto-reload register programmable pre-scaler 可以 output 到 DAC update event CNT=ARR(up-count) CNT=0 (down-count) reset CNT to 0 or ARR set UIF flag in status register update event interrupt 如果 enabled (UIE=1) UIF 被設置的時候發送訊號 $T_{EVENT}=Prescale \\times Count \\times T_{CK \\_ INT} \\\\ =(PSC+1)\\times(ARR+1)\\times T_{CK \\_ INT}$\n$T_{EVENT}$ 是兩次事件發生的間隔時間 PSC 是設定 (數值 - 1)，所以 Prescale 是 1 的話，要設 0 Control register\nCEN 是否啟用 counter UDIS 是否啟用 update event URS 設定產生 update event 的 source OPM 是否只算一次 counter 就停 ARPE 關於中途改 ARR 的 reload 設定 UIF interrupt General Purpose Timer\n16-bit or 32-bit auto-reload register use for a variety of puposes measuring lengths of input signals (Input Capture)\nInput Capture 測量 pulse width (高電位的時間) 或 period (一個週長) generating output waveforms (Output Compare and PWM Generation)\none pulse mode output Up to 4 independent channel Interrupt / DMA generation event counter overflow / underflow counter initialization trigger event input capture output compare Advanced Control Timer\n16-bit auto-reload register 特殊 timer\nlow power timer 可以用在比如睡眠狀態 補充 24 bits system timer (SysTick) reload 在 overflow 時回到 register 設定的數值 STM32 Timer 差異 可以去 Datasheet 找每個 Timer 的功能\nCounter resolution\n16/32 bit 決定能從 0 數到多少個 Counter Type\n決定能往上數或往下數或都可以 Prescaler factor\n可以把進來的數字先除以某個數，減緩速度 DMA request generation\n能否用 DMA access 記憶體 Capture / Compare channels\n一個 Timer 可能可以發多個訊號出去，並且經過多個 Compare register，比對不同 event functions Compare 和比對 register，比到了就送 event Capture 紀錄下 channel 的值 Complementary output\n有些馬達控制需要反向波，就要這個 Max interface clock (MHz) and Max timer clock (MHz)\n進去和出來的速度 System Clock - Clock tree Timer 源頭就是 clock\n有四種來源幫忙驅動 system clock (SYSCLK)\nHSI16 (high speed internal) 16 MHz RC oscillator clock MSI (multispeed internal) RC oscillator clock HSE (high speed external) oscillator clock, from 4 to 48 MHz PLL clock SYSCLK 往下接到 AHB，再接到 APB1、APB2\nFlash Read Access Latency 調整 clock 也要調整這部分 Register TIMx_CR1 control register TIMx_PSC 設定 prescale TIMx_ARR auto-reload register ","date":"2023-05-04T01:32:54+08:00","permalink":"https://roykesydon.github.io/Blog/p/stm32-timer-/-counter-%E4%BB%8B%E7%B4%B9/","title":"STM32 Timer / Counter 介紹"},{"content":"paper: Self-Instruct: Aligning Language Model with Self Generated Instructions\nAbstract 大型 \u0026ldquo;instruction-tuned\u0026rdquo; 語言模型 (經過微調好回應 instruction) 已經展現出在新任務上 zero-shot 的能力。\n然而他們嚴重依賴人工編寫的指令，在數量、多樣性和創造力上都受到了限制，阻礙了模型的通用性。\n作者介紹了 Self-Instruct 這個框架，可以透過自己生成的指令，來增強預訓練模型遵循指令的能力。\n將作者的方法應用在 GPT3，在 SuperNaturalInstructions 獲得了比原始模型高 33% 的改進，與使用 private user data 和 human annotations 的 $InstructGPT_{001}$ 性能相當。\n為了進一步評估，我們為新任務整理一組專家編寫的指令，並通過人工評估，顯示出使用 Self-Instruction 調整 GPT3 的性能大大優於使用現有公共指令資料集，只比 $InstructGPT_{001}$ 落後 5% 的差距。\nSelf-Instruct 提供一個幾乎 annotation-free 的方法，align 預訓練模型和 instructions，而且作者釋出了他們的大型合成資料集，以促進未來對 instruction tuning 的研究。\nIntroduction 最近的 NLP 文獻見證了「建構可以遵循自然語言指令的模型方面」的大量活動。\n這些發展由兩個關鍵部分組成：\n大型預訓練語言模型 (LM) 人工編寫的指令資料 PromptSource 和 SuperNaturalInstructions 是最近兩個著名的資料集。 他們透過大量手動註釋來收集指令，以建造 T0 和 T$k$-Instruct。\n然而這過程代價高昂，而且由於大多數人往往生成的都是流行的 NLP 任務，使其未能涵蓋真正多樣的任務，也不能涵蓋各種描述任務的不同方式，因此多樣性受侷限。\n鑒於這些限制，想要繼續提升 instruction-tuned models 的品質，需要幫 supervising instruction-tuned models 發展替代方案。\n本文介紹了 Self-Instruct，這是一種 semi-automated 的過程，用模型自身的 instructional signals 對 pretrained LM 進行 instruction-tuning。\n整個流程是一種 iterative bootstrapping algorithm，從手動編寫的 limited seed set 引導生成。\n在第一階段，模型要幫新任務生成指令。 利用現有的指令集合，創建更廣泛的指令，好定義 (通常是新的) 任務。\n對於新生成的指令集，框架為他們創建 input-output instances，稍後可以透過 supervising 用於 instruction tuning。\n最後，透過各種手段，在低品質和重複的指令加到 task pool 前，把他們修剪掉。\n可以重複這個流程非常多次，直到獲得大量任務。\n該模型的跌代過程中產生了大約 52K 個指令，與大約 85K 個 instance inputs 和 target outputs 配對 (有些相同的指令會對應多種輸入輸出)。\n作者觀察到生成的資料提供了各種有創意的任務，其中超過 50% 的任務和 seed instructions 的 ROUGE-L overlap 小於 0.3。\n基於上述結果，作者通過微調 GPT3 (和生成指令資料是同個模型) 建構了 $GPT3_{SELF-INST}$。\nSuperNI 的結果表明，$GPT3_{SELF-INST}$ 性能大大優於 GPT3 (原始模型)，高了 33.1%，幾乎和 $InstructGPT_{001}$ 的性能相當。\n此外，作者在新創建的的指令集上進行人工評估，$GPT3_{SELF-INST}$ 顯示出廣泛的指令遵循能力，優於在其他公開可用指令數據集上訓練的模型，只比 InstrcutGPT001 落後 5%。\n本文貢獻：\nSelf-Instruct：一種用最少的人工標記數據引導指令遵循能力的作法 通過大量的 instruction-tuning 實驗，證明了有效性。 發布了一個包含 52K 指令的大型綜合資料集，還有一組手動編寫的新任務，用於建構和評估未來的 instruction-following models。 Related Work Instruction-following language models 一系列工作顯示，使用 annotated \u0026ldquo;instructional\u0026rdquo; data，可以使普通語言模型遵循一般語言的指令。\n也顯示出 \u0026ldquo;instructional\u0026rdquo; data 的大小和多樣性直接影響模型的泛化能力。\n本文的工作目的在減少對人工註釋者的依賴。\nLanguage models for data generation and augmentation 許多工作依賴生成式 LM 來生成數據或做 augmentation。\n雖然作者的工作可被視為一種 augmentation，但和這些工作的差別在於不限於特定任務。\nSelf-Instruct 的一個明顯動機是引導出新的任務定義，而這些任務可能還未被 NLP 的研究者定義過。\nSelf-training 一種典型的 self-training 框架透過經過訓練的模型，幫 unlabeled 資料進行 label，然後用這些資料改進模型。\n雖然 Self-Instruct 和 self-training 有一些相似之處，但多數 self-training 的方法都假設了一個特定的目標任務。\n相比之下，Self-Instruct 從頭開始生出各種任務。\nKnowledge distillation 這邊我想不太通為什麼可以和 Knowledge distillation 扯上關係\nKnowledge distillation 通常涉及知識從較大模型到較小模型的轉移\nSelf-Instruct 也可以看做是 Knowledge distillation 的一種形式，但區別如下\ndistillation 的來源和目標是相同的，即模型的知識被 distill 到他自己 distill 的內容以 instruction task 的形式出現 Method 標記大規模指令資料對人類來說可能具有挑戰性，因為他需要\n創意，好提出新任務 為每個任務編寫 labeled instances 的專業知識 Defining Instruction Data 我們要生成的指令資料集包含 {$I_t$}，每個指令用自然語言定義了任務 $t$。\n每個任務都有一個或多個 input-output instances ($X_t,Y_t$)。\n給定 task instruction $I_t$，還有 instance x，模型 M 要生出 y：\n$M(I_t,x)=y, for (x,y) \\in (X_t,Y_t)$\n值得注意的是，instance input 和 instruction 沒有嚴格分界。\n比如 Instruction:\u0026ldquo;write an essay about school safety\u0026rdquo; x:\u0026quot;\u0026quot;，可以被改為 Instruction:\u0026ldquo;write an essay about the following topic\u0026rdquo; x:\u0026ldquo;school safety\u0026rdquo;\nAutomatic Instruction Data Generation 生成指令資料的 pipeline 分成四個步驟：\n指令生成 辨識指令是否是分類任務 用 input-first 或 output-first 做 instance generation 過濾掉低品質的資料 Instruction Generation Self-Instruct 是基於一個發現，也就是大型語言模型可以透過 context 中的現有指令，生出新穎的指令。\n為作者提供了一種從一小組人類編寫的指令中，使指令資料增長的做法。\n作者用他們編寫的 175 個任務 (每個任務 1 個 instruction 和 1 個 instance) 初始化 task pool。\n在每一個 step，作者從裡面 sample 8 個 instructions，作為 in-context 的範例。在這 8 個指令中，有 6 條來自人工編寫的任務，另外兩條來自前面步驟中模型生成的任務，以促進多樣性。\nClassification Task Identification 因為對於分類和非分類的任務，作者會採取兩種做法，所以作者使用來自 seed taks 的 12 條分類指令和 19 條非分類指令，讓 GPT3 透過 few-shot 來判別。\nInstance Generation 給予指令和他們的任務類別，作者獨立地為每條指令生成 instance。\n這具備挑戰性，原因在於他需要模型瞭解目標任務是什麼，根據指令找出需要那些額外的輸入內容，並生成他們。 (模型要根據 instruction 生出 instance input)\n作者發現，在 prompt 中放入其他包含 instruction-input-output 的任務範例的時候，模型可以實現這點。\n一種自然的方法是 Input-first Approach，可以要求語言模型先根據指令提出 input，再生出相應的 output。\n然而，這種方法在分類任務上，可能會偏向於生成某種 label。所以，對於分類任務，作者採用 Output-first Approach，先生成可能的 label，在每個 label 上再生成輸入。\nFiltering and Postprocessing 為了鼓勵多樣性，只有當新的指令和任何現有的指令的 ROUGE-L overlapping 小於 0.7 的時候，才會被添加到 task pool。\n還排除了一些包含了通常不能被 LM 處理的關鍵字 (e.g. images, pictures, graphs) 的指令。\n在為每個指令生成新的 instance 的時候，會過濾掉完全相同或者是輸入相同但輸出不同的 instance。\nFinetuning the LM to Follow Instructions 在創建大規模指令資料後，用這些資料對原始語言模型進行 fine-tune。\n為此，將 instruction 和 instance input 連接起來，作為 prompt，然後訓練模型透過標準的監督式學習進行微調。\n為了讓模型對不同的格式 robust，使用多個模板將指令和輸入 encode 在一起。\n例如，指令可以有或沒有 Task: 前墜、輸入可以有或沒有 Input: 前墜，或是中間可以有不同數量的換行之類的。\nSelf-Instruct Data from GPT3 作者透過 OpenAI API 訪問最大的 GPT3 (davinci)\nStatistics Diversity Quality Experimental Results $GPT3_{SELF-INST}$: fine-tuning GPT3 on its own instruction data 使用生出來的指令資料，對 GPT3 進行微調。\n微調是透過 OpenAI finetuning API\nBaselines Off-the-shelf language models T5-LM 和 GPT3 是普通 LM baselines (只有 pre-training，沒有額外 fine-tune)\n這些 baseline 將表明現成的 LM 在預訓練後，能夠立刻自然地遵循指令的程度。\nPublicly-available instruction-tuned models T0 和 $T_k$-Instruct 是兩個 instruction-tuned models。\n兩者都是從 T5 進行微調的，對這兩種模型，都使用具有 11B 參數的最大版本。\nInstruction-tuned GPT3 models 作者評估了 InstructGPT，它是 OpenAI 基於 GPT3 開發的。\n對於 SuperNI 的實驗，只與 text-davinci-001 engine 進行比較，因為更新的 engine 用最新的用戶資料，而且很可能已經看過 SuperNI。\n對於新編寫的指令，評估時則包含了 001、002 和 003，以確保完整性。\n為了進一步比較 Self-Instruct 在其他公開可用的指令訓練集資料，使用 PromptSource 和 SuperNI 的資料微調 GPT3，這些資料用於訓練 T0 和 $T_k$-Instruct 模型。\n分別簡稱為 T0 訓練和 SuperNI 訓練。\nExperiment 1: Zero-Shot Generalization on SUPERNI benchmark 首先以 zero-shot 的方式評估典型 NLP 任務遵循指令的能力。\nResults Experiment 2: Generalization to User-oriented Instructions on Novel Tasks 盡管 SuperNI 在現有的 NLP 任務具有全面性，多數的這些任務是初於研究理由提出的，而且偏向分類。\n為了更好的獲取指令遵循模型的實用價值，作者中的一部分人策劃了一組面向用戶應用的新指令集。\n他們先針對 Large LM 可能可以應用到的領域進行 brainstorm，並且制定與每個領域相關的 instruction 和 instance。\n總共創建了 252 條指令，每條指令有 1 個 instance。\nHuman evaluation setup 評估模型在這些不同任務的測試集上的表現極具挑戰性，因為不同的任務需要不同的專業知識。\n為了獲得更忠實的評價，作者請了 instructions 的作者對模型的預測結果進行評估。\n實施一個 four-level rating system：\nRating A 回覆有效且令人滿意 Rating B 回覆可接受，但存在可以改進的地方 Rating C 回覆相關，但在內容上有重大錯誤 Rating D 回覆不相關或無效，包含重複輸入的部分，完全無關的輸出。 Results 如果把 Rating B 以上視為有效，$GPT_{SELF-INST}$ 只和 $InstructGPT_{001}$ 相差 5%\nDiscussion and Limitation Why does SELF-INSTRUCT work? 值得反思的是，在最近成功的 instruction-tuning LMs 中，高品質的 human feedback 扮演的角色。\n這裡有兩個極端的假設：\nHuman feedback 是 instruction-tuning 中必要且不可或缺的角色，因為 LM 需要了解在預訓練過程中沒完全了解到的問題。\nHuman feedback 是 instruction-tuning 一個可選的方向，因為 LM 在預訓練就已經很熟悉指令了。\n雖然現實可能介於這兩個極端之間，作者推測可能更傾向於第二種假設，尤其是對於較大的模型。\n第二種，也是人類直覺，是 Self- Instruct 的關鍵動機，而且也從成功的結果獲得支持。\nBroader Impact 除了本文的直接關注點外，作者相信 Self-Instruct 可能有助於揭露各種 instruction tuning 模型 \u0026ldquo;幕後\u0026rdquo; 發生的事情。\n不幸的是，由於他們的資料集尚未發布，這種業界模型仍處於 API 牆之後。\n人們對其結構以及為何能展現令人印象深刻的能力知之甚少。\nLimitations of Self-Instruct Tail phenomena Self-Instruct 依賴於 LM，繼承 LM 的所有限制。\n最近的研究顯示出 tail phenomena 對 LM 的成功構成嚴峻的挑戰。\n換句話說，LM 的最大收益出現於語言中最頻繁出現的部分 (語言分佈的頭部)，而低頻率出現的上下文中獲得的收益最小。\n同樣的，在這項工作背景下，如果 Self-Instruct 大部分的收益偏向預訓練 corpus 中頻繁出現的任務或指令，那也不令人感到意外。\n因此，該方法在不常見和有創意的指令下，可能會顯現出脆弱性。\nDependence on large models 因為 Self-Instruct 依賴於從 LM 中提取初的 inductive bias，因此它可能適合 larger model。\n如果這是對的，這會對那些沒有大量計算資源的人造成阻礙。\nReinforcing LM biases 作者擔心這種迭代作法可能會產生意料之外的結果，比如將有問題的社會偏見放大。\n","date":"2023-04-30T00:00:12+08:00","permalink":"https://roykesydon.github.io/Blog/p/self-instruct-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"Self-Instruct 論文閱讀"},{"content":"Memory Map CPU 對 I/O 操作方法\nPort I/O 用特殊 CPU 指令 I/O 設備和記憶體不共享地址空間 Memory-Mapped I/O I/O 設備和記憶體共享地址空間 像一般控制記憶體 這塊記憶體具有四個責任\nCommand Status Output Data Input Data GPIO 結構 GPIO mode Open-Drain 由外部電壓決定輸出電壓 Output Register 是 0 會啟用 N-MOS，1 的話靠外部電壓推 好處是外部電壓可以自己決定 Push-Pull 由內部電壓決定輸出電壓 Output Register 是 0 或 1 會決定啟用 N-MOS 或是 P-MOS 有關 Register Clock enable register AHB2 peripheral clock enable regisetr (RCC_AHB2ENR) Control register GPIO port mode register GPIO port output type register GPIO port output speed register GPIO port pull-up/pull-down register Data register Output Input 使用 GPIO 先去 Memory map 找 Boudary address\n根據 table 確認要設置的數值\n設定 RCC enable\n把上面說的各種 Control register 設定好\n比如 PUPDR BSRR\n修改 ODR 會一次改到整個 GPIO port，若只要改某個 pin，可以用 BSRR Delay\nCPU 4 MHz 1 cycle = 0.25$\\mu$S 可以查每個組合語言指令要幾個 cycle 機械按鈕會有 Bouncing\nDebounce Hardware method 加上濾波電容 Software method 讀取後等待一段時間才再次讀取 連續讀取 N 次，看數值是否穩定改變 7-Segment COM 分共陽、共陰\n8 個七段顯示器就要吃掉 8 * 8 個 GPIO 接腳，可以每次只顯示一個，那只需要 8 個 GPIO 接腳，快速閃過\n也可用 Max 7219 控制，他有三個輸入 DIN、LOAD、CLK\nDIN 輸入資料 CLK 上升的時候採樣，最多 10 MHz LOAD(CS) 採用最後輸進去的 16 bits 最早的是 MSB ","date":"2023-04-26T01:32:54+08:00","permalink":"https://roykesydon.github.io/Blog/p/stm32-gpio-%E4%BB%8B%E7%B4%B9/","title":"STM32 GPIO 介紹"},{"content":"重構 在不改變軟體行為的情況下，對軟體內部構造進行改善\nCode Smell 也稱 Bad Smell，代表程式碼中需要重構的部分\nDuplicated Code 重複程式碼 在同個 Class Extract Method 在不同 Class Extract Class Long Method 用 Extract Method 拆解過長的 function Long Parameter List Preserve Whole Object 把來自同一物件的資料直接該物件取代 Introduce Parameter Object 把相關的資料包成一個 Object Large Class 一個 Class 有太多 fields / methods / lines Magic Number 特殊數值直接用數字表示，日後修改每個地方都要改 Lack of Comments 加註解的好時機：寫程式前寫上 Switch Statements 可利用「多型 (Polymorphism)」解決 Divergent Change 一個類別有太多改變的原因 盡量讓其遵守 SRP Shotgun Surgery 某個責任被分散到大量的 Class 身上，使修改其時要大量修改 Feature Envy 存取別的 Object 的 Data 的情形比自己的還頻繁 這方法可能應該屬於另一個 Object Data Clumps 常一起出現的資料群應該被單獨抽成一個 Class Primitive Obsession 過度使用基本類別，造成 Shotgun Surgery Message Chains Client 請求 A 物件，A 物件又請求 B 物件 Lazy Class 把冗員類別移除 Temporary Field Instance variable 只有在特殊情形才被使用，應該改為區域變數或參數 Inappropriate Intimacy Classes 間頻繁讀取對方資料 理解程式要同時看懂兩者 Alternative Classes with Different Interfaces 兩個 Class 具有功能相同、命名不同的 function 可汲取共同部分為 Super Class 來解決 ","date":"2023-04-25T14:26:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E9%87%8D%E6%A7%8B-refactoring/","title":"重構 Refactoring"},{"content":"說明 本文寫於 Swin Transformer 論文閱讀 之後，當時對 Relatvie position 的理解不夠清楚，本文將會做解釋，並附上原論文的筆記。\n以下將會先用長度為 3 的序列作為示範。\nAbsolute Position Encodings Absolute Position Encodings 的做法是把用某種方式生成或可學習的向量加在輸入，第一個位置用 $w_1$，第二個位置用 $w_2$，第三個位置用 $w_3$。\nRelative Position Encodings Relative Position Encodings 顧名思義，就是改用相對位置來做這些向量。\n上圖中，Position Encoding 的部分從 3 個向量變成 3*3 個向量，因為現在會以每個 token 為基準，生出 3 個相對位置向量。\n我們以 $w_0$，代表處於原點，$w_x$ 代表往右 $x$ 格，$w_{-x}$ 代表往左 $x$ 格，其中 $x$ 是正整數。\n第一個 row 有 $w_0$、$w_1$、$w_2$，意思是以第 0 個向量 (I) 為基準，他的位置是 $w_0$，對第 0 個向量來說，第 1 個向量 (like) 是 $w_1$，第 2 個向量 (cat) 是 $w_2$。\n輪流以 $n$ 個 token 為基準，就會生出 n*n 個相對位置向量，而不是原先的 n 個絕對位置向量。\n其中 $w_i$ 和 $w_j$ 如果 $i=j$，他們會共用同樣的 weight，上圖是以相同顏色表示。\n如果序列長度是 $n$，就會有 $2n-1$ 個向量要學。\nn*n 這個數量使其適合加入到 self-attention，原始論文的加入方式可以參考下方論文筆記，這邊晚點會介紹後續衍生的簡化版。\nSwin Transformer 如何導入 Relative Position Encodings Swin Transformer 是借鑒許多 CNN 架構，為了 CV 而經過修改的 vision transformer。\n其中一個重點是，他會在一小區塊的特徵圖上做 self-attention，而且是用 Relative Position Encodings。\n和剛剛的差別在於，現在要在二維空間做 Relative Position Encodings。\n假設有一張 2*2 的 feature map，我們先設定好 feature map 各個 token 的絕對位置座標。\n然後我們輪流把 feature map 的每一個 token 作為基準點，把 feature map 的每個 token 的座標減去基準點的座標，就可以得到相對位置座標。\n如果我們把四個相對位置座標各別攤平 (按照左上 -\u0026gt; 右上 -\u0026gt; 左下 -\u0026gt; 右下的順序)，並且從上到下排好，他會看起來如下圖。\n此時我們幾乎完成了相對位置的表，和剛剛序列一樣生出了 n*n 個相對位置。\n我們接下來要做的事情是把這個表給編號，把 (0, 0) 都編成某個數字，把 (1, 0) 都編成某個數字。\n在此之前，先考慮總共會有幾種可能的相對座標，對於邊長 $M$ 的 feature map (這裡 M=2)，因為兩軸可能的數字皆有 (2M-1) 種，共會有 (2M-1)*(2M-1) 種可能性，這裡等於 9。\n所以我們等等會把所有座標編為 0~8。\n想從座標生出編號 0~8 可以考慮把座標兩軸的數字相加，但由於有負數的存在，要先把兩軸的數字都變成非負整數，所以先把兩軸的座標都各別加 M-1。\n此時如果相加，會使 (2, 1) 和 (1, 2) 都對應到數字 3，所以我們先把 row 座標乘上 2M-1 再相加，此時就可以獲得一個 n*n 的 index table ，對應一組相對位置向量。\nSwin Transformer 是用簡化版的作法來引入相對位置，公式如下\n$Attention(Q,K,V)=SoftMax(QK^T/\\sqrt{d}+B)V$ $B$ 是 relative position bias，$B \\in R^{M^2 * M^2}$ $a_{ij}$ 是純量，不是向量，和原始論文不同 論文出處 paper: Self-Attention with Relative Position Representations\nAbstract 依賴於 attention 機制的 Transformer 在機器翻譯方面取得 SOTA，但在結構中沒有相對或絕對的位置資訊，他需要在輸入中添加絕對位置的資訊。\n因此本文提出一種替代方案，拓展 self-attention ，考慮相對位置的表示，並在一些任務中獲得更好的結果。\n值得一題的事，作者觀察到結合相對和絕對位置不會進一步提高翻譯品質。\n該機制可以拓展到任意 graph-labeled 的輸入\nIntroduction Non-recurrent models 不一定按順序考慮輸入元素，因此可能需要明確的 position encoding 才才能用序列順序。\n一種常見的方法是使用與輸入元素結合的 position encoding，以向模型傳達位置資訊。\n可以是 deterministic function，或是 learned representations。\nCNN 可以捕捉 kernel 的相對位置資訊，但被證明仍受益於 position encoding。\n對於既不使用卷積也不使用遞歸的 Transformer，結合位置信息的 representation 是一個特別重要的考慮因素，因為該模型在其他方面對序列排序完全不變。\n本文提出一種將相對位置合併到 Transformer 的 self-attention 的做法，即使完全換掉絕對位置編碼，也使兩個機器翻譯任務的品質有顯著提高。\nBackground 原始 self-attention\n$z_i=\\displaystyle\\sum_{j=1}^n\\alpha_{ij}(x_jW^V)$\n$\\alpha_{ij}=\\frac{\\text{exp } e_{ij}}{\\sum_{k=1}^n\\text{exp } e_{ik}}$\n$e_{ij}=\\frac{(x_iW^Q)(x_jW^K)^T}{\\sqrt{d_z}}$\nProposed Architecture Relation-aware Self-Attention 有兩個要引入 relative position 的地方，而且都是向量\n$z_i = \\displaystyle\\sum_{j=1}^n \\alpha_{ij}(x_jW^V+a_{ij}^V)$\n$e_{ij}=\\frac{x_iW^Q(x_jW^K+a_{ij}^K)^T}{\\sqrt{d_z}}$\nRelative Position Representations 可以引入 clip，把線性序列中，高於長度 k 的修剪成最大值\n$a_{ij}^K=w_{clip(j-i,k)}^K$ $a_{ij}^V=w_{clip(j-i,k)}^V$ $clip(x,k)=max(-k,min(k,x))$ Experiments Model Variations clipping 的實驗 V 和 K 的 ablation study ","date":"2023-04-24T01:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/relative-position-%E4%BB%8B%E7%B4%B9--%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"Relative Position 介紹 + 論文閱讀"},{"content":"paper: Swin Transformer: Hierarchical Vision Transformer using Shifted Windows\nAbstract 本文提出一個新的 vision Transformer，稱作 Swin Transformer，可以被用作 computer vision 中的 general-purpose backbone。\n把 Transformer 從 language 移到 vision 具備挑戰性，比如同一個 visual entity 在大小上具備很大的 variance。還有 high resolution 下 pixel 和 word 的數量差異太大。\n為了解決這些差異，作者提出 hierachical Transformer，用 shifted windows 來算出 representation。\nshifted windowing 透過把 self-attention 限制在 non-overlapping 的 local window 和允許 cross-windows connection 來提高效率。\n這種 hierarchical architecture 可以靈活地在各種 scale 下擴展 model，還可以對圖像大小有線性的計算時間複雜度。\nIntroduction ViT 把圖片打成 patch，每個 patch 是 16*16，feature maps 由 single low resolution 的輸入生成，而且由於自注意力始終都是在全局上計算的 (patch 和 patch 間做自注意力)，所以時間複雜度是 quadratic computation complexity。\nSwin Transformer 從小 patch 開始，並在更深的 Transformer layers 合併相鄰的 patches。\n有了這些 hierarchical feature maps，可以用在像是 FPN 或是 U-Net。\n一個 Swin Transformer 的關鍵設計因素是 shifted window。\n透過 bridge 不同 layer 的 windows 來提供他們連接。\nMethod Overall Architecture Patch Merging 原本特徵圖是 H * W * C 以上下 stride=2 行走，會得到四張 H/2 * W/2 * C concatenate 起來，變成 H/2 * W/2 * 4C 做 linear，變成 H/2 * W/2 * 2C Swin Transformer block Swin Transformer 是透過把 Transformer block 中的 multi-head self attention(MSA) 換成基於 shifted windows 的 module 構成。\nShifted Window based Self-Attention 標準的 Transformer 架構會算 global self-attention，計算所有 token 間彼此的關係，導致 quadratic complexity，使其不適用於需要大量 token 的許多 CV 問題\nSelf-attention in non-overlapped windows 原來的圖片會以 non-overlapping 的方式切割。\n假設每個 windows 有 M * M 個 patches，然後一張圖像有 h * w 塊 patches，計算複雜度如下：\n$\\Omega(MSA)=4hwC^2+2(hw)^2C$ $\\Omega(W-MSA)=4hwC^2+2M^2hwC$ Shifted window partitioning in successive blocks window-based self-attention module 缺乏了 windows 間彼此的連接，會限制模型能力。\n作者提出了一種 shifted window 的方法，保持 non-overlapping windows 的高效計算，同時引入 windows 間的連接。\n再兩個連續的 windows 間，會移動 $(⌊ \\frac{M}{2} ⌋, ⌊ \\frac{M}{2} ⌋)$\nEfficient batch computation for shifted configuration shifted window 有個問題是，會導致更多的 windows，從 $⌈ \\frac{h}{M} ⌉ * ⌈ \\frac{w}{M} ⌉$ 到 $(⌈ \\frac{h}{M} ⌉+1) * (⌈ \\frac{w}{M} ⌉+1)$，而且有些 window 會小於 M*M。\n這樣會導致無法把這些給壓成一個 batch 快速計算。\n一種 naive 的解法就是直接在外面加 zero padding，但會增加計算量，當 windows 數量較少時，計算量會變很可觀 (從 2 * 2 個 windows 變成 3 * 3 個 windows，增加了 2.25 倍)\n作者提出另外一種巧妙的做法，把一些部分挪移。\n但現在有些 window 裡有多個不該相互做 attention 的部分，所以要用 mask 的方式計算。\n不同 windows，做 self-attention 後，把不相干的部分做的 attention 減去一個很大的數值，最後再過 softmax。\n上圖來自作者在 github 提供的可視化\n最後再把它挪回原本的位置。\nRelative position bias 參考這個: https://blog.csdn.net/qq_37541097/article/details/121119988\nArchitecture Variants window size 預設是 M = 7\nquery dimension of each head 是 d = 32\nexpansion layer of each MLP is $\\alpha$ = 4\nC 是 first stage 的 hidden layers 的 channel numbers\nSwin-T\nC = 96 layer numbers = {2, 2, 6, 2} 大小和計算量是 Base 的大約 0.25 倍 complexity 接近 ResNet-50 Swin-S\nC = 96 layer numbers = {2, 2, 18, 2} 大小和計算量是 Base 的大約 0.5 倍 complexity 接近 ResNet-101 Swin-B\nC = 128 layer numbers = {2, 2, 18, 2} Swin-L\nC = 192 layer numbers = {2, 2, 18, 2} 大小和計算量是 Base 的大約 2 倍 Experiments Image Classification on ImageNet-1K Object Detection on COCO Semantic Segmentation on ADE20K Ablation Study Conclusion 基於 self-attention 的 shifted window 是 Swin Transformer 關鍵部分，被顯示出他在 CV 領域有效率且有效，並期望未來把它應用在 NLP。\n","date":"2023-04-14T01:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/swin-transformer-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"Swin Transformer 論文閱讀"},{"content":"分析方法 節點分析 (Nodal Analysis) 解節點電壓 選取一個節點做為參考節點 (reference node) 或已知節點 (datum node)，其他節點的電壓相對於它 假設它電位為 0，稱為 ground 把 KCL 用在剩下的 n-1 個參考節點 (假設電流方向，可以隨便假設，只要一致，不要兩端電流都流入同個電阻) 求解聯立方程式，得到各節點電壓 包含電壓源的節點分析 (Nodal Analysis with Voltage Sources) 如果電壓源連接於兩個非參考節點間，可以把電壓源和這兩個節點和與其並聯的元件看做一個超節點 (supernode) 或廣義節點 (generalized node)，解決無法知道流過電壓源的電流的問題 超節點的屬性 超節點內部的電壓源提供限制方程式 超節點本身沒電壓 超節點要同時用 KCL 和 KVL 網目分析 (Mesh Analysis) 只能適用平面電路 (planer circuit)，不能用在非平面電路 (nonplaner circuit)\n在一個平面上沒有交互連接的分支 網目 (Mesh)\n不包含子迴路的單一迴路 網目電流 (mesh current)\n流經網目的電流 決定網目電流步驟\n在 n 個網目中，指定 n 個網目電流 對 n 個網目個別應用 KVL，把歐姆定律應用在網目電流上，以表示電壓 求解 n 個聯立方程式，計算網目電流 包含電流源的網目分析 (Mesh Analysis with Current Sources) 如果有兩個 Mesh 共用同一個電流源，會形成超網目 (supermesh)，把公用的電流源還有串聯的元件給移除掉 視察法 待補 節點分析 vs 網目分析 節點比網目少選節點分析，反之也是 要求電壓節點，求電流網目 可以用一種驗證另一種的結果 有些特殊問題只能用其中一種方法 直流電晶體電路 電子產品中的基本元件有三端主動元件\u0026ndash;電晶體 (transistor)\n種類 雙極性接面電晶體 (biopolar junction transistor, BJT) 本節只討論這種 場效電晶體 (field-effect transistor, FET) BJT 類型\nNPN PNP Part\n射極 (emitter, E) 基極 (base, B) 集極 (collector, C) 工作模式\n作用 $I_C=\\alpha I_E$ $\\alpha$ 是共基極電流增益 (common-base current gain)，表示射極注入的電子被基極收集的比例 $I_C=\\beta I_B$ $\\beta$ 是共射極電流增益 (common-emitter current gain) $I_E=(1+\\beta) I_B$ $\\beta=\\frac{\\alpha}{1-\\alpha}$ 因為 $\\beta$ 很大，一個小的基極電流可以控制大電流的輸出，因此，雙極性電晶體可以當作放大器 截止 飽和 電路理論 線性性質 (Linear Property) 線性\n齊次性 輸入 ( 激發 excitation) 乘以一個常數，輸出 ( 響應 response) 也會乘以相同的常數 $kiR=kv$ 可加性 輸入總和的 response 等於個別輸入的 response 的總和 $v=(i_1+i_2)R=i_1R+i_2R=v_1+v_2$ 因此稱電阻是一個線性元件，因為電阻、電壓、電流的關係滿足齊次性和可加性\n如果電路滿足可加性和齊次性，稱此電路為線性電路\n線性電路是輸出與輸入為線性關係的電路 組成 線性元件 線性相依電源 獨立電源 重疊 (Superposition) 有兩個或更多的獨立電源時，除了節點和網目分析，可以求各獨立源對變數的貢獻，最後相加起來，這就是重疊 重疊定理 在一個線性電路中，跨接於元件上的電壓(流經元件的電流) = 每個獨立電源單獨作用於該元件二端的電壓(單獨流經該元件的電流)的代數和\n注意事項\n同一時間只考慮一個獨立電源，把其他的電壓源當作 0 V(短路)、電流源當作 0 A(開路) 相依電源受電路變數控制，保持不變 步驟\n保留一個獨立電源，算它的輸出(電壓或電流) 對每個電源做步驟 1 把每個獨立電源的貢獻相加 電源變換 (Source Transformation) 把電阻並聯的電流源和電阻串聯的電壓源做轉換(或反過來) 電源變換條件 $V_s=i_sR$ 也是用相依電源，但也要遵守條件 戴維寧定理 (Thevenin\u0026rsquo;s Theorem) 常有一種情境，電路種有一個特殊的元件是可變的，又稱負載 (load)，比如插座可能連接不同家電所組成的負載，而每當 load 改變，就要重新分析電路。戴維寧定理可以把固定的部分換成一個等效電路 戴維寧定理 線性二端電路可被由電壓源 $V_{Th}$ 和電阻 $R_{Th}$ 串聯所組成的戴維寧等效電路 (Thevenin equivalent circuit) 取代 $V_{Th}$ 是二端的開路電壓 $R_{Th}$ 是關閉獨立電源後，端點上的輸入或等效電阻 關閉所有獨立電源(根據 電壓/電流 來 短路/開路)，但考慮相依電源 $R_{Th}$ 有可能求出負值，這代表該電路提供功率，裡面有相依電源，雖然不可能出現在被動元件上，但等效電路是主動元件 假設外接一個電壓源，求外面的 v 和 i 即可算出 $R_{Th}$ 諾頓定理 (Norton\u0026rsquo;s Theorem) 和戴維寧定理很像，但是等效電路改成電流源和並聯的電阻，實際上，根據電源變換，可以知道諾頓定理和戴維寧定理的等效電阻相等\n$R_N=R_{Th}$\n$I_N=\\frac{V_{Th}}{R_{Th}}$\n計算戴維寧或諾頓等效電路，要先求 $v_{oc}$、$i_{sc}$、$R_{in}$\n求出兩個就可以算第三個 $V_{Th}=v_{oc}$ $v_{oc}$ 是 a 和 b 兩端的開路電壓 $I_N=i_{sc}$ $i_{sc}$ 是 a 和 b 兩端的短路電流 $R_{Th}=\\frac{v_{oc}}{i_{sc}}=R_N$ 最大功率轉移 (Maximum Power Transfer) 轉移到 load 的功率是 $p=i^2R_{L}=(\\frac{V_{Th}}{R_{Th}+R_L})^2R_L$ 最大值出現在 $R_L=R_{Th}$ 最大功率定理 (maximum power theorem) $p_{max}=\\frac{V_{Th}^2}{4R_{Th}}$ 電源建模 (Source Modeling) 實際的電源非理想電源 電壓源有串聯的內部電阻 (internal resistance) 下面稱為 $R_s$ 要理想要趨近於 0 若不連接 load (開路)，$v_{oc}=v_s$ $v_s$ 可以看做無負載源電壓 (unloaded source voltage)，連接 load 會使端電壓下降，這就是負載效應 (loading effect) $R_L$ 越大會越接近理想電壓 量測 $v_s$ 和內部電阻 量開路電壓 $v_s=v_{oc}$ load 端連接可變電阻，調到 $v_L=v_{oc}/2$ 此時 $R_L=R_{Th}=R_s$ 電流源有並聯的電源電阻 (source resistance) 要理想要趨近於無窮大 $R_L$ 越小越接近理想電源 電阻量測 (Resistance Measurement) 惠斯登電橋 (Wheatstone bridge) 平衡電橋 (balanced bridge) 非平衡電橋 (unbalanced bridge) ","date":"2023-04-10T00:00:54+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E9%9B%BB%E8%B7%AF%E5%AD%B8-ii/","title":"電路學 - II"},{"content":"介紹 試用 STM32 UART 功能\n會透過 RealTerm 和 STM32L476RG 溝通，並用 DMA 接收訊息\n根據 User manual，USART2 預設會連接 ST-LINK，要連接外部設備的話要修改 solder bridge\nioc 設置 Connectivity 可以設置 USART2 mode 從 disable 改選 Asynchronous Parameters Settings 可以設置各種資訊 Baud Rate Word Length Parity Stop Bits DMA Setting Add 一個 RX Mode 改成 circular，並打開 memory 的 increment address increment address 是因為資料是用 array 存 circular 是當資料滿了後，會回到 zero position NVIC Setting 設置 DMA 應該就會自動設置一個 interrupt，檢查一下 程式碼 發送\n1 2 uint8_t myTxData[13] = \u0026#34;Hello World\\r\\n\u0026#34;; HAL_UART_Transmit(\u0026amp;huart2, myTxData, 13, 10); 接收\n1 2 3 4 UART_HandleTypeDef huart2; // generated code uint8_t myRxData[20]; HAL_UART_Receive_DMA(\u0026amp;huart2, myRxData, 20); // 在 Init 後，在 main 中執行一次就好 interrupt\n在 hal_uart.c 有\n1 2 3 4 5 6 7 8 9 __weak void HAL_UART_RxCpltCallback(UART_HandleTypeDef *huart) { /* Prevent unused argument(s) compilation warning */ UNUSED(huart); /* NOTE : This function should not be modified, when the callback is needed, the HAL_UART_RxCpltCallback can be implemented in the user file. */ } 當 DMA 滿了就會呼叫這個 function\n實驗 1 2 3 4 5 6 7 8 9 10 void HAL_UART_RxCpltCallback(UART_HandleTypeDef *huart) { /* Prevent unused argument(s) compilation warning */ UNUSED(huart); /* NOTE : This function should not be modified, when the callback is needed, the HAL_UART_RxCpltCallback can be implemented in the user file. */ HAL_UART_Transmit(\u0026amp;huart2, myRxData, 20, 10); } 當 20 個 Bytes 儲存滿了就回傳資訊給電腦\nRealTerm Display 勾選 Half Duplex 發送的訊息會顯示綠色，接收的是黃色 Port 設置 Baud 和其他有的沒的 選 open Send EOL 可以勾選 CRLF 打一些文字後按 Send ASCII 結果 程式碼\n","date":"2023-04-09T01:32:54+08:00","permalink":"https://roykesydon.github.io/Blog/p/stm32-uart-%E5%AF%A6%E9%A9%97/","title":"STM32 UART 實驗"},{"content":"基本概念 常見名詞 電路 (electric circuit) 元件 (element) 電路組成的部分 單位系統 國際單位制 (International System of Units ,SI) 電荷與電流 電荷 (electric charge)\n組成原子的基本物質 庫倫 (C) 電荷守恆定律 (law of conservation of charge) 電荷不能被創造、破壞，只能轉移，系統中的電荷總數不變。 電流 (electric current)\n電荷的時間變化率 電流是電荷的移動，而且有方向性 安培 (A) 公式 $i \\triangleq \\frac{dq}{dt}$ $Q \\triangleq \\int_{t_0}^{t}i\\text{ }dt$ 直流電 (direct current, dc) 恆定常數的電流 交流電 (alternating current, ac) 隨著時間以正弦波變化的電流 電壓 電動勢 (electromotive force, emf) 驅動導體內的電子往某方向移動 電壓 (voltage)、電位差 (potential difference) 伏特 (V) $v_{ab}\\triangleq\\frac{dw}{dq}$ 單位電荷從 b 移動到 a 需要做的功 $w$ 是能量，單位是焦耳(J) $q$ 是電荷，單位是庫倫(C) 壓降 (voltage drop)、壓升 (voltage rise) 直流電壓 (dc voltage)、交流電壓 (ac voltage) 功率與能量 消耗或吸收能量的時間變化率，單位是瓦特(walt, W)\n公式\n$p \\triangleq\\frac{dw}{dt}$ $p=iv$ 被動符號規則 (passive sign convention)\n電流從電壓的正極流入元件 ($p=+vi$)，表示該元件吸收功率 電流從電壓的正極流出元件 ($p=-vi$)，表示該元件供應功率 能量守恆定律 (law of conservation of energy)\n電路中任何時刻的功率總和為 0 $\\sum p=0$ 電路元件 被動元件 (passive element) 不具備產生能量的能力 電阻器 (resistor)、電容器 (capacitor)、電感器 (inductor) 主動元件 (active element) 具備產生能量的能力 發電機 (generator)、電池 (battery)、運算放大器 (operational amplifier) 電源 電壓源、電流源 提供穩定電壓產生電流、提供穩定電流產生電壓 獨立電源 獨立電源提供指定電壓或電流的主動元件，與電路中其他元件無關。 電池和發電機可被當作近似理想的電壓源 相依電源 提供的電壓或電流受另一個電流或電壓控制的主動元件 類型 電壓控制電壓源 (voltage-controlled voltage source, VCVS) 電流控制電壓源 (current-controlled voltage source, CCVS) 電壓控制電流源 (voltage-controlled current source, VCCS) 電流控制電流源 (current-controlled current source, CCCS) 基本定律 歐姆定律 (Ohm\u0026rsquo;s Law) 一般材料具備阻止電荷流通的特性，稱為電阻 (resistance)\n均勻截面積下，$R=\\rho \\frac{l}{A}$\n$\\rho$ 是材料的電阻率 (resistivity) 電路中抑制電流的材料稱為電阻器 (resistor)\n$v=iR$\n短路 (short circuit)、開路 (open circuit)\n短路: 電壓是 0，電流可能是任意值，電阻值接近 0 開路: 電壓可能是任意值，電流是 0，電阻值接近無限大 固定電阻、可變電阻\n阻值可調與否 常用的可變電阻是電位器 (potentiometer) 不是所有電阻都遵守歐姆定律\n遵守歐姆定律的稱為線性電阻 (linear resistor)，反之則為非線性電阻 (nonlinear resistor)，阻值隨電流變化 電導 (conductance)\n電阻 R 的倒數 元件導通電流的能力 $G=\\frac{1}{R}=\\frac{i}{v}$ 單位姆歐 (mho, $\\mho$) 或西門子 (siemens, S) $1 S = 1 \\mho = 1 A/V$ Node, Branches, and Loops 分枝 (Branch)\n任意的兩端元件，比如電壓源、電阻 節點 (Node)\n指連接二個或多個分支的接點 迴路 (Loop)\n是電路中的任一封閉路徑 從一個節點開始，經過一組節點，最後回到一開始的節點，途中每個節點只經過一次 串聯\n多個元件共享單一節點 並連\n多個元件連接到相同的兩個節點 獨立迴路 (independent loop)\n至少包含一個不屬於其他獨立迴路的 branch $b=l+n-1$ b 是 branch，l 是獨立迴路，n 是 node 克希荷夫定律 (Kirchhoff\u0026rsquo;s Laws) Kirchhoff\u0026rsquo;s current law (KCL)\n流入任一 node 或封閉邊界的電流總和為 0 或是說流入某一節點的電流和等於流出的電流和 $\\sum_{n=1}^{N}i_n=0$ $N$ 是連到 node 的 branch 數 Kirchhoff\u0026rsquo;s voltage law (KVL)\n一條封閉路徑(或迴路)中的電壓總和為零 或是說 voltage drop 的總和 = voltage rise 的總和 $\\sum_{m=1}^{M}n_m=0$ $M$ 是迴路中的 branch 數 串並聯電阻 串聯\n$R_{eq}=\\sum_{n=1}^N R_n$ $R_{eq}$ 是等效電阻 (equivalent resistance) 分壓定理 (principle of voltage division) 電壓和各電阻的阻值成正比，阻值越大，壓降越大 分壓器 (voltage divider) $v_1=\\frac{R_1}{R_1+R_2}v$ 並聯\n$\\frac{1}{R_{eq}}=\\frac{1}{R_1}+\\frac{1}{R_2}+\u0026hellip;+\\frac{1}{R_N}$ $R_{eq}$ 永遠小於並聯電阻中最小的電阻值 $G_{eq} = G_{1}+G_2+\u0026hellip;+G_N$ 分流定理 (principle of current division) 各分支電流與電阻值成反比 分流器 (current divider) $i_1=\\frac{R_2}{R_1+R_2}i$ Y - $\\Delta$ 轉換 (Wye-Delta Transformations) 遇到電阻不是串聯也不是並聯的情況，要如何轉換 有時候把 Y 型網路和 $\\Delta$ 型網路相互轉換會比較好算 Y 型網路 = T 型網路 $\\Delta$ 網路 = $\\Pi$ 網路 $\\Delta$ - Y 轉換 (Delta to Wye conversion) Y 網路的每個電阻是 $\\Delta$ 中的兩個相鄰電阻的相乘除以 $\\Delta$ 中的三個電阻總和 Y - $\\Delta$ 轉換 (Wye to Delta conversion) $\\Delta$ 網路的每個電阻是 Y 中的兩兩電阻的相乘總和除以 Y 中的對角電阻\n平衡\n條件 $R_1=R_2=R_3=R_Y$ $R_a=R_b=R_c=R_{\\Delta}$ 結果 $R_Y=\\frac{R_\\Delta}{3}$ ","date":"2023-04-09T00:00:54+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E9%9B%BB%E8%B7%AF%E5%AD%B8-i/","title":"電路學 - I"},{"content":"目的 本文會試用 GPIO output / input / interrupt\nGPIO 架構 Output 介紹 在 ioc 那邊選個 pin，選 GPIO_Output\n在左邊欄位 System Core 選擇 GPIO\n有五個欄位可以設定\nGPIO output level\n初始電位 GPIO mode\npush pull 和 open drain 位於架構圖下方那部分，push pull 可以用 PMOS 和 NMOS 來得到高低電位，open drain 會 disable PMOS，讓你可以在外面自己接上拉電阻 GPIO Pull-up/Pull-down\nMaximum output speed\nUser Label\n用完記得 ctrl+s 讓他 generate code\n1 2 3 4 5 6 7 8 9 /*Configure GPIO pin : PtPin */ GPIO_InitStruct.Pin = RED_LED_Pin; GPIO_InitStruct.Mode = GPIO_MODE_OUTPUT_PP; GPIO_InitStruct.Pull = GPIO_NOPULL; GPIO_InitStruct.Speed = GPIO_SPEED_FREQ_LOW; HAL_GPIO_Init(RED_LED_GPIO_Port, \u0026amp;GPIO_InitStruct); /*Configure GPIO pin Output Level */ HAL_GPIO_WritePin(RED_LED_GPIO_Port, RED_LED_Pin, GPIO_PIN_RESET); 1 2 3 4 HAL_GPIO_WritePin(RED_LED_GPIO_Port, RED_LED_Pin, GPIO_PIN_RESET); // 低電位 HAL_GPIO_WritePin(RED_LED_GPIO_Port, RED_LED_Pin, GPIO_PIN_SET); // 高電位 HAL_Delay(1000); //等一秒 HAL_GPIO_TogglePin(RED_LED_GPIO_Port, RED_LED_Pin) 根據架構圖左側，你可以透過修改 BSRR 來修改 ODR，達到修改輸出的效果，請見 Reference Manuals，實際上 HAL_GPIO_WritePin 也是這樣實現的\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 void HAL_GPIO_WritePin(GPIO_TypeDef* GPIOx, uint16_t GPIO_Pin, GPIO_PinState PinState) { /* Check the parameters */ assert_param(IS_GPIO_PIN(GPIO_Pin)); assert_param(IS_GPIO_PIN_ACTION(PinState)); if(PinState != GPIO_PIN_RESET) { GPIOx-\u0026gt;BSRR = (uint32_t)GPIO_Pin; } else { GPIOx-\u0026gt;BRR = (uint32_t)GPIO_Pin; } } Input 介紹 看架構圖上方，用 Schmitt trigger 取得高低電位資料，他有 upper threshold 和 lower threshold，而不是用 single threshold\n1 2 3 4 5 /*Configure GPIO pin : PtPin */ GPIO_InitStruct.Pin = GREEN_LED_INPUT_Pin; GPIO_InitStruct.Mode = GPIO_MODE_INPUT; GPIO_InitStruct.Pull = GPIO_NOPULL; HAL_GPIO_Init(GREEN_LED_INPUT_GPIO_Port, \u0026amp;GPIO_InitStruct); 1 uint8_t green_led_input = HAL_GPIO_ReadPin(GREEN_LED_INPUT_GPIO_Port, GREEN_LED_INPUT_Pin); Interrupt ioc 選個 pin，設定 GPIO_EXTI，這邊我選 B1(PC13)，也就是開發版上的藍色按鈕\n可以選 GPIO mode，這邊選 Falling Edge Trigger，值得一提的是他的設計是上拉電阻，所以這樣不是放開後觸發，是按下後觸發。\nioc 的 System Core 的 NVIC 還要把 EXTI line[15:10] interrupts 給 enabled，然後 Code generation 打開 Generate IRQ handler，還有 Call HAL handler。\n在 stm32l4xx_it.c 裡， 現在會有\n1 2 3 4 5 6 7 8 9 10 void EXTI15_10_IRQHandler(void) { /* USER CODE BEGIN EXTI15_10_IRQn 0 */ /* USER CODE END EXTI15_10_IRQn 0 */ HAL_GPIO_EXTI_IRQHandler(B1_Pin); /* USER CODE BEGIN EXTI15_10_IRQn 1 */ /* USER CODE END EXTI15_10_IRQn 1 */ } 這兩行各別是因為我們剛剛開的功能生的\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 void HAL_GPIO_EXTI_IRQHandler(uint16_t GPIO_Pin) { /* EXTI line interrupt detected */ if(__HAL_GPIO_EXTI_GET_IT(GPIO_Pin) != 0x00u) { __HAL_GPIO_EXTI_CLEAR_IT(GPIO_Pin); HAL_GPIO_EXTI_Callback(GPIO_Pin); } } __weak void HAL_GPIO_EXTI_Callback(uint16_t GPIO_Pin) { /* Prevent unused argument(s) compilation warning */ UNUSED(GPIO_Pin); /* NOTE: This function should not be modified, when the callback is needed, the HAL_GPIO_EXTI_Callback could be implemented in the user file */ } __weak 代表有同名 function 的話，就會採用沒 __weak prefix 的\n所以我們可以在 gpio.c 放下面的程式碼\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #include \u0026lt;stdbool.h\u0026gt; void HAL_GPIO_EXTI_Callback(uint16_t GPIO_Pin) { if(GPIO_Pin == B1_Pin){ static bool prev_val = false; if(prev_val == false){ HAL_GPIO_WritePin(RED_LED_GPIO_Port, RED_LED_Pin, GPIO_PIN_SET); prev_val = true; } else{ HAL_GPIO_WritePin(RED_LED_GPIO_Port, RED_LED_Pin, GPIO_PIN_RESET); prev_val = false; } } } 實驗 設定兩個輸入，一個輸出，一個 interrupt\n當按下按鈕時，切換紅色 LED 的亮滅，並且讓板子上的綠色 LED 輸出和紅色 LED 相反的結果\nB1(PC13、藍色按鈕) 按下去的時候，會發出 interrupt，並讓 RED_LED(PC10) 輸出和上次相反的電位，讓麵包版上的紅色 LED 亮滅，正極那邊接一條杜邦線給 GREEN_LED_INPUT (PC12)，並且 LD2(PA5、板子上的綠色 LED) 會輸出和紅色 LED 相反的結果。\n程式碼\n","date":"2023-04-02T01:32:54+08:00","permalink":"https://roykesydon.github.io/Blog/p/stm32-gpio-%E5%AF%A6%E9%A9%97/","title":"STM32 GPIO 實驗"},{"content":"使用的板子 STM32L476RG\n開發文件 開發前需要先去 ST 官網，根據你的板子載四個重要文件\nDatasheet 上圖是其中的 block diagram\nReference Manuals\nProgramming Manuals\nSchematic\n創建 project File -\u0026gt; New -\u0026gt; STM32 Project Board Selector 搜索 NUCLEO-L476RG，選取並 Next 設置 Project Name，其他不動，Next Copy only the necessary library files，Finish ioc 專案會有個 .ioc 檔，可以透過 GUI 生成設定 pin 的程式碼\n建議 Project Manager 的 Code Generator 勾選 Generate peripheral initialization as a pair \u0026lsquo;.c/.h\u0026rsquo; files per peripheral，開發起來比較方便\nCompile 點選上面的 hammer\nClock Configuration ioc 那邊還可以設置 clock\nExternal clock LSE 和 HSE 是 (Low / High Speed External)，你有 oscillator 的話可以自己弄\n你可以調 sysclk 或 peripheral clock\nProgramming 在 USER CODE section 寫上程式碼 這是由於生成程式碼的機制所致\n選取的部分可以按 F3，看他是從哪邊來的，或看 macro 之類的\n按下 alt + / 會出現自動補全的提示\nDEBUG 上面有個 BUG 符號的東西，旁邊的箭頭可以用 DEBUG 的設定\n又建 STM32 C/C++ Application，可以 New 新設定\nC/C++ Application 那邊選你 compile 的 elf 檔\nDebugger 開啟 ST-LINK S/N，並且掃描，如果你的電腦有接上 MCU，應該會直接找到\n","date":"2023-04-02T00:32:54+08:00","permalink":"https://roykesydon.github.io/Blog/p/stm32cubeide-%E5%9F%BA%E6%9C%AC%E9%96%8B%E7%99%BC%E4%BD%BF%E7%94%A8/","title":"STM32CubeIDE 基本開發使用"},{"content":"paper: GIT: A Generative Image-to-text Transformer for Vision and Language\n1 2 3 4 5 6 ██████╗ ██╗████████╗ ██╔════╝ ██║╚══██╔══╝ ██║ ███╗██║ ██║ ██║ ██║██║ ██║ ╚██████╔╝██║ ██║ ╚═════╝ ╚═╝ ╚═╝ Abstract 設計了一個 Generative Image-to-text Transformer，統一 vision-language tasks，像是 image/video captioning 或是問答。\n雖然 generative models 在預訓練和微調的時候是同樣的網路架構，現有的工作通常都包含複雜的架構 (uni/multi-modal encoder/decoder)， 而且依賴於外部模組，比如物件偵測或 optical character recognition (OCR)。\n在 GIT，我們簡化為 single language modeling task 下的一個 image encoder 和一個 text decoder。\n擴大了預訓練資料和模型大小以提高模型性能。\n在許多具有挑戰性的 benchmarks 上取得 SOTA。\n比如首次在 TextCpas 上超越人類的表現。\n提出了一種 generation-based image classification and scene text recognition 的新方案。\nIntroduction 近年來在 vision-language（VL）預訓練方面取得了巨大進展，特別是基於 image-text pairs 的大規模數據，例如 CLIP、Florence 和 SimVLM。\n學習到的 representation 很好的提高了下游任務的性能，比如 image captioning、visual question answering 和 image-text retrieval。\n在預訓練過程中，Masked Language Modeling (MLM) 和 Image-Text Matching (ITM) 被廣泛使用。\n然而這些 loss 和下游任務不同，必須做 task-specific adaptation。\n比如， image captioning 要移除 ITM，VQA 需要額外隨機初始的 MLP。\n為了減少這種差異，最近的研究試圖為預訓練模型設計 unified generative models 來預訓練，因為大多數 VL 的問題可以轉化為生成問題。\n這些方法通常利用 multi-modal encoder 和 text decoder，並精心設計 text input 和 text target。\n為了進一步推動這方向的研究，作者設計了一個簡單的 Generative Image-to-text Transformer，稱作 GIT，只包含一個 image encoder 和 text decoder。\n預訓練任務只是把輸入的圖像映射到相關聯的文字描述。\n盡管他很簡單，但還是在眾多具有挑戰性的 benchmark 取得 SOTA。\nimage encoder 是 Swin-like vision transformer，在大量的 image-text pairs 上做 pretrain，基於 contrastive task。\n這消除了現有許多方法中對 object detector 的依賴。\n為了將其擴展到影片領域，我們把多個 frame 的特徵 concatenate，作為 video 表示。\ntext decoder 是一個用來預測相關聯文字的 transformer。\n整個網路都是基於 language modeling task 來訓練。\n對於 VQA，input question 被看作 text prefix，並以 auto-regressive 的方法生出答案。\n此外，作者提出了一種 generation-based 的 ImageNet classification 新方案，預測標籤直接根據作者的生成模型，而不用預先定義詞彙表。\n我們的作法很簡單，但在擴大預訓練資料和模型大小後，成果驚人。\n主要貢獻如下：\n我們展示了 GIT，僅由一個 image encoder 和一個 text decoder 組成，透過 language modeling task，在 0.8 billion image-text pairs 上 pretrain。\n在 image/video captioning 和 QA 上，沒有基於 object detectors，object tags 和 OCR，就在多個任務上取得 SOTA。證明簡單的網路架構也可以透過 scaling 取得強大的性能。\n我們證明 GIT 雖然 pretrain 在 image-text pairs，也能在 video tasks 上取得 SOTA，不需要 video dedicated encoders。\n我們提出了一種新的 generation-based image classification 方案，在 ImageNet-1K 上，取得不錯的性能。\nRelated Work 在 VL pre-training 中，多 multi-task pre-training 被廣泛使用，賦予網路多種或增強的能力。\n比如，MLM 和 ITM 是廣泛採用的預訓練任務，最近也有研究加入 image-text contrastive loss。\n由於多數 VL 任務都可以表示成 text generation task，所以可以訓練一個生成模型來支持各種下游任務。\n輸入和輸出文本通常都會經過精心設計，以預訓練這樣的生成模型。\n對於 image representation，Faster RCNN 被大多數現有方法用來提取區域特徵。\n同時，也很容易以 end-to-end 的方法訓練整個網路。\n除了 feature map，object tags，也很常被用來方便 transformer 理解上下文，特別是 novel objects。\n對於與場景文本相關的任務，調用 OCR 以生成場景文本作為附加網路輸入。\n對於 text prediction，常用 transformer network，結合 cross-attention module 來融合 image tokens。\n或者只是單純 concatenate text tokens 和 image tokens，然後用 self-attention。\n在本文中，我們有 9 個不同的 benchmark，3 種不同模型大小和 3 種不同預訓練資料規模。\nGenerative Image-to-text Transformer Network Architecture image encoder 基於 contrastive pre-trained model。\n輸入是原始圖像，輸出是 compact 2D feature map，被 flatten 成 list of features。\n透過一個額外的 linear layer 和一個 layernorm layer，image features 被 project 到 D dimensions，也就是 text encoder 的 input。\n作者使用做 contrastive tasks pretraining 的 image encoder，因為最近的研究表明這種 image encoder 有更好的性能。\n在後面的章節，還觀察到 VL performence 明顯地隨著更強的 image encoder 而有所提升。 這和 object detection-based 的方法觀察到的結果一致。\nCoCa 的 concurrent work 統一了 contrastive task 和 the generation task，作為一個預訓練階段。\n作者的方法相當於是按順序分離兩個任務:\n用 contrastive task 訓練 image encoder 用 generation task pretrain image encoder 和 text decoder text decoder 是一個用於預測文本描述的 transformer module，由多個 transformer block 組成，每個 transformer block 由一個 self-attention layer 和 feed-forward layer 組成。\ntext 被 tokenize 和 embed 到 D dimensions，並添加 positional encoding 和 layernorm layer。\nimage features 和 text embeddings 被 concatenate 起來作為 transformer module 的輸入。\ntext 以 [BOS] 開始，並以 auto regressive 的方式 decode，直到 [EOS] 或 maximum steps。\nattention mask 根據上圖設計，使的 text token 只能依賴於前面的 text token 和 image token，而 image token 可以互相做 attention。\n這和 unidirectional attention mask 不同，unidirectional attention mask 並非每個 image token 都可以依賴於其他的 Image token。\n作者很好地初始化 image encoder，卻隨機初始化 text decoder。\n這種設計動機是基於[MiniVLM: A Smaller and Faster Vision-Language Model]，該研究隨機初始化顯示出與 BERT 初始化相似地性能。\n原因可能在於 BERT 地初始化無法理解圖像信號，這對於 VL 任務至關重要。\n[Flamingo: a Visual Language Model for Few-Shot Learning] 採用了類似的 image encoder + text decoder，但是他們的 decoder 經過 pretrain，並且有 freeze，好保留大型語言模型的泛化能力。\nGIT 的所有參數都會更新，以更好地適應 VL 的任務。\n另一種架構是 cross-attention-based 的 decoder，用於 incorporate image signals，而不是 concatenation 再用 self-attention。\n根據實驗，large-scale 的 pre-training，self-attention-based 會有更好的性能，小規模的則是 cross-attention-based。\n一個合理的解釋是，經過充分訓練，decoder 可以很好地處理圖像和文本，而且 image token 可以為了 text generation 更好地更新。\n而 cross-attention 讓 image token 沒辦法 attend 彼此。\nPre-training 訓練採用 language modeling (LM) loss。\n$I$ 是 image $y_i,i \\in $ { $ 1,\u0026hellip;,N $ } 是文字 token，$y_0$ 是 [BOS]，$y_{N+1}$ 是 [EOS] CE 是有 0.1 label smoothing 的 cross-entropy 另一種選擇是 MLM，在每個 epoch 中預測 15% 的輸入 token，要預測所有 token 至少需要 1 / 0.15 = 6.7 個 epochs，對於 LM，每個 epoch 都可以預測所有 token，對於大規模預訓練資料來說效率更高。\nablation studies 顯示出 LM 可以在有限的 epoch 內實現更好的性能。 在大規模訓練中，由於計算資訊的限制，只有兩個 epoch，所以選擇 LM。 與此同時，大部分最近的 large-scale language model 也是基於 LM。\n如果沒有圖像輸入，該模型將簡化為 decoder-only 的語言模型，架構類似於 GPT-3。\n因此，這種設計還可以利用 text-only 的資料來提升 scaled-up decoder 的能力，把這保留給未來的工作。\nFine-tuning 對於 image captioning，由於訓練數據格式和預訓練相同，所以用同樣的 LM task 來微調 GIT。 對於 visual question answering，問題和 GT 在微調的時候被看做 special caption，但 LM loss 僅用於答案和 [EOS]。\n推理過程中，question 被當作 caption 的 prefix，完成的部分是預測。\nVQAv2 現有的工作收集候選答案，再重構成分類問題，預測一次。 作者的工作有更多挑戰，因為是生成式的，需要生出至少兩個正確的 token，答案和 [EOS]。\n然而考慮到自由形式答案的好處，作者選擇了生成方法。\n由於生成模型的難度，VQAv2 比現有的判別工作略差。\n對於和 scene-text related VQA 任務，現有方法通常利用 OCR 生成 5 個 scene text 並用 dynamic pointer network 決定當前輸出應該是 OCR 還是 general text。\n但由於作者的方法不依賴於 OCR，因此也不依賴於 dynamic pointer network。\n根據實驗，作者發現模型透過大規模預訓練資料學會如何閱讀場景文本，並且作者的模型不是專門為了影片領域設計的，但可以透過簡單的架構更改就取得具有競爭力或甚至 SOTA 的成果，也就是作者可以從每個影片採樣多個 frame，並透過 image encoder 獨立地為每個 frame 編碼。 最後添加一個 learnable temporal embedding (初始化為 0)，並 concatenate sampled frames 的特徵。\n作者還用於圖片分類，把 class name 用於 caption。\n這和現有工作不一樣，現有工作通常先定義詞彙表，並用線性層預測每個類別的可能性。\n當新數據和新類別被添加到現有數據的時候，這種新一代的方案是有益的，因為這樣可以在不引入新參數的情況下對新數據進行訓練。\nExperiments Setting 收集 0.8B 的 image-text pairs 來預訓練。\nimage encoder 是根據 pre-trained contrastive model 初始化的。\nhidden dimension (D) = 768\ntext decoder 有 6 個 randomly-initialized transformer blocks\n共有 0.7b 的參數\nimage decoder 和 text encoder 的 learning rate 各別是 1e-5 和 5e-5，都 cosine decay 到 0\n推論階段 beam size 是 4，length penalty 是 0.6。\nSupplementary materials 展示了小模型變體 (GITB and GITL) 和更大模型 (GIT2) 的結果\nResults on Image Classification 輸出必須與類別名稱完全匹配，甚至考慮多或少的空格。\n由於不知道詞彙表，精確匹被準確度只有 1.93%，如果預測包含 GT 就對，那有 40.88%。\n通過微調每個類別只有 1 shot 或 5 shot，準確度會顯著提高， 表明只用少量訓練樣本，也可以輕鬆適應下游任務。\n與 Flamingo 相比，GIT 實現更高的準確度。\nFlamingo 在沒有參數更新的情況下進行小樣本學習，但需要額外的網路輸入，可能會增加推理成本。\n相比之下，GIT 透過一次 lightweight fine-tuning，推理過程中不需要這些 training shot。\nAnalysis Model and data scaling 對於網路架構，作者的模型被稱作 Huge，把 image encoder 換成 CLIP 的 ViT-B/16 和 ViT-L/14 的則是 Base 和 Large。\n可以看出較大的 image encoder 帶來的好處，但根據實驗， 作者發現很難有效地擴展 text decoder，原因可能是 LM 很難用 limited amount of text 來訓練。\n另一個可能的原因是 image encoder 負責 object recognition，而 decoder 負責以 NLP 的方法組織 object terms。 後一項任務可能很容易，因為大多數描述都遵循相似的模式，比如 Object + verb + subject，所以只要一個 small decoder，較大的 decoder 可能會增加學習難度。\nFlamingo 的研究顯示更大的 Decoder 可以提高性能，但是他們的 decoder 有 pretrain 過，而且在 VL 預訓練的時候 frozen，避開了如何有效訓練 decoder 的問題。\nLEMON 的 transformer 可以擴展到 32 層，可能是因為他們使用 MLM 而不是 LM，後者可能更加困難。\nScene text in pre-training data 為了瞭解 scene text comprehension 的能力，作者檢查了 pretrain data 有多少 image-text pairs 有 scene text。\n作者用 Microsoft Azure OCR API4 對一些資料做 OCR，然後把 OCR 結果和 associated text 做比對，只有包含長度超過 5 個字元的 OCR 結果才會算比對。 有 15% 的 CC12M 和 31% 的下載圖像(500K) 包含 scene text 描述。 由於任務是訓練預測 text，網路逐漸學會閱讀 scene text。\nConclusion Limitations 根據實驗，目前不清楚如何控制生成的 caption 以及如何在不更新參數的情況下執行 in-context learning，把這留給未來的工作。\nSocietal impact 該模型在大規模數據集上預訓練，不能保證數據不含 toxic language，可能會 poison output。\n其他 A.3 Network 講超參數\n","date":"2023-03-29T01:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/git-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"GIT 論文閱讀"},{"content":"paper: RoBERTa: A Robustly Optimized BERT Pretraining Approach\n1 2 3 4 5 6 ██████╗ ██████╗ ██████╗ ███████╗██████╗ ████████╗ █████╗ ██╔══██╗██╔═══██╗██╔══██╗██╔════╝██╔══██╗╚══██╔══╝██╔══██╗ ██████╔╝██║ ██║██████╔╝█████╗ ██████╔╝ ██║ ███████║ ██╔══██╗██║ ██║██╔══██╗██╔══╝ ██╔══██╗ ██║ ██╔══██║ ██║ ██║╚██████╔╝██████╔╝███████╗██║ ██║ ██║ ██║ ██║ ╚═╝ ╚═╝ ╚═════╝ ╚═════╝ ╚══════╝╚═╝ ╚═╝ ╚═╝ ╚═╝ ╚═╝ Abstract 發現 BERT 訓練不足，並且作者的模型在 4/9 的 GLUE 任務, RACE 和 SQuAD 取得 SOTA。\nIntroduction 自監督的訓練方法帶來了顯著的性能提升，但要確定這一堆方法中的哪些方面貢獻最大，具備挑戰性。\n訓練的計算量是昂貴的，使 fine-tune 受限，而且通常都是用不同大小的 private training data，使評估模型更加困難。\n作者提出了對 BERT 預訓練的 replication study，包括對超參數的調整，以及對訓練集大小的仔細評估。\n作者發現 BERT 訓練不足，並提出了一種改進方法，稱為 RoBERTa，可以達到或超過所有 post-BERT 的方法。\n修改如下:\n訓練模型的時間更長，batch 更大，用更多 data 移除 next sentence prediction objective 訓練更長的序列 動態地改變用於訓練資料的 masking pattern 貢獻:\n提出一組重要的 BERT 設計選擇和訓練策略 使用了新的 dataset，叫做 CCNEWS，並證明用更多的資料來預訓練，可以提高下游任務的表現 訓練表明，在正確的設計選擇下，pretrained masked language model 和其他最近的方法比，具有競爭力 Background 對 BERT 做回顧\nArchitecture L layers A self-attention heads H hidden dimension Training Objectives 預訓練的時候，BERT 有兩個目標: masked language modeling 和 next sentence prediction\nMasked Language Model (MLM) BERT 隨機選擇 15% 的 token 進行可能的替換\n80% 換成 [MASK]，10% 保持不變，10% 被選為一個隨便的 vocabulary token\nNext Sentence Prediction (NSP) 分類第二句是不是下一句，是二元分類。\n正例由提取連續的句子產生，負例由不同的片段配對產生。\n正例和負例以相等機率產生。\nOptimization Adam $\\beta_1$ = 0.9, $\\beta_2$ = 0.999, $\\epsilon$ = 1e-6 $L_2$ weight decay of 0.01 Learning rate 前 10,000 step warm up 到 1e-4，然後 linear decay 全部的 layer 和 attention weight 都 dropout 0.1 GELU 激活函數 1,000,000 次 update，batch size 256，序列長度 512 Data BERT 在 BookCorpus 和 English Wikipedia 混和的資料集上訓練，共有 16GB 的未壓縮文本\nExperimental Setup 描述對於 BERT 的 replication study 的實驗設置\nImplementation 作者用 FAIRSEQ 重新實現了 BERT。\n主要遵循 [Background-Optimization] 中的 BERT 原始超參數，但 peak learning rate 和 warmup step 除外，他們針對每個設置單獨調整。\n作者發現訓練對 Adam epsilon 非常敏感。\n作者發現設置 $\\beta_2$ = 0.98，在大 batch size 的情況下，可以提高訓練時的穩定性。\n用最多 512 個 token 預訓練。\n作者不會隨機注入短序列，也不會為前 90% 的更新縮短輸入的長度。\n作者只訓練 full-length 的 sequences。\nData BERT-style 的預訓練仰賴大量文本。\n已有研究證明增加數據量可以提高 end-task 的性能。\n已有一些研究，用比原始 BERT 更多樣更大的數據集，但不是所有的數據集都有公開。\n本研究用了五個不同大小和領域的英文文本，共有超過 160 GB 的未壓縮文本。\n使用以下數據集:\nBookCorpus + English Wikipedia BERT 原本使用的。 16 GB CC-News 作者從 CommonCrawl News dataset 的英文部分中蒐集，包含了 2016 年 9 月到 2019 年 2 月的 6300 萬篇英文新聞。 過濾後有 76 GB OpenWebText WebText 的開源重建版，從 Reddit 上至少有 3 個 upvotes 的 shared URLs 提取出的 Web 內容。 38 GB Stories 包含 CommonCrawl data 的一個子集合，經過過濾，以匹配 story-like style of Winograd schemas 31 GB Evaluation 使用以下三個 benchmarks 評估預訓練模型\nGLUE The General Language Understanding Evaluation\n用於評估自然語言理解的 9 個數據集的集合，任務被定義為 single-sentence 分類或 sentence-pair 分類任務。\nfinetune 的流程遵循原始 BERT paper\nSQuAD The Stanford Question Answering Dataset\n提供一段 context 以及一個問題\n具有兩個版本 V1.1 和 V2.0\nV1.1 context 總是包含一個答案 評估 V1.1 的時候，作者採用和 BERT 相同的 span prediction method V2.0 一些問題在提供的 context 中沒有回答，使任務更有挑戰性 評估 V2.0 的時候，作者會用一個額外的二元分類器預測問題是否可以回答，在評估的時候，只預測被分類為可回答的 RACE The ReAding Comprehension from Examinations 大型閱讀理解數據集，有超過 28,000 篇文章 以及將近 100,000 個問題 從中國的英文考試蒐集的，這些考試是為國中生和高中生設計的 每篇文章都與多個問題相關聯 對每個問題，要從四個選項中選出一個對的 context 比起其他閱讀理解的數據集要長，而且要推理的問題比例很大 Training Procedure Analysis 探討哪些選擇對成功預訓練 BERT 很重要。\n作者把架構固定，也就是訓練和$BERT_{BASE}$ (L=12, H=768, A=12, 110M params)一樣架構的 BERT models\nStatic vs. Dynamic Masking BERT 在 preprocessing 的時候處理 masking，產生單個 static mask。 作者為了避免在每個 epoch 都對每個 instance 用相同的 mask，將數據複製了 10 次，在 40 個 epochs 裡，以 10 種不同的方式 mask。所以一次訓練過程中，相同的 mask 會出現四次。\n作者會以上述策略和 Dynamic masking 進行比較，Dynamic masking 是在每次餵 model 前，才生成 mask。\n作者發現 Dynamic Masking 相比 static，要不是差不多，就是略好，基於結果和效率的優勢考量，其他實驗中都用 dynamic masking。\nModel Input Format and Next Sentence Prediction 原始的 BERT 預訓練中，兩個句子要不是同一個文件的連續句子(p = 0.5)，不然就是不同的 document 做採樣\n以往有研究指出移除 NSP 會損害性能，但也有研究質疑必要性，所以本文比較了幾種替代訓練格式：\nSEGMENT-PAIR+NSP 最原始的方法，每個 segment 可以有多個自然句子 SENTENCE-PAIR+NSP 只包含一對句子，由於輸入明顯少於 512 token，所以會增加 batch size 讓 token 總數和前者差不多 FULL-SENTENCES 包含從一個或多個文件中連續採樣的完整句子，可能會跨越文件邊界，在文件邊界間會加個額外的分隔符 移除了 NSP DOC-SENTENCES 和 FULL-SENTENCES 差不多，但不能跨越 document，在 document 尾巴的部分會容易少於 512，所以會動態增加 batch size，讓 token 總數和 FULL-SENTENCES 差不多 移除了 NSP 發現 DOC-SENTENCES 是最棒的，但由於 DOC-SENTENCES 會讓 batch sizes 大小可變，所以其他實驗會用 FULL-SENTENCES，比較好和其他相關工作比較。\nTraining with large batches 根據過去神經網路機器翻譯的工作，當 learning rate 適當增加的時候，用非常大的的 mini-bathces 可以提高 optimization 的速度和 end-task 性能。\n最近的研究也顯示 BERT 適用於 large batch training。\nText Encoding Byte-Pair Encoding (BPE) 是一種介於字符級別和詞級別表示之間的混合表示方法，它允許處理自然語言語料庫中常見的大詞彙量。\nBPE 不依賴於完整的單詞，而是依靠 subwords units，通過對訓練語料進行統計分析來提取這些 subwords units。\nBPE 詞彙表的大小通常在 10K-100K 的 subword units。\n在 \u0026ldquo;Language Models are Unsupervised Multitask Learners\u0026rdquo; 文中，提到了一種巧妙的 BPE 實現，不是用 unicode characters，而是用 bytes 作為 base subword units。可以生出 50K 大小的詞彙表，而且不用引入任何的 \u0026ldquo;unknown\u0026rdquo;。\n原始的 BERT 用 character-level BPE vocabulary，大小為 30K。\n本文考慮用 50K byte-level BPE vocabulary，而不對輸入做額外的 preprocessing 或 tokenization，\u0026ldquo;Language Models are Unsupervised Multitask Learners\u0026rdquo; 的研究顯示這些 Encoding 的方法在最終效能上並無太大差別，只在某些任務上 end-task performance 表現稍差。\n但作者相信 universal encoding scheme 的優勢超過了輕微的性能下降，其他實驗也會用這種邊碼方式。\nRoBERTa 整理上面說的改進。\nRoBERTa 用以下配置:\ndynamic masking FULL-SENTENCES without NSP loss large mini-batches larger byte-level BPE 此外，還調查了兩個之前的工作沒強調的重要因素:\n用於預訓練的 data 訓練過 data 的次數 為了把這些因素的重要性和其他模型選擇分隔開，先按照 $BERT_{LARGE}$ (L = 24, H = 1024, A = 16, 355M parameters) 訓練 RoBERTa。\n作者在 BOOKCORPUS plus WIKIPEDIA dataset 進行了 100K step 的預訓練。\n在控制 training data 的情況下， RoBERTa 比 $BERT_{LARGE}$ 的結果有大幅度的改進，重申了前面設計選擇的重要性。\n接下來，結合之前說的額外 dataset，並用相同的步數(100K) 訓練 RoBERTa，觀察到下游任務的性能進一步提高，驗證了數據大小和多樣性的重要性。\n最後，對 RoBERTa 做更長時間的預訓練，將步數提高到 300K 和 500K，再次觀察到下游任務性能顯著提升。\n作者也注意到，即使是他們訓練時間最長的模型，也不會 overfit 他們的數據。\n本文的其他部分在三個 benchmark 評估好壞: GLUE、SQuaD 和 RACE\nGLUE Results 雖然很多 GLUE 排行榜的提交都是 depend on multi-task finetuning，但作者的 submission 是 depends only on single-task finetuning。\n此外，對於 RTE、STS 和 MRPC，從 MNLI 的模型微調會比 baseline 的 RoBERTa 有幫助許多。\n在第一個設置 (single-task, dev) 中，RoBERTa 在所有 9 個 GLUE 任務 dev set 上都取得了最先進的結果。\n在第二個設置 (ensembles, test) 中，作者將 RoBERTa 提交到 GLUE 排行榜，並在 9 個任務中的 4 個上取得了 SOTA 和迄今為止的最高平均分。\n這令人興奮的地方在於，與多數 top submissions 不同，RoBERTa 不是 depend on multi-tasking finetuning\nConclusion 在預訓練 BERT 模型時，作者仔細評估了許多設計決策。\n作者發現，通過對模型進行更長時間的訓練、使用更大的批次處理更多的數據、去除 NSP、訓練更長的序列、dynamic masking，可以顯著提高性能。\n作者改進的預訓練程序，我們稱之為 RoBERTa，在 GLUE、RACE 和 SQuAD 上實現了 SOTA，而無需為 GLUE 進行多任務微調或為 SQuAD 提供額外的數據。\n這些結果說明了這些以前被忽視的設計決策的重要性，並表明 BERT 的預訓練目標與最近提出的替代方案相比仍然具有競爭力。\n","date":"2023-03-22T01:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/roberta-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"RoBERTa 論文閱讀"},{"content":"開發環境 IDE SW4STM32 支援 STM32 GCC C/C++ compiler GDB-based debugger 板子 STM32 Bucleo Board Cortex-M4 ST-LINK debugger Memories 1MB Flash 128KB SRAM Debug Interface JTAG Joint Test Action Group standard ASICs hardware debug interface SWD Serial Wire Debug 只從 JTAG 用 5 wires Bootup Code Reset\nBoot Loader\n0x00000000 的程式 把 CPU 重置 Reset handler\nStstem initialization C startup code\nApplication(main)\nMemory map 見官網 memory map\n只用到 SRAM 的 128KB(SRAM)，還有 Code 的 1MB(Flash)\nSections .data 儲存資料 .text 儲存程式碼 同 section 會放在一塊是為了設定 read-only 方便，比如 .text 的要靠硬體實現 read-only\n重要的額外文件 Linker Script 定義了不同 section 該存放的地方，以及 memory 相關定義 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 MEMORY { RAM (xrw)\t: ORIGIN = 0x20000000, LENGTH = 96K ROM (rx)\t: ORIGIN = 0x8000000, LENGTH = 1024K } SECTIONS { /* The program code and other data into ROM memory */ .text : { . = ALIGN(8); *(.text) /* .text sections (code) */ *(.text*) /* .text* sections (code) */ *(.glue_7) /* glue arm to thumb code */ *(.glue_7t) /* glue thumb to arm code */ *(.eh_frame) KEEP (*(.init)) KEEP (*(.fini)) . = ALIGN(8); _etext = .; /* define a global symbols at end of code */ } \u0026gt;ROM .data : { . = ALIGN(8); _sdata = .; /* create a global symbol at data start */ *(.data) /* .data sections */ *(.data*) /* .data* sections */ . = ALIGN(8); _edata = .; /* define a global symbol at data end */ } \u0026gt;RAM AT\u0026gt; ROM } Make File 描述如何編譯和連接的規則 把 startup 的 .s檔加進去 startup_stm32.s 編譯好後擺在 binary 頭的地方\nvector table\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 /****************************************************************************** * * The STM32L476RGTx vector table. Note that the proper constructs * must be placed on this to ensure that it ends up at physical address * 0x0000.0000. * ******************************************************************************/ .section .isr_vector,\u0026#34;a\u0026#34;,%progbits .type g_pfnVectors, %object .size g_pfnVectors, .-g_pfnVectors g_pfnVectors: .word _estack .word Reset_Handler .word NMI_Handler .word HardFault_Handler .word\tMemManage_Handler .word\tBusFault_Handler .word\tUsageFault_Handler .word\t0 .word\t0 .word\t0 .word\t0 .word\tSVC_Handler Reset_Handler 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 Reset_Handler: ldr r0, =_estack mov sp, r0 /* set stack pointer */ /* Copy the data segment initializers from flash to SRAM */ ldr r0, =_sdata ldr r1, =_edata ldr r2, =_sidata movs r3, #0 b LoopCopyDataInit LoopCopyDataInit: adds r4, r0, r3 cmp r4, r1 bcc CopyDataInit /* Zero fill the bss segment. */ ldr r2, =_sbss ldr r4, =_ebss movs r3, #0 b LoopFillZerobss LoopFillZerobss: cmp r2, r4 bcc FillZerobss /* Call the clock system intitialization function.*/ bl SystemInit /* Call static constructors */ bl __libc_init_array /* Call the application\u0026#39;s entry point.*/ bl main ARM Register ARM 的可存取暫存器為 R0-R15\nr13: Stack Pointer r14: Link Register r15: Program Counter r0~r7 是 low register r8~r15 是 high register 狀態暫存器\nCPSR (Current Processor Status Register) 用來儲存各種狀態，包含 condition flag，比如 negative, zero, carry, overflow carry: 無符號加法操作是否溢出 overflow: 有符號加法操作是否溢出 當兩個都為 1 或都為 0 代表運算沒問題 有多種模式，有些模式有自己獨立的 r 暫存器，並有 SPSR，用來在中斷發生時，把 CPSR 的資訊 copy 過去\nSpecial-purpose registers\nAPSR, IPSR, EPSR Assembly syntax UAL: Unified Assembler Language 自己去翻 instruction set Instructions class Branch instructions B, BL, BX,\u0026hellip; Data-processing instructions MOV, ADD, SUB, MUL,\u0026hellip; Load and store instructions LDR, STR,\u0026hellip; Status register access instructions MSR, MRS,\u0026hellip; Miscellaneous instructions Memory Barrier instructions Exception-Related instructions Pseudo instructions examples MOVS R0, #0x12\nR0=0x12 MOVS R1, #`A` R1=A(ASCII) NVIC_IRQ_SETEN EQU 0xE000E100\n宣告常數 NVIC_IRQ_SETEN，賦值 0xE000E100 LDR R0,=NVIC_IRQ_SETEN\n放 0xE000E100 進 R0 這不能改成 MOVS R0, #0xE000E100 ，因為每個 instruction 只有 32 個 bits，這勢必塞不下，必須從記憶體 load 進來 NVIC_IRQ0_ENABLE EQU 0x1\n宣告常數 NVIC_IRQ0_ENABLE，賦值 0x1 MOVS R1, #NVIC_IRQ0_ENABLE\nR1=0x1 STR R1, [R0]\n把 0x1 存到 0xE000E100，這裡可以 enable external interrupt IRQ#0 LDR rn [pc, #offset to literal pool]\nload register n with one word from the address [pc + offset] 最後的形式 Operand2 共有 12 bits 設計成 4 bits for rotate, 8 bits for Immediate ARM instrcution formats ADD vs ADDS 有 S 代表會去更新 status cond 根據之前的執行情況，判斷指令要不要執行 suffix Reverse Ordering Operations REV (Byte-Reverse Word) 把 4 個 Byte 全數反轉，用在一個是 Little-Endian 一個是 Big-Endian 的情況 Load and Store Instructions examples LDR r0, [r1] r0 = [r1] LDM r0, {r1, r2} r1 = [r0] r2 = [r0+4] STM r0, {r1, r2} [r0] = r1 [r0+4] = r2 Status Register Access Instructions 一般來說不太會用到，因為用 suffix 就可以看條件 MRS: Register = Status Register MRS r0, IPSR MSR: Status Register = Register MSR APSR, r0 If-Then-Else 用 CMP 和 conditional branches Example 1 2 CMP R0, #10 ;compare r0 to 10 BLE incr_counter ; if less or equal, then branch to incr_counter Branch Instructinos 能跳的距離受限於 operand 長度\nB-Branch 能跳 PC 的 +/- 2046 bytes BL-Branch and Link 能跳 PC 的 +/- 254 bytes Branch to subroutine 的時候，會把下一行指令放到 Link register 沒有 push 到 stack，所以要特別小心，register 是共用的， 可能要視情況自己放到 stack 比如要進兩層 function，可以用 push {r4-r6, LR} 和 POP {R4-R6, PC} 這種做法來保留參數 BX-Branch and exchange return Stack memory access PUSH\nSP = SP - N*4 POP\nSP = SP + N*4 Ascending/Descending\nstack 往哪個方向長 Empty/Full\nstack 指向下一個空的位置，還是最後一個 item 預設且常見的是 fully descending\nSTM 和 LDM 可以透過 suffix 來存到 stack\nexample STMFD r13!, {r4-r7} 把 r4 到 r7 push 到 stack Memory Barrier Instructions DMB, SDB, ISB 在下個指令前 sync memory data Function Call and Parameter Passing caller 和 callee 誰負責 backup 和 restore caller 負責 不管 callee 怎樣亂搞都行 但不知道 callee 要用哪些參數，全 backup 可能多此一舉 怎麼傳遞參數給 callee 常放在 stack，但這樣要透過 memory，相較 register 慢 怎麼 return value 給 caller 和上個問題差不多 ARM Procedure Call Standard 又稱 APCS，講不同的 register 的一種使用規範\nr0-r3 用來當參數和回傳 r4-r11 用來 local variable，callee 使用前可以先 backup r12-r15 特殊用途，沒事別亂動 ","date":"2023-03-21T01:32:54+08:00","permalink":"https://roykesydon.github.io/Blog/p/arm-%E7%B5%84%E5%90%88%E8%AA%9E%E8%A8%80%E4%BB%8B%E7%B4%B9/","title":"ARM 組合語言介紹"},{"content":"paper: PatentSBERTa: A Deep NLP based Hybrid Model for Patent Distance and Classification using Augmented SBERT\nAbstract 本研究提供了一個計算 patent-to-patent (p2p) technological similarity 的有效方法。\n並提出一個 hybrid framework，用於把 p2p 相似性的結果應用於 semantic search 和 automated patent classification。\n把 Sentence-BERT (SBERT) 用在 claims 上來作 embeddings。\n為了進一步提升 embedding 的品質，使用基於 SBERT 和 RoBERT 的 transformer model，然後再用 augmented approach 在 in-domain supervised patent claims data(相對於 out-domain) 來 fine-tune SBERT。\n用 KNN(Nearest Neighbors) 來根據 p2p similarity 分類模型。\nIntroduction 傳統上的 p2p 相似度是基於關鍵字、技術類別等 metadata 決定的，但近期 semantic-based 的方法也越來越受歡迎。\n目前遇到的問題 BERT 用來計算 p2p 相似性的成本很高 基於 generic text 的 pre-trained model 在遇到特定領域的專業術語時可能會遇到侷限。 在專利做 multi-label classification (MLC) 是個挑戰 貢獻 提供一個快速高效的框架，利用 Transformer 架構計算 p2p 相似度 透過 augmented SBERT，將 transformer model fine-tune 到 domain-specific language 提出一個基於 Transformer 和 傳統 ML 模型的混和架構，可以打敗 multi-label 和 multi-class 的專利分類 SOTA 模型 用簡單的 KNN 進行專利分類，提供了一種簡單的方法來檢查、理解和解釋模型的預測結果 Data Dataset Description 本研究使用 PatentsView dataset，PatentsView 平台建立在一個定期更新的 database 上。\ndataset 已用於之前類似的研究，比如 DeepPatent、PatentBERT。\n本研究使用了 2013-2017 的所有專利，這些專利至少要在 BigQuery 上有一條 claim。\n本研究的 record 有 1,492,294 項專利，並用 8% 作為測試集。\n此外，本研究刪除了有重複專利 ID 和 claim text 的 record。\nTextual Data: Patent Claims 本研究使用 claim 作為輸入。\nclaim 被認為是準備專利文件的初始框架，其他文件都是根據 claim 準備的， 因此，claim 比其他文件包含更全面和準確的訊息。\nclaim 具有層次結構，first claim 被視為該架構的主幹。\n本研究僅使用 first claim，但在以後的研究中，希望根據 tree structure 組合所有 claim，並計算 semantic similarity，並做多標籤分類。\n在研究樣本中， claim 平均有 17 個。\nclaim 的平均長度是 162，本研究中，BERT 的 max_seq_length 是 510。\nPatent Classification: CPC Classes CPC系統和IPC（國際專利分類）系統是最常用的兩種分類系統，CPC 是 IPC 系統的更具體和詳細的版本。\nCPC 具有用於分類的層次結構，包括 Section、Class、Subclass 和 Group， 在子類級別，CPC 有 667 個標籤。\n在數據集中我們有 663 個標籤，其中 159 個在數據集中的樣本少於 350 個，這種標籤分佈導致了 KNN 不好處理，一般來說，隨著 instance 數量的增加，我們可以提高模型的準確性。\nMethod and experimental setup Pretrained Language Models (LMs) 在 NLP 中變得十分流行。\n在 pairwise sentence semantic similarity，SBERT 和 BERT 是兩種具有顯著不同效果的方法。\nBERT 通常可以取得更好的性能，但在實際應用上來說太慢了。\nSBERT 在實際應用上表現還行，但需要 in-domain training data 並且 finetune。\n上圖是 Augmented SBERT In-domain approach。\nin-domain sentence pairs 透過 cross-encoder 來標記，假設有 n 個 in-domain sentences，會有 $C_2^n$ 組可能的組合。\n使用所有可能的組合並不會提高性能，所以要有正確的採樣策略，才可提升性能的同時也減少計算開銷。\n上圖那種結合 cross-encoder 和 bi-encoder 的作法被稱為 Augmented SBERT (AugSBERT)， 涉及以下三個步驟:\n用資料集 Fine-tune RoBERTa 以生出 cross-encoder 用 cross-encoder 來把未標記的資料標記，同時基於某種特定的採樣策略，從 652,653 種可能的組合中挑選 3432 組 把資料集 + 額外的 3432 組資料一起拿來訓練 SBERT Results P2P similarity and semantic search Patent Semantic Search (PSS) 是專利分析的基礎部分。\nTransformer 模型等語義相似性的解法是一種新解法，可以用來解決基於關鍵字的搜尋方法中， query terms 和專利內容不匹配的問題。\n為了評估模型的準確性，未來的研究中，作者希望通過 Mean Reciprocal Rank (MRR) 來評估分類結果。\nCPC Prediction Top-N 準確度等於 GT 與預測有最高概率的任何 N 個預測匹配的頻率， 所以 Top-5 就是最高的五個分類中一個就有中。\nConclusion 本文使用 augmented SBERT 獲得 SOTA 的專利文本 embedding。\n介紹了一種 augmented 的方法，把 SBERT 微調到適合 patent claims 的 domain。\nSBERT 的一個主要優點是可以有效率地獲得 embedding distance，使我們能夠為大的專利資料集建構 p2p similarity。\n雖然基於文本的 p2p similarity 的有用性已經在各種應用方面得到證明，但本文進一步證明作者的 transformer-based p2p similarity 可以被用在 SOTA 的專利分類。\n而且使用簡單的 KNN 方法，檢查他們可以使模型決策具備 understandable 和 explainable。\nLimitations \u0026amp; Future Research 未來希望用 Annoy(Approximate Nearest Neighbor Oh Yeah!) 來測試更大樣本的模型並比較結果。\nAnnoy(Approximate Nearest Neighbor Oh Yeah!) 是想尋找近似相似而不是精確相似的句子。\n","date":"2023-03-15T15:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/patentsberta-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"PatentSBERTa 論文閱讀"},{"content":"Introduction 結合 policy-based 和 value-based\nA3C Actor-Critic 最知名的方法 Advantage Actor-Critic 是 A2C Advantage Actor-Critic Review: Policy gradient\n$\\triangledown \\overline{R_{\\theta}}\\approx \\frac{1}{N}\\displaystyle\\sum_{n=1}^{N}\\displaystyle\\sum_{t=1}^{T_n}(\\displaystyle\\sum_{t^{\u0026rsquo;}=t}^{T_n}\\gamma^{t^{\u0026rsquo;}-t}r_{t^{\u0026rsquo;}}^n-b)\\triangledown log p_{\\theta}(a_t^n|s_t^n)$ $G_t^n=\\displaystyle\\sum_{t^{\u0026rsquo;}=t}^{T_n}\\gamma^{t^{\u0026rsquo;}-t}r_{t^{\u0026rsquo;}}^n-b$ G very unstable，因為給同樣的 state 作同樣的 action 不一定會得到同樣的結果，G 是個 random variable 想要改獲得期望值，取代掉 sample 的值(G 的部分)，可以用 Q-Learning\n$E[G_t^n]=Q^{\\pi_\\theta}(s_t^n,a_t^n)$ Q function 這樣定義 所以我們可以把 G 的部分改用 Q 替換掉，就可以把 Actor 和 Critic 結合起來 baseline 的部分也可以用 value function 替換掉 但用 $Q^{\\pi}(s_t^n,a_t^n)-V^{\\pi}(s_t^n)$ 要一次 estimate 兩個 network\n可以把 Q 以 V 來表示，那只需要估測 V $Q^{\\pi}(s_t^n,a_t^n)=E[r_t^n+V^{\\pi}(s_{t+1}^n)]$ 雖然有隨機性(獲得的 reward 和跳到什麼 state 不一定)，但先不管期望值 $Q^{\\pi}(s_t^n,a_t^n)=r_t^n+V^{\\pi}(s_{t+1}^n)$ 現在雖然多個一個 r，有一些 variance，但也比 G 好 $\\triangledown \\overline{R_{\\theta}}\\approx \\frac{1}{N}\\displaystyle\\sum_{n=1}^{N}\\displaystyle\\sum_{t=1}^{T_n}(r_t^n+V^{\\pi}(s_{t+1}^n)-V^{\\pi}(s_t^n))\\triangledown log p_{\\theta}(a_t^n|s_t^n)$\nTips actor $\\pi(s)$ 和 critic $V^{\\pi}(s)$ 的權重可以共享\n前面幾個 layer 可以 share 對 $\\pi$ 的 output 下 constrain，讓他的 entropy 不要太小，達到 exploration 的效果\nAsynchronous Advantage Actor-Critic 一開始有個 global network，開一堆 worker，每次工作前，把 global network 的參數 copy 過去 個別去和環境作互動，更新的梯度施加在 global network 上 Pathwise Derivative Policy Gradient 可以當作是 Q-Learning 解 continuous action 的一種方法 訓練一個 actor，目標是生出的 a 餵給 Q 後，可以讓 Q function 的輸出越大越好 只會調 actor 的參數，會 fix Q 的 就是個 GAN 在每個 episode\n對於每個 time step t ⚠️給 state $s_t$，根據 $\\pi$ 執行 action $a_t$ (epsilon greedy)⚠️ 獲得 reward $r_t$，到達 $s_{t+1}$ 把 {$s_t,a_t,r_t,s_{t+1}$} 存到 buffer 從 buffer sample {$s_t,a_t,r_t,s_{t+1}$}(通常是一個 batch) ⚠️Target $y=r_i+\\hat{Q}(s_{i+1},\\hat{\\pi}(s_{i+1}))$⚠️ Update Q 的參數，好讓 $Q(s_i,a_i)$ 更接近 y(regression) ⚠️Update $\\pi$ 的參數，讓 $Q(s_i,\\pi(s_i))$ 最大化⚠️ 每 C 步 reset $\\hat{Q}=Q$ ⚠️每 C 步 reset $\\hat{\\pi}=\\pi$⚠️ ⚠️ 是和 Q-Learning 不一樣的地方\n","date":"2023-03-14T16:21:23+08:00","permalink":"https://roykesydon.github.io/Blog/p/actor-critic/","title":"Actor-Critic"},{"content":"Normalization 目的 避免 redundent information 更容易 understand、enhance、extend 避免 anomalies 隨著 1NF ~ 5NF，有更多的 safety guarantee\n1NF 違反條件 用 row order 傳達資訊 mixing data types in single column 但 relational database 不會讓你這樣做 存在沒有 primary key 的 table repeating groups 同一個 column 有多個數值，或是在同一個 row 存多個同類型的數值。 ex : player item roy 1 item_1, 4 item_2 star 4 item_4 player item_type1 quantity1 item_type2 quantity2 roy item1 1 item2 4 star item_4 4 2NF 所有的 non-key attribute 都要 depend on 整個 PK 非正式定義，有點細微差異 functional dependency ex: {player_id, item_type} -\u0026gt; {item_Quantity} 3NF transitive dependency {A} -\u0026gt; {B} -\u0026gt; {C} 所有 non-key attribute 都要 depend on the whole key，不能 depend on 其他 non-key attribute Boyce-Codd Normal Form 所有 attribute 都要 depend on the whole key，不能 depend on 其他 non-key attribute 4NF multivalued dependency 不像 functional dependency，箭頭後方的那項可以有多個 value {Model} $\\twoheadrightarrow$ {Color} 一個 table 中的所有 multivalued dependency 必須依賴於 key 5NF 沒有 Join Dependency table 不能表示成其他 table join 起來的結果 ","date":"2023-03-14T10:26:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/database-normalization/","title":"Database Normalization"},{"content":"paper: Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks\nAbstract BERT 和 RoBERTa 在 semantic textual similarity (STS) 上太花時間，因為他需要將兩個句子都輸入網路，並且兩兩比對。\nSentence-BERT(SBERT) 對預訓練的 BERT 作了一些修改，透過 siamese 和 triplet network 的結構來生出有意義的 embeddings，使其最後可以透過 cosine-similarity 比較相似度。\nIntroduction SBERT 使 BERT 可以用於某些迄今為止不適用於 BERT 的任務，比如 large-scale semantic similarity comparison、clustering 還有 information retrieval via semantic search。\n以往的相關研究是把單個句子輸入 BERT，最後 average BERT output layer，或是使用第一個 output，但這樣會產生糟糕的 sentence embeddings。\nSentEval 是一個 evaluation toolkit for sentence embeddings\nRelated Work BERT 透過輸入兩個句子，以 [SEP] 隔開，可以在 STS 取得 SOTA。\n但這樣無法計算獨立的 sentence embedding，所以過往的研究人員把單個句子輸入 BERT，最後 average BERT output layer，或是使用第一個 output。\nModel SBERT 在 BERT / RoBERTa 的輸出中添加了 pooling，作者嘗試了三種策略，CLS-token 的輸出、所以輸出向量的平均、max-over-time of the output vectors，默認是 MEAN。\n實驗以下結構和目標函數:\nClassification Objective Function\nRegression Objective Function\n用 mean squared-error loss\nTriplet Objective Function\nTraining Details Dataset SNLI 結合 Multi-Genre NLI SNLI: 570,000 個 句子 pair，有三類，contradiction, eintailment, and neutral MultiNLI: 430,000 個句子 pair 3-way softmax Classification Objective Function 1-epoch batch-size: 16 Adam lr: 2e-5 warm-up: 超過 10% of the training data 默認 pooling 策略: MEAN Evaluation 學習一個複雜的回歸函數分析 STS 常是 SOTA，但是由於他是 pair-wise，遇到 combinatorial explosion，不好拓展。\n本文用 cosine-similarity 比較兩個 embeddings 的相似度，也用 negative Manhatten 和 negative Euclidean distances，但得到差不多的結果。\nConclusion 用 BERT 生出的 embeddings 不適合常見的相似度測量方法，比如 cosine-similarity。\n本文提出 SBERT 改進，在 siamese / triplet 網路架構中微調 BERT。\n用 RoBERTa 替換掉 BERT 並沒有什麼顯著改進。\n","date":"2023-03-12T10:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/sentence-bert-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"Sentence-BERT 論文閱讀"},{"content":"UML 類別圖 Relationship Dependency \u0026ldquo;uses-a\u0026rdquo; Association \u0026ldquo;knows-a\u0026rdquo; Composition \u0026ldquo;has-a\u0026rdquo; child 的存在依賴於 parent，若刪除 parent，child 也會隨之刪除 Aggregation \u0026ldquo;has-a\u0026rdquo; child 的存在獨立於 parent，若刪除 parent，child 不會隨之刪除 Inheritance \u0026ldquo;is-a\u0026rdquo; Implementation \u0026ldquo;can-do\u0026rdquo; 實現 interface other features Navigation 當兩個 class 都可以看到對方，就用沒箭頭的關聯線，否則有箭頭 Role Name 類別中的 Attribute Multiplicity 關聯端點上可以寫數量，代表物件個數 Self-Association 同個類別的物件彼此有關係 軟體設計原則 Encapsulate What Varies 把經常改變的程式碼封裝起來，使日後修改時不會影響其他區塊的程式碼 實際使用的情境，可以把常改變的東西放在 interface 後，使日後改變實作時不影響呼叫該 interface 的程式碼 Favor Composition over Inheritance Composition(組合)在很多情境可以取代掉 Inheritance(繼承)，甚至實現 Polymorphism(多型) 只有當 is-a 的情境出現，才用繼承比較好 Composition 使用起來更有彈性 SOLID 設計原則 Single Responsibility Principle, SRP 單一職責原則 A class should have only one reason to change. 可以把一個複雜的 module 拆成多個 Open-Close Principle, OCP 開放封閉原則 You should be able to extend the behavior of a system without having to modify that system. 要可以擴充，同時不修改到原系統 LiskovSubstitution Principle, LSP 里氏替換原則 父類別有的功能，子類別必須遵從，父類別的部分要可以直接替換成子類別 Interface Segregation Principle, ISP 介面隔離原則 No client should be forced to depend on methods it does not use 以 interface 來說，不該讓 module 實現它不需要的功能，可以把 interface 拆小 Dependency Inversion Principle, DIP 反向依賴原則 高階模組不應該依賴低階模組，兩者都應依賴抽象層 ","date":"2023-03-08T14:26:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E8%BB%9F%E9%AB%94%E8%A8%AD%E8%A8%88%E5%8E%9F%E5%89%87/","title":"軟體設計原則"},{"content":"paper: PatentBERT: Patent Classification with Fine-Tuning a pre-trained BERT Model\nAbstract 把 fine-tune BERT 應用在專利分類上，當應用於超過 200 萬件專利的資料集時，該方法超越了結合 word-embedding 的 CNN 的 SOTA 作法。\n貢獻: 一個用預訓練的 BERT 去 fine-tune 的 SOTA 方法 一個叫做 USPTO-3M 的大型資料集，屬於 CPC subclass level，並提供 SQL 語句讓後續的研究者使用 與傳統觀念相反，只需要 claim 就足以完成分類任務 Introduction 專利分類是一個 multi-label 的分類任務。\n由於標籤的數量可能很大，所以是個具有挑戰性的任務。\n作者準備了一個基於 CPC 的新資料集，有超過三百萬項美國專利。\nCPC Cooperative Patent Classification 是 IPC 更具體和詳細的版本 可預見將取代 IPC 成為新的標準 只是由於 CLEP-IP 競賽，大部分論文都基於 IPC 資料集包含 1978 到 2009 提交的專利 IPC International Patent Classification 此外，作者的 dataset 基於 patent claims\npatent claims 重要性在過往被低估 在起草專利申請時，專利業者會先起草 patent claims 專利文件的其餘部分由 claim 做延伸 在專利法中，claims 定義了專利發明的界線，確定了專利權範圍 為使模型更簡單，只關注 patent claims，並且僅用第一項 claim。\n相關工作 過往有些研究只顯示了 precision，但沒有 F1 value 或 recall，難以公平比較。\n以 DeepPatent\nData 過往資料基於 CLEF-IP 或 patent offices。\n作者發現在 BigQuery 用 Google Patents Public Datasets 更容易。\n而且可用 SQL statements，作者認為比共享傳統資料集更好，原因如下:\nSeperation of concerns 如果資料包含前處理或後處理，其他研究人員需要不同操作時會很頭痛。 Clarity and flexibility SQL statement 精確且容易根據不同條件進行修改。 在和 DeepPatent 比較的時候，可以的話，會用 USPTO2M 進行測試，如果不行，才會合併來自 USPTO-3M 的資料，比如 USPTO-2M 沒有 claims 的情況。\n為了比較 claim 如何影響性能，將合併兩個資料集。\nMethod \u0026amp; Experimental Setup 用 BERT-Base 就可以打敗 DeepPatent。\n遵循 BERT Project 中給的 fine-tune 範例。\n為了 multilabel，用 sigmoid cross entropy with logits function 而不是用 softmax。\nConclusion 專利分類作為具有挑戰性的任務，幾十年來一直沒有令人滿意的表現。\n本文提出一個基於 fine-tune BERT 的方法，性能優於 DeepPatent。\n並且結果表明只用 patent claim 就可以完成分類任務。\n","date":"2023-03-02T16:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/patentbert-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"PatentBERT 論文閱讀"},{"content":"linear equation $a_1x_1+a_2x_2+\u0026hellip;+a_nx_n = b$ $a$ 是 coefficient $x$ 是 variables $b$ 是 constant term Systems of linear equations m equations, n variables\n$a_{11}x_1+a_{12}x_2+\u0026hellip;+a_{1n}x_n = b_1\\\\ a_{21}x_1+a_{22}x_2+\u0026hellip;+a_{2n}x_n = b_2\\\\ \u0026hellip;\\\\ a_{m1}x_1+a_{m2}x_2+\u0026hellip;+a_{mn}x_n = b_m$\nsolution\n$[s_1~s_2~\u0026hellip;~s_n]^T$ 是一組解，代換到 $x_1$~$x_n$ 後滿足所有 equation 的向量 所有 Systems of linear equations 都有\nno solution exactly one solution infinitely many solutions consistent/inconsistent\n如果有一組以上的解就是 consistent 無解就是 inconsistent equivalent\n如果兩組 Systems of linear equations 的 solution set 一樣，稱為 equivalent elementary row operations\n不會影響 solution set types Interchange 兩 row 互換 Scaling 某 row 乘某個 nonzero scalar Row addition 把某 row 乘某個 scalar 後加到某 row property 所有 elementary row operations 都是 reversible 用來求解 coefficient matrix\n$a_{11}x_1+a_{12}x_2+\u0026hellip;+a_{1n}x_n = b_1\\\\ a_{21}x_1+a_{22}x_2+\u0026hellip;+a_{2n}x_n = b_2\\\\ \u0026hellip;\\\\ a_{m1}x_1+a_{m2}x_2+\u0026hellip;+a_{mn}x_n = b_m$ 可以拆為 $Ax=b$\n$A=\\begin{bmatrix} a_{11}\u0026amp; a_{12}\u0026amp;\u0026hellip;\u0026amp; a_{1n} \\\\ a_{21}\u0026amp; a_{22}\u0026amp;\u0026hellip;\u0026amp; a_{2n} \\\\ \u0026hellip;\u0026amp; \u0026hellip;\u0026amp;\u0026hellip;\u0026amp; \u0026hellip; \\\\ a_{m1}\u0026amp; a_{m2}\u0026amp;\u0026hellip;\u0026amp; a_{mn} \\end{bmatrix}$\nA 就是 coefficient matrix $x=\\begin{bmatrix} x_1\\\\ x_2\\\\ \u0026hellip;\\\\ x_n \\end{bmatrix}$\n$x$ 是 variable vector $[A|b]=\\begin{bmatrix} a_{11}\u0026amp; a_{12}\u0026amp;\u0026hellip;\u0026amp; a_{1n} \u0026amp; b_1 \\\\ a_{21}\u0026amp; a_{22}\u0026amp;\u0026hellip;\u0026amp; a_{2n} \u0026amp; b_2\\\\ \u0026hellip;\u0026amp; \u0026hellip;\u0026amp;\u0026hellip;\u0026amp; \u0026hellip; \u0026amp; \u0026hellip;\\\\ a_{m1}\u0026amp; a_{m2}\u0026amp;\u0026hellip;\u0026amp; a_{mn} \u0026amp; b_m \\end{bmatrix}$\n叫做 augmented matrix ","date":"2023-02-21T15:42:47+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E7%B7%9A%E6%80%A7%E4%BB%A3%E6%95%B8-ii/","title":"線性代數 - II"},{"content":"matrix a rectangular array of scalars\nsize\nm by n 叫做 square if m = n equal\n兩個矩陣的 size 和每個 entry 都一樣 submatrix\n從一個大矩陣刪掉 rows 或 columns addition\n兩個大小相同的矩陣，每個對應位置的 entry 兩兩相加 scalar multiplication\n一個矩陣的所有 entry 乘以某個 scalar zero matrix\n所有 entry 都是 0，該矩陣常以 $O_{n \\times m}$ 來表示 性質 $A = O + A$ $0 \\cdot A = O $ subtraction\n$A-B=A+(-B)$ transpose\n$A^T$ 的 $(i,j)$-entry 是 $A$ 的 $(j,i)$-entry Properties $(A+B)^T=A^T+B^T$ $(sA)^T=sA^T$ $(A^T)^T=A$ vectors type\nrow vector 只有 1 row 的 matrix column vector 只有 1 column 的 matrix components\nthe entries of a vector 用 the $i$ th component 代表 $v_i$ addition, scalar multiplication\n和 matrix 一樣 矩陣表示\n一個矩陣常被表示為 a stack of row vectors a cross list of column vectors linear combination $c_1u_1+c_2u_2+\u0026hellip;+c_ku_k$\nscalars\n$c_1,c_2,\u0026hellip;,c_k$ 又被稱作 linear combination 的 coefficients vectors\n$u_1,u_2,\u0026hellip;,u_k$ 如果 $u,v$ 非平行二維向量，則二維空間中所有向量皆是 $u,v$ 的 linear combination，且是 unique 的\nstandard vectors $e_1 = \\begin{bmatrix} 1 \\\\ 0 \\\\ \u0026hellip; \\\\ 0 \\end{bmatrix} ,e_2 = \\begin{bmatrix} 0 \\\\ 1 \\\\ \u0026hellip; \\\\ 0 \\end{bmatrix},\u0026hellip;, e_n = \\begin{bmatrix} 0 \\\\ 0 \\\\ \u0026hellip; \\\\ 1 \\end{bmatrix}$\n$R^n$ 的任何一個向量都可以被 standard vectors 表示成 uniquely linearly combined\n矩陣向量乘法 $Av=v_1a_1+v_2a_2+\u0026hellip;+v_na_n$ Identity Matrix 對整數 n，$n \\times n$ identity matrix $I_n$ 每個 columns 是 standard vectors $e_1, e_2, \u0026hellip;, e_n$ in $R^n$ Stochastic Matrix 對整數 n，$n \\times n$ stochastic matrix 所有 entry 都必須非負 每個 column 的 entry 總和必須是 unity (相加為 1) ","date":"2023-02-21T14:42:47+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E7%B7%9A%E6%80%A7%E4%BB%A3%E6%95%B8-i/","title":"線性代數 - I"},{"content":"Process Scheduling 可能時機\nrunning -\u0026gt; waiting running -\u0026gt; ready waiting -\u0026gt; ready running -\u0026gt; terminate Process Scheduler\nPreemptive scheduler (Time slice) 可以被搶占 Non-Preemptive scheduler 又稱 cooperative scheduling 只可能出現在時機 1 或 4 Classification fo Processes(related to scheduling)\nInteractive Processes (50 - 150 ms) Batch Processes Real time Processes Hard Soft Classification of Processes(related to CPU usage)\nCPU Bound I/O Bound Standard Scheduling Algorithm FCFS SJF SRTF Priority Based Highest Response Ratio Next Round Robin Virtual RR Multi-Level Queue Scheduler Multi-Level Feed Back Queue Scheduler Rotating Staircase Deadline Scheduler UNIX SVR3 Scheduler 有 32 個 runqueue，每個 runqueue 負責 4 個 priority values\n128 Priority values\n0-49: Kernel 50-127: User $Priority_j=Base_j+CPU_j(i)+nice_j$\nBase: 0-127 $CPU_j(i) = DR * CPU_j(i-1)$ DR = $\\frac{1}{2}$ nice: -20 ~ +19 可以用 nice 和 renice 改 process nice value Schedtool Query \u0026amp; set per process scheduling parameters\nScheduling Policy Real time SCHED_RR SCHED_FIFO Conventional SCHED_NORMAL (default) SCHED_BATCH (CPU intensive) SCHED_ISO (unused) SCHED_IDLEPRIO (low pri jobs) Nice Value (-20 to +19) Static Priority (1-99) CPU affinity process 想運行在某個指定的 CPU 上，不被轉移到其他 CPU，才不會降低指定 CPU 的 cache 命中率 soft CPU affinity hard CPU affinity cpus_allowed 一個用來指定 CPU 的 mask 1 schedtool \u0026lt;PID\u0026gt; ","date":"2023-02-20T21:12:52+08:00","permalink":"https://roykesydon.github.io/Blog/p/process-scheduling/","title":"Process Scheduling"},{"content":"RL 方法 Policy-based learn 做事的 actor Value-based 不直接 learn policy，而是 Learn critic，負責批評 Q-learning 屬於這種 Critic 不直接決定 action 給予 actor $\\pi$，評估 actor $\\pi$ 有多好 critic 的 output 依賴於 actor 的表現 State Value Function State value function $V^{\\pi}(s)$ 用 actor $\\pi$，看到 s 後玩到結束，cumulated reward expectation 是多少 評估方法 Monte-Carlo(MC) based approach\ncritic 看 $\\pi$ 玩遊戲 訓練一個 network，看到不同的 state ，輸出 cumulated reward(直到遊戲結束，以下稱為 $G_a$)，解 regression 問題 Temporal-difference(TD) approach\nMC 的方法至少要玩到遊戲結束才可以 update network，但有些遊戲超長 TD 只需要 {$s_t,a_t,r_t,s_{t+1}$} $V^{\\pi}(s_t)=V^{\\pi}(s_{t+1})+r_t$ MS v.s. TD\nMC Larger variance 每次的輸出差異很大 TD smaller variance 相較 $G_a$ 較小，因為這邊的 random variable 是 r，但 $G_a$ 是由很多 r 組合而成 V 可能估得不準確 那 learn 出來的結果自然也不准 較常見 Another Critic State-action value function $Q^\\pi(s,a)$\n又叫 Q function 當用 actor $\\pi$ 時，在 state s 採取 a 這個 action 後的 cumulated reward expectation 有一個要注意的地方是，actor 看到 s 不一定會採取 a 只要有 Q function，就可以找到\u0026quot;更好的\u0026quot; policy，再替換掉原本的 policy \u0026ldquo;更好的\u0026quot;定義 $V^{\\pi^{\u0026rsquo;}} \\ge V^{\\pi}(s), \\text{for all state s}$ $\\pi^{\u0026rsquo;}(s)=arg \\underset{a}{max}Q^{\\pi}(s,a)$ $\\pi^{\u0026rsquo;}$ 沒有多餘的參數，就單純靠 Q function 推出來 這邊如果 a 是 continuous 的會有問題，等等解決 這樣就可以達到\u0026quot;更好的\u0026quot;policy，不過就不列證明了 Basic Tip Target network 在 training 的時候，把其中一個 Q 固定住，不然要學的 target 是不固定的，會不好 train Exploration policy 完全 depend on Q function 如果 action 總是固定，這不是好的 data collection 方法，要在 s 採取 a 過，才比較好估計 Q(s, a)，如果 Q function 是 table 就根本不可能估出來，network 也會有一樣的問題，只是沒那麼嚴重。 解法 Epsilon Greedy $a=\\begin{cases} arg \\underset{a}{max}Q(s,a), \u0026amp; \\text{with probability } 1-\\varepsilon \\\\ random, \u0026amp; otherwise \\end{cases}$ 通常 $\\varepsilon$ 會隨時間遞減，因為你一開始 train 的時候不知道怎麼比較好 Boltzmann Exploration $P(a|s)=\\frac{exp(Q(s,a))}{\\sum_a exp(Q(s,a))}$ Replay Buffer 把一堆的 {$s_t,a_t,r_t,s_{t+1}$} 存放在一個 buffer {$s_t,a_t,r_t,s_{t+1}$} 簡稱為 exp 裡面的 exp 可能來自於不同的 policy 在 buffer 裝滿的時候才把舊的資料丟掉 每次從 buffer 隨機挑一個 batch 出來，update Q function 好處 跟環境作互動很花時間，這樣可以減少跟環境作互動的次數 本來就希望 batch 裡的 data 越 diverse 越好，不會希望 batch 裡的 data 都是同性質的 issue 我們要觀察 $\\pi$ 的 value，混雜了一些不是 $\\pi$ 的 exp 到底有沒有關係? 理論上沒問題，但李老師沒解釋 Typical Q-learning 演算法 初始化 Q-fucntion Q，target Q-function $\\hat{Q}=Q$ 在每個 episode 對於每個 time step t 給 state $s_t$，根據 Q 執行 action $a_t$ (epsilon greedy) 獲得 reward $r_t$，到達 $s_{t+1}$ 把 {$s_t,a_t,r_t,s_{t+1}$} 存到 buffer 從 buffer sample {$s_t,a_t,r_t,s_{t+1}$}(通常是一個 batch) Target $y=r_i+\\underset{a}{max}\\hat{Q}(s_{i+1},a)$ Update Q 的參數，好讓 $Q(s_i,a_i)$ 更接近 y(regression) 每 C 步 reset $\\hat{Q}=Q$ Adveanced Tip Double DQN Q Value 往往被高估 我們的目的是要讓 $Q(s_t, a_t)$ 和 $r_t+\\underset{a}{max}Q(s_{t+1},a)$ 越接近越好(後者就是 target) target 常常不小心設太高，因為如果有 action 被高估了，就會選那個當 target Double DQN: 兩個函式 $Q$ 和 $Q^{\u0026rsquo;}$ 把 target 換成 $r_t+Q^{\u0026rsquo;}(s_{t+1},arg \\underset{a}{max}Q(s_{t+1},a))$ 選 action 交給 $Q$，實際算交給 $Q^{\u0026rsquo;}$ 如果 $Q$ 選了高估的 action，$Q^{\u0026rsquo;}$ 有可能修正回來 如果 $Q^{\u0026rsquo;}$ 高估，$Q$ 不一定會選到 $Q^{\u0026rsquo;}$ 是 target network(固定不動) Dueling DQN 改變 network 架構 分成兩條 path 第一條算 scalar 第二條算 vector，每個 action 都有個 value 把 scalar 加到每一個維度 只更改到 V(s) 的時候，會全部的 action 都改到，可能會是一個比較有效率的方式，不用 sample 所有的 action 但有可能模型不管 V(s)，直接設 0，只改 A 所以會對 A 下 constrain，讓 network 傾向於改 V 比如同個 state 下的所有 action 要生出 A(s,a) 總和為 0 在 A 的輸出加個 normalization 即可辦到，這個 normalization 就是把每個維度都減掉平均 Prioritized Replay 原本是 uniform 的從 buffer sample data 改讓 「有更大的 TD error」的 data 有更高的機率被 sample TD error 就是 $Q(s_t, a_t)$ 和 target 的差距 實際在做的時候有額外的細節，不會只改 sampling 的 process，還要改 update 參數的方法 Multi-step Balance between MC 和 TD TD 只需要存 {$s_t,a_t,r_t,s_{t+1}$} 改存 {$s_t,a_t,r_t,\u0026hellip;,s_{t+N},a_{t+N},r_{t+N}, s_{t+N+1}$} 我們的目的是要讓 $Q(s_t, a_t)$ 和 $\\displaystyle\\sum_{t^{\u0026rsquo;}=t}^{t+N} r_{t^{\u0026rsquo;}}+\\hat{Q}(s_{t+N+1},a_{t+N+1})$ 越接近越好(後者就是 target) $a_{t+N+1}=arg\\underset{a}{max}\\hat{Q}(s_{t+N+1},a)$ 同時有 MC 和 TD 的好處和壞處 估測的影響比較輕微 r 比較多項，variance 比較大 Noisy Net improve exploration Noise on Action Epsilon Greedy(之前的回顧) $f_X(x) = \\begin{cases} arg \\underset{a}{max}Q(s,a), \u0026amp; \\text{with probability }1-\\varepsilon \\\\ random, \u0026amp; ,otherwise \\end{cases}$ 給同樣的 state，採取的 action 不一定一樣 沒有真實的 policy 會這樣運作 Noise on Parameters $a = arg \\underset{a}{max}\\tilde{Q}(s,a)$\n在每個 episode 剛開始的時候，在 Q-function 的參數上面加上 gaussian noise 給同樣的 state，採取同樣的 action\n叫做 state-dependent exploration explore in a consistent way\nDistributional Q-function Q-function 生出的東西是 cumulated reward 的期望值 所以我們是在對 distribution 取 mean，但不同的 distribution 也可能有同樣的 mean 想做的事情是 model distribution 如果有做這個，就比較不會有 over estimate reward 的結果，反而容易 under estimate，使 double 比較沒用 output 的 range 不可能無限寬，超過邊界的 reward 會被丟掉 Rainbow 綜合一堆方法 Continuous actions Q learning 不容易處理 continuous action Solution sample n 個可能的 a，都丟 Q function 看誰最大\ngradient descent\n把 a 當作 parameter，要找一組 a 去 maximize Q function 運算量大，要 iterative 的 update a 不一定可以找到 global 的最佳解 特別設計 Q network，讓解 optimization 的問題變容易\n範例 Q network 輸出 $\\mu(s)$、$\\Sigma(s)$、$V(s)$，個別是 vector、matrix、scalar a 是 continuous 的 Action，是一個 vector，每個維度都是實數 $\\Sigma(s)$ 是 positive definite 的，實作的時候會把 $\\Sigma$ 和它的 transpose 相乘 $Q(s,a)=-(a-\\mu(s))^T\\Sigma(s)(a-\\mu(s))+V(s)$ $(a-\\mu(s))^T\\Sigma(s)(a-\\mu(s))$ 這項必為正，所以 $a=\\mu(s)$ 的時候就是最佳解 不要用 Q-learning\n","date":"2023-02-20T16:21:23+08:00","permalink":"https://roykesydon.github.io/Blog/p/q-learning/","title":"Q-learning"},{"content":"On/Off-policy On-policy 學習的 agent 和與環境互動的 agent 是同一個 Off-policy 學習的 agent 和與環境互動的 agent 是不同個 想從 On-policy 轉 Off-policy On-policy 每次都要重新蒐集資料，很花時間 由另一個 $\\pi_{\\theta^{\u0026rsquo;}}$ 去 train $\\theta$，$\\theta^{\u0026rsquo;}$是固定的，所以我們可以 re-use sample data Importance Sampling 是一個 general 的想法，不限於 RL\n$E_{x \\text{\\textasciitilde} p}[f(x)]\\approx \\frac{1}{N}\\displaystyle\\sum_{i=1}^N f(x^i)$\n$x^i$ is sampled from p(x) 我們遇到的問題是沒辦法從 p 來 sample data，只能透過 q(x) 去 sample $x^i$\n可以把上式改寫成 $E_{x \\text{\\textasciitilde} p}[f(x)]=E_{x \\text{\\textasciitilde} q}[f(x)\\frac{p(x)}{q(x)}]$\nIssue 雖然理論上 q 可以任意選，只要不要 q(x) 是 0 的時候 p(x) 不是 0，實作上 p 和 q 不能差太多，不然會有問題\n這兩項的 Variance 不一樣，如果 p 除以 q 差距很大，右邊的 Variance 會很大，如果 sample 不夠多次就會有問題 轉換 原本\n$\\triangledown \\overline{R_{\\theta}}=E_{\\tau \\text{\\textasciitilde}p_{\\theta}(\\tau)}[R(\\tau)\\triangledown log p_{\\theta} (\\tau)]$ 改為\n$\\triangledown \\overline{R_{\\theta}}=E_{\\tau \\text{\\textasciitilde}p_{\\theta^{\u0026rsquo;}}(\\tau)}[\\frac{p_{\\theta}(\\tau)}{p_{\\theta^{\u0026rsquo;}}(\\tau)}R(\\tau)\\triangledown log p_{\\theta} (\\tau)]$ 從 $\\theta^{\u0026rsquo;}$ sample 資料 更新 $\\theta$ 多次 Advantage function 原本\n$E_{(s_t,a_t)\\text{\\textasciitilde}\\pi_{\\theta}}[A^{\\theta}(s_t,a_t)\\triangledown log p_\\theta(a_t^n|s_t^n)]$ 改為\n$E_{(s_t,a_t)\\text{\\textasciitilde}\\pi_{\\theta^{\u0026rsquo;}}}[\\frac{P_\\theta(s_t,a_t)}{P_{\\theta^{\u0026rsquo;}}(s_t,a_t)}A^{\\theta^{\u0026rsquo;}}(s_t,a_t)\\triangledown log p_\\theta(a_t^n|s_t^n)]$ 要注意 Advantage 的結果要由 $\\theta^{\u0026rsquo;}$ 得出，是 $\\theta^{\u0026rsquo;}$在和環境互動 新的 objective function\n$J^{\\theta^{\u0026rsquo;}}(\\theta)=E_{(s_t,a_t)\\text{\\textasciitilde}\\pi_{\\theta^{\u0026rsquo;}}}[\\frac{p_\\theta(a_t|s_t)}{p_{\\theta^{\u0026rsquo;}}(a_t|s_t)}A^{\\theta^{\u0026rsquo;}}(s_t,a_t)]$ PPO 確保 $\\theta$ 和 $\\theta^{\u0026rsquo;}$ 不會差太多 $J_{PPO}^{\\theta^{\u0026rsquo;}}(\\theta)=J^{\\theta^{\u0026rsquo;}}(\\theta)-\\beta KL(\\theta, \\theta^{\u0026rsquo;})$ 前身 TRPO Trust Region Policy Optimization $J_{TRPO}^{\\theta^{\u0026rsquo;}}(\\theta)=E_{(s_t,a_t)\\text{\\textasciitilde}\\pi_{\\theta^{\u0026rsquo;}}}[\\frac{p_\\theta(a_t|s_t)}{p_{\\theta^{\u0026rsquo;}}(a_t|s_t)}A^{\\theta^{\u0026rsquo;}}(s_t,a_t)], KL(\\theta, \\theta^{\u0026rsquo;})\u0026lt;\\delta$ constrain 很難處理 KL divergence 這邊不是 $\\theta$ 和 $\\theta^{\u0026rsquo;}$ 參數上的距離，而是 behavior 的距離 參數上的距離是指這兩個參數有多像 是給同樣的 state 生出 action 的 distribution 要像 algorithm 初始參數 $\\theta^0$ 每個 iteration 用 $\\theta^k$ 和環境互動，蒐集{$s_t,a_t$}，並計算 advantage $A^{\\theta^k}(s_t,a_t)$\n找出 theta 最佳化 $J_{PPO}(\\theta)$\n$J_{PPO}^{\\theta^{k}}(\\theta)=J^{\\theta^{k}}(\\theta)-\\beta KL(\\theta, \\theta^{k})$ 可以更新很多次 動態調整 $\\beta$\nAdaptive KL Penalty 設可接受的 KL 數值範圍 if $KL(\\theta,\\theta^k)\u0026gt;KL_{max},\\text{increase} \\beta$ if $KL(\\theta,\\theta^k)\u0026lt;KL_{min},\\text{decrease} \\beta$ PPO2 PPO\n$J_{PPO}^{\\theta^{k}}(\\theta)=J^{\\theta^{k}}(\\theta)-\\beta KL(\\theta, \\theta^{k})$ PPO2\n$J_{PPO2}^{\\theta^{k}}(\\theta)\\approx \\displaystyle\\sum_{(s_t,a_t)}min(\\frac{p_{\\theta}(a_t|s_t)}{p_{\\theta^k}(a_t|s_t)}A^{\\theta^k}(s_t,a_t), \\\\ clip(\\frac{p_{\\theta}(a_t|s_t)}{p_{\\theta^k}(a_t|s_t)}, 1-\\varepsilon, 1+\\varepsilon)A^{\\theta^k}(s_t,a_t))$ ","date":"2023-02-20T12:35:56+08:00","permalink":"https://roykesydon.github.io/Blog/p/proximal-policy-optimizationppo/","title":"Proximal Policy Optimization(PPO)"},{"content":"Basic Components Actor Policy $\\pi$ is a network with parameter $\\theta$ Env Reward Function Trajectory 在一場遊戲，把 env 輸出的 s 和 actor 輸出的 a 串起來，是一個 Trajectory Trajectory $\\tau$ = {$s_1,a_1,s_2,a_2,\u0026hellip;,s_T,a_T$} $p_{\\theta}(\\tau)=p(s_1)\\displaystyle\\prod_{t=1}^Tp_{\\theta}(a_t|s_t)p(s_{t+1}|s_t,a_t)$ Update $\\theta \\leftarrow \\theta + \\eta \\triangledown \\overline{R}_{\\theta}$\n$\\triangledown \\overline{R_{\\theta}} = \\displaystyle\\sum_{\\tau} R(\\tau) \\triangledown p_{\\theta} (\\tau) \\\\ =\\frac{1}{N}\\displaystyle\\sum_{n=1}^{N}\\displaystyle\\sum_{t=1}^{T_n}R(\\tau^n)\\triangledown log p_{\\theta} (a_t^n|s_t^n)$\n實作 常見公式 $\\triangledown f(x)=f(x)\\triangledown logf(x)$ 用當前模型蒐集一堆 Trajectory 更新模型 回到第一步 細節 做一個分類問題，把 state 當作分類器的 Input，把 action 當作分類器的 ground truth 作訓練 在實作分類問題的時候，objective function 都會寫成 minimize cross entropy，就是 maximize log likelihood RL 和一般分類的區別是，要記得在 loss 前面乘上 $R(\\tau^n)$ Tip Add a Baseline $R(\\tau^n)$ 有可能永遠都為正 此時等於告訴 Model 說，今天不管是什麼 action，都要提高它的機率。不一定會有問題，因為雖然都是正的，但正的量有大有小，可能某些 action 上升的幅度會更大。因為我們是在做 sampling，不一定會 sample 到某些 action，本來想的情況是所有的 trajectory 都會出現才沒問題。 解法: 希望 reward 不要總是正的 $\\triangledown \\overline{R_{\\theta}}\\approx \\frac{1}{N}\\displaystyle\\sum_{n=1}^{N}\\displaystyle\\sum_{t=1}^{T_n}(R(\\tau^n)-b)\\triangledown log p_{\\theta}(a_t^n|s_t^n)$ $b \\approx E[R(\\tau)]$ Assign Suitable Credit 原本整場遊戲的所有 action 都會乘上 $R(\\tau)$，但這不太公平，因為就算結果是好的，不代表所有 action 都是對的，反之亦然。在理想的情況下，如果 sample 夠多，就可以解決這問題。 解法 只計算從這個 action 後的 reward 總和 因為前面的 reward 和你做了什麼沒關係 接續解法 1，把比較未來的 reward 做 discount 乘某個小於 1 的 $\\gamma^{t^{\u0026rsquo;}-t}$ Advantage function base 可以是 state-dependent，可以根據 network 得出，以後再說 $(Reward-b)$ 可以合起來看做 Advantage function $A^{\\theta}(s_t,a_t)$ 這邊 Reward 不管你是什麼形式，有沒有 discount。 它的意義是，這個 action 相較於其他的 action 有多好，而不是絕對好 這個 A 通常可以由某個類神經網路估計，那個類神經網路叫做 critic，以後講 Actor-Critic 的時候再說 ","date":"2023-02-19T17:16:14+08:00","permalink":"https://roykesydon.github.io/Blog/p/policy-gradient/","title":"Policy Gradient"},{"content":"paper: Masked Autoencoders Are Scalable Vision Learners\nAbstract 這篇論文顯示出 MAE 是 CV 中的 scalable self-supervised learners。\nMAE 的方法很簡單\n隨機蓋住輸入影像的一些 patch 重建 missing pixels 具備兩個核心設計\n非對稱的 encoder-decoder 架構，encoder 只作用於可見的 patch 子集合(沒有 mask tokens)，lightweight decoder 則根據 latent representation 和 make tokens 來重建圖片。 當遮住高比例(比如 75%)的影像時，會得到一個 nontrivial 和 meaningful 的 self-supervisory task 結合這兩點設計，可以有效地訓練大模型。 以 ViT-Huge 用 ImageNet-1K 訓練(訓練集一百多萬張照片)可達到 87.8% 的準確度。\nIntroduction 在 CV 中，常需要大量 labeled images。 NLP 中，自監督預訓練處理了需要大量標註資料的問題。 masked autoencoders 是一種更 general 的 denoising autoencoders 的形式。 BERT 非常成功，autoencoding methods 在 CV 的研究卻落後 NLP，作者思考是什麼讓 masked autoencoding 在 CV 和 NLP 產生不同。 有以下觀點\n直到前陣子，CV 中的 CNN 是主流，但卷積層不好引入 mask tokens 或 positional embedding 這些 indicator。但這些可以透過 ViT 來解決，不應成為問題。 語言和視覺的 Information density 不同，語言是 highly semantic 和 information-dense，使填字本身不是很簡單的事情，但影像含有大量冗餘的訊息，缺失的部分比較好從相鄰的 patch 重建，比如直接插值，所以作者用一種簡單的策略，隨機 mask 很大一部分的 patch，創造一個具有挑戰性的自監督任務，強迫模型關注 global 的資訊。 關於 decoder，CV 還原 pixel，pixel 屬於 lower semantic level，NLP 還原 word，word 的 semantic information 較高。作者發現，雖然在 BERT 中，可以用簡單的 decoder 還原(一個 MLP)，但 CV 中 decoder 的設計就很重要。 基於以上觀點，作者提出 MAE，隨機遮住大量的 patch，並在 pixel space 重建失去的 patch。而且是非對稱 encoder-decoder 架構，encoder 只會看到可見的 patch，但 docoder 除了 latent representation，還會看到 mask tokens。這種設計在非常高的掩蓋率(比如 75%)下不但可以提高準確度，還可以讓 encoder 只處理較少比例(比如 25%)的 patch，將訓練時間減少 3 倍或更多，使 MAE 可以輕鬆擴展成更大的模型。\n在這樣的架構下，用 MAE 的 pre-training，可以訓練非常吃 data 的模型，比如 ViT-Large/-Huge，而只使用 ImageNet-1K。\n用 ImageNet-1K 在 vanilla ViT-Huge 上 fine-tune 可達到 87.8% 準確度，比以往只使用 ImageNet-1K 的結果都高。\n在 obejct detection、instance segmentation、semantic segmentation 上做 transfer learning 都達到不錯的效果，可以打敗用監督式預訓練模型的對手。\n相關工作 Autoencoding MAE 是一種 denoising autoencoding 的形式，但和 DAE 還是差別很大。 Masked image encoding iGPT、ViT、BEiT Approach Masking\n和 ViT 一樣，把圖片切成多個 patch，對於 patch 均勻隨機地採樣保留，剩下地遮住 MAE encoder\nViT 也有 positional embedding MAE decoder\nTransformer block 輸入 encoded visible patches mask tokens shared, learned vector 都會加入 positional embedding 用相較 encoder 輕量的解碼器，所有的 patch 由這個輕量的 decoder 處理，減少預訓練時間 Reconstruction target\ndecoder 的最後一層是 linear projection，之後再 reshape 成你要的 patch loss function mean squared error(MSE) 只算 masked patched 的 MSE，像 BERT Simple implementation\n先取得一系列 token(patch 做 linear projection + positional embedding) randomly shuffle，根據比例移除尾端一部份 encoding 後，尾端接上 mask tokens，並且 unshuffle 加上 positional embedding 後，給 decoder ImageNet Experiments 在 ImageNet-1K 上做自監督的預訓練，然後做\nend-to-end fine-tuning 所有參數都可改 linear probing 只改最後一層線性層 optimal masking ratio 意外地高，相比 BERT 只有 15%\n討論和結論 在 CV 實用的預訓練做法主流是監督式的，CV 中自監督的做法可能正跟著 NLP 的軌跡走。\n要仔細處理圖像和語言的區別，作者去除圖片中很可能不構成 semantic segment 的部分，而不是移除某個 object。\n","date":"2023-02-15T16:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/mae-%E8%AB%96%E6%96%87/","title":"MAE 論文"},{"content":"paper: An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale\nAbstract 在 CV 領域 transformer 表現有限，目前 attention 常常是和卷積神經網路一起用，或是用來把一些卷積層換成 self-attention，但整體架構不變。這篇論文想展現一個純 Transformer 可以直接在影像分類上表現很好。如果用大量資料作預訓練，再遷移到中小型的資料集，可以和 SOTA 的 CNN 表現得一樣好，還需要較少的訓練資源作訓練。\nIntroduction self-attention-based 架構，特別是 Transformer，已經是 NLP 的重要選擇。主流的作法是在大型文字資料集上作訓練，再針對小型任務資料集作 fine-tune。由於 Transformer 的計算效率高，還有可擴展性，可以 train 一些很大的 model，隨著 model 和資料集增大，目前還沒看出飽和的現象。\n然而在 CV，CNN 還是主流，一些工作嘗試用 self-attention 結合 CNN-like 的架構，比如把 feature map 當 transformer 的輸入，因為原始 pixel 太多，或甚至把卷積層全換成 self-attention，雖然後者理論上效率很高(原論文中有另外 cite 兩篇作法)，但因為他們做法特殊，在現代硬體上很難加速，所以無法很有效地擴展。在 large-scale 的影像識別上， ResNet-like 的架構還是 SOTA。\n該實驗直接把一個標準的 Transformer 作用於圖片上，只作最少的修改。把影像分成多個 patch，並把它們變成一系列的 linear embedding，當作 NLP 中的 tokens(words) 來處理。\n當在中型大小的資料集(e.g. ImageNet)上訓練，如果沒有 strong regularization，ViT 會略輸同等大小的 ResNets\n這篇論文在更大的資料集(14M-300M 的影像)上訓練，就打敗了 inductive bias。在大量資料上作預訓練就很讚。\nRelated Work 大型的 Transformer-based 模型常常是先在大資料集上預訓練然後根據任務 fine-tune，比如 BERT 和 GPT。\n要把 self-attention 用在 CV 上，最簡單的做法就是把每個 Pixel 當一個元素，但 self-attention 是平方複雜度，在現實的圖片很難應用。一個應用 Transformer 的做法是只把 self-attention 用在 local neighborhood，另外一個是用 Sparse Transformer，還有一堆特殊的方法，雖然表現不錯，但要用硬體加速起來不容易。\n另一個有關的模型是 iGPT，在 reduce image resolution 和 color space 後把 transformer 應用在 image pixels 上。它用非監督式訓練後，再 fine-tune 或做 linear probing(只更新最後的 linear layer) 分類任務，表現很好。\n已經有類似的工作了，抽取 patches of size 2 * 2，最後再接 full self-attention，基本上和 ViT 非常像，這篇論文進一步證明了作大規模的預訓練可以讓 Transformer 和 SOTA 的 CNN 相比，而且 ViT 因為 patch 比較大，可以處理 medium-resolution 的圖片。這問題是可預期的，因為 Transformer 缺少了一些 inductive biases。\ninductive biases 一些假設 比如 CNN 常有四個假設 locality translation invariance with pooling layers 平移不變性 translation equivariance f(g(x)) = g(f(x)) 卷積和平移的先後順序沒差 Method 模型盡可能類似原始 Transformer，這樣可以把一些 NLP 上成功的 Transformer 架構拿來用，還可以用一些很有效率的 implementation\nembedding 維度是 768 = 16 * 16 * 3 position embedding 的做法是 standard learnable 1D positional embeddings，就是 BERT 的做法，簡單來說就是生出一張可以訓練的表，(序列長度, embedding size)，作者也有嘗試其他方法，但發現成效差不多，比如 2D positional embedding，概念就是從生出(序列長度, embedding size)變成生出 2 個(sqrt(序列長度), embedding size)。\n[class] 的概念是 NLP 出來的，ResNet-like 的架構常見的做法也有通過 globally average-pooling (GAP)來生出向量，再接上分類器做預測。實驗發現直接在 transformer 的輸出做 GAP 和 [class] 都可以達到不錯的效果。\nConclusion 拿標準的 Transformer 來作 Image recognition，和以往用 self-attention 在 CV 的方法不一樣，除了一開始的 initial patch extraction，沒有引入其他影像特有的 inductive biases。直接把圖片當成是一系列的 patch，然後直接用 Transformer encoder 當一般 NLP 任務處理。在很多影像分類訓練集上表現得更好還在 pre-train 上相對便宜。\n還有一些值得挑戰的地方，比如把 ViT 應用在其他 CV 任務，比如 detection 和 segmentation。另一個挑戰是探索自監督預訓練的方法。這篇論文其實有實驗自監督，表現 OK，但和監督式還是有很大的落差。擴大 ViT 可能有更好的結果。\n","date":"2023-02-12T00:27:55+08:00","permalink":"https://roykesydon.github.io/Blog/p/vit-%E8%AB%96%E6%96%87/","title":"ViT 論文"},{"content":"隨機變數之和 Z=X+Y\n$p_Z(z)=\\displaystyle\\sum_{x=-\\infty}^{\\infty}p_{X,Y}(x,z-x)\\\\ =\\displaystyle\\sum_{y=-\\infty}^{\\infty}p_{X,Y}(z-y,y)$\n$f_Z(z)=\\int_{-\\infty}^{\\infty}f_{X,Y}(x,z-x)dx\\\\ =\\int_{-\\infty}^{\\infty}f_{X,Y}(z-y,y)dy$\n如果 X, Y 獨立\n離散\n$p_Z(z)=\\displaystyle\\sum_{x=-\\infty}^{\\infty}p_{X}(x)\\cdot p_Y(z-x)\\\\ =\\displaystyle\\sum_{y=-\\infty}^{\\infty}p_{X}(z-y)\\cdot p_Y(y)$ 這兩個等式是 discrete convolution $=p_X(z) * p_Y(z)$ 連續\n$f_Z(z)=\\int_{-\\infty}^{\\infty}f_{X}(x) f_Y(z-x) dx\\\\ =\\int_{-\\infty}^{\\infty}f_{X}(z-y) f_Y(y) dy$ 這兩個等式是 continuous convolution $=f_X(z) * f_Y(z)$ 如果有 n 個獨立隨機變數\n$X=X_1+X_2+\u0026hellip;+X_n$ 如果 $X_1,\u0026hellip;,X_n$ 獨立 $p_X(x)=p_{X_1}(x) * p_{X_2}(x) * p_{X_3}(x) * \u0026hellip; * p_{X_n}(x)$ 連續做 convolution $f_X(x)=f_{X_1}(x) * f_{X_2}(x) * f_{X_3}(x) * \u0026hellip; * f_{X_n}(x)$ 連續做 convolution MGF moment generating function\nconvolution 很難算\n流程\n如果有多個連續 convolution 也適用下面流程，全部一次一起相乘 給定 $p_{X_1}(x), p_{X_2}(x)$，目標是求 $p_{X_1}(x) * p{X_2}(x)$\n轉換到 MGF\n$\\phi_{X_1}(s)=E \\lbrack e^{sX_1} \\rbrack\\\\ = \\displaystyle\\sum_{x=-\\infty}^{\\infty}e^{sx}\\cdot p_{X_1}(x)$\n$\\phi_{X_2}(s)=E \\lbrack e^{sX_2} \\rbrack$\n相乘 $\\phi_{X_1}(s) \\cdot \\phi_{X_2}(s)$\n逆轉換\n查表 $\\phi_X(s)$ 定義\n$\\phi_X(s)=E \\lbrack e^{sX} \\rbrack = \\begin{cases} \\displaystyle\\sum_{x=-\\infty}^{\\infty} e^{sx} \\cdot p_{X}(x) \u0026amp; 離散, \\\\ \\int_{-\\infty}^{\\infty} e^{sx} \\cdot f_{X}(x)dx \u0026amp; 連續 \\end{cases}$ 性質\nY = aX + b $\\phi_Y(s) = e^{sb} \\cdot \\phi_X(as) $ 常見離散機率分佈的 MGF\n$X$~$Bernoulli(p)$ $\\phi_X(s)=1-p+pe^s$ $X$~$BIN(n, p)$ 作 n 次實驗成功次數等於個實驗室成功次數的總和 $X = X_1 + X_2 + \u0026hellip; + X_n, X_i 獨立, Xi$~$Bernoulli(p)$ $\\phi_{X_i}(s)=1-p+pe^s$ $\\phi_{X}(s)=\\lbrack 1-p+pe^s \\rbrack ^n$ $X$~$Geometric(p)$ 自行推導 $X$~$Pascal(k,p)$ 看到第 k 次成功，花的總實驗室次數等於第 1 號成功花多少次 + 第 2 號 +\u0026hellip;+ 第 k 號 $X = X_1 + X_2 + \u0026hellip; + X_n, X_i 獨立, Xi$~$Gemetric(p)$ $X$~$Exponential(\\lambda)$ 自行推導 $X$~$Erlang(n,\\lambda)$ $X = X_1 + X_2 + \u0026hellip; + X_n, X_i 獨立, Xi$~$Exponential(\\lambda)$ 多個隨機變數之和 獨立隨機變數之和 $X_1, X_2, \u0026hellip;$獨立，且各自有一模一樣的機率分佈 { $X_i$ } $I.I.D.$\nIndependently and Identically Distributed $X = X_1+X_2+\u0026hellip;+X_n$，n 為常數，請問 X 的機率分佈\n$p_X(x)=p_{X_1}(x) * p_{X_1}(x) * p_{X_1}(x) * \u0026hellip; * p_{X_1}(x)$ $f_X(x)=f_{X_1}(x) * f_{X_1}(x) * f_{X_1}(x) * \u0026hellip; * f_{X_1}(x)$ 因為他們機率分佈一模一樣，所以底下都是 $X_1$ $\\phi_X(s)=\\lbrack \\phi_{X_1}(s) \\rbrack ^n$ e.g. 假設壽司理想重量是 13g，抓飯量是常態分佈，期望值是 14，標準差是 3，每天要作 100 個，每天飯量的機率分佈是?\n$X_i$ : 第 i 個壽司的飯量，{ $X_i$ } I.I.D. $X_i$~$N(14,9)\\\\ \\Rightarrow \\phi_{X_i}(s)=\\phi_{X_1}(s)\\\\ =e^{\\mu S + \\frac{\\sigma^2}{2}s^2} = e^{14 s + \\frac{9}{2}s^2}$ $X=X_1+X_2+\u0026hellip;+X_{100}$ $\\phi_X(s)=\\lbrack \\phi_{X_1}(s) \\rbrack^{100}\\\\ =e^{1400 s + \\frac{900}{2}s^2}$ 這個東西是 $X$~$N(1400,900)$ 的 MGF，所以可以逆推回來機率分佈 隨機變數之獨立隨機變數和 $X_1,X_2,\u0026hellip;I.I.D.$\n$X = X_1 + X_2 + \u0026hellip; + X_N$\nN 本身也是隨機變數，其機率分佈已知\n$\\phi_X(s)=\\phi_N(ln(\\phi_{X_1}(s)))$\n中央極限定理 central limit theorem(CLT)\n若 $X_1,X_2,\u0026hellip;,X_n$ 為 $I.I.D.$，當 n 趨近於無窮大時\n$X=X_1+X_2+\u0026hellip;+X_n$~$N(\\mu_{X_1+X_2\u0026hellip;+X_n}, \\sigma^2_{X_1+X_2+\u0026hellip;+X_n})$ $\\mu_{X_1+X_2+\u0026hellip;+X_n}=\\mu_{X_1}+\\mu_{X_2}+\u0026hellip;+\\mu_{X_n}=n\\mu_{X_1}$ $\\sigma^2_{X_1+X_2+\u0026hellip;+X_n}=\\sigma^2_{X_1}+\\sigma^2_{X_2}+\u0026hellip;+\\sigma^2_{X_n}=n\\sigma^2_{X_1}$ 應用\n要處理多個獨立的隨機變數的和時，可以用 CLT 將其機率分佈近似為常態分佈後計算機率 比如雜訊常當作常態分佈 如果某機率分佈等於多個獨立隨機變數的和，此機率分佈可以用常態分佈近似，再算機率 e.g. $X$~$BIN(100,0.3)$ $X=X_1+X_2+\u0026hellip;+X_100$ {$X_i$} $I.I.D., X_i$~$Bernoulli(0.3)$ 範例\n天團粉絲有 0.2 的機率買 CD，共有100萬個粉絲，發售 CD 超過 200800 張的機率為何 $X$~$BIN(1000000,0.2)$ $P(X\u0026gt;200800)=\\displaystyle\\sum_{x=200801}^{10^6}(\\overset{1000000}{x})0.2^x0.8^{10^6-x}$ $(\\overset{1000000}{x})=\\frac{1000000!}{200801!799199!}$ 算不出來 $X=X_1+X_2+\u0026hellip;+X_{1000000}, X_i$~$Bernoulli(0.2)\\\\ \\Rightarrow \\mu_{X_1}=0.2, \\sigma_{X_1}^2=0.16$ By CLT $\\Rightarrow X$~$N(200000,160000)$ $P(X\u0026gt;200800)\\\\ =P(\\frac{X-200000}{400} \u0026gt; \\frac{200800-200000}{400})\\\\ =P(Z\u0026gt;2) =Q(2) \\approx0.023$ De Moivre - Laplace Formula 如果是離散的隨機變數和，可以算的更精確 $P(k_1 \\le X \\le k_2) \\approx \\Phi(\\frac{k_2+0.5-n\\mu_{X_1}}{\\sqrt{n}\\sigma_{X_1}}) - \\Phi(\\frac{k_1-0.5-n\\mu_{X_1}}{\\sqrt{n}\\sigma_{X_1}})$ ","date":"2023-02-05T15:18:41+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E6%A9%9F%E7%8E%87%E8%AB%96-iv/","title":"機率論 - IV"},{"content":"隨機變數的函數 隨機變數 X 的任意函數 g(x) 也是一個隨機變數，常被稱為 Derived Random Variable 求 g(x) 的機率分佈 X 是離散 直接推 g(X) 的 PMF X 是離散隨機變數，Y = g(X) 也是離散隨機變數 $p_{g(X)}(y) = \\displaystyle\\sum_{會讓g(x)=y 的所有x}p_X(x)$ X 是連續 先推 g(x) 的 CDF，再微分得 PDF\n先算 g(X) 的 CDF $F_{g(X)}(y)=P\\lbrack g(X) \\le y \\rbrack$ 若 g(X) 可以微分，再對 y 微分得 PDF $f_{g(X)}(y)=\\frac{d}{dy}F_{g(X)}(y)$ e.g. 若 Y=3X+2，請問 Y 的 PDF 與 $f_X(x) 的關係?$\n$F_Y(y)=P(Y \\le y)\\\\ =P(3X+2 \\le y)\\\\ =P(X \\le \\frac{y-2}{3})\\\\ =F_X(\\frac{y-2}{3})$ $f_Y(y)=\\frac{d}{dy}F_Y(y)\\\\ =\\frac{d}{dy}F_X(\\frac{y-2}{3})\\\\ =\\frac{dF_X(\\frac{y-2}{3})}{d(\\frac{y-2}{3})} \\cdot \\frac{d \\frac{y-2}{3}}{dy}\\\\ =f_X(\\frac{y-2}{3}) \\cdot \\frac{1}{3}$ 若 Y=aX+b\n$f_Y(y)=\\frac{1}{|a|}f_X(\\frac{y-b}{a})$ 條件機率分佈 若 X 是離散隨機變數，PMF 是 $p_X(x)$，某事件 B 已發生 PMF: $p_{X|B}(x)= x = \\begin{cases} x \\in B: \u0026amp; \\frac{p_X(x)}{p(B)}, \\ x \\notin B: \u0026amp; 0 \\end{cases}$ CDF: $F_{X|B}(x)\\\\ =\\displaystyle\\sum_{u \\le x}p_{X|B}(u)\\\\ =\\displaystyle\\sum_{u \\le x, u \\in B} \\frac{p_X(u)}{P(B)}$ 若 X 是連續隨機變數，某事件 B 已發生 PDF: $f_{X|B}(x)\\\\ =\\begin{cases} x \\in B: \u0026amp; \\frac{f_X(x)}{P(B)}, \\ x \\notin B: \u0026amp; 0 \\end{cases}$ CDF: $F_{X|B}(x)\\\\ =\\int_{-\\infty \\le u \\le x, u \\in B} \\frac{f_X(u)}{P(B)} du$ 條件期望值 Conditional Excpectation $E \\lbrack X|B \\rbrack\\\\ =\\begin{cases} \\displaystyle\\sum_{x=-\\infty}^{\\infty} x \\cdot p_{X|B}(x) \u0026amp; 離散, \\\\ \\int_{-\\infty}^{\\infty} x \\cdot f_{X|B}(x)dx \u0026amp; 連續 \\end{cases}$\n$E \\lbrack g(X)|B \\rbrack\\\\ =\\begin{cases} \\displaystyle\\sum_{x=-\\infty}^{\\infty} g(x) \\cdot p_{X|B}(x) \u0026amp; 離散, \\\\ \\int_{-\\infty}^{\\infty} g(x) \\cdot f_{X|B}(x)dx \u0026amp; 連續 \\end{cases}$\n$Var(X|B) = E\\lbrack X^2 | B \\rbrack - (\\mu_{X|B})^2$\n失憶性 Memoryless Geometric 和 Exponential 機率分佈都有失憶性 不管事情已經進行多久，對於事情之後的進行一點影響都沒有 聯合機率分佈 joint probability distribution 同時考慮多個隨機變數的機率分佈 Joint PMF X, Y 皆為離散，聯合PMF\n$p_{X,Y}(x,y)=P(X=x, Y=y)$ 性質\n$0 \\le p_{X,Y}(x,y) \\le 1$ $\\Sigma^{\\infty}{x=-\\infty}\\Sigma^{\\infty}{y=-\\infty} p_{X,Y}(x,y)=1$ X, Y 獨立 $P_{X,Y}(x,y)\\\\ =P(X=x,Y=y)\\\\ =P_X(x)P_Y(y)$ 對任何事件 B $P(B)=\\Sigma_{(x,y)\\in B}P_{X,Y}(x,y)$ Joint CDF $F_{X,Y}(x,y)=P(X \\le x, Y \\le y)$\n性質\n$0 \\le F_{X,Y}(x, y) \\le 1$ 若 $x_1 \\le x_2$ 且 $y_1 \\le y_2$，則 $F_{X,Y}(x_1,y_1) \\le F_{X,Y} (x_2, y_2)$ $F_{X,Y}(x, \\infty) = F_X(x)$ $F_{X,Y}(\\infty, y) = F_Y(y)$ $F_{X,Y}(\\infty, \\infty) = 1$ $F_{X,Y}(x, -\\infty)\\\\ = P(X \\le x, Y \\le -\\infty)\\\\ \\le P(Y \\le -\\infty) \\\\ = 0$ $F_{X,Y}(-\\infty, y) = 0$ $P(x_1 \u0026lt; X \\le x_2, y_1 \u0026lt; Y \\le y_2)\\\\ =F_{X,Y}(x_2,y_2)-F_{X,Y}(x_2,y_1)-F_{X,Y}(x_1,y_2)+F_{X,Y}(x_1,y_1)$ Joint PDF $f_{X,Y}(x,y)= \\frac{\\partial^2F_{X,Y}(x,y)}{\\partial x \\partial y}$\n$F_{X,Y}(x,y) = \\int_{-\\infty}^{x} \\int_{-\\infty}^{y} f_{X,Y}(u,v)dv du$\n性質\n$f_{X,Y}(x,y) \\ge 0$ $\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}f_{X,Y}(x,y)dxdy=1$ 如果 X,Y 獨立 $f_{X,Y}(x,y)=f_X(x) \\cdot f_Y(y)$ 對任何事件 B $P(B)=\\int\\int_{(x,y)\\in B}f_{X,Y}(x,y)dxdy$ 邊際 PMF Marginal PMF 已知聯合 PMF : $p_{X,Y}(x,y)$，求 $p_X(x), p_Y(y)$，稱為邊際 PMF $p_X(x)=\\displaystyle\\sum_{y=-\\infty}^{\\infty}P_{X,Y}(x,y)$ $p_Y(y)=\\displaystyle\\sum_{x=-\\infty}^{\\infty}P_{X,Y}(x,y)$ 已知聯合 PDF : $p_{X,Y}(x,y)$，求 $f_X(x), f_Y(y)$，稱為邊際 PDF $f_X(x)=\\int_{-\\infty}^{\\infty}f_{X,Y}(x,y)dy$ $f_Y(y)=\\int_{-\\infty}^{\\infty}f_{X,Y}(x,y)dx$ 雙變數期望值 聯合 PMF 下的期望值\n$E\\lbrack h(X,Y) \\rbrack = \\displaystyle\\sum_{x=-\\infty}^{\\infty}\\displaystyle\\sum_{y=-\\infty}^{\\infty}h(x,y)\\cdot p_{X,Y}(x,y)$ h(X,Y) 也可以只和 X 有關，比如它可以是 $x^2$ 聯合 PDF 下的期望值\n$E\\lbrack h(X,Y) \\rbrack = \\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}h(x,y)\\cdot f_{X,Y}(x,y) dxdy$ e.g. 已知 $f_{X,Y}(x,y)=\\begin{cases} 0.5, \u0026amp; \\text{if } 0 \\le y \\le x \\le 2, \\\\ 0, \u0026amp; otherwise \\end{cases}$ $E \\lbrack X + Y \\rbrack \\\\ = \\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}(x+y)\\cdot f_{X,Y}(x,y) dxdy\\\\ = \\int_{0}^{2}\\int_{y}^{2}(x+y)\\cdot 0.5 dxdy$ 期望值性質\n$E\\lbrack \\alpha h_1(X,Y)+ \\beta h_2(X,Y) \\rbrack\\\\ =\\alpha E\\lbrack h_1(X,Y)\\rbrack + \\beta E\\lbrack h_2(X,Y) \\rbrack$ 若 X,Y 獨立 $E\\lbrack g(X)h(Y) \\rbrack = E \\lbrack g(X) \\rbrack \\cdot E \\lbrack h(Y) \\rbrack$ Variance 性質\n$Var(X+Y)=Var(X)+Var(Y)+2 \\cdot Cov(X,Y)$ $Cov(X,Y)=E\\lbrack (X-\\mu_X)(Y -\\mu_Y) \\rbrack$ 如果 X, Y 獨立 $2E\\lbrack (X-\\mu_X)(Y -\\mu_Y) \\rbrack \\\\ = 2E\\lbrack (X-\\mu_X) \\rbrack E\\lbrack (Y -\\mu_Y) \\rbrack \\\\ = 0$ ","date":"2023-02-02T15:18:41+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E6%A9%9F%E7%8E%87%E8%AB%96-iii/","title":"機率論 - III"},{"content":"機率密度函數 PDF probability density function PMF 在 連續R.V. 上，假如 $X\\text{\\textasciitilde}[0,1)$，$p_X(0.7)$ = 0，因為有無窮多個數字 公式 $f_X(x)=\\lim\\limits_{\\Delta x \\rightarrow 0} \\frac{P(x \\le X \\le x + \\Delta x)}{\\Delta x} \\\\ = \\lim\\limits_{\\Delta x \\rightarrow 0} \\frac{F_X(x+\\Delta x) - F_X(x)}{\\Delta x} \\\\ = F^{\\prime}_X(x) $ 和 CDF 的關係 $CDF: F_X(x) = PDF: f_X(x)$ $\\int^x_{-\\infty}$ 可以從 PDF 轉到 CDF\n$\\frac{d}{dx} 可以從 CDF 轉到 PDF$\n跟機率的關係 $P(a \u0026lt; X \\le b) = F_X(b) - F_X(a) \\\\ = \\int^b_{-\\infty} f_X(x)dx - \\int^a_{-\\infty} f_X(x)dx \\\\ = \\int^a_b f_X(x)dx$ $f_X(x)=\\lim\\limits_{\\Delta x \\rightarrow 0} \\frac{P(x \\le X \\le x + \\Delta x)}{\\Delta x}$ 當 $\\Delta x$ 很小時 $P(x \\le X \\le x + \\Delta x) \\approx f_X(x) \\cdot \\Delta x$ 性質 $f_X(x) = F^{\\prime}_X(x)$ $F_X(x)=\\int^x_{-\\infty}f_X(u)du$ $P(a \\le X \\le b)=\\int^b_a f_X(x) dx$ $\\int^{\\infty}_{-\\infty}f_X(x)dx=1$ $f_X(x) \\ge 0$ $f_X(x)$ 可以比 1 大 連續機率分佈 Uniform 機率分佈 $X \\text{\\textasciitilde}UNIF(a,b)$ PDF $f_X(x) = \\begin{cases} \\frac{1}{b-a} \u0026amp; ,a \\le x \\le b \\\\ 0 \u0026amp; ,otherwise \\end{cases}$ CDF $F_X(x) = \\begin{cases} 0 \u0026amp; ,x \\le a \\\\ \\frac{x-a}{b-a} \u0026amp; ,a \u0026lt; x \\le b\\\\ 1 \u0026amp; ,x \u0026gt; b \\end{cases}$ Exponential 機率分佈 有失憶性(memoryless)，常被用來 model 有這種性質的事情 $X \\text{\\textasciitilde}Exponential(\\lambda)$ PDF $f_X(x) = \\begin{cases} \\lambda e^{-\\lambda x} \u0026amp; ,x \\ge 0 \\\\ 0 \u0026amp; ,otherwise \\end{cases}$ CDF $F_X(x) = 1-e^{-\\lambda x}$ Erlang 機率分佈 Gamma Distribution $X \\text{\\textasciitilde}Erlang(n,\\lambda)$ PDF $f_X(x) = \\begin{cases} \\frac{1}{(n-1)!}\\lambda^n x^{n-1} e^{-\\lambda x} \u0026amp; ,x \\ge 0 \\\\ 0 \u0026amp; ,otherwise \\end{cases}$ $f_X(x)=(\\lambda e^{-\\lambda x}) * (\\lambda e^{-\\lambda x}) * \u0026hellip; * (\\lambda e^{-\\lambda x})$ 自己和自己做 n 次 convolution CDF $F_X(x) = \\begin{cases} 1 - \\Sigma^{n-1}_{k=0}\\frac{(\\lambda x)^k}{k!}e^{-\\lambda x} \u0026amp; ,x \\ge 0 \\\\ 0 \u0026amp; ,otherwise \\end{cases}$ 常見用法 用來 model 一件有多個關卡事情的總時間，而每個關卡所需時間是隨機的 關卡數: n 每關卡所需時間之機率分佈 $Exponential(\\lambda)$ e.g. 打電動過三關所需時間 $Erlang(3, \\lambda)$ Normal 機率分佈 (常態分佈) 在自然界常出現\n常被用做「很多隨機量的總和」的機率模型\n又稱 Gaussian 機率分佈\n$X \\text{\\textasciitilde}Gaussian(\\mu,\\sigma)$\nPDF\n$f_X(x)=\\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}$ 也常用 $X \\text{\\textasciitilde}N(\\mu,\\sigma^2)$\n注意 $\\sigma$ 不一樣 CDF\n太難算，積不出來\n針對某組特別的 $\\mu, \\sigma$ 的 CDF 建表，把其他常態分佈的 CDF 和這組產生關聯 標準常態分佈\n$Z \\text{\\textasciitilde}N(0,1)$ $f_Z(z)=\\frac{1}{\\sqrt{2 \\pi}}e^{-\\frac{z^2}{2}}$ CDF 表示為 $\\Phi(z)$ $\\Phi(z)=\\int^z_{-\\infty}\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{u^2}{2}}du$\n積不出來，以數值方法近似出來後建表給人家查 查 standard normal table e.g. $F_Z(1.325)=?$\n查表 $F_Z(1.32)=0.9066$，$F_Z(1.33)=0.9082$ 用內插約略得 0.9074 性質\n$\\Phi(-z) = 1 - \\Phi(z)$ 任意 $\\mu, \\sigma$ 的 CDF\n對任何 $X \\text{\\textasciitilde}N(\\mu,\\sigma^2)$ $\\frac{X-\\mu}{\\sigma}\\text{\\textasciitilde}N(0,1)$ $F_X(x)=\\Phi(\\frac{x-\\mu}{\\sigma})$ 期望值 Expectation 大數法則 $P(A)=\\lim\\limits_{N \\rightarrow \\infty}\\frac{N_A}{N}$ 基本上期望值是利用大數法則算的 mean 值，雖然平均值是 R.V.，但當實驗無窮多次時，會收斂到常數，因此以這為估算值 Mean 值又稱做期望值 離散隨機變數 $E\\lbrack X \\rbrack=\\mu_X=\\displaystyle\\sum^{\\infty}_{x=-\\infty}x \\cdot P_X(x)$ 離散隨機變數的函數的期望值 對離散隨機變數 X 而言，其任意函數 g(x) 也是一隨機變數，也有期望值 $g(X)$ 的期望值定義為 $E \\lbrack g(X) \\rbrack=\\displaystyle\\sum^{\\infty}_{x=-\\infty}g(x)\\cdot P_X(x)$ 性質 $E\\lbrack \\alpha g(X) \\rbrack = \\alpha \\cdot E \\lbrack g(X) \\rbrack$ $E\\lbrack \\alpha g(X) + \\beta h(X) \\rbrack \\\\ =\\alpha \\cdot E \\lbrack g(X) \\rbrack + \\beta \\cdot E \\lbrack h(X) \\rbrack$ $E\\lbrack \\alpha \\rbrack = \\alpha$ 常見隨機變數函數的期望值 $X$ 的 $n^{th} moment$ $E \\lbrack X^n \\rbrack = \\displaystyle\\sum^{\\infty}_{x=-\\infty}x^n \\cdot P_X(x)$ X 的變異數(variance) $E \\lbrack (X-\\mu_X)^2 \\rbrack = \\displaystyle\\sum^{\\infty}_{x=-\\infty} (x-\\mu_X)^2 \\cdot P_X(x)$ 變異數 Variance Variance 通常符號表示為 $\\sigma^2_X=E \\lbrack (X-\\mu_X)^2 \\rbrack$ 隱含隨機變數 X 多「亂」的資訊 variance 大的話，X 不見得接近 $\\mu_X$ 變異數開根號是標準差(standard deviation) $\\sigma_X = \\sqrt{Variance} \\ge 0$ 算法 $\\sigma^2_X=E \\lbrack X^2 \\rbrack - \\mu^2_X\\\\ \\Rightarrow E \\lbrack X^2 \\rbrack = \\sigma^2_X + \\mu^2_X$\n常見離散分佈的期望值 / 變異數 $X\\text{\\textasciitilde}Bernouli(p)$\n$\\mu_X=1 \\cdot p + 0 \\cdot (1-p) \\\\ = p$\n$\\sigma^2_X = E \\lbrack X^2 \\rbrack - \\mu^2_X \\\\ = \\displaystyle\\sum^1_{x=0}x^2\\cdot p_X(x)-\\mu_X^2 \\\\ =1^2 \\cdot p + 0^2 \\cdot (1-p) - p^2\\\\ =p(1-p)$\n$X$~$BIN(n,p)$\n$\\mu_X = np$\n$\\sigma^2_X = np(1-p)$\n$X$~$GEO(p)$\n$\\mu_X = \\frac{1}{p}$\n$\\sigma^2_X = \\frac{(1-p)}{p^2}$\n$X$~$PASKAL(k,p)$\n$\\mu_X = \\frac{k}{p}$\n$\\sigma^2_X = \\frac{k(1-p)}{p^2}$\n$X$~$POI(\\alpha)$\n$\\mu_X = \\alpha$\n$\\sigma^2_X = \\alpha$\n$X$~$UNIF(a,b)$\n$\\mu_X = \\frac{a+b}{2}$\n$\\sigma^2_X = \\frac{1}{12}(b-a)(b-a+2)$\n連續隨機變數 對連續的隨機變數 X 而言，將 X 的值以 $\\Delta$ 為單位無條件捨去來近似，以隨機變數 Y 表示(當 $\\Delta \\rightarrow$ 0 時，$X \\approx Y$)，然後再當做 PMF 處理。\n$E \\lbrack X \\rbrack = \\int^{\\infty}_{-\\infty}xf_X(x)dx$ 連續隨機變數的函數的期望值 對連續隨機變數 X 而言，其任意函數 g(x) 也是一隨機變數，也有期望值 $g(X)$ 的期望值定義為 $E \\lbrack g(X) \\rbrack=\\int^{\\infty}_{-\\infty}g(x)\\cdot f_X(x)dx$ 性質 $E\\lbrack \\alpha g(X) \\rbrack = \\alpha \\cdot E \\lbrack g(X) \\rbrack$ $E\\lbrack \\alpha g(X) + \\beta h(X) \\rbrack \\\\ =\\alpha \\cdot E \\lbrack g(X) \\rbrack + \\beta \\cdot E \\lbrack h(X) \\rbrack$ $E\\lbrack \\alpha \\rbrack = \\alpha$ 常見隨機變數函數的期望值 $X$ 的 $n^{th} moment$ $E \\lbrack X^n \\rbrack = \\int^{\\infty}_{-\\infty}x^n \\cdot f_X(x)dx$ X 的變異數(variance) $E \\lbrack (X-\\mu_X)^2 \\rbrack = \\int^{\\infty}_{-\\infty} (x-\\mu_X)^2 \\cdot f_X(x)dx$ 變異數 Variance 和離散隨機變數的資訊一樣 常見連續分佈之期望值/變異數 $X$~$Exponential(\\lambda)$\n$\\mu_X = \\frac{1}{\\lambda}$\n$\\sigma^2_X = \\frac{1}{\\lambda^2}$\n$X$~$Erlang(n, \\lambda)$\n$\\mu_X = \\frac{n}{\\lambda}$\n$\\sigma^2_X = \\frac{n}{\\lambda^2}$\n$X$~$Gaussian(\\mu,\\sigma)$\n$\\mu_X = \\mu$\n$\\sigma^2_X = \\sigma^2$\n$X$~$UNIF(a,b)$\n$\\mu_X = \\frac{a+b}{2}$\n$\\sigma^2_X = \\frac{1}{12}(b-a)^2$\n","date":"2023-02-01T15:18:41+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E6%A9%9F%E7%8E%87%E8%AB%96-ii/","title":"機率論 - II"},{"content":"集合論 名詞 子集合(Subset) B 是 C 的子集(B 不能等於 C) $B \\subset C$ 補集(Complement) C 是 A 的補集 $C=A^C$ 不相交(Disjoint) $X \\cap Y = \\{\\}$ 互斥(Mutually Exclusive) 一群集合 $X_1, X_2, \u0026hellip;, X_n$ 中任選兩個集合 $X_i, X_j$ 都不相交，則 $X_1, X_2, \u0026hellip;, X_n$ 這群集合互斥 公式 De Morgan\u0026rsquo;s Law ${(A \\cup B)}^C=A^C \\cap B^C$ 機率名詞 Outcome (結果) 實驗中可能的結果 Sample Space (樣本空間) 機率實驗所有可能的結果的集合，常以 $S$ 表示 Event (事件) 對於實驗結果的某種敘述 事件可以看做是 outcome 的集合，也是 sample space 的子集 機率是一個函數，其自變數是 event，故可看做是一個映射 公理 Axioms 對任何事件 $A$ 而言, $P(A) \\geq 0$\n$P(S) = 1$\n事件 $A_1, A_2, \u0026hellip;$ 互斥 $\\Rightarrow$ $P(A_1 \\cup A_2 \\cup A_3 \\cup \u0026hellip;)$\n$=P(A_1)+P(A_2)+P(A_3)+\u0026hellip;$\n衍生公式 Boole\u0026rsquo;s 不等式\n對任意 $n$ 個事件 $A_1, A_2, \u0026hellip;, A_n$ 而言 $P(\\cup^n_{i=1}A_i \\leq \\Sigma^n_{i=1}P(A_i))$ Bonferroni\u0026rsquo;s 不等式\n對任意 $n$ 個事件 $A_1, A_2, \u0026hellip;, A_n$ 而言 $P(\\cap^n_{i=1} A_i) \\geq 1 - \\Sigma^n_{i=1} P(A^C_i)$ 條件機率 公式 $P(X|Y) = \\frac{P(X \\cap Y)}{P(Y)}$ $P(X \\cap Y) = P(X|Y) * {P(Y)} = P(Y|X) * P(X)$ 性質 $P(X|Y) \\geq 0$ $P(Y|Y) = 1$ $A, B$ 互斥 $\\Rightarrow P(A \\cup B |Y) = \\frac{P(A)}{P(Y)} + \\frac{P(B)}{P(Y)} = P(A|Y)+P(B|Y)$ 定理 Total Probability 定理 若 $C_1, C_2, \u0026hellip;, C_n$ 互斥且 $C_1 \\cup C_2 \\cup \u0026hellip; \\cup C_n = S$，則對任意事件 $A$ $P(A) = P(A|C_1)P(C_1) + P(A|C_2)P(C_2) + \u0026hellip; + P(A|C_n)P(C_n)$ Bayes\u0026rsquo; Rule 貝式定理 若 $C_1, C_2, \u0026hellip;, C_n$ 互斥且 $C_1 \\cup C_2 \\cup \u0026hellip; \\cup C_n = S$，則對任意事件 $A$ $P(C_j|A)=\\frac{P(A|C_j) * P(C_j)}{\\Sigma^n_{i=1}P(A|C_i)*P(C_i)}$\n$= \\frac{P(C_j \\cap A)}{P(A)}$\n獨立性 Independence 若兩事件 $A, B$ 之機率滿足\n$P(A \\cap B) = P(A) * P(B)$ 或以 $P(A|B) = P(A)$ 表示 則 $A, B$ 兩事件稱為機率上的獨立事件\n若事件 $A_1, A_2, \u0026hellip; A_n$ 滿足下列條件，則稱此 $n$ 事件獨立 $(n\u0026gt;2)$\n從中任選 $m$ 事件 $A_{i_1}, A_{i_2}, \u0026hellip; A_{i_m}$ 均滿足 $P(A_{i_1} \\cap A_{i_2} \\cap \u0026hellip; \\cap A_{i_m}) = P(A_{i_1})P(A_{i_2})\u0026hellip;P(A_{i_m}) , m=2, 3, \u0026hellip;, n$ 排列組合 二項式係數(binomial coefficient) $(^n_k)$ 有 $n$ 個異物，從中取出 $k$ 個 多項式係數(multinomial coefficient) $\\frac{n!}{n_1!n_2!\u0026hellip;n_m!}$ 有 m 種異物，每次選物從中選一後放回，依序選 n 次，共有 $m^n$ 種 outcome，在所有實驗結果中，第一種出現 $n_1$ 次，以此類推，這樣的實驗結果有多少種 隨機變數 Random Variable, R.V. 用來把 outcome 數字化的表示方式 通常用大寫英文字母 是將 outcome 轉成對應數字的函數 $X: S \\rightarrow R$ 從樣本空間映射到實數 隨機變數的函數，也是一個隨機變數 種類 離散隨機變數 (Discrete R.V.)\n值是有限個，或是「可數的」無窮多個 連續隨機變數 (Continuous R.V.)\n值有無窮多個，而且「不可數」 可數、不可數 可數 包含的東西可一個個被數，總有一天會被數到 e.g. 正偶數集合 不可數的 不管怎麼數，裡面一定有個東西會沒數到 e.g. 0~1 之間的所有數字 累積分佈函數 CDF cumulative distribution function\n對任一個隨機變數 $X$，定義 CDF 為\n$F_X(x) \\overset{def}{=}P(X \\leq x)$ 永遠用 $F$ 表示 常見用途\n算 X 落在某範圍的機率 $P(A \u0026lt; X \\le b) = F_X(b)-F_X(a)$ $P(A \\le X \\le b) = F_X(b)-F_X(a)+P(X=a)$ $P(A \u0026lt; X \u0026lt; b) = P(A \u0026lt; X \\le b^-)$ 性質 離散隨機變數的 CDF $F_X(x^+)=F_X(x)$ $F_X(x^-)=F_X(x)-P(X=x)$ 連續隨機變數的 CDF $F_X(x^-)=F_X(x)=F_X(x^+)$ 共同 $F_X(- \\infty)=P(X \\le - \\infty)=0$ $F_X(\\infty)=P(X \\le \\infty) = 1$ $0 \\le F_X(x) \\le 1$ 機率質量函數 PMF probability mass function 對任一個「離散」隨機變數 $X$，其 PMF 為 $p_X(x) \\overset{def}{=}P(X=x)$ PMF 和 CDF 的關係 對任何 $x$ $F_X(x) = \\displaystyle\\sum^{\\lfloor x \\rfloor}_{n=-\\infty}p_X(n)$ $P_X(x)=F_X(x^+)-F_X(x^-)$ 機率分佈(Probability Distribution) PMF 和 PDF 都是一種機率分佈 將總和為 1 的機率分佈在點上 離散機率分佈 Bernoulli 機率分佈 1 次實驗，2 種結果，在意某結果發生與否 $X \\text{\\textasciitilde}Bernoulli(p)$ PMF $p_X(x) = \\begin{cases} p \u0026amp; ,x=1 \\\\ 1-p \u0026amp; x=0 \\\\ 0 \u0026amp; ,otherwise \\end{cases}$ CDF $F_X(x) = \\begin{cases} 0 \u0026amp; ,x\u0026lt;0 \\\\ 1-p \u0026amp; 0 \\leq x \u0026lt;1 \\\\ 1 \u0026amp; ,x \\geq 1 \\end{cases}$ Binomial 機率分佈 實驗成功機率為 p，做 n 次實驗，X 表成功次數 $X \\text{\\textasciitilde}BIN(p)$ PMF $p_X(x) = (^n_x)p^x(1-p)^{n-x}$ 成功 $x$ 次 CDF $F_X(x) = \\displaystyle\\sum^{\\lfloor x \\rfloor}_{m=-\\infty} (^n_m)\\cdot p^m \\cdot (1-p)^{n-m}$ Uniform 機率分佈 1 次實驗，n 種結果，各結果機率均等，在意某結果發生否 $X \\text{\\textasciitilde}UNIF(a,b)$ PMF $p_X(x) = \\begin{cases} \\frac{1}{b-a+1} \u0026amp; ,x=a,a+1,\u0026hellip;,b \\\\ 0 \u0026amp; ,otherwise \\end{cases}$ CDF $F_X(x) = \\begin{cases} 0 \u0026amp; ,x\u0026lt;a \\\\ \\frac{\\lfloor x \\rfloor - a + 1}{b-a+1} \u0026amp; ,a \\leq x\u0026lt; b\\\\ 1 \u0026amp; ,x \\geq b \\end{cases}$ Geometric 機率分佈 若實驗成功機率為 p，到成功為止，做了 X 次嘗試 有失憶性 $X \\text{\\textasciitilde}Geometric(p)$ PMF $p_X(x) = \\begin{cases} (1-p)^{x-1} \\cdot p \u0026amp; ,x=1, 2, 3, \u0026hellip; \\\\ 0 \u0026amp; ,otherwise \\end{cases}$ CDF $F_X(x) = \\begin{cases} 1-(1-p)^{\\lfloor x \\rfloor} \u0026amp; ,x \\ge 1 \\\\ 0 \u0026amp; ,otherwise \\end{cases}$ Pascal 機率分佈 若實驗成功機率為 p，到第 k 次成功為止，共做了 X 次嘗試 $X \\text{\\textasciitilde}Pascal(k, p)$ PMF $p_X(x) = \\begin{cases} \\binom{x-1}{k-1}(1-p)^{x-k} p^k \u0026amp; ,x=k, k+1, \u0026hellip; \\\\ 0 \u0026amp; ,otherwise \\end{cases}$ CDF $F_X(x) = P(X \\le x) \\\\ = P(在 x 次實驗中 \\ge k 次成功)\\\\ = P(Y \\ge k), Y~BIN (x,p) \\\\ $ 故 Pascal 又稱 Negative Binomial Poisson 機率分佈 已知某事發生速率為每單位時間 $\\lambda$ 次，觀察時間為 $T$ 時間單位，$X$ 為該觀察時間內發生該事的總次數。 $X \\text{\\textasciitilde}POI(\\lambda T)$ 有時候也會以 $\\mu$ 來表示 $\\lambda T$ PMF $p_X(x) = e^{-\\lambda T} \\cdot \\frac{(\\lambda T)^x}{x!}$ CDF $F_X(x) = \\begin{cases} \\displaystyle\\sum^{\\lfloor x \\rfloor}_{n=-\\infty}e^{-\\lambda T} \\cdot \\frac{(\\lambda T)^n}{n!} \u0026amp; ,x = 0,1,2,\u0026hellip; \\\\ 0 \u0026amp; ,otherwise \\end{cases}$ ","date":"2023-01-31T15:18:41+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E6%A9%9F%E7%8E%87%E8%AB%96-i/","title":"機率論 - I"},{"content":"Share information between processes 透過硬碟上的文件溝通 超慢 透過 kernel buffer 滿快的，但這樣要一直在 user mode 和 kernel mode 來回切換，因為kernel buffer 在 kernel space 透過 shared memory region shared memory region 在 user space Mechanisms Signals\nCommunication\nData transfer Byte Stream Pipes FIFOs(Named Pipes) stream sockets Message Passing SystemV MsgQ POSIX MsgQ datagram sockets Shared Memory SystemV S.M POSIX S.M Memory Mapping anonymous memory mapping memory mapped file Synchronization\nPipes Related processes parent-child sibling Executing on same machine 用法 cmd1 | cmd2 cmd1 不是輸出到 stdout，而是由 kernel 維護的 buffer，也就是 pipe cmd 不是從 stdin 獲取輸入，而是從 pipe 獲取 cmd1 | cmd2 | \u0026hellip; | cmdn Named Pipes / FIFOs Related / Unrelated processes\nExecuting on same machine\ncreat a FIFO\ncommands mkfifo mknod 嘗試寫入或讀取 FIFO 時，會被 redirect 到 pipe\nSignal Handling Signal Used by OS to notify running process some event has occured without the process needing to pull for that event process 收到 signal 後會先停止執行並執行 signal handler A process did something SIGSEGV(11), SIGFPE(8), SIGILL(4), SIGPIPE(13)\u0026hellip; A process wants to tell another process something SIGCHILD(17) child process terminated User sends sig to foreground processes Ctrl + C SIGINT(2) Ctrl + \\ SIGQUIT(3) Ctrl + Z SIGTSTP(20) disposition 決定 process 遇到 signal 時該怎麼處理\nTerm teminate process Ign ignore Core terminate the process and dump core Stop stop the process Cont continue the process if it is stopped Signal can\u0026rsquo;t not be caught SIGKILL(9) SIGSTOP(19) Commands trap\n可以 handle signal\nkill kill - L 可以看到 standard signal 和 real-time signal\nstandard signal 開頭是 SIG，realt-time signal 是 SIGRT\n","date":"2023-01-28T15:31:50+08:00","permalink":"https://roykesydon.github.io/Blog/p/ipc--inter-process-communication/","title":"IPC -- Inter-Process Communication"},{"content":"paper: Training language models to follow instructions with human feedback\nAbstract 把語言模型變大不代表他們會更好地遵循用戶的意圖。\n大的語言模型有可能會生成 untruthful, toxic, not helpful 的答案。\n該論文透過 fine-tuning with human feedback 來解決這問題。\n一開始準備一系列人工標註的 prompts，然後用這 dataset 對 GPT-3 做 fine-tune。\n接下來再蒐集一個 dataset，存放 rankings of model outputs，由人工判斷輸出好壞，再用 RL 把剛剛 fine-tune 過的 model 繼續 fine-tune。\n最後有 1.3B 參數的 InstructGPT 表現的結果比 175B 參數的 GPT-3 還好。\nIntroduction Large language models(LMs) 可以透過 \u0026ldquo;prompt\u0026rdquo; 來執行各種 NLP 任務。\n但這些模型也常有一些非目的性的行為，諸如捏造事實等等。\n原因是出在目標函數上，多數 LMs 的目標函數是根據網路上的文本生出下一個字詞。\n這和「根據使用者指令生出安全且有幫助的答案不同」。\n上述的差異使語言模型的目標是 misaligned。\n作者的目標是生出 helpful、 honest(沒有誤導性資訊)、harmless 的 model。\n具體作法，使用 reinforcement learning from human feedback(RLHF)。\n訓練步驟 結果 Labelers 明顯偏好 InstructGPT 的答案，勝過 GPT-3 的答案\nInstructGPT 的答案在 truthfulness 勝過 GPT-3 的答案\nInstructGPT 的答案在 toxicity 上小勝 GPT-3 的答案，但在 bias 上沒有\nMethods Dataset 標註人員寫很多 prompts\nPlain: 隨便寫任意任務 Few-shot: 想個 instruction，並寫 multiple query/response pairs for that instruction User-based: 根據一些申請使用 OpenAI API 的用戶，提出有關的 prompts 然後根據這個訓練初步模型，並把這個初步模型放到他們的 Playground 給用戶使用。\n再把用戶問的問題蒐集回來，並做篩選。\n訓練 SFT 的模型用 13k training prompts\n訓練 RM 的模型用 33k training prompts\n訓練 PPO 的模型用 31k training prompts\nModel Supervised fine-tuning(SFT)\n拿 GPT-3 去訓練 16 個 epochs 跑一個 epoch 就發現 overfitting，但發現訓練更多 epoches 對後面的 RM 有用，而且這個 model 也只是過渡產品 Reward modeling(RM)\n把 SFT 後面的 unembedding layer 去除掉，接上線性層，最後輸出一個 scalar reward\n用 6B RMs\n這模型會吃 prompt 和 response\n人工標記的是排序，不是分數\n對每個 prompt 生出 9 個答案\n原本是 4 個，但排 9 個花的時間可能不會到 4 個的兩倍，因為主要心力會花在讀 prompt。但標註訊息會多很多，因為都是兩兩比較。 而且在 loss 中最多只要丟入 RM 9 次，因為可以重用 Pairwise Ranking Loss\n對一個 prompt(假設是 x)，取出一對回覆(假設是 $y_w$ 和 $y_l$)，算出 RM(x, $y_w$) 和 RM(x, $y_l$)，假設 $y_w$ 比 $y_l$ 排序高，讓 RM(x, $y_w$) - RM(x, $y_l$) 的數值越大越好 Reinforcement learning(RL)\nPPO\n$\\beta$ 那項是 KL divergence $\\gamma$ 那項是不想要讓這 model 太專注在微調的任務，而失去原本在其他 NLP 任務也表現很好的功能。 $D_{pretrain}$ 是 pretraining distribution 如果 $\\gamma$ 為 0，在該實驗中叫做 PPO，否則，稱為 PPO-ptx Result ","date":"2023-01-27T17:39:12+08:00","permalink":"https://roykesydon.github.io/Blog/p/instructgpt/","title":"InstructGPT"},{"content":"介紹 一種用於自動化找超參數的方法，用在採樣昂貴而且是黑盒子的情況\n流程 取樣一些資料點 生出一個 Surrogate Model(可採用 Gaussian Process) 反覆做以下事情 用 Acquisition Function 挑選下一個要採樣的點 重新評估 Surrogate Model Gaussian Process 最終的 prediction 是一個 distribution 而不是單一個數字 生成方法需借助 kernel function，常用 RBF(Radial Basis Function)\n$K(x, x^{\u0026rsquo;}|\\tau)=\\sigma^2exp(-\\frac{1}{2}(\\frac{x-x^{\u0026rsquo;}}{l})^2)$\n$\\sigma$ 和 $l$ 是兩個可以調整的超參數\nAcquisition Function 可用超參數來調節 exploitation 和 exploitation\nUCB(Upper confidence bound) PI(probability of improvement) EI(Expected improvement) ","date":"2023-01-26T01:36:53+08:00","permalink":"https://roykesydon.github.io/Blog/p/bayesian-optimization/","title":"Bayesian Optimization"},{"content":"PPFDT per process file descriptor table 每個 process 都有 存放 file descriptors file descriptors 是一個唯一的整數，用來識別作業系統上的 open file 0, 1, 2 是 Standard input / ouput / error 大小受限於 OPEN_MAX，亦即能同時間能開的最多檔案數 Redirection Input redirection $ wc \u0026lt; /etc/passwd 把 wc 的 PPFDT 的 stdin 改成 /etc/passwd 如果是 $ wc /etc/passwd，則是在 PPFDT 追加 /etc/passwd Ouput redirection $ wc \u0026gt; f1 把 wc 的 PPFDT 的 stdout 改成 f1 Input \u0026amp; output redirection 兩個可以同時用\n$ cat \u0026lt; f1 \u0026gt; f2 \u0026gt;\u0026gt; 可以 append $ \u0026lt; f1 cat \u0026gt; f2 可以亂換位置 Error redirection $ find / -name f1 2\u0026gt; error 1\u0026gt; outputs 這樣就會把那些 Permission denied 的給到 errors，成功的給到 outputs 2\u0026gt;/dev/null /dev/null 會把丟進來的東西都丟棄 Copy Descripter 這兩者等價 $ cat f1 1\u0026gt;op_err 2\u0026gt;op_err $ cat f1 1\u0026gt;op_err 2\u0026gt;\u0026amp;1 make 2 a copy of 1 ","date":"2023-01-21T02:20:43+08:00","permalink":"https://roykesydon.github.io/Blog/p/io-redirection/","title":"IO Redirection"},{"content":"Compile C 4-steps pre-processing compilation assembly linking Types of Object Files Executable object file Relocatable object file Shared object file Core file Formats of Object Files a.out initial version of UNIX COFF SVR3 UNIX PE Win. NT ELF SVR4 Linux ELF format of a program ELF Header Program Header Table .text .rodata .data .bss .symtab .rel.text .rel.data .debug .line .strtab Section Header Table 可參考: http://ccckmit.wikidot.com/lk:elf\nProcess Instance of a program running on a computer\nProcess Control Block task_struct\nProcess Identification PID, PPID, SID, UID, EUID.. Process State Information Process Control Information ","date":"2023-01-21T00:08:25+08:00","permalink":"https://roykesydon.github.io/Blog/p/process-management/","title":"Process Management"},{"content":"Features Process control Variables Flow control Functions File \u0026amp; cmd name completions Cmd line editng Cmd history Command Mode Interactive Non- Interactive Command Type internal / Builtin command\n指令的程式碼是 shell 的一部分 e.g., cd, exit 不會產生 child process 有些 internal command，比如 echo, pwd，會 internal 和 external 都有實作 external command\n指令的程式碼在硬碟上的某個 binary file e.g., clear, ls 會產生 child process Common Commands 比較實用或常用的\ngrep\n找字詞\ngrep \u0026lt;string/pattern\u0026gt; -i 大小寫不敏感 -v 不包含關鍵字的 cut 找 column\n-f 找哪些 column -d 分隔符是什麼 比較兩個檔案\ncomm\n顯示 file1 獨有的列、 file2 獨有的列、file1 和 file2 共有的列\ncmp, diff\n回傳不一樣的列資訊\nunset\n把指定的變數移除掉\ntee\n吃 stdin 輸出到 stdout 和其他檔案\nless\n讀檔案用\nExpansions White space Control Operators ; 讓指令接著執行 \u0026amp; 放在結尾，讓指令在背景執行 \u0026amp;\u0026amp; logical AND || logical OR\n前面失敗才會跑後面\n# 註解用 \\ escape special characters 放結尾好換行繼續輸入 $? 一個特別的變數，有上個指令的 exit code Shell variables User defined Env var Shell history File Globing *, ?, [], -, ! ","date":"2023-01-19T23:00:02+08:00","permalink":"https://roykesydon.github.io/Blog/p/shell/","title":"Shell"},{"content":"GPT 本質上就是 Transformer 的 decoder\nGPT-1 paper: Improving Language Understanding by Generative Pre-Training\n用 semi-supervised，後來被歸為 self-supervised\nUnsupervised pre-training $L_1(U)=\\sum_i logP(u_i|u_{i-k},\u0026hellip;,u_{i-1};\\theta)$\n$U= \\{ u_1,\u0026hellip;,u_n \\}$\n$U$ 是一系列未標記的文本 token\n$k$ 是窗口大小\n模型大致架構 $h_0=UW_e+W_p$\n$h_1=transformer \\_ block(h_{i-1})\\forall i \\in[1,n]$\n$P(u)=softmax(h_nW^T_e)$\n$U=\\{u_{-k},\u0026hellip;,u_{-1}\\}$\nSupervised fine-tuning $P(y|x^1,\u0026hellip;,x^m)=softmax(h^m_lW_y)$\n$L2(C)=\\sum_{(x,y)}log P(y|x^1,\u0026hellip;,x^m)$\n$L_3(C)=L_2(C)+\\lambda*L_1(C)$\n$C$ 是 labeled 的資料集，微調基本上就是在後面加上線性層\n作者最大化 likelihood 的時候是用 $L_3$ 而非單純的 $L_2$\n微調應用範例 資料集 用 BooksCorpus 訓練出來的\n有超過 7000 本未出版的書\n模型結構 12 層 transformer 的 decoder 768 維 word embedding 12 個 attention heads 和 BERT BASE 比較 BERT 論文比較晚出，但 BASE 的模型架構和 GPT 有相似之處，\nBASE 是 12 層的 decoder，word embedding 和 attention head 的維度或數量和 GPT-1 相同\nGPT-2 paper: Language Models are Unsupervised Multitask Learner\nGPT-2 除了用更大的的模型和更大的資料集，把重點放在 zero-shot 上，雖然在 GPT-1 的論文就有提過 zero-shot\n資料集 這次做了一個叫做 WebText 的資料集，有百萬級別的網頁\nCommon Crawl 大型爬蟲專案，有大量網頁資料，但充斥了垃圾訊息\nWebText WebText 的資料來源是 reddit 上的外部連結，只要有至少三個 karma，就會被採納，由此取得品質較好的網頁資料。透過這種方法，取得了 4500 萬個連結。並用Dragnet (Peters \u0026amp; Lecocq, 2013) and Newspaper content extractors 把文字訊息從 HTML 中抓出來\n架構 和原本差不多，變成有 1.5B 參數的 Transformer decoder\nzero-shot 不需要下游任務的標記資料\n改把任務輸入進模型\n目前問題 現在的模型泛化能力不太好 Multitask learning 在 NLP 上不太常用，NLP 現在主流還是在預訓練模型上做微調以應對下游任務 對每個下游任務都得重新訓練模型 得蒐集 labeled 資料 結果 GPT-3 paper: Language Models are Few-Shot Learners\n摘要 有 175B 的參數，由於模型極大，要在子任務微調會成本很大，所以不做任何梯度更新 在很多 NLP 任務有傑出的成果 可以生出人類難以區分的新聞文章 目前有的問題 要在子任務微調，需要資料集 微調後在有些子任務上表現好不代表你預訓練模型一定泛化能力高 人類不需要大量 labeled 資料去完成小任務 評估方式 分為三種，few / one / zero-shot learning 架構 基本上 GPT-3 和 GPT-2 架構一樣\n相同 modified initialization pre-normalization reversible tokenization described therein 不同 把 Sparse Transformer 的一些修改拿過來用 GPT-3 Small 是 GPT-1 的大小 GPT-3 Medium 是 BERT Large 的大小 GPT-3 XL 和 GPT-2 相近，比較淺也比較寬\nBatch Size 大小 模型小的時候需要小一點，透過這種額外的 noise 來避免 overfitting(不確定是不是猜想)\n資料集 Common Crawl 架構比 GPT-2 大很多，所以回頭考慮這個資料集\n三步驟 先過濾，透過 reddit 那個高品質的資料集，來訓練一個模型分類高品質和低品質的網頁。 透過 LSH 演算法把相似的文本過濾掉 把一些已知高品質的資料集也加進來 這是一個 Batch 裡有 60% 來自 Common Crawl(filtered) 的意思 Wikipedia 雖然總量比較少，但也有 3% 的採樣率\n結果 計算量指數增長，loss 卻是線性的往下降\npaper 裡有很多任務的實驗結果，這邊就不附上了\nLimitations 在文本生成上還是比較弱，生很長的東西，可能會重複自己說過的話、失去連貫性、自相矛盾等等\n在有些雙向性的任務上可能表現更差\n影響 可能被用來散布不實消息、垃圾郵件等等 偏見 結論 在很多 NLP 任務可以做到接近 SOTA 微調模型的成果\n","date":"2023-01-19T01:50:07+08:00","permalink":"https://roykesydon.github.io/Blog/p/gpt-%E4%B8%89%E9%83%A8%E6%9B%B2/","title":"GPT 三部曲"},{"content":"VM A software implementation of a machine\nSystem VM 提供可以執行 GuestOS 的 complete system platform Process VM 像一個一般的 app 一樣在 hostOS 跑，支援單一個 process Hypervisor 又稱虛擬機器監視器（英語：virtual machine monitor，縮寫為VMM） 用來管理 VM\n允許多個 GuestOS 跑在 host computer\nType-1\nbare-metal hypervisors 直接在硬體上執行 Type-2\nhosted hypervisors 在 hostOS 上執行 directories Binary\ne.g., bin, sbin, lib, opt bin: 有關 user 的指令 sbin: 管理員會用的指令 opt: optional software，多數機器中這是空的 Configuration\ne.g., boot, etc, Data\ne.g., home, root, srv, media, mnt, temp In memory 字面上的意思，不在 hard disk，在 memory\ne.g., dev, proc, sys System Resources\ne.g., usr Variable Data\ne.g., var ","date":"2023-01-19T01:50:07+08:00","permalink":"https://roykesydon.github.io/Blog/p/linux-%E7%91%A3%E4%BA%8B/","title":"Linux 瑣事"}]