[{"content":"邏輯上的執行順序 FROM WHERE GROUP BY HAVING DISTINCT SELECT ORDER BY DDL Data Definition Language 用來定義資料庫的結構 Create Database 1 CREATE DATABASE database_name; Create Table 1 2 3 4 5 6 CREATE TABLE table_name ( column1 datatype, column2 datatype, column3 datatype, .... ); Data types: INTENGER, VARCHAR(size), TEXT, etc. VARCHAR Variable-length character string Constraints 1 2 3 4 5 6 CREATE TABLE table_name ( column1 datatype constraint, column2 datatype constraint, column3 datatype constraint, .... ); Auto Increment 用來自動增加一個數值 通常用在 primary key Primary Key 用來唯一識別一筆資料 Foreign Key 用來避免資料不一致 必須是另一個 table 的 primary key 可以是 NULL 可以設置 reference action 比如 ON DELETE CASCADE Not Null 用來限制 column 不可以是 NULL Unique 不像 primary key，可以有 null Check 用來限制 column 的值，可以自己寫條件 可以用在多個 column DCL Data Control Language 用來控制資料庫的存取權限 DQL Data Query Language 用來查詢資料庫中的資料 Select 1 SELECT column1, column2, ... FROM table_name; * 代表所有的 column column column 也可以利用 operator 1 SELECT column1 + column2 FROM table_name; 可以使用 AS 來改變 column 的名稱 1 SELECT column1 AS new_name FROM table_name; WHERE 針對 row 的條件過濾 1 SELECT column1, column2, ... FROM table_name WHERE condition; ANY, ALL 用來比較子查詢的結果 1 SELECT column1, column2, ... FROM table_name WHERE column1 \u0026gt; ANY (SELECT column1 FROM table_name); 如果用 \u0026gt; ANY subquery，而 subquery 沒有任何結果，那麼就會回傳 false，因為你的數值沒有比任何一人都高（要至少一人） 如果是 \u0026gt; ALL subquery，那麼就是要比所有人都高，所以如果 subquery 沒有任何結果，那麼就會回傳 true，你的數值比裡面的東西都高 JOIN 用來結合兩個 table 1 SELECT column1, column2, ... FROM table1 JOIN table2 ON table1.column = table2.column; types INNER JOIN, LEFT JOIN, RIGHT JOIN, FULL JOIN GROUP BY 用來將資料分組 針對 group 的條件過濾 1 SELECT column1, column2, ... FROM table_name GROUP BY column1; select 的 column 必須是 group by 的 column 或是 aggregate function HAVING 用來過濾 group by 的結果 要有 group by 才能使用 1 SELECT column1, column2, ... FROM table_name GROUP BY column1 HAVING condition; ORDER BY 1 SELECT column1, column2, ... FROM table_name ORDER BY column1; 可以指定升冪或降冪 DESC, ASC LIMIT \u0026amp; OFFSET 用來限制查詢結果的數量 DISTINCT 用來去除重複的資料 CASE 用來做條件判斷 1 2 3 4 5 6 SELECT column1, column2, ... CASE WHEN condition1 THEN result1 WHEN condition2 THEN result2 ELSE result END FROM table_name; 查詢結果集合運算 UNION 用來結合兩個查詢結果 1 2 3 (SELECT column1, column2, ... FROM table1) UNION (SELECT column1, column2, ... FROM table2); UNION ALL 會包含重複的資料 UNION 會自動去除重複的資料 限制 每個查詢的 column 數量必須相同 每個查詢的 column 的資料型態必須相同 column 的順序必須相同 INTERSECT 用來取兩個查詢結果的交集 EXCEPT 用來取兩個查詢結果的差集 ALL 要加這個才會包含重複的資料 Subquery select, from, where 等等都可以有 subquery 他可以視情況回傳一個值，也可以回傳一堆 row，或是一個 column（一維向量 可以用 outer query 的 column 來當作 subquery 的條件 Correlated Subquery 一個 subquery 用到 outer query 的 value 可能導致效能問題，比如每一筆資料都要執行一次 subquery 像是兩層 for loop flattening 寫成等效的 flat query DML Data Manipulation Language 用來操作資料庫中的資料 Insert 1 2 3 INSERT INTO table_name (column1, column2, column3, ...) VALUES (value1, value2, value3, ...), (value1, value2, value3, ...) 可以一次插入多筆資料 Update 1 UPDATE table_name SET column1 = value1, column2 = value2 WHERE condition; Delete 1 DELETE FROM table_name WHERE condition; Operators Arithmetic Operators Comparison Operators Bitwise Operators String Operators Functions Math Functions Date Functions String Functions ","date":"2024-08-25T00:00:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/sql-%E8%AA%9E%E6%B3%95%E7%AD%86%E8%A8%98/","title":"SQL 語法筆記"},{"content":"Kafka event streaming platform 專注在 publish / subscribe message 會在一段時間後被刪除，而不是等待 consumer 處理 Topic 一個特定的 data stream 一系列的 message 沒有限制 topic 的數量 由 name 來識別 Topic replication 如果有一個 broker down 了，會有另一個 broker 繼續提供複本 topic replication factor 這個 factor 要大於 1 常見的設定值是 3 這個數值代表有幾個複本 複本會被放在其他的 broker 上 設為 n，可以承受 n-1 個 broker down 一個 partition 只會有一個 broker 作為他的 leader 其他的有複本的 broker 被稱為 ISR (in-sync replica) producer 寫入的時候，只能寫到 leader consumer 預設也只會從 leader 讀取 2.4 版本後，可以設定從 ISR 讀取 Partition topic 通常會被分成多個 partition partiton 中的 message 是有序的 message 會獲得 id，他是 incremental 的 這個 id 被稱為 offset 只在特定的 partition 中有意義，不同的 partition 的 offset 是獨立的 但不同 partition 的 message 是沒有順序的，只有在同一個 partition 中才有順序 immutable 一旦 message 被寫入，就不能被修改 通常 partition 的數量至少為 consumer 數量 如果 partition 數量少於 consumer 數量，有些 consumer 會閒置 Message message 也被叫做 event 構成 required key, value, compression type, partition, offset, timestamp key, value 可以是 null timestamp 可以由系統設置 message 發給 kafka 後，會加上 partition, offset, timestamp optional header retention message 會在一段時間後被刪除 預設 7 天，可以設定 Message serialization / deserialization Kafka 會將 message 轉換成 bytes 才傳輸 用在 key 和 value 不支援的格式也可以用自訂的 serializer / deserializer ex: JSON 優點 可以用不同的語言來寫 producer 和 consumer 減少資料大小 Producer producer 會將 message 寫入到 topic producer 會知道要寫入哪個 partition send message 會帶有一個 key，可以是任何資料型態 如果 key 是 null，會以 round-robin 的方式分配到 partition 如果不是，同個 key 會被分配到同個 partition，因為有 hash function 來決定 kafka partitioner 會負責做 key hashing 預設 hash function 是 murmur2 Producer acknoledgement (ack) 有三種 ack acks=0 producer 不會等待 broker 的回應 這樣會有最高的效能，但是可能會有 message 丟失 acks=1 producer 會等待 leader 的回應 這樣會有中等的效能，但是可能發生 leader down 的情況 acks=all producer 會等待所有的 ISR 的回應 這樣會有最低的效能，但是不會有 message 丟失 Consumer consumer 會從 topic 中讀取 message 是 pull 的方式 和 producer 解耦 Push vs Pull push 沒辦法知道 consumer 能不能 handle message 如果 push 出去但 consumer 來不及消化會造成問題 pull 如果 consumer 速度比 producer 慢，可以之後慢慢補上 Consumer group 一個 application 可以有多個 consumer，共同組成一個 consumer group 同個 consumer group 中的 consumer 會共同設置一個 group id consumer group 中的所有 consumer 會以 exclusive 的方式從 partition 中讀取 message 不會有同一個 partition 被配給多個 consumer 如果 consumer 比 partition 多，有些 consumer 會閒置 group coordinator 會負責管理 group 中的 consumer 會負責分配 partition 給 consumer 利用 __consumer_offsets 來記錄 consumer group 中的 consumer 的 offset Consumer offset kafka 會紀錄 consumer group 中的每個 consumer 消耗到哪裡了 會放在 topic 的 __consumer_offsets 當 group 中的 consumer 取得 message 後，會週期性的 commit offset，讓 kafka 更新到 ＿consumer_offsets 這樣即使 consumer down 了，下次啟動時，也可以從上次消耗的地方繼續 三種 commit 策略 at least once 會在處理完 message 後才 commit 要確保處理方式是 idempotent 可以幫 message 加上 primary key at most once 會在取得 message 後就 commit exactly once Kafka broker kafka cluster 中的每個 server 都是 broker 多個連接在一起的 broker 組成一個 cluster 會有一個 broker 是 controller 負責管理 cluster 中的 broker 也管 topic 和 partition 用 id 來識別，id 是整數 broker 會包含某些 partition 也被叫做 bootstrap server 一但連到某個 broker，就可以連到整個 cluster kafka client 會處理 broker 數量考量 儲存空間 容錯 throughput Zookeeper 被用來管理 kafka broker 可以拿來幫 partition 做 leader election Zookeeper 分成 leader 和 follower Kafka 3.0 之後，可以改用 Kafka Raft 4.0 之後，會移除 zookeeper 該不該用 現在似乎 KRaft 已經準備好上 production 了 如果是 kafka client，應該盡量不使用 zookeeper CLI kafka-server-start.sh \u0026lt;config file\u0026gt; 啟動 kafka server (broker) 指定 config file --bootstrap-server 指定 kafka server 不推薦使用 --zookeeper --command-config 指定 config file 裡面會寫包含帳號密碼以及加密方式等安全設定 kaft-topics.sh --partitions 指定 partition 數量 --replication-factor 指定 replication factor --topic 指定 topic name --create delete --describe 描述 topic Replicas 顯示哪些 broker 有複本 (id) ISR 顯示哪些 broker 和 leader 同步 --list 列出所有 topic kaft-console-producer.sh --topic 指定 topic --producer.config 指定 config file --producer-property 指定 producer property acks 指定 acks 模式 --property 可以打許多次，每次指定一個 property kaft-console-consumer.sh --topic 指定 topic --from-beginning 不只是自打開 consumer 後的 message，而是從一開始的 message 開始 如果同一個 group 有多個 consumer，這個選項只會對第一個 consumer 有用，offset 是看 group 的 --consumer.config 指定 config file --property --group 指定 consumer group kafka-consumer-groups.sh --list 列出所有 consumer group --describe 描述 consumer group CURRENT-OFFSET 目前 offset LOG-END-OFFSET 最後一個 offset LAG 落後的 offset ","date":"2024-08-17T00:00:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/kafka-%E7%AD%86%E8%A8%98/","title":"Kafka 筆記"},{"content":"MongoDB 以 BSON (Binary JSON) 儲存資料 composite index prefix 如果有一個 index 是 (a, b)，那麼 (a) 也是有效的 index explain 用來看 query 的 execution plan cursor BasicCursor 會 scan 整個 collection，是個警訊 掃描的文件數量 nscanned 掃描的 index 數量 nscannedObjects 掃描的 document 數量 n 回傳的 document 數量 nscanned \u0026gt;= nscannedObjects \u0026gt;= n scanAndOrder 是否需要把文件都放在 memory 並排序 還會一次性回傳資料 hint 強制使用某個 index optimizer 挑選索引 第一階段 - 挑選最佳索引 最佳索引 包含所有的 filter 和 sort 的欄位 range filter 和 sort 的欄位必須在 equality filter 的後面 sort 的欄位必須在 range filter 的後面 如果有多個最佳索引就會隨便選一個 第二階段 - 透過實驗挑選索引 沒有最佳索引就會實驗判斷要選哪個，看看誰先找到指定數量的文件 換句話說，如果有多個索引，optimizer 會選 nscanned 最小的 MMAPv1 Mongo 一開始用的 storage engine _id 直接對應到 diskloc，也就是 disk 的偏移量 查找速度驚人，但是更新就要維護偏移量很費時 採用 database-level lock，Mongo 後來也只更新成 collection-level lock WiredTiger MongoDB 收購的 storage engine Document-level locking 可以做到 compression 5.2 之前 _id 會先被用來尋找 recordid，再用 recordid 去獲取 document recordid 是 clustered index 5.3 _id 變成 clustered index 之前 recordid 只有 64 位，但現在 _id 作為 primary key 有 12 bytes 對 secondary index 造成更大的負擔 Mongo 想達成跨機器和 shard 的唯一性 ","date":"2024-08-16T00:00:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/mongodb-%E7%AD%86%E8%A8%98/","title":"MongoDB 筆記"},{"content":"Estimation 要評估的指標 latency throughput capacity Database 估計 沒特別指定的話，可以預估 single relational database 可以處理 read \u0026amp; write 10K per second single relational database 的容量可以抓 3 TB redis 可以抓 100K，但是受限於 memory，可能抓 30GB 可以問的問題類型 總共有多少用戶？ 有多少活躍用戶？ 每個用戶平均每天使用多久？ Network Load Balancer type application load balancer (ALB) OSI layer 7 (Application layer) 可以根據 request header, URL, query string 來做 routing 可以 validate / terminate SSL network load balancer (NLB) OSI layer 4 (Transport layer) 可以根據 protocol (TCP, UDP, IP..), destination port etc 來做 routing 一般來說預設會 pass through SSL 比較適合應付高流量 strategy round robin 輪流 least connection resource-based 考慮每個 instance 的資源使用情況 weighted variants of the above 可以把上面說的各種情況多加入 weight 的考量 random 優點 resilience 可以關注到某個 instance down 了，自動把 request 轉到其他 instance scalability 後面的 instance 可以 horizontal scale 和 API Gateway 的差異 API Gateway 除了 load balancing 會有更多的功能，例如 rate limiting, authentication, authorization, request validation, caching, logging etc Protocol \u0026amp; Send/Receive data TCP UDP http websocket duplex (two-way) communication 只會建立一次 TCP connection load balancer 可以會遇到問題 long polling client 送 request 給 server，server 不會立刻 close connection，而是等待有新資料或 timeout 才回應 某些不能用 websocket 的情況下，可以用 long polling 來模擬 但是在一些框架或語言可能不好實作 gRPC RPC remote procedure call 把一些 service 包裝成像 local function 一樣，就可以像調用本地函式一樣使用 remote 的服務 google 開發的 RPC 框架 用 protobuf 作為 IDL (Interface Definition Language) binary protocol 非 readable，需要 encode / decode 但比 json 小 .proto file 定義 message 的格式 描述了 interface 長怎樣 protoc 用來 compile .proto file，根據指定的程式語言，產生 client / server code server 再實作 interface 用 http/2 來傳輸 不能用在 browser 適合用在內部服務之間的溝通 GraphQL 流程 User perspective 描述身為 user 期待看到什麼東西 這裡可以先簡單介紹這個 app 的大概邏輯，之後 marketplace 再針對不同 role 探討資料和使用情境 也可以詢問使用的平台 Marketplace 詢問要支援的用戶數量，以及活躍用戶數量 如果有多種用戶，也要分開討論 ex: 叫車服務會有司機和乘客 有更多角色後，可以開始根據角色討論他們的 perspective 取得一些數字 考慮 sotrage 以及 throughput 叫車服務範例 乘客總數量、活躍乘客數、每月乘客需求趟數 司機總數量、活躍司機數、單趟平均時間 throuput 活躍用戶 refresh rate 每個 user 平均打開 app 的次數 平均打開 app 會用多久 Rough design 探討資料的傳遞 根據不同 role 去講他們應該傳送什麼資料，用什麼協定，request 的頻率 (request per second) 討論的時候可以用 average，但是會有 peak time，可以考慮 X2, X4, X10 探討資料的儲存 要準備一些前提，比如假設單一資料庫每秒可以 insert 5K 筆資料 可以討論不同的 sharding 考慮怎樣存可以讓大小減少 評估這樣分是否可能導致 sharding uneven 怎樣的切法可以讓 query 盡量不要跨 shard 每個階段也可以探討 throughput 開始根據情境設計不同的 service 來表達他們的交互 Tips 查找 能不能用地理資訊來做 hashing 能不能用 geo index 工具 \u0026amp; 技術 headless browser 沒有 user interface 的 browser 但是依然有 rendering engine 和 js interpreter。可以用來得到最終的 html Cyclic redundancy check (CRC) 一般用在檢查封包是否有錯誤，但是我們也可以用來檢查某個檔案是否有被修改，好做 sync CQRS (Command Query Responsibility Segregation) 把 read 和 write 分開 一個 storage 針對 read 做 optimize，另一個 storage 針對 write 做 optimize Unique ID UUID 是 random 且 human-readable（不會有相近的 char，比如 0 和 O） 但是太長 可以用不同的 encoding 壓縮長度 因為 UUID 用的 charactor 是 0-9, a-f，所以可以用有更多種 charactor 的 encoding 來壓縮 BASE62 包含 0-9, a-z, A-Z BASE58 BASE62 但不包含容易混淆的 0, O, I, l BASE64 BASE62 但多了 +, / Other 每個 Phase 可以多和 interviewer 討論，確認走在正確的方向上 面對面試官給的數字可以嘗試為了好算向上抓一些 延遲任務 如果遇到因為某些原因需要晚點才能做某個任務，可以用 queue 來處理 Cache 除了用專門的 cache database 做，Server 自身也可以用 memory 來 cache 對於先搶先贏的系統不一定要追求公平，只要達成目標即可 對於搶票機制可以做 pre-populate，事先在 database 生好指定數量的票，這樣就可以只 lock 某個 row，不用 lock 整個 table ","date":"2024-08-03T00:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/system-design/","title":"System Design"},{"content":"Transaction 一個或多個操作的集合 一個 transaction 要不全部執行，要不全部不執行 即使程式中未顯式使用 transaction，資料庫也會自動為操作包裹一個隱式的 transaction lifespan begin commit rollback Atomicity 一個 transaction 要不全部執行，要不全部不執行 在 commit 前不管因為任何理由失敗，都該 rollback Consistency 符合當初制定的規則 (ex: 設置的 foreign key 指向的資料一定要存在) referential integrity 保證 primary key 和 foreign key 之間的關係 Eventual consistency 最後一定會 consistent，儘管過程中可能會出現短暫的不一致 Isolation 一個 transaction 的執行不應該影響其他 transaction read phenomena dirty read 一個 transaction 讀到了另一個 transaction 已經寫了但還沒 commit 的資料。這個資料有可能被 commit 也有可能被 rollback non-repeatable read 一個 transaction 兩次讀取同個資料時，得到的資料不一樣因是因為有其他 transaction 更新了這個資料（已經 commit 了） 和 dirty read 不同的是，這個資料是已經 commit 的 phantom read 也是第一次和第二次讀取的資料不一樣，第二次發現多了額外的資料，這次是因為有其他 transaction 寫入了新的資料（並且 commit 了） 之所以要和 non-repeatable read 分開，是因為他這裡沒辦法簡單的靠鎖起來已經讀過的資料，因為你沒辦法鎖你本來看不到的資料 系統設計遇到這問題可以考慮用 pre-populate 的方式，把所有可能的資料都先創好，就可以個別鎖住 lost update 我更新了某筆資料，但是在 commit 之前，有其他 transaction 也更新了這筆資料，並且 commit。我再去讀取這筆資料時，發現我更新的資料就被覆蓋了 double booking problem 當兩個 transaction 同時搶更新同個資源就有可能遇到該問題 example 兩個 transaction 都先 select 再 update 他們兩個 select 都先看到有空位，然後一前一後更新，就會造成 double booking Isolation level 為了解決 read phenomena，資料庫提供了不同的隔離等級 不同的隔離等級會影響到 transaction 之間讀取資料的方式，以達到不同的資料一致性要求 不會影響自身 transaction 前面所 write 的資料 read uncommitted No isolation 可以看到其他 transaction 還沒 commit 的資料 所有的 read phenomena 都有可能發生 read committed 只能看到其他 transaction commit 的資料 許多資料庫的預設隔離等級 除了 dirty read 之外，其他 read phenomena 都有可能發生 repeatable read 確保同一筆資料在同一個 transaction 中讀取時，結果是一樣的 phantom read 還是有可能發生 snapshot 保證 transaction 得到的資料是一致的 只會看到 transaction 開始時的 snapshot read phenomena 都不會發生 好像不是所有資料庫都有這個隔離等級，也有些 repeatable read 就是用 snapshot 來實現的 比如 PostgreSQL 就是用 snapshot 來實現 repeatable read 但這不代表不會遇到問題，請參考 double booking problem serializable 最高隔離等級 保證所有 concurrent transaction 執行起來會和依序執行的效果一樣 如果 transaction 不會彼此影響，還是有可能會讓 transaction 並行執行 read phenomena 都不會發生 和要求 exclusive lock 相比，有可能實現方法是遇到衝突會 fail Durability 一旦 transaction 完成，資料應該要 persistent 完成的 transaction 會被記在 non-volatile storage durability technique Write ahead log (WAL) 先寫 log (寫你做了什麼操作，但不去真的改 disk 上對應的資料)，有空再修改 這樣一些修改就可以改在 memory，如果 crash 了，可以用 log 來 recover 而且考量硬碟限制，如果你想修改的資料遠小於硬碟可寫的最小單位，會很浪費 Asynchronous snapshot 在後台把 snapshot 寫到 disk ","date":"2024-07-21T00:00:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/database-transactions-and-acid-properties/","title":"Database Transactions and ACID Properties"},{"content":"Database internal Storage concept Table Row_id 多數 database 會維護自己的 row_id 也叫做 tuple id Page 多個 row 會被存在一個 page 讀取不會只讀一個 row，而是一個或多個 page IO IO operation 指的是存取 disk 的操作 一個 IO 可能會獲得多個 page，也可能只是用 cache 的資料 Database 常常會利用 cache 來減少 IO 因此有些 query 很快，可能是因為有快取資料可用 Heap data structure 儲存整個 table 的資料 有些 database 會用 clustered index 來儲存，就不會有 heap Index data structure (b-tree) 一個有 pointer 來指向 heap 的資料結構 較流行的是 b-tree 可以對一個或多個 column 做 index index 可以告訴你要查詢的資料在哪個 page index 也會被儲存在 page Row-oriented vs Column-oriented Row-oriented database (row store) 每個 row 接著下個 row 來儲存 每次 IO 會獲得多個 row，每個都有所有的 column Col-oriented database (column store) 每個 column 接著下個 column 來儲存 比較好壓縮，也比較好做 aggregation，所以在一些分析資料的軟體會用到 Data structure B-tree Balanced data structure for fast search 限制 node 中的 element 同時存了 key 和 value range query 效率很差，因為要各別 random access B+Tree B-tree 的變形，和 B-tree 很像，不過 internal node 只存放 key，只有 leaf node 會存放 value internal node 因為現在只需要儲存 key，element size 比較小，所以可以存放更多 element leaf node 會用 linked list 串起來 適合 range query 通常一個 node 是一個 DBMS page LSM-tree Log-Structured Merge-Tree 都加在尾端，不會覆蓋原本的資料，對 SSD 有利 B-Tree 為了平衡會頻繁修改 有利於 insert Fragmentation 這裡是以 database 為出發點去看 fragmentation Internal fragmentation 一個 Page 中有很多空間是空的 External fragmentation 多個 Page 存放不是連續的。剩下的空間夠儲存新的資料，但是因為不連續，所以不能用 Database cursor 當資料庫有很大的結果集時，不可能一次把所有資料用網路傳給 client，用戶也沒有 memory 來存放所有資料 Server side / client side cursor Server side 一次只傳一部分資料給 client 但是要多次往返可能最後總時間會比較久 Client side 一次把所有資料傳給 client client 自己分批處理 對 network bandwidth 要求較大 可能沒有足夠的 memory Partitioning 把大 table 分成多個小 table Vertical vs Horizontal Vertical 根據 columns 拆成多個 partition 可以把不太常用又大的 column (比如 blob) 放到另外一個 partition 可以把他放在較慢的 disk，保留其他常存取的 column 在 SSD 也可以讓比較不常用的資料比較不容易進入 cache Horizontal 把 rows 拆成多個 partition 優點 用 single query 存取單一 partition 的速度更快 對某些 sequential scan 有幫助 可以把舊資料放在比較便宜的設備 缺點 如果要從一個 partition 移動資料到另一個 partition，效率很慢 對於效率很差的 query，可能會需要 scan 所有 partition，此時比掃描整個沒做 partition 的 table 還要慢 partition 可能會 unbalance Data types 這裡以 PostgreSQL 為例，列一小部分 設計 column 前可以先看有沒有合適的 data type Numeric 整數 浮點數 Serial 一種特殊的整數，會 auto increment Character char varchar 可變長度的字串，如果沒有設定長度，就是 text text bpchar 好像就是 varchar，但是 document 有寫 blank trimmed Date / Time Boolean Binary Geometric 特地寫這個是因為如果要用二維平面點，一般來說可能會用兩個 float，但是如果用 geometric 類有 point 可用 其他形狀也可存 UUID Enum 一個有限的字串集合 有序 按照建立時的順序 Database indexing 如果需要搜索的欄位沒做 index，那麼就會需要 scan 整個 table，直到找到 如果要求欄位做 like 之類的，那麼依然需要 scan 整個 table 搜索方法 table scan 如果掃描的範圍過大，Database 可能就會選擇該方法 通常會用 parallel 的方式搜尋，所以還是會快一些 index scan Index-only scan 也叫 covering index 需要的欄位在 index 裡面就有了，在這種情況不用去 heap 取，可以加速很多 但也要小心使 index 變得過大。如果 memory 不夠，又會用到 disk，拖垮效率 non-key column 可以用 include 把一些常常需要一起帶入的資訊放到 index 裡面 可以促成 index-only scan composite index 把多個 col 作為 key 做 index 在 PostgreSQL ，如果有一個 index 是 (a, b)，用靠左的 index 可以做 index scan，但是用靠右的就不行 Clustered index 也叫做 Index-Organized Table 資料圍繞 index 來組織 這也是為什麼 clustered index 只能有一個 沒特別指定的話，primary key 一般是 clustered index Primary key vs Secondary key primary key clusering 把 table 圍繞 primary key 來組織，但也有些 Database 不是這樣設計，比如 PostgreSQL 需要維持 order，但是如果我要根據 PK 取得小範圍內的資料，和不顧排序相比，就可能不用多次 IO Secondary key 不在乎原本 table 的 order，而是根據自訂的 key 來排序 但是會有另外一個結構去放 index，可以找到 row_id 設計差異 PostgreSQL 的 index 都指向 row，不管是 primary 還是 secondary 這樣 secondary index 就可以直接取資料，不用再跳一層 primary key 但是如果更新 row，會更新 row id，連帶影響要更新所有 secondary index，不管修改的欄位有沒有在這 index MySQL 的 secondary index 指向 primary key，primary key 指向 row 這樣 secondary index 就要先找到 primary key，再找到 row Distributed database Sharding 把 table 拆成多個 table，分散在不同的 database 分散式會帶來很多問題，比如要怎麼做 transaction 和 join? Horizontal partitioning vs sharding Horizontal partitioning 一個 table 拆成多個 table，但是還是在同一個 database 和 Horizontal partitioning 的差別 table 現在會分到不同的 database server 做 partition，client 不用管資料具體在哪個 partition，交給 DBMS 去處理。但是 sharding 就要 client 自己去處理 Sharding key Hash 用 hash function 來決定資料要放在哪個 shard Range 用某個 column 所處的範圍來決定資料要放在哪個 shard Dictionary 用離散的值來決定資料要放在哪個 shard 考慮事項 cardinality cardinality 是 set 中的元素數量 key 種類太少，就會限制水平擴展 frequency monotonicity 如果 key 是遞增或遞減的，可能會導致某個 shard 過度使用 Database replication 透過 redundancy 來提高 reliability, tolerance, accessibility Master / Backup replication 也叫 master-slave replication 只有一個 master / leader，有一或多個 backup / standby 一寫多讀 Multi-master replication 多個 master，可以同時寫入 需要處理 conflict Sychronous vs Asynchronous replication Synchronous transaction 會被 blocked，直到所有的 backup 都寫入 有些 database 可以設定 First N 或是 any 完成就好 Asynchronous transaction 被寫入 master 後就算完成 Concurrency control strategy pessimistic 用各種 lock 來保證 isolation optimistic 不用 lock，真的有 transaction 衝突時就 fail Lock shared vs exclusive shared lock 可以被多個 transaction 同時持有 用在讀取，所以可以多個 transaction 同時讀取 在有 shared lock 的條件下，其他 transaction 也可以設置 shared lock exclusive lock 只能被一個 transaction 持有 他人不能讀取或寫入 PostgreSQL 有一個 SELECT ... FOR UPDATE 來取得 exclusive lock 當涉及的資料持有其中一種 lock 時，其他 transaction 都不能設置另外一種 lock Deadlock 多個 transaction 互相等待對方釋放 lock 多數 DBMS 會檢查 deadlock，並讓最後一個造成 deadlock 的 transaction rollback Two-phase locking (2PL) DBMS 為了實現 isolation 需要保證 conflict serializability (CSR)，2PL 可以保證這一點 two-phase growing phase 取得 lock shrinking phase 釋放 lock 強調一個 transaction 不能釋放 lock 後就再也無法取得 有可能造成 deadlock Database Engine 也叫 storage engine 或 embedded database 負責處理 CRUD 的 library DBMS 基於 engine 來提供更多功能 ORM Eager vs Lazy loading Eager 一次把所有相關的資料都讀取出來 如果 Teacher 有很多 Student，可能會一次把所有 Student 都讀取出來 Lazy 只有在需要的時候才讀取 但是可能會有很多次 IO Open session in view (OSIV) 一個 request 一個 database session 可以配合 lazy loading 來用 N+1 problem 一個 query 取得所有資料，然後再用每個資料的 id 來取得相關資料 這樣就會有 N+1 次 IO 第一次是從主表拿清單 接下來 N 次是從子表拿資料 Tips 盡量不要使用 offset 最 naive 的實現 pagination 的做法就是用 offset + limit。但是 offset 代表讀取並丟掉前面幾筆資料，所以他會多讀一堆沒用的資料 可以讓用戶那邊保存 id，where 設置 id 要大於多少來規避 offset Connection pool 維護一定數量的連接，避免每次都要建立連接 Idempotency key 用來確保一個 request 只會被執行一次 會生成一個唯一的 key，並且在 request 中帶上這個 key。執行操作後會把這個 key 存起來，下次再收到這個 key 時就不會再執行操作 可以用 ULID 而不用 UUID，因為 ULID 前面的 bit 有時間戳，可以用來排序 輸入的資料集中在相近的 page，還都加在尾端，可以減少 IO (相較隨機的 UUID) 不用被迫頻繁存取 disk。而且 UUID 的隨機性拉一堆 page 會導致 buffer 更容易被塞滿，而得強制寫入 disk consistent hashing 把 hash function 的結果分散在一個 hash ring 上 根據 hash function 的結果，看自己落在哪段範圍，配給指定的 server 這樣的好處是追加或是移除 server 時，只會影響一台 server 的資料 也可以追加到負載比較高的 server 附近 write amplification 寫入資料時，發現 disk 寫入的資料比你預期寫入的資料多很多 分很多不同 level，通常是在說 SSD 造成的 想更新的時候，更新的 page 會被標記為不能使用。會有另外一隻非同步程式定期處理這種 但是他會把整個 block 寫到新的地方，再把原地方設為 free，就為了那些不能再被使用的空間搬整個 block polymorphic association 一個 table 有多個關聯，但是這些關聯是不同的 table 某個 id column 會根據不同情況代表不同 table 的 id 可能可以節省空間 也可能因為這樣而沒辦法使用 foreign key 可以考慮拆成多個 column 或是多個 table ","date":"2024-07-21T00:00:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/database-%E4%B8%80%E8%88%AC%E7%AD%86%E8%A8%98/","title":"Database 一般筆記"},{"content":"Pipeline 名詞 Artifact 你需要用到的檔案，可能是 build 出來的檔案，或是跑測試用的專案 ex: .jar, .war Type Build pipeline Release pipeline azure-pipelines.yml 可以 create pipeline，在專案中加入該檔案，Azure DevOps 會自動偵測並執行 用於 build pipeline trigger 指定哪些 branch 有 push 時，要執行 pipeline Variables 可以設定變數，用在 yaml 中 Task 可以搜尋各種 task 來完成任務 copy files publish build artifacts Release pipeline 把 build 出來的 artifact，部署到指定的環境 artifact 上方的閃電，可以設置當有新的 artifact 時，自動觸發 release create release 執行 CI/CD Agent pool 可以加入自己的 agent，也就是自己的 server Board Work item Epic 一個非常 high level 的需求 Issue 把 Epic 拆成小的需求 在敏捷也可以稱為 User Story Task 再把 Issue 拆成更小的需求 Backlog PO 創建的 Issue，會在 Backlog 中 可以把 Issue 拖拉到 sprint 中 可以結合 git repo，把 commit 或 branch 關聯到 Issue Sprint 在這可以新增 sprint 也有 task board，列出所有 task 可以設置 task 的狀態以及指派人員 ","date":"2024-07-20T00:00:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/azure-devops-%E7%AD%86%E8%A8%98/","title":"Azure Devops 筆記"},{"content":"File Uploaded Vulnerability 防禦方法 不要允許使用者上傳任何可執行的檔案 檢查 file type 和 file extension file type 指的是 header 的 Content-Type 用某些套件分析檔案，並重新創建和重新命名檔案 Code Execution Vulnerability 允許攻擊者執行 OS command 防禦方法 不要使用危險的 function 透過 filter 檢查輸入 比如利用 regex File Inclusion Vulnerability LFI (Local File Inclusion) Vulnerability 攻擊者可以讀取伺服器上的任何檔案（包含 /var/www 外的檔案） 透過輸入讀其他檔案的時候沒有檢查檔案路徑 可以用來讀 /proc/self/environ，可能會存在一些可以透過 request 修改的變數。植入PHP 程式碼便有可能被執行 RFI (Remote File Inclusion) Vulnerability 和 LFI 類似，但是檔案來自外部 可以在當前 server 執行其他 server 的 php 程式碼 可以在其他 server 以 .txt 存 php file 防禦方法 避免 remote file inclusion php 的話可以關掉 allow_url_fopen 和 allow_url_include 避免 local file inclusion 用 static file inclusion，不要透過變數去取得檔案位置 SQL Injection 防禦方法 使用 prepared statement XSS (Cross Site Scripting) 允許攻擊者在網頁上執行 javascript code 執行在 client 端，不是 server 端 Main types Reflected XSS 用 URL 攻擊 Persistent/Stored XSS 攻擊的程式碼存在 database 或是某個 page DOM-based XSS 利用前面的方法，透過開發者不當操作 DOM 來攻擊 ex: 攻擊者透過 .innerHTML 放入 script tag Exploitation BeEF Framework 可以把目標 hook 到 beef 可以透過 beef 對被 hook 的目標做各種操作 防禦方法 盡量避免讓 user 的輸入直接顯示在網頁上 在 insert 到網頁前，escape 所有不信任的輸入 把這些 character 轉換成 HTML 用的格式 ex: \u0026lt; -\u0026gt; \u0026amp;lt; CSRF (Cross Site Request Forgery) 防禦方法 Anti CSRF token 生表單的時候也生一個 token，並記住，request 要帶上這個 token unpredictable can\u0026rsquo;t be reused 前後端分離 後端生 CORS 不要接受所有來源，讓前端取得 token 前端生 要發 request 的時候把 cookie 改成和 token 一樣的值 Backdoor msfvenom msfconsole Anti-Virus Principle Static Analysis 和已知的 malware 比對 可以利用 packers, encoders, abfuscators 來讓程式更加獨特 Dynamic(Heuristic) Analysis 在 sandbox 中執行，看他的行為 要幫程式增加安全的操作 延遲 Payload 執行的時間 ","date":"2024-06-28T00:00:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/web-security/","title":"Web Security"},{"content":"Terms Incremental vs Iterative Incremental 隨時間一步一步完成 Iterative 建立 prototype，然後不斷改進 Model type Linear/Predictive 有類似的專案經驗 有明確的流程 沒什麼可以改動的空間 Flexible/Adaptive 專案屬於 new idea 專案很有可能隨時間改變 Waterfall Model 像瀑布一樣，一個階段完成後才能進行下一個階段 Requirement -\u0026gt; Design -\u0026gt; Implementation -\u0026gt; Testing -\u0026gt; Deployment -\u0026gt; Maintenance 非常 predictive，沒有彈性 如果在 Testing 發現重大問題，可能要從 Requirement 重新開始 隨著進度推進，fix 成本增長很快 每一步都得考慮周密 用戶很晚才能看到結果 Incremental Model 在整個開發過程中多次完成軟體開發過程 每個子開發過程都有明確的目標 Agile 一種思維方法，不是模型 Manifesto Individuals and interactions over processes and tools 如果一組人決定要用一組新的工具，那他們應該有更高的優先權 過往的做法可能偏向使用過的工具 Working software over comprehensive documentation document 很重要，但是只有大量的 document 沒辦法讓客戶給出反饋 Customer collaboration over contract negotiation 強調和客戶的合作，而不是只在意合同上的項目 Responding to change over following a plan 瀑布式開發的缺點 現在的技術環境變化太快，Agile 希望在開發過程中能夠快速適應 傳統的開發方法考量到金錢損失，不太可能辦到。但透過小的 increment，可以在每個 increment 中朝正確的方向前進 軟體系統不可能被 100% 預測 系統可能不符合用戶要求 市場變化很快，Agile 可以在短時間內推出最小可行產品，先行推向市場 Kanban 會存在多張卡片 可以直觀看到某個欄位是否堆積大量工作 Properties Visualize workflow Limit work in progress Manage flow Make process policies explicit Improve collaboratively Principles Start with what you do now Agree to pursue incremental, evolutionary change 並非試著立刻改變所有事情 Respect the current process, roles, responsibilities \u0026amp; titles Encourage acts of leadership at all levels 這裡的 leadership 不一定指領導他人，也可以是激勵他人 欄位 Backlog Analyze Develop Test Release Scrum 可以利用 back-to-back testing 來確認沒有弄壞之前 sprint 的功能 roles Product Owner 決定要用什麼方式完成什麼事 與外部世界溝通的人，和利害關係人溝通 目標 最大化產品價值 價低成本、提高收益 職責 維護 open, healthy product backlog 回答產品相關問題 管理預算、release schedule 確保團隊價值，找出問題 Scrum Master 確保團隊遵守 Scrum 的規則，促成會議、解決衝突 Servant Leader 有一點領導，但和大家平等。促成團隊工作而不是指揮別人 目標 促成 Daily Standup 移除障礙 確保大家的心情 確保 Scurm values 團隊的調解人 Dev Team 包含工程師、設計師等等 目標 和 Product Owner 合作，create user stories 寫 code 和測試，確保符合預期 research, design, prototype 流程 product backlog 待完成的事情 可能的欄位 優先度 預計花費時間 誰來執行 spring planning meeting 決定要在這個 sprint 完成的事情 時間點會是 sprint 的第一天 目標 把 product backlog 轉換成 sprint backlog 職責 Scrum Master 促成會議 確保和準備會議地點 確保會議有在持續推進，好達成 timebox 如果有講太久的部分，可能稍後再排單獨會議 確保一切都和 sprint goal 一致 Product Owner 準備好 product backlog 澄清 product backlog 的細節 要準備好描述 acceptance criteria 比如搜索速度要多快？ Dev Team 協助判斷哪些任務可達成且符合 sprint goal sprint backlog 這個 sprint 要完成的事情 開發人員去自己選擇要做的事情 然後就會花 1-4 週完成一個 sprint Daily Scrum (Daily standup) 不該花太久，比如最多 15 分鐘 職責 Scrum Master 確保會議的進行，確保 timebox 紀錄關於目前障礙的筆記，規劃時間移除 Dev Team 回答問題 做了什麼 計畫做什麼 遇到什麼問題 sprint review 找 stakeholders 來看看這個 sprint 的成果 秀出 product increment product increment 意味著他本身就是一個完成的產品，經過測試且準備 release 任務 review sprint result 回顧那些任務做得好和不好 如果有事情沒完成，要解釋為什麼推遲 這個 sprint 有沒有達到目標 Discuss and demonstrate work product owner 全程記錄筆記 Update status of the project Collaborate on the plan ahead sprint retrospective 團隊討論這個 sprint 的問題，並且改進 常見方法 start-stop-continue 每個人說出一個想開始做的事情，一個想停止做的事情，一個想繼續做的事情 可以保持匿名 3-5-3 Structure 3 artifacts Sprint Backlog Product Backlog Product Increment 5 events Sprint Planning Daily Scrum The Sprint Sprint Review Sprint Retrospective 3 roles Product Owner Scrum Master Dev Team 可以再加上 5 values Focus Respect Commitment Courage Openness 3 pillars Transparency Inspection Adaptation ","date":"2024-06-27T02:00:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/software-development-model/","title":"Software Development Model"},{"content":"通用術語 Test data 用來測試系統的輸入 Test case 包含測試步驟, 預期結果, 測試資料 Oracle 理想的結果 Bug error 或是偏離預期的行為 用詞 failure 偏離預期的 event error 導致 failure 的 code part fault outcome Verification 確認系統是否符合 specifcation 這裡出問題是工程師的錯 Validation 確認系統是否符合使用者需求 這裡出問題代表產品目標有錯 Stub 用來代替其他 component 的 template，會回傳 hard-coded value Mock 用來代替其他 component 的 template，會回傳預先設定的值，而且會檢查調用的次數 Driver 用來執行 commands 還有初始化變數的 template Test coverage line coverage 根據程式碼實際執行的程式碼行數來計算 branch coverage 檢查程式碼是不是不同的可能都跑過 考慮 if, switch\u0026hellip; Testing Types Unit Testing 專注在測試 smallest unit of software 要 isolate unit，避免其他 unit 影響測試結果 用 dummy value Integration Testing 專注在測試 communication 和 architecture type non-incremental 一次測試所有 component，測試整個應用程式 Big Bang Testing incremental 每次新增一個 module，做一些測試，反覆執行 Top-Down Testing 從最上層開始，下面調用的部分用 stub 代替 Bottom-Up Testing 從最底層開始，上面呼叫的部分用 driver 代替 Back-to-Back Testing 把已知良好的版本和新版本比較 如果 output 一樣，就代表新版本舊的功能是正確的 可以是 incremental testing 的一部分 Black Box vs White Box Testing Black Box Testing 不需要知道內部結構 用 input 和 output 來測試 Boundary Value 測試高低邊界值，過了就假設中間都過了 Cause-Effect Graph 一種設計 Test Case 的方法 又稱為 fishbone diagram 不同的 cause 會導致不同的 effect 最後會有一個 table 來表示所有可能輸入的組合會對應到什麼結果 Pair-wise Testing 測試多個參數的可能組合 State-based Testing 測試不同狀態下的輸入，確認 state 改變的情形 White Box Testing 知道內部原理，嘗試測試程式碼本身 Control Flow Testing 寫涵蓋所有 branch condition 的 test case Data Flow Testing test case 要涵蓋所有的變數，包含 declaration 和 use ","date":"2024-06-27T00:01:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/testing/","title":"Testing"},{"content":"基礎概念 Container runtime CRI (Container Runtime Interface) Kubernetes 用來和 container runtime 互動的 interface 任何可以實現 CRI 的 container runtime 都可以用在 Kubernetes，比如 containerd 以前有幫 Docker 特別實現一個 CRI，叫做 Docker shim OCI (Open Container Initiative) 一個開放的 container image 和 runtime 的標準 他定義了 container image 和 container runtime 的格式 containerd 一個 container runtime，docker 底下所使用的 container runtime，現在已經與 docker 單獨出來開發維護 他實現了 CRI，所以可以用在 Kubernetes CLI ctr 如果你只裝 containerd，沒有裝 docker，就可以用這個來操作 containerd 能用的指令比較少 For Debugging nerdctl docker-like 的 CLI 很多指令可以把 docker 的指令換成 nerdctl 的指令 For general purpose crictl 用來操作符合 CRI 的 container runtime 的 CLI For Debugging Node Kubernetes 集群中的一台機器 過去叫做 Minion Cluster 由多個 Node 組成的集群 Node Type Master 控制整個集群的 Node Worker 其他非 Master 的 Node 叫做 Worker Node Master vs Worker Master 擁有的 Component API Server etcd Controller Scheduler Worker 擁有的 Component Container Runtime Kubelet Component 安裝 Kubernetes，實際上是安裝以下幾個 Component API Server front-end of the Kubernetes kubectl 是在和這裡溝通 etcd distributed key-value store 會實現 lock mechanism，確保沒有 conflict 預設聽 2379 port command line client etcdctl kubelet 在每個 node 上運行的 agent 負責確保 container 在 node 上如期運行 Container Runtime 用來 run container 的 underlying software Controller Manager 當 node、container、endpoint 掛掉的時候，他要負責監控和回應 底下有許多種的 Controller，負責監控還有作出應對處理 type Replication Controller 確保指定數量的 Pod 在任何時間都在運行 load balancing \u0026amp; scaling 後來被 ReplicaSet 取代 Node Controller 確保 node 在運行 設定固定間隔監測 node 的健康狀態 Scheduler 負責處理 node 間的 distributing work 會尋找新創的 container，並分配到 node 嘗試幫每個 pod 挑選最適合的 node two phase Filter 檢查 node 是否符合 pod 的需求 Rank 給 node 一個分數，選擇最高分的 node Pod Kubernetes 的最小單位 一個 Pod 封裝一個應用程式，可能包含一個或多個 container ReplicaSet 新版本的 Replication Controller yaml spec template 指定要創建的 Pod 的 template 把 pod 的 metadata 和 spec 都放在這裡 replicas 指定要創建的 Pod 的數量 selector 指定要選擇的 Pod 需要這個是因為 ReplicaSet 也可以管理那些不是他創建的 Pod matchLabels 指定要選擇的 Pod 的 label command kubectl scale --replicas=3 -f \u0026lt;file\u0026gt; scale up/down replicas 這樣不會修改檔案，所以檔案的如果原本是 2，檔案依然會寫 2，只是 replicas 會變成 3 kubectl scale --replicas=3 replicaset \u0026lt;name\u0026gt; scale up/down replicas kubectl edit replicaset \u0026lt;name\u0026gt; 想要 scale up/down replicas 也可以用這個，他會立刻生效 簡寫 rs Deployment 管理 ReplicaSet 和 Replica Controller yaml 和 ReplicaSet 很像，把 kind 從 ReplicaSet 改成 Deployment 就好 會自動創建 ReplicaSet 使用情境 Rolling update 想要更新每個 Pod，但不是同時更新，而是一個一個更新，確保不會有 downtime Rollback 如果更新失敗，可以回到之前的版本 Pause and Resume 當需要做 multiple changes，不想要一下指令就馬上做，可以先 pause，等所有指令下完再 resume rollout 創建 Deployment 的時候，會自動創建一個 rollout 創建一個 rollout 的時候，會自動創建一個 Deployment revision Deployment Strategy Recreate 先刪除所有舊的 Pod，再創建新的 Pod 中間會有 Application downtime Rolling Update 一個一個更新 Pod 這個是預設的 strategy command kubectl rollout status deployment \u0026lt;name\u0026gt; 查看 rollout 的狀態 kubectl rollout history deployment \u0026lt;name\u0026gt; 查看 rollout 的 history (revision) kubectl rollout undo deployment \u0026lt;name\u0026gt; 回到上一個 revision 簡寫 deploy Service 讓不同 group 的 Pod 互相通信 像一個 virtaul server，可以連接到一個或多個 Pod 每個 Node 都有一個 kube-proxy，他會檢查有沒有新的 service，並維護 iptables type NodePort 會在每個 node 上開一個 port，讓外部可以連進來 default valid port range: 30000-32767 yaml spec type ports port service 的 port targetPort pod 的 port 如果不設置，會用 port 的值 nodePort 如果不設置，會從 default port range 選一個 selector 指定要連接的 Pod 預設會用 load balancing，策略是 Random，像是一個內建的 load balancer 如果有在同個 cluster 跨 node 的情況，不需要其他設定，就可以創建一個跨 node 的 service，會幫他們都設同一個 nodePort ClusterIP 只有在 cluster 內部可以連進來 用來幫某一組的 pod 提供一個統一的界面並做轉發 不能依賴 internal IP，因為每個 pod 都有可能會 down 或 up yaml spec type ports port targetPort selector service 可以用 cluster IP 或是 service name 來連接 LoadBalancer 會在 cloud provider 上開一個 load balancer nodePort 的 load balancer 是在 node 內部的，現在是要幫多個 node 做 load balancing 這只有在 cloud provider 上才有 name 很重要，因為其他的 Pod 會用這個 name 來連接 (就像 domain name) 簡寫 svc YAML Kubernetes 的配置文件 root level properties apiVersion kind apiVersion Pod v1 Service v1 ReplicaSet apps/v1 Deployment apps/v1 kind Pod, Service, ReplicaSet, Deployment metadata name labels 可以加入任何 key-value pair spec specification section pod containers name image env: list of environment variables name value Tool kubectl kubectl 用來 deploy、inspect、manage application on a Kubernetes cluster commands kubectl run \u0026lt;name\u0026gt; --image=\u0026lt;image\u0026gt; 創建一個 Pod kubectl get pods 查看所有 Podllll -o wide 顯示更多資訊 column READY / 也可以用 kubectl get all 來查看 Pod、Service、ReplicaSet、Deployment kubectl describe pod \u0026lt;name\u0026gt; 查看 Pod 的詳細資訊 欄位 Node Pod 在哪個 Node 上運行，包含了 Node 的 IP IP Pod 的 IP kubectl delete pod \u0026lt;name\u0026gt; 刪除 Pod kubectl create -f \u0026lt;file\u0026gt; 根據 YAML file 創建 resource 如果 resource 已經存在，會報錯 kubectl apply -f \u0026lt;file\u0026gt; 根據 YAML file 創建 resource 如果 resource 已經存在，會更新 resource kubectl replace -f \u0026lt;file\u0026gt; 根據 YAML file 創建 resource 如果 resource 已經存在，會刪除舊的 resource，並創建新的 resource kubectl edit replicaset \u0026lt;name\u0026gt; 可以直接編輯 Replica Set 的 yaml 檔，但他不是一開始創建用的檔案，而是 Kubernetes 在 memory 暫時生成的 kubectl set image deployment \u0026lt;name\u0026gt; \u0026lt;container-name\u0026gt;=\u0026lt;new-image\u0026gt; 更新 Deployment 的 image 注意這裡是 Container name，不是 Pod name --record=true 會記錄每次的操作 用在 rollout 的時候，可以看到每次的操作，不然會顯示 minikube 用來在 local machine 上建立一個 single-node cluster kubeadm 用來在多個 node 上建立 cluster 在多個 node 上安裝 Kubernetes 流程 安裝 container runtime 安裝 kubeadm 初始化 master node 建立 pod network 加入 worker node Networking Cluster Networking 每個 Pod 都有自己的 IP 兩個不同屬於同一個 cluster 的 Pod 可能會有相同的 IP Kubernetes 要求所有的 Pod 要可以在不用 NAT 的情況下互相通信 所有的 container 和 node 都要可以在沒有 NAT 的情況下互相通信 可以用 Calico 等方案實現 他會把每個 node network 都設成不同的，底下的 pod IP 自然就不會重複 ","date":"2024-06-14T00:00:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/kubernetes-%E7%AD%86%E8%A8%98/","title":"Kubernetes 筆記"},{"content":"基礎概念 Module 把相關的 Component、Directive、Pipe、Service 等打包在一起的容器 Lazy Loading Component Angular 應用程式的基本組成單位 Pipe 用來轉換資料的工具，可以把字串格式化、日期格式化等 Directive 用來修改 DOM 元素的外觀或行為 比如說 ngIf、ngFor、ngStyle、ngClass 類型 Structural Directive: 修改 DOM 的結構 可以搭配 ng-container 不會產生額外的 DOM 元素，可以用在想要用 ngIf 和 ngFor 但不想產生額外元素的情況 *ngFor let item of items; index as i Attribute Directive: 修改 DOM 的屬性 Component Directive: 包含 template 的 directive Service 負責 API 請求、資料處理等工作 Dependency Injection @Injectable providedIn root: 全域共用 也可以在 component 的 providers 中設定要注入的 service Router 負責處理 URL 路由 routes path component guard ng g guard \u0026lt;guard-name\u0026gt; CanActivate CLI Command ng new my-app: 建立新的 Angular 專案 ng serve: 啟動開發伺服器 ng build: 打包專案 generate ng generate module my-module: 建立新的 Module ng generate component my-component: 建立新的 Component --module=app: 指定 Component 所屬的 Module ng generate service my-service: 建立新的 Service ng generate pipe my-pipe: 建立新的 Pipe ng generate directive my-directive: 建立新的 Directive Module NgModule declarations: 定義同一 Module 中的 Component、Directive、Pipe imports: 匯入其他 Module providers: 定義 Service bootstrap: 定義啟動的 Component exports: 定義要匯出的 Component、Directive、Pipe Component 包含元素 Template TypeScript Class .spec.ts: 測試檔 Selector: 定義 Component 的名稱 CSS Style standalone 新版 Angular 預設 app 使用 Standalone 模式，使 component 不再需要透過 NgModule 管理 Lifecycle Hooks ngOnChanges 當 Angular 重新綁定輸入屬性時調用 ngOnInit 當 Angular 初始化指令/元件時調用 在第一輪 ngOnChanges 後調用 只調用一次 使用場景 初始化資料（需要根據 @Input 變數） fetch data from API ngDoCheck 在 ngOnChange 和 ngOnInit 之後調用 ngAfterContentInit 在 Angular 把 ng-content 投影到 view 後調用 在第一個 ngDoCheck 之後調用 ngAfterContentChecked 在 ng-content 的內容變更後調用 ngAfterViewInit 在 Angular 初始化完 view 後調用 ngAfterViewChecked 在每次做完 view 的變更檢查後調用 ngOnDestroy 在 Angular 銷毀 directive/component 前調用 Component check 操作 update child component input binding update DOM interpolation update query list Sharing Data @Input 父元件傳遞資料給子元件 @Output 子元件傳遞資料給父元件 Binding Property Binding 用來設定 HTML 元素的屬性 用中括號 [] 包住屬性名稱 ex: \u0026lt;img [src]=\u0026quot;imageUrl\u0026quot;\u0026gt; Event Binding 用來設定 HTML 元素的事件 用小括號 () 包住事件名稱 ex: \u0026lt;button (click)=\u0026quot;onClick()\u0026quot;\u0026gt; $event: 可以取得事件物件 Two-way Binding 把屬性和事件綁定在一起 用中括號和小括號 [(ngModel)] 包住屬性名稱 ex: \u0026lt;input [(ngModel)]=\u0026quot;name\u0026quot;\u0026gt; ","date":"2024-05-24T00:00:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/angular-%E7%AD%86%E8%A8%98/","title":"Angular 筆記"},{"content":"Maven 專案管理工具 會先檢查 maven local repository 有沒有需要的 dependency，沒有的話就會去 maven central repository (remote repository) 下載 pom.xml project cooridnate groupId artifactId version plugin 和 dependency 的差別是，是用來執行某種 task 的 mvnw maven wrapper 在沒有安裝 maven 的環境下，會下載正確的 maven 版本 Spring IoC Invocation of Constructor 把物件交給 Spring 管理 loose coupling Dependency Injection Bean 給 Spring 管理的物件 創建方法 @Component 創建出的 Bean 名字是 class 的開頭轉小寫 注入方法 @Autowired 種類 field injection 不太推薦，不利於 unit test spring boot 會先建立所有 component，在逐一注入，使元件可能短暫處於初始化不完整狀態 constructor injection 最推薦 建立 bean 時就注入 確保 component 被使用時是處於完整的狀態 有利於 unit test，因為可以把設計好的 mock bean 從 constructor 傳入 spring 建議使用 constructor injection setter injection 用 setter 來注入 創好 component 後，再注入 限制 該 Class 也得是 Bean 會根據類型注入 bean 如果同時有多個同類型的 bean，會報錯，可以用 @Qualifier 指定要注入的 bean 名稱 @Qualifier 指定要注入的 bean 名稱 @Primary 如果有多個同類型的 bean，會優先注入這個 bean Cycle life @PostConstruct 創建 bean 後，就會執行這個方法 限制 必須是 public void 不能有參數 @PreDestroy bean 被銷毀前執行 限制 必須是 public void 不能有參數 Lazy Initialization 本來 beans 不管有沒有用都會被創建 @Lazy 只有在要使用時才會初始化 缺點是用 @RestController 的話，第一次 request 才會創建 可以在 application.properties 裡設定 spring.main.lazy-initialization=true，讓所有 beans 都變成 lazy initialization AOP Aspect Oriented Programming 透過 Aspect 統一處理不同方法的共同邏輯 要導入 aop 的 starter 只有 Bean 才能設置 @Aspect Annotation @Aspect 這個 class 是一個切面 @Before 加上切入點，就可以在切入點 (Pointcut) 的方法執行前執行 @After 在方法之後執行 @Around 在方法之前和之後都執行 常用的功能都已經被封裝好了，開發較少用到 AOP Run app use java -jar mvn clean package java -jar target/xxx.jar use mvn spring-boot:run mvn spring-boot:run 特性 Starter Spring Boot Starters 官方的 starter 命名是 spring-boot-starter-* 第三方的 starter 命名是 *-spring-boot-starter\n外部化配置 application.properties 重新啟動 jar 時會自動載入，不用改配置要重新 build jar 集中管理 @Value 可以注入到變數中 可以用 : 來設定預設值 限制 只能在 Bean 和 Configuration 中使用 YAML application.properties 寫多後，沒有層級辨識度 application.yml profiles 可以根據不同的環境來設定不同的配置 (dev, test, prod) application-{profile}.properties application-{profile}.yml spring.profiles.active 指定啟用的 profile jar -Dspring.profiles.active=dev 指定配置文件 cli --spring.config.location Config 資料夾 可以在 jar 目錄下建立 config 資料夾，放配置文件，不用輸入額外的 args 大致分類 core logging web security data actuator integration devtools test Dependency Management parent 寫了版本號，故 dependency 可以不用寫版本號 真的要指定的話，可以利用 maven 的就近原則 Auto Configuration Component Scan Spring Boot 會掃描主程式所在的 package 以及子 package 也可以在主程式上加以下註解來指定掃描的 package @SpringBootApplication(scanBasePackages = \u0026quot;com.example\u0026quot;) 所有 starter 都有 spring-boot-starter，spring-boot-starter 又有 spring-boot-autoconfigure，這個就是自動配置的地方 spring boot 默認掃描不到 spring-boot-autoconfigure 的所有配置類 (因為預設只掃描 Main Application Class 的 package)，但是 @SpringBootApplication 的 @EnableAutoConfiguration 會預設掃描 spring-boot-autoconfigure 的所有配置類 它們再依據 conditional annotation 來決定是否要啟用這個配置類 Common Annotations Spring Boot 放棄了 XML 配置，改用 Annotation 配置\nComponent registration @Configuration, @SpringBootConfiguration @Bean 有時候可能會想用第三方套件，此時可能不能修改套件的 code，這時候就可以用 @Configuration 來註冊 bean @Controller, @Service, @Repository, @Component 三層式架構 @Controller 用來處理請求 @Service 用來處理業務邏輯 @Repository 用來處理資料庫操作 @SpringBootApplication 由以下組成 @SpringBootConfiguration @EnableAutoConfiguration @ComponentScan Web @RestController @Controller + @ResponseBody @RequestMapping 設置 route Method @GetMapping @PostMapping @PutMapping @DeleteMapping @PatchMapping 取得參數 @RequestParam 取得 url 中的參數 @RequestBody 取得 request body 根據欄位名字調用對應的 setter @RequestHeader 取得 header @PathVariable 取得 route 中的參數 @Scope mode singleton 預設，共用一個 instance prototype 每次注入都創建新的 instance 可以用 proxy.mode = ScopedProxyMode.TARGET_CLASS，會變成每次調用 method 都創建新的 instance prototype 的元件生出後，spring 不會再管理，要自己管理生命週期，相當於 new 出物件的替代作法 預設是 lazy initialization request 每個 request 都有一個獨立的 instance request 指的是 HTTP request，從進入 controller 到離開 controller session 每個 session 都有一個獨立的 instance session 指的是 HTTP session，從進入 controller 到離開 controller Conditional Annotations 條件成立則觸發指定行為 ConditionalOn example ConditionalOnClass 如果 classpath 有指定的 class 才會觸發 ConditionalOnMissingClass 如果 classpath 沒有指定的 class 才會觸發 ConditionalOnBean 如果容器中有指定的 bean 才會觸發 ConditionalOnMissingBean 如果容器中沒有指定的 bean 才會觸發 Scenario 如果有某個 dependency，則創建某個 bean Property Binding 把任意 Bean 的 property 與配置文件 (application.properties) 中的 property 綁定 annotations @ConfigurationProperties prefix @EnableConfigurationProperties 如果 class 只有 @ConfigurationProperties，沒有 @Component，需要加這個 annotation 用在第三方 package 上，因為默認掃不到第三方的 @component Java JSON Data Binding 在 Java POJO 和 JSON 之間轉換 Spring 用 Jackson 來做轉換 Jackson 會 call getter, setter 來轉換 alias mapping marshalling serialization 輔助工具 Spring boot devtools Hot reload Spring Boot Actuator 公開用來 monitor 的 endpoint endpoints 都有固定前綴 /actuator /health 查看應用程式的 status /info 查看應用程式的 info /beans 查看所有 bean Logging Logging 選擇\nLogging API JCL SLF4J (Simple Logging Facade for Java) jboss-logging Logging implementation Logback Log4j2 JUL (java.util.logging) Spring Boot 預設使用 Logback 和 SLF4J spring-boot-starter 引用了 spring-boot-starter-logging\nLog Format Default example 1 2024-05-06T19:21:40.751+08:00 INFO 22932 --- [demo] [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat started on port 8080 (http) with context path \u0026#39;\u0026#39; 時間, 日誌等級, pid, 分割符, thread, logger, message Log Level Type (由低到高) ALL TRACE 一般不用 DEBUG INFO WARN ERROR FATAL OFF 會 print 出比設定的等級高的 log Log Configuration logging.level.*\n設定不同 package 的 log 等級 1 logging.level.com.example=DEBUG logging.group.\n把多個 package 放在一組，可以統一設定 預設有 web, sql 組 logging.file\n.name 檔名 歸檔 and 切割\n歸檔 每天單獨存 .logback.rolllingpolicy.file-name-pattern 切割 超過指定大小就切割 .logback.rolllingpolicy.max-file-size Filter 實做 javax.servlet.Filter，就能註冊為 spring 的 filter OncePerRequestFilter 保證一次 request 只會執行一次 doFilterInternal chain.doFilter(request, response) 這行之後代表後面的 filter 都執行完了 如果只有一個 filter，就代表 controller 執行完了 shouldNotFilter 可以設定不要執行的 url pattern 註冊 Filter 流程\n設定 @Configuration 加到 Bean \u0026lt;option\u0026gt; setUrlPatterns 只有符合 url pattern 的 request 才會經過這個 filter \u0026lt;option\u0026gt; setOrder 決定 filter 的順序 如果 filter 要取得 request 和 response 的內容，可以用 ContentCachingRequestWrapper 和 ContentCachingResponseWrapper 重新包裝\n因為原本的作法是用 stream 讀取資料，只能讀一次 @WebFilter\n屬於 Java servlet 而非 Spring 要在 application 補上 @ServletComponentScan 可以直接註冊 filter Spring Security 名詞 Authentication 認證 檢查是不是系統的使用者，以及是哪個使用者 Authorization 授權 檢查使用者有沒有權限做某件事 流程 filter chain\nexample UsernamePasswordAuthenticationFilter 檢查使用者名稱和密碼 ExceptionTranslationFilter 處理例外 FilterSecurityInterceptor 檢查授權 authorizeHttpRequests 設定哪些 request 需要什麼權限 example: JWT 驗證流程\n先透過 filter chain 經過 JWT filter 透過 UserDetailsService 取得使用者資訊 驗證使用者資訊 更新 SecurityContextHolder 用來判斷使用者是否已經通過 authentication Configuration @EnableWebSecurity 啟用 web security example 1 2 3 4 5 6 7 8 9 10 11 12 @Configuration @EnableWebSecurity public class SecurityConfig { @Bean public SecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception { http.authorizeHttpRequests((requests) -\u0026gt; { ((AuthorizeHttpRequestsConfigurer.AuthorizedUrl)requests.anyRequest()).authenticated(); }); http.httpBasic(Customizer.withDefaults()); return (SecurityFilterChain)http.build(); } } 把 Spring Boot 預設實作的 fitler chain 的 @Order 拿掉，這是決定誰的優先序高 也把 formLogin 拿掉，就不會有登入頁面 UserDetails 實現 UserDetailsService 的 Bean 可以被用來取得 UserDetails implements UserDetails getAuthorities getUsername getPassword isAccountNonExpired isAccountNonLocked isCredentialsNonExpired isEnabled SecurityContextHolder 用來存放 authentication CommandLineRunner 用來在 Spring Boot 啟動後執行一些任務 會在所有 bean 創建完後執行 JPA Jakarta Persistence API 以前叫 Java Persistence API 只是一個 specifcation，提供一組 interface，需要實作 包含了 Entity, EntityManager, Query, Transaction.. DataSource 用來連接資料庫 定義了連接資料庫的 info EntityManager 用來創建 query 的主要 component 需要 DataSource EntityManager vs JpaRepositroy EntityManager low-level control and flexibility JpaRepository high-level abstraction JPQL 基於 Entity name 和 fields 的 query language 不是基於資料庫的 column 或 table name，是基於 Entity 的名字，要注意區別 Data access object (DAO) common pattern 需要 JPA Entity Manager Config spring.jpa.hibernate.ddl-auto create 每次都會重新創建新的 table update 只會更新 table，不會刪除 create-drop 創建 table，然後刪除 validate 只會檢查 table 是否存在，不會創建 Annotation @Entity, @Table 也要記得寫 getter, setter @Entity 需要 public 或 protected 的無參數建構子 @Table 可選，可以設定 table 名稱 @Transient 不會被序列化，不會被存到資料庫 可用在可以單獨計算的欄位，比如用資料庫的生日可以算出年齡 @Transactional 用在 method 上，代表這個 method 是一個 transaction propagation 用在 method 上，被別的 transaction 調用應該怎麼處理，講 transaction 的傳播 REQUIRED 如果有外層 transaction 就用，沒有就創建一個 REQUIRES_NEW 無論有沒有外層 transaction，都創建一個新的，不受影響 NESTED 嵌套 transaction，如果外層 transaction rollback，內層也會 rollback 如果自己 rollback，外層不受影響 @Column 可以設定欄位名稱 這是可選的，沒有的話就是用變數名稱 @Id Primary key @GeneratedValue strategy AUTO 根據資料庫自動選擇 IDENTITY 用資料庫的 identity column SEQUENCE 用資料庫的 sequence Table 用 underlying table 來確保唯一性 UUID 用 UUID 來確保唯一性 @OneToMany, @ManyToOne 用來設定關聯 cascade 設定當 parent 被刪除時，child 要怎麼處理 CascadeType.ALL parent 被刪除時，child 也會被刪除 CascadeType.PERSIST parent 被刪除時，child 不會被刪除 Spring Data JPA 用特定語法，只需要定好 interface，不用 implement extends JpaRepository\u0026lt;Entity, ID\u0026gt; 第一個參數是 entity 第二個參數是 primary key 的型態 示範 findByXxx 用 XXX 的欄位來查詢 findByXXXLike 用 XXX 的欄位來模糊查詢 JpaRepository @Repository 用來標記 DAO extends JpaRepository\u0026lt;Entity, ID\u0026gt; 第一個參數是 entity 第二個參數是 entity 的 id 的型態 可以自定義方法 遵循命名規則，他會自己轉 SQL 也可以用 @Query 來自定義 SQL \u0026lt;?0\u0026gt; 代表第一個參數，以此類推 Hibernate 用來儲存 java object 到資料庫的框架 ORM Object Relational Mapping 用物件來操作資料庫 一種 JPA 的實作 背後用 JDBC 來操作資料庫 Spring Boot 預設用 Hibernate 來實作 JPA Validation field validation\n@NotEmpty @Min @Max @Valid\n用在 controller 上，才會自動檢查參數 Exception RuntimeException 繼承這個，可以設置 status, message, timestamp @ExceptionHandler 放在 Controller 中的 exception handler method 上，可以處理底下 method 丟出的 exception @ControllerAdvice 類似 interceptor/filter 可以 pre-process request, post-process response 可以用在 global exception handler Testing Integration Test 在 test class 前面的 annotation @RunWith(SpringRunner.class) @SpringBootTest @AutoConfigureMockMvc 測試開始時會在容器中創建 MockMvc 在 test method 前面加的 annotation @Test @Before, @After 在每個測試前後執行，可以用來清空資料庫和設置 header MockMvc 用來模擬 HTTP request example 1 2 3 4 5 6 7 8 9 @Autowired private MockMvc mockMvc; @Test public void test() throws Exception { mockMvc.perform(get(\u0026#34;/hello\u0026#34;)) .andExpect(status().isOk()) .andExpect(content().string(\u0026#34;Hello World\u0026#34;)); } 其他 Lombok @Getter, @Setter 生成 getter, setter @ToString 印出所有變數 @EqualsAndHashCode 生成 equals, hashCode Args @NoArgsConstructor 生成無參數建構子 @AllArgsConstructor 生成所有參數建構子 @RequiredArgsConstructor 只幫 final 變數生成建構子 @Data 同時用 @Getter, @Setter, @ToString, @EqualsAndHashCode, @RequiredArgsConstructor @Value 把所有變數都設成 final 同時用 @Getter, @ToString, @EqualsAndHashCode, @RequiredArgsConstructor 和 Spring boot 的 @Value 撞名 @Builder 生成 builder pattern @Slf4j 生成 log 變數 Jackson ObjectMapper 用來轉換物件和 JSON readValue 把 JSON 轉成物件 用 getter, setter 來判斷欄位 Annotation @JsonIgnore 不轉換 @JsonProperty 指定欄位名字 @JsonUnwrapped 把物件的欄位展開，從巢狀變成平面 @JsonInclude 設定要不要轉換 null 如果設定為 Include.NON_NULL，給 null 的話，就不會轉換 @JsonFormat 設定日期格式 ","date":"2024-05-06T00:00:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/spring-boot-%E7%AD%86%E8%A8%98/","title":"Spring Boot 筆記"},{"content":" 有關名詞\n扇區: 最小的儲存單位 block: 一次讀取的最小單位，是多個連續的扇區 inode OS 用來記錄檔案的 metadata 每個文件的 inode number 是唯一的 可以用 ls -li 來看 inode number inode data 檔案的大小 擁有者 擁有者的 group 權限 修改時間 文件的實體指針，指向 block 格式化分區\n主分區 擴展分區 邏輯分區 默認分區 1~4 給主分區和擴展分區，邏輯分區從 5 開始 /dev/sda1、/dev/sda2 這種就是分區 fdisk\n小於 2TB 的磁碟，可以用 fdisk，但是大於 2TB 的磁碟，要用 parted，且要用 GPT fdisk -l 列出所有分區 fdisk /dev/sda 進入 fdisk n 新增分區 再設置 sector 的起始位置和結束位置 d 刪除分區 t 更改分區的 system id w 寫入並且離開 parted\nparted /dev/sda 進入 parted mklabel gpt 可以把 disk 轉成 GPT GPT 區分主分區和邏輯分區 mkpart primary \u0026lt;start\u0026gt; \u0026lt;end\u0026gt; 創建一個 primary partition，從 start 到 end (MB) 軟硬連結\n軟連結 ln -s \u0026lt;source\u0026gt; \u0026lt;destination\u0026gt; 如果刪除軟連結的檔案的話，不會影響原本的檔案 源文件刪除後，軟連結失效 支持資料夾 支持跨文件系統 硬連結 ln \u0026lt;source\u0026gt; \u0026lt;destination\u0026gt; 一般情況，inode 和檔案名稱是一對一的關係 軟連結 inode 號碼是不一樣的，代表是兩個個體，硬連結 inode 號碼是一樣的 刪除硬連結對源文件沒有影響 刪除源文件對硬連結沒有影響 但是如果刪除所有硬連結，文件的連結數變成 0，則文件會被刪除 不能對資料夾使用 不能跨文件系統 mkfs\n對分區進行格式化文件系統 fsck\nfile system check 檢查和修復文件系統 lsblk\nlsblk -f 列出所有分區的文件系統 vfs\nvirtual file system linux 可能有多種文件系統，在上面有一層 vfs，讓所有文件系統都可以通過一個統一的接口來訪問 Mount\n設備要 mount 才可以使用，給設備提供一個出入口 mount -l 列出所有已經 mount 的設備 -t 指定文件系統，不指定的話，會自動判斷 -o 一些有關於 mount 的參數 async 非同步讀寫，效率高，但是喪失安全性 sync 同步讀寫，效率低，但是讀寫安全 atime/noatime 是否要紀錄文件的訪問時間 -r read-only LVM\nlogical volume manager 把一個或多個硬碟在邏輯上進行合併，可以動態調整大小 硬盤的多個分區，由 LVM 統一管理為 volume group 名詞 PP: physical partition PV: physical volume 通常一個 PV 對應一個 PP PE: physical extends PV 中可以分配的最小單位，同一個 VG 中，所有 PV 的 PE 大小都是一樣的 VG: volume group 創建在 PV 上，可以劃分成多個 PV LV: logical volume 創建在 VG 上，可以動態擴容的分區 LE: logical extends LV 中的基本單位，一個 LE 對應一個 PE 創建 PP 階段 用 fdisk 格式化，修改 system id 為 8e (預設是 83) PV 階段 用 pvcreate, pvdisplay 把 linux 分區轉成 PV 指令 pvcreate /dev/sda /dev/sdb: 把 sda 和 sdb 轉成 PV 適用硬碟和分區 pvs: 查看 PV VG 階段 用 vgcreate, vgdisplay 創建 VG 指令 vgcreate vg1 /dev/sda /dev/sdb: 創建 VG vg1，用 sda 和 sdb vgs: 查看 VG vgextend vg1 /dev/sdc: 把 sdc 加入 vg1 vgdisplay: 查看 VG LV 階段 用 lvcreate, lvdisplay 創建 LV 把 VG 分成多個 LV 也要幫 LV 創建文件系統 指令 lvs: 查看 LV lvextend -L +1000G /dev/vg1/lv1: 把 lv1 增加 1000G ex4 可以不用 umount 還要 resize2fs /dev/vg1/lv1 來調整文件系統大小 可以用 df -h 來檢查 ","date":"2024-04-24T00:00:43+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E7%A3%81%E7%A2%9F%E7%AE%A1%E7%90%86/","title":"磁碟管理"},{"content":"Creational patterns 關於 object creation 的 patterns。\nFactory Method 將不同 Product 定義一個共有的 Interface，並由子類別實作，透過工廠類別來產生實體。\n將建立 Product 的方法獨立出來，符合 Single Responsibility Principle。 可以輕易擴充新的 Product，而不用修改原本的程式碼，符合 Open-Closed Principle。\nAbstract Factory 相比 Factory Method，現在的情境是有多個 Product，而且每次都是使用同一系列的 Product。\nBuilder 對於建構一個複雜且具備多種組合的產品，可以透過建構巨大的建構函式或是覆蓋所有可能的子類別來解決。\n但都存在其問題，要不是大量的子類別，不然就是難以呼叫的建構函式。\n把建立物件的每個 component 獨立出來，並且切成多個可分開執行的 step。\n由 Builder 來負責生出每一個 component，Director 不是必需的，但有需要的話可以讓他幫忙調用 Builder 的 method，好在專案中重複使用。\nPrototype 使用在想要獲得某個對象的 clone 的情境。\n把 clone 的責任交給對象本身，而不是交給 Client。由對象本身提供 clone method。\nSingleton 確保某個類別只有一個 instance，並且提供一個 global access point。\n但是這樣違反了 Single Responsibility Principle，因為除了原本的功能外，還要負責管理自己的 instance。\nStructural patterns 探討如何組裝類別和物件成為更大的結構。\nAdapter 轉換某個對象的 interface 到另外一種 interface，讓另外一個 Object 可以理解他。 就像 XML 要轉到 JSON。\nBrdige 使用在需要在多個 orthogonal (independent) 的維度上擴展類別時的情境。 讓情況從難以計數的子類別數，變成多組功能聯合起來。\n拆成 abstraction (high-level control) 和 implementation (實際工作)， 由 abstraction 來控制 implementation，比如 GUI 來控制底下的 API\nComposite 用在某些層級結構。\n對於 Composite (Container)，不但實現 Component，也提供一個 list 來存放子 component。\n對 Composite 的操作，會被委託給子 component，不需要 client 擔心。\n就像指揮官只需要對高階軍官下命令。\nDecorator 當今天有多種同類型的東西，你可以能會同時用到多種子類別所形成的組合時，就可以用 Decorator。\n比如多種類型的 notification，你可能同時想要 FB 和 TG 的，或是只想要其中一個。 或是多件衣服，有超級多種的穿搭。\n但這是一層層的感覺，具有順序性。 Decorator 和 Component 都繼承同一個 interface。 就像是 Data data = new Encrypt(new Compress(new FileData()))。\n存在很難從 stack 中刪除特定 decorator 的缺點。\nFacade 為複雜的一堆子系統提供一個 Class，讓 client 可以使用他們關心的功能。 實際怎麼調用 client 無須知道。\n容易形成 god object。\nFlyweight 對於大量類似的物件，為求節省記憶體而誕生的 pattern。\n把物件的內容分成 intrinsic 和 extrinsic，intrinsic 是不會改變的 (unique)，而 extrinsic 是會改變的 (repeating)。\n讓 extrinsic 的東西用同一塊記憶體。\nProxy 用在多個服務想要調用某個重量級資源的情境下。\n存在多種 proxy 的應用類型，比如 cache 機制來加速資源的存取，並減少系統資源消耗。\nBehavioral patterns Chain of Responsibility 對於一系列檢查的情況，可以用這種作法，有兩種形式：\n一路檢查，檢查失敗則中斷請求。 每個 Handler 自行決定要不要處理該請求，要的話則不會往下傳。 這樣可能會最後沒人處理 就像網頁點擊事件，一層層元素往下問。\nCommand 把請求獨立出來，讓該請求可以被用作參數、佇列、撤銷行為等。\n比如多種不同的按鈕背後都執行同一個存檔功能。存檔就可以作為 command 獨立出來。 背後再根據這個 command 實施對應的業務邏輯。\nIterator 用來需要遍歷集合中元素的情境，把不同種類的遍歷行為細節隱藏起來。\n提供多種不同的 iterator，但遵循同一種 interface，讓使用者可以根據需要選擇 iterator。 對於不關心用哪種 iterator 的使用者，也能受益於 iterator 的 interface，而不必耦合於特定的演算法。\nMediator 禁止多個 component 間的直接溝通，迫使他們透過 mediator 來溝通，避免複雜的關係。 所有人只能透過 notify mediator 來溝通，mediator 根據 sender 和 event，來做出相應處理。\nMemento 讓你可以儲存和復原到先前的狀態。\n讓要儲存的對象自己生成 snapshot。\n建議存在名為 momento 的 special object，這個 object 不能讓除了 producer 外的其他 object 直接存取。 其他 object 只能透過 limited interface 來取得 metadata。\n這些限制讓 momento 可以交給其他 object 來管理，稱為 caretaker。\nObserver 定義 subscription 機制。\n有 interesting state 的 object 稱為 subject，但由於他也會通知其他人，所以又稱為 publisher。追蹤它的人稱為 Subscriber。\nState 用在類似 Finite-State Machine 的情況。\n該 pattern 把每個 state 獨立成一個 Class，把實際的行為委託給 state，而不是由 context (原始物件) 來控制。Context 只管切換 state。\nStrategy 把不同實現方法的演算法定義為遵循同一個 interface 的類別，讓使用者可以根據需要選擇演算法。\nTemplate Method 把演算法拆成多個步驟，讓子類別可以覆寫其中的步驟，但不改變演算法的結構。\nVisitor 讓我們可以把演算法從執行他們的 object 中分離出來。\n假設我們要對一堆繼承 client 屬性的公司新增 sendEmail 功能，如果我們在 client 新增 sendEmail 並且 override 每個子 class，就會違反 Single Responsibility Principle 和 Open-Closed Principle。\n要利用 Double-Dispatch，讓 Object 本身選擇該用的演算法。\n雖然這樣依然會修改到子 class，但這屬於微不足道的改變，而且可以讓之後新增的一些功能不用再去修改這些子 class。\n","date":"2023-10-10T00:00:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E8%A8%AD%E8%A8%88%E6%A8%A1%E5%BC%8F-desing-pattern/","title":"設計模式 Desing Pattern"},{"content":"Union-Find (DSU) 不同條件下的時間複雜度 待補 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 int find(int x) { if (f[x] == x) return x; else return f[x] = find(f[x]); } int merge(int x, int y) { f[find(x)] = find(y); } int main() { for (int i = 1; i \u0026lt;= n; i++) f[i] = i; x = find(x); y = find(y); if (x != y) { merge(x, y); } } Trie 1 2 3 4 5 6 7 8 9 10 11 class Node { public: int cnt; int id; Node* nxt[26]; Node() { cnt = 0; for (int i = 0; i \u0026lt; 26; i++) nxt[i] = nullptr; } }; Segment Tree 單點修改線段樹 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 #define pl(x) (x * 2 + 1) #define pr(x) (x * 2 + 2) void build(int index, int l, int r) { if (l == r) { tree[index] = arr[l]; return; } int mid = (l + r) / 2; build(pl(index), l, mid); build(pr(index), mid + 1, r); tree[index] = tree[pl(index)] * tree[pr(index)]; } void change(int index, int q, int l, int r, int \u0026amp;value) { if (l == r) { tree[index] = value; return; } int mid = (l + r) / 2; if (mid \u0026gt;= q) change(pl(index), q, l, mid, value); else change(pr(index), q, mid + 1, r, value); tree[index] = tree[pl(index)] * tree[pr(index)]; } void query(int index, int ql, int qr, int l, int r, int \u0026amp;ans) { if (ql \u0026lt;= l \u0026amp;\u0026amp; r \u0026lt;= qr) { ans *= tree[index]; return; } int mid = (l + r) / 2; if (ql \u0026lt;= mid) query(pl(index), ql, qr, l, mid, ans); if (mid \u0026lt; qr) query(pr(index), ql, qr, mid + 1, r, ans); } ","date":"2023-08-29T00:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E8%B3%87%E6%96%99%E7%B5%90%E6%A7%8B%E7%AD%86%E8%A8%98/","title":"資料結構筆記"},{"content":"Sorting Merge Sort 一直拆分兩邊最後再輪流 merge 起來，merge 時看兩邊開頭誰最小，依序放 都是 $O(nlogn)$ stable not in-place Quick sort 選定一個 pivot，用兩個指針從兩邊開始往中間找。當左指針找到比 pivot 大的數值，右指針找到比 pivot 小的數值後交換。直到兩個指針相遇，再把 pivot 換到中間，繼續兩邊處理\n最差會到 $O(n^2)$，平均 $O(nlogn)$\n選 pivot\n隨機選 Median of Three 選開頭、中間和結尾的中位數 Other Binary Exponentiation 快速冪 1 2 3 4 5 6 7 8 9 int qpow(int x, int m) { int ans = 1; while (m) { if (m \u0026amp; 1) ans *= x; x *= x; m \u0026gt;\u0026gt;= 1; } return ans; } Discretization 離散化 1 2 3 4 5 sort(vec.begin(), vec.end()); vec.resize(unique(vec.begin(), vec.end()) - vec.begin()); for (int i = 0; i \u0026lt; vec.size(); i++) { val[i] = lower_bound(vec.begin(), vec.end(), val[i]) - vec.begin(); } Ternary Search 三分搜 1 2 3 4 5 6 7 8 9 10 11 l = -10000.0; r = 10000.0; while (r - l \u0026gt; eps) { ml = (r - l) / 3.0 + l; mr = (r - l) * 2.0 / 3.0 + l; if (f(ml) \u0026gt; f(mr)) { l = ml; } else { r = mr; } } ","date":"2023-08-27T00:09:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E6%9C%AA%E5%88%86%E9%A1%9E%E6%BC%94%E7%AE%97%E6%B3%95-%E8%B3%87%E6%96%99%E7%B5%90%E6%A7%8B%E7%AD%86%E8%A8%98/","title":"未分類演算法 \u0026 資料結構筆記"},{"content":"Floyd-Warshall 1 2 3 4 for (int k = 0; k \u0026lt; nodeCount; k++) for (int i = 0; i \u0026lt; nodeCount; i++) for (int j = 0; j \u0026lt; nodeCount; j++) DP[i][j] = min(DP[i][j], DP[i][k]+ DP[k][j]); dijkstra 時間複雜度 $O((V+E)*log(E))$ 最差每條邊都要插入 heap 要取出 V 個點 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 class cmp { public: bool operator()(edge a,edge b) { if(a.weight\u0026lt;b.weight) return true; return false; } }; dis[a] = 0; priority_queue\u0026lt;edge, vector\u0026lt;edge\u0026gt;, cmp\u0026gt; pq; pq.push({a, 0}); while (!pq.empty()) { edge u = pq.top(); pq.pop(); if (!vis[u.to_node]) { vis[u.to_node] = 1; for (auto i : mp[u.to_node]) { if (dis[i.to_node] \u0026gt; dis[u.to_node] + i.weight) { dis[i.to_node] = dis[u.to_node] + i.weight; pq.push({i.to_node, dis[i.to_node]}); } } } } Topological Sorting 記得確認是不是 Directed Acyclic Graph BFS 是沒有前繼節點優先，DFS 是沒有後繼節點優先 用 BFS 的話就是把入度為 0 的點加入 Queue，一直維護該 Queue 1 2 3 4 5 6 7 8 9 10 void dfs(int u) { if (!vis[u]) { vis[u] = true; for (auto j : edge[u]) dfs(j); toposort.push_back(u); } } for (int i = 1; i \u0026lt;= n; i++) dfs(i); reverse(toposort.begin(), toposort.end()); 樹的直徑 兩次 DFS，第一次找到離任意點最遠的點，第二次從該點出發找到離他最遠的點，這兩個點之間的距離就是樹的直徑。\nLowest Common Ancestor 待補 Eulerian path 歐拉路徑 每條邊只能被訪問一次（一筆畫問題） 條件 除了兩個點外，其他都得為入度==出度。另外兩個點，最多有一個出度要比入度大一，最多有一個入度要比出度大一。（只能有 0 或 2 個奇點） 須為連通圖 視作無向圖的時候是否可以連到每個點 Matching Hungarian Algorithm 待補 最小點覆蓋等等 待補 ","date":"2023-08-27T00:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E5%9C%96%E8%AB%96%E7%AD%86%E8%A8%98/","title":"圖論筆記"},{"content":"簡介 Meta 在 2015 年公開的 API Query Language 常被用來和傳統的 REST API 比較，具備查詢更加靈活等特性 有在使用的公司 Facebook GitHub Twitter \u0026hellip; 和 REST API 的主要差別 Single Endpoint\n和 REST API 對於不同 resource 需要不同 endpoint 不同，GraphQL 對於所有 resource 都是從同一個 endpoint 進行存取 但 GraphQL 不能輕易地用 HTTP caching，因為現在只剩一種 URL 了 解決 Under-fetching 和 Over-fetching 問題\nUnder-fetching\n一個 API call 沒辦法取得所有想要的資料，需要多次 API call 假如要用 RESTful API 取得一個文章的作者，可能得先取得文章，再取得作者，這樣就需要兩次 API call 但 GraphQL 可以在一次 API call 中取得文章和作者，透過 nested query Over-fetching\n一個 API call 取得的資料比想要的還多，造成資源浪費 GraphQL 可以透過 query 定義只想取得的欄位 使用 和 RESTful API 不同，需要特別架個 GraphQL server，可以考慮用 Apollo Server\n要定義不同 Data type 的 schema、relationship，以及寫對應不同 query 的 resolver\nQuery 可能會是長這樣的東西\n1 2 3 4 5 6 7 8 9 10 11 query postQuery($id: ID!) { post(id: $id) { id title content author { id name } } } Mutation 新增、修改、刪除資料都屬於這塊\n1 2 3 4 5 6 7 8 9 10 11 query addPost($post: AddPostInput!) { addPost(post: $post) { id title content author { id name } } } ","date":"2023-08-22T00:00:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/graphql-%E7%B0%A1%E4%BB%8B/","title":"GraphQL 簡介"},{"content":"Use Cases Cache 把常用的資料回傳，省略長時間的 IO 操作 Shared Session 在 stateless server 間共享 session Distributed lock 用在程式間想共用某種資源的時候 用 setnx (set if not exists) atomic Rate Limiter 用 increment 和 expiration 實現 快取常見策略 cache aside 先問 cache，沒有的話再問 db，並把 db 回傳的資料放到 cache read through client 只能存取到 cache，如果沒資料，cache 會去 db 拿資料 write through client 寫資料時，cache 會留一份資料，並把資料寫到 db write behind 和 write through 很像，但是不會立即寫到 db，會等到有更多的資料時，才一次寫到 db Feature NoSQL In-memory Key-Value Basic Command redis-server default port: 6379 redis-cli Access data set \u0026lt;key\u0026gt; \u0026lt;value\u0026gt;\nPretty much everything stored in Redis is going to be a type of string by default get \u0026lt;key\u0026gt;\ndel \u0026lt;key\u0026gt;\nexists \u0026lt;key\u0026gt;\nkeys \u0026lt;pattern\u0026gt;\nfind keys with certain pattern keys * get all keys flushall\nget rid of everything Expiration ttl \u0026lt;key\u0026gt;\nshow time to live \u0026ldquo;-1\u0026rdquo; for no expiration \u0026ldquo;-2\u0026rdquo; already expired expire \u0026lt;key\u0026gt; \u0026lt;second\u0026gt;\nsetex \u0026lt;key\u0026gt; \u0026lt;seconds\u0026gt; \u0026lt;value\u0026gt;\nset with expiration Data Structure List lpush/rpush \u0026lt;key\u0026gt; \u0026lt;value\u0026gt; lrange \u0026lt;key\u0026gt; \u0026lt;start index\u0026gt; \u0026lt;end index\u0026gt; \u0026lt;end index\u0026gt; can be -1 lpop/rpop \u0026lt;key\u0026gt; Set sadd \u0026lt;key\u0026gt; \u0026lt;value\u0026gt; smembers \u0026lt;key\u0026gt; srem \u0026lt;key\u0026gt; \u0026lt;value\u0026gt; remove Hash Key-value in Key-value\nhset \u0026lt;key\u0026gt; \u0026lt;field\u0026gt; \u0026lt;value\u0026gt; hget \u0026lt;key\u0026gt; \u0026lt;field\u0026gt; hgetall \u0026lt;key\u0026gt; get everything about \u0026lt;key\u0026gt; hdel hexists \u0026lt;key\u0026gt; \u0026lt;field\u0026gt; Redis doesn\u0026rsquo;t support nested hash struct 刪除過期 key 定期刪除 在固定間隔時間隨機抽 key 檢查並刪除\n惰性刪除 在訪問 key 的時候發現過期就刪除\nmaxmemory-policy (Eviction) 可以設定這些 policy，在記憶體依然額滿的情況下做對應的處理\nnoeviction allkeys-lru allkeys-lfu volatile-lru volatile-lfu allkeys-random volatile-random volatile-ttl 快取情境問題 快取雪崩 Cache Avalanche 某個時刻大量 cache 失效，使資料庫需要承擔很大的流量。 解法 幫 cache 加上額外的隨機過期時間 快取擊穿 Hotspot Invalid 某個 hotspot 的 cache 失效，使大量請求跑到資料庫 解法 讓 hotspot 永不過期 查詢資料庫的部分加上 lock 快取穿透 Cache Penetration client request 不存在的資料，因為同時不存在於 cache 和資料庫中，所以直接跑到資料庫 解法 在 application 先過濾掉非法請求 Bloom Filter 布隆過濾器 Persistence RDB 固定時間對所有資料做快照，memory dump 出來 recovery 比 AOF 快 save、bgsave AOF 紀錄操作流程 檔案比較肥 Rewrite 當 AOF 太大，Redis 會生一個新文件取代舊的，用最少操作生出目前的資料\n混合 在 AOF 重寫的時候也利用 RDB 前面是 RDB，後面是 AOF\nAvailability 主從同步 一主多從，把讀取壓力分擔到 slave 上\n哨兵模式 Sentinel 會有哨兵不斷地 Ping 主從伺服器，確認是否有異常\n如果哨兵是集群，有哨兵檢測到異常，會判斷某伺服器主觀下線，當有一定數量的哨兵投票認為伺服器不可能用，就會變成客觀下線，進行 failover\nCluster 分擔寫入壓力\nRedis 有 16384 個 slot，透過 hash 分配 key 到不同的 slot\n預設會另外用 port 16379 來讓節點間溝通\n可以混和主從同步達到高可用\n","date":"2023-06-05T00:00:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/redis/","title":"Redis"},{"content":"Hexagonal Architecture 也稱為 Ports and Adapters Architecture 把軟體分為兩個部分 內部部分 包含 domain logic 會先被開發，並且不會受到外部系統的影響 外部部分 包含所有的 depending layers，不屬於你的軟體的部分，比如 UI、DB、或是你用的 framework Ports 一個 interface，定義了一個外部系統可以使用的方法 Adapters Primary Adapter 這個 adapter 會透過實現 input port 來達成 use case Secondary Adapter 這個 adapter 會實作 output port，並且被 domain logic 調用 Clean Architecture 希望讓 domain logic 與其他部分分離，好讓其他部分應用新技術的時候不會影響到。 將軟體分為不同的層次，並且讓這些層次互相獨立。dependency 只能往內部移動，不會往外部移動。 透過 DIP (Dependency Inversion Principle) 來達到這個目標。 DIP 高層次模組不應該依賴低層次模組，兩者都應該依賴抽象。 抽象不應該依賴細節，細節應該依賴抽象。 在常見的三層架構中，常會見到 Presentation Layer、Business Logic Layer、Data Access Layer 這三層的依賴關係是 Presentation Layer -\u0026gt; Business Logic Layer -\u0026gt; Data Access Layer Clean Architecture 則是會讓所有都依賴於 Business Logic Layer 優點 因為 domain logic 保持獨立，許多部分可以換新技術而不影響到 domain logic 可以單獨替換掉 adapter 讓實作 dependencies 的部分可以被延遲到最後，因為 domain logic 不會依賴於他們，所以可以用 mock 來測試 domain logic 元件 Entities 核心的 Object，帶有 data 同時也包含 enterprise business rules 比如一個帳號的 entity 可能包含帳號的名稱、密碼、以及驗證密碼的方法 Use Cases 描述 application business rules，會再調用不同 entity 的 enterprise business rules Interface Adapters 這裡會把 data 從最適合的格式轉換成 domain layer 可以使用的格式 Frameworks and Drivers 這裡會包含所有的 frameworks 和 infrastructure ","date":"2023-05-22T00:00:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/clean-architecture/","title":"Clean Architecture"},{"content":"前言 軟體要對 domain 做 Modeling，呈現出 domain 裡的核心概念，才能滿足使用者需求，因此不乏與領域專家的討論\n寫這篇的時候我還沒嗑完 Eric 的聖經，可能嗑完了之後會回來修改\n通用語言 Ubiquitous Language 鑒於程式開發人員與領域專家熟悉知識的差異，會產生交流困難\n因此領域專家和開發團隊要訂定共同的語言，並且盡可能少用自己知道的術語\nUML UML 適合用在小型模型上，它擅長表達類別間的關係，但對於抽象概念卻沒那麼好傳達\n因此用 UML 建構模型時，理想上要添加額外的文字，傳達一些圖所不能表達的 behavior 和 constraint\n並且不能一次寫過於複雜，而是分塊處理\nLayered Architecture 分為四個概念層，只會往下調用，可能會跨層\n可以達到關注點分離 (separation of concerns)，提高各個方面的 cohesive\nUser Interface (Presentation Layer) 呈現給 user 的 UI，User 可能是另一個系統 Application Layer 不含 bussiness logic，指揮表達領域概念的物件來完成任務 Domain Layer 有關 domain 的資訊都在這裡，業務邏輯在此處理 表達業務概念、狀態、規則 劃分出這層是 Model-Driven Design 的關鍵 Infrastructure layer supporting library 保存業務狀態的技術細節在此實作 為前三個 layer 服務 Entity 具備 identity identity 在 status 經過改變後依然不變 追蹤 entity 需要高成本 mutable Value Object 沒有 identity 只關心 obejct 的 value 可以輕易創建丟棄 immutable (不變的) 如果想修改數值就創新的 可被共用 Service 有些動作不屬於某個 Entity 或 Value Object，因為它是跨物件的 Stateless 每個請求不互相影響 Aggregate 把複雜關聯的物件圈在一起考量 確保 consistency 和 inveraints consistency (一致性) 相關物件的資料一致 invariants (不變量) 資料改變時要維護的規則 Aggregate root 具備 global identity，其他內部 entity 只有 local identity 通常是 entity 擔任 外部只能存取它，不能存取 aggregate 的其他 entity 或 value obejct Factory 若創建 aggregate、entity、value object 的過程很複雜，或是涉及專業知識，就該用 factory 包起來 對於不複雜的情況，或是想控制更多細節，可以只依賴於簡單的建構函式 Repository 如果大家都直接存取資料庫的各種物件，會破壞原本精心設計的結構，破壞封裝性\nRepositoy 用來存取物件，封裝了資料庫操作\nDomain event Domain 中重要的事情 可以用在其他物件和 aggrgate 訂閱，讓 aggregate 通知他們 domain event 的發生 Anti-Pattern 應該避免的情形 Smart UI 超肥的萬能 UI Anemic Domain Model 貧血模型 只有 getter 和 setter，沒有業務邏輯的模型 Subdomain 把 domain 切分成小塊，理想上 subdomain 和 bounded context 有 one-to-one 的關係\nTypes core subdomain 和其他競爭者相比不同的部分，最核心的業務，比如搜尋引擎中的搜尋演算法 generic subdomain 大家都會弄的部分，比如登入系統 supporting subdomain 用來輔助 core subdomain 的部分，比如篩選網頁 Bounded Context 劃出 boundary，確保 boundary 內用的概念、規則皆一致 同個名詞可能出現在不同的 context，但有不同意思 Context Map 描述 BC 和 BC 間的關係\n上下游 (U/D) 上游提供下游 (下游依賴上游) Shared Kernel 兩個 BC 共用的部份 違反 BC 的基本原則，是一種例外設計 Customer-Supplier 一個子系統重度依賴另一個子系統 Conformist Customer 完全配合 Supplier Partnership 兩個 BC 互相合作，沒有以誰為主 一起成功或一起失敗 Anticorruption Layer (ACL) 開發系統和外部系統的中間層 可能出現在調用 legacy system 常用到 Facade 和 Adapter Open Host Service (OHS) 如果外部子系統要給一堆用戶端子系統調用，就得在所有用戶端子系統搞 ACL 外部系統做為服務提供，常會搭配 Published Language (PL) PL 是協定傳送資料的格式，比如 XML、JSON 或是 Protocol Buffer Pratical DDD The strangler migration 透過 Facade，把一些服務慢慢移植給新系統，最後取代 legacy ","date":"2023-05-22T00:00:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E9%A0%98%E5%9F%9F%E9%A9%85%E5%8B%95%E8%A8%AD%E8%A8%88-domain-driven-design/","title":"領域驅動設計 Domain-Driven Design"},{"content":"簡介 Timer 和 Counter 的差別是 Timer 是定期的數數\nTiming functions 定期對 CPU 發送 interrupt 產生準確時間的 delay 產生 pulses 或 periodic waveforms PWM 量測 duration STM32 Timer / Counter 從 Basic 到 Advanced，追加更多功能\nBasic TImer (Simple Timer)\n16 bit auto-reload register programmable pre-scaler 可以 output 到 DAC update event CNT=ARR(up-count) CNT=0 (down-count) reset CNT to 0 or ARR set UIF flag in status register update event interrupt 如果 enabled (UIE=1) UIF 被設置的時候發送訊號 $T_{EVENT}=Prescale \\times Count \\times T_{CK \\_ INT} \\\\ =(PSC+1)\\times(ARR+1)\\times T_{CK \\_ INT}$\n$T_{EVENT}$ 是兩次事件發生的間隔時間 PSC 是設定 (數值 - 1)，所以 Prescale 是 1 的話，要設 0 Control register\nCEN 是否啟用 counter UDIS 是否啟用 update event URS 設定產生 update event 的 source OPM 是否只算一次 counter 就停 ARPE 關於中途改 ARR 的 reload 設定 UIF interrupt General Purpose Timer\n16-bit or 32-bit auto-reload register use for a variety of puposes measuring lengths of input signals (Input Capture)\nInput Capture 測量 pulse width (高電位的時間) 或 period (一個週長) generating output waveforms (Output Compare and PWM Generation)\none pulse mode output Up to 4 independent channel Interrupt / DMA generation event counter overflow / underflow counter initialization trigger event input capture output compare Advanced Control Timer\n16-bit auto-reload register 特殊 timer\nlow power timer 可以用在比如睡眠狀態 補充 24 bits system timer (SysTick) reload 在 overflow 時回到 register 設定的數值 STM32 Timer 差異 可以去 Datasheet 找每個 Timer 的功能\nCounter resolution\n16/32 bit 決定能從 0 數到多少個 Counter Type\n決定能往上數或往下數或都可以 Prescaler factor\n可以把進來的數字先除以某個數，減緩速度 DMA request generation\n能否用 DMA access 記憶體 Capture / Compare channels\n一個 Timer 可能可以發多個訊號出去，並且經過多個 Compare register，比對不同 event functions Compare 和比對 register，比到了就送 event Capture 紀錄下 channel 的值 Complementary output\n有些馬達控制需要反向波，就要這個 Max interface clock (MHz) and Max timer clock (MHz)\n進去和出來的速度 System Clock - Clock tree Timer 源頭就是 clock\n有四種來源幫忙驅動 system clock (SYSCLK)\nHSI16 (high speed internal) 16 MHz RC oscillator clock MSI (multispeed internal) RC oscillator clock HSE (high speed external) oscillator clock, from 4 to 48 MHz PLL clock SYSCLK 往下接到 AHB，再接到 APB1、APB2\nFlash Read Access Latency 調整 clock 也要調整這部分 Register TIMx_CR1 control register TIMx_PSC 設定 prescale TIMx_ARR auto-reload register ","date":"2023-05-04T01:32:54+08:00","permalink":"https://roykesydon.github.io/Blog/p/stm32-timer-/-counter-%E4%BB%8B%E7%B4%B9/","title":"STM32 Timer / Counter 介紹"},{"content":"Memory Map CPU 對 I/O 操作方法\nPort I/O 用特殊 CPU 指令 I/O 設備和記憶體不共享地址空間 Memory-Mapped I/O I/O 設備和記憶體共享地址空間 像一般控制記憶體 這塊記憶體具有四個責任\nCommand Status Output Data Input Data GPIO 結構 GPIO mode Open-Drain 由外部電壓決定輸出電壓 Output Register 是 0 會啟用 N-MOS，1 的話靠外部電壓推 好處是外部電壓可以自己決定 Push-Pull 由內部電壓決定輸出電壓 Output Register 是 0 或 1 會決定啟用 N-MOS 或是 P-MOS 有關 Register Clock enable register AHB2 peripheral clock enable regisetr (RCC_AHB2ENR) Control register GPIO port mode register GPIO port output type register GPIO port output speed register GPIO port pull-up/pull-down register Data register Output Input 使用 GPIO 先去 Memory map 找 Boudary address\n根據 table 確認要設置的數值\n設定 RCC enable\n把上面說的各種 Control register 設定好\n比如 PUPDR BSRR\n修改 ODR 會一次改到整個 GPIO port，若只要改某個 pin，可以用 BSRR Delay\nCPU 4 MHz 1 cycle = 0.25$\\mu$S 可以查每個組合語言指令要幾個 cycle 機械按鈕會有 Bouncing\nDebounce Hardware method 加上濾波電容 Software method 讀取後等待一段時間才再次讀取 連續讀取 N 次，看數值是否穩定改變 7-Segment COM 分共陽、共陰\n8 個七段顯示器就要吃掉 8 * 8 個 GPIO 接腳，可以每次只顯示一個，那只需要 8 個 GPIO 接腳，快速閃過\n也可用 Max 7219 控制，他有三個輸入 DIN、LOAD、CLK\nDIN 輸入資料 CLK 上升的時候採樣，最多 10 MHz LOAD(CS) 採用最後輸進去的 16 bits 最早的是 MSB ","date":"2023-04-26T01:32:54+08:00","permalink":"https://roykesydon.github.io/Blog/p/stm32-gpio-%E4%BB%8B%E7%B4%B9/","title":"STM32 GPIO 介紹"},{"content":"重構 在不改變軟體行為的情況下，對軟體內部構造進行改善\nCode Smell 也稱 Bad Smell，代表程式碼中需要重構的部分\nDuplicated Code 重複程式碼 在同個 Class Extract Method 在不同 Class Extract Class Long Method 用 Extract Method 拆解過長的 function Long Parameter List Preserve Whole Object 把來自同一物件的資料直接該物件取代 Introduce Parameter Object 把相關的資料包成一個 Object Large Class 一個 Class 有太多 fields / methods / lines Magic Number 特殊數值直接用數字表示，日後修改每個地方都要改 Lack of Comments 加註解的好時機：寫程式前寫上 Switch Statements 可利用「多型 (Polymorphism)」解決 Divergent Change 一個類別有太多改變的原因 盡量讓其遵守 SRP Shotgun Surgery 某個責任被分散到大量的 Class 身上，使修改其時要大量修改 Feature Envy 存取別的 Object 的 Data 的情形比自己的還頻繁 這方法可能應該屬於另一個 Object Data Clumps 常一起出現的資料群應該被單獨抽成一個 Class Primitive Obsession 過度使用基本類別，造成 Shotgun Surgery Message Chains Client 請求 A 物件，A 物件又請求 B 物件 Lazy Class 把冗員類別移除 Temporary Field Instance variable 只有在特殊情形才被使用，應該改為區域變數或參數 Inappropriate Intimacy Classes 間頻繁讀取對方資料 理解程式要同時看懂兩者 Alternative Classes with Different Interfaces 兩個 Class 具有功能相同、命名不同的 function 可汲取共同部分為 Super Class 來解決 ","date":"2023-04-25T14:26:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E9%87%8D%E6%A7%8B-refactoring/","title":"重構 Refactoring"},{"content":"介紹 試用 STM32 UART 功能\n會透過 RealTerm 和 STM32L476RG 溝通，並用 DMA 接收訊息\n根據 User manual，USART2 預設會連接 ST-LINK，要連接外部設備的話要修改 solder bridge\nioc 設置 Connectivity 可以設置 USART2 mode 從 disable 改選 Asynchronous Parameters Settings 可以設置各種資訊 Baud Rate Word Length Parity Stop Bits DMA Setting Add 一個 RX Mode 改成 circular，並打開 memory 的 increment address increment address 是因為資料是用 array 存 circular 是當資料滿了後，會回到 zero position NVIC Setting 設置 DMA 應該就會自動設置一個 interrupt，檢查一下 程式碼 發送\n1 2 uint8_t myTxData[13] = \u0026#34;Hello World\\r\\n\u0026#34;; HAL_UART_Transmit(\u0026amp;huart2, myTxData, 13, 10); 接收\n1 2 3 4 UART_HandleTypeDef huart2; // generated code uint8_t myRxData[20]; HAL_UART_Receive_DMA(\u0026amp;huart2, myRxData, 20); // 在 Init 後，在 main 中執行一次就好 interrupt\n在 hal_uart.c 有\n1 2 3 4 5 6 7 8 9 __weak void HAL_UART_RxCpltCallback(UART_HandleTypeDef *huart) { /* Prevent unused argument(s) compilation warning */ UNUSED(huart); /* NOTE : This function should not be modified, when the callback is needed, the HAL_UART_RxCpltCallback can be implemented in the user file. */ } 當 DMA 滿了就會呼叫這個 function\n實驗 1 2 3 4 5 6 7 8 9 10 void HAL_UART_RxCpltCallback(UART_HandleTypeDef *huart) { /* Prevent unused argument(s) compilation warning */ UNUSED(huart); /* NOTE : This function should not be modified, when the callback is needed, the HAL_UART_RxCpltCallback can be implemented in the user file. */ HAL_UART_Transmit(\u0026amp;huart2, myRxData, 20, 10); } 當 20 個 Bytes 儲存滿了就回傳資訊給電腦\nRealTerm Display 勾選 Half Duplex 發送的訊息會顯示綠色，接收的是黃色 Port 設置 Baud 和其他有的沒的 選 open Send EOL 可以勾選 CRLF 打一些文字後按 Send ASCII 結果 程式碼\n","date":"2023-04-09T01:32:54+08:00","permalink":"https://roykesydon.github.io/Blog/p/stm32-uart-%E5%AF%A6%E9%A9%97/","title":"STM32 UART 實驗"},{"content":"目的 本文會試用 GPIO output / input / interrupt\nGPIO 架構 Output 介紹 在 ioc 那邊選個 pin，選 GPIO_Output\n在左邊欄位 System Core 選擇 GPIO\n有五個欄位可以設定\nGPIO output level\n初始電位 GPIO mode\npush pull 和 open drain 位於架構圖下方那部分，push pull 可以用 PMOS 和 NMOS 來得到高低電位，open drain 會 disable PMOS，讓你可以在外面自己接上拉電阻 GPIO Pull-up/Pull-down\nMaximum output speed\nUser Label\n用完記得 ctrl+s 讓他 generate code\n1 2 3 4 5 6 7 8 9 /*Configure GPIO pin : PtPin */ GPIO_InitStruct.Pin = RED_LED_Pin; GPIO_InitStruct.Mode = GPIO_MODE_OUTPUT_PP; GPIO_InitStruct.Pull = GPIO_NOPULL; GPIO_InitStruct.Speed = GPIO_SPEED_FREQ_LOW; HAL_GPIO_Init(RED_LED_GPIO_Port, \u0026amp;GPIO_InitStruct); /*Configure GPIO pin Output Level */ HAL_GPIO_WritePin(RED_LED_GPIO_Port, RED_LED_Pin, GPIO_PIN_RESET); 1 2 3 4 HAL_GPIO_WritePin(RED_LED_GPIO_Port, RED_LED_Pin, GPIO_PIN_RESET); // 低電位 HAL_GPIO_WritePin(RED_LED_GPIO_Port, RED_LED_Pin, GPIO_PIN_SET); // 高電位 HAL_Delay(1000); //等一秒 HAL_GPIO_TogglePin(RED_LED_GPIO_Port, RED_LED_Pin) 根據架構圖左側，你可以透過修改 BSRR 來修改 ODR，達到修改輸出的效果，請見 Reference Manuals，實際上 HAL_GPIO_WritePin 也是這樣實現的\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 void HAL_GPIO_WritePin(GPIO_TypeDef* GPIOx, uint16_t GPIO_Pin, GPIO_PinState PinState) { /* Check the parameters */ assert_param(IS_GPIO_PIN(GPIO_Pin)); assert_param(IS_GPIO_PIN_ACTION(PinState)); if(PinState != GPIO_PIN_RESET) { GPIOx-\u0026gt;BSRR = (uint32_t)GPIO_Pin; } else { GPIOx-\u0026gt;BRR = (uint32_t)GPIO_Pin; } } Input 介紹 看架構圖上方，用 Schmitt trigger 取得高低電位資料，他有 upper threshold 和 lower threshold，而不是用 single threshold\n1 2 3 4 5 /*Configure GPIO pin : PtPin */ GPIO_InitStruct.Pin = GREEN_LED_INPUT_Pin; GPIO_InitStruct.Mode = GPIO_MODE_INPUT; GPIO_InitStruct.Pull = GPIO_NOPULL; HAL_GPIO_Init(GREEN_LED_INPUT_GPIO_Port, \u0026amp;GPIO_InitStruct); 1 uint8_t green_led_input = HAL_GPIO_ReadPin(GREEN_LED_INPUT_GPIO_Port, GREEN_LED_INPUT_Pin); Interrupt ioc 選個 pin，設定 GPIO_EXTI，這邊我選 B1(PC13)，也就是開發版上的藍色按鈕\n可以選 GPIO mode，這邊選 Falling Edge Trigger，值得一提的是他的設計是上拉電阻，所以這樣不是放開後觸發，是按下後觸發。\nioc 的 System Core 的 NVIC 還要把 EXTI line[15:10] interrupts 給 enabled，然後 Code generation 打開 Generate IRQ handler，還有 Call HAL handler。\n在 stm32l4xx_it.c 裡， 現在會有\n1 2 3 4 5 6 7 8 9 10 void EXTI15_10_IRQHandler(void) { /* USER CODE BEGIN EXTI15_10_IRQn 0 */ /* USER CODE END EXTI15_10_IRQn 0 */ HAL_GPIO_EXTI_IRQHandler(B1_Pin); /* USER CODE BEGIN EXTI15_10_IRQn 1 */ /* USER CODE END EXTI15_10_IRQn 1 */ } 這兩行各別是因為我們剛剛開的功能生的\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 void HAL_GPIO_EXTI_IRQHandler(uint16_t GPIO_Pin) { /* EXTI line interrupt detected */ if(__HAL_GPIO_EXTI_GET_IT(GPIO_Pin) != 0x00u) { __HAL_GPIO_EXTI_CLEAR_IT(GPIO_Pin); HAL_GPIO_EXTI_Callback(GPIO_Pin); } } __weak void HAL_GPIO_EXTI_Callback(uint16_t GPIO_Pin) { /* Prevent unused argument(s) compilation warning */ UNUSED(GPIO_Pin); /* NOTE: This function should not be modified, when the callback is needed, the HAL_GPIO_EXTI_Callback could be implemented in the user file */ } __weak 代表有同名 function 的話，就會採用沒 __weak prefix 的\n所以我們可以在 gpio.c 放下面的程式碼\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #include \u0026lt;stdbool.h\u0026gt; void HAL_GPIO_EXTI_Callback(uint16_t GPIO_Pin) { if(GPIO_Pin == B1_Pin){ static bool prev_val = false; if(prev_val == false){ HAL_GPIO_WritePin(RED_LED_GPIO_Port, RED_LED_Pin, GPIO_PIN_SET); prev_val = true; } else{ HAL_GPIO_WritePin(RED_LED_GPIO_Port, RED_LED_Pin, GPIO_PIN_RESET); prev_val = false; } } } 實驗 設定兩個輸入，一個輸出，一個 interrupt\n當按下按鈕時，切換紅色 LED 的亮滅，並且讓板子上的綠色 LED 輸出和紅色 LED 相反的結果\nB1(PC13、藍色按鈕) 按下去的時候，會發出 interrupt，並讓 RED_LED(PC10) 輸出和上次相反的電位，讓麵包版上的紅色 LED 亮滅，正極那邊接一條杜邦線給 GREEN_LED_INPUT (PC12)，並且 LD2(PA5、板子上的綠色 LED) 會輸出和紅色 LED 相反的結果。\n程式碼\n","date":"2023-04-02T01:32:54+08:00","permalink":"https://roykesydon.github.io/Blog/p/stm32-gpio-%E5%AF%A6%E9%A9%97/","title":"STM32 GPIO 實驗"},{"content":"使用的板子 STM32L476RG\n開發文件 開發前需要先去 ST 官網，根據你的板子載四個重要文件\nDatasheet 上圖是其中的 block diagram\nReference Manuals\nProgramming Manuals\nSchematic\n創建 project File -\u0026gt; New -\u0026gt; STM32 Project Board Selector 搜索 NUCLEO-L476RG，選取並 Next 設置 Project Name，其他不動，Next Copy only the necessary library files，Finish ioc 專案會有個 .ioc 檔，可以透過 GUI 生成設定 pin 的程式碼\n建議 Project Manager 的 Code Generator 勾選 Generate peripheral initialization as a pair \u0026lsquo;.c/.h\u0026rsquo; files per peripheral，開發起來比較方便\nCompile 點選上面的 hammer\nClock Configuration ioc 那邊還可以設置 clock\nExternal clock LSE 和 HSE 是 (Low / High Speed External)，你有 oscillator 的話可以自己弄\n你可以調 sysclk 或 peripheral clock\nProgramming 在 USER CODE section 寫上程式碼 這是由於生成程式碼的機制所致\n選取的部分可以按 F3，看他是從哪邊來的，或看 macro 之類的\n按下 alt + / 會出現自動補全的提示\nDEBUG 上面有個 BUG 符號的東西，旁邊的箭頭可以用 DEBUG 的設定\n又建 STM32 C/C++ Application，可以 New 新設定\nC/C++ Application 那邊選你 compile 的 elf 檔\nDebugger 開啟 ST-LINK S/N，並且掃描，如果你的電腦有接上 MCU，應該會直接找到\n","date":"2023-04-02T00:32:54+08:00","permalink":"https://roykesydon.github.io/Blog/p/stm32cubeide-%E5%9F%BA%E6%9C%AC%E9%96%8B%E7%99%BC%E4%BD%BF%E7%94%A8/","title":"STM32CubeIDE 基本開發使用"},{"content":"Normalization 目的 避免 redundant information 資料重複容易導致資料不一致 避免 anomalies 避免資料不一致 隨著 1NF ~ 5NF，有更多的 safety guarantee\nFunctional Dependency {X} -\u0026gt; {Y}\nX 是 determinant，Y 是 dependent Y is functionally dependent on X (Y depends on X) X functionally determines Y 一個 attribute 的 value 可以決定另一個 attribute 的 value\nex: {playerID} -\u0026gt; {playerName} 這代表 playerID 決定了 playerName 用箭頭表示，左邊是 determinant，右邊是 dependent\n一個 attribute 可以有多個 dependent\nex: {playerID} -\u0026gt; {playerName, playerAge}\n一個 attribute 也可以是多個 attribute 的 dependent\nex: {playerID, itemID} -\u0026gt; {itemName}\n1NF 去除重複性 違反條件 用 row order 傳達資訊 mixing data types in single column 但 relational database 不會讓你這樣做 存在沒有 primary key 的 table repeating groups 同一個 column 有多個數值，或是在同一個 row 存多個同類型的數值 每個 column 的 value 都應該是 atomic ex : player item roy 1 item_1, 4 item_2 star 4 item_4 player item_type1 quantity1 item_type2 quantity2 roy item1 1 item2 4 star item_4 4 2NF 去除 partial dependency 所有的 non-key attribute 都要 depend on 整個 PK 非正式定義，有點細微差異 如果是 composite key，不能 depend on PK 的其中一部分 functional dependency ex: {playerID, itemID} -\u0026gt; {itemName} 違反的例子 ex: playerID itemID itemName 1 1 item_1 1 2 item_2 2 1 item_1 這裡的 PK 是 {playerID, itemID}，但 itemName 只 depend on itemID 3NF 去除 transitive dependency\ntransitive dependency {A} -\u0026gt; {B} -\u0026gt; {C} 考慮到 functional dependency 有遞移性(Transitivity)\nTransitivity {A} -\u0026gt; {B}，{B} -\u0026gt; {C}，則 {A} -\u0026gt; {C} 所有 non-key attribute 都要 depend on the whole key，不能 depend on 其他 non-key attribute\n違反的例子\nex: playerID itemID itemName itemCategory 1 1 item_1 weapon 1 2 item_2 weapon 2 1 item_1 weapon 這裡的 PK 是 {playerID, itemID}，但 itemCategory 只 depend on itemName 這裡的 itemCategory 是 transitive dependency Boyce-Codd Normal Form (BCNF) 3NF 的強化版，又稱 3.5NF 實務中大多做到 3NF 對於每個 functional dependency，左邊的 attribute 都是 super key 違反例子 ex: playerID itemID itemName PlayerName 1 1 item_1 roy 1 2 item_2 roy 2 1 item_1 test 存在至少兩個 functional dependency {itemID} -\u0026gt; {itemName} {playerID} -\u0026gt; {playerName} 但是 {playerID} 和 {itemID} 都不是 super key 拆成三個表就可以解決 4NF 要先符合 BCNF 去除多值依賴(Multivalued Dependency) multivalued dependency 一個表格至少要有 3 個 column 才有可能有 multivalued dependency 對於 {A} -\u0026gt; {B}，如果一個 A 可以對應到多個 B，也可以對應到多個 C，然後 B 和 C 獨立，則有 multivalued dependency 一個 table 中的所有 multivalued dependency 必須依賴於 key 5NF 又稱 Project-Join Normal Form (PJNF) 去除 join dependency join dependency 一個 table 可以表示成其他 table join 起來的結果 如果 JOIN dependency 存在，就拆分多個 table ","date":"2023-03-14T10:26:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/database-normalization/","title":"Database Normalization"},{"content":"UML 類別圖 Relationship Dependency \u0026ldquo;uses-a\u0026rdquo; Association \u0026ldquo;knows-a\u0026rdquo; Composition \u0026ldquo;has-a\u0026rdquo; child 的存在依賴於 parent，若刪除 parent，child 也會隨之刪除 Aggregation \u0026ldquo;has-a\u0026rdquo; child 的存在獨立於 parent，若刪除 parent，child 不會隨之刪除 Inheritance \u0026ldquo;is-a\u0026rdquo; Implementation \u0026ldquo;can-do\u0026rdquo; 實現 interface other features Navigation 當兩個 class 都可以看到對方，就用沒箭頭的關聯線，否則有箭頭 Role Name 類別中的 Attribute Multiplicity 關聯端點上可以寫數量，代表物件個數 Self-Association 同個類別的物件彼此有關係 軟體設計原則 Encapsulate What Varies 把經常改變的程式碼封裝起來，使日後修改時不會影響其他區塊的程式碼 實際使用的情境，可以把常改變的東西放在 interface 後，使日後改變實作時不影響呼叫該 interface 的程式碼 Favor Composition over Inheritance Composition(組合)在很多情境可以取代掉 Inheritance(繼承)，甚至實現 Polymorphism(多型) 只有當 is-a 的情境出現，才用繼承比較好 Composition 使用起來更有彈性 SOLID 設計原則 Single Responsibility Principle, SRP 單一職責原則 A class should have only one reason to change. 可以把一個複雜的 module 拆成多個 Open-Close Principle, OCP 開放封閉原則 You should be able to extend the behavior of a system without having to modify that system. 要可以擴充，同時不修改到原系統 LiskovSubstitution Principle, LSP 里氏替換原則 父類別有的功能，子類別必須遵從，父類別的部分要可以直接替換成子類別 Interface Segregation Principle, ISP 介面隔離原則 No client should be forced to depend on methods it does not use 以 interface 來說，不該讓 module 實現它不需要的功能，可以把 interface 拆小 Dependency Inversion Principle, DIP 反向依賴原則 高階模組不應該依賴低階模組，兩者都應依賴抽象層 Modularity Coupling type Tight coupling Content coupling 一個模組依賴另一個模組的內部運作 ex: 一個模組直接存取另一個模組的變數，假設回傳的數值是公尺，如果另一個模組要修改成公分，就會影響到這個模組 可以用 getter 抽象出 getMeter()，這樣就不會直接存取變數 Common coupling 多個模組共同存取和修改同個 global data ex: 一個模組錯誤修改會導致其他人都壞掉 External coupling 多個模組直接存取同個 external I/O ex: API 要改就會全部都影響到 Medium coupling Control coupling 一個模組影響另一個模組的內部邏輯（比如說透過參數） ex: 參數要改個寫法就會影響一堆模組 Data-Sructure coupling 多個模組共同存取同個 data structure ex: Data structure 要改就會影響到其他模組 Loose coupling Data Coupling 兩個模組 share/pass 同樣的資料 Message Coupling 多個模組間透過 message 或是 command 來溝通 和 control coupling 的差別在於，並沒有去控制某個模組，只是叫他做某件事情 No Coupling 不是好的設計 模組間沒有關聯，或是有個超巨大的模組 Cohesion type Weak cohesion Coincidental cohesion 唯一的關聯是他們在同個檔案 ex: single file program Temporal cohesion 關聯的地方是他們在同個時間點被執行 ex: 「執行 shutdown 相關的活動」 Logical cohesion 活動間可以被歸類在同個 general category ex: Backup Controller，可能有很多地方需要 Backup Medium cohesion Procedureal cohesion command 間存在執行順序 ex: Clean car module 可能包含噴水、填表格、擦乾等等 但是 Clean car module 此處包含了操控財務資料的狀況 Communicational cohesion 所有的 activities 都支援相同的 input/output ex: 提取文章的作者、提取文章的標題、提取文章的內容 Sequential cohesion 某個 activities 的輸出是另一個 activities 的輸入，且具有順序性 Procedureal cohesion 和 Communicational cohesion 的結合 這個沒那麼糟糕 Strong cohesion Functional cohesion Module 只支援只和一個問題相關的 activities Object cohesion 所有的 activities 都只會修改一個 object ","date":"2023-03-08T14:26:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E8%BB%9F%E9%AB%94%E8%A8%AD%E8%A8%88-low-level/","title":"軟體設計 - Low Level"},{"content":"Process Scheduling 可能時機\nrunning -\u0026gt; waiting running -\u0026gt; ready waiting -\u0026gt; ready running -\u0026gt; terminate Process Scheduler\nPreemptive scheduler (Time slice) 可以被搶占 Non-Preemptive scheduler 又稱 cooperative scheduling 只可能出現在時機 1 或 4 Classification fo Processes(related to scheduling)\nInteractive Processes (50 - 150 ms) Batch Processes Real time Processes Hard Soft Classification of Processes(related to CPU usage)\nCPU Bound I/O Bound Standard Scheduling Algorithm FCFS SJF SRTF Priority Based Highest Response Ratio Next Round Robin Virtual RR Multi-Level Queue Scheduler Multi-Level Feed Back Queue Scheduler Rotating Staircase Deadline Scheduler UNIX SVR3 Scheduler 有 32 個 runqueue，每個 runqueue 負責 4 個 priority values\n128 Priority values\n0-49: Kernel 50-127: User $Priority_j=Base_j+CPU_j(i)+nice_j$\nBase: 0-127 $CPU_j(i) = DR * CPU_j(i-1)$ DR = $\\frac{1}{2}$ nice: -20 ~ +19 可以用 nice 和 renice 改 process nice value Schedtool Query \u0026amp; set per process scheduling parameters\nScheduling Policy Real time SCHED_RR SCHED_FIFO Conventional SCHED_NORMAL (default) SCHED_BATCH (CPU intensive) SCHED_ISO (unused) SCHED_IDLEPRIO (low pri jobs) Nice Value (-20 to +19) Static Priority (1-99) CPU affinity process 想運行在某個指定的 CPU 上，不被轉移到其他 CPU，才不會降低指定 CPU 的 cache 命中率 soft CPU affinity hard CPU affinity cpus_allowed 一個用來指定 CPU 的 mask 1 schedtool \u0026lt;PID\u0026gt; ","date":"2023-02-20T21:12:52+08:00","permalink":"https://roykesydon.github.io/Blog/p/process-scheduling/","title":"Process Scheduling"},{"content":"Share information between processes 透過硬碟上的文件溝通 超慢 透過 kernel buffer 滿快的，但這樣要一直在 user mode 和 kernel mode 來回切換，因為kernel buffer 在 kernel space 透過 shared memory region shared memory region 在 user space Mechanisms Signals\nCommunication\nData transfer Byte Stream Pipes FIFOs(Named Pipes) stream sockets Message Passing SystemV MsgQ POSIX MsgQ datagram sockets Shared Memory SystemV S.M POSIX S.M Memory Mapping anonymous memory mapping memory mapped file Synchronization\nPipes Related processes parent-child sibling Executing on same machine 用法 cmd1 | cmd2 cmd1 不是輸出到 stdout，而是由 kernel 維護的 buffer，也就是 pipe cmd 不是從 stdin 獲取輸入，而是從 pipe 獲取 cmd1 | cmd2 | \u0026hellip; | cmdn Named Pipes / FIFOs Related / Unrelated processes\nExecuting on same machine\ncreat a FIFO\ncommands mkfifo mknod 嘗試寫入或讀取 FIFO 時，會被 redirect 到 pipe\nSignal Handling Signal Used by OS to notify running process some event has occured without the process needing to pull for that event process 收到 signal 後會先停止執行並執行 signal handler A process did something SIGSEGV(11), SIGFPE(8), SIGILL(4), SIGPIPE(13)\u0026hellip; A process wants to tell another process something SIGCHILD(17) child process terminated User sends sig to foreground processes Ctrl + C SIGINT(2) Ctrl + \\ SIGQUIT(3) Ctrl + Z SIGTSTP(20) disposition 決定 process 遇到 signal 時該怎麼處理\nTerm teminate process Ign ignore Core terminate the process and dump core Stop stop the process Cont continue the process if it is stopped Signal can\u0026rsquo;t not be caught SIGKILL(9) SIGSTOP(19) Commands trap\n可以 handle signal\nkill kill - L 可以看到 standard signal 和 real-time signal\nstandard signal 開頭是 SIG，realt-time signal 是 SIGRT\n","date":"2023-01-28T15:31:50+08:00","permalink":"https://roykesydon.github.io/Blog/p/ipc--inter-process-communication/","title":"IPC -- Inter-Process Communication"},{"content":"介紹 一種用於自動化找超參數的方法，用在採樣昂貴而且是黑盒子的情況\n流程 取樣一些資料點 生出一個 Surrogate Model(可採用 Gaussian Process) 反覆做以下事情 用 Acquisition Function 挑選下一個要採樣的點 重新評估 Surrogate Model Gaussian Process 最終的 prediction 是一個 distribution 而不是單一個數字 生成方法需借助 kernel function，常用 RBF(Radial Basis Function)\n$K(x, x^{\u0026rsquo;}|\\tau)=\\sigma^2exp(-\\frac{1}{2}(\\frac{x-x^{\u0026rsquo;}}{l})^2)$\n$\\sigma$ 和 $l$ 是兩個可以調整的超參數\nAcquisition Function 可用超參數來調節 exploitation 和 exploitation\nUCB(Upper confidence bound) PI(probability of improvement) EI(Expected improvement) ","date":"2023-01-26T01:36:53+08:00","permalink":"https://roykesydon.github.io/Blog/p/bayesian-optimization/","title":"Bayesian Optimization"},{"content":"PPFDT per process file descriptor table 每個 process 都有 存放 file descriptors file descriptors 是一個唯一的整數，用來識別作業系統上的 open file 0, 1, 2 是 Standard input / ouput / error 大小受限於 OPEN_MAX，亦即能同時間能開的最多檔案數 Redirection Input redirection $ wc \u0026lt; /etc/passwd 把 wc 的 PPFDT 的 stdin 改成 /etc/passwd 如果是 $ wc /etc/passwd，則是在 PPFDT 追加 /etc/passwd Ouput redirection $ wc \u0026gt; f1 把 wc 的 PPFDT 的 stdout 改成 f1 Input \u0026amp; output redirection 兩個可以同時用\n$ cat \u0026lt; f1 \u0026gt; f2 \u0026gt;\u0026gt; 可以 append $ \u0026lt; f1 cat \u0026gt; f2 可以亂換位置 Error redirection $ find / -name f1 2\u0026gt; error 1\u0026gt; outputs 這樣就會把那些 Permission denied 的給到 errors，成功的給到 outputs 2\u0026gt;/dev/null /dev/null 會把丟進來的東西都丟棄 Copy Descripter 這兩者等價 $ cat f1 1\u0026gt;op_err 2\u0026gt;op_err $ cat f1 1\u0026gt;op_err 2\u0026gt;\u0026amp;1 make 2 a copy of 1 ","date":"2023-01-21T02:20:43+08:00","permalink":"https://roykesydon.github.io/Blog/p/io-redirection/","title":"IO Redirection"},{"content":"Compile C 4-steps pre-processing compilation assembly linking Types of Object Files Executable object file Relocatable object file Shared object file Core file Formats of Object Files a.out initial version of UNIX COFF SVR3 UNIX PE Win. NT ELF SVR4 Linux ELF format of a program ELF Header Program Header Table .text .rodata .data .bss .symtab .rel.text .rel.data .debug .line .strtab Section Header Table 可參考: http://ccckmit.wikidot.com/lk:elf\nProcess Instance of a program running on a computer\nProcess Control Block task_struct\nProcess Identification PID, PPID, SID, UID, EUID.. Process State Information Process Control Information ","date":"2023-01-21T00:08:25+08:00","permalink":"https://roykesydon.github.io/Blog/p/process-management/","title":"Process Management"},{"content":"Features Process control Variables Flow control Functions File \u0026amp; cmd name completions Cmd line editng Cmd history Command Mode Interactive Non- Interactive Command Type internal / Builtin command\n指令的程式碼是 shell 的一部分 e.g., cd, exit 不會產生 child process 有些 internal command，比如 echo, pwd，會 internal 和 external 都有實作 external command\n指令的程式碼在硬碟上的某個 binary file e.g., clear, ls 會產生 child process Common Commands 比較實用或常用的\ngrep\n找字詞\ngrep \u0026lt;string/pattern\u0026gt; -i 大小寫不敏感 -v 不包含關鍵字的 cut 找 column\n-f 找哪些 column -d 分隔符是什麼 比較兩個檔案\ncomm\n顯示 file1 獨有的列、 file2 獨有的列、file1 和 file2 共有的列\ncmp, diff\n回傳不一樣的列資訊\nunset\n把指定的變數移除掉\ntee\n吃 stdin 輸出到 stdout 和其他檔案\nless\n讀檔案用\nExpansions White space Control Operators ; 讓指令接著執行 \u0026amp; 放在結尾，讓指令在背景執行 \u0026amp;\u0026amp; logical AND || logical OR\n前面失敗才會跑後面\n# 註解用 \\ escape special characters 放結尾好換行繼續輸入 $? 一個特別的變數，有上個指令的 exit code Shell variables User defined Env var Shell history File Globing *, ?, [], -, ! ","date":"2023-01-19T23:00:02+08:00","permalink":"https://roykesydon.github.io/Blog/p/shell/","title":"Shell"},{"content":"VM A software implementation of a machine\nSystem VM 提供可以執行 GuestOS 的 complete system platform Process VM 像一個一般的 app 一樣在 hostOS 跑，支援單一個 process Hypervisor 又稱虛擬機器監視器（英語：virtual machine monitor，縮寫為VMM） 用來管理 VM\n允許多個 GuestOS 跑在 host computer\nType-1\nbare-metal hypervisors 直接在硬體上執行 Type-2\nhosted hypervisors 在 hostOS 上執行 directories Binary\ne.g., bin, sbin, lib, opt bin: 有關 user 的指令 sbin: 管理員會用的指令 opt: optional software，多數機器中這是空的 Configuration\ne.g., boot, etc, Data\ne.g., home, root, srv, media, mnt, temp In memory 字面上的意思，不在 hard disk，在 memory\ne.g., dev, proc, sys System Resources\ne.g., usr Variable Data\ne.g., var ","date":"2023-01-19T01:50:07+08:00","permalink":"https://roykesydon.github.io/Blog/p/linux-%E7%91%A3%E4%BA%8B/","title":"Linux 瑣事"}]