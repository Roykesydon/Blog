[{"content":"paper: SQUID: Deep Feature In-Painting for Unsupervised Anomaly Detection\nAbstract Radiography imaging protocols (æ”¾å°„ç·šæˆåƒå”å®š) æœƒå°ˆæ³¨æ–¼ç‰¹å®šçš„èº«é«”å€åŸŸï¼Œå› æ­¤æœƒåœ¨æ‚£è€…é–“ç”¢ç”Ÿå¤§é‡ç›¸ä¼¼çš„ç…§ç‰‡ã€‚\nç‚ºäº†åˆ©ç”¨é€™ç¨® structed informationï¼Œä½œè€…æå‡ºäº† Space-aware Memory Queues for In-painting and Detecting anomalies from radiography images (SQUID)ï¼Œå®ƒå¯ä»¥æŠŠå›ºæœ‰çš„äººé«”çµæ§‹åˆ†é¡ç‚ºåè¦†å‡ºç¾çš„ patternã€‚\nåœ¨æ¨ç†ç‹€æ…‹ä¸‹ï¼Œå®ƒå¯ä»¥è­˜åˆ¥åœ–ç‰‡ä¸­çš„ç•°å¸¸æƒ…æ³ã€‚\næ¯”è¼ƒå…©å€‹ chest X-ray benchmarkï¼ŒSQUID åœ¨éç›£ç£ç•°å¸¸æª¢æ¸¬ä¸Šè¶…è¶Šäº† 13 ç¨® SOTA æ–¹æ³•è‡³å°‘ 5 å€‹ç™¾åˆ†é»ã€‚\nä½œè€…é‚„å‰µå»ºäº†ä¸€å€‹æ–°çš„è³‡æ–™é›† (DigitAnatomy)ï¼Œè©²è³‡æ–™é›†çµåˆäº†èƒ¸è…”è§£å‰–å­¸ä¸­çš„ spatial correlation å’Œ consistent shape é€™å…©å€‹ç‰¹æ€§ã€‚\nIntroduction æ”¾å°„ç·šæˆåƒå’Œä¸€èˆ¬åœ–ç‰‡çš„å·®åˆ¥ ä¸€èˆ¬çš„ photographic imaging å’Œ radiography imaging æ˜¯ä¸åŒçš„ã€‚ä¸€èˆ¬çš„åœ–ç‰‡ç‰©é«”ï¼Œæˆ‘å€‘æœƒå‡è¨­ translation invariance (å¹³ç§»ä¸è®Šæ€§)ï¼Œç„¡è«–è²“åœ¨å·¦å³ï¼Œéƒ½æ˜¯è²“ã€‚ä½†æ˜¯åœ¨æ”¾å°„ç·šæˆåƒä¸­ï¼Œçµæ§‹çš„ç›¸å°ä½ç½®å’Œæ–¹å‘æ˜¯è¾¨åˆ¥æ­£å¸¸å’Œç•°å¸¸çš„é‡è¦ç‰¹å¾µã€‚ è€Œä¸”ç”±æ–¼ radiography imaging protocols ä»¥ç›¸ç•¶ä¸€è‡´çš„æ–¹å‘è©•ä¼°æ‚£è€…ï¼Œæˆåƒåœ¨ä¸åŒçš„è¨­å‚™è£½é€ å•†ã€è¨­æ–½ä½ç½®é‚„æœ‰æ‚£è€…çš„æƒ…æ³ä¸‹ï¼Œéƒ½å…·æœ‰å¾ˆå¤§çš„ç›¸ä¼¼æ€§ã€‚åƒé€™æ¨£åè¦†å‡ºç¾ä¸”ä¸€è‡´çš„çµæ§‹ï¼Œæœ‰åŠ©æ–¼åˆ†æå•é¡Œï¼Œæ˜¯æ”¾å°„ç·šæˆåƒçš„å„ªå‹¢ã€‚ æœ‰å¤šé …ç ”ç©¶è­‰æ˜äº†è¨±å¤šå…ˆé©—çŸ¥è­˜åœ¨å¢å¼·æ·±åº¦å­¸ç¿’æ¨¡å‹æ€§èƒ½ä¸Šçš„å„ªå‹¢ï¼Œæ¯”å¦‚æ·»åŠ  location featuresã€ä¿®æ”¹ç›®æ¨™å‡½æ•¸é‚„æœ‰ç´„æŸç›¸å°æ–¼ç…§ç‰‡ä¸­ landmarks çš„ç›¸å°åº§æ¨™ã€‚\næƒ³è§£æ±ºçš„å•é¡Œ\nå¤šé” 80% çš„è‡¨åºŠéŒ¯èª¤æ˜¯ç”±æ–¼æ”¾å°„ç§‘é†«ç”Ÿæ¼æ‰ç•°å¸¸è€Œé€ æˆã€‚ æœ¬æ–‡æƒ³å›ç­”ä¸€å€‹é—œéµå•é¡Œï¼šæœ‰æ²’æœ‰è¾¦æ³•åˆ©ç”¨ anatomical patterns çš„ consistency å’Œ spatial informationï¼Œåœ¨æ²’æœ‰æ‰‹å‹•æ¨™è¨»çš„æƒ…æ³ä¸‹ï¼ŒåŠ å¼·æ·±åº¦å­¸ç¿’æ¨¡å‹çš„ç•°å¸¸æª¢æ¸¬èƒ½åŠ›ï¼Ÿéç›£ç£çš„ç•°å¸¸æª¢æ¸¬åªç”¨å¥åº·çš„åœ–ç‰‡é€²è¡Œè¨“ç·´ï¼Œä¸ç”¨ç–¾ç—…è¨ºæ–·æˆ–ä»»ä½• labelã€‚ SQUID è§£æ±ºè¾¦æ³•\næœ¬æ–‡ä¸åƒå…ˆå‰çš„ç•°å¸¸æª¢æ¸¬æ–¹æ³•ï¼Œæœ¬æ–‡æŠŠ task åˆ¶å®šç‚º in-painting task (åœ–åƒä¿®å¾©)ï¼Œå¥½åˆ©ç”¨æ”¾å°„ç·šæˆåƒçš„å¤–è§€ã€ä½ç½®ã€å¸ƒå±€ã€‚\nä½œè€…æå‡ºäº† SQUIDï¼Œåœ¨è¨“ç·´éç¨‹ä¸­ï¼Œæ¨¡å‹å¯ä»¥é€éç©ºé–“ä¸­ç¶“å¸¸å‡ºç¾çš„ anoatomical patterns ä¾†å‹•æ…‹ç¶­è­·ä¸€å€‹ visual pattern dictionaryã€‚\nç”±æ–¼è§£å‰–å­¸çš„ consistencyï¼Œå¥åº·æˆåƒä¸­çš„èº«é«”å€åŸŸæœƒå‘ˆç¾é¡ä¼¼çš„ visual patternï¼Œä½¿ unique pattern çš„æ•¸é‡æ˜¯å¯æ§çš„ã€‚\nåœ¨æ¨ç†éšæ®µï¼Œç”±æ–¼ dictionary ä¸å­˜åœ¨ anomaly patternï¼Œå› æ­¤å¦‚æœå­˜åœ¨ç•°å¸¸ï¼Œç”¢ç”Ÿçš„æ”¾å°„ç·šæˆåƒæœƒå’Œç¾å¯¦æœ‰æ‰€å·®è·ã€‚å› æ­¤ï¼Œæ¨¡å‹å¯ä»¥é€éå€åˆ†ä¿®å¾©ä»»å‹™çš„å“è³ªä¾†è­˜åˆ¥ç•°å¸¸ã€‚\nå¯¦é©—å‡è¨­\nç•°å¸¸æª¢æ¸¬çš„æˆåŠŸåŸºæ–¼å…©å€‹å‡è¨­ è³‡æ–™ä¸­å¾ˆå°‘ç•°å¸¸åœ–ç‰‡ ç•°å¸¸å’Œæ­£å¸¸æœ‰é¡¯è‘—ä¸åŒ å¯¦é©—\nåœ¨å…©å€‹å¤§è¦æ¨¡ã€å…¬é–‹çš„æ”¾å°„ç·šæˆåƒè³‡æ–™é›†ä¸Šå¯¦é©— ZhangLab åœ¨éç›£ç£æ–¹é¢è´ SOTA è¶…é 5 å€‹ç™¾åˆ†é» Stanford CheXpert æ¯”æœ€è¿‘çš„ 13 ç¨®æ–¹æ³•æé«˜ 10 å€‹ç™¾åˆ†é» æ–°è³‡æ–™é›†\nå‰µå»ºäº† DigitAnatomy è³‡æ–™é›†ï¼Œé—¡æ˜èƒ¸è…”è§£å‰–çµæ§‹çš„ spatial correlation å’Œ consistent shapeã€‚ è²¢ç»ç¸½çµ\nåœ¨èƒ¸è…”æ”¾å°„ç·šæˆåƒçš„æ–°éç›£ç£ SOTA ç•°å¸¸æª¢æ¸¬æ–¹æ³• æ–°çš„ç¶œåˆè³‡æ–™é›† ç™¼æ˜æ–°æ–¹æ³•æ‰“æ•—ä¸»æµéç›£ç£ç•°å¸¸æª¢æ¸¬æ–¹æ³• Related Work Anomaly detection in natural imaging è­˜åˆ¥åé›¢æ­£å¸¸è³‡æ–™åˆ†ä½ˆçš„ç½•è¦‹äº‹ä»¶ ç”±æ–¼ç•°å¸¸æ¨£æœ¬çš„ç¼ºä¹ï¼Œå¾Œä¾†çš„å·¥ä½œéƒ½åˆ¶å®šç‚ºéç›£ç£å­¸ç¿’å•é¡Œ å¤§è‡´åˆ†ç‚ºå…©é¡ reconstruction-based æ¢å¾©åŸå§‹è¼¸å…¥ä¸¦åˆ†æé‡å»ºèª¤å·® density-based é€éä¼°è¨ˆæ­£å¸¸è³‡æ–™çš„åˆ†ä½ˆä¾†é æ¸¬ç•°å¸¸ ä¸éé€™äº›æ–¹æ³•éƒ½æ²’è¾¦æ³•è§£é‡‹å¯èƒ½çš„ç•°å¸¸ï¼Œæœ¬æ–‡é€éç¶­è­· visual pattern memory ä¾†è§£æ±ºé€™å€‹å•é¡Œ Anomaly detection in medical imaging åŸºæ–¼ç›£ç£å­¸ç¿’çš„æ–¹æ³•å¤šåŠç”¨æ–¼æª¢æ¸¬ç‰¹å®šç¨®é¡çš„ç•°å¸¸ï¼Œæ¯”å¦‚è…«ç˜¤ æœ€è¿‘æå‡ºäº†ä¸€äº›ç„¡ç›£ç£æ–¹æ³•ä¾†æª¢æ¸¬ä¸€èˆ¬ç•°å¸¸ï¼Œå’Œ GAN æœ‰é—œï¼Œä½†æ˜¯é€™äº›æ–¹æ³•éœ€è¦æœ‰é—œæ–¼ç•°å¸¸ç¨®é¡çš„å¼·å¤§å…ˆé©—çŸ¥è­˜å’Œå‡è¨­æ‰èƒ½ä½¿å¢å¼·æœ‰æ•ˆ å’Œä¸€èˆ¬çš„ç…§ç‰‡ä¸åŒï¼ŒRadiography imaging protocols ç”Ÿæˆå…·ä¸€è‡´æ€§çš„åœ–ç‰‡ï¼Œç•°å¸¸çš„è®ŠåŒ–æ¯”è¼ƒå¾®å¦™ (subtle)ï¼Œæª¢æ¸¬èµ·ä¾†æ›´å…·æŒ‘æˆ°ï¼Œä½œè€…åˆ©ç”¨æ”¾å°„ç·šæˆåƒçš„ç‰¹æ€§ï¼Œå¤§å¤§æé«˜æª¢æ¸¬æ€§èƒ½ã€‚ Memory networks éå¾€æœ‰ä¸€äº›æœ‰é—œæ–¼æŠŠ Memory modules ç´å…¥ç¥ç¶“ç¶²è·¯çš„ç ”ç©¶ï¼Œå…¶ä¸­æœ‰æ¡ç”¨åˆ° Memory Matrixã€‚æœ¬æ–‡å…‹æœäº† Memory matrix çš„ä¾·é™æ€§ï¼Œä¸¦æå‡ºä¸€ç¨®æœ‰æ•ˆä¸”é«˜æ•ˆç‡çš„çš„ memory queueã€‚ SQUID Overview Feature extraction\næŠŠåœ–ç‰‡åˆ‡æˆ N x N å€‹ non-overlapping patchesï¼Œç„¶å¾Œé¤µå…¥ä¸€å€‹ encoder åšç‰¹å¾µæå–ï¼Œé€™è£¡æ˜¯ç”¨ CNN æå–ï¼Œä½†è¦ç”¨å…¶ä»– backbone ä¹Ÿå¯ä»¥ Image reconstruction\né€™è£¡æœƒç”¨ teacher å’Œ student generator teacher ç›´æ¥ç”¨ encoder çš„ feature é‡å»ºåœ–ç‰‡ æœ¬è³ªä¸Šæ˜¯ auto-encoder ä½œç‚º regularizer ä¾†é¿å… student generator é‡è¤‡ç”Ÿæˆç›¸åŒçš„æ­£å¸¸åœ–ç‰‡ student ä½¿ç”¨ in-painting block å¢å¼·å¾Œçš„ feature ä¾†é‡å»ºï¼Œæœ€å¾Œæœƒè¢«ç”¨åœ¨ discrimination å…©å€‹ generator æœƒåœ¨æ¯å€‹ up-sampling level ç”¨ knowledge distillation paradigm ä¾†çµåˆ Anomaly discrimination\nåœ¨ adversarial learning å¾Œï¼Œä½¿ç”¨ discriminator ä¾†å€åˆ†æ­£å¸¸å’Œç•°å¸¸ ç”¨ 2 å€‹ generator ä¾†ç”Ÿæˆåœ–ç‰‡ï¼Œå†ç”¨ discriminator ä¾†å€åˆ†ï¼Œåªæœ‰ student generator æœƒæ¥æ”¶ discriminator çš„æ¢¯åº¦ Inventing Memory Queue as Dictionary Motivation Memory Matrix è¢«å»£æ³›æ¡ç”¨ Feature æœƒé€éåœ¨ Memory matrix åšåŠ æ¬Šå¹³å‡ä¾†å¼·åŒ– ç¼ºé» é€™æ¨£çš„å¢å¼·æ–¹æ³•æ˜¯å°æ•´å¼µåœ–ç‰‡çš„æå‡ºçš„ç‰¹å¾µåšçš„ï¼Œä¸Ÿæ£„äº†åœ–ç‰‡ä¸­çš„ spatial informationã€‚å°è‡´ä»–ç„¡æ³•æ„ŸçŸ¥åˆ°æ”¾å°„ç·šæˆåƒä¸­çš„ä¸€è‡´æ€§çµæ§‹ Space-aware memory ç‚ºäº†åˆ©ç”¨ç©ºé–“è³‡è¨Šï¼Œä½œè€…åªå°‡ patch è€Œä¸æ˜¯æ•´å¼µåœ–ç‰‡å‚³éåˆ° modelï¼Œè®“ patch åªèƒ½å­˜å– Memory matrix ä¸­å°æ‡‰åˆ°çš„å€æ®µï¼Œä½œè€…æŠŠé€™ç¨®ç­–ç•¥ç¨±ç‚º Space-aware memoryï¼Œè€Œä¸”é‚„å¯ä»¥åŠ å¿«é€Ÿåº¦ï¼Œå› ç‚ºä¸ç”¨å­˜å–æ•´å€‹ Memory matrix Memory queue åœ¨ learning-based Memory matrix ä¸­ï¼Œnormal patterns æ˜¯ç”± matrix ä¸­çš„ learned basis çµ„åˆè€Œæˆï¼Œä½†çµ„åˆå‡ºä¾†çš„æ±è¥¿å’Œç¾å¯¦ç…§ç‰‡çš„ç‰¹å¾µç¸½æœƒæœ‰åˆ†ä½ˆå·®è·ï¼Œä½¿å¾ŒçºŒçš„å½±åƒç”Ÿæˆè®Šå¾—å›°é›£ ä½œè€…æå‡º memory queueï¼Œç”¨ä¾†åœ¨è¨“ç·´æœŸé–“å„²å­˜çœŸå¯¦çš„å½±åƒ featureï¼Œå¾è€Œå‘ˆç¾å’Œå½±åƒç‰¹å¾µç›¸åŒçš„åˆ†ä½ˆã€‚å®ƒåœ¨è¨“ç·´æœŸé–“æœƒæŠŠå…ˆå‰çœ‹åˆ°çš„ç‰¹å¾µç›´æ¥è¤‡è£½åˆ° queue Gumbel shrinkage æ§åˆ¶ memory matrix ä¸­ activated pattern çš„æ•¸é‡æ˜¯æœ‰åˆ©çš„ï¼Œä½†å¦‚æœç”¨ hard shrinkage threashold æœƒç„¡æ³•è™•ç†æ‰¾ä¸åˆ°åˆé© entry çš„æƒ…æ³ã€‚ä¸€ç¨®è‡ªç„¶çš„è§£æ³•æ˜¯è®“æ¢¯åº¦æµéå‰ k å€‹ç›¸ä¼¼çš„ entryï¼Œå…¶é¤˜çš„ä¸æ›´æ–°ã€‚ä½†é€™æ¨£åˆæœƒå°è‡´æœªå•Ÿå‹•çš„ entry ç„¡æ³•æ¥æ”¶ä»»ä½•æ¢¯åº¦ä¸¦æ›´æ–°ï¼Œå› æ­¤æå‡ºäº† Gumbel shrinkage schema $w\u0026rsquo; = sg(hs(w,topk(w)) - \\phi(w)) + \\phi(w)$ $w$ ä»£è¡¨ feature å’Œ entry çš„ç›¸ä¼¼åº¦ $sg(\\cdot)$ ä»£è¡¨ stop-gradientï¼Œä¸è¨ˆç®—è¼¸å…¥çš„æ¢¯åº¦ $hs(\\cdot, t)$ ä»£è¡¨ hard shrinkageï¼Œæœ‰å€‹ threshold $t$ $\\phi(\\cdot)$ ä»£è¡¨ softmax é€™æ¨£ä¿ç•™äº† top k ä½œç‚º w çš„æœ€çµ‚çµæœï¼Œåˆç”¨ softmax å°æ‰€æœ‰ entry é€²è¡Œæ›´æ–° Formulating Anomaly Detection as In-painting Motivation\nImage in-painting æœ€åˆæ˜¯ç”¨ä¾†æ¢å¾©å…·æœ‰ neighboring context çš„åœ–ç‰‡å€å¡Šï¼Œå› æ­¤æ ¹æ“šæ­¤ç›´è¦ºï¼Œæƒ³æŠŠç•°å¸¸åœ–ç‰‡ä¿®å¾©æˆæ­£å¸¸åœ–ç‰‡ä¾†å¯¦ç¾æª¢æ¸¬ åœ¨ä¿®å¾©åƒç´ çš„æ™‚å€™ï¼Œç‰¹åˆ¥æ˜¯ç”¨æ·±åº¦ç¶²è·¯ï¼Œå®¹æ˜“æœ‰ boundary artifactsï¼Œåœ¨ pixel ç´šåˆ¥çš„ä¿®å¾©ä¸­ï¼Œé€™äº› boundary artifacts æœƒå°è‡´å¤§é‡èª¤å ± artifact ä¸­ç¿»å¥½åƒæ˜¯ã€Œå½å½±ã€ï¼Œå°±æ˜¯é‡å»ºçš„æ™‚å€™æœƒå‘ˆç¾æœ‰é»åƒæ£‹ç›¤çš„æ•ˆæ‡‰ ä½œè€…é¸æ“‡åœ¨ feature level é€²è¡Œ in-paintingï¼Œé¿é–‹é€™å•é¡Œ In-painting block\næœƒå…ˆæŠŠæ¯å€‹ patch $F_{1,1}$ ~ $F_{w,h}$ éƒ½å…ˆæ‰¾åˆ°æœ€æ¥è¿‘çš„ normal patterns $N_{1,1}$ ~ $N_{w,h}$ å› ç‚º N æ˜¯ä¹‹å‰è¨“ç·´è³‡æ–™ä¸­æå–çš„ç‰¹å¾µçµ„æˆçš„ï¼Œä¸å—ç•¶å‰è¼¸å…¥å½±åƒçš„å½±éŸ¿ã€‚ç‚ºäº†å°å…¥è¼¸å…¥åœ–ç‰‡çš„ç‰¹å¾µï¼Œä½œè€…æŠŠ F å’Œ N ç”¨ transformer block ä¾†çµåˆ å°æ–¼æ¯å€‹ patch $F_{i,j}$ï¼ŒæœƒæŠŠå…¶ç•¶ä½œä¸­å¿ƒï¼Œç”¨ç›¸é„°çš„ 8 å€‹ N patch ä¾†é‡æ–°å®šç¾© $F_{i,j}$ï¼ŒæŠŠé€™ 8 å€‹ N patch ä½œç‚º key å’Œ valueï¼Œ$F_{i,j}$ ä½œç‚º query æœ€å¾Œæœƒåœ¨ in-painting block çš„å‰å¾Œåš point-wise convolution (1x1) Masked shortcut\nå¯¦é©—çµæœè¡¨æ˜ï¼Œç›´æ¥åš residual connection æœƒé™ä½ä¿®å¾©çš„æ€§èƒ½ï¼Œä½œè€…æ¡ç”¨ random binary mask åœ¨ training æœŸé–“ gate shortcut feature $F\u0026rsquo;=(1-\\delta)\\cdot F + \\delta \\cdot inpaint(F)$ $\\delta$~$Bernoulli(\\rho)$ $\\rho$ gating probability ç²å¾— F\u0026rsquo; å¾Œï¼ŒåŸå§‹çš„ F æœƒè¢«æ›´æ–°é€² memory åœ¨æ¨è«–éšæ®µï¼Œæœƒ disable shortcutï¼Œä½¿ $F\u0026rsquo;=inpaint(F)$ Anomaly Discrimination Discriminator è©•ä¼°åœ–ç‰‡ç¾ä¸ç¾å¯¦ï¼Œä¸ç¾å¯¦è¡¨ç¤ºç•°å¸¸ å› ç‚º Generator åªåœ¨æ­£å¸¸åœ–ç‰‡è¨“ç·´ï¼Œæ‰€ä»¥ Memory Queue ä¹Ÿåªæœ‰ normal pattern ç¨å¾®ç¸½çµ in-painting block æœƒæŠŠ patch å¼·åŒ–ç‚ºç›¸ä¼¼çš„ normal feature student generator æœƒæ ¹æ“š \u0026ldquo;normal\u0026rdquo; feature é‡å»ºå‡º \u0026ldquo;normal\u0026rdquo; image å¦‚æœæ²’æœ‰ç•°å¸¸çš„è©±ï¼Œé‚£ input å’Œé‡å»ºçš„ image åœ¨èªæ„ä¸Šæ‡‰è©²ç›¸å·®å¾ˆå° ç•°å¸¸åˆ†æ•¸ $A$ çš„ç®—æ³• $A=\\phi(\\frac{D(G_s(E(I)))-\\mu}{\\sigma})$ $\\phi(\\cdot)$ æ˜¯ sigmoid function $\\mu$ å’Œ $\\sigma$ æ˜¯æ ¹æ“š training samples ç®—å‡ºçš„ç•°å¸¸åˆ†æ•¸çš„å¹³å‡å€¼å’Œæ¨™æº–å·® Loss Function Generator $\\mathcal L_t = (I-G_t (E(I)))^2$ $\\mathcal L_s = (I-G_s (E(I)))^2$ Knowledge distillation $\\mathcal L_{dist} = \\sum_{l}^{i=1} (F^i_t-F^i_s)^2$ $l$ æ˜¯ levels of features Adversarial loss é¡ä¼¼ DCGAN $\\mathcal L_{gen} = log(1-D(G_s(E(I))))$ Discriminator $\\mathcal L_{dis} = log(D(I)) + log(1-D(G_s(E(I))))$ æŠŠ real image æ©Ÿç‡æ‹‰é«˜ï¼ŒæŠŠ fake image æ©Ÿç‡æ‹‰ä½ Total loss minimize generative loss $\\lambda_t \\mathcal L_t + \\lambda_s \\mathcal L_s + \\lambda_{dist} \\mathcal L_{dist} + \\lambda_{gen} \\mathcal L_{gen}$ maximize discriminative loss $\\lambda_{dis} \\mathcal L_{dis}$ Experiments New Benchmark æå‡ºä¸€å€‹æ–°è³‡æ–™é›† - DigitAnatomyã€‚ã€‚å¦‚æœåŒ…å«æ­£ç¢ºé †åºçš„é˜¿æ‹‰ä¼¯æ•¸å­— 1~9 å‰‡è¦–ç‚ºæ­£å¸¸ï¼Œç•°å¸¸åŒ…æ‹¬ç¼ºå¤±ã€äº‚åºã€ç¿»è½‰å’Œ zero digitã€‚\nè©²è³‡æ–™é›†å°æ–¼æ”¾å°„ç·šæˆåƒå°¤å…¶æœ‰åˆ©ï¼ŒåŸå› å¦‚ä¸‹:\nspatial correlation and consistent shape æ”¾å°„ç·šæˆåƒè¦æ¨™è¨˜éœ€è¦å°ˆæ¥­çŸ¥è­˜ï¼Œä½†æ•¸å­—å®¹æ˜“ debug è©²è³‡æ–™é›†å¾ˆå®¹æ˜“å°±å¯ä»¥ç²å¾—æ¨¡æ“¬ç•°å¸¸çš„ ground truth Public Benchmarks ZhangLab Chest X-ray åŒ…å«å¥åº·å’Œè‚ºç‚çš„å½±åƒ è¨“ç·´é›† 1349 å¼µæ­£å¸¸ 3883 å¼µç•°å¸¸ æ¸¬è©¦é›† 234 å¼µæ­£å¸¸ 390 å¼µç•°å¸¸ ä½œè€…å¾è¨“ç·´é›†éš¨æ©ŸæŒ‘ 200 å¼µåšç‚ºèª¿æ•´è¶…åƒæ•¸çš„ validation set å½±åƒéƒ½èª¿æ•´ç‚º 128x128 Stanford CheXpert å° front-view PA å½±åƒé€²è¡Œè©•ä¼°ï¼Œå…±æœ‰ 12 ç¨®ç•°å¸¸ æœ‰ 5249 å¼µæ­£å¸¸å’Œ 23671 å¼µç•°å¸¸ç”¨ä½œè¨“ç·´ ä½¿ç”¨å’Œ ZhangLab ç›¸åŒçš„è¶…åƒæ•¸ ç”¨è¨“ç·´é›†çš„ 250 å¼µæ­£å¸¸å’Œ 250 å¼µç•°å¸¸é€²è¡Œæ¸¬è©¦ Baselines and Metrics è€ƒæ…® 13 å€‹ä¸»è¦çš„ baseline\nç¶“å…¸ UAD (unsupervised anomaly detection) Auto-encoderã€VAE é†«å­¸å½±åƒçš„ SOTA Ganomalyã€f-AnoGANã€IFã€SALAD æœ€è¿‘çš„ UAD MemAEã€CutPasteã€M-KDã€PANDAã€PaDiMã€IGD é™¤éæœ‰ç‰¹åˆ¥è¨»æ˜ï¼Œä¸ç„¶éƒ½æ˜¯å¾é ­ç¨ç«‹è¨“ç·´è‡³å°‘ä¸‰æ¬¡\nResults Interpreting SQUID on DigitAnatomy ä½œè€…åœ¨ DigitAnatomy çš„å¯¦é©—ä¸­ï¼Œæ•…æ„æ³¨å…¥ç•°å¸¸åˆ°æ­£å¸¸åœ–ç‰‡ä¸­ï¼Œæ¸¬è©¦æ¨¡å‹æ˜¯å¦å¯ä»¥é‡å»ºæ­£å¸¸åœ–ç‰‡ã€‚\nSQUID é‡å»ºå‡ºçš„åœ–ç‰‡æ¯”å…¶ä»– baseline æœ‰æ›´å¤šæœ‰æ„ç¾©çš„è¨Šæ¯ï¼Œä¸»è¦æ­¸åŠŸæ–¼ space-aware memoryï¼Œå…¶ç”¢ç”Ÿç¨ç‰¹çš„ patternï¼Œè€Œä¸”å’Œç©ºé–“è¨Šæ¯ç›¸é—œè¯ã€‚\nä¸€æ—¦å‡ºç¾ç•°å¸¸ï¼Œin-painting block æœƒå¾å­—å…¸ä¸­æ‰¾å‡ºå‰ k å€‹ç›¸è¿‘çš„ï¼ŒæŠŠç•°å¸¸ç‰¹å¾µå¢å¼·åˆ°å…¶å°æ‡‰çš„æ­£å¸¸ç‰¹å¾µï¼Œå…¶ä»–æ–¹æ³•ä¸å…·å‚™æ­¤èƒ½åŠ›ï¼Œæ‰€ä»¥ä»–å€‘é‡å»ºå‡ºæœ‰ç¼ºé™·çš„åœ–åƒã€‚\nGAN å‚¾å‘æ–¼é‡å»ºè¨“ç·´æ¨£æœ¬å¹³å‡å¾—åˆ°çš„å½±åƒã€‚ MemAE å—ç›Šæ–¼ Memory matrixï¼Œè¡¨ç¾è¼ƒå¥½ï¼Œä½†å°æ–¼ç¼ºå¤±æ•¸å­—çš„ç•°å¸¸æ•ˆæœä¸ä½³ã€‚\nBenchmarking SQUID on Chest Radiography Limitation ä½œè€…ç™¼ç¾ç›®å‰çš„ SQUID æ²’è¾¦æ³•åœ¨åƒç´ å±¤ç´šç²¾ç¢ºå®šä½ç•°å¸¸ã€‚é€™å¯ä»¥ç†è§£ï¼Œå› ç‚º SQUID æ˜¯ä¸€ç¨®éç›£ç£æ–¹æ³•ï¼Œä¸éœ€è¦æ¨™è¨»ã€‚\né‚£äº›åƒç´ ç´šåˆ¥çš„ç•°å¸¸æª¢æ¸¬æœƒé­é‡æ”¾å¤§é›œè¨Šçš„å½±éŸ¿ï¼Œä½†æ˜¯ç”±æ–¼ SQUID æ˜¯åœ¨ç‰¹å¾µå±¤ç´šé€²è¡Œçš„ï¼Œæ¯”åƒç´ ç´šåˆ¥æ›´åŠ  robustã€‚\nAblating Key Properties in SQUID Component study Hyper-parameter robustness Disease-free training requirement? ç”¨æ–¼é†«å­¸ç•°å¸¸æª¢æ¸¬çš„éç›£ç£æ–¹æ³•ä¸¦ä¸å¸¸è¦‹ï¼Œå› ç‚ºæ‰€è¬‚çš„ UAD æ–¹æ³•ä¸¦ä¸æ˜¯ã€Œéç›£ç£ã€çš„ï¼Œå› ç‚ºä»–å€‘å¿…é ˆåªåœ¨ç„¡ç–¾ç—…å½±åƒä¸Šä½œè¨“ç·´ã€‚\nåœ¨å¯¦è¸ä¸­ï¼Œè¦ç²å¾—å¥åº·åœ–ç‰‡éœ€è¦ manual annotationã€‚\nåœ¨è¨“ç·´é›†ä¸­è€ƒæ…® disease-free å¾ 100% - 50% çš„æƒ…æ³ï¼ŒæŠŠ SQUID çš„ robust å’Œå¦å¤–ä¸‰å€‹ baseline é€²è¡Œæ¯”è¼ƒã€‚\nSQUID çš„ memory queue å¯ä»¥è‡ªå‹•å¿½ç•¥å°‘æ•¸çš„ anatomical patternsã€‚\n","date":"2024-03-31T00:27:55+08:00","permalink":"https://roykesydon.github.io/Blog/p/squid-%E8%AB%96%E6%96%87/","title":"ğŸ¦‘SQUIDğŸ¦‘ è«–æ–‡"},{"content":"Abstract æœ¬æ–‡æƒ³åœ¨ manufacturing context ä¸‹é–‹ç™¼ä¸€å€‹ XR (extended reality) æ¶æ§‹ï¼Œæƒ³ç”¨ XR æ•´åˆä¸¦æ”¹å–„å‚³çµ±å·¥ä½œæµç¨‹ã€‚\nè©²æ¡†æ¶åŒ…å«äº”å€‹ iterative phase:\nRequirement analysis Solution selection data preparation system implementation system evaluation æ­¤å¯¦é©—ä¹Ÿå¼·èª¿äº† user-centered çš„æ–¹æ³•åœ¨é–‹ç™¼æœ‰é—œè£½é€ æ¥­çš„ XR ç³»çµ±çš„é‡è¦æ€§ã€‚\nIntroduction ä½œè€…èªç‚º XR ç³»çµ±çš„æ•´åˆå°è£½é€ æ¥­çš„è½‰å‹å¾ˆé‡è¦ï¼Œæœ‰åŠ©æ–¼å¯¦ç¾ Industry 4.0ã€‚\nç›¡ç®¡ç ”ç©¶é¡¯ç¤º XR åœ¨è£½é€ æ¥­ä¸­æœ‰å·¨å¤§æ½›åŠ›ï¼Œä½†å·¥ç¨‹å¸«åœ¨æ—¥å¸¸ç”Ÿæ´»ä¸­ç”¨ XR çš„ç³»çµ±å¾ˆå°‘ï¼Œé¡¯ç¤ºå‡ºæ•´åˆ XR åˆ°è£½é€ æ¥­æ˜¯å›°é›£ä¸”å…·å‚™æŒ‘æˆ°æ€§çš„ã€‚\næœ¬ç ”ç©¶æƒ³é–‹ç™¼ä¸€å€‹ç³»çµ±æ¡†æ¶ï¼Œæ”¯æ´æœªä¾† XR ç³»çµ±åœ¨è£½é€ æ¥­çš„é–‹ç™¼ï¼Œè€Œä¸æ˜¯åªåœç•™åœ¨ã€Œwow effectã€\nFrame of reference Extended Reality Classification é€éé›»è…¦å¯¦ç¾çš„ç¾å¯¦å¢å¼·æŠ€è¡“å¯ä»¥è¿½æº¯åˆ° 1960sï¼Œåœ¨è¿‘å¹´æ¼”è®Šæˆå¤šç¨®å­é›†ï¼Œä¹Ÿå› æ­¤ç”¢ç”Ÿä¸åŒè¡“èªï¼Œä½¿äººå›°æƒ‘ã€‚\næœ¬æ–‡èªªçš„ XR è¢«ç”¨ä½œç¸½ç¨±ï¼Œä»£æŒ‡æ‰€æœ‰ä»¥é›»è…¦ç‚ºåª’ä»‹çš„ Reality Technologiesã€‚\nå€åˆ†ä¸åŒç³»çµ±çš„ XR ååˆ†é‡è¦ï¼Œé€™æ¨£æ‰èƒ½é‡å°è£½é€ æ¥­ä¸­ä»»ä½•ä¸€å€‹ç‰¹å®šçš„æ‡‰ç”¨ä½œå‡ºæ­£ç¢ºçš„æ±ºç­–ã€‚\nä¸€ç¨®å¸¸è¦‹çš„æ–¹æ³•æ˜¯ reality-virtuality continuumï¼ŒæŠŠç¾å¯¦ä¸–ç•Œå’Œè™›æ“¬ä¸–ç•Œæ”¾åœ¨å…©ç«¯ï¼Œæ ¹æ“šé è¿‘å“ªç«¯é€²è¡Œå€åˆ†ã€‚\nå·¦ç«¯æ˜¯ç¾å¯¦ä¸–ç•Œï¼Œå³ç«¯æ˜¯è™›æ“¬ä¸–ç•Œã€‚å¾å·¦åˆ°å³å‡ºç¾ augmented reality(AR)ã€mixed reality(MR) å’Œ virtual reality(VR)\nAugmented Reality (AR) æœ€å»£æ³›çš„å®šç¾©ï¼Œæœ‰ä»¥ä¸‹ä¸‰å€‹ç‰¹å¾µ çµåˆè™›æ“¬èˆ‡ç¾å¯¦ è¦å¯ä»¥ real-time çš„äº’å‹• é¡¯ç¤ºåœ¨ 3D ç©ºé–“ ç”¨æˆ¶è¦ä¾ç„¶å¯ä»¥çœ‹åˆ°å‘¨é­ç’°å¢ƒï¼Œä¸¦èˆ‡ä¹‹äº’å‹•ï¼ŒåŒæ™‚ç²å¾—è«¸å¦‚æ–‡å­—æˆ–åœ–ç‰‡çš„å¢å¼·é«”é©— å¯é€é smart glass æˆ–æ‰‹æ©Ÿå¯¦ç¾ Mixed Reality (MR) å¯ä»¥å®šç¾©ç‚ºæŠŠç¾å¯¦ä¸–ç•Œå’Œè™›æ“¬ä¸–ç•Œä¸­çš„æ±è¥¿å‘ˆç¾åœ¨ä¸€èµ·çš„æ‡‰ç”¨ç¨‹å¼ï¼Œä¹Ÿå°±æ˜¯ reality-virtuality continuum ä¸Šçš„ä»»ä½•ä½ç½® MR æ¯” AR æ›´é€²ä¸€æ­¥ï¼Œä¸åªå¸Œæœ›è™›æ“¬ç‰©é«”ç–ŠåŠ åœ¨ç¾å¯¦ä¸–ç•Œä¸Šï¼Œé‚„å¸Œæœ›ä½¿ç”¨è€…å¯ä»¥åƒå°å¾…çœŸå¯¦ç‰©é«”ä¸€æ¨£å’Œä»–å€‘äº’å‹• ç‚ºäº†å¯¦ç¾ MRï¼Œéœ€è¦ä¸€å°æ•´åˆäº†é›»è…¦ã€åŠé€æ˜ç»ç’ƒã€å’Œæ„Ÿæ¸¬å™¨çš„è€³æ©Ÿ æŸç¨®æ„ç¾©ä¸Šæ˜¯æ›´å…·æ²‰æµ¸æ„Ÿçš„ AR Virtual Reality (VR) ä½¿ç”¨è€…å®Œå…¨æ²‰æµ¸åœ¨è™›æ“¬ä¸–ç•Œä¸­ï¼Œç„¡æ³•çœ‹åˆ°ç¾å¯¦ä¸–ç•Œ æœ‰ä¸‰ç¨®å…¸å‹è¨­å®šï¼šç¨ç«‹è€³æ©Ÿã€CAVE (æˆ¿é–“æ˜¯å¤§å‹æŠ•å½±å¹•)ã€é€£æ¥åˆ°é›»è…¦çš„é ­æˆ´å¼é¡¯ç¤ºå™¨ æœ€å¾Œä¸€ç¨®å·²ä½”æ“šä¸»å°åœ°ä½ Hardware parameters for extended reality æ·±å…¥äº†è§£ç¡¬é«”åƒæ•¸ä¹Ÿå¾ˆé‡è¦ï¼Œæœƒå½±éŸ¿å¯ç”¨æ€§\nField of View (FOV) äººé¡çš„ binocular FOV å¤§ç´„æ˜¯ 114 åº¦ï¼ŒXR ä½¿ç”¨çš„è¢å¹•å…·æœ‰é¡ä¼¼çš„è¦–é‡æ‰æœƒæ˜¯ç†æƒ³çš„ï¼Œç¢ºä¿ç”¨æˆ¶æœ‰ç„¡ç¸«é«”é©— é€šå¸¸ AR å’Œ VR çš„ FOV æœƒå°çš„å¤šï¼Œåªæœ‰ 30-60 åº¦ï¼Œæ¯æ¬¡å‘ˆç¾æœ‰é™çš„è™›æ“¬å…§å®¹ï¼Œç•¶éœ€è¦æ¸²æŸ“å¤§å‹è™›æ“¬ç‰©ä»¶æ™‚å°±æœƒæœ‰å•é¡Œ ç”±æ–¼ AR å’Œ MR ä¸¦ä¸æ’æ–¥ç¾å¯¦ä¸–ç•Œï¼Œæ‰€ä»¥å¦‚æœå…§å®¹å°ºå¯¸é©ç•¶ï¼Œä¸å½±éŸ¿ä½¿ç”¨è€…æ„ŸçŸ¥ ç¾ä»Šçš„ VR é ­æˆ´è£ç½® FOV å¤§å¾—å¤šï¼Œè½åœ¨ 90-110 åº¦ä¹‹é–“ ä¸€äº›å…ˆé€²çš„æ¨¡å‹ç”šè‡³è²ç¨±åˆ° 200 åº¦ï¼Œè¶…éäººé¡çš„ FOV å…·æœ‰è¼ƒå° FOV çš„è€³æ©Ÿæœƒå› ç‚ºã€Œtunnel vision effectã€è€Œåˆ†æ•£ç”¨æˆ¶çš„æ³¨æ„åŠ› Frame per Second (FPS) å°æ–¼ MR æˆ– ARï¼Œ30-60 FPS å°±è¶³å¤ äº†ï¼ŒVR å‰‡å»ºè­°çˆ­å–åˆ° 90 ç”±æ–¼ä½¿ç”¨è€…æ²‰æµ¸åœ¨é›»è…¦ç”Ÿæˆçš„å…§å®¹ï¼ŒFPS å¤ªä½æœƒå°è‡´ motion jitterï¼Œå°è‡´ç”¨æˆ¶ç”¢ç”Ÿ motion sickness FPS ä¸å–®ç”±ç¡¬é«”æ±ºå®šï¼Œä¹Ÿç”±è»Ÿé«”æ±ºå®š Software for extended reality ä½œè€…å°‡å…¶åˆ†ç‚ºå…©å¤§é¡ï¼ŒåŸºæ–¼ã€Œé–‹æ”¾é–‹ç™¼å¹³å°çš„æ–¹æ³•ã€å’ŒåŸºæ–¼ã€Œå·²æœ‰å•†æ¥­è»Ÿé«”çš„æ“´å±•æ–¹æ³•ã€ã€‚é–‹æ”¾å¼é–‹ç™¼å¹³å°çš„å„ªé»æ˜¯é–‹ç™¼éç¨‹å®Œå…¨å—æ§ï¼Œå¯ä»¥æ ¹æ“šå€‹äººéœ€æ±‚è¨‚è£½ï¼Œä½†éœ€è¦è»Ÿé«”å·¥ç¨‹æ–¹é¢çš„å°ˆæ¥­çŸ¥è­˜ã€‚\nç•¶ä»Šè£½é€ æ¥­ä½¿ç”¨çš„æˆç†Ÿå•†æ¥­è»Ÿé«”ä¹Ÿåœ¨æ“´å¤§å° XR åŠŸèƒ½çš„æ”¯æ´ï¼Œå› æ­¤ï¼Œç¾æœ‰ç”¨æˆ¶å¯ä»¥æ¯«ä¸è²»åŠ›å‰µå»º XR é«”é©—ã€‚ç„¶è€Œï¼Œä½¿ç”¨æ­¤é¡è»Ÿé«”ä¾†æ¢ç´¢ XR æ–°åŠŸèƒ½çš„è‡ªç”±åº¦æœ‰é™ï¼Œå› ç‚ºå®ƒä¾è³´è»Ÿé«”ä¾›æ‡‰å•†çš„æ›´æ–°ã€‚\nOpen development platform å…©å¤§ä¸»è¦å¹³å°æ˜¯ Unity3D å’Œ Unreal Engine 4 Established commercial software ç¯„ä¾‹ Siemens çš„ Plant Simulation é›–ç„¶ç¼ºä¹æ›´é«˜ç¨‹åº¦çš„å®¢è£½åŒ–è‡ªç”±åº¦ï¼Œä½†ç¯€çœäº†å‰µå»ºé€šç”¨åŠŸèƒ½çš„æ™‚é–“å’Œæˆæœ¬ Research Approach æœ¬æ–‡ç‚ºäº†é–‹ç™¼ä¸€å€‹å¯ä»¥æé«˜æœªä¾† XR ç³»çµ±çš„å¯ç”¨æ€§å’Œæ¥å—åº¦çš„æ¡†æ¶ï¼Œé¸æ“‡äº†å…­å€‹æ¡ˆä¾‹ã€‚\nå®ƒå€‘å„è‡ªæ¡ç”¨äº†ä»£è¡¨äº†ä¸åŒå…¬å¸è£½é€ æ´»å‹•çš„å››å€‹éšæ®µï¼šdesignã€trainingã€operationã€disruptive\nFramework development XR ç³»çµ±æ•´åˆæ¡†æ¶çš„é–‹ç™¼æ¡ç”¨äº† SDLCï¼Œä¹Ÿè¢«ç¨±ä½œ application development life cycleï¼Œå¸¸è¢«ç”¨åœ¨é–‹ç™¼å„ç¨® IT ç³»çµ±ã€‚ æè¿°äº†ç³»çµ±è¨­è¨ˆäººå“¡å’Œé–‹ç™¼äººå“¡ç‚ºäº†ç¢ºä¿é–‹ç™¼å“è³ªï¼Œéœ€è¦éµå¾ªçš„å¤šå€‹éšæ®µæ´»å‹•ã€‚\nå¤šå¹´ä¾†ï¼ŒåŸºæ–¼ SLDC æ–¹æ³•é–‹ç™¼äº†å„ç¨®æ¨¡å‹å’Œæ–¹æ³•ï¼Œæ¯”å¦‚ç€‘å¸ƒå¼é–‹ç™¼æˆ–æ˜¯ Scrumã€‚\næœ¬ç ”ç©¶ä¸­æ¡ç”¨çš„ SDLC éšæ®µå¦‚ä¸‹ï¼š\nIdentifying problems Analyzing the needs Designing the system Developing and documenting Testing the system Implementing and maintenance Case 1 Background è¦è¨“ç·´äººå“¡ç¶­è­·æ©Ÿå™¨\nResarch Process æœ‰å…¬å¸é€²è¡Œäº†æ¡ˆä¾‹ç ”ç©¶ï¼Œé–‹ç™¼äº†ä¸€ç¨®æ”¯æ´å°å‹å·¥å…·ç®±ç¶­è­·ä»»å‹™çš„ AR ç³»çµ±\nResult and conclusion æ–‡æœ¬æ•™å­¸å®¹æ˜“è¢«å¿½ç•¥ï¼Œä»¥å¸å¼•äººçš„ç‰©ä»¶ç¬¦è™Ÿæ”¹é€²ã€‚ æœ€å¾Œå•å·æŒæ­£é¢æ…‹åº¦ã€‚ ä½†é‚„æ˜¯æœ‰ä¸€äº›å¯æ”¹é€²çš„é»ï¼Œæ¯”å¦‚éœ€è¦é€£æ¥é›»è…¦ï¼Œåœ¨å¯¦éš›å·¥å» è»Šé–“ä¸¦ä¸æ–¹ä¾¿ã€‚\nCase 2 ~ Case 6 æ™‚é–“å•é¡Œæš«ä¸è£œ\nThe proposed framework é‡å°ä¸Šä¸€ç¯€ SDLC çš„æ¡ˆä¾‹ç¸½çµå’Œæ•´åˆï¼Œçµåˆäº†ä»¥ä½¿ç”¨è€…ç‚ºä¸­å¿ƒçš„ XR ç³»çµ±é–‹ç™¼äº”æ­¥é©Ÿæ¡†æ¶ã€‚\nStep 1: Understanding the requirements è½èµ·ä¾†å¾ˆé¡¯è€Œæ˜“è¦‹ï¼Œä½†å¯¦è¸ä¸­å¸¸è¢«è·³éæˆ–æ·¡åŒ–ï¼Œå°è‡´ä¸ä»¤äººæ»¿æ„çš„çµæœã€‚ è€Œä¸”è£½é€ ç’°å¢ƒæ¯”ä¸€èˆ¬ç”¨ä¾‹å ´æ™¯æ›´åŠ è¤‡é›œã€‚\nå…¨é¢äº†è§£éœ€æ±‚æ˜¯æˆåŠŸé–‹ç™¼ XR ç³»çµ±çš„é‡è¦ç¬¬ä¸€æ­¥ã€‚ ä»¥ä½¿ç”¨è€…ç‚ºä¸­å¿ƒçš„è¨­è¨ˆæ–¹æ³•ä¸­ï¼Œæ¡ç”¨çš„æ¯”å¦‚ observationã€stakeholder workshopã€contextual inquiryã€storyboardã€prototyping adopted éƒ½è¢«è­‰æ˜åœ¨æ˜¯åˆ¥éœ€æ±‚æ–¹é¢æ˜¯æœ‰æ•ˆçš„ã€‚\næ‡‰è©²è¦å¯ä»¥å›ç­”ä»¥ä¸‹å•é¡Œï¼š\nWhat actions are taken? What support are used? What outcome are achieved? What main drawbacks are there? å›ç­”ä¸Šè¿°å•é¡Œå¾Œï¼Œå°±å¯ä»¥é–‹ç™¼ storyboards å’Œ prototypes äº†ã€‚\næ­¤å¤–ï¼Œä¸åªæ˜¯é–‹ç™¼è€…å’Œè² è²¬äººï¼Œæœ€çµ‚ç”¨æˆ¶ä¹Ÿè¦å¯ä»¥åƒèˆ‡è©•ä¼°å’Œå›é¥‹ï¼Œç›´åˆ°æœ€çµ‚çš„éœ€æ±‚è¢«è§£æ±ºã€‚\nStep 2: Solution selection é€šå¸¸æ˜¯æ ¹æ“šå…¬å¸ç¾æœ‰ç¡¬è»Ÿé«”ä¾†é¸æ“‡ï¼Œè€Œä¸æ˜¯æ ¹æ“šå“ªç¨®è§£æ±ºæ–¹æ¡ˆæœ€èƒ½æ»¿è¶³è¦æ±‚ï¼Œä½¿é¸æ–¹æ¡ˆæ˜¯å€‹å›°é›£çš„æ±ºå®šã€‚\nStep 3: Data preparation Step 4: System implementation Step 5: System evaluation Iteration åœ¨å®Œæˆæ‰€ä»¥æå‡ºçš„æ­¥é©Ÿå¾Œå¯ä»¥è¿­ä»£ï¼Œä»¥å°é‡çš„æ”¹é€²é€²è¡Œè¿­ä»£ï¼Œç›´åˆ°é”æˆç‰¹å®šéœ€æ±‚ã€‚\nFramework validation è©²æ¡†æ¶è¢«ç”¨æ–¼ä¸€å€‹çœŸå¯¦æ¡ˆä¾‹ï¼Œç”¨ä¾†è©•ä¼°é©ç”¨æ€§ã€‚ æ­¤å¤–ï¼Œä»–é‚„èˆ‡å…­é …å…ˆå‰çš„ç ”ç©¶é€²è¡Œé©—è­‰ï¼Œé€™äº›ç ”ç©¶éƒ¨åˆ†èˆ‡æå‡ºçš„æ¡†æ¶ä¸€è‡´ã€‚\nThe empicial case æœ¬æ–‡çš„æ¡†æ¶è¢«ç”¨æ–¼é–‹ç™¼ VR å·¥å…·ï¼Œå¥½æ”¯æ´æ±½è»Šå…¬å¸çš„ç”¢å“è¨­è¨ˆå¯©æŸ¥ã€‚\nRequirement analysis æ˜¯ä¸€å®¶åˆ†å¸ƒå…¨çƒçš„æ±½è»Šå…¬å¸ï¼Œç ”ç™¼ä¸­å¿ƒåœ¨ç‘å…¸ï¼Œå·¥å» åœ¨ä¸­åœ‹ã€‚\nå…·é«”ä»»å‹™æ˜¯å°ç”¨æ–¼é»ç„Šçš„æ–°å‹ fixtures é€²è¡Œ design reviewã€‚\nç›®å‰çš„åšæ³•ä¾è³´ CAD è»Ÿé«”åˆ†å¸ƒåœ¨ä¸åŒåœ°é»çš„ä¸åŒåœ˜éšŠä¹‹é–“ä¾†å‚³é”ç†å¿µã€‚\nä»–é‚„éœ€è¦ä¸€å€‹æˆ–å¤šå€‹åŸå‹ï¼Œåœ¨æœ€çµ‚å®‰è£å‰é€²è¡Œé©—è­‰ã€‚\nä¸»è¦ç¼ºé»æ˜¯ï¼Œå’ŒåŸå‹å¯¦é«”ç›¸é—œçš„æºé€šååˆ†å†—é•·ã€‚\næ­¤å¤–ï¼Œæœ€çµ‚ä½¿ç”¨è€… ( operators of fixtures) ç¼ºç™¼ CAD è¨­è¨ˆçš„å°ˆæ¥­çŸ¥è­˜ï¼Œå°è‡´ä»–å€‘ç„¡æ³•åƒèˆ‡è¨­è¨ˆã€‚\nå› æ­¤ï¼Œæå‡ºäº†å…·é«”è¦æ±‚ï¼š\né©ç”¨æ–¼æ‰€æœ‰ stakeholder çš„è™›æ“¬å·¥å…·ï¼Œå¯ä»¥ç›´è§€åœ°è¦–è¦ºåŒ–æ–°ç”¢å“è¨­è¨ˆï¼Œä¸¦å’Œæ–°ç”¢å“è¨­è¨ˆäº’å‹• å¤šå€‹ stakeholder å¯ä»¥å¾ä¸åŒçš„åœ°é»åƒèˆ‡åŒä¸€å€‹ virtual session æ‰€æœ‰ stakeholder éƒ½å¯ä»¥å£é ­äº¤æµ virtual session å¯ä»¥ç”¨åœ–åƒæˆ–å½±ç‰‡å½¢å¼è¨˜éŒ„ æ¯å€‹ stakeholder éƒ½è¦æœ‰å€‹äººåŒ–è™›æ“¬ä»£è¡¨ è¦æœ‰ä¸»æŒäººã€èˆ‡æœƒè€…å’Œè§€çœ¾ç­‰è§’è‰²ç›¸é—œåŠŸèƒ½ Solution selection é¸ VR å’Œ Unity3D\nData preparation System implementation System evaluation é€²è¡Œå…©æ¬¡è¿­ä»£é–‹ç™¼ï¼Œè©•ä¼° VR ç³»çµ±æ˜¯å¦å¯ä»¥è£œå……æˆ–ç”šè‡³å–ä»£ç¾æœ‰ä½œæ³•çš„å¯è¡Œæ€§\nOutcome é–‹ç™¼äº†ä¸€å€‹å¯ä»¥æ”¯æ´æœ€å¤š 20 å€‹ä½¿ç”¨è€…å¾ä»»ä½•æœ‰ç¶²è·¯çš„åœ°æ–¹é€£ç·šåŠ å…¥çš„æ‡‰ç”¨ç¨‹å¼ã€‚\nExternal Validation ä½œè€…æŒ‘äº†ä¸ƒç¯‡æœ‰é—œçš„ XR æ•´åˆåˆ°è£½é€ æ¥­çš„ç ”ç©¶ï¼Œä»–å€‘éƒ½æ¡å–äº†é¡ä¼¼çš„æ–¹æ³•ï¼Œéƒ¨åˆ†èˆ‡æå‡ºçš„æ¡†æ¶ä¸€è‡´ã€‚\nConclusion æœ¬æ–‡ç¬¬ä¸€å€‹è²¢ç»æ˜¯æ ¹æ“šæ¡ˆä¾‹çµæœæå‡ºçš„æ¡†æ¶ï¼Œç”±äº”å€‹è¿­ä»£éšæ®µçµ„æˆï¼š\nRequirement analysis Solution selection Data preparation System implementation System evaluation é€šéä¸€å€‹å¯¦éš›æ¡ˆä¾‹ä»¥åŠä¸ƒé …å…ˆå‰çš„ç ”ç©¶é€²è¡Œäº†é©—è­‰ï¼Œé€™äº›ç ”ç©¶èˆ‡æå‡ºçš„æ¡†æ¶éƒ¨åˆ†ä¸€è‡´ã€‚\nè©²ç ”ç©¶é‚„æœƒå·¥æ¥­å¾æ¥­è€…æä¾›äº†çŸ¥è­˜ï¼Œæœ‰åˆ©ä»–å€‘æ¡ç”¨ XR æŠ€è¡“åšç‚º å·¥æ¥­ 4.0 çš„ä¸€éƒ¨åˆ†ã€‚\n","date":"2024-03-30T00:00:01+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80a-framework-for-extended-reality-system-development-in-manufacturing/","title":"è«–æ–‡é–±è®€ï¼šA Framework for Extended Reality System Development in Manufacturing"},{"content":"paper: Matryoshka Representation Learning\nAbstract æƒ³è¨­è¨ˆ flexible çš„ representation å¥½é©æ‡‰ä¸åŒçš„ä¸‹æ¸¸ä»»å‹™\nMRL æ ¹æ“šä¸åŒçš„ granularities ä¾† encode è³‡è¨Šï¼Œä¸¦å…è¨±ä¸€å€‹ single embedding ä¾†é©æ‡‰ä¸‹æ¸¸ä»»å‹™çš„é‹ç®—é™åˆ¶\nMRL å­¸ç¿’å¾ coarse-to-fine çš„ representationï¼Œè‡³å°‘å’Œç¨ç«‹è¨“ç·´ä½ç¶­åº¦çš„ representation æœ‰ä¸€æ¨£çš„æº–ç¢ºåº¦\nåœ¨ç›¸åŒç²¾æº–åº¦ä¸‹ï¼ŒMRL çš„ embedding ç¸®å° 14 å€\nåœ¨ ImageNet-1K å’Œ 4K ä¸Šé€²è¡Œå¤§è¦æ¨¡æª¢ç´¢æ™‚ï¼Œå¯¦éš›é€Ÿåº¦æå‡ 14 å€\nlong-tail few-shot learning çš„æº–ç¢ºåº¦æé«˜ 2%ï¼Œä¸¦ä¸”å’ŒåŸæœ‰ representation ä¸€æ¨£ robust\næœ€å¾Œï¼Œä½œè€…è­‰æ˜ MRL å¯ä»¥ç„¡ç¸«åœ°æ“´å±•åˆ°å„ç¨®æ¨¡å¼çš„ç¶²è·¯è¦æ¨¡è³‡æ–™é›†ï¼ŒåŒ…å« Vision, Vision + Language, å’Œ Language\nIntroduction deep representation çš„ deployment æœ‰å…©å€‹æ­¥é©Ÿï¼š\næ˜‚è²´çš„ forward-pass è¨ˆç®— representation representations åœ¨ä¸‹æ¸¸çš„åˆ©ç”¨ (æ¯”å¦‚æª¢ç´¢) åœ¨ web-scale ä¸Šï¼Œé€™ç¨®åˆ©ç”¨çš„æˆæœ¬è“‹éäº†ç‰¹å¾µè¨ˆç®—æˆæœ¬\nå¸¸è¦‹çš„åšæ³•çš„ representation çš„å‰›æ€§è¿«ä½¿å¤šå€‹ä»»å‹™ä¸­ä½¿ç”¨é«˜ç¶­åµŒå…¥å‘é‡\näººé¡å°è‡ªç„¶ä¸–ç•Œçš„æ„ŸçŸ¥æ˜¯ç”±ç²—åˆ°ç´°çš„ç²’åº¦\nç„¶è€Œï¼Œæˆ–è¨±æ˜¯åŸºæ–¼æ¢¯åº¦è¨“ç·´çš„ inductive-biasï¼Œæ·±åº¦å­¸ç¿’å‚¾å‘æ–¼å°‡ã€Œè³‡è¨Šã€æ“´æ•£åˆ°æ•´å€‹è¡¨ç¤ºå‘é‡ä¸­\né€šå¸¸é€éè¨“ç·´å¤šå€‹ä½ç¶­æ¨¡å‹ã€è¯åˆå„ªåŒ–ä¸åŒå®¹é‡çš„å­ç¶²è·¯ã€äº‹å¾Œå£“ç¸®ï¼Œåœ¨ç¾æœ‰çš„ fixed representation ä¸Šå¯¦ç¾å½ˆæ€§\né€™äº›æŠ€è¡“ä¸­çš„æ¯ä¸€ç¨®éƒ½é›£ä»¥æ»¿è¶³è‡ªé©æ‡‰å¤§è¦æ¨¡éƒ¨å±¬çš„è¦æ±‚ï¼ŒåŸºæ–¼é–‹éŠ· / ç¶­è­·è€ƒé‡ç­‰ç­‰\nMRL ä»¥ nested çš„æ–¹å¼ä¾†å­¸ç¿’ O(log(d)) å€‹ç›¸åŒçš„é«˜ç¶­å‘é‡ã€ä½†ä¸åŒ capacity çš„ representationï¼Œå› æ­¤è¢«ç¨±ç‚º Matryoshka\nMatryoshka Representation æé«˜äº†å¤§è¦æ¨¡åˆ†é¡å’Œæª¢ç´¢çš„æ•ˆç‡ï¼Œè€Œä¸æœƒé¡¯è‘—å¤±å»æº–ç¢ºåº¦\næœ¬æ–‡é‡é»é—œæ³¨åœ¨æ©Ÿå™¨å­¸ç¿’ç³»çµ±çš„å…©å€‹é—œéµæ¨¡çµ„ï¼šå¤§è¦æ¨¡åˆ†é¡å’Œæª¢ç´¢\nåœ¨åˆ†é¡ä¸Šï¼Œä½œè€…ä½¿ç”¨ variable-size representations çµåˆ adaptive cascades ä¾†é¡¯è‘—æ¸›å°‘å¯¦ç¾ç‰¹å®šç²¾åº¦æ‰€éœ€åµŒå…¥çš„å¹³å‡ç¶­åº¦\nä¾‹å¦‚ï¼Œåœ¨ ImageNet-1K ä¸Šï¼ŒMRL + Adaptive classification åœ¨å’Œ baseline åŒç²¾æº–åº¦çš„æƒ…æ³ä¸‹å°‡ representation ç¸®å° 14 å€\nå°æ–¼æª¢ç´¢ï¼Œå…ˆç”¨ query embedding ä¸€é–‹å§‹çš„ few dimensions ä¾†æ¸›å°‘ retrieval candidatesï¼Œç„¶å¾Œå†ç”¨æ›´å¤šçš„ dimensions ä¾† re-rank retrieved set\nMRL çš„æª¢ç´¢ç²¾ç¢ºåº¦å’Œ single-shot retrieval ç›¸ç•¶\nä¸»è¦è²¢ç»å¦‚ä¸‹ï¼š\næå‡ºäº† MRL ä¾†ç²å¾— filexible çš„ representation for adaptive deployment ä½¿ç”¨ MRL é€²è¡Œå¤§è¦æ¨¡åˆ†é¡å’Œæª¢ç´¢ï¼Œé€Ÿåº¦æé«˜ 14 å€è€Œä¸”ä¸€æ¨£æº–ç¢º å¯ä»¥åœ¨è·¨ modalities é‚„æœ‰å¯æ¥å— web-scale è³‡æ–™çš„æƒ…æ³ä¸‹ç„¡ç¸«èª¿æ•´ MRL åœ¨å…¶ä»–ä¸‹æ¸¸ä»»å‹™çš„èƒŒæ™¯ä¸‹é€²ä¸€æ­¥åˆ†æ MRL çš„è¡¨ç¤º Related Work Efficient Classification and Retrieval åœ¨æ¨ç†éç¨‹ä¸­ï¼Œåˆ†é¡å’Œæª¢ç´¢çš„æ•ˆç‡å¯ä»¥å¾å…©å€‹æ–¹é¢ç ”ç©¶ï¼š\næ·±åº¦ç‰¹å¾µçš„é«˜ä½†æ†å®šçš„æˆæœ¬ éš¨è‘—æ¨™ç±¤ç©ºé–“å’Œæ•¸æ“šå¤§å°è€Œè®ŠåŒ–çš„æœç´¢æˆæœ¬ ç¬¬ä¸€å€‹å•é¡Œå¯ä»¥é€éä¸åŒçš„æ¼”ç®—æ³•è¨­è¨ˆé«˜æ•ˆçš„ç¥ç¶“ç¶²è·¯ä¾†è§£æ±º\nä½†æ˜¯ï¼Œä¼´éš¨è‘—å¼·å¤§çš„ featurizerï¼Œå¤šæ•¸ scale ç›¸é—œçš„å•é¡Œå‡ºåœ¨ æ¨™ç±¤æ•¸é‡(L)ã€è³‡æ–™å¤§å°(N)ã€æˆ–æ˜¯è¡¨ç¤ºç¶­åº¦(d) é€™ç¨® linear dependence ä¸Š\nè®“ RAM, disk å’Œ CPU éƒ½åŒæ™‚æœ‰å·¨å¤§çš„å£“åŠ›\næ¨™ç±¤æ•¸é‡åœ¨è¨ˆç®—å’Œ RAM æ–¹é¢å·²ç¶“å¾—åˆ°äº†å¾ˆå¥½çš„ç ”ç©¶ï¼Œå¯ä»¥é€é Approximate Nearest Neighbor Search (ANNS) æˆ– leveraging the underlying hierarchy ä¾†è§£æ±º\nåœ¨è¡¨ç¤ºå¤§å°æ–¹é¢ï¼Œé™ç¶­ã€Hash å’Œç‰¹å¾µé¸æ“‡ç­‰æŠ€è¡“å¸¸ç”¨æ–¼ç·©è§£ O(d) çš„å¢é•·è¦æ¨¡ï¼Œä½†ä»£åƒ¹æ˜¯ç²¾ç¢ºåº¦çš„é¡¯è‘—é™ä½\nANNS ä½¿ç”¨æˆ¶å¯ä»¥å¾è³‡æ–™åº«ä¸­å–å¾—å’Œè«‹æ±‚æœ€ç›¸ä¼¼çš„æ–‡ä»¶æˆ–åœ–ç‰‡\nå»£æ³›æ¡ç”¨çš„ HNSW å¯ä»¥è®“ O(d log(N)) å’Œæº–ç¢ºæœç´¢ O(dN) ä¸€æ¨£ç²¾æº–ï¼Œä½†ä»£åƒ¹æ˜¯éœ€è¦åœ¨ RAM å’Œ disk æ‰¿æ“” graph-based index çš„é–‹éŠ·\nMRL è§£æ±ºå° d çš„ç·šæ€§ä¾è³´å•é¡Œï¼Œä½ç¶­åº¦çš„ Mayryoshka representations å’Œç¨ç«‹è¨“ç·´çš„ representations ä¸€æ¨£æº–ç¢ºï¼Œè€Œä¸éœ€è¦å¤šæ¬¡æ˜‚è²´çš„å‰å‘å‚³é\nMatryoshka Representation Learning æœ‰åˆ†å…©ç¨®è¨“ç·´æ–¹æ³•ï¼š\nMatryoshka Representation Learning (MRL)\nåœ¨å¾Œé¢æ¥ 9 å±¤ MLPï¼Œä¸æ˜¯ä¸²è¯ï¼Œæ˜¯ä¸¦è¯ æ¯”å¦‚ mlp(768,8)\u0026hellip;., mlp(768,2048) Efficient Matryoshka Representation Learning (MRL-E)\nåœ¨å¾Œé¢åªæ¥ 1 å±¤ï¼Œç„¶å¾Œå–å‰é¢ç¶­åº¦å¾—åˆ°ä¸€å€‹å‘é‡ï¼Œä»¥æ­¤é¡æ¨ æ¯”å¦‚ mlp(768, 2048)ï¼Œå¯èƒ½å–å‰ 16 ç¶­ç•¶ä¸€å€‹å‘é‡ï¼Œç„¶å¾Œå†å–å‰ 64 ç¶­ç•¶ä¸€å€‹å‘é‡ ","date":"2024-02-26T00:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/mrl-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"MRL è«–æ–‡é–±è®€"},{"content":"paper: REALM: Retrieval-Augmented Language Model Pre-Training\nAbstract ç‚ºäº†ç”¨æ›´åŠ æ¨¡çµ„åŒ–å’Œå¯è§£é‡‹çš„æ–¹å¼ç²å–çŸ¥è­˜ï¼Œä½œè€…ç”¨ latent knowledge retriever ä¾†åŠ å¼·èªè¨€æ¨¡å‹çš„é è¨“ç·´ï¼Œlatent knowledge retriever å…è¨±æ¨¡å‹æª¢ç´¢ large corpus çš„ documentï¼Œä¸¦åœ¨é è¨“ç·´ã€å¾®èª¿å’Œæ¨ç†æ™‚ä½¿ç”¨ã€‚\nIntroduction åœ¨è«¸å¦‚ BERT çš„èªè¨€æ¨¡å‹ä¸­ï¼Œå­¸åˆ°çš„ world knowledge éš±å¼åœ°å„²å­˜åœ¨ç¥ç¶“ç¶²è·¯çš„åƒæ•¸ä¸­ï¼Œä½¿å…¶å¾ˆé›£ç¢ºå®šå„²å­˜äº†å“ªäº›çŸ¥è­˜ä»¥åŠå„²å­˜åœ¨ä½•è™•ã€‚è€Œä¸”å„²å­˜ç©ºé–“å—ç¶²è·¯å¤§å°é™åˆ¶ï¼Œä½†è¨“ç·´æ›´å¤§çš„ç¶²è·¯å¯èƒ½éå¸¸æ˜‚è²´\næœ¬æ–‡ç‚ºäº†ä»¥æ›´åŠ å¯è§£é‡‹å’Œæ¨¡çµ„åŒ–çš„æ–¹å¼ç²å–çŸ¥è­˜ï¼Œæå‡ºäº†ä¸€å€‹æ–°ç©çš„æ¡†æ¶ï¼ŒRetrieval-Augmented Language Model (REALM) é è¨“ç·´ï¼Œé€é learned textual knowledge retriever ä¾†åŠ å¼·é è¨“ç·´\nå’ŒæŠŠçŸ¥è­˜å„²å­˜åœ¨åƒæ•¸ä¸­çš„æ¨¡å‹ç›¸æ¯”ï¼Œè©²æ–¹æ³•é¡¯ç¤ºåœ°æ­ç¤º world knowledge æ‰®æ¼”çš„è§’è‰²ï¼Œåšæ³•æ˜¯è¦æ±‚æ¨¡å‹åœ¨æ¨ç†éç¨‹ä¸­æ±ºå®šå“ªäº›çŸ¥è­˜ä¾† retrieveï¼Œä¸¦ç”¨åœ¨æ¨ç†éšæ®µ\nåœ¨æ¯æ¬¡é æ¸¬å‰ï¼Œèªè¨€æ¨¡å‹ä½¿ç”¨ retriever åœ¨ large corpus æœç´¢æ–‡ä»¶ï¼Œä¸¦ç”¨é€™äº›æ–‡ä»¶å¹«åŠ©é æ¸¬\nEnd to End çš„å­¸ç¿’éœ€è¦è€ƒæ…®æ•´å€‹æª¢ç´¢æ­¥é©Ÿï¼Œå¥½é€²è¡Œåå‘å‚³æ’­\nREALM æœ‰å€‹é—œéµç›´è¦ºï¼Œå°±æ˜¯è¨“ç·´ retriever çš„æ™‚å€™ç”¨çš„æ˜¯ unsupervised text çš„ performance-based signalï¼š\nä¸€å€‹å¯ä»¥æé«˜èªè¨€æ¨¡å‹è¤‡é›œæ€§çš„æª¢ç´¢æ˜¯æœ‰å¹«åŠ©ï¼Œä¸”è©²è¢«çå‹µçš„ è³‡è¨Šä¸è¶³çš„æª¢ç´¢æ‡‰è©²å—åˆ°æ‡²ç½° æ¯”å¦‚åœ– Fig.1 æ‰¾åˆ°çš„æ–‡ä»¶å°±è©²ç²å¾—çå‹µ\nä½œè€…å°‡ retrieve-then-predict çš„æ–¹æ³•å»ºæ¨¡ä¸¦è¦–ä½œ latent variable language model ä¸¦å„ªåŒ– marginal likelihood\nä½†åœ¨é è¨“ç·´æœŸé–“è¦è¨“ç·´å¤§è¦æ¨¡çš„ retrieval module æˆç‚ºå•é¡Œï¼Œå› ç‚º Retriever å¾—ç‚ºæ¯å€‹é è¨“ç·´æ­¥é©Ÿè€ƒæ…®æ•¸ç™¾è¬å€‹å€™é¸æ–‡æª”ï¼Œè€Œä¸”å¿…é ˆæ ¹æ“šæ±ºç­–åå‘å‚³æ’­ã€‚ç‚ºäº†è§£æ±ºé€™å•é¡Œï¼Œä½œè€…å»ºæ§‹äº† retrieverï¼Œä»¥ä¾¿å¿«å–å’ŒéåŒæ­¥æ›´æ–°æ¯å€‹æ–‡ä»¶çš„è¨ˆç®—ï¼Œä¸¦å°‡æœ€ä½³æ–‡ä»¶çš„é¸æ“‡è¡¨ç¤ºç‚º Maximum Inner Product Search (MIPS)\né€éåœ¨ Open-QA ä»»å‹™ä¸Šä½¿ç”¨ REALM é è¨“ç·´çš„ model ä¾† finetune é€²è¡Œè©•ä¼°ï¼ŒOpenQA æ˜¯æœ€ knowledge-intensive çš„ä»»å‹™ä¹‹ä¸€\nä½œè€…æŒ‘äº†ä¸‰å€‹æµè¡Œçš„ Open-QA benchmarkï¼Œæ¯”å¦‚ NaturalQuestions-Openã€WebQuestionsã€CuratedTrecï¼Œä¸¦å’Œ SOTA Open-QA model æ¯”è¼ƒ\nåœ¨ä¸‰å€‹åŸºæº–éƒ½å–å¾—äº† SOTA çš„çµæœï¼Œabsolute accuracy æ˜é¡¯é«˜æ–¼å…ˆå‰ç³»çµ± 4-16%\nä¹Ÿå±•ç¤ºäº† REALM çš„ qualitative benefitï¼Œæ¯”å¦‚å¯è§£é‡‹æ€§å’Œæ¨¡çµ„åŒ–\nBackground Open-domain question answering (Open-QA) OpenQA çš„ open æ˜¯æŒ‡æ¨¡å‹ä¸æœƒæ¥æ”¶åˆ°åŒ…å«ç­”æ¡ˆçš„é æä¾›æ–‡ä»¶ï¼Œå’Œå‚³çµ±çš„é–±è®€ç†è§£ä¸åŒ\nApproach REALMâ€™s generative process é è¨“ç·´åš masked language modelingï¼Œå¾®èª¿çš„ä»»å‹™æ˜¯ Open-QA\nModel architecture neural knowledge retriever æ˜¯ $p(z|x)$\nknowledge-augmented encoder æ˜¯ $p(y|z,x)$\nKnowledge Retriever $p(z|x)=\\frac{\\text{exp }f(x,z)}{\\sum_{z\u0026rsquo;}\\text{exp }f(x,z\u0026rsquo;)}$\n$f(x,z) = Embed_{input}(x)^T Embed_{doc}(z)$\n$join_{BERT}(x)=[CLS]x[SEP]$\n$join_{BERT}(x_1, x_2)=[CLS]x_1[SEP]x_2[SEP]$\n$Embed_{input}(x)=W_{input}BERT_{CLS}(join_{BERT}(x))$\n$Embed_{doc}(z)=W_{doc}BERT_{CLS}(join_{BERT}(z_{title}, z_{body}))$\nKnowledge-Augmented Encoder Finetune:\n$p(y|z,x) \\propto \\displaystyle\\sum_{s\\in S(z,y)}exp(MLP([h_{START(s)};h_{END(s)}]))$\n$h_{START(s)}=BERT_{START(s)}(join_{BERT}(x,z_{body}))$\n$h_{END(s)}=BERT_{END(s)}(join_{BERT}(x,z_{body}))$\nTraining é—œéµçš„è¨ˆç®—æŒ‘æˆ°æ˜¯ $p(y|x)=\\sum_{z\\in Z}p(y|x,z)p(z,x)$ï¼Œæ¶‰åŠåˆ° Z knowledge corpus ä¸­çš„ æ‰€æœ‰ document zï¼Œå› æ­¤åªå–æ©Ÿç‡ $p(z|x)$ æœ€é«˜çš„ top k æ–‡ä»¶ä¾†æ±‚å’Œï¼Œè€ƒé‡åˆ°å¤šæ•¸æ–‡ä»¶çš„æ©Ÿç‡æ‡‰è©²ç‚º 0ï¼Œé€™æ˜¯åˆç†çš„\nä½†æ˜¯ä¾ç„¶éœ€è¦ä¸€å€‹æœ‰æ•ˆçš„æ–¹æ³•ä¾†å°‹æ‰¾å‰ k å€‹æ–‡ä»¶\nå‰é¢çš„ $f(x,z)$ æ˜¯ä¸€å€‹å…§ç©ï¼Œå¯ä»¥ç”¨ Maximum Inner Product Search (MIPS) æ¼”ç®—æ³•ä¾†å°‹æ‰¾è¿‘ä¼¼å‰ k å€‹æ–‡æª”\nç‚ºäº†ç”¨ MIPSï¼Œè¦å…ˆç”¨ä¸€ç¨® embedding å‡½å¼ä¾†å¹« z encodeï¼Œä½†æ˜¯å¦‚æœæ›´æ–°äº†é€™å€‹å‡½å¼ï¼Œè³‡æ–™çµæ§‹å’Œ $p(z|x)$ åˆæœƒä¸ä¸€è‡´\nå› æ­¤ï¼Œæ¯æ¬¡å° embedding å‡½å¼æ›´æ–°å¾Œï¼Œsearch index éƒ½æœƒè®Š \u0026ldquo;stale\u0026rdquo; (é™³èˆŠ)\næ¯éš”æ•¸ç™¾å€‹è¨“ç·´æ­¥é©ŸéåŒæ­¥é‡æ–° embed å’Œ index æ‰€æœ‰ document ä¾†åˆ·æ–° index\nMIPS çš„ index åœ¨åˆ·æ–°ä¹‹å‰æœƒæœ‰é» staleï¼Œä½†å®ƒåªç”¨æ–¼æŒ‘é¸å‰ k å€‹æ–‡ä»¶\nçµæœè­‰æ˜ï¼Œåªè¦åœ¨æ°ç•¶çš„åˆ·æ–°ç‡ä¸‹ï¼Œé‚„æ˜¯å¯ä»¥ç©©å®š optimize\nWhat does the retriever learn? é€™è£¡å±•ç¤ºäº†å®ƒå¦‚ä½•çå‹µæé«˜é æ¸¬æº–ç¢ºæ€§çš„æª¢ç´¢\n$\\triangledown \\text{log }p(y|x)=\\displaystyle\\sum_{z\\in Z}r(z)\\triangledown f(x,z)$\n$r(z)=[\\frac{p(y|z,x)}{p(y|x)}-1]p(z|x)$\nå¦‚æœ $r(z)$ æ˜¯æ­£çš„ï¼Œæœƒè®“ f(x,z) æé«˜ï¼Œå¦å‰‡æ¸›ä½\n$r(z)$ åªæœ‰åœ¨ $p(y|z,x)\u0026gt;p(y|x)$ çš„æƒ…æ³ä¸‹æ‰æœƒæ˜¯æ­£çš„\n$p(y|x)$ æ˜¯ $p(y|x,z)$ åœ¨éš¨æ©Ÿå–æ¨£çš„æƒ…æ³ä¸‹çš„æœŸæœ›å€¼\nåªè¦æ–‡æª” z å¥½éé æœŸï¼Œå°±æœƒæŒçºŒæ­£é¢æ›´æ–°\nInjecting inductive biases into pre-training åœ¨ç™¼å±• REALM çš„éç¨‹ä¸­ï¼Œä½œè€…ç™¼ç¾å¹¾å€‹é¡å¤–ç­–ç•¥ï¼Œå¯ä»¥é€²ä¸€æ­¥å¼•å°æ¨¡å‹é€²è¡Œæœ‰æ„ç¾©çš„æª¢ç´¢\nSalient span masking æœ‰ä¸€äº› MLM span åªéœ€è¦ local contextï¼Œä½†ä½œè€…æƒ³å°ˆæ³¨æ–¼ world knowledge\næ‰€ä»¥ä½œè€…æœƒ mask ä¸€äº› salient spanï¼Œæ¯”å¦‚ã€Œè‹±åœ‹ã€ã€ã€Œ1969 å¹´ 7 æœˆã€\nä½œè€…ç”¨åœ¨ CoNLL-2003 ä¸Šè¨“ç·´çš„ BERT-based taggerï¼Œä¾†æ‰¾å‡º named entitiesï¼Œä¸¦ç”¨æ­£è¦è¡¨é”å¼ä¾†æ‰¾å‡ºæ—¥æœŸ\nçµæœè¡¨æ˜é€™é¡¯è‘—å„ªæ–¼å…¶ä»– mask ç­–ç•¥\nNull document é›–ç„¶ Salient span masking è¡¨ç¾å¾ˆå¥½ï¼Œä½†ä¸æ˜¯æ‰€æœ‰ mask éƒ½éœ€è¦ world knowledge\né€éå‘å‰ top k æ–‡æª”ä¸­å¤šåŠ ä¸€å€‹ç©ºçš„æ–‡æª”ï¼Œå…è¨±åœ¨ä¸éœ€è¦æª¢ç´¢æœ‰ç©ºç™½é¸é …\nProhibiting trivial retrievals å¦‚æœ mask çš„å¥å­ä¾†è‡ªæ–‡ä»¶ zï¼Œå¯ä»¥é€éæŸ¥çœ‹ z ä¸­ x çš„ unmasked ç‰ˆæœ¬ä¾†è¼•é¬†é æ¸¬ yï¼Œä½¿ p(z|x) å‡ºç¾è¼ƒå¤§çš„æ¢¯åº¦ï¼Œå¦‚æœé€™ç¨®æƒ…æ³å¤ªé »ç¹ï¼Œæœƒä½¿ retriever æœ€çµ‚å­¸æœƒçš„æ±è¥¿åå‘ exact matchï¼Œè€Œä¸æœƒæ•ç²å…¶ä»–å½¢å¼çš„ç›¸é—œæ€§\nå› æ­¤ï¼Œåœ¨é è¨“ç·´æœŸé–“æ’é™¤äº† trivial candidate\nInitialization åœ¨è¨“ç·´é–‹å§‹æ™‚ï¼Œå¦‚æœ input å’Œ document å„è‡ªçš„ Embedding function æ²’æœ‰è‰¯å¥½çš„æ•ˆèƒ½ï¼Œæœƒä½¿æª¢ç´¢åˆ°çš„ z å’Œ x ç„¡é—œ\næœƒå°è‡´æ¨¡å‹å­¸ç¿’å¿½ç•¥æª¢ç´¢åˆ°çš„æ–‡ä»¶ï¼Œæª¢ç´¢å™¨å°±ä¸æœƒæ”¶åˆ°æœ‰æ„ç¾©çš„æ¢¯åº¦ï¼Œä¹Ÿç„¡æ³•æ”¹é€²\nç‚ºäº†é¿å… cold-start problemï¼Œä½œè€…æ¡ç”¨ warm-start æ–¹æ¡ˆï¼Œå…ˆä»¥ Inverse Cloze Task (ICT) é€™ç¨®ç°¡å–®çš„ç›®æ¨™ä¾†è™•ç†å…©å€‹ embedding functionï¼Œçµ¦å®šä¸€å€‹å¥å­ï¼Œè¨“ç·´æ¨¡å‹æª¢ç´¢å¥å­ä¾†è‡ªçš„æ–‡æª”\nExperiments Open-QA Benchmarks æœ¬æ–‡å°‡é‡é»æ”¾åœ¨å•é¡Œä½œè€…ä¸çŸ¥é“ç­”æ¡ˆçš„è³‡æ–™é›†ï¼Œæ¯”è¼ƒèƒ½åæ˜ ç¾å¯¦ä¸­çš„å•é¡Œ\nNaturalQuestions-Open ç”±è‡ªç„¶ç™¼ç”Ÿçš„ google æŸ¥è©¢å’Œç­”æ¡ˆçµ„æˆï¼Œæ¯å€‹ç­”æ¡ˆé‚„å¸¶æœ‰ answer type\næœ¬æ–‡åªç”¨å±¬æ–¼ \u0026ldquo;short answer type\u0026rdquo; çš„å•é¡Œï¼Œæœ€å¤šæœ‰ 5 å€‹ token\nWebQuestions å¾ Google Suggest API æ”¶é›†çš„\nCuratedTrec å¾ MSNSearch å’Œ AskJeeves ç­‰ç¶²ç«™ä¸ŠçœŸå¯¦ä½¿ç”¨è€…æŸ¥è©¢ä¸­æå–çš„å•ç­”\nApproaches compared Retrieval-based Open-QA æœ€è¿‘çš„ä¸€äº›æ–¹æ³•æå‡ºç”¨ MIPS index ä¾†å¯¦ç¾å¯è¨“ç·´çš„æª¢ç´¢\nORQA èˆ‡ REALM é¡ä¼¼\nä½† REALM æå‡ºäº†æ›´æ–°ç©çš„æ¨¡å‹é è¨“ç·´æ­¥é©Ÿï¼Œä¸¦åå‘å‚³æ’­åˆ° MIPS index ä¸­ï¼Œè€Œä¸ç”¨å›ºå®šçš„ index\nä¸Šé¢æŒ‡çš„æ‡‰è©²æ˜¯æœ‰é—œæ–¼éåŒæ­¥æ›´æ–° index çš„éƒ¨åˆ†ï¼Œé‚„å¯ä»¥æ¢¯åº¦æ›´æ–°\nå€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒREALM å’Œ OrQA çš„é è¨“ç·´éƒ½æ˜¯ç”¨ ICT åˆå§‹åŒ–çš„\nGeneration-based Open-QA Open-QA çš„æ–°èˆˆæ›¿ä»£æ–¹æ¡ˆæ˜¯å°‡å…¶å»ºæ¨¡ç‚ºåºåˆ—é æ¸¬ä»»å‹™ï¼Œåªéœ€å°å•é¡Œé€²è¡Œç·¨ç¢¼ï¼Œç„¶å¾Œæ ¹æ“šç·¨ç¢¼é€å€‹æ¨™è¨˜ç·¨ç¢¼ç­”æ¡ˆ\nGPT2 å¯ä»¥é€é sequence to sequence ç›´æ¥ç”¢ç”Ÿç­”æ¡ˆï¼Œè€Œä¸éœ€è¦çµ¦æŒ‡å®šçš„ä¸Šä¸‹æ–‡ï¼Œä½†å¯èƒ½ç”±æ–¼ç¼ºä¹ finetune è€Œæ²’æœ‰ç«¶çˆ­åŠ›\nåŒæ™‚ï¼ŒT5 è¡¨æ˜ï¼Œç›´æ¥ç”Ÿæˆç­”æ¡ˆè€Œä¸å¾çµ¦å®šä¸Šä¸‹æ–‡ä¸­æ˜ç¢ºæå–æ˜¯å¯è¡Œçš„æ–¹æ³•ï¼Œä½†ä»–å€‘åªåœ¨æä¾›ä¸Šä¸‹æ–‡æ–‡æª”çš„é–±è®€ç†è§£ä»»å‹™ä¸Šé€²è¡Œå¯¦é©—\nç‚ºäº†å’Œæœ€å…·ç«¶çˆ­åŠ›çš„ baseline æ¯”è¼ƒï¼Œæœ¬æ–‡èˆ‡é‡å° Open-QA finetune çš„ T5 é€²è¡Œæ¯”è¼ƒ\nImplementation Details Fine-tuning æ–‡ä»¶è¢«è²ªå©ªåœ°åˆ†å‰²æˆå¤šé” 288 å€‹ BERT wordpieces çš„ chunkï¼Œç”¢ç”Ÿè¶…é 1300 è¬å€‹ retrieval candidates\nåœ¨å¾®èª¿æ¨ç†éç¨‹ä¸­ï¼Œè€ƒæ…®å‰äº”å€‹å€™é¸è€…\nPre-training ä½¿ç”¨ BERT çš„é è¨­å„ªåŒ–å™¨åœ¨ 64 å€‹ Google Cloud TPU ä¸Šé è¨“ç·´ 20 è¬æ­¥\nMIPS åœ¨ 16 å€‹ TPU ä¸Šä¸¦è¡Œ\nMain results REALM åœ¨ table.1 æ˜é¡¯å„ªæ–¼ä¹‹å‰çš„æ‰€æœ‰æ–¹æ³•\nREALM æœ€ç›´æ¥çš„æ¯”è¼ƒæ˜¯ ORQAï¼Œå¾®èª¿è¨­å®šã€è¶…åƒæ•¸å’Œè¨“ç·´è³‡æ–™éƒ½ç›¸é€š\nREALM å°æ¯” ORQA çš„æ”¹é€²ç´”ç²¹æ˜¯æ›´å¥½çš„é è¨“ç·´æ–¹æ³•\nè€Œä¸”æœ¬æ–‡è¡¨æ˜ä»–å€‘çš„é è¨“ç·´æ–¹æ³•å¯ä»¥ç”¨åœ¨ single-corpus setting æˆ– seperate corpus setting\nå…©è€…çš„å·®åˆ¥åœ¨ X å’Œ Z ä¾†æºä¸€ä¸ä¸€æ¨£\nAnalysis table.2 å±•ç¾äº†å»é™¤ REALM é—œéµçµ„ä»¶å¾Œçš„çµæœ\né‚„å±•ç¾äº† finetune å‰ gold answer å‡ºç¾åœ¨å‰äº”å€‹æª¢ç´¢ä¸­çš„é »ç‡\nMasking scheme salient span masking åœ¨å…ˆå‰æ¨™æº–çš„ BERT è¨“ç·´ä¸­å°šæœªè¢«è­‰æ˜å…·æœ‰å½±éŸ¿åŠ›ï¼Œä½†å°æ–¼ REALM è‡³é—œé‡è¦\nMIPS index refresh rate åœ¨é è¨“ç·´æœŸé–“ï¼Œé‹è¡Œä¸¦è¡Œéç¨‹ä¾†é‡æ–° embed document å’Œé‡å»º MIPS index\nå°è‡´æ¯å¤§ç´„ 500 å€‹è¨“ç·´æ­¥é©Ÿåˆ·æ–°ä¸€æ¬¡ index\nç‚ºäº†è­‰æ˜é »ç¹åˆ·æ–°çš„é‡è¦æ€§ï¼Œä¹Ÿå’Œè¼ƒæ…¢åˆ·æ–°ç‡æ¯”è¼ƒ\ntable.2 é¡¯ç¤ºï¼Œstale index å¯èƒ½æœƒå‚·å®³æ¨¡å‹ï¼Œé€²ä¸€æ­¥æ¸›å°‘é€™ç¨®éæ™‚æ€§å¯ä»¥æä¾›æ›´å¥½çš„æœ€ä½³åŒ–\nDiscussion and Related Work Scalable grounded neural memory document index å¯ä»¥è¢«è¦–ç‚ºä¸€ç¨® memoryï¼Œkey æ˜¯ document embedding\nå¾é€™è§’åº¦ä¾†çœ‹ï¼Œæœ¬æ–‡çš„å·¥ä½œå’Œ product key memory æœ‰å…±åŒçš„å‹•æ©Ÿï¼Œå®ƒèƒ½å¤ åœ¨è¨˜æ†¶é«”ç¶²è·¯ä¸­å¯¦ç¾ä½æ–¼ç·šæ€§çš„å­˜å–\nä¸€å€‹ä¸»è¦çš„å€åˆ¥æ˜¯æœ¬æ–‡çš„è¨˜æ†¶é«”æ˜¯æœ‰æ ¹æ“šçš„ï¼Œæ¯å€‹ memory éƒ½å’Œä¸€å€‹æ–‡æª”ç›¸é—œè¯ï¼Œè€Œä¸æ˜¯å’Œ unnamed value vector ç›¸é—œè¯\né€™ç¨®ç¨‹åº¦çš„å¯è§£é‡‹æ€§å° Open-QA è‡³é—œé‡è¦ï¼Œåœ¨é€™äº›æ‡‰ç”¨ç¨‹å¼ä¸­ï¼Œç”¨æˆ¶éœ€è¦å‡ºè™•æ‰èƒ½ä½¿é æ¸¬ç­”æ¡ˆå€¼å¾—ä¿¡è³´\nFuture Work ","date":"2024-01-05T00:00:13+08:00","permalink":"https://roykesydon.github.io/Blog/p/realm-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"REALM è«–æ–‡é–±è®€"},{"content":"paper: Dense Passage Retrieval for Open-Domain Question Answering\nAbstract Open-domain question answering ä¾è³´æœ‰æ•ˆçš„ passage retrieval ä¾†é¸æ“‡ candidate contextï¼Œå‚³çµ±ä¸Šç”¨çš„ sparse vector space modelsï¼Œæœ‰ TF-IDFã€BM25 ç­‰ç­‰\næœ¬æ–‡é¡¯ç¤ºå‡ºæª¢ç´¢å¯¦éš›ä¸Šå¯ä»¥åªç”¨ dense representationï¼Œembedding æ˜¯å¾å°‘é‡çš„ question å’Œ passage å­¸åˆ°çš„ï¼Œåˆ©ç”¨ç°¡å–®çš„ dual-encoder framework\nåœ¨å»£æ³›çš„ open-domain QA è³‡æ–™é›†ä¸Šï¼Œæœ¬æ–‡çš„ dense retriever åœ¨ top-20 passage retrieval accuracy ä¸Šæ¯” Lucene BM25 å¥½ 9%-19%\nä¸¦å¹«åŠ©ä½œè€…çš„ end-to-end QA system åœ¨ multiple open-domain QA benchmarks ä¸Šå–å¾— SOTA\nIntroduction æ—©æœŸé–±è®€ç†è§£æ¨¡å‹æå‡ºäº†ç°¡å–®çš„ two-stage frameworkï¼š\nä¸€å€‹ context retriever å…ˆé¸å®šä¸€äº› passage å­é›†åˆï¼Œå…¶ä¸­æŸä¸€äº› passage åŒ…å«ç­”æ¡ˆ\nä¸€å€‹ machine readerï¼Œå¯ä»¥å¾¹åº•æª¢æŸ¥é¸å‡ºçš„ context ä¸¦æ‰¾åˆ°ç­”æ¡ˆ\nç›¡ç®¡å°‡ open-domain QA ç°¡åŒ–ç‚º machine reading æ˜¯ä¸€å€‹åˆç†çš„ç­–ç•¥ï¼Œä½†æ˜¯å¯¦éš›ä¸Šç¶“å¸¸çœ‹åˆ°åš´é‡çš„æ€§èƒ½ä¸‹é™ï¼Œé¡¯ç¤ºå‡ºéœ€è¦æ”¹é€² retrieval\nopen-domain QA ä¸­çš„ retrieval é€šå¸¸ç”¨ TF-IDF æˆ– BM25 ä¾†å¯¦ç¾ï¼Œå¯ä»¥é€é inverted index æœ‰æ•ˆåœ° match keywordsï¼Œè€Œä¸”æŠŠ question å’Œ context è¡¨ç¤ºç‚º high-dimensional sparse vectors\nç›¸åçš„ï¼ŒDense latent semantic encoding åœ¨è¨­è¨ˆä¸Šå’Œ sparse representation æ˜¯äº’è£œçš„\nä¾‹å¦‚ï¼Œç”±å®Œå…¨ä¸åŒçš„ token çµ„æˆçš„å…©å€‹åŒç¾©è©ä¾ç„¶å¯ä»¥æ˜ å°„åˆ°æ¥è¿‘çš„å‘é‡\nterm-based system ç›¸è¼ƒ dense retrieval system å¾ˆé›£å°‡æ¯”å¦‚ã€Œå£äººã€å’Œã€Œæƒ¡æ£ã€åŒ¹é…\nDense encoding ä¹Ÿå¯ä»¥é€éèª¿æ•´ embedding function ä¾†å­¸ç¿’ï¼Œå°æ–¼ task-specific çš„ representation æä¾›äº†å½ˆæ€§\né€éç‰¹æ®Šçš„ in-memory data structure å’Œ indexing schemeï¼Œå¯ä»¥ç”¨ maximum inner product search (MIPS) ä¾†å¿«é€Ÿæª¢ç´¢\nç„¶è€Œï¼Œäººå€‘æ™®éèªç‚ºå­¸ç¿’è‰¯å¥½çš„ dense vector representation éœ€è¦å¤§é‡çš„ QA labeled pair\nå› æ­¤ï¼Œåœ¨ ORQA ä¹‹å‰ï¼ŒDense retrieval å¾æ²’è¢«è­‰æ˜éå¯ä»¥åœ¨ open-domain QA ä¸Šè´é TF-IDF æˆ– BM25\nORQA æå‡ºäº† ICT ä¾†åšé¡å¤–çš„é è¨“ç·´\nç›¡ç®¡ ORQA è­‰æ˜äº† dense retrieval å¯ä»¥è¶…è¶Š BM25ï¼Œåœ¨å¤šå€‹ open-domain QA è³‡æ–™é›†ä¸Šå–å¾— SOTAï¼Œä½†ä»–ä¹Ÿå­˜åœ¨å…©å€‹å¼±é»ï¼š\nICT é è¨“ç·´æ˜¯ compute-intensiveï¼Œè€Œä¸”ä¸ç¢ºå®š regular sentence æ˜¯å¦èƒ½å¾ˆå¥½çš„æ›¿ä»£ objective function ä¸­çš„ question\nç”±æ–¼ context encoder æ²’æœ‰ç”¨ QA pair é€²è¡Œ finetuneï¼Œå› æ­¤ç›¸æ‡‰çš„ representation å¯èƒ½ä¸æ˜¯æœ€ä½³çš„\nåœ¨æœ¬æ–‡ä¸­ï¼Œæœ¬æ–‡å°‡è§£æ±ºä¸€å€‹å•é¡Œ \u0026ndash; æˆ‘å€‘æ˜¯å¦å¯ä»¥åªç”¨ QA pair ä¾†è¨“ç·´æ›´å¥½çš„ dense embedding modelï¼Œè€Œä¸ç”¨é¡å¤–çš„é è¨“ç·´ï¼Ÿ\nåˆ©ç”¨ç¾åœ¨çš„ standard BERT pre-trained model ä»¥åŠ dual-encoder architectureï¼Œæœ¬æ–‡å°ˆæ³¨æ–¼ç”¨ç›¸å°å°‘é‡çš„ question and passage pair ä¾†è¨“ç·´ dense retriever\nç¶“éä¸€ç³»åˆ—çš„ ablation studyï¼Œæœ¬æ–‡çš„è§£æ±ºæ–¹æ¡ˆå‡ºå¥‡çš„ç°¡å–®\nembedding å¯ä»¥ç”¨æœ€å¤§åŒ– question å’Œ ç›¸é—œçš„ passage çš„ inner product ä¾†è¨“ç·´\nä½œè€…çš„ Dense Passage Retrieval (DPR) éå¸¸å¼·å¤§ï¼Œä¸åƒ…å¤§å¹…å„ªæ–¼ BM25ï¼Œè€Œä¸”å’Œ ORQA ç›¸æ¯”ï¼Œend-to-end QA æº–ç¢ºåº¦ä¹Ÿæœ‰å¤§å¹…æå‡\nä½œè€…çš„è²¢ç»æœ‰å…©éƒ¨åˆ†ï¼š\nä½œè€…è­‰æ˜åœ¨é©ç•¶çš„è¨­ç½®ä¸‹ï¼Œåªéœ€åœ¨ç¾æœ‰ question-passge pair ä¸Š finetune question and passage encoderï¼Œå°±å¯ä»¥å¤§å¹…è¶…é BM25ï¼Œå¯¦é©—çµæœä¹Ÿè­‰æ˜å¯èƒ½ä¸ç”¨é¡å¤–çš„é è¨“ç·´\nä½œè€…è­‰æ˜äº†åœ¨ open-domain QA çš„èƒŒæ™¯ä¸‹ï¼Œæ›´é«˜çš„ retrieval accuracy å¯ä»¥è½‰åŒ–ç‚ºæ›´é«˜çš„ end-to-end QA accuracy\né€éå° top retrived passage ä½¿ç”¨ modern reader modelï¼Œå’Œå¹¾å€‹éå¸¸è¤‡é›œçš„ç³»çµ±ç›¸æ¯”ï¼Œä½œè€…åœ¨ open-retrieval setting ä¸‹çš„å¤šå€‹è³‡æ–™é›†å–å¾—äº†å¯æ¯”è¼ƒæˆ–æ›´å¥½çš„çµæœ\nBackground æœ¬æ–‡ç ”ç©¶çš„ open-domain QA çš„æè¿°å¦‚ä¸‹ï¼š\nå…ˆçµ¦å‡ºä¸€å€‹äº‹å¯¦æ€§å•é¡Œï¼Œä¸å±¬æ–¼ç‰¹å®šä¸»é¡Œï¼Œéœ€è¦ä¸€å€‹ç³»çµ±ä½¿ç”¨å¤§é‡å¤šæ¨£åŒ–ä¸»é¡Œçš„ corpus ä¾†å›ç­”\næ›´å…·é«”åœ°èªªï¼Œä½œè€…å‡è¨­ extractive QA settingï¼Œç­”æ¡ˆåƒ…é™æ–¼ corpus ä¸­çš„ä¸€å€‹æˆ–å¤šå€‹ passage ä¸­å‡ºç¾çš„ç¯„åœ\nå‡è¨­æœ‰ D å€‹ documentsï¼Œå…ˆæŠŠæ¯å€‹ document æ‹†æˆå¤šå€‹ç­‰é•·çš„ text passageï¼Œå¥½åšç‚º basic retrieval unitï¼Œæœ€å¾Œå¾—åˆ° M å€‹ passage in corpus C\næ¯å€‹ passage å¯ä»¥è¢«è¦–ä½œä¸€å€‹ token åºåˆ—\nå°æ–¼ question qï¼Œå‰‡æ˜¯è¦æ‰¾åˆ°æŸæ®µ passage ä¸­çš„ä¸€ä¸²é€£çºŒçš„ token ä¾†å›ç­”\nå€¼å¾—æ³¨æ„çš„ä¸€é»æ˜¯ï¼Œç‚ºäº†æ¶µè“‹ç›¡å¯èƒ½å»£æ³›çš„æ¦‚å¿µï¼Œcorpus çš„å¤§å°å¯èƒ½æœƒå¾æ•¸ç™¾è¬å€‹æ–‡ä»¶åˆ°æ•¸åå„„å€‹æ–‡ä»¶ä¸ç­‰\nå› æ­¤ï¼Œä»»ä½• open-domain QA system éƒ½éœ€è¦ä¸€å€‹é«˜æ•ˆçš„ retrieverï¼Œå¯ä»¥åœ¨ reader æå–ç­”æ¡ˆå‰é¸æ“‡ä¸€å°çµ„ç›¸é—œçš„æ–‡æœ¬\nDense Passage Retriever (DPR) ä½œè€…çš„ç ”ç©¶é‡é»æ˜¯æ”¹é€² open-domain QA çš„ retrieval component\nçµ¦å®š M å€‹ passageï¼ŒDPR çš„ç›®æ¨™æ˜¯æŠŠæ‰€æœ‰ low-dimensional continuous space çš„æ‰€æœ‰ passage éƒ½çµ¦ indexï¼Œä½¿å®ƒå¯ä»¥æœ‰æ•ˆåœ°æª¢æ‰€å’Œè¼¸å…¥å•é¡Œç›¸é—œçš„ top-k passage\nM æœ‰å¯èƒ½éå¸¸å¤§ï¼Œæ¯”å¦‚æœ¬æ–‡æœ‰ 21M å€‹ passageï¼Œè€Œ k é€šå¸¸å¾ˆå°ï¼Œå¯èƒ½åªæœ‰ 20~100 å€‹\nOverview ç”¨ dense encoder $E_P(ï¼)$ å’Œ $E_Q(ï¼)$ ä¾†åˆ†åˆ¥ encode passage å’Œ questionï¼Œåœ¨è¨ˆç®—å…©è€…çš„ inner product ä¾†è¡¡é‡ç›¸ä¼¼åº¦\nç›¡ç®¡ç¢ºå¯¦å­˜åœ¨æ¸¬é‡ question å’Œ passage ä¹‹é–“æ›´å…·è¡¨ç¾åŠ›çš„æ¨¡å‹å½¢å¼ï¼Œæ¯”å¦‚å¸¶æœ‰ cross-attention çš„ multi-layer networksï¼Œä½†æ˜¯ similarity function éœ€è¦å¯ä»¥åˆ†è§£ï¼Œæ‰å¯ä»¥é å…ˆè¨ˆç®— passage çš„ embedding\nå¤§å¤šæ•¸ decomposable similarity function æ˜¯ Euclidean distance (L2) çš„è®Šæ›\næ¯”å¦‚ï¼Œconsine æ˜¯ unit vector çš„ inner productï¼Œè€Œ Mahalanobis distance ç­‰åŒæ–¼åœ¨ transformed space çš„ L2 distance\nç”±æ–¼ ablation study è¡¨ç¤ºå…¶ä»–ç›¸ä¼¼å«æ•¸çš„è¡¨ç¾ç›¸ç•¶ï¼Œå› æ­¤é¸æ“‡æ›´ç°¡å–®çš„å…§ç©å‡½æ•¸ï¼Œä¸¦é€éå­¸ç¿’æ›´å¥½çš„ encoder ä¾†æ”¹å–„ dense passage retriever\nEncoder æœ¬æ–‡æ¡ç”¨å…©å€‹ç¨ç«‹çš„ BERTï¼Œä¸¦æŠŠ [CLS] token çš„ representation ç•¶ä½œ output\nInference æ¨ç†éšæ®µï¼Œå°‡ passage encoder $E_P$ æ‡‰ç”¨åœ¨æ‰€æœ‰ passageï¼Œä¸¦ç”¨ FAISS offline index\nFAISS æ˜¯ä¸€å€‹éå¸¸é«˜æ•ˆçš„ open-source libraryï¼Œç”¨åœ¨ similarity search å’Œ clustering of dense vectorsï¼Œå¯ä»¥è¼•é¬†æ‡‰ç”¨åœ¨æ•¸åå„„å€‹å‘é‡ä¸Š\nåœ¨æ¨è«–æ¥æ®µï¼Œè¨ˆç®— q çš„ embeddingï¼Œç„¶å¾Œç”¨ FAISS ä¾†æ‰¾åˆ° top-k passages\nTraining æ¯ä¸€å€‹ training instance éƒ½åŒ…å«å•é¡Œ qï¼Œé‚„æœ‰ä¸€å€‹æ­£ (ç›¸é—œ) passageï¼Œä»¥åŠ n å€‹è²  (ä¸ç›¸é—œ) passages\nPositive and negative passages å°æ–¼æª¢ç´¢å•é¡Œï¼Œæ­£ä¾‹é€šå¸¸æ˜ç¢ºå¯ç”¨ï¼Œè€Œåä¾‹å‰‡é€šå¸¸è¦å¾éå¸¸å¤§çš„ pool ä¸­é¸æ“‡\næ­£ä¾‹å¯èƒ½æœƒåœ¨ QA è³‡æ–™é›†çµ¦å‡ºï¼Œæˆ–æ˜¯å¯ä»¥å¾ç­”æ¡ˆæ‰¾åˆ°ï¼Œå…¶ä»–çš„æ®µè½é è¨­æƒ…æ³ä¸‹éƒ½å¯è¦–ç‚ºä¸ç›¸é—œ\nåœ¨å¯¦è¸ä¸­ï¼Œå¦‚ä½•é¸æ“‡è² ä¾‹å¸¸è¢«å¿½è¦–ï¼Œä½†å°æ–¼å­¸ç¿’ high-quality encoder å¯èƒ½å¾ˆé—œéµ\nè€ƒæ…®ä¸‰ç¨®è² ä¾‹ï¼š\néš¨æ©Ÿ Corpus ä¸­éš¨æ©Ÿé¸æ“‡ BM25 BM25 è¿”å›çš„ passage ä¸å«ç­”æ¡ˆï¼Œä½†åŒ…å«æœ€å¤š question token Gold positive å’Œ question é…å° ç¬¬ 2 å’Œ 3 ç¨®æ˜¯åœ¨èªªæ‹¿å…¶ä»–å•é¡Œçš„æ­£ä¾‹ç•¶è² ä¾‹\nIn-batch negatives æœ‰ B è¨“ç·´å¯¦é«”ï¼Œæ¯å€‹å•é¡Œæœ‰ B-1 å€‹ negative passageï¼Œåªæœ‰ i = j æ™‚ï¼Œ$(q_i, p_j)$ æ˜¯æ­£ä¾‹ï¼Œå…¶ä»–éƒ½æ˜¯è² ä¾‹\nin-batch negative çš„æŠ€å·§å·²è¢«ç”¨åœ¨ full batch setting å’Œ mini-batch setting\nå·²è¢«è­‰æ˜æ˜¯å­¸ç¿’ dual-encoder çš„æœ‰æ•ˆç­–ç•¥ï¼Œå¯ä»¥å¢åŠ è¨“ç·´ç¯„ä¾‹çš„æ•¸é‡\nExperimental Setup Wikipedia Data Pre-processing ç”¨ DrQA æä¾›çš„é è™•ç†ç¨‹å¼ç¢¼å¾ Wikipedia dump ä¸­æå–æ–‡ç« ä¸­ä¹¾æ·¨çš„æ–‡å­—éƒ¨åˆ†\næ­¤æ­¥é©Ÿå°‡åˆªé™¤ semi-structured dataï¼Œæ¯”å¦‚è¡¨æ ¼å’Œ info-boxes\næ¥è‘—å°‡æ¯å¤©æ–‡ç« åˆ†æˆå¤šå€‹ä¸ç›¸äº¤çš„æ–‡å­—å€å¡Šï¼Œæ¯å€‹æ–‡å­—å€å¡Šç”± 100 å€‹å–®å­—çµ„æˆï¼Œä½œç‚º basic retrieval unitï¼Œæœ€å¾Œæœƒæœ‰ 21,015,324 å€‹ passage\næ¯å€‹ passage ä¹Ÿå¸¶æœ‰æ¨™é¡Œä»¥åŠ [SEP]\nSelection of positive passages ç”±æ–¼ TREC, WebQuestions å’Œ TriviaQA ä¸­åªæœ‰ question-answer pairï¼Œå› æ­¤ä½¿ç”¨ BM25 æŠŠåŒ…å«ç­”æ¡ˆæœ€å¤šçš„ passage ç•¶ä½œæ­£ä¾‹\nå¦‚æœæª¢ç´¢åˆ°çš„å‰ 100 ç¯‡æ–‡ç« ä¸­æ²’æœ‰ç­”æ¡ˆï¼Œå‰‡è©²å•é¡Œæœƒè¢«ä¸Ÿæ£„\nExperiments: Passage Retrieval Main Results SQuAD è¡¨ç¾è¼ƒå·®æœ‰å¯èƒ½æ˜¯å› ç‚º passage å’Œ question å­˜åœ¨é«˜åº¦è©å½™é‡ç–Šï¼Œçµ¦ BM25 å¸¶ä¾†å„ªå‹¢ï¼Œè€Œä¸”è³‡æ–™åƒ…å¾ 500 å¤šç¯‡ wiki æ–‡ç« ä¸­è’é›†ï¼Œå› æ­¤è¨“ç·´ç¯„ä¾‹çš„åˆ†ä½ˆå­˜åœ¨æ¥µå¤§çš„ bias\nç•¶ç”¨å¤šå€‹è³‡æ–™é›†è¨“ç·´æ™‚ï¼ŒTRECï¼ˆè£¡é¢æœ€å°çš„è³‡æ–™é›†ï¼‰ç²ç›Šæœ€å¤š\nAblation Study on Model Training Sample efficiency In-batch negative training in-batch negative å¯ä»¥é¡¯è‘—æ”¹å–„çµæœï¼Œé‚„ç°¡å–®ä¸”ç¯€çœè¨˜æ†¶é«”ï¼Œå¯ä»¥é‡è¤‡ä½¿ç”¨ batch ä¸­å·²ç¶“æœ‰çš„è² ä¾‹\nå®ƒæœƒç”¢ç”Ÿæ›´å¤š pairï¼Œå¾è€Œå¢åŠ è¨“ç·´è³‡æ–™çš„æ•¸é‡\nImpact of gold passages åšäº† distant supervisionï¼Œåªæœ‰å¾ˆå°çš„å½±éŸ¿ï¼Œé™ä½äº† 1 å€‹é»\nSimilarity and loss L2 å’Œ inner product çš„è¡¨ç¾ç›¸ç•¶ï¼Œå…©å€‹éƒ½æ¯” cosine å¥½\næœ‰ä¸€ç¨®æµè¡Œçš„ ranking loss å«åš triplet lossï¼Œä½†æ˜¯åœ¨æœ¬æ–‡ä¸­ï¼Œä½œè€…ç™¼ç¾å®ƒçš„è¡¨ç¾ä¸æœƒå°çµæœç”¢ç”Ÿå¤ªå¤§å½±éŸ¿\nCross-dataset generalization ç‚ºäº†æ¸¬è©¦æ³›åŒ–èƒ½åŠ›ï¼Œåªåœ¨ Natural Questions ä¸Šè¨“ç·´ï¼Œåœ¨è¼ƒå°çš„ WebQuestions å’Œ CuratedTREC ä¸Šæ¸¬è©¦ï¼Œç™¼ç¾æ³›åŒ–èƒ½åŠ›å¾ˆå¥½ï¼Œè¼¸çµ¦ SOTA finetune model 3~5 å€‹é»ï¼Œä½†ä»å¤§å¤§å„ªæ–¼ BM25 baseline\nExperiments: Question Answering Result Related Work Conclusion è­‰æ˜äº† dense retrieval å¯ä»¥ outperform ç”šè‡³å¯èƒ½å–ä»£å‚³çµ±çš„ sparse retrieval\né›–ç„¶ç°¡å–®çš„ dual-encoder framework å¯ä»¥é”åˆ°å¾ˆæ£’çš„æ•ˆæœï¼Œä½†ä½œè€…é¡¯ç¤ºå‡ºè¦æˆåŠŸè¨“ç·´ä¹Ÿæœ‰ä¸€äº›é—œéµå› ç´ \næ­¤å¤–ï¼Œæ ¹æ“š empirical analysis å’Œ ablation studyï¼Œæ›´è¤‡é›œçš„ model framework æˆ– similarity function ä¸ä¸€å®šèƒ½æä¾›é¡å¤–åƒ¹å€¼\nç”±æ–¼æª¢ç´¢æ€§èƒ½çš„æé«˜ï¼Œåœ¨å¤šå€‹ open-domain QA benchmarks ä¸Šå–å¾—äº† SOTA\n","date":"2023-12-28T00:00:13+08:00","permalink":"https://roykesydon.github.io/Blog/p/dpr-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"DPR è«–æ–‡é–±è®€"},{"content":"paper: Latent Retrieval for Weakly Supervised Open Domain Question Answering\nAbstract æœ€è¿‘çš„å·¥ä½œå¸¸ä¾è³´æ–¼å…©å€‹å‡è¨­ï¼Œä¸€å€‹æ˜¯å° supporting evidence åš strong supervisionï¼Œå¦ä¸€å€‹æ˜¯å‡è¨­ blackbox information retrieval (IR) system å¯ä»¥æ‰¾åˆ°æ‰€æœ‰çš„ evidence candidates\nä½œè€…èªç‚ºå…©è€…éƒ½ä¸æ˜¯æœ€ç†æƒ³çš„ï¼Œå› ç‚º gold evidence ä¸ç¸½æ˜¯å¯ç”¨ï¼Œè€Œä¸” QA å’Œ IR æœ‰è‘—æ ¹æœ¬ä¸Šçš„ä¸åŒ\nä½œè€…é¦–æ¬¡è­‰æ˜ï¼Œåœ¨æ²’æœ‰ä»»ä½• IR çš„æƒ…æ³ä¸‹ï¼Œå¯ä»¥å¾ question-answer pair ä¸­å…±åŒå­¸ç¿’ retriver å’Œ reader\nåœ¨é€™ç¨® setting ä¸‹ï¼Œä¾†è‡ª Wikipedia çš„ evidence retrieval è¢«è¦–ä½œ latent variable\nç”±æ–¼ learn from scratch ä¸åˆ‡å¯¦éš›ï¼Œå› æ­¤ç”¨ Inverse Cloze Task (ICT) ä¾†é è¨“ç·´ retriever\nä½œè€…å°äº”å€‹ QA è³‡æ–™é›†é€²è¡Œè©•ä¼°\nåœ¨æå•è€…å·²ç¶“çŸ¥é“ç­”æ¡ˆçš„æƒ…æ³ä¸‹ï¼Œå‚³çµ±çš„ IR ç³»çµ±ï¼ˆæ¯”å¦‚ BM25ï¼‰å·²è¶³å¤ \nåœ¨ä½¿ç”¨è€…çœŸæ­£å°‹æ±‚ç­”æ¡ˆçš„è³‡æ–™é›†ä¸Šï¼Œä½œè€…é¡¯ç¤ºå‡º learned retrival çš„é‡è¦æ€§ï¼Œåœ¨ exact match ä¸Šæ¯” BM25 å¥½ 19 å€‹é»\nIntroduction ç”±æ–¼é–±è®€ç†è§£ç³»çµ±çš„ç™¼å±•ï¼Œäººå€‘å° open domain question answering (QA) çš„èˆˆè¶£é‡æ–°ç‡ƒèµ·\nå…¶ä¸­ evidence å¾—å¾ open corpus å–å¾—ï¼Œè€Œä¸æ˜¯ç›´æ¥å¾è¼¸å…¥çµ¦å…¥\nç¾æœ‰çš„æ–¹æ³•éœ€è¦ blackbox IR system ä¾†å®Œæˆå¤§éƒ¨åˆ†ç¹é‡çš„å·¥ä½œï¼Œå³ä½¿å®ƒç„¡æ³•å°ä¸‹éŠä»»å‹™é€²è¡Œå¾®èª¿\nåœ¨ DrQA æ¨å»£çš„å¼·ç›£ç£ç’°å¢ƒä¸­ï¼Œä»–å€‘ä¹Ÿå‡è¨­äº†ä¸€å€‹è¨“ç·´åœ¨ question-answer-evidence triple ä¸Šçš„é–±è®€ç†è§£æ¨¡å‹\nåœ¨æŸäº›äººæå‡ºçš„ weakly supervised setting ä¸­ï¼Œä»–å€‘å‡è¨­ IR system æä¾› noisy gold evidence\né€™äº›æ–¹æ³•åˆ©ç”¨ IR system ä¾†å¤§å¹…æ¸›å°‘æœå°‹ç©ºé–“\nç„¶è€Œ QA å’Œ IR æœ‰è‘—æ ¹æœ¬æ€§çš„å·®ç•°\né›–ç„¶ IR é—œå¿ƒçš„æ˜¯ lexical å’Œ semantic matchingï¼Œä½† question çš„å®šç¾©ä¸¦ä¸å…·é«”ï¼Œè€Œä¸”éœ€è¦æ›´å¤š language understandingï¼Œå› ç‚º user åœ¨æ‰¾çš„æ˜¯æœªçŸ¥è³‡è¨Š\næˆ‘å€‘æ‡‰è©²ç›´æ¥ ç”¨ QA data å­¸ç¿’ retrieveï¼Œè€Œä¸æ˜¯å—é™æ–¼ blackbox IR system\nåœ¨æœ¬æ–‡ä¸­ï¼Œä½œè€…ä»‹ç´¹äº†ç¬¬ä¸€å€‹ OpenRetrieval Question Answering system (ORQA) æ¡†æ¶\nORQA å­¸ç¿’å¾ open corpus retrieve evidenceï¼Œä¸¦ä¸”åªåš question-answer pair çš„ç›£ç£è¨“ç·´\né›–ç„¶æœ€è¿‘çš„å·¥ä½œåœ¨æ”¹é€² evidence retrieval ä¸Šå–å¾—äº†å·¨å¤§çš„é€²å±•ï¼Œä½†æ˜¯ä»–å€‘ä¾ç„¶åªæ˜¯åœ¨ closed evidence set ä¸‹ rerank\nfully end-to-end çš„æŒ‘æˆ°æ˜¯ï¼Œopen corpus çš„ retrieval å¿…é ˆè¢«è¦–ç‚º latent variableï¼Œè¦ train from scratch æ˜¯ä¸åˆ‡å¯¦éš›çš„\nIR system æä¾›äº†ä¸€å€‹åˆç†ä½†å¯èƒ½éæœ€å¥½çš„èµ·é»\næœ¬æ–‡çš„ä¸€å€‹é—œéµæ˜¯ï¼Œå¦‚æœç”¨ç„¡ç›£ç£ çš„ ICT å° retriever åšé è¨“ç·´ï¼Œé‚£ end-to-end learning æ˜¯æœ‰å¯èƒ½çš„\nåœ¨ ICT ä¸­ï¼Œä¸€å€‹å¥å­è¢«è¦–ä½œ pseudo-questionï¼Œè€Œå®ƒçš„ context è¢«è¦–ä½œ pseudo-evdience\nçµ¦å®šä¸€å€‹ pseudo-questionï¼Œretriever çš„ç›®æ¨™æ˜¯å¾ batch ä¸­çš„ candidate æ‰¾å‡ºå°æ‡‰çš„ pseudo-evidence\nICT pretraining æä¾›äº†å¼·å¤§çš„åˆå§‹åŒ–ï¼Œä½¿ ORQA å¯ä»¥ç°¡å–®åœ°å„ªåŒ–\nä½œè€…åœ¨äº”å€‹ QA è³‡æ–™é›†ä¸Šé€²è¡Œäº†è©•ä¼°ï¼Œåœ¨å•é¡Œä½œè€…å·²çŸ¥ç­”æ¡ˆçš„è³‡æ–™é›†ä¸Š (SQuADã€TriviaQA)ï¼Œæª¢ç´¢å•é¡Œé¡ä¼¼å‚³çµ±çš„ IRï¼Œä¸¦ä¸” BM25 æ˜¯ SOTA retrieval\nåœ¨å•é¡Œä½œè€…ä¸çŸ¥é“ç­”æ¡ˆçš„è³‡æ–™é›†ä¸Š (Natural Questionsã€WebQuestionsã€CuratedTrec)ï¼Œä½œè€…é¡¯ç¤ºå‡º learned retrieval çš„é‡è¦æ€§ï¼Œæ¯” BM25 åœ¨ exact match ä¸Šå¥½ 6~19 å€‹é»\nOverview Task åœ¨ open-domain QA ä¸­ï¼Œ$q$ æ˜¯ question stringï¼Œè€Œ $a$ æ˜¯ answer string\nèˆ‡é–±è®€ç†è§£ä¸åŒï¼Œevidence çš„ä¾†æºæ˜¯ modeling choiceï¼Œè€Œé task definition çš„ä¸€éƒ¨åˆ†\nFormal Definitions Model æŠŠä¸€å€‹ unstructured text corpus åˆ‡æˆ B å¡Šçš„ evidence text\nä¸€å€‹ answer derivation æ˜¯ä¸€å€‹ pair $(b,s)$\n$1 \\le b \\le B$ æ˜¯ block çš„ index\n$s$ æ˜¯ block $b$ çš„ span\nscoring function $S(b,s,q)$ ç”¨ä¾†è¨ˆç®— $(b,s)$ å°æ–¼ $q$ çš„åˆ†æ•¸\nä¸€èˆ¬ä¾†èªª scoring function æœƒè¢«åˆ†è§£æˆ retrieval component $S_{retr}(b,q)$ å’Œ $S_{read}(b,s,q)$\n$S(b,s,q) = S_{retr}(b,q) + S_{read}(b,s,q)$ åœ¨æ¨è«–éšæ®µï¼š\n$a^* = TEXT(argmax_{b,s} S(b,s,q))$ open-domain QA çš„ä¸€å€‹ä¸»è¦æŒ‘æˆ°æ˜¯ handling the scale\nä½œè€…åœ¨ English Wikipedia ä¸Šåšå¯¦é©—ï¼ŒåŒ…å«è¶…é 13M å€‹ blocksï¼Œæ¯å€‹ block éƒ½æœ‰è¶…é 2000 å€‹å¯èƒ½çš„ spans\nExisting Pipelined Models åœ¨ç¾æœ‰çš„ retrieval-based open-domain QA æ¨¡å‹ä¸­ï¼Œblackbox IR system å…ˆé¸æ“‡ä¸€çµ„ closed set of evidence candidates\nç„¶å¾Œ DrQA ä¹‹å¾Œçš„å¤šæ•¸å·¥ä½œéƒ½ç”¨ TF-IDF ä¾†æŒ‘é¸ candidateï¼Œä¸¦å°ˆæ³¨æ–¼é–±è®€ç†è§£æˆ– reranking çš„éƒ¨åˆ†\nreading component $S_{read}(b,s,q)$ æ˜¯å¾ gold answer å­¸ç¿’çš„\nåœ¨æœ€æ¥è¿‘æˆ‘å€‘çš„æ–¹æ³•çš„å·¥ä½œä¸­ï¼Œreader æ˜¯é€é weak supervision å­¸ç¿’çš„\nretrieval system æœƒå•Ÿç™¼å¼ï¼ˆheuristicallyï¼‰åœ°åˆªé™¤ spurious ambiguitiesï¼Œä¸¦æŠŠæ¸…ç†å¾Œçš„çµæœè¦–ç‚º gold evidence\nOpen-Retrieval Question Answering (ORQA) $BERT(x_1, [x_2]) = \\{CLS: h_{CLS}, 1: h_1, 2: h_2,\u0026hellip;\\}$\nRetriever component $h_q = W_q BERT(q)[CLS]$ $h_b = W_b BERT(b)[CLS]$ $S_{retr}(b,q) = h_q^T h_b$ Reader component $h_{start} = BERT_R(q,b)[START(s)]$ $h_{end} = BERT_R(q,b)[END(s)]$ $S_{read}(b,s,q) = MLP([h_{start};h_{end}])$ Inference \u0026amp; Learning Challenges ä¸Šé¢çš„æ¨¡å‹æ¦‚å¿µå¾ˆç°¡å–®\nä½†æ¨è«–å’Œå­¸ç¿’ä¸Šå…·æœ‰æŒ‘æˆ°æ€§ï¼Œå› ç‚ºï¼š\nopen evidence corpus æœ‰å·¨å¤§çš„æœå°‹ç©ºé–“ï¼ˆè¶…é 13M å€‹ blocksï¼‰ è¦å¦‚ä½•åœ¨ç©ºé–“ navigate æ˜¯ latent å› æ­¤æ¨™æº–çš„ teacher forcing ä¸èƒ½ç”¨ï¼Œlatent variable ä¹Ÿä¸èƒ½ç”¨ï¼Œå› ç‚ºå­˜åœ¨å¤§é‡ spuriously ambiguous derivationsï¼ˆæ¯”å¦‚ç­”æ¡ˆæ˜¯ \u0026ldquo;seven\u0026rdquo;ï¼Œå¾ˆå¤š evidence éƒ½æœƒæœ‰ \u0026ldquo;seven\u0026rdquo; é€™å€‹å­—çœ¼ï¼‰\nä½œè€…é€ééç›£ç£é è¨“ç·´ä¾†è‰¯å¥½åœ°åˆå§‹åŒ– retriever ä¾†è§£æ±ºé€™äº›æŒ‘æˆ°\né è¨“ç·´çš„ retriever ä½¿ä½œè€…èƒ½å¤ ï¼š\npre-encode Wikipedia blocksï¼Œå¾è€Œåœ¨ finetune éšæ®µå¯¦ç¾å‹•æ…‹ä¸”å¿«é€Ÿçš„ top-k retrieval\nä½¿ retrieval å¯ä»¥é é›¢ spuriously ambiguities ä¸¦åå‘ supportive evidence\nInverse Cloze Task ä½œè€…æå‡ºçš„é è¨“ç·´æµç¨‹çš„ç›®æ¨™æ˜¯æƒ³è®“ retriever è§£æ±ºå’Œ evidence retrieval for QA ç›¸ä¼¼çš„ç„¡ç›£ç£ä»»å‹™\nç›´è¦ºä¸Šï¼Œuseful evidence é€šå¸¸æœƒè¨è«–å•é¡Œä¸­çš„ entities, events å’Œ relations\né‚„åŒ…å«å•é¡Œä¸­ä¸å­˜åœ¨çš„é¡å¤–è³‡è¨Š (the answer)\nquestion-evidence pair æ˜¯ setence-context pairï¼Œå¥å­çš„ä¸Šä¸‹æ–‡åœ¨èªæ„ä¸Šæ˜¯ç›¸é—œçš„ï¼Œå¯ä»¥æ¨è«–å¥å­ä¸­ç¼ºå°‘çš„è³‡è¨Š\næ†‘é€™ç¨®æƒ³æ³•ï¼Œä½œè€…å»ºè­°ä½¿ç”¨ ICT ä¾†é è¨“ç·´ retriever\nåœ¨ standard cloze task ä¸­ï¼Œç›®æ¨™æ˜¯æ ¹æ“šä¸Šä¸‹æ–‡é æ¸¬ masked-out text\nç›¸åï¼ŒICT è¦é€†å‘é æ¸¬ï¼Œçµ¦å®šä¸€å€‹å¥å­ï¼Œé æ¸¬ä¸Šä¸‹æ–‡\nä½¿ç”¨é¡ä¼¼ downstream retrieval çš„ discriminative objectiveï¼š\n$P_{ICT}(b|q)=\\frac{exp(S_{retr}(b,q))}{\\sum_{b\u0026rsquo; \\in BATCH} exp(S_{retr}(b\u0026rsquo;,q))}$\né æ¸¬å“ªå€‹ä¸Šä¸‹æ–‡æ˜¯ query çš„\nICT æœ‰å€‹é‡é»æ˜¯ï¼Œå®ƒè¦åšçš„ä¸åƒ…åƒ…æ˜¯å–®å­—åŒ¹é…ï¼Œå› ç‚º evidence ä¸­æ²’æœ‰ pseudo-question\nä¾‹å¦‚ fig.2 çš„ pseudo-question å®Œå…¨æ²’æœ‰æåŠ zebraï¼Œä½† retriever è¦èƒ½å¤ é¸æ“‡ zebra çš„ context\nèƒ½å¤ å¾éæŒ‡å®šçš„èªè¨€æ¨è«–å‡ºèªæ„æ˜¯ QA å’Œå‚³çµ± IR çš„å·®ç•°\nç„¶è€Œä½œè€…ä¹Ÿä¸æƒ³é˜»æ­¢ retriever å­¸ç¿’å–®å­—åŒ¹é…ï¼Œå› ç‚º lexical overlap æœ€çµ‚æ˜¯ä¸€å€‹éå¸¸æœ‰ç”¨çš„ç‰¹å¾µ\nå› æ­¤ï¼Œä½œè€…åªåœ¨ 90 % çš„ä¾‹å­ä¸­æŠŠ sentence å¾ context ä¸­ç§»é™¤ï¼Œé¼“å‹µæ¨¡å‹åœ¨éœ€è¦çš„æ™‚å€™å­¸ç¿’æŠ½è±¡è¡¨ç¤ºï¼Œä¹Ÿåœ¨å¯ç”¨æ™‚å­¸ç¿’ low-level word matching features\nICT é è¨“ç·´å¯¦ç¾å…©å€‹ä¸»è¦ç›®æ¨™ï¼š\nå„˜ç®¡é è¨“ç·´çš„å¥å­å’Œå¾®èª¿æ™‚çš„ question ä¸åŒ¹é…ï¼Œä½†ä½œè€…é æœŸ zero-shot evidence retrieval performance è¶³ä»¥å¼•å° latent variable çš„å­¸ç¿’\npretrained evidence blocks å’Œ downstream evidence blocks é–“æ²’æœ‰é€™ç¨®ä¸åŒ¹é…çš„å•é¡Œ\nå› æ­¤å¯é æœŸ $BERT_{B}(b)$ ç„¡é ˆé€²ä¸€æ­¥è¨“ç·´å³å¯æ­£å¸¸å·¥ä½œ\nåªæœ‰ question encoder éœ€è¦é‡å°ä¸‹éŠè³‡æ–™å¾®èª¿\nInference ç”±æ–¼ fixed block encoder å·²ç¶“ç‚º retrieval æä¾›äº†æœ‰ç”¨çš„ representationï¼Œå¯ä»¥é å…ˆè¨ˆç®—æ‰€æœ‰ block çš„ encoding\nå› æ­¤åœ¨å¾®èª¿çš„æ™‚å€™ä¸éœ€è¦å°å¤§é‡ evidence block é‡æ–° encodeï¼Œä¸¦ä¸”å¯ä»¥ä½¿ç”¨æ¯”å¦‚ locality-sensitive hashing ä¹‹é¡çš„ç¾æœ‰å·¥å…·ä¾†å»ºç«‹ç´¢å¼•\né€é pre-compiled indexï¼Œæ¨ç†éµå¾ª standard beam-search\næª¢ç´¢ top-k evidence blockï¼Œä¸¦åªè¨ˆç®—é€™ k å€‹ block çš„ reader score\nLearning é€™é‚Šå¤ªè¤‡é›œï¼Œå»ºè­°çœ‹åŸæ–‡\nExperimental Setup Open Domain QA Datasets å° 5 å€‹ç¾æœ‰ question answering æˆ–é–±è®€ç†è§£è³‡æ–™é›†é€²è¡Œè©•ä¼°\nä¸¦éæ‰€æœ‰è³‡æ–™é›†çš„åŸå§‹å½¢å¼éƒ½æ˜¯ open-domain QAï¼Œå› æ­¤ä½œè€…éµå¾ª DrQA çš„åšæ³•ï¼Œè½‰æˆ open format\næ¯å€‹ example éƒ½æœ‰ä¸€å€‹ single question å’Œä¸€ã€Œçµ„ã€ reference answer\nNatural Questions åŒ…å«äº†å¾ Google Search çš„ aggregated queries ä¸­çš„ question\nç‚ºäº†è’é›†é€™å€‹è³‡æ–™é›†çš„ open versionï¼Œä½œè€…åªä¿ç•™ short answer ä¸¦ä¸Ÿæ£„ evidence document\nå…·æœ‰è¨±å¤š token çš„ç­”æ¡ˆé€šå¸¸é¡ä¼¼ extractive snippets è€Œä¸æ˜¯ canonical answerï¼Œå› æ­¤ä½œè€…ä¸Ÿæ£„é•·åº¦è¶…é 5 å€‹ token çš„ç­”æ¡ˆ\nWebQuestions åŒ…å«å¾ Google Suggest API æŠ½å–çš„å•é¡Œ\nç­”æ¡ˆæ˜¯æ ¹æ“š Freebase æ¨™è¨»çš„ï¼Œä½†æ˜¯åªä¿ç•™ entities çš„ string representation\nCuratedTrec å•é¡Œä¾†è‡ªçœŸå¯¦æŸ¥è©¢çš„å„ç¨®ä¾†æºï¼Œæ¯”å¦‚ MSNSearch\nTriviaQA å¾ç¶²è·¯ä¸ŠæŠ“çš„ question-answer pairs\nä½œè€…ä½¿ç”¨ unfiltered set ä¸¦æ¨æ£„ distanly supervised evidence\nSQuAD è¢«è¨­è¨ˆä¾†ç”¨ä½œé–±è®€ç†è§£ï¼Œè€Œä¸æ˜¯ open-domain QA\nç­”æ¡ˆç¯„åœæ˜¯å¾ Wikipedia çš„æ®µè½ä¸­é¸æ“‡çš„ï¼Œå•é¡Œç”± annotators ç·¨å¯«ï¼Œannotators è¢«æŒ‡ç¤ºæå‡ºå•é¡Œï¼Œè¦ç”±çµ¦å®šçš„ context ä¸­çš„ span ä¾†å›ç­”\nDataset Biases åœ¨ Natural Questionsã€WebQuestions å’Œ CuratedTrec ä¸­ï¼Œæå•è€…ä¸çŸ¥é“ç­”æ¡ˆï¼Œåæ˜ äº†çœŸå¯¦çš„å°‹æ±‚å•é¡Œçš„åˆ†ä½ˆ\nä½†æ˜¯ï¼Œannotators å¿…é ˆå–®ç¨æ‰¾åˆ°æ­£ç¢ºçš„ç­”æ¡ˆï¼Œå› æ­¤éœ€è¦ automatic toolsï¼Œä¸¦å¯èƒ½æœƒå°é€™äº›å·¥å…·çš„çµæœç”¢ç”Ÿ bias\nåœ¨ TriviaQA å’Œ SQuAD ä¸­ï¼Œä¸éœ€è¦ automatic toolsï¼Œå› ç‚º annotators æ˜¯æ ¹æ“šå·²çŸ¥ç­”æ¡ˆå¯«å•é¡Œçš„\nç„¶è€Œé€™å¼•å…¥äº†å¦ä¸€çµ„å¯èƒ½æ›´æˆå•é¡Œçš„ biasï¼Œå°±æ˜¯æ’°å¯«å•é¡Œä¸¦éå‡ºæ–¼è³‡è¨Šéœ€æ±‚\nå°è‡´å•é¡Œä¸­æœ‰è¨±å¤šè‡ªç„¶å‡ºç¾çš„å•é¡Œä¸­æ²’æœ‰çš„æç¤º\né€™åœ¨ SQuAD ä¸­å•é¡Œç‰¹åˆ¥åš´é‡ï¼Œä½¿å•é¡Œå’Œ evidence é–“äººç‚ºåœ°å‡ºç¾å¤§é‡è©å½™é‡ç–Š\nä½†ä¸Šè¿°é€™äº›åªæ˜¯æƒ³è¡¨é”è³‡æ–™é›†çš„å±¬æ€§ï¼Œè€Œéå¯æ¡å–è¡Œå‹•çš„æ‰¹è©•ï¼Œå› ç‚ºè¦å–å¾—å¤§è¦æ¨¡è³‡æ–™å¿…å®šæœƒé‡åˆ°é€™äº›ç‹€æ³ï¼Œç›®å‰é‚„ä¸æ¸…æ¥šå¦‚ä½•åœ¨åˆç†çš„æˆæœ¬ä¸‹æ”¶é›†å…¬æ­£çš„è³‡æ–™é›†\nImplementation Details Evidence Corpus corpus è¢«åˆ†æˆæœ€å¤š 288 å€‹å–®å­—çš„ chunkï¼Œä¸¦ä¸”ä¿ç•™ sentence boundaries\nå°è‡´æœ‰è¶…é 13M å€‹ blocks\nMain Results Baselines BM25 BM25 æ˜¯äº‹å¯¦ä¸Šçš„éç›£ç£æœç´¢æ–¹æ³• SOTA è¢«è­‰æ˜å°æ–¼å‚³çµ±è³‡è¨Šæª¢ç´¢ä»»å‹™å’Œ QA çš„ evidence retrieval ä»»å‹™éƒ½æ˜¯ robust\nLanguage Models éç›£ç£çš„ neural retrieval å°æ–¼å‚³çµ± IR ä¾†èªªå¾ˆé›£æ”¹é€²ï¼Œä½†é€™è£¡è¦–ä½œæ¯”è¼ƒçš„ baseline\nä½œè€…å° LM é€²è¡Œå¯¦é©—ï¼Œä¸¦ä¸”é€™å·²è¢«è­‰æ˜æ˜¯ SOTA unsupervised representation\næˆ‘å€‘èˆ‡å…©ç¨®å»£æ³›ä½¿ç”¨çš„ 128-dimensional representation é€²è¡Œæ¯”è¼ƒï¼š\nNNLM context-independent embedding ELMO context-dependent bidirectional LSTM å°±åƒ ICT ä¸€æ¨£ï¼Œä½¿ç”¨ alternate encoder ä¾†é å…ˆè¨ˆç®— encoded evidence blocks é‚„æœ‰åˆå§‹åŒ–ç¶“é finetune çš„ question encoding\næ ¹æ“šç¾æœ‰çš„ IR æ–‡ç»ï¼Œé‚„æœ‰ LM æ²’æœ‰é¡¯è‘—å„ªåŒ– retrieval çš„ç›´è¦ºï¼Œä½œè€…ä¸¦ä¸æœŸæœ›é€™äº›æˆç‚ºå¼·å¤§çš„ baselineï¼Œä½†æ˜¯ä»–å€‘è­‰æ˜äº†å°‡æ–‡æœ¬ç·¨ç¢¼ç‚º 128 ç¶­çš„é›£åº¦\nResults åœ¨æå•è€…å·²ç¶“çŸ¥é“ç­”æ¡ˆçš„è³‡æ–™é›†ä¸­\nè­‰å¯¦å£“ç¸®åˆ° 128ç¶­çš„å‘é‡ç„¡æ³•èˆ‡ BM25 ç²¾ç¢ºè¡¨ç¤º evidence ä¸­æ¯å€‹å–®å­—çš„èƒ½åŠ›ç›¸ç¬¦\nSQuAD çš„ dev å’Œ test é–“çš„é¡¯è‘—ä¸‹é™åæ˜ äº†è³‡æ–™é›†ä¸­çš„æŸå€‹ç‰¹æ€§ - 10 è¬å€‹å•é¡Œåƒ…æºè‡ª 536 å€‹æ–‡ä»¶\nå› æ­¤ï¼ŒSQuAD çš„å¥½çš„æª¢ç´¢ç›®æ¨™ï¼Œæœƒå’Œè¨“ç·´ç¯„ä¾‹é«˜åº¦ç›¸é—œï¼Œé•åäº† IID å‡è¨­ï¼Œä½¿å…¶ä¸é©åˆå­¸ç¿’æª¢ç´¢\nå› æ­¤ï¼Œä½œè€…å¼·çƒˆå»ºè­°å° end-to-end open-domain QA models æœ‰èˆˆè¶£çš„äººä¸å†ä½¿ç”¨ SQuAD é€²è¡Œè¨“ç·´å’Œè©•ä¼°\nAnalysis Strongly supervised comparison ç‚ºäº†è­‰å¯¦ä½œè€…çš„ BM25 Baseline æ˜¯ SOTAï¼Œæä¾›äº†å’Œ DrQA çš„æ¯”è¼ƒ\nDrQA çš„ reader æ˜¯ DocReaderï¼Œç”¨ TF-IDF å–å¾— top k documents\né‚„åŒ…æ‹¬åŸºæ–¼ TF-IDF retrieval çš„ distant supervision\nBERTserini çš„ reader æ˜¯ä¸€å€‹åŸºæ–¼ base BERTï¼ˆé¡ä¼¼ä½œè€…çš„ readerï¼‰ï¼Œä¸¦ç”¨ BM25 æœç´¢ top-k å€‹æ®µè½ï¼ˆåƒä½œè€…çš„ BM25 baselineï¼‰\nä¸»è¦å€åˆ¥åœ¨ BERTserini ä½¿ç”¨ Wikipedia ä¸­çš„çœŸå¯¦æ®µè½ï¼Œè€Œä¸æ˜¯ä»»æ„ blockï¼Œå¾è€Œç”±æ–¼é•·åº¦ä¸å‡å°è‡´æ›´å¤š evidence blocks\nç‚ºäº†å’Œé€™äº›å¼·ç›£ç£ç³»çµ±é€²è¡Œæ¯”è¼ƒï¼Œä½œè€…åœ¨ SQuAD ä¸Šé è¨“ç·´ reader\nMasking Rate in the Inverse Cloze Task pseudo-query åœ¨ 90% çš„æ™‚é–“è£¡éƒ½å¾ evidence block é®è”½\nå¦‚æœç¸½æ˜¯å±è”½ pseudo-queryï¼Œé‚£éº¼ retriever æ°¸é ä¸æœƒçŸ¥é“ n-gram overlap æ˜¯ä¸€å€‹å¼·å¤§çš„ retrieval signalï¼Œå°è‡´æå¤± 10 å€‹é»\nå¦‚æœå¾ä¸å±è”½ï¼Œå•é¡Œå°±æœƒç°¡åŒ–ç‚ºè¨˜æ†¶ï¼Œå°è‡´ä¸èƒ½å¾ˆå¥½åœ°æ¨å»£åˆ°å•é¡Œ\nExample Predictions ç™¼ç¾ ORQA åœ¨å…·æœ‰é«˜åº¦è©å½™é‡ç–Šçš„æ–‡æœ¬æ›´åŠ  robust\nä½†æ˜¯ç”±æ–¼ 128 ç¶­å‘é‡çš„è³‡è¨Šæœ‰é™\nå¾ˆé›£ç²¾ç¢ºåœ°è¡¨ç¤ºæ¥µç‚ºå…·é«”çš„æ¦‚å¿µï¼Œæ¯”å¦‚æº–ç¢ºæ—¥æœŸ\n","date":"2023-12-25T00:00:13+08:00","permalink":"https://roykesydon.github.io/Blog/p/orqa-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"ORQA è«–æ–‡é–±è®€"},{"content":"paper: Reading Wikipedia to Answer Open-Domain Questions\nAbstract æœ¬æ–‡æå‡ºä»¥ Wikipedia ç‚ºçŸ¥è­˜ä¾†æºä¾†è§£æ±º open-domain question answering å•é¡Œ\nä»»ä½•å•é¡Œçš„ç­”æ¡ˆéƒ½æ˜¯ Wikipedia ä¸­çš„ä¸€æ®µæ–‡å­—\né€™é …æŒ‘æˆ°çµåˆäº†æ–‡ä»¶æª¢ç´¢å’Œç†è§£æ–‡å­—çš„èƒ½åŠ›\næœ¬æ–‡çš„ä½œæ³•åŸºæ–¼ä¸€å€‹ search componentï¼Œç”± bigram hashing å’Œ TF-IDF matching æ§‹æˆï¼Œä¸¦çµåˆ RNN\nå°å¤šå€‹ QA è³‡æ–™é›†åšçš„å¯¦é©—è¡¨æ˜ï¼š\né€™å…©å€‹ components å°æ–¼ç¾æœ‰çš„å°æ‡‰æ¨¡å¡Šå…·æœ‰é«˜åº¦ç«¶çˆ­åŠ› åœ¨ä»–å€‘çš„çµ„åˆä¸Šä½¿ç”¨ distant supervision ååˆ†æœ‰æ•ˆ Introduction è¦æŠŠ wikipedia ç•¶ä½œçŸ¥è­˜ä¾†æºï¼Œå›ç­”ä»»ä½•ä¸€å€‹å•é¡Œï¼Œéƒ½å¿…é ˆå…ˆå¾è¶…é 5 ç™¾è¬ç¯‡æ–‡ç« ä¸­æ‰¾å‡ºå°‘æ•¸ç›¸é—œçš„æ–‡ç« ï¼Œä¸¦ä»”ç´°æƒæä»¥æ‰¾å‡ºç­”æ¡ˆã€‚\næœ¬æ–‡å°‡é€™ç¨±ç‚º machine reading at scale (MRS)\næœ¬æ–‡æŠŠ wikipedia ç•¶ä½œä¸€å€‹æ–‡ç« çš„é›†åˆï¼Œä¸¦ä¸”ä¸ä¾è³´å…§éƒ¨çš„ graph structure\nå› æ­¤è©²æ–¹æ³•æ˜¯é€šç”¨çš„ï¼Œå¯ä»¥å¥—åˆ°è«¸å¦‚æ–°èã€ç¶²è·¯è«–å£‡ç­‰ç­‰çš„è³‡æ–™é›†ä¸Š\næœ¬æ–‡é–‹ç™¼äº† DrQAï¼Œå¼·å¤§çš„ç¶­åŸºç™¾ç§‘å•ç­”ç³»çµ±ï¼Œç”±ä»¥ä¸‹éƒ¨åˆ†çµ„æˆï¼š\nDocument Retriever ä¸€å€‹ç”¨ bigram hashing å’Œ TF-IDF matching çš„ module ç”¨æ–¼åœ¨çµ¦å®šå•é¡Œçš„æƒ…æ³ä¸‹ï¼Œè¿”å›æœ‰æ•ˆç›¸é—œæ–‡ç« çš„å­é›† Document Reader RNNï¼Œç”¨ä¾† detect æ–‡ç« ä¸­ç­”æ¡ˆçš„ä½ç½® å¯¦é©—è¡¨æ˜ Document Retriever çš„æ€§èƒ½å„ªæ–¼ Wikipedia çš„å…§éƒ¨æœå°‹å¼•æ“ï¼ŒDocument Reader åœ¨ SQuAD ä¸Šé”åˆ° SOTA\næ­¤å¤–ï¼Œèˆ‡ single task training ç›¸æ¯”ï¼Œä½œè€…è¡¨æ˜ multitask learning å’Œ distant supervision æœ‰åŠ©æ–¼æé«˜æ¨¡å‹çš„æ€§èƒ½\nRelated Work éš¨è‘— Knowledge Base (KB) çš„ç™¼å±•ï¼ŒQA å‡ºç¾äº†è¨±å¤šå‰µæ–°ï¼Œä½†æ˜¯ KB å…·å‚™å›ºæœ‰é™åˆ¶ï¼ˆincompleteness, fixed schemaï¼‰ï¼Œä¿ƒä½¿ç ”ç©¶äººå“¡è½‰å›å¾ raw text ä¸­æå–ç­”æ¡ˆ\næœ‰äº›å·¥ä½œå˜—è©¦åˆ©ç”¨ multitask learning ä¾†çµ„åˆå¤šå€‹ QA è³‡æ–™é›†ï¼Œç›®æ¨™æ˜¯ï¼š\né€é task transfer ä¾†å¯¦ç¾è·¨è³‡æ–™é›†çš„æ”¹é€² æä¾›ä¸€å€‹å–®ä¸€é€šç”¨çš„ç³»çµ±ï¼Œå¯ä»¥å›ç­”ä¸åŒç¨®é¡çš„å•é¡Œï¼Œå› ç‚ºè³‡æ–™ä¾†æºä¸­ä¸å¯é¿å…åœ°å­˜åœ¨ä¸åŒçš„è³‡æ–™åˆ†å¸ƒ æœ¬æ–‡çš„å·¥ä½œåœ¨å…ˆ retrive å† read çš„ setting ä¸‹ï¼Œæ²’æœ‰åˆ©ç”¨ KBï¼Œå–å¾—äº†æ­£é¢æˆæœ\nDrQA ç”±å…©å€‹ Components çµ„æˆï¼š\nDocument Retriever ç”¨ä¾†å°‹æ‰¾ç›¸é—œæ–‡ç«  Document Reader ç”¨æ–¼å¾å–®ä¸€æ–‡ä»¶æˆ–ä¸€å°éƒ¨åˆ†æ–‡ä»¶æå–ç­”æ¡ˆ Document Retriever éµå¾ªç¶“å…¸çš„ QA Systemï¼Œå…ˆç”¨é«˜æ•ˆçš„ ï¼ˆéæ©Ÿå™¨å­¸ç¿’ï¼‰çš„ document retrieval system ç¸®å°æœç´¢ç¯„åœï¼Œä¸¦å°ˆæ³¨æ–¼æ¯”è¼ƒå¯èƒ½æœ‰é—œçš„æ–‡ç« \nèˆ‡åŸºæ–¼ ElasticSearch çš„ Wikipedia Search API ç›¸æ¯”ï¼Œç°¡å–®çš„ inverted index lookup å’Œ term vector model scoring è¡¨ç¾çš„ååˆ†å¥½\næ–‡ç« å’Œå•é¡Œè¢«è¡¨ç¤ºç‚º TF-IDF weighted bag-of-words vectors\nä½œè€…è€ƒæ…®é€éè€ƒæ…® local word order å’Œ n-gram features ä¾†é€²ä¸€æ­¥æ”¹å–„\nè¡¨ç¾æœ€ä½³çš„ç³»çµ±ç”¨ bigram countsï¼Œä¸¦åˆ©ç”¨ hashing æ˜ å°„åˆ° $2^{24}$ bins ä¾†ä¿æŒ speed å’Œ memory efficiencyï¼Œç”¨çš„æ˜¯ unsigned murmur3 hash\nDocument Retriever ä½œç‚ºæ¨¡å‹çš„ç¬¬ä¸€éƒ¨åˆ†ï¼Œè¨­å®šç‚ºå°ä»»ä½•å•é¡Œè¿”å› 5 å€‹ç›¸é—œçš„æ–‡ç« \né€™äº›æ–‡ç« å†äº¤ç”± Document Reader ä¾†è™•ç†\nDocument Reader Paragraph encoding $p_i$ æ˜¯æ®µè½ $p$ ä¸­çš„ tokenï¼ŒæœŸæœ› $p_i$ å¯ä»¥è¢« encode æˆå¸¶æœ‰å‘¨åœè³‡è¨Šçš„å‘é‡\næ¡ç”¨çš„æ˜¯ multi-layer bidirectional LSTM\nç‰¹å¾µå‘é‡ $p_i$ ç”±ä»¥ä¸‹éƒ¨åˆ†çµ„æˆï¼š\nWord embedding\nç”¨ 300 ç¶­çš„ Glove word embeddingï¼Œå›ºå®šå¤§éƒ¨åˆ†é è¨“ç·´çš„ word embeddingï¼Œåª finetune æœ€å¸¸è¦‹çš„ 1000 å€‹ question wordsï¼Œä¾‹å¦‚ what, how, which Exact match\næ¡ç”¨ä¸‰å€‹ç°¡å–®çš„ binary featuresï¼Œç”¨ä¾†è¡¨ç¤º $p_i$ æ˜¯å¦èˆ‡å•é¡Œä¸­çš„ question word $q$ ç²¾ç¢ºåŒ¹é…ï¼Œç„¡è«–æ˜¯åŸå§‹å½¢å¼ã€å°å¯«ï¼Œé‚„æ˜¯ lemma form Token features\nä½œè€…æ·»åŠ äº†ä¸€äº› manual feature å¥½åæ‡‰ $p_i$ åœ¨ context ä¸­çš„å±¬æ€§ï¼Œæ¯”å¦‚ part-of-speech (POS)ã€named entity recognition (NER) tags å’Œå®ƒçš„ (normalized) term frequency (TF) Aligned question embedding\n$f_{align}(p_i)=\\sum_j a_{i,j}E(q_j)$ $E$ æ˜¯ word embedding $a_{i,j}$ æ˜¯ attention scoreï¼Œè¨ˆç®— $p_i$ å’Œæ¯å€‹ $q_j$ ä¹‹é–“çš„ similarity Question encoding é€™å€‹æ¯”è¼ƒç°¡å–®ï¼Œåªæ˜¯åœ¨ word embedding ä¸ŠåŠ ä¸Šä¸€å±¤ RNNï¼Œä¸¦æŠŠ hidden units é‡æ–°çµåˆæˆä¸€å€‹å‘é‡\nPrediction æŠŠ $\\{p_1,\u0026hellip;,p_m\\}$ å’Œ $q$ ä½œç‚º inputï¼Œä¸¦å€‹åˆ¥å–®ç¨è¨“ç·´å…©å€‹åˆ†é¡å™¨é æ¸¬é–‹é ­å’Œçµå°¾çš„ä½ç½®\nå…·é«”ä¾†èªªï¼Œä½œè€…ç”¨ bilinear term ä¾†è¨ˆç®—æ¯å€‹ $p_i$ å’Œ $q$ ä¹‹é–“çš„ç›¸ä¼¼åº¦ï¼Œä¸¦è¨ˆç®—æ¯å€‹ $p_i$ æ˜¯é–‹é ­çš„æ©Ÿç‡å’Œçµå°¾çš„æ©Ÿç‡\næœ€å¾Œé¸æ“‡æœ€ä½³ç¯„åœï¼Œå¾ token $i$ åˆ° token $i'$\n$i \\le i\u0026rsquo; \\le i+15$\nä¸¦ä¸”ä½¿ $P_{start}(i) \\times P_{end}(i\u0026rsquo;)$ æœ€å¤§åŒ–\nData æœ¬æ–‡çš„å·¥ä½œä¾è³´ä¸‰ç¨®è³‡æ–™ï¼š\nWikipedia å°‹æ‰¾ç­”æ¡ˆçš„ä¾†æº SQuAD ç”¨ä¾†è¨“ç·´å’Œè©•ä¼°æ¨¡å‹ å¦å¤–ä¸‰å€‹ QA è³‡æ–™é›† (WebQuestions, CuratedTREC, WikiMovies) ç”¨ä¾†æ¸¬è©¦æ¨¡å‹åœ¨ Open-domain QA ä¸Šçš„æ³›åŒ–èƒ½åŠ›ï¼Œä¸¦è©•ä¼°æ¨¡å‹å¾ multitask learning å’Œ distant supervision ä¸­ç²ç›Šçš„ç¨‹åº¦ Wikipedia (Knowledge Source) ç”¨ 2016-12-21 dump2 çš„ English Wikipedia\nå°æ–¼æ¯é ï¼Œåªæå–æ–‡æœ¬ï¼Œä¸¦åˆªé™¤çµæ§‹åŒ–çš„è³‡æ–™ï¼ˆlists and figuresï¼‰\nä¸Ÿæ£„ disambiguation pages, list, index å’Œ outline pagesï¼Œä¿ç•™äº† 5,075,182 ç¯‡æ–‡ç« \nSQuAD ä½¿ç”¨å…©å€‹ evaluation metricsï¼š\nExact string match (EM) F1 score ç‚ºäº†è©•ä¼° open-domain QA çš„èƒ½åŠ›ï¼Œä½œè€…åªæœ‰ä½¿ç”¨ SQuAD çš„ QA pairsï¼Œè¦æ±‚ç³»çµ±åœ¨ç„¡æ³•å­˜å–ç›¸é—œæ®µè½çš„æƒ…æ³ä¸‹ç™¼ç¾æ­£ç¢ºçš„ answer span\nä¸åƒæ¨™æº–çš„ SQuAD setting æœƒçµ¦å‡ºç›¸é—œæ®µè½\nOpen-domain QA Evaluation Resources SQuAD æ˜¯ç›®å‰å¯ç”¨çš„æœ€å¤§çš„ general purpose QA è³‡æ–™é›†ä¹‹ä¸€\næ”¶é›†éç¨‹åŒ…æ‹¬å‘æ¯å€‹ human annotator å±•ç¤ºä¸€å€‹æ®µè½ï¼Œä¸¦å¯«ä¸€å€‹å•é¡Œ\nå› æ­¤ï¼Œdistribution éå¸¸ç‰¹å®š\nä½œè€…å»ºè­°åœ¨å…¶ä»– open-domain QA è³‡æ–™é›†ä¸Šè©•ä¼°ç³»çµ±ï¼Œä»–å€‘ä»¥ä¸åŒçš„æ–¹å¼å»ºæ§‹\nCuratedTREC ä½¿ç”¨å¤§ç‰ˆæœ¬ï¼ŒåŒ…å« TREC 1999, 2000, 2001 å’Œ 2002 çš„ 2180 å€‹å•é¡Œ\nWebQuestions é€™è³‡æ–™é›†æ—¨åœ¨å›ç­” Freebase KB çš„å•é¡Œ\né€é Google Suggest API æŠ“å•é¡Œï¼Œå†ç”¨ Amazon Mechanical Turk ä¾†ç²å–ç­”æ¡ˆ\nä½œè€…ç”¨ entity names æŠŠæ¯å€‹ answer è½‰æˆç­”æ¡ˆï¼Œä»¥ä¾¿ä¸å¼•å…¥ Freebase IDs\nWikiMovies åŒ…å«å°é›»å½±é ˜åŸŸçš„ 96k å€‹å•ç­”å°\nDistantly Supervised Data ä¸Šé¢èªªçš„è³‡æ–™é›†é™¤äº† SQuAD éƒ½æ²’æœ‰ç›¸é—œæ®µè½ï¼Œå› æ­¤ä¸èƒ½ç›´æ¥è¨“ç·´ Document Reader\nè¿½éš¨ä¹‹å‰å·²æœ‰çš„åˆ©ç”¨ distant supervision (DS) ä¾†åš relation extraction çš„å·¥ä½œï¼Œä½œè€…ç”¨ä¸€å€‹ç¨‹å¼è‡ªå‹•æŠŠæ®µè½å’Œæ­¤é¡è¨“ç·´ç¯„ä¾‹åšç›¸é—œè¯\nå°æ¯å€‹å•ç­”å°ä½¿ç”¨ä»¥ä¸‹éç¨‹ä¾†å»ºç«‹è¨“ç·´é›†ï¼š\né¦–å…ˆï¼Œå°å•é¡Œç”¨ Document Retriever æ‰¾åˆ°å‰ 5 å€‹ç›¸é—œçš„æ®µè½\nèˆ‡å·²çŸ¥ç­”æ¡ˆæ²’æœ‰ exact match çš„æ®µè½éƒ½è¢«ç›´æ¥ä¸Ÿæ£„\nçŸ­æ–¼ 25 å€‹å­—å…ƒæˆ–é•·æ–¼ 1500 å€‹å­—å…ƒçš„æ®µè½ä¹Ÿè¢«ä¸Ÿæ£„\nå¦‚æœåœ¨å•é¡Œä¸­æ‰¾åˆ° named entityï¼Œä¸åŒ…å«è©² named entity çš„æ®µè½ä¹Ÿè¢«ä¸Ÿæ£„\nå°æ–¼æ¯å€‹ retrived page çš„æ¯å€‹æ®µè½ï¼Œä½¿ç”¨ question å’Œ 20 token window é–“çš„ unigram å’Œ bigram overlap ä¾†è¨ˆç®—ç›¸ä¼¼åº¦ï¼Œä¿ç•™é‡ç–Šåº¦æœ€é«˜çš„å‰äº”å€‹æ®µè½\nå°‡æ‰¾åˆ°çš„æ¯å€‹ pair åŠ å…¥åˆ° DS è¨“ç·´é›†ä¸­\nå¤§ç´„ä¸€åŠçš„ DS ç¯„ä¾‹ä¾†è‡ª SQuAD ä»¥å¤–çš„é é¢\nExperiments Finding Relevant Articles å…ˆæª¢æŸ¥ Retriever åœ¨æ‰€æœ‰ QA è³‡æ–™é›†ä¸Šçš„æ€§èƒ½\nè¨ˆç®— ration æ˜¯æ ¹æ“šç‰¹å®šçš„å•é¡Œï¼Œè€ƒæ…®é€™äº›å•é¡Œå°æ‡‰çš„æ–‡æœ¬åœ¨å‰ 5 å€‹ç›¸é—œæ–‡ç« ä¸­çš„æ¯”ä¾‹\nçµæœè¡¨æ˜ï¼Œæ¯” Wikipedia Search é‚„æ›´å¥½ï¼Œå°¤å…¶æ˜¯ä½¿ç”¨ bigram hashing çš„æƒ…æ³ä¸‹\nReader Evaluation on SQuAD Implementation details ä½¿ç”¨ h=128 çš„ 3 å±¤é›™å‘ LSTMï¼Œä¾†åš paragraph encoding å’Œ question encoding\nä½¿ç”¨ Stanford CoreNLP ä¾†åš tokenization ä¸¦ç”Ÿæˆ lemma, part-of-speech å’Œ named entity tags\nOptimizer ä½¿ç”¨ Adamax\nDropout rate ç‚º 0.3\nResult and analysis ä½œè€…çš„ç³»çµ±å¯ä»¥åœ¨ SQuAD ä¸Šé”åˆ° SOTA\nåšäº† ablation studyï¼Œçµæœè¡¨æ˜æ‰€æœ‰åŠŸèƒ½éƒ½æœƒå½±éŸ¿æ€§èƒ½\næœ‰è¶£çš„æ˜¯ï¼Œå–®ç¨æ²’æœ‰ $f_{alignd}$ æˆ– $f_{exact_match}$ å°æ€§èƒ½ä¸æœƒæœ‰æ¥µå¤§çš„å½±éŸ¿ï¼Œä½†å…©å€‹éƒ½æ²’æœ‰å°±æœƒæ€¥é½ä¸‹é™\nFull Wikipedia Question Answering æ¯”è¼ƒä¸‰å€‹ç‰ˆæœ¬çš„ DrQAï¼š\nSQuAD åªåœ¨ SQuAD ä¸Šè¨“ç·´ï¼Œä¸¦ç”¨æ–¼æ‰€æœ‰è©•ä¼°è³‡æ–™é›† Fine-tune (DS) å…ˆåœ¨ SQuAD ä¸Šé è¨“ç·´ï¼Œåœ¨ç”¨ DS è¨“ç·´é›†å°æ¯å€‹è³‡æ–™é›†é€²è¡Œå¾®èª¿ Multitask (DS) åœ¨ SQuAD å’Œ DS è¨“ç·´é›†ä¸Šè¯åˆè¨“ç·´ Results Conclusion å…©å€‹æ˜é¡¯çš„ angles of attackï¼š\næŠŠå¤šå€‹æ®µè½ç›´æ¥ç´å…¥ Document Reader çš„è¨“ç·´ï¼Œå› ç‚ºä»–ç›®å‰ç¨ç«‹è¨“ç·´æ¯å€‹æ®µè½ å¯¦ä½œä¸€å€‹ end-to-end training çš„ pipelineï¼Œå¯ä»¥åœ¨ä¸€å€‹æ¨¡å‹ä¸­çµåˆ Document Retriever å’Œ Document Reader ","date":"2023-12-25T00:00:12+08:00","permalink":"https://roykesydon.github.io/Blog/p/drqa-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"DrQA è«–æ–‡é–±è®€"},{"content":"ä»‹ç´¹ ChatGPT çš„ç¼ºé™·\næ²’æœ‰ä¸€å®šæ™‚é–“å¾Œçš„è³‡æ–™ (ç•¶æ™‚) æ²’æœ‰è¾¦æ³•é€£çµå¤–éƒ¨ç§äººè³‡æ–™ (e.g. Google Drive) LangChain çš„å„ªé»\nIntegration å¯ä»¥é€£çµå¤–éƒ¨è³‡æ–™ Agency è®“ LLM å¯ä»¥å’Œç’°å¢ƒäº’å‹•ï¼Œåšå‡ºæ±ºç­– Components çµæ§‹ Schema å°è©± System: å°è©±çš„ context Human: ä½ çš„è©¢å• AI: AI çš„å›ç­” Document å„²å­˜ä¸€æ®µæ–‡å­—ä»¥é›† metadata çš„çµæ§‹ Embedding OpenAIEmbeddings å¯ä»¥æŠŠæ–‡å­—è½‰æ›æˆå‘é‡ï¼Œé è¨­æ˜¯ 1536 ç¶­ ä½†æ˜¯æœ‰æœ€å¤§é•·åº¦é™åˆ¶ æ–‡å­—è™•ç† Output Parser è®“æ¨¡å‹é‡ç”Ÿä½ æƒ³è¦çš„æ ¼å¼ï¼Œä¸¦è½‰æ›æˆä½ æƒ³è¦çš„çµæ§‹ï¼Œæ¯”å¦‚ json\nè³‡æ–™å„²å­˜ Indexes Document_loaders\nå¯ä»¥å¾ä¸åŒçš„ä¾†æºç²å¾—è³‡æ–™ text_splitter\næŠŠå¤§é‡çš„æ–‡å­—åˆ‡æˆå¤šå€‹ chunks retriever\nç”¨ä¾†æ‰¾åˆ°ç›¸è¿‘çš„æ–‡ä»¶ VectorStores\nChroma local storage äº¤äº’ PromptTemplate ç”¨ä¾†å¾€ String Template å¡«å…¥è®Šæ•¸ æœ‰äº› Component æœƒå’Œé€™å€‹ç”¨æ³•çµ„åˆï¼Œæ‰€ä»¥ä¸é©åˆç›´æ¥æ›æˆ f-string FewShotPromptTemplate å¯ä»¥ç”¨è‡ªå·±æº–å‚™çš„ä¸€äº›ä¾‹å­çµåˆ PromptTemplate ä¾†åš Few-shot learning å¯ä»¥é€é FAISS ä¾†æ‰¾åˆ°æœ€ç›¸è¿‘çš„ä¾‹å­ Chain ç”¨åœ¨æœ‰å¤šå€‹æœ‰åºçš„å•é¡Œçš„æƒ…æ³\nmulti-step workflow\nVectorDBQA\nå¯ä»¥ç”¨åœ¨æœç´¢ local çš„å‘é‡è³‡æ–™åº« Instruction çµåˆ context çš„æ¨¡å¼ (Summarize)\næ¨¡å¼ Stuffing Map Reduce Refine Map-Rerank èªªæ˜ ç›´æ¥æŠŠ context å’Œ query çµåˆ æŠŠ Document åˆ‡æˆå¤šå¡Š ï¼ŒæŠŠæ¯å¡Šäº¤çµ¦ LLMï¼Œè½‰æ›æˆ summaryï¼Œåè¦†å¾é€™äº› summary ç”Ÿ summary æ¯æ¬¡åˆ‡ä¸€å°å¡Šï¼Œä¸¦ä¸”å’Œå…ˆå‰çš„çµæœåš summary è®“æ¯å€‹ chunk å’Œ query å»ç”Ÿç­”æ¡ˆï¼Œä¸¦è¦æ¨¡å‹å°è‡ªå·±çš„ç­”æ¡ˆè©•åˆ†ï¼Œæœ€å¾Œé¸åˆ†æ•¸é«˜çš„ å„ªé» åªéœ€ call ä¸€æ¬¡ APIã€æ¶µè“‹æ‰€æœ‰è³‡æ–™ å¯ä»¥é¤µå…¥æ›´å¤§çš„æ–‡ä»¶ã€å¯ä»¥å¹³è¡Œé‹ç®— å¯ä»¥é¤µå…¥æ›´å¤§çš„æ–‡ä»¶ å°æ–¼ç°¡å–®çš„å•é¡Œå¯èƒ½æ¯”è¼ƒæœ‰æ•ˆ ç¼ºé» å®¹æ˜“é”åˆ° token ä¸Šé™ call å¤šæ¬¡ APIã€summary çš„éç¨‹ä¸­æœƒæµå¤±è³‡è¨Š call å¤šæ¬¡ APIã€summary çš„éç¨‹ä¸­æœƒæµå¤±è³‡è¨Š æ²’æœ‰è¾¦æ³•çµåˆå¤šå€‹ Document çš„è³‡è¨Š Agent æœ‰äº›æ‡‰ç”¨ä¸­ï¼Œä½ å¯èƒ½ä¸çŸ¥é“è©²éµå¾ªä»€éº¼æµç¨‹ä¾†è®“ LLM å®Œæˆä»»å‹™ï¼Œé€™æ™‚å€™ä½ æœƒéœ€è¦è®“ LLM è‡ªè¡Œæ±ºå®šè¦æ¡å–å“ªäº›å‹•ä½œä»¥åŠæ¡å–çš„é †åº å¯ä»¥å‹•æ…‹åœ°åˆ©ç”¨ Chain verbose=True çš„æ™‚å€™æœƒå°å‡ºæ€è€ƒéç¨‹ Tools æœ‰æ¯”å¦‚ Google Search ä¹‹é¡çš„ Tool å¯ä»¥çµåˆæ‡‰ç”¨ Memory ConversationChain è®“ Chain å’Œ Agent å¯ä»¥ä¿ç•™ä¹‹å‰çš„å°è©± ","date":"2023-12-18T00:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/langchain-%E7%AD%86%E8%A8%98/","title":"LangChain ç­†è¨˜"},{"content":"paper: Learning Transferable Visual Models From Natural Language Supervision\nAbstract ç¾æœ‰çš„ SOTA CV system å¯ä»¥ç¶“éè¨“ç·´é æ¸¬ä¸€çµ„å›ºå®šçš„é¡åˆ¥ã€‚ ä½†é€™ç¨®ç›£ç£å¼çš„æ–¹æ³•ä¹Ÿå—é™äº†é€šç”¨æ€§ï¼Œå› ç‚ºéœ€è¦é¡å¤–çš„ labeled data ä¾†æ“´å±•ã€‚\nç›´æ¥å¾ raw text å­¸ç¿’ image æ˜¯å€‹æœ‰å‰é€”çš„æ›¿ä»£æ–¹æ¡ˆã€‚\næœ¬æ–‡è­‰æ˜äº†ã€Œé æ¸¬å“ªå€‹æ˜¯åœ–ç‰‡çš„ captionã€é€™ç¨®å½¢å¼çš„é è¨“ç·´æ˜¯ä¸€ç¨®é«˜æ•ˆä¸”å¯æ“´å±•çš„æ–¹æ³•ï¼Œå¯ä»¥å¾ internet ä¸Šè’é›†çš„ 4 å„„å°è³‡æ–™å¾é ­å­¸ç¿’åˆ° SOTA image representationã€‚\né è¨“ç·´å¾Œï¼Œé€éè‡ªç„¶èªè¨€ä¾†å¼•å°ï¼Œå°±å¯ä»¥åœ¨ä¸‹æ¸¸ä»»å‹™åç·š zero-shotã€‚\næœ¬æ–‡å° 30 å€‹ä¸åŒçš„ç¾æœ‰é›»è…¦è¦–è¦ºè³‡æ–™é›†é€²è¡Œæ¯”è¼ƒï¼Œå¯ä»¥åœ¨å¤šæ•¸ä»»å‹™å’Œç›£ç£å¼å­¸ç¿’çš„ baseline ç«¶çˆ­ï¼Œè€Œä¸”ç„¡é ˆä»»è³‡æ–™é›†ä¾†åšç‰¹åˆ¥çš„è¨“ç·´ã€‚\nä¾‹å¦‚åœ¨ ImageNet ä¸Šåš zero-shot å¯ä»¥å’Œ ResNet-50 å–å¾—ç›¸è¿‘çš„æº–ç¢ºåº¦ã€‚\nIntroduction and Motivating Work ç›´æ¥å¾åŸå§‹æ–‡æœ¬å­¸ç¿’çš„é è¨“ç·´æ–¹æ³•åœ¨éå»å¹¾å¹´å¾¹åº•æ”¹è®Šäº† NLPã€‚\nTask-agnostic (èˆ‡ä¸‹æ¸¸ä»»å‹™ç„¡é—œ) objectivesï¼Œæ¯”å¦‚ autoregressive å’Œ masked language modelingï¼Œè®“æ¨¡å‹å¾—ä»¥éš¨è‘— compute, model capacity, å’Œ data è¦æ¨¡çš„å¢é•·ï¼Œä½¿èƒ½åŠ›ä¹Ÿé€æ­¥æå‡ã€‚\nåœ¨ \u0026ldquo;text-to-text\u0026rdquo; é€™ç¨®è¼¸å…¥è¼¸å‡ºå½¢å¼çš„é è¨“ç·´ï¼Œä½¿æ¨¡å‹è½‰ç§»åˆ°ä¸‹æ¸¸ä»»å‹™çš„æ™‚å€™ï¼Œä¸ç”¨ç‰¹åœ°å®¢è£½åŒ– output headï¼Œæˆ–å°è³‡æ–™é›†åšç‰¹åˆ¥åœ°è™•ç†ã€‚\né€™äº›çµæœè¡¨æ˜ï¼Œç¾ä»£çš„é è¨“ç·´æ–¹æ³•åœ¨ web-scale çš„æ–‡å­—é›†åˆçš„è¡¨ç¾å·²ç¶“è¶…éäº†ç”¨é«˜å“è³ªçš„äººç‚ºæ¨™è¨˜ NLP è³‡æ–™é›†ã€‚\nç„¶è€Œåœ¨ CV ç­‰é ˜åŸŸï¼Œåœ¨ ImageNet é€™ç¨®äººç‚ºæ¨™è¨˜çš„è³‡æ–™é›†ä¸Šåšé è¨“ç·´å»ä¾ç„¶æ˜¯æ¨™æº–åšæ³•ã€‚\nç›´æ¥å¾ç¶²è·¯æ–‡æœ¬å­¸ç¿’çš„å¯æ“´å±•é è¨“ç·´æ–¹æ³•æˆ–è¨±èƒ½åœ¨ CV å¸¶ä¾†é¡ä¼¼çš„çªç ´ã€‚\nä»¥å¾€æœ‰ä¸€äº›å·¥ä½œå˜—è©¦åˆ©ç”¨å¹¾ä¹ç„¡é™é‡çš„åŸå§‹æ–‡æœ¬è€Œä¸æ˜¯æœ‰é™æ•¸é‡çš„ \u0026ldquo;gold-labels\u0026rdquo;ï¼Œ ä½†æ˜¯é€™äº›æ–¹æ³•éƒ½æœ‰ä¸€äº›å¦¥å”ï¼Œæ¯”å¦‚éƒ½åˆ©ç”¨ softmax ä¾†åŸ·è¡Œé æ¸¬ï¼Œä½¿å…¶æ²’è¾¦æ³•æ‡‰ä»˜æ–°é¡åˆ¥ï¼Œåš´é‡é™åˆ¶äº† zero-shot çš„èƒ½åŠ›ã€‚\nä½œè€…æäº†å¹¾å€‹å¼±ç›£ç£å­¸ç¿’çš„ä¾‹å­ï¼Œä»–å€‘åˆ©ç”¨é¡å¤–çš„è³‡æ–™çµåˆé è¨“ç·´ï¼Œä¾†å¹«å¿™æ”¹å–„ç›£ç£å¼å­¸ç¿’çš„çµæœã€‚\nä¹Ÿæäº†å¹¾å€‹å’Œ CLIP é¡ä¼¼çš„å·¥ä½œ VirTex, ICMLM, ConVIRTï¼Œæƒ³åˆ©ç”¨ Transformerï¼Œå¾ Natural Language ä¸­å­¸ç¿’ image representationã€‚\né€™äº› weakly supervised model å’Œæœ€è¿‘å¾ NLP å­¸ç¿’ image representation çš„æ–¹æ³•æœ‰ä¸€å€‹é‡å¤§å·®ç•°ï¼Œè¦æ¨¡ã€‚\næœ€è¿‘çš„ä¸€äº›ç ”ç©¶ï¼Œæ¯”å¦‚ä¸€äº›å¼±ç›£ç£å­¸ç¿’åœ¨æ•¸ç™¾è¬åˆ°æ•¸åå„„å¼µç…§ç‰‡ä¸Šè¨“ç·´äº†å¤šå€‹ accelerator yearsã€‚ä½†æ˜¯å’Œ CLIP ç›¸ä¼¼çš„ç ”ç©¶åªåœ¨äºŒåè¬å¼µåœ–ç‰‡ä¸Šè¨“ç·´äº†å¹¾å¤©ã€‚\næœ¬æ–‡å°‡è¦æ¨¡æ‹‰é«˜ï¼Œä»¥ç¸®çŸ­è¦æ¨¡ä¸Šçš„å·®è·ã€‚\nä½œè€…åœ¨ internet ä¸Šè’é›†äº† 4 å„„å°åœ–ç‰‡å’Œæ–‡å­—çš„è³‡æ–™ï¼Œåšæˆæ–°çš„è³‡æ–™é›†ï¼Œä¸¦æå‡ºäº† CLIPï¼ŒConVIRT çš„ç°¡åŒ–ç‰ˆæœ¬ã€‚\nä½œè€…åœ¨ 30 å¹¾å€‹è³‡æ–™é›†ä¸Šæ¸¬è©¦ï¼ŒåŸºæœ¬ä¸Šèƒ½å’Œç›£ç£å¼çš„æ¨¡å‹ç«¶çˆ­ã€‚\nå¦‚æœç”¨ linear-probeï¼Œæ¯”å…¬é–‹å¯ç”¨çš„ SOTA ImageNet model é‚„æ›´å¥½ã€‚\nApproach Natural Language Supervision æ ¸å¿ƒæƒ³æ³•æ˜¯åˆ©ç”¨ natural language ä¾†å­¸ç¿’ perceptionã€‚\nä½œè€…ç¨±é€™ä¸æ˜¯ä¸€å€‹æ–°æƒ³æ³•ï¼Œä½†ä»¥å¾€ç›¸ä¼¼çš„æ–¹æ³•çš„ç”¨èªå¤šæ¨£ï¼Œä»–ä»‹ç´¹äº†å››ç¯‡æ–‡ç« ï¼Œä½†æŠŠå¾æ–‡å­—å’Œåœ–ç‰‡ä¸­å­¸ç¿’ image representation çš„æ–¹æ³•å€‹åˆ¥ç¨±ç‚ºï¼šç„¡ç›£ç£ã€è‡ªç›£ç£ã€å¼±ç›£ç£ã€ç›£ç£å¼ã€‚\næ“´å±• natural language supervision æ¯”èµ·åœ–åƒåˆ†é¡ç°¡å–®çš„å¤šï¼Œä¸å¿…å®šå¥½é¡åˆ¥ï¼Œå†å»æ¨™è¨»æ¯å¼µç…§ç‰‡çš„é¡åˆ¥ã€‚\nè€Œä¸” natural language supervision é‚„æœ‰å€‹å„ªå‹¢ï¼Œä»–ä¸åªèƒ½å­¸ç¿’ image representationï¼Œé‚„èƒ½å°‡å…¶å’Œæ–‡å­—ç›¸é—œè¯ï¼Œä½¿å…¶æ›´å¥½åš zero-shot çš„é·ç§»ã€‚\nCreating a Sufficiently Large Dataset ç¾æœ‰å·¥ä½œä¸»è¦ç”¨ä¸‰å€‹è³‡æ–™é›†:\nMS-COCO Visual Genome YFCC100M MS-COCO å’Œ Visual Genome éƒ½æ˜¯é«˜å“è³ªçš„äººç‚ºæ¨™è¨˜è³‡æ–™é›†ï¼Œä½†æ˜¯æŒ‰ç…§ç¾ä»£æ¨™æº–ä¾†çœ‹ï¼Œå®ƒå€‘å¾ˆå°ï¼Œæ¯å€‹è³‡æ–™é›†å¤§ç´„æœ‰ 100,000 å¼µè¨“ç·´ç…§ç‰‡ã€‚\nç›¸è¼ƒä¹‹ä¸‹ï¼Œä½œè€…èˆ‰äº†ä¸€å€‹æœ€è¿‘çš„ç ”ç©¶ï¼Œç”¨äº† 3.5 Billion å¼µ Instagram ç…§ç‰‡ä½œç‚ºè¨“ç·´è³‡æ–™ã€‚\nYFCC100M æ˜¯ä¸€å€‹å¯èƒ½çš„æ›¿ä»£æ–¹æ¡ˆï¼Œå®ƒæœ‰ 100 million å¼µç…§ç‰‡ï¼Œä½†æ¯å¼µç…§ç‰‡çš„ metadata è³‡æ–™ç¨€ç–ï¼Œè€Œä¸”è‰¯è ä¸é½Šã€‚\næ¯”å¦‚è¨±å¤šæª”åæ˜¯è‡ªå‹•ç”¢ç”Ÿçš„ï¼Œå¯èƒ½æ˜¯æ™‚é–“ï¼Œæˆ–æ˜¯ç›¸æ©Ÿçš„åƒæ•¸ã€‚\nç¶“ééæ¿¾ï¼Œä¿ç•™å¸¶æœ‰è‡ªç„¶èªè¨€çš„æ¨™é¡Œæˆ–æè¿°çš„åœ–åƒï¼Œè³‡æ–™é›†ç¸®å°äº† 6 å€ï¼Œåªå‰© 15000 è¬å¼µç…§ç‰‡ï¼Œå’Œ ImageNet çš„å¤§å°ç›¸ç•¶ã€‚\nnatural language supervision çš„ä¸€å€‹ä¸»è¦å‹•æ©Ÿæ˜¯ç¶²è·¯ä¸Šå…¬é–‹è‘—å¤§é‡é€™ç¨®å½¢å¼çš„ dataã€‚ ç”±æ–¼ç¾æœ‰è³‡æ–™é›†æ²’æœ‰åæ˜ é€™ç¨®å¯èƒ½æ€§ï¼Œå› æ­¤åªè€ƒæ…®é€™äº›è³‡æ–™é›†æœƒä½ä¼°é€™æ–¹é¢ç ”ç©¶çš„æ½›åŠ›ã€‚\næ‰€ä»¥ä½œè€…å»ºç«‹äº†ä¸€å€‹æ–°çš„åŒ…å« 400 million pairs çš„è³‡æ–™é›†ï¼Œå¾ç¶²è·¯ä¸Šå„ç¨®å…¬é–‹çš„ä¾†æºè’é›†çš„ã€‚\nç‚ºäº†ç›¡å¯èƒ½æ¶µè“‹æ‰€æœ‰çš„ visual conceptsï¼Œä½œè€…åœ¨å»ºæ§‹è³‡æ–™é›†çš„æ™‚å€™æº–å‚™äº† 50 è¬çµ„ç‰¹å®šçš„ queryï¼Œæ¯çµ„ query æœ€å¤šåŒ…å« 20,000 å€‹ pairï¼Œä¾†é€²è¡Œ class balanceã€‚\nç”¢ç”Ÿçš„è³‡æ–™é›†çš„ç¸½å­—æ•¸å’Œ GPT-2 ç”¨çš„ WebText å·®ä¸å¤šã€‚\nå°‡æ­¤è³‡æ–™é›†ç¨±ç‚º WITï¼Œå…¨åæ˜¯ WebImageTextã€‚\nSelecting an Efficient Pre-Training Method æœ€å…ˆé€²çš„ CV System éœ€è¦å¤§é‡çš„è¨ˆç®—ã€‚\nä½œè€…èˆ‰äº†å…©å€‹è¨ˆç®—é‡éƒ½éå¸¸ææ€–çš„æ¨¡å‹ï¼Œè€Œä¸”ä»–å€‘åªèƒ½é æ¸¬ 1000 å€‹ ImageNet çš„é¡åˆ¥ã€‚ å…¶ä¸­ä¸€å€‹èŠ±äº† 19 å€‹ GPU yearsï¼Œå¦ä¸€å€‹èŠ±äº† 33 å€‹ TPUv3 core-yearsã€‚ ä¹çœ‹ä¹‹ä¸‹ï¼Œå¾è‡ªç„¶èªè¨€ä¸­å­¸ç¿’ä¸€çµ„é–‹æ”¾çš„è¦–è¦ºæ¦‚å¿µä¼¼ä¹ä»¤äººç”Ÿç•ã€‚\nä½†åœ¨ä½œè€…åŠªåŠ›çš„éç¨‹ä¸­ï¼Œä»–å€‘ç™¼ç¾è¨“ç·´æ•ˆç‡æ˜¯æˆåŠŸæ“´å±•è‡ªç„¶èªè¨€ç›£ç£çš„é—œéµï¼Œä¹Ÿæ ¹æ“šè©²æŒ‡æ¨™é¸å®šæœ€çµ‚çš„é è¨“ç·´æ–¹æ³•ã€‚\næœ€åˆçš„æ–¹æ³•å’Œ VirTex ç›¸ä¼¼ï¼Œå¾é ­é–‹å§‹è¨“ç·´ä¸€å€‹ CNNï¼Œå’Œ text transformer ä¾†é æ¸¬ captionã€‚\nFig.2 å±•ç¤ºçš„ Transformer èªè¨€æ¨¡å‹çš„è¨ˆç®—é‡æ˜¯ ResNet-50 Image encoder çš„å…©å€ã€‚ é æ¸¬ caption æ¯”é æ¸¬ caption ä½†æ¡ç”¨è©è¢‹çš„æ–¹å¼é‚„æ…¢ä¸‰å€ã€‚\né€™æ¨£é æ¸¬ caption æ˜¯ä¸€å€‹å›°é›£çš„ä»»å‹™ï¼ŒåŒä¸€å¼µç…§ç‰‡å°æ‡‰çš„ caption å¯èƒ½å‡ºç¾çš„æè¿°ç”šè‡³æœ‰éå¸¸å¤šç¨®ã€‚ æœ€è¿‘åœ¨ Contrastive representation learning æ–¹é¢çš„ç ”ç©¶ç™¼ç¾ contrastive objectives æœ‰ä¸éŒ¯çš„è¡¨ç¾ã€‚\nå› æ­¤ä½œè€…æ¢ç´¢ä¸€ç¨®æ–¹æ³•æ˜¯ï¼Œåªé æ¸¬æ–‡æœ¬å’Œå“ªä¸€å€‹åœ–ç‰‡é…å°ï¼Œè€Œä¸æ˜¯é æ¸¬ç¢ºåˆ‡çš„å–®å­—ã€‚\nå› ç‚ºè³‡æ–™é›†è¶…ç´šå¤§ï¼Œoverfitting çš„å•é¡Œå½±éŸ¿ä¸å¤§ã€‚\næ­¤å¤–ï¼Œä½œè€…ç™¼ç¾å°æ–¼ encoder çš„ representationï¼Œè¦è½‰æ›åˆ° multi-model embedding spaceï¼Œåªéœ€è¦ä½¿ç”¨ linear projection å³å¯ï¼Œä¸éœ€è¦ non-linearï¼Œå…©è€…ä¹‹é–“å·®åˆ¥ä¸å¤§ã€‚\nData augmentation åªæœ‰ä½¿ç”¨ random cropï¼Œè€Œæ²’æœ‰ä½¿ç”¨å…¶ä»–çš„ã€‚\nChoosing and Scaling a Model 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # image_encoder - ResNet or Vision Transformer # text_encoder - CBOW or Text Transformer # I[n, h, w, c] - minibatch of aligned images # T[n, l] - minibatch of aligned texts # W_i[d_i, d_e] - learned proj of image to embed # W_t[d_t, d_e] - learned proj of text to embed # t - learned temperature parameter # extract feature representations of each modality I_f = image_encoder(I) #[n, d_i] T_f = text_encoder(T) #[n, d_t] # joint multimodal embedding [n, d_e] I_e = l2_normalize(np.dot(I_f, W_i), axis=1) T_e = l2_normalize(np.dot(T_f, W_t), axis=1) # scaled pairwise cosine similarities [n, n] logits = np.dot(I_e, T_e.T) * np.exp(t) # symmetric loss function labels = np.arange(n) loss_i = cross_entropy_loss(logits, labels, axis=0) loss_t = cross_entropy_loss(logits, labels, axis=1) loss = (loss_i + loss_t)/2 Experiments Prompt Engineering and Ensembling ä¸€ç¨®å¸¸è¦‹çš„å•é¡Œæ˜¯ polysemyï¼Œä¸€å€‹å–®å­—å¯èƒ½æœ‰å¤šç¨®æ„æ€ï¼Œæ¯”å¦‚ \u0026ldquo;boxer\u0026rdquo; å¯èƒ½æ˜¯ä¸€ç¨®ç‹—ï¼Œæˆ–æ˜¯æ‹³æ“Šæ‰‹ã€‚ å¦‚æœä¸€å¼µåœ–ç‰‡å°æ‡‰ä¸€å€‹å–®å­—å°±æœƒé¢è‡¨é€™å•é¡Œã€‚\nå¦ä¸€ç¨®æ˜¯ distribution gapï¼Œæ¯”å¦‚è¨“ç·´ç”¨å¥å­ï¼Œä½†æ¸¬è©¦ç”¨å–®å­—ã€‚ ç‚ºäº†ç·©è§£é€™å•é¡Œï¼Œä½œè€…ç™¼ç¾ç”¨ prompt template \u0026ldquo;A photo of a {label}.\u0026rdquo; æ¯”ç›´æ¥ç”¨ label å¥½ã€‚\nå…‰ç”¨é€™å€‹ prompt template å°±æé«˜ 1.3 % åœ¨ ImageNet ä¸Šçš„æº–ç¢ºåº¦ã€‚\nå¦‚æœå¯ä»¥çµ¦å…¶ä»–é¡å¤–è¨Šæ¯æœƒæ›´æœ‰å¹«åŠ©ï¼Œæ¯”å¦‚å°æ–¼å¯µç‰©çš„è³‡æ–™é›†ï¼Œå¯ä»¥ç”¨ \u0026ldquo;A photo of a {label}, a type of pet.\u0026quot;ã€‚\nå°æ–¼ OCR è³‡æ–™é›†ï¼Œä½œè€…ç™¼ç¾åœ¨è¦è­˜åˆ¥çš„æ–‡å­—æˆ–æ•¸å­—å‰å¾ŒåŠ ä¸Šå¼•è™Ÿå¯ä»¥æé«˜æ•ˆèƒ½ã€‚\nå†ä¾†æ˜¯ prompt ensemblingï¼Œä½œè€…ç™¼ç¾ç”¨å¤šå€‹ prompt template ä¾†é æ¸¬ï¼Œç„¶å¾Œç¶œåˆçµæœï¼Œå¯ä»¥æé«˜æ•ˆèƒ½ã€‚ ä½œè€…ç”¨äº† 80 å€‹ templateã€‚åœ¨ ImageNet ä¸Šæ¯”ç”¨å–®ä¸€çš„ prompt template æé«˜ 3.5 % çš„ performanceã€‚\nç¶œåˆè€ƒæ…® prompt engineering å’Œ prompt ensemblingï¼Œä½œè€…åœ¨ ImageNet ä¸Šçš„æº–ç¢ºåº¦æé«˜å¤§æ¦‚ 5%ã€‚\né€™è£¡åˆ—å¹¾å€‹ä½œè€…ç”¨çš„ prompt template: \u0026ldquo;a bad photo of a {}.\u0026rdquo; \u0026ldquo;a photo of many {}.\u0026rdquo; \u0026ldquo;a sculpture of a {}.\u0026rdquo; \u0026ldquo;a photo of the hard to see {}.\u0026rdquo; Analysis of Zero-Shot CLIP Performance å°æ–¼ä¸€èˆ¬çš„ç‰©é«”åˆ†é¡çš„è³‡æ–™é›†ï¼ŒCLIP è¡¨ç¾è¼ƒå¥½ã€‚\nä¸‹é¢æœ‰äº›è¤‡é›œã€å°ˆé–€ã€æŠ½è±¡çš„ä»»å‹™ï¼ŒCLIP å‰‡è¡¨ç¾çš„å¾ˆå·®ï¼Œæ¯”å¦‚è¨ˆç®—å ´æ™¯ä¸­æœ‰å¤šå°‘ç‰©é«”çš„ ï¼ˆCLEVRCountsï¼‰ã€è¡›æ˜Ÿåœ–åƒåˆ†é¡ï¼ˆEuroSATï¼‰æˆ–æ˜¯ è­˜åˆ¥æœ€è¿‘çš„æ±½è»Šè·é›¢ï¼ˆKITTI Distanceï¼‰\nå°æ–¼é€™ç¨®ç‰¹åˆ¥é›£çš„ä»»å‹™ï¼Œè®“ CLIP åš zero-shot ä¸å¤ªåˆç†ã€‚ å¯èƒ½ç”¨ few-shot çš„æ–¹å¼æœƒæ¯”è¼ƒå¥½ã€‚\nBiT æ˜¯ google ç‚º Transfer Learning è¨­è¨ˆçš„é è¨“ç·´æ¨¡å‹ï¼Œåœ¨åˆ†é¡å•é¡Œï¼ŒFew-shot learning ä¸Šæœ‰è‰¯å¥½çš„è¡¨ç¾ã€‚\nRepresentation Learning é€™ç¯€æ¢è¨å®Œå…¨ä½¿ç”¨ä¸‹æ¸¸ä»»å‹™è³‡æ–™é›†è€Œé Zero-shot æˆ– few-shot çš„æƒ…æ³ã€‚\nä½œè€…é¸ç”¨ linear-probe è€Œä¸æ˜¯ finetune ä¾†åšä¸‹æ¸¸ä»»å‹™çš„è©•ä¼°ã€‚\nå› ç‚ºä»–å€‘çš„é‡é»æ˜¯é–‹ç™¼èˆ‡è³‡æ–™é›†ç„¡é—œçš„é è¨“ç·´æ–¹æ³•ï¼Œfinetune æœ‰å¯èƒ½è®“ä¸€å€‹é è¨“ç·´å­¸ç¿’ representation å¤±æ•—çš„æ¨¡å‹åœ¨å¾®èª¿éç¨‹ä¸­è®Šå¥½ã€‚ è€Œ linear-probe çš„é™åˆ¶å¯ä»¥å‡¸é¡¯é€™äº›å¤±æ•—ã€‚\nComparison to Human Performance å†ä¾†æ˜¯ CLIP å’Œäººé¡ç›¸æ¯”çš„çµæœã€‚ æŒ‘é¸äº†äº”å€‹äººåœ¨å¯µç‰©è³‡æ–™é›†ä¸Šæ¯”è¼ƒçš„çµæœã€‚\nData Overlap Analysis å¯èƒ½æœƒæœ‰äººè³ªç–‘ï¼ŒCLIP çš„è¡¨ç¾æ˜¯å› ç‚ºè¨“ç·´è³‡æ–™é›†å’Œæ¸¬è©¦è³‡æ–™é›†æœ‰é‡ç–Šã€‚ ä½†ä½œè€…åšäº†ä¸€äº›å¯¦é©—ï¼Œæœ‰äº›è³‡æ–™é›†å®Œå…¨æ²’æœ‰åµæ¸¬åˆ°é‡ç–Šã€‚ å°æœ‰é‡ç–Šçš„åšå¯¦é©—ï¼Œç™¼ç¾æœ‰é‡ç–Šçš„å°æ•ˆæœæå‡å½±éŸ¿å¾ˆå°ã€‚\nLimitations CLIP é›–ç„¶å¯ä»¥å’Œä½œç‚º Baseline çš„ ResNet-50 æ‰“å¹³æ‰‹ï¼Œä½†ç¾åœ¨çš„ SOTA é é«˜æ–¼è©² Baselineã€‚\nä½œè€…ç™¼ç¾å†ç¹¼çºŒåŠ å¤§æ¨¡å‹å’Œè³‡æ–™æ˜¯å¯ä»¥ç¹¼çºŒæå‡æ€§èƒ½çš„ï¼Œä½†ä½œè€…ä¼°è¨ˆè¦é”åˆ°ç¾æœ‰çš„ SOTA éœ€è¦å¢åŠ å¤§æ¦‚ 1000 å€çš„è¨ˆç®—é‡æ‰èƒ½é”åˆ°ï¼Œä½¿ç”¨ç¾æœ‰çš„ç¡¬é«”æ˜¯ä¸å¯è¡Œçš„ã€‚\nCLIP å°ç´°åˆ†é¡ã€æŠ½è±¡æˆ–æ›´é›£çš„ä»»å‹™è¡¨ç¾ä¸å¥½ï¼Œä½œè€…ç›¸ä¿¡é‚„æœ‰è¨±å¤šä»»å‹™æ˜¯ CLIP ç”¨ zero-shot åªèƒ½é”åˆ°äº‚çŒœç­‰ç´šçš„ã€‚\nZero-Shot çš„ CLIP å¾ˆé›£æ³›åŒ–åˆ° out-of-distribution çš„è³‡æ–™ï¼Œæ¯”å¦‚åœ¨ MNIST ä¸Šåªèƒ½é”åˆ° 88% çš„æº–ç¢ºåº¦ã€‚ ä½œè€…ç™¼ç¾é è¨“ç·´è³‡æ–™å¹¾ä¹æ²’æœ‰é¡ä¼¼ MNIST çš„åœ–ç‰‡ã€‚\nç›¡ç®¡ CLIP å¯ä»¥éˆæ´»æ‡‰ç”¨å„ç¨® Zero-Shot çš„åˆ†é¡ï¼Œä½†åŸºæœ¬ä¸Šé‚„æ˜¯å¾ä½ çµ¦å®šçš„åˆ†é¡é¸æ“‡ã€‚ å’ŒçœŸæ­£éˆæ´»çš„æ–¹æ³•ï¼ˆç”Ÿæˆ image captionï¼‰ç›¸æ¯”ï¼Œæ˜¯é‡å¤§çš„é™åˆ¶ã€‚\nä¸€å€‹å€¼å¾—å˜—è©¦çš„ç°¡å–®æƒ³æ³•æ˜¯æŠŠ contrastive objective å’Œ generative objectiveï¼Œçµåˆã€‚\nCLIP ä¹Ÿæ²’æœ‰è§£æ±ºæ·±åº¦å­¸ç¿’è³‡æ–™æ•ˆç‡ä½ä¸‹çš„å•é¡Œï¼ŒCLIP è¨“ç·´äº† 32 å€‹ epochï¼Œå¦‚æœæŠŠé è¨“ç·´æœŸé–“çš„ç…§ç‰‡ä»¥ä¸€ç§’ä¸€å¼µä¾†å‘ˆç¾ï¼Œéœ€è¦ 405 å¹´ã€‚ æŠŠ CLIP å’Œ self-supervision æˆ–è€…å’Œ self-training åšçµåˆæ˜¯æœ‰å‰é€”çš„æ–¹å‘ã€‚\né›–ç„¶ä½œè€…å¼·èª¿ Zero-Shot Learningï¼Œä½†æ˜¯ä½œè€…é‚„æ˜¯æœ‰åè¦†æª¢æŸ¥ä¸‹æ¸¸ä»»å‹™æ¸¬è©¦é›†çš„è¡¨ç¾ï¼Œä¾†èª¿æ•´ CLIPã€‚ æ¯æ¬¡éƒ½ç”¨ ImageNet ä¾†ç¢ºèªï¼Œä¸¦ä¸ç®—çœŸæ­£çš„ zero-shot çš„æƒ…æ³ã€‚ å¦‚æœèƒ½å†å‰µä¸€å€‹æ–°çš„è³‡æ–™é›†ï¼Œå°ˆé–€ç”¨ä¾†è©•ä¼° zero-shot é·ç§»çš„èƒ½åŠ›æœƒæ›´æ°ç•¶ã€‚\nçˆ¬ä¸‹ä¾†çš„è³‡æ–™æœ‰å¯èƒ½å¸¶æœ‰ç¤¾æœƒåè¦‹ã€‚\næœ‰ä¸€äº›è¤‡é›œçš„ä»»å‹™å¾ˆé›£ç”¨æ–‡å­—ä¾†å‚³é”ï¼Œé›–ç„¶å¯¦éš›çš„è¨“ç·´æ¨£æœ¬æœ‰ç”¨ï¼Œä½† CLIP ä¸¦ä¸æœƒé‡å° few-shot æœ€ä½³åŒ–ã€‚æœ‰å€‹é•åç›´è¦ºçš„çµæœï¼Œå¯ä»¥æ³¨æ„åˆ°åœ¨æŸäº›æƒ…æ³ä¸‹ï¼Œfew-shot ä¸è¦‹å¾—æ¯” zero-shot å¥½ã€‚\né¡å¤–æ‡‰ç”¨ åœ–ç‰‡ç”Ÿæˆ StyleCLIP: Text-Driven Manipulation of StyleGAN Imagery ç”¨æ–‡å­—å¼•å°ç”Ÿæˆåœ–ç‰‡ CLIPDraw: Exploring Text-to-Drawing Synthesis through Language-Image Encoders ç‰©ä»¶åµæ¸¬ Open-Vocabulary Object Detection via Vision and Language Knowledge Distillation å°‡åŸºç¤é¡åˆ¥å†åšç´°åˆ†é¡ OCR Contrastive Language-Image Forensic Search æœç´¢å½±ç‰‡ä¸­æœ‰æ²’æœ‰æ–‡æœ¬æè¿°çš„ç‰©é«” ç­†è¨˜ prompt engineering prompt ensemble\n","date":"2023-11-21T01:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/clip-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"CLIP è«–æ–‡é–±è®€"},{"content":"paper: PonderNet: Learning to Ponder\nAbstract CNN åœ¨ CV é ˜åŸŸæ˜¯é¦–é¸ï¼Œä½†åŸºæ–¼ attention çš„ç¶²è·¯ä¹Ÿåœ¨è®Šæµè¡Œã€‚\næœ¬æ–‡è­‰æ˜é›–ç„¶ convolution å’Œ attention éƒ½å¯ä»¥ç²å¾—è‰¯å¥½çš„ performanceï¼Œä½†çš†éå¿…é ˆã€‚\næœ¬æ–‡æå‡ºäº† MLP-Mixerï¼Œä¸€ç¨®ç´” MLP çš„æ¶æ§‹ï¼ŒåŒ…å«å…©ç¨® layerï¼š\nå°‡ MLP ç¨ç«‹ç”¨åœ¨ patch mixing per-location features å°‡ MLP ç”¨åœ¨ patches ä¹‹é–“ã€‚ mixing spatial information Introduction æœ¬æ–‡æå‡ºäº†å®Œå…¨åŸºæ–¼ MLP çš„ MLP-Mixer ( åˆç°¡ç¨± Mixer )ï¼Œæœ‰ç«¶çˆ­åŠ›å»æ¦‚å¿µå’ŒæŠ€è¡“ä¸Šéƒ½å¾ˆç°¡å–®ã€‚\næœ‰å…©ç¨® MLP layerï¼š\nChannel-Mixing MLP\nç”¨åœ¨æ¯å€‹ patch ä¸Š è®“ä¸åŒ channel ä¹‹é–“çš„è³‡è¨Šäº’ç›¸äº¤æ› Token-Mixing MLP\nç”¨åœ¨æ‰€æœ‰ patch ä¸Š è®“ç©ºé–“è³‡è¨Šäº’ç›¸äº¤æ› é€™å…©è€…äº¤éŒ¯å‡ºç¾ï¼Œè®“å…©å€‹è¼¸å…¥ç¶­åº¦å¯ä»¥äº¤äº’ä½œç”¨\nåœ¨æ¥µç«¯æƒ…æ³ä¸‹ï¼Œæœ¬æ–‡çš„æ¶æ§‹å¯ä»¥çœ‹åšæ˜¯ä¸€å€‹éå¸¸ç‰¹æ®Šçš„ CNNï¼Œä½¿ç”¨ 1*1 å·ç©åš channel mixingï¼Œä¸¦ç”¨ single-channel ä¸” full receptive field çš„ 1D å·ç©åš token mixingã€‚\nåä¹‹å‰‡ä¸ç„¶ï¼Œå› ç‚ºç¶“å…¸çš„ CNN ä¸¦ä¸æ˜¯ Mixer çš„ç‰¹ä¾‹ã€‚\nç›¡ç®¡å¾ˆç°¡å–®ï¼Œä½† Mixer å»å–å¾—æœ‰ç«¶çˆ­åŠ›çš„çµæœã€‚\nç„¶è€Œèˆ‡ ViT ä¸€æ¨£ï¼Œåœ¨ä¸€åˆ‡ç‰¹æœ‰çš„ CNN æ¶æ§‹ä¸‹ç•¥æœ‰æ¬ ç¼ºã€‚\nMixer Architecture Mixer çš„æ ¸å¿ƒæ¦‚å¿µæ˜¯æƒ³æŠŠ\nmix features at a given spatial location mix features between different spatial locations çµ¦åˆ†é–‹ä¾†\næ‰€æœ‰çš„ patch éƒ½æ˜¯ç”¨åŒä¸€å€‹ projection matrix\næ³¨æ„ fig1 çš„ MLP2ï¼Œä»–å€‘å…±äº«åŒæ¨£çš„åƒæ•¸ï¼Œé€™æ¨£ç¶å®šåƒæ•¸å¯ä»¥é é˜² C å’Œ S å¢åŠ æ™‚ä½¿æ¶æ§‹å¢é•·éå¿«ã€‚åœ¨ seperable convolution ä¸­ï¼Œä¸åŒé€šé“ä½¿ç”¨ä¸åŒçš„ kernelã€‚ä¸éä½œè€…é€™æ¨£çš„é¸æ“‡ä¸¦ä¸å½±éŸ¿å¯¦éš›çš„ performanceã€‚\nMixer çš„æ‰€æœ‰ Layer éƒ½å…·å‚™ç›¸åŒçš„è¼¸å…¥å¤§å°ã€‚\né€™ç¨®ã€Œisotropicã€çš„è¨­è¨ˆå’Œ Transformer æˆ– RNN æ¯”è¼ƒåƒã€‚\nèˆ‡å¤§å¤šæ•¸å…·æœ‰ pyramidal structure çš„ CNN ä¸åŒï¼Œå®ƒå€‘åœ¨æ›´æ·±çš„å±¤æœ‰æ›´ä½çš„ resolutionï¼Œä½†æœ‰æ›´å¤š channelã€‚\nä¸éä¸Šé¢åªæ˜¯æ¢è¨å…¸å‹çš„è¨­è¨ˆï¼Œä¹Ÿå­˜åœ¨ä¾‹å¤–ï¼Œæ¯”å¦‚ isotropic Resnet æˆ– pyramidal ViTã€‚\né™¤äº† MLPï¼ŒMixer é‚„æœ‰ç”¨åˆ° LayerNorm å’Œ skip connectionã€‚\nä½†æ˜¯ Mixer æ²’æœ‰ç”¨åˆ° positional encodingï¼Œå› ç‚º token-mixing MLP æœ¬èº«å°±å°ä½ç½®æ•æ„Ÿã€‚\\\nExperiments Mixer ç”¨ä¸­å¤§å‹è³‡æ–™é›†é è¨“ç·´ï¼Œç„¶å¾Œåœ¨ä¸€ç³»åˆ—ä¸­å°è³‡æ–™é›†ä¸Šè©•ä¼°ã€‚\nç›®æ¨™ä¸æ˜¯æ‹¿åˆ° SOTAï¼Œè€Œæ˜¯é¡¯ç¤ºå‡ºèˆ‡ SOTA çš„ CNN å’Œ attention-based model ç›¸æ¯”ï¼ŒMixer æœ‰ç«¶çˆ­åŠ›ã€‚\nFine-tuning åœ¨ fine-tuning æ™‚ï¼Œç”¨æ¯”é è¨“ç·´æ™‚é‚„è¦é«˜çš„ resolutionã€‚ ç”±æ–¼æ¯å€‹ patch çš„ resolution æ˜¯å›ºå®šçš„ï¼Œé€™æ¨£æœƒå°è‡´æœ‰æ›´å¤šçš„ patchesã€‚\nå°æ–¼é€™å€‹å•é¡Œï¼Œæ¡ç”¨ä»¥ä¸‹è§£æ³•ï¼š\næˆ‘å€‘åŸå…ˆé è¨ˆåƒ S å€‹ patchï¼Œç¾åœ¨æˆ‘å€‘ç”±æ–¼è¼¸å…¥è§£æåº¦æ›´é«˜ï¼Œè€Œä¸” patch å¤§å°ä¸è®Šï¼Œæ‰€ä»¥æˆ‘å€‘å¾—åˆ°ä¸€å€‹æ¯” S é‚„å¤§çš„ $S\u0026rsquo;$ã€‚ æ‰€ä»¥æˆ‘å€‘åœ¨å¾ˆå¤šåœ°æ–¹å°±éœ€è¦æ¯”åŸå…ˆæ¬Šé‡çŸ©é™£ W é‚„æ›´å¤§çš„ $W'$\næˆ‘å€‘è¦æŠŠ $S\u0026rsquo;$ æ‹†æˆ $K^2$ å€‹é•·åº¦ç‚º $S$ çš„ sequenceï¼ŒK æ˜¯æ•´æ•¸ã€‚\nä¸¦ä¸”æˆ‘å€‘æŠŠ $W\u0026rsquo;$ çš„ shape æ”¹æˆ $(W.shape[0] * K^2, W.shape[1] * K^2)$\nç„¶å¾Œæˆ‘å€‘æŠŠ $W\u0026rsquo;$ ä½œç‚º block-diagonal matrix ä¾†åˆå§‹åŒ–ï¼ŒæŠŠ $W$ copy å¥½å¹¾ä»½ï¼Œæ”¾åœ¨ main diagonal ä¸Šã€‚\næ‰€æœ‰æ¬Šé‡éƒ½ç”¨é¡ä¼¼çš„è™•ç†æ–¹æ³•ã€‚\n","date":"2023-10-30T00:27:55+08:00","permalink":"https://roykesydon.github.io/Blog/p/mlp-mixer-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"MLP-Mixer è«–æ–‡é–±è®€"},{"content":"å¤§è‡´æ¦‚å¿µ å±¬æ–¼ç”Ÿæˆå¼ AIï¼Œä¸€é–‹å§‹ç”¨åœ¨ç”Ÿæˆåœ–ç‰‡ï¼Œå¾Œä¾†ä¹Ÿæœ‰æ‡‰ç”¨åˆ°è«¸å¦‚ NLP ç­‰é ˜åŸŸã€‚\nä¸‹æ–‡ç¨±å‘¼åŸåœ–ç‚º spriteã€‚\nèˆ‡ AutoEncoder æœ‰é»é¡ä¼¼ï¼Œå…ˆå–å¾—ä¸€å¼µ spriteï¼Œéš¨è‘—æ™‚é–“æ¨é€²ï¼Œæ¯æ¬¡éƒ½åœ¨åœ–ç‰‡ä¸ŠåŠ ä¸€å±¤é›œè¨Šï¼Œåè¦†ç–ŠåŠ ï¼Œè¿­ä»£å¤šæ¬¡å¾Œï¼Œå°±æœƒå¾—åˆ°ä¸€å¼µé›£ä»¥çœ‹å‡ºåŸåœ–çš„é›œè¨Šã€‚\nå¾ sprite åˆ°åªèƒ½çœ‹å‡ºæ˜¯ä¸€åœ˜é›œè¨Šä¸¦éæ˜¯ä¸€æ­¥åˆ°ä½çš„éç¨‹ã€‚ä¸€é–‹å§‹æ²’æœ‰é›œè¨Šæ™‚å¯ä»¥çœ‹å‡ºåŸæœ¬çš„ spriteï¼Œä¸€å€‹è¿­ä»£å¾Œå¯èƒ½å¯ä»¥å‹‰å¼·çœ‹å‡ºåŸæœ¬çš„ spriteï¼Œå†å¹¾å€‹è¿­ä»£å¾Œå¯èƒ½ä¹Ÿé‚„èƒ½çœ‹å‡ºåŸæœ¬çš„ outlineï¼Œç¶“éè¨±å¤šæ¬¡å¾Œæ‰æœƒè®Šæˆå®Œå…¨è¾¨è­˜ä¸äº†çš„é›œè¨Šã€‚\næˆ‘å€‘æœŸæœ›æ¨¡å‹åšçš„äº‹æƒ…å‰‡æ˜¯å¾ gaussian noise é€æ­¥æ¨å› spriteï¼ŒåŒæ¨£ä¸æ˜¯ä¸€æ­¥åˆ°ä½ï¼Œè€Œæ˜¯è®“æ¨¡å‹é æ¸¬ä¸Šä¸€å€‹æ™‚é–“é»çš„é›œè¨Šï¼Œç›¸æ¸›å¾Œå†é€æ­¥æ¨å› spriteï¼Œé€™éç¨‹ç¨±ç‚º denoiseã€‚\nDDPM å¯¦ç¾ Diffusion å¯èƒ½æœƒæœ‰é» confusingï¼Œå› ç‚ºä»–å¯¦ä½œä¸Šå’Œä¸Šé¢èªªçš„ä¸å¤ªç›¸åŒã€‚ åœ¨è¨“ç·´çš„æ™‚å€™ï¼Œæˆ‘å€‘æœƒæ¡æ¨£ä¸‰å€‹æ±è¥¿ï¼š\nè¨“ç·´åœ–ç‰‡ (sprite) é›œè¨Š æ™‚é–“é» (t) è¨“ç·´éšæ®µçš„æ™‚å€™ï¼Œæˆ‘å€‘æœƒæŠŠã€ŒåŸå§‹ä¹¾æ·¨çš„åœ–ç‰‡ã€å’Œã€Œé›œè¨Šã€æ ¹æ“šæ™‚é–“é€²è¡Œä¸åŒæ¯”ä¾‹çš„ç›¸åŠ  (æ··åˆ)ï¼Œt è¶Šå¤§ï¼Œé›œè¨Šçš„æ¯”ä¾‹è¶Šå¤§ã€‚\næ¨¡å‹é æ¸¬çš„ç›®æ¨™æ˜¯å‰é¢ sample å‡ºçš„é›œè¨Šã€‚\né€™èˆ‡å‰é¢èªªçš„æ¦‚å¿µç›¸æ‚–ã€‚æŒ‰ç…§å‰é¢çš„èªªæ³•ï¼Œå°æ–¼æ™‚é–“é» tï¼Œæ‡‰è©²æ˜¯ä»¥ä¸€å¼µåŠ äº† t-1 æ¬¡é›œè¨Šçš„ sprite ä½œç‚ºè¼¸å…¥ï¼Œå†åŠ ä¸Š t æ‰€ sample å‡ºçš„é›œè¨Šã€‚\nç¾åœ¨å¯¦ä½œå»æ˜¯åŸå§‹ä¹¾æ·¨çš„ sprite ç›´æ¥æ ¹æ“šæ™‚é–“é»æ··å’ŒæŸå€‹é›œè¨Šã€‚\né€™èƒŒå¾Œçš„æ•¸å­¸æ¨å°ååˆ†å†—é•·ï¼Œé€™è£¡ä¸æ•˜è¿°ï¼Œä½†éœ€çŸ¥é“å¯¦ä½œå·®ç•°ã€‚\nInference åœ¨æ¨è«–éšæ®µçš„æ™‚å€™ï¼Œæ¯æ¬¡ denoise å¾Œéœ€è¦æŠŠåœ–ç‰‡å’Œé¡å¤– sample çš„ noise ç›¸åŠ ã€‚é€™å€‹ noise å’Œå‰é¢çš„ noise ä¸€æ¨£ï¼Œéƒ½æ˜¯å¾ mean=0, std=1 çš„ gaussian distribution ä¸­ sample å‡ºä¾†çš„ã€‚\nä¸åŠ çš„è©±ä¼¼ä¹é‚„å®¹æ˜“æœ‰ Mode Collapse çš„ç¾è±¡ã€‚ çœ‹åˆ°ä¸€å€‹èªªæ³•æ˜¯ï¼Œæ¨¡å‹å–œæ­¡åƒåœ–ç‰‡åŠ ä¸Šé›œè¨Šçš„åœ–åƒä½œç‚ºåœ–ç‰‡ï¼Œåœ¨åœ–ç‰‡ä¸ŠåŠ ä¸Š noise ä¼¼ä¹æœƒæ›´ç¬¦åˆæ¨¡å‹é æœŸçš„è¼¸å…¥ã€‚\nçœ‹äº†æå¼˜æ¯…çš„å½±ç‰‡ï¼Œä¹Ÿæœ‰åŸºæ–¼éš¨æ©Ÿæ€§çš„è§€é»ã€‚\nç”Ÿæˆå¼ Model ç”Ÿæˆæ–‡ç« æ™‚æ°¸é å–æ©Ÿç‡æœ€å¤§çš„ï¼Œä¸è¦‹å¾—æœ‰æ›´å¥½çš„æ•ˆæœï¼š\næœ‰ç ”ç©¶æ˜¯è®“ Model é¸æ©Ÿç‡æœ€å¤§çš„ï¼Œçµæœå®¹æ˜“ç”Ÿå‡ºåè¦†è·³é‡çš„æ–‡ç« ã€‚\nä¹Ÿæœ‰æŠŠäººé¡å¯«çš„æ–‡ç« å»é¤µçµ¦ Model çœ‹ï¼Œå¾ä»–çš„è§’åº¦çœ‹äººé¡å¯«çš„ä¸‹ä¸€å€‹å­—çš„æ©Ÿç‡æ˜¯å¤šå°‘ï¼Œç™¼ç¾äººé¡å¯«çš„æ–‡ç« å¾ˆå¸¸å‡ºç¾ä¸€ä¸‹æ©Ÿç‡é«˜ä¸€ä¸‹æ©Ÿç‡ä½çš„å­—ã€‚\næŸç¯‡èªéŸ³åˆæˆçš„æ–‡ç« éœ€è¦åœ¨æ¨è«–éšæ®µã€Œå•Ÿç”¨ã€dropout æ‰å¯ä»¥æœ‰å¥½çš„çµæœã€‚\nDiffusion ä¹Ÿæœ‰å¯èƒ½æˆåŠŸçš„é»æ˜¯åœ¨æ–¼ä¸¦éã€Œä¸€æ¬¡åˆ°ä½ã€è€Œæ˜¯ã€ŒN æ¬¡åˆ°ä½ã€ã€‚ å¾é€™æ¨£çš„è§’åº¦çœ‹ï¼ŒDiffusion æ˜¯ autoregressive æ¨¡å‹ã€‚\né¡ä¼¼çš„ä½œæ³•ä¹Ÿæœ‰ Mask-Predictï¼Œå¤§è‡´æ¦‚å¿µæ˜¯å¾åŸæœ¬éƒ½æ˜¯ Mask çš„æƒ…å¢ƒé–‹å§‹ï¼Œå°‡ä¸€äº›ä¿¡å¿ƒé«˜çš„é æ¸¬ç•™ä½ï¼Œä¿¡å¿ƒä½çš„ä¿æŒç‚º Maskï¼Œä¸€æ­¥æ­¥é æ¸¬å‡ºæ‰€æœ‰è³‡è¨Šã€‚\n","date":"2023-10-23T00:27:55+08:00","permalink":"https://roykesydon.github.io/Blog/p/diffusion-%E5%85%A5%E9%96%80/","title":"Diffusion å…¥é–€"},{"content":"Creational patterns é—œæ–¼ object creation çš„ patternsã€‚\nFactory Method å°‡ä¸åŒ Product å®šç¾©ä¸€å€‹å…±æœ‰çš„ Interfaceï¼Œä¸¦ç”±å­é¡åˆ¥å¯¦ä½œï¼Œé€éå·¥å» é¡åˆ¥ä¾†ç”¢ç”Ÿå¯¦é«”ã€‚\nå°‡å»ºç«‹ Product çš„æ–¹æ³•ç¨ç«‹å‡ºä¾†ï¼Œç¬¦åˆ Single Responsibility Principleã€‚ å¯ä»¥è¼•æ˜“æ“´å……æ–°çš„ Productï¼Œè€Œä¸ç”¨ä¿®æ”¹åŸæœ¬çš„ç¨‹å¼ç¢¼ï¼Œç¬¦åˆ Open-Closed Principleã€‚\nAbstract Factory ç›¸æ¯” Factory Methodï¼Œç¾åœ¨çš„æƒ…å¢ƒæ˜¯æœ‰å¤šå€‹ Productï¼Œè€Œä¸”æ¯æ¬¡éƒ½æ˜¯ä½¿ç”¨åŒä¸€ç³»åˆ—çš„ Productã€‚\nBuilder å°æ–¼å»ºæ§‹ä¸€å€‹è¤‡é›œä¸”å…·å‚™å¤šç¨®çµ„åˆçš„ç”¢å“ï¼Œå¯ä»¥é€éå»ºæ§‹å·¨å¤§çš„å»ºæ§‹å‡½å¼æˆ–æ˜¯è¦†è“‹æ‰€æœ‰å¯èƒ½çš„å­é¡åˆ¥ä¾†è§£æ±ºã€‚\nä½†éƒ½å­˜åœ¨å…¶å•é¡Œï¼Œè¦ä¸æ˜¯å¤§é‡çš„å­é¡åˆ¥ï¼Œä¸ç„¶å°±æ˜¯é›£ä»¥å‘¼å«çš„å»ºæ§‹å‡½å¼ã€‚\næŠŠå»ºç«‹ç‰©ä»¶çš„æ¯å€‹ component ç¨ç«‹å‡ºä¾†ï¼Œä¸¦ä¸”åˆ‡æˆå¤šå€‹å¯åˆ†é–‹åŸ·è¡Œçš„ stepã€‚\nç”± Builder ä¾†è² è²¬ç”Ÿå‡ºæ¯ä¸€å€‹ componentï¼ŒDirector ä¸æ˜¯å¿…éœ€çš„ï¼Œä½†æœ‰éœ€è¦çš„è©±å¯ä»¥è®“ä»–å¹«å¿™èª¿ç”¨ Builder çš„ methodï¼Œå¥½åœ¨å°ˆæ¡ˆä¸­é‡è¤‡ä½¿ç”¨ã€‚\nPrototype ä½¿ç”¨åœ¨æƒ³è¦ç²å¾—æŸå€‹å°è±¡çš„ clone çš„æƒ…å¢ƒã€‚\næŠŠ clone çš„è²¬ä»»äº¤çµ¦å°è±¡æœ¬èº«ï¼Œè€Œä¸æ˜¯äº¤çµ¦ Clientã€‚ç”±å°è±¡æœ¬èº«æä¾› clone methodã€‚\nSingleton ç¢ºä¿æŸå€‹é¡åˆ¥åªæœ‰ä¸€å€‹ instanceï¼Œä¸¦ä¸”æä¾›ä¸€å€‹ global access pointã€‚\nä½†æ˜¯é€™æ¨£é•åäº† Single Responsibility Principleï¼Œå› ç‚ºé™¤äº†åŸæœ¬çš„åŠŸèƒ½å¤–ï¼Œé‚„è¦è² è²¬ç®¡ç†è‡ªå·±çš„ instanceã€‚\nStructural patterns æ¢è¨å¦‚ä½•çµ„è£é¡åˆ¥å’Œç‰©ä»¶æˆç‚ºæ›´å¤§çš„çµæ§‹ã€‚\nAdapter è½‰æ›æŸå€‹å°è±¡çš„ interface åˆ°å¦å¤–ä¸€ç¨® interfaceï¼Œè®“å¦å¤–ä¸€å€‹ Object å¯ä»¥ç†è§£ä»–ã€‚ å°±åƒ XML è¦è½‰åˆ° JSONã€‚\nBrdige ä½¿ç”¨åœ¨éœ€è¦åœ¨å¤šå€‹ orthogonal (independent) çš„ç¶­åº¦ä¸Šæ“´å±•é¡åˆ¥æ™‚çš„æƒ…å¢ƒã€‚ è®“æƒ…æ³å¾é›£ä»¥è¨ˆæ•¸çš„å­é¡åˆ¥æ•¸ï¼Œè®Šæˆå¤šçµ„åŠŸèƒ½è¯åˆèµ·ä¾†ã€‚\næ‹†æˆ abstraction (high-level control) å’Œ implementation (å¯¦éš›å·¥ä½œ)ï¼Œ ç”± abstraction ä¾†æ§åˆ¶ implementationï¼Œæ¯”å¦‚ GUI ä¾†æ§åˆ¶åº•ä¸‹çš„ API\nComposite ç”¨åœ¨æŸäº›å±¤ç´šçµæ§‹ã€‚\nå°æ–¼ Composite (Container)ï¼Œä¸ä½†å¯¦ç¾ Componentï¼Œä¹Ÿæä¾›ä¸€å€‹ list ä¾†å­˜æ”¾å­ componentã€‚\nå° Composite çš„æ“ä½œï¼Œæœƒè¢«å§”è¨—çµ¦å­ componentï¼Œä¸éœ€è¦ client æ“”å¿ƒã€‚\nå°±åƒæŒ‡æ®å®˜åªéœ€è¦å°é«˜éšè»å®˜ä¸‹å‘½ä»¤ã€‚\nDecorator ç•¶ä»Šå¤©æœ‰å¤šç¨®åŒé¡å‹çš„æ±è¥¿ï¼Œä½ å¯ä»¥èƒ½æœƒåŒæ™‚ç”¨åˆ°å¤šç¨®å­é¡åˆ¥æ‰€å½¢æˆçš„çµ„åˆæ™‚ï¼Œå°±å¯ä»¥ç”¨ Decoratorã€‚\næ¯”å¦‚å¤šç¨®é¡å‹çš„ notificationï¼Œä½ å¯èƒ½åŒæ™‚æƒ³è¦ FB å’Œ TG çš„ï¼Œæˆ–æ˜¯åªæƒ³è¦å…¶ä¸­ä¸€å€‹ã€‚ æˆ–æ˜¯å¤šä»¶è¡£æœï¼Œæœ‰è¶…ç´šå¤šç¨®çš„ç©¿æ­ã€‚\nä½†é€™æ˜¯ä¸€å±¤å±¤çš„æ„Ÿè¦ºï¼Œå…·æœ‰é †åºæ€§ã€‚ Decorator å’Œ Component éƒ½ç¹¼æ‰¿åŒä¸€å€‹ interfaceã€‚ å°±åƒæ˜¯ Data data = new Encrypt(new Compress(new FileData()))ã€‚\nå­˜åœ¨å¾ˆé›£å¾ stack ä¸­åˆªé™¤ç‰¹å®š decorator çš„ç¼ºé»ã€‚\nFacade ç‚ºè¤‡é›œçš„ä¸€å †å­ç³»çµ±æä¾›ä¸€å€‹ Classï¼Œè®“ client å¯ä»¥ä½¿ç”¨ä»–å€‘é—œå¿ƒçš„åŠŸèƒ½ã€‚ å¯¦éš›æ€éº¼èª¿ç”¨ client ç„¡é ˆçŸ¥é“ã€‚\nå®¹æ˜“å½¢æˆ god objectã€‚\nFlyweight å°æ–¼å¤§é‡é¡ä¼¼çš„ç‰©ä»¶ï¼Œç‚ºæ±‚ç¯€çœè¨˜æ†¶é«”è€Œèª•ç”Ÿçš„ patternã€‚\næŠŠç‰©ä»¶çš„å…§å®¹åˆ†æˆ intrinsic å’Œ extrinsicï¼Œintrinsic æ˜¯ä¸æœƒæ”¹è®Šçš„ (unique)ï¼Œè€Œ extrinsic æ˜¯æœƒæ”¹è®Šçš„ (repeating)ã€‚\nè®“ extrinsic çš„æ±è¥¿ç”¨åŒä¸€å¡Šè¨˜æ†¶é«”ã€‚\nProxy ç”¨åœ¨å¤šå€‹æœå‹™æƒ³è¦èª¿ç”¨æŸå€‹é‡é‡ç´šè³‡æºçš„æƒ…å¢ƒä¸‹ã€‚\nå­˜åœ¨å¤šç¨® proxy çš„æ‡‰ç”¨é¡å‹ï¼Œæ¯”å¦‚ cache æ©Ÿåˆ¶ä¾†åŠ é€Ÿè³‡æºçš„å­˜å–ï¼Œä¸¦æ¸›å°‘ç³»çµ±è³‡æºæ¶ˆè€—ã€‚\nBehavioral patterns Chain of Responsibility å°æ–¼ä¸€ç³»åˆ—æª¢æŸ¥çš„æƒ…æ³ï¼Œå¯ä»¥ç”¨é€™ç¨®ä½œæ³•ï¼Œæœ‰å…©ç¨®å½¢å¼ï¼š\nä¸€è·¯æª¢æŸ¥ï¼Œæª¢æŸ¥å¤±æ•—å‰‡ä¸­æ–·è«‹æ±‚ã€‚ æ¯å€‹ Handler è‡ªè¡Œæ±ºå®šè¦ä¸è¦è™•ç†è©²è«‹æ±‚ï¼Œè¦çš„è©±å‰‡ä¸æœƒå¾€ä¸‹å‚³ã€‚ é€™æ¨£å¯èƒ½æœƒæœ€å¾Œæ²’äººè™•ç† å°±åƒç¶²é é»æ“Šäº‹ä»¶ï¼Œä¸€å±¤å±¤å…ƒç´ å¾€ä¸‹å•ã€‚\nCommand æŠŠè«‹æ±‚ç¨ç«‹å‡ºä¾†ï¼Œè®“è©²è«‹æ±‚å¯ä»¥è¢«ç”¨ä½œåƒæ•¸ã€ä½‡åˆ—ã€æ’¤éŠ·è¡Œç‚ºç­‰ã€‚\næ¯”å¦‚å¤šç¨®ä¸åŒçš„æŒ‰éˆ•èƒŒå¾Œéƒ½åŸ·è¡ŒåŒä¸€å€‹å­˜æª”åŠŸèƒ½ã€‚å­˜æª”å°±å¯ä»¥ä½œç‚º command ç¨ç«‹å‡ºä¾†ã€‚ èƒŒå¾Œå†æ ¹æ“šé€™å€‹ command å¯¦æ–½å°æ‡‰çš„æ¥­å‹™é‚è¼¯ã€‚\nIterator ç”¨ä¾†éœ€è¦éæ­·é›†åˆä¸­å…ƒç´ çš„æƒ…å¢ƒï¼ŒæŠŠä¸åŒç¨®é¡çš„éæ­·è¡Œç‚ºç´°ç¯€éš±è—èµ·ä¾†ã€‚\næä¾›å¤šç¨®ä¸åŒçš„ iteratorï¼Œä½†éµå¾ªåŒä¸€ç¨® interfaceï¼Œè®“ä½¿ç”¨è€…å¯ä»¥æ ¹æ“šéœ€è¦é¸æ“‡ iteratorã€‚ å°æ–¼ä¸é—œå¿ƒç”¨å“ªç¨® iterator çš„ä½¿ç”¨è€…ï¼Œä¹Ÿèƒ½å—ç›Šæ–¼ iterator çš„ interfaceï¼Œè€Œä¸å¿…è€¦åˆæ–¼ç‰¹å®šçš„æ¼”ç®—æ³•ã€‚\nMediator ç¦æ­¢å¤šå€‹ component é–“çš„ç›´æ¥æºé€šï¼Œè¿«ä½¿ä»–å€‘é€é mediator ä¾†æºé€šï¼Œé¿å…è¤‡é›œçš„é—œä¿‚ã€‚ æ‰€æœ‰äººåªèƒ½é€é notify mediator ä¾†æºé€šï¼Œmediator æ ¹æ“š sender å’Œ eventï¼Œä¾†åšå‡ºç›¸æ‡‰è™•ç†ã€‚\nMemento è®“ä½ å¯ä»¥å„²å­˜å’Œå¾©åŸåˆ°å…ˆå‰çš„ç‹€æ…‹ã€‚\nè®“è¦å„²å­˜çš„å°è±¡è‡ªå·±ç”Ÿæˆ snapshotã€‚\nå»ºè­°å­˜åœ¨åç‚º momento çš„ special objectï¼Œé€™å€‹ object ä¸èƒ½è®“é™¤äº† producer å¤–çš„å…¶ä»– object ç›´æ¥å­˜å–ã€‚ å…¶ä»– object åªèƒ½é€é limited interface ä¾†å–å¾— metadataã€‚\né€™äº›é™åˆ¶è®“ momento å¯ä»¥äº¤çµ¦å…¶ä»– object ä¾†ç®¡ç†ï¼Œç¨±ç‚º caretakerã€‚\nObserver å®šç¾© subscription æ©Ÿåˆ¶ã€‚\næœ‰ interesting state çš„ object ç¨±ç‚º subjectï¼Œä½†ç”±æ–¼ä»–ä¹Ÿæœƒé€šçŸ¥å…¶ä»–äººï¼Œæ‰€ä»¥åˆç¨±ç‚º publisherã€‚è¿½è¹¤å®ƒçš„äººç¨±ç‚º Subscriberã€‚\nState ç”¨åœ¨é¡ä¼¼ Finite-State Machine çš„æƒ…æ³ã€‚\nè©² pattern æŠŠæ¯å€‹ state ç¨ç«‹æˆä¸€å€‹ Classï¼ŒæŠŠå¯¦éš›çš„è¡Œç‚ºå§”è¨—çµ¦ stateï¼Œè€Œä¸æ˜¯ç”± context (åŸå§‹ç‰©ä»¶) ä¾†æ§åˆ¶ã€‚Context åªç®¡åˆ‡æ› stateã€‚\nStrategy æŠŠä¸åŒå¯¦ç¾æ–¹æ³•çš„æ¼”ç®—æ³•å®šç¾©ç‚ºéµå¾ªåŒä¸€å€‹ interface çš„é¡åˆ¥ï¼Œè®“ä½¿ç”¨è€…å¯ä»¥æ ¹æ“šéœ€è¦é¸æ“‡æ¼”ç®—æ³•ã€‚\nTemplate Method æŠŠæ¼”ç®—æ³•æ‹†æˆå¤šå€‹æ­¥é©Ÿï¼Œè®“å­é¡åˆ¥å¯ä»¥è¦†å¯«å…¶ä¸­çš„æ­¥é©Ÿï¼Œä½†ä¸æ”¹è®Šæ¼”ç®—æ³•çš„çµæ§‹ã€‚\nVisitor è®“æˆ‘å€‘å¯ä»¥æŠŠæ¼”ç®—æ³•å¾åŸ·è¡Œä»–å€‘çš„ object ä¸­åˆ†é›¢å‡ºä¾†ã€‚\nå‡è¨­æˆ‘å€‘è¦å°ä¸€å †ç¹¼æ‰¿ client å±¬æ€§çš„å…¬å¸æ–°å¢ sendEmail åŠŸèƒ½ï¼Œå¦‚æœæˆ‘å€‘åœ¨ client æ–°å¢ sendEmail ä¸¦ä¸” override æ¯å€‹å­ classï¼Œå°±æœƒé•å Single Responsibility Principle å’Œ Open-Closed Principleã€‚\nè¦åˆ©ç”¨ Double-Dispatchï¼Œè®“ Object æœ¬èº«é¸æ“‡è©²ç”¨çš„æ¼”ç®—æ³•ã€‚\né›–ç„¶é€™æ¨£ä¾ç„¶æœƒä¿®æ”¹åˆ°å­ classï¼Œä½†é€™å±¬æ–¼å¾®ä¸è¶³é“çš„æ”¹è®Šï¼Œè€Œä¸”å¯ä»¥è®“ä¹‹å¾Œæ–°å¢çš„ä¸€äº›åŠŸèƒ½ä¸ç”¨å†å»ä¿®æ”¹é€™äº›å­ classã€‚\n","date":"2023-10-10T00:00:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E8%A8%AD%E8%A8%88%E6%A8%A1%E5%BC%8F-desing-pattern/","title":"è¨­è¨ˆæ¨¡å¼ Desing Pattern"},{"content":"æé«˜æŸ¥æ‰¾ç›¸ä¼¼å‘é‡çš„é€Ÿåº¦ ä»»ä½•éæš´åŠ›æœå°‹çš„æœå°‹æ–¹æ³•ï¼Œéƒ½æœƒä¸€å®šç¨‹åº¦ä¸Šçš„é™ä½æœç´¢å“è³ªã€‚ éœ€è¦åœ¨æœç´¢å“è³ªå’Œé€Ÿåº¦é€²è¡Œ trade-offã€‚\nK-Means å¯ç”¨åœ¨å°‡å‘é‡è³‡æ–™åº«åˆ†ç¾¤ï¼Œä»¥ä¾¿ç¸®å°æŸ¥æ‰¾ç›¸ä¼¼å‘é‡çš„ç¯„åœã€‚\nè¿­ä»£è¨ˆç®—ç¾¤å¿ƒï¼Œç›´åˆ°æ”¶æ–‚\nä¾æ“šé›¢ç¾¤å¿ƒçš„é è¿‘åˆ†é¡\nå•é¡Œ ç›¸è¿‘çš„å‘é‡æœ‰å¯èƒ½è¢«åˆ†åˆ°ä¸åŒç¾¤\nå¯ä»¥é€éã€Œç”¨æ›´å¤šé¡ï¼Œä¸¦æœç´¢å¤šå€‹æœ€è¿‘ç¾¤ã€ä¾†ç·©è§£å•é¡Œ\nå¯ä»¥æ‰¾å…¶ä»– ANN (Approximate Nearest Neighbors) æ¼”ç®—æ³•ä¾†é¢å°è©²å•é¡Œ\nä½ç½®æ•æ„Ÿå“ˆå¸Œ (Locality Sensitive Hashing, LSH) è®“è¶Šç›¸ä¼¼çš„å‘é‡è¶Šå®¹æ˜“ç¢°æ’ï¼Œæ‰¾ç›¸ä¼¼å‘é‡å°±åœ¨åŒå€‹ bucket æ‰¾\nå¯¦ç¾æ–¹æ³• æ­¤è™•æŒ‘ä¸€ç¨®æ–¹å¼èˆ‰ä¾‹ï¼Œæ­¤è™•ç”¨éš¨æ©Ÿè¶…å¹³é¢èˆ‰ä¾‹ã€‚\nå¯ä»¥åœ¨ç©ºé–“ä¸­éš¨æ©Ÿç”Ÿæˆå¤šå€‹ (n-1) ç¶­åº¦çš„è¶…å¹³é¢ï¼Œå°‡å…©é‚Šåˆ†é¡ç‚º 0 å’Œ 1ã€‚ è·é›¢è¼ƒé çš„é»å°è¢«åˆ‡å‰²é–‹çš„æ©Ÿç‡æœƒæ¯”è·é›¢è¼ƒè¿‘çš„é»å°é‚„å¤§ã€‚ ç”¨é€™æ¨£çš„æ–¹æ³•ï¼Œæœƒè®“ç›¸è¿‘çš„é»å°ç”Ÿå‡ºçš„ Hash å€¼è¼ƒæ¥è¿‘ã€‚\nå•é¡Œ æ¥è¿‘çš„å‘é‡æœ‰å¯èƒ½å› ç‚ºæ©Ÿç‡å› ç´ è¢«åˆ†åˆ°ä¸åŒ bucket å°‡å‘é‡åˆ†æ®µï¼Œæ¯æ®µæœ‰åŒ¹é…åˆ°åŒå€‹ bucket å°±è¦–ä½œå€™é¸é … æ¸›å°‘æŸ¥æ‰¾ç›¸ä¼¼å‘é‡çš„è¨˜æ†¶é«”é–‹éŠ· å¤§é‡çš„é«˜ç¶­å‘é‡æœƒé€ æˆå¤§é‡çš„è¨˜æ†¶é«”é–‹éŠ·\nK-Means æŠŠåŒä¸€ç¾¤çš„å‘é‡éƒ½ç”¨ç¾¤å¿ƒå‘é‡ä»£æ›¿ï¼Œæ˜¯ä¸€ç¨®æœ‰æå£“ç¸®ã€‚\nå•é¡Œ ä½†é€™æ¨£éœ€è¦å¦å¤–çš„ç©ºé–“ä¾†å­˜å– codebook (å‘é‡å°æ‡‰è¡¨)ï¼Œåœ¨æŸäº›æƒ…æ³ä¸è¦‹å¾—æ¯”åŸæœ¬çš„å‘é‡é‚„çœç©ºé–“ï¼Œç”šè‡³å¯èƒ½èŠ±æ›´å¤šã€‚\nn ç¶­çš„å‘é‡å¯èƒ½éœ€è¦ $2^{\\frac{n}{2}}$ çš„ class æ‰å¯ä»¥è¼ƒå¥½çš„åˆ†é¡ (ä¾†æºæœªçŸ¥)\nå¯ä»¥é€éæŠŠé«˜ç¶­å‘é‡åˆ‡å‰²æˆå¤šå€‹ä½ç¶­å­å‘é‡å€‹åˆ¥è™•ç†å†åˆä½µä¾†ç·©è§£è©²å•é¡Œã€‚\nè©²æ–¹æ³•ç¨±ç‚º Product Quntization (PQ)\nå…¶ä»–åšæ³• NSW å…­åº¦åˆ†éš”ç†è«– (Six degrees of separation) å°æ–¼ä¸–ç•Œä¸Šå…©å€‹äº’ä¸ç›¸è­˜çš„äººï¼Œåªéœ€è¦å…­å€‹ä¸­é–“äººå°±å¯ä»¥å»ºç«‹èµ·é€£çµã€‚\nåšæ³• æˆ‘å€‘æƒ³æ‰¾å°æ–¼æŸå€‹ç›®æ¨™å‘é‡è€Œè¨€æœ€ç›¸ä¼¼çš„å‘é‡ã€‚\nå…ˆéš¨æ©Ÿæ‰¾ä¸€å€‹é»ï¼Œæ‰¾ä»–çš„ç›¸é„°ç¯€é»èª°å’Œç›®æ¨™å‘é‡æœ€ç›¸è¿‘ï¼Œä¸¦åè¦†æ­¤éç¨‹ï¼Œç›´åˆ°æ‰€æœ‰ç›¸é„°ç¯€é»éƒ½æ²’æœ‰è‡ªå·±é›¢ç›®æ¨™ç›¸è¿‘ã€‚\nå…­åº¦åˆ†éš”ç†è«–è®“æˆ‘å€‘æ¨æ¸¬é€™éç¨‹å¯èƒ½å¾ˆå¿«å°±æœƒçµæŸã€‚\nå»ºç«‹çµæ§‹ æˆ‘å€‘å¾—å¹«é€™äº›å‘é‡å»ºç«‹åœ–é—œä¿‚ã€‚\nDelaunay triangulation algorithm å¯ä»¥ç”¨ä¾†å»ºç«‹åœ–é—œä¿‚ ä½†é  Delaunay triangulation algorithmï¼Œæœ‰å¯èƒ½éš¨æ©Ÿçš„å‘é‡å’Œç›®æ¨™å‘é‡è·é›¢å¾ˆé ï¼ŒæŸ¥æ‰¾å¾ˆæ…¢ã€‚\nNSW çš„å¯¦éš›åšæ³•æ˜¯å°‡æ‰€æœ‰å‘é‡éš¨æ©Ÿåœ°æ”¾å›åœ–ä¸­ï¼Œä¸¦å’Œæœ€è¿‘çš„ k å€‹é»é€£æ¥ã€‚\nåªçœ‹è¼ƒçŸ­çš„é€£æ¥ï¼Œæœƒç™¼ç¾å’Œ Delaunay triangulation algorithm ç”¢çš„åœ–ç›¸è¿‘ï¼Œå¯ä»¥é€²è¡Œç´°ç²’åº¦çš„æŸ¥æ‰¾ã€‚ åªçœ‹è¼ƒé•·çš„é€£æ¥ï¼Œå‰‡å¯é”åˆ°å¿«é€Ÿå°èˆªçš„æ•ˆæœã€‚\nHNSW å»ºç«‹ä¸€å€‹åˆ†å±¤çµæ§‹ï¼Œè¶Šä¸Šå±¤çš„é»è¶Šç¨€ç–ã€é€£ç·šè¶Šé•·ã€‚\nå’Œ NSW ç›¸æ¯”ï¼Œè®“ç²—ç²’åº¦åˆ°ç´°ç²’åº¦çš„å°èˆªéç¨‹æ›´åŠ ç©©å®šã€‚\nä½†å ç”¨çš„è¨˜æ†¶é«”ç©ºé–“æ›´å¤§ã€‚\n","date":"2023-10-06T00:27:55+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E6%9F%A5%E6%89%BE%E7%9B%B8%E4%BC%BC%E5%90%91%E9%87%8F/","title":"æŸ¥æ‰¾ç›¸ä¼¼å‘é‡"},{"content":"Union-Find (DSU) ä¸åŒæ¢ä»¶ä¸‹çš„æ™‚é–“è¤‡é›œåº¦ å¾…è£œ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 int find(int x) { if (f[x] == x) return x; else return f[x] = find(f[x]); } int merge(int x, int y) { f[find(x)] = find(y); } int main() { for (int i = 1; i \u0026lt;= n; i++) f[i] = i; x = find(x); y = find(y); if (x != y) { merge(x, y); } } Trie 1 2 3 4 5 6 7 8 9 10 11 class Node { public: int cnt; int id; Node* nxt[26]; Node() { cnt = 0; for (int i = 0; i \u0026lt; 26; i++) nxt[i] = nullptr; } }; Segment Tree å–®é»ä¿®æ”¹ç·šæ®µæ¨¹ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 #define pl(x) (x * 2 + 1) #define pr(x) (x * 2 + 2) void build(int index, int l, int r) { if (l == r) { tree[index] = arr[l]; return; } int mid = (l + r) / 2; build(pl(index), l, mid); build(pr(index), mid + 1, r); tree[index] = tree[pl(index)] * tree[pr(index)]; } void change(int index, int q, int l, int r, int \u0026amp;value) { if (l == r) { tree[index] = value; return; } int mid = (l + r) / 2; if (mid \u0026gt;= q) change(pl(index), q, l, mid, value); else change(pr(index), q, mid + 1, r, value); tree[index] = tree[pl(index)] * tree[pr(index)]; } void query(int index, int ql, int qr, int l, int r, int \u0026amp;ans) { if (ql \u0026lt;= l \u0026amp;\u0026amp; r \u0026lt;= qr) { ans *= tree[index]; return; } int mid = (l + r) / 2; if (ql \u0026lt;= mid) query(pl(index), ql, qr, l, mid, ans); if (mid \u0026lt; qr) query(pr(index), ql, qr, mid + 1, r, ans); } ","date":"2023-08-29T00:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E8%B3%87%E6%96%99%E7%B5%90%E6%A7%8B%E7%AD%86%E8%A8%98/","title":"è³‡æ–™çµæ§‹ç­†è¨˜"},{"content":"Sorting Merge Sort ä¸€ç›´æ‹†åˆ†å…©é‚Šæœ€å¾Œå†è¼ªæµ merge èµ·ä¾†ï¼Œmerge æ™‚çœ‹å…©é‚Šé–‹é ­èª°æœ€å°ï¼Œä¾åºæ”¾ éƒ½æ˜¯ $O(nlogn)$ stable not in-place Quick sort é¸å®šä¸€å€‹ pivotï¼Œç”¨å…©å€‹æŒ‡é‡å¾å…©é‚Šé–‹å§‹å¾€ä¸­é–“æ‰¾ã€‚ç•¶å·¦æŒ‡é‡æ‰¾åˆ°æ¯” pivot å¤§çš„æ•¸å€¼ï¼Œå³æŒ‡é‡æ‰¾åˆ°æ¯” pivot å°çš„æ•¸å€¼å¾Œäº¤æ›ã€‚ç›´åˆ°å…©å€‹æŒ‡é‡ç›¸é‡ï¼Œå†æŠŠ pivot æ›åˆ°ä¸­é–“ï¼Œç¹¼çºŒå…©é‚Šè™•ç†\næœ€å·®æœƒåˆ° $O(n^2)$ï¼Œå¹³å‡ $O(nlogn)$\né¸ pivot\néš¨æ©Ÿé¸ Median of Three é¸é–‹é ­ã€ä¸­é–“å’Œçµå°¾çš„ä¸­ä½æ•¸ Other Binary Exponentiation å¿«é€Ÿå†ª 1 2 3 4 5 6 7 8 9 int qpow(int x, int m) { int ans = 1; while (m) { if (m \u0026amp; 1) ans *= x; x *= x; m \u0026gt;\u0026gt;= 1; } return ans; } Discretization é›¢æ•£åŒ– 1 2 3 4 5 sort(vec.begin(), vec.end()); vec.resize(unique(vec.begin(), vec.end()) - vec.begin()); for (int i = 0; i \u0026lt; vec.size(); i++) { val[i] = lower_bound(vec.begin(), vec.end(), val[i]) - vec.begin(); } Ternary Search ä¸‰åˆ†æœ 1 2 3 4 5 6 7 8 9 10 11 l = -10000.0; r = 10000.0; while (r - l \u0026gt; eps) { ml = (r - l) / 3.0 + l; mr = (r - l) * 2.0 / 3.0 + l; if (f(ml) \u0026gt; f(mr)) { l = ml; } else { r = mr; } } ","date":"2023-08-27T00:09:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E6%9C%AA%E5%88%86%E9%A1%9E%E6%BC%94%E7%AE%97%E6%B3%95-%E8%B3%87%E6%96%99%E7%B5%90%E6%A7%8B%E7%AD%86%E8%A8%98/","title":"æœªåˆ†é¡æ¼”ç®—æ³• \u0026 è³‡æ–™çµæ§‹ç­†è¨˜"},{"content":"Floyd-Warshall 1 2 3 4 for (int k = 0; k \u0026lt; nodeCount; k++) for (int i = 0; i \u0026lt; nodeCount; i++) for (int j = 0; j \u0026lt; nodeCount; j++) DP[i][j] = min(DP[i][j], DP[i][k]+ DP[k][j]); dijkstra æ™‚é–“è¤‡é›œåº¦ $O((V+E)*log(E))$ æœ€å·®æ¯æ¢é‚Šéƒ½è¦æ’å…¥ heap è¦å–å‡º V å€‹é» 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 class cmp { public: bool operator()(edge a,edge b) { if(a.weight\u0026lt;b.weight) return true; return false; } }; dis[a] = 0; priority_queue\u0026lt;edge, vector\u0026lt;edge\u0026gt;, cmp\u0026gt; pq; pq.push({a, 0}); while (!pq.empty()) { edge u = pq.top(); pq.pop(); if (!vis[u.to_node]) { vis[u.to_node] = 1; for (auto i : mp[u.to_node]) { if (dis[i.to_node] \u0026gt; dis[u.to_node] + i.weight) { dis[i.to_node] = dis[u.to_node] + i.weight; pq.push({i.to_node, dis[i.to_node]}); } } } } Topological Sorting è¨˜å¾—ç¢ºèªæ˜¯ä¸æ˜¯ Directed Acyclic Graph BFS æ˜¯æ²’æœ‰å‰ç¹¼ç¯€é»å„ªå…ˆï¼ŒDFS æ˜¯æ²’æœ‰å¾Œç¹¼ç¯€é»å„ªå…ˆ ç”¨ BFS çš„è©±å°±æ˜¯æŠŠå…¥åº¦ç‚º 0 çš„é»åŠ å…¥ Queueï¼Œä¸€ç›´ç¶­è­·è©² Queue 1 2 3 4 5 6 7 8 9 10 void dfs(int u) { if (!vis[u]) { vis[u] = true; for (auto j : edge[u]) dfs(j); toposort.push_back(u); } } for (int i = 1; i \u0026lt;= n; i++) dfs(i); reverse(toposort.begin(), toposort.end()); æ¨¹çš„ç›´å¾‘ å…©æ¬¡ DFSï¼Œç¬¬ä¸€æ¬¡æ‰¾åˆ°é›¢ä»»æ„é»æœ€é çš„é»ï¼Œç¬¬äºŒæ¬¡å¾è©²é»å‡ºç™¼æ‰¾åˆ°é›¢ä»–æœ€é çš„é»ï¼Œé€™å…©å€‹é»ä¹‹é–“çš„è·é›¢å°±æ˜¯æ¨¹çš„ç›´å¾‘ã€‚\nLowest Common Ancestor å¾…è£œ Eulerian path æ­æ‹‰è·¯å¾‘ æ¯æ¢é‚Šåªèƒ½è¢«è¨ªå•ä¸€æ¬¡ï¼ˆä¸€ç­†ç•«å•é¡Œï¼‰ æ¢ä»¶ é™¤äº†å…©å€‹é»å¤–ï¼Œå…¶ä»–éƒ½å¾—ç‚ºå…¥åº¦==å‡ºåº¦ã€‚å¦å¤–å…©å€‹é»ï¼Œæœ€å¤šæœ‰ä¸€å€‹å‡ºåº¦è¦æ¯”å…¥åº¦å¤§ä¸€ï¼Œæœ€å¤šæœ‰ä¸€å€‹å…¥åº¦è¦æ¯”å‡ºåº¦å¤§ä¸€ã€‚ï¼ˆåªèƒ½æœ‰ 0 æˆ– 2 å€‹å¥‡é»ï¼‰ é ˆç‚ºé€£é€šåœ– è¦–ä½œç„¡å‘åœ–çš„æ™‚å€™æ˜¯å¦å¯ä»¥é€£åˆ°æ¯å€‹é» Matching Hungarian Algorithm å¾…è£œ æœ€å°é»è¦†è“‹ç­‰ç­‰ å¾…è£œ ","date":"2023-08-27T00:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E5%9C%96%E8%AB%96%E7%AD%86%E8%A8%98/","title":"åœ–è«–ç­†è¨˜"},{"content":"ç°¡ä»‹ Meta åœ¨ 2015 å¹´å…¬é–‹çš„ API Query Language å¸¸è¢«ç”¨ä¾†å’Œå‚³çµ±çš„ REST API æ¯”è¼ƒï¼Œå…·å‚™æŸ¥è©¢æ›´åŠ éˆæ´»ç­‰ç‰¹æ€§ æœ‰åœ¨ä½¿ç”¨çš„å…¬å¸ Facebook GitHub Twitter \u0026hellip; å’Œ REST API çš„ä¸»è¦å·®åˆ¥ Single Endpoint\nå’Œ REST API å°æ–¼ä¸åŒ resource éœ€è¦ä¸åŒ endpoint ä¸åŒï¼ŒGraphQL å°æ–¼æ‰€æœ‰ resource éƒ½æ˜¯å¾åŒä¸€å€‹ endpoint é€²è¡Œå­˜å– ä½† GraphQL ä¸èƒ½è¼•æ˜“åœ°ç”¨ HTTP cachingï¼Œå› ç‚ºç¾åœ¨åªå‰©ä¸€ç¨® URL äº† è§£æ±º Under-fetching å’Œ Over-fetching å•é¡Œ\nUnder-fetching\nä¸€å€‹ API call æ²’è¾¦æ³•å–å¾—æ‰€æœ‰æƒ³è¦çš„è³‡æ–™ï¼Œéœ€è¦å¤šæ¬¡ API call å‡å¦‚è¦ç”¨ RESTful API å–å¾—ä¸€å€‹æ–‡ç« çš„ä½œè€…ï¼Œå¯èƒ½å¾—å…ˆå–å¾—æ–‡ç« ï¼Œå†å–å¾—ä½œè€…ï¼Œé€™æ¨£å°±éœ€è¦å…©æ¬¡ API call ä½† GraphQL å¯ä»¥åœ¨ä¸€æ¬¡ API call ä¸­å–å¾—æ–‡ç« å’Œä½œè€…ï¼Œé€é nested query Over-fetching\nä¸€å€‹ API call å–å¾—çš„è³‡æ–™æ¯”æƒ³è¦çš„é‚„å¤šï¼Œé€ æˆè³‡æºæµªè²» GraphQL å¯ä»¥é€é query å®šç¾©åªæƒ³å–å¾—çš„æ¬„ä½ ä½¿ç”¨ å’Œ RESTful API ä¸åŒï¼Œéœ€è¦ç‰¹åˆ¥æ¶å€‹ GraphQL serverï¼Œå¯ä»¥è€ƒæ…®ç”¨ Apollo Server\nè¦å®šç¾©ä¸åŒ Data type çš„ schemaã€relationshipï¼Œä»¥åŠå¯«å°æ‡‰ä¸åŒ query çš„ resolver\nQuery å¯èƒ½æœƒæ˜¯é•·é€™æ¨£çš„æ±è¥¿\n1 2 3 4 5 6 7 8 9 10 11 query postQuery($id: ID!) { post(id: $id) { id title content author { id name } } } Mutation æ–°å¢ã€ä¿®æ”¹ã€åˆªé™¤è³‡æ–™éƒ½å±¬æ–¼é€™å¡Š\n1 2 3 4 5 6 7 8 9 10 11 query addPost($post: AddPostInput!) { addPost(post: $post) { id title content author { id name } } } ","date":"2023-08-22T00:00:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/graphql-%E7%B0%A1%E4%BB%8B/","title":"GraphQL ç°¡ä»‹"},{"content":"paper: End-to-End Object Detection with Transformers\nAbstract ä½œè€…æŠŠ object detection è¦–ä½œä¸€å€‹ set prediction å•é¡Œã€‚\nç°¡åŒ–äº† pipelineï¼Œæ¶ˆé™¤äº†è¨±å¤š hand-designed componentsï¼Œæ¯”å¦‚ non-maximum suppression å’Œ anchor generationï¼Œé€™äº› component ç”±æˆ‘å€‘å°æ–¼ä»»å‹™çš„å…ˆé©—çŸ¥è­˜æ§‹æˆã€‚\næå‡ºäº†ä¸€å€‹æ–°çš„ç›®æ¨™å‡½æ•¸ï¼Œé€éäºŒåˆ†åŒ¹é…ï¼ˆbipartite matchingï¼‰é€²è¡Œé æ¸¬ï¼Œä¹Ÿç”¨ Transformer encoder-decoder æ¶æ§‹ã€‚\nçµ¦äºˆä¸€çµ„å›ºå®šçš„ learned object queryï¼ŒDETR å¯ä»¥æ¨ç† objects å’Œ globol image context çš„é—œä¿‚ï¼Œä¸¦ã€Œä¸¦è¡Œã€è¼¸å‡ºä¸€çµ„é æ¸¬é›†ã€‚\nDETR æ¦‚å¿µéå¸¸ç°¡å–®ã€‚\nDETR åœ¨ COCO ä¸Šå’Œ Faster RCNN baseline åœ¨æº–ç¢ºåº¦å’Œ performance ä¸Šç›¸ç•¶ã€‚\nDETR å¯ä»¥å¾ˆç°¡å–®åœ°æ¨å»£åˆ° Panoptic Segmentationã€‚\nIntroduction ç›®æ¨™æª¢æ¸¬çš„ç›®æ¨™å°±æ˜¯é›†åˆé æ¸¬ã€‚\nä½†ç›®å‰éƒ½ç”¨ä¸€äº›å¾ˆé–“æ¥çš„æ–¹å¼å»åšï¼Œåƒæ˜¯ç”¨ proposals, anchors æˆ– window centersã€‚\nä½†æ˜¯é€™äº›æ–¹æ³•æ€§èƒ½æ˜é¡¯å—é™æ–¼å¾Œè™•ç†æ­¥é©Ÿï¼Œæ¯”å¦‚ non-maximum suppressionï¼Œå› ç‚ºä»–å€‘æœƒç”¢ç”Ÿå¤§é‡å†—é¤˜çš„æ¡†ã€‚\nç‚ºäº†ç°¡åŒ– pipelineï¼Œä½œè€…æå‡ºäº†ä¸€ç¨® End-to-End çš„æ–¹æ³•ï¼Œä»¥å¾€ä¹Ÿæœ‰ä¸€äº›å˜—è©¦ï¼Œä½†ä»–å€‘è¦ä¸æ·»åŠ äº†å…¶ä»–çš„å…ˆé©—çŸ¥è­˜ï¼Œä¸ç„¶å°±æ˜¯åœ¨å…·æœ‰æŒ‘æˆ°æ€§çš„ benchmark ä¸Šè¡¨ç¾ä¸å¥½ã€‚\nåœ¨ COCO ä¸Šå’Œ Faster R-CNN çš„æ€§èƒ½ç›¸ç•¶ï¼Œè¡¨ç¾å’Œé€Ÿåº¦éƒ½å·®ä¸å¤šã€‚\nDETR åœ¨å¤§ç‰©é«”è¡¨ç¾å¾ˆå¥½ï¼Œå¯èƒ½æ˜¯æ­¸åŠŸæ–¼ Transformer non-local çš„è¨ˆç®—èƒ½åŠ›ã€‚ é›–ç„¶ DETR åœ¨å°ç‰©é«”ä¸Šè¡¨ç¾å€’ä¸æ€éº¼æ¨£ã€‚\nDETR éœ€è¦è¶…é•·çš„è¨“ç·´æ™‚é–“ï¼Œä½† DETR çš„è¨­è¨ˆç†å¿µå¯ä»¥æ‹“å±•åˆ° Panoptic Segmentationã€‚\nRelated Work Set Prediction æ²’æœ‰è¦ç¯„çš„æ·±åº¦å­¸ç¿’æ¨¡å‹å¯ä»¥ç›´æ¥é æ¸¬é›†åˆã€‚\né€™äº›ä»»å‹™ä¸­çš„ä¸€å€‹å›°é›£é»æ˜¯é¿å… near-dulicatesï¼ˆç›¸è¿‘çš„é‡è¤‡æª¢æ¸¬æ¡†ï¼‰ ç•¶å‰å¤šæ•¸æª¢æ¸¬å™¨ç”¨ NMS ä¾†è§£æ±ºæ­¤å•é¡Œï¼Œå¦‚æœæ˜¯ direct set prediction å°±ä¸ç”¨å¾Œè™•ç†ã€‚\nTransformers and Parallel Decoding Transformer åœ¨å„ç¨®åœ°æ–¹è¡¨ç¾å‡ºè‰²ï¼Œä½†æ¨ç†æˆæœ¬ä»¤äººæœ›è€Œç”Ÿç•ã€‚\nObject detection ç¾åœ¨å¤šæ•¸çš„ç›®æ¨™æª¢æ¸¬æ–¹æ³•æ˜¯åŸºæ–¼ä¸€äº›åˆå§‹çš„çŒœæ¸¬ï¼Œå†å»åšé æ¸¬ã€‚\næ¯”å¦‚å°æ–¼ two-stage çš„æ–¹æ³•ï¼Œå°±æ˜¯å°æ–¼ proposals å¾€ä¸‹åšé æ¸¬ã€‚\nå°æ–¼ single-stageï¼Œåˆå§‹çŒœæ¸¬å°±æ˜¯ anchorsã€‚\nSet-based loss ä»¥å‰çš„ä¸€äº›ä½œæ³•æ¯”å¦‚ Learnable NMS æˆ– relation networks éƒ½å¯ä»¥é€é attention ä¾†è™•ç†ä¸åŒé æ¸¬ä¹‹é–“çš„é—œä¿‚ã€‚\nç”¨ direct set lossesï¼Œä»–å€‘ä¸éœ€è¦ä»»ä½•å¾Œè™•ç†ã€‚\nä½†æ˜¯é€™äº›æ–¹æ³•å¾€å¾€ç”¨é¡å¤–çš„ hand-crafted context featureï¼Œæ¯”å¦‚ proposal box coordinatesã€‚ä½œè€…å°‹æ‰¾æ¸›å°‘æ¨¡å‹ä¸­å…ˆé©—çŸ¥è­˜çš„æ–¹æ¡ˆã€‚\nRecurrent detectors ä»¥å¾€æœ‰é¡ä¼¼çš„å·¥ä½œï¼Œä½†ä»–å€‘æ˜¯ç”¨ RNNã€‚\nThe DETR model Object detection set prediction loss DETE æœƒçµ¦ N å€‹å›ºå®šå¤§å°çš„é›†åˆé æ¸¬ã€‚\nè¦è§£äºŒåˆ†åœ–åŒ¹é…ï¼Œæœ¬æ–‡ç”¨ scipy çš„ linear_sum_assignment è™•ç†ï¼Œä»–èƒŒå¾Œæ˜¯åŒˆç‰™åˆ©æ¼”ç®—æ³•ã€‚\nå…¶å¯¦é€™ç¨®æ–¹æ³•å’Œ proposals å’Œ anchors æœ‰å·®ä¸å¤šçš„ä½œç”¨ï¼Œå·®åˆ¥åœ¨æ–¼é€™è£¡æœƒæ‰¾ä¸€å°ä¸€çš„åŒ¹é…ï¼Œè€Œä¸ç”¨é‡è¤‡ã€‚\nç›®æ¨™å‡½æ•¸ï¼š\n$L_{Hungarian}(y, \\text{\\^{y}}) = \\displaystyle\\sum^{N}_{i=1} [-log \\text{\\^{p}} $ $_{\\^{\\sigma}(i)}(c_i) + \\text{1}$ $_\\{$ $_{c_i \\neq \\text{\\o}}$ $_\\}$ $\\mathcal{L}$ $_{\\text{box}} (b_i, \\text{\\^{b}}$ $_{\\^{\\sigma}}(i))]$\nå‰é¢æ˜¯åˆ†é¡çš„ lossï¼Œå¾Œé¢æ˜¯ bounding box çš„ lossã€‚\né€™é‚Šæœ‰å…©å€‹æ”¹å‹•ï¼Œç¬¬ä¸€å€‹æ˜¯åˆ†é¡é‚£é‚Šä¸ç”¨ logï¼Œä½¿å€¼å’Œ bounding box çš„ loss æ¯”è¼ƒæ¥è¿‘ã€‚\nå¦ä¸€å€‹æ˜¯ bounding box é‚£é‚Šä¸¦ä¸æ˜¯ç”¨æœ€å¸¸è¦‹çš„ L1ï¼Œå› ç‚º L1 å°æ–¼å¤§çš„ç›®æ¨™ loss æ¯”è¼ƒé«˜ï¼Œé€™è£¡é™¤äº† L1 é‚„é¸ç”¨ generalized IoU lossï¼Œå®ƒåœ¨å°ºåº¦ä¸Šèˆ‡ loss ç„¡é—œã€‚\nDETR architecture ç”¨ CNN å¾åœ–ç‰‡æŠ½ç‰¹å¾µï¼Œæ‹‰ç›´ï¼Œé¤µçµ¦ Transformer encoder-decoderï¼Œå¾—åˆ°ä¸€çµ„é æ¸¬é›†åˆã€‚\né€™è£¡ encoder æœ‰åŠ©æ–¼ç‰¹å¾µé–“å½¼æ­¤äº¤äº’ã€‚\nè¨“ç·´çš„æ™‚å€™ï¼Œé æ¸¬çš„æ¡†å’Œ GT åšåŒ¹é…ï¼Œæ²’åŒ¹é…åˆ°çš„å°±æ”¾åˆ° \u0026ldquo;no object\u0026rdquo; classã€‚\ndecoder æœƒé¤µå…¥ object queriesï¼Œé€™äº›æ˜¯ learnable positional encodingsã€‚\nExperiments Ablations Number of encoder layers ä½œè€…é€éæ”¹è®Š Encoder layer çš„æ•¸é‡ä¾†è©•ä¼° global imagelevel self-attention çš„é‡è¦æ€§ã€‚\nä½œè€…æ¨è«– encoder å¯èƒ½å°æ–¼åˆ¤æ–·åˆ†é–‹å°è±¡å¾ˆé‡è¦ï¼Œåœ– 3 å¯è¦–åŒ–äº†æœ€å¾Œä¸€å€‹ encoder layer çš„ attention mapã€‚\nencoder çœ‹ä¼¼å·²ç¶“åˆ†é›¢äº† instanceï¼Œå¯èƒ½ç°¡åŒ–äº† decoder å°æ–¼ object extraction å’Œ localization çš„å·¥ä½œã€‚\nNumber of decoder layers åœ¨åœ– 6 åšäº† decoder çš„æ³¨æ„åŠ›å¯è¦–åŒ–ï¼Œå¯ä»¥æ³¨æ„åˆ°è§€å¯Ÿçš„æ³¨æ„åŠ›ç›¸ç•¶å±€éƒ¨ã€‚\næ¨è«–æ˜¯ encoder ä¸»è¦åˆ†é›¢å¯¦é«”ï¼Œdecoder åªéœ€è¦é—œæ³¨å››è‚¢å³å¯æå–å‡ºå°è±¡çš„é‚Šç•Œå’Œåˆ†é¡ã€‚\nAnalysis åœ– 7 æŠŠ 100 å€‹é æ¸¬æ§½ä¸­çš„ 20 å€‹åšå¯è¦–åŒ–ã€‚\næ¯å€‹é æ¸¬æ¡†ä»£è¡¨ä¸€é»ï¼Œå¯ä»¥æ³¨æ„åˆ°ä¸åŒçš„æ§½ä½æœƒå°ˆæ³¨åœ¨ä¸åŒå€åŸŸã€‚\n","date":"2023-08-10T00:27:55+08:00","permalink":"https://roykesydon.github.io/Blog/p/detr-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"DETR è«–æ–‡é–±è®€"},{"content":"paper: BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\nç¾åœ¨å›é ­å¯« BERT è«–æ–‡ç­†è¨˜æ„Ÿè¦ºæœ‰é»æ€ªï¼Œä¹‹å‰å·²ç¶“å¯«éä»€éº¼ RoBERTa ä¹‹é¡çš„ã€‚\nä¸éç¾åœ¨å› æ‡‰å¯¦é©—å®¤è®€æ›¸æœƒè¦æ±‚ï¼Œé‚„æ˜¯çœ‹ä¸€ä¸‹è«–æ–‡ä¹Ÿå¯«ä¸€ä¸‹ç­†è¨˜ã€‚\nAbstract æœ¬æ–‡æå‡ºäº† BERTï¼Œä¸€ç¨®åŸºæ–¼ Transformer Bidirectional Encoder çš„èªè¨€è¡¨ç¤ºæ¨¡å‹ã€‚\nBERT æ—¨åœ¨é€é unlabeled text é€²è¡Œ pretrainã€‚\nå› æ­¤ï¼Œåªéœ€è¦ä¸€å€‹é¡å¤–çš„è¼¸å‡ºå±¤å°±å¯ä»¥å°é è¨“ç·´çš„ BERT é€²è¡Œå¾®èª¿ï¼Œåœ¨å„ç¨®ä»»å‹™ä¸Šå–å¾— SOTAã€‚\nIntroduction ã€Œèªè¨€æ¨¡å‹åšé è¨“ç·´ã€å·²è¢«è­‰æ˜å¯ä»¥æœ‰æ•ˆæ”¹å–„å¤šç¨® NLP ä»»å‹™ã€‚\nå°‡é è¨“ç·´æ¨¡å‹æ‡‰ç”¨åœ¨ä¸‹æ¸¸ä»»å‹™ï¼Œæœ‰å…©ç¨®ç­–ç•¥ï¼š\nFeature-based æŠŠ pretrained çš„ representations ä½œç‚ºé¡å¤–çš„ç‰¹å¾µ Fine-tuning æ ¹æ“šç‰¹å®šä»»å‹™å¼•å…¥é¡å¤–åƒæ•¸ï¼Œä¸¦ç°¡å–®åœ°å¾®èª¿æ‰€æœ‰åƒæ•¸ é€™å…©ç¨®æ–¹æ³•åœ¨é è¨“ç·´æœŸé–“å…±ç”¨åŒå€‹ objective functionï¼Œä¸¦ç”¨å–®å‘èªè¨€æ¨¡å‹ä¾†å­¸ç¿’ representationã€‚\nä½œè€…èªç‚ºç•¶å‰çš„æŠ€è¡“é™åˆ¶äº†é è¨“ç·´çš„è¡¨ç¤ºèƒ½åŠ›ï¼Œç‰¹åˆ¥æ˜¯åœ¨ Fine-tuning æ–¹æ³•ä¸Šã€‚\nä¸»è¦çš„å•é¡Œåœ¨æ–¼èªè¨€æ¨¡å‹æ˜¯å–®å‘çš„ï¼Œé™åˆ¶äº†é è¨“ç·´æœŸé–“å¯ä»¥ä½¿ç”¨çš„æ¶æ§‹çš„é¸æ“‡ã€‚é€™ç¨®å–®å‘çš„æ¶æ§‹å¯èƒ½åœ¨ä¸€äº›ä»»å‹™æœ‰å®³ï¼Œç‰¹åˆ¥æ˜¯å°æ–¼é‚£äº›éœ€è¦å…©å€‹æ–¹å‘çš„ context çš„ä»»å‹™ã€‚\næœ¬æ–‡æå‡ºçš„ BERT æ”¹å–„äº†ç¾æœ‰çš„ Fine-tuning æ–¹æ³•ï¼Œç”¨ Transformer çš„ Bidirectional Encoder ä¾†è¨“ç·´èªè¨€æ¨¡å‹ã€‚\nBERT é€éå—åˆ° Cloze taskï¼ˆå¡«ç©ºï¼‰å•Ÿç™¼çš„ masked language model(MLM)ï¼Œä½œç‚ºé è¨“ç·´ç›®æ¨™ã€‚MLM éš¨æ©Ÿåœ°é®è”½ä¸€äº›è¼¸å…¥çš„ä¸€äº› tokenï¼Œç›®æ¨™æ˜¯æ ¹æ“šä¸Šä¸‹æ–‡ä¾†å›æ¨åŸè©ï¼Œä½¿ representation å¯ä»¥èåˆå·¦å³å…©é‚Šçš„ contextã€‚\né™¤äº† MLMï¼Œä½œè€…é‚„åˆ©ç”¨ next sentence predictionï¼ˆNSPï¼‰ä»»å‹™ä¾†è¨“ç·´ BERTã€‚\næœ¬æ–‡è²¢ç»å¦‚ä¸‹ï¼š\nBERT è­‰æ˜äº†é›™å‘é è¨“ç·´å° representation çš„é‡è¦æ€§ã€‚\nBERT å±•ç¾å‡ºé è¨“ç·´çš„ representation æ¸›å°‘äº†è¨±å¤šé‡å° NLP ä»»å‹™ç²¾å¿ƒè¨­è¨ˆæ¶æ§‹çš„éœ€æ±‚ã€‚ BERT æ˜¯ç¬¬ä¸€å€‹åŸºæ–¼ Fine-tuningï¼Œåœ¨å¤§é‡ sentence-level å’Œ token-level ä»»å‹™ä¸Šå–å¾— SOTA çš„æ¨¡å‹ã€‚\nBERT æ¨é€²äº† 11 å€‹ NLP ä»»å‹™çš„ SOTAã€‚\nRelated Work Unsupervised Feature-based Approaches å­¸ç¿’å»£æ³›é©ç”¨çš„ representation of words ä¸€ç›´æ˜¯æ´»èºçš„ç ”ç©¶é ˜åŸŸï¼Œç”šè‡³åœ¨éç¥ç¶“ç¶²è·¯çš„é ˜åŸŸä¹Ÿæ˜¯ã€‚\né è¨“ç·´çš„ word embeddings èˆ‡å¾é ­è¨“ç·´çš„ embedding ç›¸æ¯”ï¼Œæœ‰é¡¯è‘—æ”¹é€²ã€‚\né€™äº›æ–¹æ³•é è¢«æ¨å»£åˆ° coarser granularitiesï¼Œåƒæ˜¯ sentence embedding æˆ–æ˜¯ paragraph embeddingã€‚\næœ‰ç ”ç©¶è­‰æ˜ cloze task æé«˜äº†ç”Ÿæˆæ¨¡å‹çš„ robustnessã€‚\nBERT æ¡†æ¶æœ‰å…©æ­¥é©Ÿï¼š\nPre-training åœ¨ä¸åŒçš„é è¨“ç·´ä»»å‹™ä¸­ï¼Œç”¨ unlabeled data ä¾† fine-tuneã€‚ Fine-tuning ä½¿ç”¨é è¨“ç·´çš„åƒæ•¸åˆå§‹åŒ–ï¼Œåœ¨åˆ©ç”¨ä¸‹æ¸¸ä»»å‹™çš„ labeled data å°æ‰€æœ‰åƒæ•¸å¾®èª¿ã€‚ BERT çš„ä¸€å€‹ç‰¹é»æ˜¯ä»–å…·å‚™è·¨ä¸åŒä»»å‹™çš„çµ±ä¸€æ¶æ§‹ï¼Œé è¨“ç·´æ¶æ§‹å’Œä¸‹æ¸¸ä»»å‹™æœ€çµ‚æ¶æ§‹å·®ç•°ä¸å¤§ã€‚\nModel Architecture\næœ¬æ–‡è¡¨ç¤ºæ–¹æ³•\nL: Transformer çš„å±¤æ•¸ H: hidden size A: self-attention heads çš„æ•¸é‡ model size\nBASE: L=12, H=768, A=12, 110M parameters å’Œ GPT ç›¸åŒ LARGE: L=24, H=1024, A=16, 340M parameters Input/Output Representations\nInput representation å¯ä»¥åœ¨ token sequence ä¸­æ˜ç¢ºè¡¨ç¤ºå–®å€‹ sentence å’Œä¸€å° sentenceã€‚\nsentence å¯ä»¥æ˜¯é€£çºŒæ–‡æœ¬çš„ä»»æ„ç¯„åœï¼Œè€Œä¸æ˜¯å¯¦éš›çš„å¥å­ã€‚ sequence æ˜¯è¼¸å…¥çš„ token sequenceï¼Œå¯ä»¥æ˜¯å–®å€‹ sentence æˆ–æ˜¯ä¸€å° sentenceã€‚ æ¯å€‹ sequence çš„ç¬¬ä¸€å€‹ token å§‹çµ‚æ˜¯ç‰¹æ®Šçš„åˆ†é¡ token \u0026ndash; [CLS] å°æ–¼å…©å€‹å¥å­æ”¾åœ¨ä¸€å€‹åºåˆ—çš„æƒ…æ³ï¼Œç”¨ [SEP] éš”é–‹ Token Embeddings\nä½œè€…ä½¿ç”¨ WordPiece embeddingsï¼Œæœ‰ 30000 å€‹è©å½™ã€‚ learned embedding\nå°æ¯å€‹ token æ·»åŠ é€™å€‹æ±è¥¿ï¼Œè¡¨ç¤ºå±¬æ–¼ sentence A é‚„ sentence B Pre-training BERT Masked LM ç›´è§€ä¸Šï¼Œæœ‰ç†ç”±ç›¸ä¿¡æ·±åº¦çš„é›™å‘æ¨¡å‹æœƒæ¯”å–®åƒä¸²é€£èµ·ä¾†çš„æ·ºå±¤æ¨¡å‹æ›´å¼·å¤§ã€‚\nä¸å¹¸çš„æ˜¯ standard condition language model åªèƒ½å–®å‘è¨“ç·´ï¼Œå› ç‚ºé›™å‘æœƒå…è¨±æ¯å€‹å–®è©ã€Œé–“æ¥çœ‹åˆ°è‡ªå·±ã€ã€‚\nç‚ºäº†è¨“ç·´ deep bidirectional representationsï¼Œæœ¬æ–‡éš¨æ©Ÿé®è”½äº†ä¸€å®šæ¯”ä¾‹çš„ tokensï¼Œä¸¦é æ¸¬é€™äº› tokenï¼Œé€™ç¨®æ–¹æ³•ç¨±ç‚º masked language modelï¼Œæˆ–å¸¸è¢«ç¨±ç‚º cloze taskã€‚\nä½œè€…æœƒç”¨ [MASK] åšé è¨“ç·´ï¼Œä½†æœ‰å€‹å•é¡Œæ˜¯ [MASK] åœ¨ fine-tuning æœŸé–“ä¸æœƒå‡ºç¾ï¼Œé€ æˆé è¨“ç·´å’Œå¾®èª¿ä¹‹é–“çš„ mismatchingï¼Œç‚ºäº†ç·©æ¸›é€™ç¨®æƒ…æ³ï¼Œä¸¦ä¸æœƒç¸½æ˜¯ç”¨ [MASK] æ›¿ä»£ masked tokenã€‚\nè¦æ›¿æ› token çš„æ™‚å€™ï¼Œæœ‰ 80% çš„æ™‚é–“æ˜¯ [MASK]ï¼Œ10% æ˜¯éš¨æ©Ÿ tokenï¼Œ10% æ˜¯åŸæœ¬çš„ tokenã€‚\nNext Sentence Prediction (NSP) è¨±å¤šé‡è¦ä¸‹æ¸¸ä»»å‹™ï¼Œæ¯”å¦‚ Question Answering (QA) å’Œ Natural Language Inference (NLI) æ˜¯åŸºæ–¼å…©å€‹å¥å­é–“çš„é—œä¿‚ã€‚\nNSP å°±æ˜¯ç‚ºäº†ç†è§£å¥å­é–“çš„é—œä¿‚è€Œç”¨çš„ã€‚\næ¯æ¬¡æŒ‘å¥å­ A å’Œ B çš„æ™‚å€™ï¼Œæœ‰ 50% çš„æ©Ÿæœƒ B æ˜¯ A çš„ä¸‹ä¸€å€‹å¥å­ï¼Œæœ‰ 50% æ˜¯éš¨æ©Ÿçš„ã€‚\né‡å° NSP çš„é è¨“ç·´å° QA å’Œ NLI éƒ½å¾ˆæœ‰ç”¨ã€‚\né è¨“ç·´è³‡æ–™ ç”¨ BookCorpus å’Œ English Wikipedia ä¾†è¨“ç·´ BERTã€‚\nå°æ–¼ English Wikipediaï¼Œåªæå– text passagesï¼Œå¿½ç•¥ lists, tables, headersã€‚\nç‚ºäº†æå–é•·çš„é€£çºŒåºåˆ—ï¼Œç”¨ document-level çš„ corpus è€Œä¸æ˜¯æ‰“äº‚çš„ sentence-level corpus éå¸¸é‡è¦ã€‚\nAblation Studies Effect of Pre-training Tasks No NSP åªæœ‰ MLM LTR \u0026amp; No NSP Left-to-Right åªçœ‹å·¦é‚Šçš„ context ç™¼ç¾åˆªé™¤ NSP æœƒé¡¯è‘—å‚·å®³å° QNLI ç­‰è³‡æ–™é›†çš„æ€§èƒ½ã€‚\nLTR åœ¨æ‰€æœ‰ä»»å‹™ä¸Šéƒ½æ¯” MLM å·®ã€‚\né›–ç„¶å¯ä»¥åƒ ELMo å–®ç¨è¨“ç·´ LTR å’Œ RTLï¼Œä¸¦ä¸”æŠŠä»–å€‘çµåˆèµ·ä¾†\nä½†æœ‰ä»¥ä¸‹ç¼ºé»ï¼š\næ¯”å–®å‘æ¨¡å‹è²´å…©å€ å° QA ä»»å‹™ä¸ç›´è§€ï¼Œå› ç‚º RTL ç„¡æ³•æ ¹æ“šå•é¡Œçµ¦å‡ºç­”æ¡ˆ ä¸å¦‚æ·±åº¦é›™å‘æ¨¡å‹å¼·å¤§ï¼Œå› ç‚ºå…¶å¯ä»¥ç›´æ¥åœ¨æ¯ä¸€å±¤çœ‹åˆ°å·¦å³çš„ context Feature-based Approach with BERT ä½œè€…ä¹Ÿç ”ç©¶äº†ç”¨ feature-based çš„æ•ˆæœï¼Œç™¼ç¾å…·å‚™ç«¶çˆ­åŠ›ã€‚\nåœ¨ä»–çš„å¯¦é©—ä¸­ï¼Œç”¨é è¨“ç·´ Transformer çš„ top 4 éš±è—å±¤çš„ token ä¸²è¡—æ•ˆæœæœ€å¥½ã€‚\n","date":"2023-08-05T00:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/bert-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"BERT è«–æ–‡é–±è®€"},{"content":"åœ–ç°¡ä»‹ Graph\nè¡¨ç¤º Entity (nodes) é–“çš„ relations (edges) çµ„æˆ Vertex attributes (V) Edge attributes and directions (E) Global attributes (U) ä¸‹æ–‡ç°¡ç¨± U, V, E å¯ä»¥è¡¨ç¤ºæˆåœ–çš„ç¯„ä¾‹\nImages ç›¸é„° pixel å»ºç„¡å‘é‚Š Text è©å’Œä¸‹ä¸€å€‹è©å»ºå–®å‘é‚Š Molecules åˆ†å­çš„é€£æ¥è™•å»ºç„¡å‘é‚Š Social networks äººå’Œäººä¹‹é–“å»ºç„¡å‘é‚Š å®šç¾©å•é¡Œ ç¨®é¡ Graph-level Node-level Edge-level å€‹åˆ¥è¬›çš„æ˜¯åŸºæ–¼ä»€éº¼æ±è¥¿åšåˆ†é¡ï¼Œæ¯”å¦‚å°æ¯å€‹äººï¼ˆnodeï¼‰åˆ†é¡ä¸€å€‹é™£ç‡Ÿï¼Œå°±ç®— Node-level æŒ‘æˆ° å„²å­˜é‚Šçš„é—œä¿‚ é„°æ¥çŸ©é™£ åœ¨ç¯€é»å¤šçš„æƒ…æ³ä¸‹ä½”ç”¨ç©ºé–“å¤§ï¼Œè€Œä¸”å¯èƒ½éå¸¸ç¨€ç– åŒä¸€å¼µåœ–ï¼Œæ›å€‹é»çš„é †åºå¾Œé„°æ¥çŸ©é™£çœ‹èµ·ä¾†å°±æœƒä¸åŒ é›£ä»¥ä¿è­‰é€™äº›æ±è¥¿é¤µå…¥ç¥ç¶“ç¶²è·¯å¾Œè¼¸å‡ºç›¸åŒ å¯ä»¥ç”¨å…©å€‹ listï¼Œä¸€å€‹å„²å­˜é‚Šçš„å‘é‡ï¼Œå¦ä¸€å€‹æ˜¯ Adjacency listï¼Œä¾åºç´€éŒ„é‚Šçš„é—œä¿‚ ç¨€ç–çŸ©é™£ é›£ä»¥ç”¨ GPU é‹ç®— Graph Neural Network GNN æ˜¯å°åœ–ä¸Šæ‰€æœ‰å±¬æ€§çš„ optimizable transformationï¼Œè€Œä¸”å¯ä»¥ä¿æŒ graph symmetries (permutation invariancesï¼ŒæŠŠ node æ’åºå¾Œçµæœä¸è®Š)\nä¸‹æ–‡ç”¨çš„ GNN æ˜¯ message passing neural network\ngraph-in, graph-out ä¸æ”¹è®Šåœ–çš„ connectivity æœ€ç°¡å–®çš„ GNN U, V, E å€‹åˆ¥é¤µçµ¦ä¸åŒçš„ MLPï¼Œçµ„æˆä¸€å€‹ GNN çš„ layer MLP å–®ç¨é¤µå…¥æ¯ä¸€å€‹é»ï¼Œä¸è€ƒæ…®é€£æ¥è¨Šæ¯ï¼Œä¿æŒäº† graph symmetries é æ¸¬ å‡å¦‚è¦å°æ¯å€‹é ‚é»åšé æ¸¬ï¼Œæœ€å¾Œå†åŠ å€‹å…¨é€£æ¥å±¤åˆ†é¡ pooling å‡å¦‚è¦å°ä¸€å€‹æ²’æœ‰å‘é‡çš„é ‚é»åšé æ¸¬ï¼Œæˆ‘å€‘å¯ä»¥ç”¨ poolingï¼Œè’é›†ç›¸é„°é‚Šå’Œå…¨å±€å‘é‡çš„è³‡è¨Š å°æ–¼æ²’æœ‰é ‚é»è³‡è¨Šçš„åœ–ï¼Œæˆ‘å€‘å¯ä»¥ç”¨ pooling layer ç²å–å…¨éƒ¨é»çš„è³‡è¨Šï¼Œå†åšåˆ†é¡ å°æ–¼æ²’æœ‰é‚Šè³‡è¨Šçš„åœ–ï¼Œæˆ‘å€‘ä¹Ÿå¯ä»¥ç”¨ pooling å»å¾ç›¸é„°é»å’Œå…¨å±€å‘é‡ç²å¾—è³‡è¨Š å°æ–¼æ²’æœ‰å…¨å±€å‘é‡çš„åœ–ï¼Œæˆ‘å€‘å¯ä»¥ç”¨ pooling å»å¾å…¨éƒ¨çš„é»æˆ–é‚Šç²å¾—è³‡è¨Š ç¼ºé™· ä¸­é–“çš„ layer æ²’æœ‰åˆ©ç”¨åœ–çš„è¨Šæ¯ï¼Œéƒ½æ˜¯å„è‡ªé€²å…¥å„è‡ªçš„ MLP åšè½‰æ› Passing messages åœ¨åšè½‰æ›å‰ï¼Œå…ˆåšä¸€äº› pooling\nåŒ¯èšé ‚é»è³‡è¨Š ä¸æ˜¯å–®å–®æŠŠé»å‘é‡é€²è¡Œè½‰æ›ï¼Œè€Œæ˜¯å’Œç›¸é„°çš„é»ä¸€èµ·åš aggregation å¾Œå†åšè½‰æ› å¦‚æœ aggregation æ˜¯åŠ ç¸½ï¼Œå’Œå·ç©æœ‰ä¸€é»åƒï¼Œåªä¸éæ˜¯æ¬Šé‡ä¸€æ¨£çš„ç‰ˆæœ¬ åŒ¯èšé ‚é»å’Œé‚Šçš„è³‡è¨Š å¯ä»¥å…ˆæŠŠé ‚é»åŒ¯èšçµ¦é‚Šï¼Œå†æŠŠé‚ŠåŒ¯èšå›é ‚é»ï¼Œåä¹‹äº¦ç„¶ é †åºä¸åŒæœƒå°è‡´ä¸åŒçµæœ å…©ç¨®æ–¹æ³•å¯ä»¥ä¸€èµ·åŒæ­¥åšï¼Œäº¤æ›¿æ›´æ–° å…¨å±€è³‡è¨Š æ¯æ¬¡ layer åªçœ‹é„°å±…ï¼Œè¦å‚³éåˆ°é çš„é»é ˆè¦èµ°å¾ˆå¤šå±¤ å°å…¥ master node (context vector)ï¼Œä»–é€£æ¥äº†æ‰€æœ‰çš„é»å’Œé‚Š ç›¸é—œä¸»é¡Œ æ¡æ¨£\nè€ƒé‡åˆ°è¨ˆç®—æ¢¯åº¦å¯èƒ½éœ€è¦å„²å­˜éå¤šçš„ä¸­é–“è³‡è¨Šï¼Œå¯ä»¥è€ƒæ…®æ¡æ¨£ä¸€äº›é»ï¼Œåªåœ¨å­åœ–ä¸Šåšè¨ˆç®— Batch\næ¯å€‹é»é„°å±…å„æ•¸ä¸åŒï¼Œä½¿åš batch æˆç‚ºæœ‰æŒ‘æˆ°æ€§çš„å•é¡Œã€‚ Inductive Bias\ngraph symmetries Aggregation\nç›®å‰æ²’æœ‰ä¸€å€‹æœ€ä½³é¸æ“‡ Graph Convolutional Network\nnode æ˜¯æ ¹æ“šé„°å±… node å»åšæŸç¨® aggregateï¼Œäº‹å¾Œå†åšæ›´æ–° ç”±æ–¼æ¯æ¬¡éƒ½çœ‹é„°å±…ï¼Œå‡å¦‚æœ‰ k å±¤ï¼Œå¯ä»¥æŠŠåœ–çœ‹åšè§£ n å€‹å­åœ–ï¼Œæ¯å€‹å­åœ–å°±æ˜¯åŸºæ–¼æ¯å€‹é»å»èµ° k æ­¥æ‰€å½¢æˆçš„ Graph Attention Network\nç”¨ attention æ±ºå®šå…¶å®ƒé»çš„æ¬Šé‡ï¼Œè€Œä¸åƒ GCN ä¸€æ¨£æŠŠé„°å±…åŠ èµ·ä¾† ","date":"2023-08-04T00:27:55+08:00","permalink":"https://roykesydon.github.io/Blog/p/gnn-%E4%BB%8B%E7%B4%B9/","title":"GNN ä»‹ç´¹"},{"content":"paper: Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset\nAbstract ç›®å‰çš„å‹•ä½œåˆ†é¡è³‡æ–™é›† (UCF-101 å’Œ HMDB-51) çš„å½±ç‰‡éå¸¸ç¼ºä¹ï¼Œä½¿è¾¨è­˜ã€Œè‰¯å¥½çš„å½±åƒæ¶æ§‹ã€è®Šå¾—å›°é›£ï¼Œ ä½¿å¤šæ•¸æ–¹æ³•åœ¨ç¾æœ‰çš„å°è¦æ¨¡ benchmark çš„è¡¨ç¾å·®ä¸å¤šã€‚ç‚ºæ­¤æœ¬æ–‡æ ¹æ“šæ–°çš„ Kinetics Human Action Video dataset å° SOTA æ¶æ§‹é€²è¡Œäº†é‡æ–°è©•ä¼°ã€‚\nKinetics æœ‰ 400 å€‹äººé¡å‹•ä½œé¡åˆ¥ã€‚æ¯å€‹é¡åˆ¥æœ‰ 400 å€‹ clipã€‚å¾ YouTube ä¸Šç²å–çš„ï¼Œè€Œä¸”æ¯å€‹ clip ä¾†è‡ª unique çš„ youtube å½±ç‰‡ã€‚\næœ¬æ–‡åˆ†æäº†ç•¶å‰æ¶æ§‹åœ¨ Kinetics ä¸Šå‹•ä½œåˆ†é¡ä»»å‹™çš„è¡¨ç¾ï¼Œä¹Ÿè©•ä¼° Kinetcis ç”¨ä½œé è¨“ç·´çš„æ•ˆæœã€‚\næœ¬æ–‡æå‡ºäº†ä¸€ç¨®åŸºæ–¼ 2D ConvNet inflation çš„ Two-Stream Inflated 3D ConvNet (I3D)ã€‚\nI3D çš„æ“´å±•æ–¹æ³•è®“ ImageNet ä¸Šå·²ç¶“å–å¾—æˆåŠŸçš„æ¶æ§‹å¯ä»¥è¢«åˆ©ç”¨åœ¨è§£æ±ºå½±åƒä»»å‹™ä¸Šã€‚\nçµæœè¡¨æ˜ï¼Œç¶“éåœ¨ Kinetics ä¸Šé è¨“ç·´å¾Œï¼ŒI3D åœ¨å‹•ä½œåˆ†é¡æ–¹é¢é¡¯è‘—æé«˜äº† SOTAï¼Œåœ¨ HMDB-51 ä¸Šé”åˆ° 80.9%ï¼Œåœ¨ UCF-101 ä¸Šé”åˆ° 98.0%ã€‚\nIntroduction åœ¨ ImageNet ä¸Šé è¨“ç·´æ¨¡å‹çš„æ•ˆæœå¾ˆå¥½ï¼Œä½†åœ¨å½±ç‰‡é ˜åŸŸï¼Œé è¨“ç·´æˆæ•ˆä¸€ç›´æ˜¯ä¸€å€‹æœªçŸ¥çš„å•é¡Œã€‚å› ç‚ºæµè¡Œçš„å‹•ä½œè­˜åˆ¥ benchmark éƒ½éå¸¸å°ï¼Œç´„ç•¥åªæœ‰ 10k å€‹å½±ç‰‡ã€‚\nKinetics æœ‰ 400 å€‹äººé¡å‹•ä½œé¡åˆ¥ã€‚æ¯å€‹é¡åˆ¥æœ‰ 400 å€‹ clipï¼Œè€Œä¸”æ¯å€‹ clip éƒ½ä¾†è‡ªä¸€å€‹ unique çš„ Youtube å½±ç‰‡ã€‚\næœ¬æ–‡å¯¦é©—ç­–ç•¥æ˜¯åœ¨ Kinetics ä¸Šé è¨“ç·´ï¼Œå†åœ¨ HMDB-51 å’Œ USC-101 ä¸Šå¾®èª¿ï¼Œçµæœé¡¯ç¤ºå‡ºé è¨“ç·´ç¸½æ˜¯èƒ½æé«˜æ€§èƒ½ï¼Œä½†æå‡å¤šå¯¡å› æ¶æ§‹è€Œç•°ã€‚\næœ¬æ–‡æå‡ºæ–°æ¶æ§‹ï¼Œç¨±ç‚ºã€ŒTwo-Stream Inflated 3D ConvNetsã€(I3D)ï¼Œå»ºç«‹åœ¨ SOTA çš„å½±åƒåˆ†é¡æ¶æ§‹ä¸Šï¼Œä¸¦å°‡ filters å’Œ pooling kernel è†¨è„¹æˆ 3Dã€‚\nåŸºæ–¼ Inceptionv1 çš„ I3D åœ¨ Knetics ä¸Šé è¨“ç·´å¾Œï¼Œæ€§èƒ½é è¶…éç•¶å‰çš„ SOTA æ¶æ§‹ã€‚\nåœ¨æœ¬æ–‡çš„æ¨¡å‹ä¸­ï¼Œä¸¦æ²’æœ‰è€ƒæ…®æ›´å¤šç¶“å…¸æ–¹æ³•ï¼Œæ¯”å¦‚ bag-of-visual-words representationï¼Œä½† Kinetics æ˜¯å…¬é–‹çš„ï¼Œå› æ­¤å…¶ä»–äººå¯ä»¥é€²è¡Œå¾ŒçºŒç ”ç©¶ã€‚\nAction Classification Architectures ç›®å‰å½±ç‰‡æ¶æ§‹ä¸­çš„ä¸€äº›ä¸»è¦å€åˆ¥å¦‚ä¸‹ï¼š\nå·ç©æ˜¯ 2D é‚„ 3D çš„ æ˜¯å¦åªæ˜¯ RGB å½±ç‰‡ï¼Œé‚„æ˜¯åŒ…å«äº‹å…ˆè¨ˆç®—çš„ optical flow å°æ–¼ 2D ConvNetsï¼Œè¨Šæ¯æ˜¯æ€éº¼åœ¨ frame ä¹‹é–“å‚³éçš„ é€™éƒ¨åˆ†å¯ä»¥ä½¿ç”¨ temporally-recurrent layersï¼Œæ¯”å¦‚ LSTMï¼Œæˆ–æ˜¯ç”¨éš¨æ™‚é–“çš„ feature aggregation ä¾†å®Œæˆã€‚ åœ¨æœ¬æ–‡ä¸­ï¼Œè€ƒæ…®äº†æ¶µè“‹å¤§éƒ¨åˆ†ç¾æœ‰æ¶æ§‹çš„æ¨¡å‹å­é›†ï¼š\n2D ConvNets é ‚éƒ¨æœ‰ LSTM çš„ ConvNet æœ‰å…©ç¨® stream fusion çš„ two-stream networks 3D ConvNets C3D ç”±æ–¼åƒæ•¸ç¶­åº¦è¼ƒé«˜ï¼Œä»¥åŠç¼ºä¹ labeled video dataï¼Œä»¥å‰çš„ 3D ConvNet ç›¸å°è¼ƒæ·ºï¼ˆæœ€å¤š 8 å±¤ï¼‰ã€‚\næœ¬æ–‡ç™¼ç¾è«¸å¦‚ VGG-16 å’Œ ResNet ç­‰å¾ˆæ·±çš„å½±åƒåˆ†é¡ç¶²è·¯å¯ä»¥è¼•é¬†æ“´å±•æˆ spatio-temporal feature extractorsï¼Œä¸¦ä¸”ä»–å€‘çš„é è¨“ç·´æ¬Šé‡ä¹Ÿå¯ä»¥æä¾›æœ‰åƒ¹å€¼çš„åˆå§‹åŒ–ã€‚\næœ¬æ–‡ä¹Ÿç™¼ç¾ two-stream çš„ä½œæ³•ä¾ç„¶æœ‰ç”¨ã€‚\nfig2. K æ˜¯å½±ç‰‡ä¸­çš„ frame çš„ç¸½æ•¸ï¼ŒN æ˜¯ç›¸é„° frames çš„å­é›†åˆã€‚\nä¸Šåœ–æ˜¯æœ¬æ–‡å¯¦é©—çš„äº”ç¨®æ¶æ§‹ï¼Œå‰å››ç¨®æ˜¯ä¹‹å‰çš„åšæ³•ï¼Œæœ€å¾Œä¸€ç¨®æ˜¯æå‡ºçš„æ–°ä½œæ³•ã€‚ ä¸Šåœ–ä¸­é™¤äº† C3D å¤–éƒ½æœ‰ç”¨åˆ° ImageNet é è¨“ç·´çš„æ¨¡å‹ã€‚\næ™‚é–“æ˜¯æ ¹æ“š input çš„ frame æ›ç®—å‡ºä¾†çš„ï¼Œfps æ˜¯ 25ï¼Œé™¤äº† LSTM é‚£å€‹æ¯”è¼ƒç‰¹åˆ¥ï¼Œå› ç‚º LSTM é‚£å€‹æ˜¯æ¯ 5 frame å– 1 frameï¼Œæ‰€ä»¥æ™‚é–“æ˜¯ 5 å€ã€‚\nä¹‹å‰çš„åšæ³• ConvNet+LSTM\næœ‰ä¸€ç¨®åšæ³•æ˜¯æŠŠæ¯å€‹ frame ç¨ç«‹é¤µçµ¦ 2D Convï¼Œç„¶å¾Œå†æŠŠé æ¸¬åšå½™æ•´ï¼Œç¬¦åˆ bag of words image modeling çš„ç²¾ç¥ï¼Œä½†é€™æ¨£æœƒå¿½ç•¥æ™‚é–“çµæ§‹ä¸Šçš„è³‡è¨Šï¼Œæ¯”å¦‚ç„¡æ³•åˆ¤æ–·é–‹é–€æˆ–é—œé–€ã€‚\næ‰€ä»¥æœ€å¥½åœ¨å¾Œé¢åŠ ä¸€å€‹ recurrent layerï¼Œæ‰€ä»¥é€™é‚Šå°±ç”¨ Inception-V1 çµåˆ LSTMã€‚\nåŸå§‹çš„å½±ç‰‡ stream æ˜¯ 25 fpsï¼Œé€™é‚Šæ¯ 5 frame æ¡æ¨£ä¸€æ¬¡ã€‚\n3D ConvNets\nå’Œä¸€èˆ¬çš„å·ç©ç¥ç¶“ç¶²è·¯å·®ä¸å¤šï¼Œåªæ˜¯å…·æœ‰ spatio-temporal filtersã€‚\nä½†ç”±æ–¼é¡å¤–çš„ kernel ç¶­åº¦ï¼Œç›¸æ¯” 2D Conv æœƒæœ‰æ›´å¤šåƒæ•¸ï¼Œä¹Ÿä½¿ä»–å€‘æ›´é›£è¨“ç·´ã€‚\nè€Œä¸”é€™æ¨£æœƒç„¡æ³•ç™¼æ® ImageNet é è¨“ç·´çš„å¥½è™•ï¼Œå› æ­¤ä¹‹å‰çš„å·¥ä½œéƒ½å®šç¾©äº†ç›¸å°æ·ºå±¤çš„æ¶æ§‹ï¼Œä¸¦ä¸”å¾é ­è¨“ç·´ã€‚\nbenchmark ä¸­çš„è¡¨ç¾å‚™å—æœŸå¾…ï¼Œä½†å’Œ SOTA æ¯”æ²’æœ‰ç«¶çˆ­åŠ›ï¼Œä¹Ÿå› æ­¤æˆç‚ºæœ¬æ–‡å¯¦é©—çš„è‰¯å¥½å€™é¸è€…ã€‚\næœ¬æ–‡ç”¨çš„æ˜¯ C3D çš„å°è®Šé«”ï¼Œå·®ç•°åœ¨æ–¼æ‰€æœ‰å·ç©å±¤å’Œ FC å±¤çš„å¾Œé¢éƒ½ç”¨äº† BNã€‚ è€Œä¸”åœ¨ç¬¬ä¸€å€‹ pooling layer ç”¨çš„ stride æ˜¯ 2ï¼Œå¥½æ¸›å°‘è¨˜æ†¶é«”çš„ä½¿ç”¨ï¼Œæ¯”ç”¨æ›´å¤§çš„ batchï¼Œé€™åœ¨ BN ä¸­éå¸¸é‡è¦ã€‚\nTwo-Stream Networks\nRoyï¼šé€™è£¡ç”±æ–¼æ¯”è¼ƒè¤‡é›œï¼Œæˆ‘è¦æ”¹æ two-stream çš„åŸå§‹è«–æ–‡ï¼ˆTwo-Stream Convolutional Networks for Action Recognition in Videosï¼‰èªªæ˜é€™æ±è¥¿æ˜¯ä»€éº¼\nç°¡è€Œè¨€ä¹‹å°±æ˜¯åˆ†æˆå…©å€‹éƒ¨åˆ†ï¼š\nç©ºé–“è³‡è¨Šï¼š\nç”¨å½±ç‰‡çš„ä¸€å€‹ frameã€€ç¶“éå·ç©ç¥ç¶“ç¶²è·¯é”æˆï¼Œé€™å€‹ frame ç”¨ä¾†æå–å½±åƒä¸­çš„ç‰©ä»¶è³‡è¨Šï¼Œæ¯”å¦‚æ‰“æ’çƒé€™å‹•ä½œå¯èƒ½è¾¨è­˜å‡ºæ’çƒå°±éå¸¸å¥½åˆ¤å®šï¼Œæ‰€ä»¥ç”¨æŸå€‹ frame ä¾†æå–ç©ºé–“è³‡è¨Šã€‚\nå‹•ä½œè³‡è¨Šï¼š\né€™é‚Šç”¨ä¸€é€£ä¸²çš„å…‰æµï¼ˆoptical flowï¼‰åœ–ä¾†é”æˆï¼Œå…‰æµæ˜¯ç‰©é«”ï¼ˆpixelï¼‰åœ¨å…©å€‹ frame é–“çš„ä½ç§»å‘é‡ï¼Œä¼°è¨ˆæ–¹æ³•æœ‰å¾ˆå¤šï¼Œé€™è£¡ä¸ä¸€ä¸€èˆ‰ä¾‹ã€‚\nä¸Šåœ–å‡ºè‡ª Two-Stream Convolutional Networks for Action Recognition in Videosï¼Œåœ– c å°±æ˜¯å…‰æµï¼Œå…·æœ‰å…©å€‹æ–¹å‘ï¼ŒæŒ‡å‡ºåƒç´ çš„ä½ç§»ï¼Œåœ– d æ˜¯æ°´å¹³æ–¹å‘çš„è¦–è¦ºåŒ–ï¼Œåœ– e æ˜¯å‚ç›´æ–¹å‘çš„è¦–è¦ºåŒ–ã€‚\nå†æŠŠé€™äº›å…‰æµåœ–é¤µçµ¦å·ç©ç¥ç¶“ç¶²è·¯ï¼Œç”¨ä½œå‹•ä½œè³‡è¨Šçš„åˆ¤åˆ¥ã€‚\nå€¼å¾—ä¸€æçš„æ˜¯ä»–æ˜¯ late fusionï¼Œè€Œä¸”æ˜¯ç”¨åŠ æ¬Šå¹³å‡ï¼Œä¸æ˜¯åƒä¸€èˆ¬æƒ³çš„æŠŠç‰¹å¾µçµåˆå†åšå…¶ä»–è™•ç†ã€‚\nThe New: Two-Stream Inflated 3D ConvNets ä½œè€…æŠŠæˆåŠŸçš„ 2D åˆ†é¡æ¨¡å‹ç°¡å–®åœ°è½‰æ›ç‚º 3D\nInflating åšæ³•æ˜¯æŠŠæ–¹å½¢çš„ filter æ”¹æˆç«‹æ–¹é«”ï¼ŒæŠŠ N x N çš„ filter æ”¹æˆ N x N x N çš„ filterï¼Œä½†é€™åªæœ‰æ¶æ§‹ä¸Šçš„åƒè€ƒã€‚\nBootstraping æŠŠæ¬Šé‡ä¹Ÿçµ¦è½‰æ›åˆ° 3D æ¶æ§‹çš„æ–¹æ³•ã€‚\nä½œè€…è§€å¯Ÿåˆ°å½±åƒå¯ä»¥é€éåè¦†è¤‡è£½è²¼ä¸Šä¾†ç”Ÿå‡ºä¸€å€‹ã€Œä¸æœƒå‹•çš„ç„¡èŠå½±ç‰‡ã€ï¼Œ é€éé€™äº›å½±ç‰‡ï¼Œ3D æ¨¡å‹å¯ä»¥é€éé€™ç¨®æ–¹å¼åœ¨ ImageNet ä¸Š implicitly pretrainï¼Œåšæ³•å°±æ˜¯è®“ 3D filter åƒç„¡èŠå½±ç‰‡çš„è¼¸å‡ºå’Œ 2D filter åƒå–®ä¸€ frame çš„è¼¸å‡ºç›¸åŒï¼Œåšæ³•å¦‚ä¸‹ï¼š\næˆ‘å€‘å¯ä»¥æ²¿æ™‚é–“ç¶­åº¦é‡è¤‡ 2D filter N æ¬¡ï¼ŒæŠŠé€™æ¬Šé‡çµ¦ 3D filterï¼ŒåŒæ™‚æŠŠæ¬Šé‡é™¤ä»¥ Nï¼Œé”åˆ°é€™ç¨®æ•ˆæœã€‚\nPacing receptive field growth in space, time and network depth ä»¥å¾€åœ¨åœ–ç‰‡ä¸Šå°æ°´å¹³å’Œå‚ç›´è»¸çš„å°å¾…æ˜¯å¹³ç­‰çš„ï¼Œpooling kernel å’Œ stride éƒ½ä¸€æ¨£ã€‚ ä½¿æ„Ÿå—é‡åœ¨å…©å€‹ç¶­åº¦ä¸Šéš¨è‘—æ¨¡å‹è¶Šä¾†è¶Šæ·±ï¼Œæ…¢æ…¢å¹³ç­‰å¢é•·ã€‚\nä½†æ˜¯æ™‚é–“è»¸ç”¨å°ç¨±çš„æ„Ÿå—é‡ä¸ä¸€å®šæœ€å¥½ï¼Œè€Œè©²å–æ±ºæ–¼ frame rate å’Œ image dimensinosã€‚ å¦‚æœæ™‚é–“ç›¸å°æ–¼ç©ºé–“å¢é•·å¤ªå¿«ï¼Œå¯èƒ½æœƒæ··æ·†ä¸åŒå°è±¡çš„é‚Šç·£ï¼Œå½±éŸ¿æ—©æœŸçš„ç‰¹å¾µæª¢æ¸¬ã€‚å¦‚æœå¢é•·å¤ªæ…¢ï¼Œå¯èƒ½ç„¡æ³•å¾ˆå¥½åœ°æ•æ‰å ´æ™¯å‹•æ…‹ã€‚\nå¯¦é©—ä¸­ï¼Œè¼¸å…¥å½±ç‰‡çš„ fps æ˜¯ 25ã€‚\nä½œè€…ç™¼ç¾åœ¨å‰å…©å€‹ max pooling layer ä¸åœ¨æ™‚é–“è»¸ poolingï¼ˆé€éç”¨ 1 x 3 x 3 çš„ kernelï¼Œä¸¦ä¸”æ™‚é–“è»¸çš„ stride æ˜¯ 1ï¼‰ï¼Œä¸¦åœ¨å…¶ä»– max pooling layer éƒ½ç”¨ symmetric kernels å’Œ stride æ˜¯æœ‰å¹«åŠ©çš„ã€‚\næœ€å¾Œçš„ average pooling layer æ˜¯ç”¨ 2 x 7 x 7 çš„ kernelã€‚\nä½œè€…ç”¨ 64 frame è¨“ç·´ï¼Œä½†ç”¨æ•´å€‹å½±ç‰‡æ¸¬è©¦ã€‚ï¼ˆaveraging predictions temporallyï¼‰\næˆ‘æƒ³äº†ä¸€ä¸‹ï¼Œ250 / 64 é™¤ä¸é€²ï¼Œä½†æ˜¯æˆ‘çœ‹ code ç™¼ç¾ä»–å¥½åƒå¯¬é«˜ 224 * 224 çš„ç…§ç‰‡æœƒåœ¨æœ€å¾Œç¶“é Average pool å¾Œè®Šæˆ 1 * 1ï¼Œæ‰€ä»¥ä»–å¯ä»¥ç›´æ¥ç”¨ 1 * 1 * 1 çš„å·ç©æ ¸æŠŠè¼¸å…¥é€šé“æ”¹æˆåˆ†é¡æ•¸ï¼Œå†æŠŠæ™‚é–“è»¸çš„çµæœå¹³å‡ã€‚\nTwo 3D Streams åˆ†åˆ¥è¨“ç·´å…©å€‹ç¶²è·¯ï¼Œä¸¦åœ¨æ¸¬è©¦éšæ®µå°é æ¸¬é€²è¡Œå¹³å‡ã€‚\né€™é‚Šä½œè€…èªªå…‰æµçš„æ¼”ç®—æ³•æŸç¨®æ„ç¾©ä¸Šæ˜¯ recurrentï¼ˆä¾‹å¦‚ï¼Œå°æ–¼ flow fields é€²è¡Œ iterative optimizationï¼‰ï¼Œæˆ‘ä¸å¤ªæ‡‚é€™é‚Šæ˜¯ä»€éº¼æ„æ€ï¼Œæˆ‘æƒ³ä½œè€…ç”¨çš„å…‰æµæ¼”ç®—æ³•æ‡‰è©²æ˜¯é€éæŸç¨®é¡ä¼¼ EM æ¼”ç®—æ³•é‚£ç¨®ä¸æ–·è¿­ä»£å»é€¼è¿‘æ•¸å€¼çš„æ¼”ç®—æ³•ï¼Œä½†ä½œè€…æåˆ°ã€Œæˆ–è¨±æ˜¯å› ç‚ºç¼ºä¹ recurrenceï¼Œæˆ‘å€‘ç™¼ç¾é›™æµæœ‰åƒ¹å€¼ã€ï¼Œæˆ‘ä¸å¤ªæ‡‚ç‚ºä»€éº¼éœ€è¦ recurrence æ•ˆæœæ‰æœƒå¥½ã€‚\nä½†çµè«–æ˜¯ two-stream ä¾ç„¶å…·å‚™åƒ¹å€¼ã€‚\nImplementation Details é€™é‚Šè¬›æ»¿è©³ç´°çš„ï¼Œæœ‰èˆˆè¶£å¯ä»¥å»åŸæ–‡çœ‹ã€‚ åªæä¸€ä¸‹å¹¾é»:\nå…‰æµæ¼”ç®—æ³•æ˜¯ç”¨ TV-L1ã€‚ é™¤äº†é¡ä¼¼ C3D çš„ 3D ConvNet éƒ½ç”¨ä½¿ç”¨ ImageNet é è¨“ç·´çš„ Inception-V1 ä½œç‚º base networkã€‚ å°æ–¼è¼ƒçŸ­çš„å½±ç‰‡ï¼Œæœƒé‡è¤‡å¾ªç’°ä»¥æ»¿è¶³æ¨¡å‹çš„è¼¸å…¥ä»‹é¢ æ¸¬è©¦æ™‚æœƒåœ¨ä¸­é–“å‰ªè£ 224 x 224 The Kinetics Human Action Video Dataset Kinetics æœ‰ 400 å€‹äººé¡å‹•ä½œé¡åˆ¥ã€‚æ¯å€‹é¡åˆ¥æœ‰ 400 å€‹ clipï¼Œè€Œä¸”æ¯å€‹ clip éƒ½ä¾†è‡ªä¸€å€‹ unique çš„ Youtube å½±ç‰‡ï¼Œå…±æœ‰ 24 è¬å€‹è¨“ç·´å½±ç‰‡ã€‚\næ¯å€‹ clip éƒ½å¤§ç´„ 10 ç§’ï¼Œè€Œä¸”æ²’æœ‰æœªå‰ªçš„å½±ç‰‡ã€‚\næ¸¬è©¦é›†æ¯å€‹ class åŒ…å« 100 å€‹ clipã€‚\nExperimental Comparison of Architectures I3D åœ¨æ‰€æœ‰è³‡æ–™é›†ä¸Šéƒ½è¡¨ç¾æœ€å¥½ï¼Œç”šè‡³æ˜¯åœ¨ UCF-101 å’Œ HMDB-51 é€™ç¨®å°è³‡æ–™é›†ä¸Šä¹Ÿæ˜¯å¦‚æ­¤ï¼Œé€™æ„å‘³è‘— ImageNet é è¨“ç·´çš„å¥½è™•æœ‰æˆåŠŸæ“´å±•åˆ° 3D ConvNetã€‚\nå¤šæ•¸æ¨¡å‹åœ¨ UCF ä¸Šéƒ½è¡¨ç¾å¾—æ¯” Kinetics ä¸Šå¥½ï¼Œé¡¯ç¾å‡ºè³‡æ–™é›†çš„é›£åº¦å·®è·ã€‚\nä½†æ˜¯åœ¨ HMDB è¡¨ç¾å¾—è¼ƒå·®ï¼ŒåŸå› å¯èƒ½æ˜¯ HMDB æ•…æ„å¼„å¾—å¾ˆé›£ï¼Œä½œè€…æœ‰èˆ‰ä¾‹ï¼Œå¾ˆå¤š clip åœ¨å®Œå…¨ç›¸åŒçš„å ´æ™¯æœƒæœ‰ä¸åŒçš„å‹•ä½œã€‚\nä½œè€…æœ‰æåˆ°èªª I3D ç‰¹å¾µæ¯”è¼ƒå¥½é·ç§»çš„ä¸€ç¨®è§£é‡‹æ˜¯å®ƒå…·å‚™ high temporal resolutionï¼Œ I3D åœ¨ 25 fps çš„å½±ç‰‡ä¸­ç”¨ 64 frames åšè¨“ç·´ï¼Œä½¿å®ƒèƒ½æ•æ‰å‹•ä½œçš„ fine-grained æ™‚é–“çµæ§‹ã€‚\nExperimental Evaluation of Features Kinetics ä¸Šåšé è¨“ç·´æ•ˆæœæ˜é¡¯æ¯” ImageNet å¥½ã€‚\nDiscussion Kinetics ä¸Šçš„é è¨“ç·´å°æ–¼é·ç§»å­¸ç¿’æœ‰æ˜é¡¯å¥½è™•ï¼Œä½†å°æ–¼å…¶ä»–å½±åƒä»»å‹™ï¼Œæ¯”å¦‚å½±åƒèªç¾©åˆ†å‰²æ˜¯å¦æœ‰å¥½è™•ä»å¾…è§€å¯Ÿã€‚\nç›®å‰å°æ–¼æ¶æ§‹æ²’æœ‰å…¨é¢æ¢ç´¢ï¼Œæ¯”å¦‚æ²’æœ‰æ¡ç”¨ action tubes æˆ–æ˜¯ attention æ©Ÿåˆ¶ã€‚\n","date":"2023-07-23T00:27:55+08:00","permalink":"https://roykesydon.github.io/Blog/p/i3d-%E8%AB%96%E6%96%87/","title":"I3D è«–æ–‡"},{"content":"å‰è¨€ è¦å¼„ Hololens 2 çš„é–‹ç™¼ç’°å¢ƒè¦ä¸€å †æœ‰çš„æ²’çš„éº»ç…©æ±è¥¿ï¼Œç´€éŒ„ä¸€ä¸‹é¿å…ä¹‹å¾Œè¦é‡è£\nåŸæœ¬å¾ˆæ€•ç‰ˆæœ¬å°ä¸ä¸Šå¾ˆéº»ç…©ï¼Œä½†å¯¦éš›ç”¨èµ·ä¾†å¥½åƒé‚„å¥½\næ³¨æ„ï¼Œé€™ä¸æ˜¯æœ€å°å®‰è£ï¼Œæœ‰äº›æ±è¥¿æˆ‘ä¸ç¢ºå®šæ˜¯ä¸æ˜¯å¿…è¦çš„ï¼Œä½†æˆ‘æ€•éº»ç…©å°±è£äº†\nå¾ŒçºŒè«‹åƒè€ƒå¾®è»Ÿçš„æ•™å­¸\næˆ‘å€‹äººçš„ç‰ˆæœ¬ç´€éŒ„ (2023/07/03) Unity 2021.3.27f1 (LTS) MRTK 2.8.3 Visual Studio 2022 Mixed Reality OpenXR Plugin 1.8.0 ä½œæ¥­ç³»çµ±è¦æ±‚ å¿…é ˆæ˜¯ Windows å°ˆæ¥­ç‰ˆä»¥ä¸Šï¼Œå› ç‚ºè¦ç”¨ Hyper-V å…ˆå» BIOS é–‹ Virtualization Technology é–‹å•Ÿ Hyper-V å‰ç½®æ­¥é©Ÿ å®‰è£ windows SDK\nè½èªªè£å®Œæœ€æ–°çš„å¾Œï¼Œå»ºè­°å†å¤šè£å¹¾å€‹ç‰ˆæœ¬ æˆ‘å€‹äººåªæœ‰è£æœ€æ–°çš„ å®‰è£ visual studio\nå¥½åƒæœƒæ ¹æ“š MRTK çš„ç‰ˆæœ¬æœ‰å°æ‡‰çš„ç‰ˆæœ¬è¦æ±‚ï¼Œä¸èƒ½ç„¡è…¦è£æœ€æ–° æ“šèªªè¦é¸ ã€ŒC++ é–‹ç™¼ã€å’Œã€Œé€šç”¨ Windows å¹³å°é–‹ç™¼ã€ å³é‚Šå¥½åƒé‚„è¦é¸ USB è¨­å‚™é€£æ¥ C++ é€šç”¨ Windows å¹³å°å·¥å…· å®‰è£ Hololens 2 æ¨¡æ“¬å™¨\né€™æ˜¯çµ¦ build å¥½çš„ç¨‹å¼ç”¨çš„ï¼Œä¸æ˜¯åœ¨èªª Unity Editor è£¡é¢çš„æ‰‹ å®‰è£ Unity\nå»ºè­°é€é Unity Hub ç®¡ç† Unity ç‰ˆæœ¬ æ“šèªªè£çš„ Unity è¦è£ä»¥ä¸‹å…©å€‹ module Universal Windows Platform Build Support Windows Build Support (IL2CPP) Windows å’Œ Hololens éƒ½è¦é–‹å•Ÿã€Œé–‹ç™¼è€…æ¨¡å¼ã€\nä¸‹è¼‰ Mixed Reality Feature Tool\næ³¨æ„çœ‹é€™ä¸æ˜¯ MRTK é€™å¯ä»¥å¾€ Unity å°ˆæ¡ˆå°å…¥ MRTK å¯ä»¥å°å…¥ MRTK 2.6 ä»¥å¾Œçš„å·¥å…·åŒ… å‰µå»ºå°ˆæ¡ˆ Unity é–‹å€‹ 3D å°ˆæ¡ˆ\nFile -\u0026gt; Build Settings é¸æ“‡ Universal Windows Platform é»é¸ Switch Platform é–‹å•Ÿ Mixed Reality Feature Tool\né‡å°å°ˆæ¡ˆå®‰è£ MRTK å¿…è£\nMRTK Foundation Mixed Reality OpenXR Plugin å¯é¸\nMRTK Examples Extensions Tools TestUtilities å‰©ä¸‹çš„çœ‹å¾®è»Ÿå°ˆæ¡ˆå»ºç½®æ•™å­¸ï¼Œå¯¦åœ¨å¤ªå¤šè¦å¼„äº†\nåœ¨æ¨¡æ“¬å™¨ä¸ŠåŸ·è¡Œ é€™å‘çœŸçš„æœ‰å¤ å¤šï¼Œæˆ‘çµåˆä¸Š stack overflow çš„è§£æ³•ï¼Œæ‰€ç”¨çš„æ­¥é©Ÿ:\nè¦ç”¨ç®¡ç†å“¡æ¨¡å¼é–‹ Visual Studioï¼Œä¸ç„¶æœ‰å¯èƒ½é‡åˆ°æ¬Šé™å•é¡Œ\nVisual studio è¦éƒ¨å±¬ç¨‹å¼çš„æ™‚å€™ï¼Œæœƒè‡ªå·±é–‹ä¸€å€‹ Hololens 2 Simulatorï¼Œä½†ä»–æœƒé–‹è¶…ä¹…ï¼Œç„¶å¾Œé€ æˆ Timeoutï¼Œç„¡æ³•éƒ¨å±¬ï¼Œéƒ¨å±¬å¤±æ•—å¾Œä¸è¦é¸ç¹¼çºŒï¼Œä¹Ÿä¸è¦é—œæ‰æ¨¡æ“¬å™¨\né€™æ™‚å€™å†çœ‹æƒ…æ³æŒ‰ å¯¦å¿ƒ / ç©ºå¿ƒç¶ è‰²ä¸‰è§’å½¢ (without debugging)\næœ‰å¯èƒ½å¯ä»¥ deployï¼Œä½†é‹è¡Œæ™‚æœ‰å•é¡Œï¼Œæ­¤æ™‚æŒ‰ç´…è‰²æ–¹å¡Šçµ‚æ­¢ï¼Œç¹¼çºŒç¶ è‰²ä¸‰è§’å½¢ï¼Œä¸è¦é—œæ‰æ¨¡æ“¬å™¨\n","date":"2023-07-03T00:00:01+08:00","permalink":"https://roykesydon.github.io/Blog/p/hololens-2-%E9%96%8B%E7%99%BC%E7%92%B0%E5%A2%83%E8%A8%AD%E7%BD%AE/","title":"Hololens 2 é–‹ç™¼ç’°å¢ƒè¨­ç½®"},{"content":"Use Cases Cache æŠŠå¸¸ç”¨çš„è³‡æ–™å›å‚³ï¼Œçœç•¥é•·æ™‚é–“çš„ IO æ“ä½œ Shared Session åœ¨ stateless server é–“å…±äº« session Distributed lock ç”¨åœ¨ç¨‹å¼é–“æƒ³å…±ç”¨æŸç¨®è³‡æºçš„æ™‚å€™ ç”¨ setnx (set if not exists) atomic Rate Limiter ç”¨ increment å’Œ expiration å¯¦ç¾ Feature NoSQL In-memory Key-Value Basic Command redis-server default port: 6379 redis-cli Access data set \u0026lt;key\u0026gt; \u0026lt;value\u0026gt;\nPretty much everything stored in Redis is going to be a type of string by default get \u0026lt;key\u0026gt;\ndel \u0026lt;key\u0026gt;\nexists \u0026lt;key\u0026gt;\nkeys \u0026lt;pattern\u0026gt;\nfind keys with certain pattern keys * get all keys flushall\nget rid of everything Expiration ttl \u0026lt;key\u0026gt;\nshow time to live \u0026ldquo;-1\u0026rdquo; for no expiration \u0026ldquo;-2\u0026rdquo; already expired expire \u0026lt;key\u0026gt; \u0026lt;second\u0026gt;\nsetex \u0026lt;key\u0026gt; \u0026lt;seconds\u0026gt; \u0026lt;value\u0026gt;\nset with expiration Data Structure List lpush/rpush \u0026lt;key\u0026gt; \u0026lt;value\u0026gt; lrange \u0026lt;key\u0026gt; \u0026lt;start index\u0026gt; \u0026lt;end index\u0026gt; \u0026lt;end index\u0026gt; can be -1 lpop/rpop \u0026lt;key\u0026gt; Set sadd \u0026lt;key\u0026gt; \u0026lt;value\u0026gt; smembers \u0026lt;key\u0026gt; srem \u0026lt;key\u0026gt; \u0026lt;value\u0026gt; remove Hash Key-value in Key-value\nhset \u0026lt;key\u0026gt; \u0026lt;field\u0026gt; \u0026lt;value\u0026gt; hget \u0026lt;key\u0026gt; \u0026lt;field\u0026gt; hgetall \u0026lt;key\u0026gt; get everything about \u0026lt;key\u0026gt; hdel hexists \u0026lt;key\u0026gt; \u0026lt;field\u0026gt; Redis doesn\u0026rsquo;t support nested hash struct åˆªé™¤éæœŸ key å®šæœŸåˆªé™¤ åœ¨å›ºå®šé–“éš”æ™‚é–“éš¨æ©ŸæŠ½ key æª¢æŸ¥ä¸¦åˆªé™¤\næƒ°æ€§åˆªé™¤ åœ¨è¨ªå• key çš„æ™‚å€™ç™¼ç¾éæœŸå°±åˆªé™¤\nmaxmemory-policy (Eviction) å¯ä»¥è¨­å®šé€™äº› policyï¼Œåœ¨è¨˜æ†¶é«”ä¾ç„¶é¡æ»¿çš„æƒ…æ³ä¸‹åšå°æ‡‰çš„è™•ç†\nnoeviction allkeys-lru allkeys-lfu volatile-lru volatile-lfu allkeys-random volatile-random volatile-ttl å¿«å–æƒ…å¢ƒå•é¡Œ å¿«å–é›ªå´© Cache Avalanche æŸå€‹æ™‚åˆ»å¤§é‡ cache å¤±æ•ˆï¼Œä½¿è³‡æ–™åº«éœ€è¦æ‰¿æ“”å¾ˆå¤§çš„æµé‡ã€‚ è§£æ³• å¹« cache åŠ ä¸Šé¡å¤–çš„éš¨æ©ŸéæœŸæ™‚é–“ å¿«å–æ“Šç©¿ Hotspot Invalid æŸå€‹ hotspot çš„ cache å¤±æ•ˆï¼Œä½¿å¤§é‡è«‹æ±‚è·‘åˆ°è³‡æ–™åº« è§£æ³• è®“ hotspot æ°¸ä¸éæœŸ æŸ¥è©¢è³‡æ–™åº«çš„éƒ¨åˆ†åŠ ä¸Š lock å¿«å–ç©¿é€ Cache Penetration client request ä¸å­˜åœ¨çš„è³‡æ–™ï¼Œå› ç‚ºåŒæ™‚ä¸å­˜åœ¨æ–¼ cache å’Œè³‡æ–™åº«ä¸­ï¼Œæ‰€ä»¥ç›´æ¥è·‘åˆ°è³‡æ–™åº« è§£æ³• åœ¨ application å…ˆéæ¿¾æ‰éæ³•è«‹æ±‚ Bloom Filter å¸ƒéš†éæ¿¾å™¨ Persistence RDB å›ºå®šæ™‚é–“å°æ‰€æœ‰è³‡æ–™åšå¿«ç…§ï¼Œmemory dump å‡ºä¾† recovery æ¯” AOF å¿« saveã€bgsave AOF ç´€éŒ„æ“ä½œæµç¨‹ æª”æ¡ˆæ¯”è¼ƒè‚¥ Rewrite ç•¶ AOF å¤ªå¤§ï¼ŒRedis æœƒç”Ÿä¸€å€‹æ–°æ–‡ä»¶å–ä»£èˆŠçš„ï¼Œç”¨æœ€å°‘æ“ä½œç”Ÿå‡ºç›®å‰çš„è³‡æ–™\næ··åˆ åœ¨ AOF é‡å¯«çš„æ™‚å€™ä¹Ÿåˆ©ç”¨ RDB å‰é¢æ˜¯ RDBï¼Œå¾Œé¢æ˜¯ AOF\nAvailability ä¸»å¾åŒæ­¥ ä¸€ä¸»å¤šå¾ï¼ŒæŠŠè®€å–å£“åŠ›åˆ†æ“”åˆ° slave ä¸Š\nå“¨å…µæ¨¡å¼ Sentinel æœƒæœ‰å“¨å…µä¸æ–·åœ° Ping ä¸»å¾ä¼ºæœå™¨ï¼Œç¢ºèªæ˜¯å¦æœ‰ç•°å¸¸\nå¦‚æœå“¨å…µæ˜¯é›†ç¾¤ï¼Œæœ‰å“¨å…µæª¢æ¸¬åˆ°ç•°å¸¸ï¼Œæœƒåˆ¤æ–·æŸä¼ºæœå™¨ä¸»è§€ä¸‹ç·šï¼Œç•¶æœ‰ä¸€å®šæ•¸é‡çš„å“¨å…µæŠ•ç¥¨èªç‚ºä¼ºæœå™¨ä¸å¯èƒ½ç”¨ï¼Œå°±æœƒè®Šæˆå®¢è§€ä¸‹ç·šï¼Œé€²è¡Œ failover\nCluster åˆ†æ“”å¯«å…¥å£“åŠ›\nRedis æœ‰ 16384 å€‹ slotï¼Œé€é hash åˆ†é… key åˆ°ä¸åŒçš„ slot\né è¨­æœƒå¦å¤–ç”¨ port 16379 ä¾†è®“ç¯€é»é–“æºé€š\nå¯ä»¥æ··å’Œä¸»å¾åŒæ­¥é”åˆ°é«˜å¯ç”¨\n","date":"2023-06-05T00:00:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/redis/","title":"Redis"},{"content":"å‰è¨€ è»Ÿé«”è¦å° domain åš Modelingï¼Œå‘ˆç¾å‡º domain è£¡çš„æ ¸å¿ƒæ¦‚å¿µï¼Œæ‰èƒ½æ»¿è¶³ä½¿ç”¨è€…éœ€æ±‚ï¼Œå› æ­¤ä¸ä¹èˆ‡é ˜åŸŸå°ˆå®¶çš„è¨è«–\nå¯«é€™ç¯‡çš„æ™‚å€™æˆ‘é‚„æ²’å—‘å®Œ Eric çš„è–ç¶“ï¼Œå¯èƒ½å—‘å®Œäº†ä¹‹å¾Œæœƒå›ä¾†ä¿®æ”¹\né€šç”¨èªè¨€ Ubiquitous Language é‘’æ–¼ç¨‹å¼é–‹ç™¼äººå“¡èˆ‡é ˜åŸŸå°ˆå®¶ç†Ÿæ‚‰çŸ¥è­˜çš„å·®ç•°ï¼Œæœƒç”¢ç”Ÿäº¤æµå›°é›£\nå› æ­¤é ˜åŸŸå°ˆå®¶å’Œé–‹ç™¼åœ˜éšŠè¦è¨‚å®šå…±åŒçš„èªè¨€ï¼Œä¸¦ä¸”ç›¡å¯èƒ½å°‘ç”¨è‡ªå·±çŸ¥é“çš„è¡“èª\nUML UML é©åˆç”¨åœ¨å°å‹æ¨¡å‹ä¸Šï¼Œå®ƒæ“…é•·è¡¨é”é¡åˆ¥é–“çš„é—œä¿‚ï¼Œä½†å°æ–¼æŠ½è±¡æ¦‚å¿µå»æ²’é‚£éº¼å¥½å‚³é”\nå› æ­¤ç”¨ UML å»ºæ§‹æ¨¡å‹æ™‚ï¼Œç†æƒ³ä¸Šè¦æ·»åŠ é¡å¤–çš„æ–‡å­—ï¼Œå‚³é”ä¸€äº›åœ–æ‰€ä¸èƒ½è¡¨é”çš„ behavior å’Œ constraint\nä¸¦ä¸”ä¸èƒ½ä¸€æ¬¡å¯«éæ–¼è¤‡é›œï¼Œè€Œæ˜¯åˆ†å¡Šè™•ç†\nLayered Architecture åˆ†ç‚ºå››å€‹æ¦‚å¿µå±¤ï¼Œåªæœƒå¾€ä¸‹èª¿ç”¨ï¼Œå¯èƒ½æœƒè·¨å±¤\nå¯ä»¥é”åˆ°é—œæ³¨é»åˆ†é›¢ (separation of concerns)ï¼Œæé«˜å„å€‹æ–¹é¢çš„ cohesive\nUser Interface (Presentation Layer) å‘ˆç¾çµ¦ user çš„ UIï¼ŒUser å¯èƒ½æ˜¯å¦ä¸€å€‹ç³»çµ± Application Layer ä¸å« bussiness logicï¼ŒæŒ‡æ®è¡¨é”é ˜åŸŸæ¦‚å¿µçš„ç‰©ä»¶ä¾†å®Œæˆä»»å‹™ Domain Layer æœ‰é—œ domain çš„è³‡è¨Šéƒ½åœ¨é€™è£¡ï¼Œæ¥­å‹™é‚è¼¯åœ¨æ­¤è™•ç† è¡¨é”æ¥­å‹™æ¦‚å¿µã€ç‹€æ…‹ã€è¦å‰‡ åŠƒåˆ†å‡ºé€™å±¤æ˜¯ Model-Driven Design çš„é—œéµ Infrastructure layer supporting library ä¿å­˜æ¥­å‹™ç‹€æ…‹çš„æŠ€è¡“ç´°ç¯€åœ¨æ­¤å¯¦ä½œ ç‚ºå‰ä¸‰å€‹ layer æœå‹™ Entity å…·å‚™ identity identity åœ¨ status ç¶“éæ”¹è®Šå¾Œä¾ç„¶ä¸è®Š è¿½è¹¤ entity éœ€è¦é«˜æˆæœ¬ mutable Value Object æ²’æœ‰ identity åªé—œå¿ƒ obejct çš„ value å¯ä»¥è¼•æ˜“å‰µå»ºä¸Ÿæ£„ immutable (ä¸è®Šçš„) å¦‚æœæƒ³ä¿®æ”¹æ•¸å€¼å°±å‰µæ–°çš„ å¯è¢«å…±ç”¨ Service æœ‰äº›å‹•ä½œä¸å±¬æ–¼æŸå€‹ Entity æˆ– Value Objectï¼Œå› ç‚ºå®ƒæ˜¯è·¨ç‰©ä»¶çš„ Stateless æ¯å€‹è«‹æ±‚ä¸äº’ç›¸å½±éŸ¿ Aggregate æŠŠè¤‡é›œé—œè¯çš„ç‰©ä»¶åœˆåœ¨ä¸€èµ·è€ƒé‡ ç¢ºä¿ consistency å’Œ inveraints consistency (ä¸€è‡´æ€§) ç›¸é—œç‰©ä»¶çš„è³‡æ–™ä¸€è‡´ invariants (ä¸è®Šé‡) è³‡æ–™æ”¹è®Šæ™‚è¦ç¶­è­·çš„è¦å‰‡ Aggregate root å…·å‚™ global identityï¼Œå…¶ä»–å…§éƒ¨ entity åªæœ‰ local identity é€šå¸¸æ˜¯ entity æ“”ä»» å¤–éƒ¨åªèƒ½å­˜å–å®ƒï¼Œä¸èƒ½å­˜å– aggregate çš„å…¶ä»– entity æˆ– value obejct Factory è‹¥å‰µå»º aggregateã€entityã€value object çš„éç¨‹å¾ˆè¤‡é›œï¼Œæˆ–æ˜¯æ¶‰åŠå°ˆæ¥­çŸ¥è­˜ï¼Œå°±è©²ç”¨ factory åŒ…èµ·ä¾† å°æ–¼ä¸è¤‡é›œçš„æƒ…æ³ï¼Œæˆ–æ˜¯æƒ³æ§åˆ¶æ›´å¤šç´°ç¯€ï¼Œå¯ä»¥åªä¾è³´æ–¼ç°¡å–®çš„å»ºæ§‹å‡½å¼ Repository å¦‚æœå¤§å®¶éƒ½ç›´æ¥å­˜å–è³‡æ–™åº«çš„å„ç¨®ç‰©ä»¶ï¼Œæœƒç ´å£åŸæœ¬ç²¾å¿ƒè¨­è¨ˆçš„çµæ§‹ï¼Œç ´å£å°è£æ€§\nRepositoy ç”¨ä¾†å­˜å–ç‰©ä»¶ï¼Œå°è£äº†è³‡æ–™åº«æ“ä½œ\nDomain event Domain ä¸­é‡è¦çš„äº‹æƒ… å¯ä»¥ç”¨åœ¨å…¶ä»–ç‰©ä»¶å’Œ aggrgate è¨‚é–±ï¼Œè®“ aggregate é€šçŸ¥ä»–å€‘ domain event çš„ç™¼ç”Ÿ Anti-Pattern æ‡‰è©²é¿å…çš„æƒ…å½¢ Smart UI è¶…è‚¥çš„è¬èƒ½ UI Anemic Domain Model è²§è¡€æ¨¡å‹ åªæœ‰ getter å’Œ setterï¼Œæ²’æœ‰æ¥­å‹™é‚è¼¯çš„æ¨¡å‹ Subdomain æŠŠ domain åˆ‡åˆ†æˆå°å¡Šï¼Œç†æƒ³ä¸Š subdomain å’Œ bounded context æœ‰ one-to-one çš„é—œä¿‚\nTypes core subdomain å’Œå…¶ä»–ç«¶çˆ­è€…ç›¸æ¯”ä¸åŒçš„éƒ¨åˆ†ï¼Œæœ€æ ¸å¿ƒçš„æ¥­å‹™ï¼Œæ¯”å¦‚æœå°‹å¼•æ“ä¸­çš„æœå°‹æ¼”ç®—æ³• generic subdomain å¤§å®¶éƒ½æœƒå¼„çš„éƒ¨åˆ†ï¼Œæ¯”å¦‚ç™»å…¥ç³»çµ± supporting subdomain ç”¨ä¾†è¼”åŠ© core subdomain çš„éƒ¨åˆ†ï¼Œæ¯”å¦‚ç¯©é¸ç¶²é  Bounded Context åŠƒå‡º boundaryï¼Œç¢ºä¿ boundary å…§ç”¨çš„æ¦‚å¿µã€è¦å‰‡çš†ä¸€è‡´ åŒå€‹åè©å¯èƒ½å‡ºç¾åœ¨ä¸åŒçš„ contextï¼Œä½†æœ‰ä¸åŒæ„æ€ Context Map æè¿° BC å’Œ BC é–“çš„é—œä¿‚\nä¸Šä¸‹æ¸¸ (U/D) ä¸Šæ¸¸æä¾›ä¸‹æ¸¸ (ä¸‹æ¸¸ä¾è³´ä¸Šæ¸¸) Shared Kernel å…©å€‹ BC å…±ç”¨çš„éƒ¨ä»½ é•å BC çš„åŸºæœ¬åŸå‰‡ï¼Œæ˜¯ä¸€ç¨®ä¾‹å¤–è¨­è¨ˆ Customer-Supplier ä¸€å€‹å­ç³»çµ±é‡åº¦ä¾è³´å¦ä¸€å€‹å­ç³»çµ± Conformist Customer å®Œå…¨é…åˆ Supplier Partnership å…©å€‹ BC äº’ç›¸åˆä½œï¼Œæ²’æœ‰ä»¥èª°ç‚ºä¸» ä¸€èµ·æˆåŠŸæˆ–ä¸€èµ·å¤±æ•— Anticorruption Layer (ACL) é–‹ç™¼ç³»çµ±å’Œå¤–éƒ¨ç³»çµ±çš„ä¸­é–“å±¤ å¯èƒ½å‡ºç¾åœ¨èª¿ç”¨ legacy system å¸¸ç”¨åˆ° Facade å’Œ Adapter Open Host Service (OHS) å¦‚æœå¤–éƒ¨å­ç³»çµ±è¦çµ¦ä¸€å †ç”¨æˆ¶ç«¯å­ç³»çµ±èª¿ç”¨ï¼Œå°±å¾—åœ¨æ‰€æœ‰ç”¨æˆ¶ç«¯å­ç³»çµ±æ ACL å¤–éƒ¨ç³»çµ±åšç‚ºæœå‹™æä¾›ï¼Œå¸¸æœƒæ­é… Published Language (PL) PL æ˜¯å”å®šå‚³é€è³‡æ–™çš„æ ¼å¼ï¼Œæ¯”å¦‚ XMLã€JSON æˆ–æ˜¯ Protocol Buffer Pratical DDD The strangler migration é€é Facadeï¼ŒæŠŠä¸€äº›æœå‹™æ…¢æ…¢ç§»æ¤çµ¦æ–°ç³»çµ±ï¼Œæœ€å¾Œå–ä»£ legacy ","date":"2023-05-22T00:00:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E9%A0%98%E5%9F%9F%E9%A9%85%E5%8B%95%E8%A8%AD%E8%A8%88-domain-driven-design/","title":"é ˜åŸŸé©…å‹•è¨­è¨ˆ Domain-Driven Design"},{"content":"é‹ç®—æ”¾å¤§å™¨ (Operational Amplifiers) ä»‹ç´¹ é‹ç®—æ”¾å¤§å™¨ (Operational Amplifiers) ç‰¹æ€§ é¡ä¼¼æ–¼é›»å£“æ§åˆ¶é›»å£“ç›¸ä¾é›»æºçš„é›»å­å…ƒä»¶ ä¸»å‹•é›»è·¯å…ƒä»¶ ç”¨æ–¼åŸ·è¡ŒåŠ ã€æ¸›ã€ä¹˜ã€é™¤ã€å¾®åˆ†èˆ‡ç©åˆ†ç­‰é‹æ•¸å­¸é‹ç®—çš„ä¸»å‹•é›»è·¯å…ƒä»¶ ç”±é›»é˜»ã€é›»æ™¶é«”ã€é›»å®¹å’ŒäºŒæ¥µé«”ç­‰æ‰€æ§‹æˆçš„é›»å­å…ƒä»¶ï¼Œä½†å› å…§éƒ¨é›»è·¯çš„è¨è«–å·²è¶…å‡ºç¯„åœï¼Œå…ˆçœ‹ä½œæ˜¯é›»è·¯æ¨¡çµ„ å°è£å½¢å¼ DIP è¼¸å‡ºé›»å£“ $v_O$ $v_O=Av_d=A(v_2-v_1)$ $v_2$ æ˜¯éåç›¸è¼¸å…¥ (noninverting input) $v_1$ æ˜¯åç›¸è¼¸å…¥ (inverting input) $A$ æ˜¯é–‹è¿´è·¯é›»å£“å¢ç›Š (open-loop voltage gain) æ˜¯æ²’æœ‰ä»»ä½•å¾è¼¸å‡ºåˆ°è¼¸å…¥çš„å›æˆ (feedback) æ™‚ï¼Œé‹ç®—æ”¾å¤§å™¨çš„å¢ç›Š å›æˆ è² å›æˆ (negative feedback) è¼¸å‡ºå›æˆè‡³åç›¸è¼¸å…¥ç«¯ é–‰è¿´è·¯å¢ç›Š (closed-loop gain) å¦‚æœå­˜åœ¨ç”±è¼¸å‡ºåˆ°è¼¸å…¥çš„å›æˆï¼Œè¼¸å‡ºé›»å£“èˆ‡è¼¸å…¥é›»å£“çš„æ¯”ä¾‹ç¨±ç‚ºé–‰è¿´è·¯å¢ç›Š å°è² å›æˆé›»è·¯è€Œè¨€ï¼Œå¯ä»¥è­‰æ˜é–‰è¿´è·¯å¢ç›Šå’Œé–‹è¿´è·¯å¢ç›Šç„¡é—œï¼Œå› æ­¤é‹ç®—æ”¾å¤§å™¨ç¸½æ˜¯ç”¨æ–¼å…·å›æˆçš„é›»è·¯ä¸­ å·¥ä½œæ¨¡å¼ æ­£é£½å’Œå€ $v_O=V_{CC}$ ç·šæ€§å€ $-V_{CC} \\leq v_O = Av_d \\leq V_{CC}$ è² é£½å’Œå€ $v_O=-V_{CC}$ ç¬¦è™Ÿ $v_O$ æ˜¯è¼¸å‡ºé›»å£“ $v_d$ æ˜¯è¼¸å…¥é›»å£“å·® ç†æƒ³é‹ç®—æ”¾å¤§å™¨ (Ideal Op Amp) å‡å®šé‹ç®—æ”¾å¤§å™¨æ˜¯ç†æƒ³çš„æ˜¯ç¬¦åˆå¯¦éš›çš„ï¼Œå› ä½ç›®å‰çµ•å¤§å¤šæ•¸é‹ç®—æ”¾å¤§å™¨éƒ½æœ‰å¾ˆå¤§çš„å¢ç›Šå’Œè¼¸å…¥é›»é˜» å…·æœ‰ä»¥ä¸‹ç‰¹æ€§çš„é‹ç®—æ”¾å¤§å™¨ï¼Œç¨±ç‚ºç†æƒ³é‹ç®—æ”¾å¤§å™¨ $A \\simeq \\inf$ é–‹è¿´è·¯å¢ç›Šç„¡çª®å¤§ $R_i \\simeq \\inf$ è¼¸å…¥é›»é˜»ç„¡çª®å¤§ $R_O \\simeq 0$ è¼¸å‡ºé›»é˜»ç‚ºé›¶ ç‰¹æ€§ æµå…¥å…©å€‹è¼¸å…¥ç«¯çš„é›»æµå‡ç‚º 0ï¼Œå› ç‚ºè¼¸å…¥é›»é˜»ç„¡çª®å¤§ï¼Œè¼¸å…¥ç«¯é–“é–‹è·¯ è¼¸å…¥ç«¯é–“çš„é›»å£“å·®ç­‰æ–¼é›¶ï¼Œ$v_d=v_2-v_1=0$ åç›¸æ”¾å¤§å™¨ (Inverting Amplifier) å°è¼¸å…¥ä¿¡è™Ÿæ”¾å¤§çš„åŒæ™‚åè½‰æ¥µæ€§ å…¬å¼ $v_0=-\\frac{R_f}{R_1}v_i$ $R_f$ æ˜¯å›æˆé›»é˜» $R_1$ æ˜¯é€²åˆ°è² å›æˆç¯€é»å‰çš„é›»é˜» éåç›¸æ”¾å¤§å™¨ (Noninverting Amplifier) æä¾›æ­£é›»å£“å¢ç›Šçš„é‹ç®—æ”¾å¤§å™¨é›»è·¯\nå…¬å¼\n$v_0=(1+\\frac{R_f}{R_1})v_i$ é›»å£“éš¨è€¦å™¨ (voltage follewer)\nåˆç¨±å–®ä½å¢ç›Šæ”¾å¤§å™¨ (unity gain amplifier) æ¢ä»¶ $R_f=0 æˆ– R_1=\\inf æˆ– (R_f=0 ä¸” R_1=\\inf)$ å…¬å¼ $v_0=v_i$ åŠ æ³•æ”¾å¤§å™¨ (Summing Amplifier) å°‡å¤šå€‹è¼¸å…¥çµåˆï¼Œåœ¨è¼¸å‡ºç”¢ç”Ÿè¼¸å…¥çš„åŠ æ¬Šç¸½åˆ å…¬å¼ $v_O=-(\\frac{R_f}{R_1}v_1+\\frac{R_f}{R_2}v_2+\\frac{R_f}{R_3}v_3)$ å·®å‹•æ”¾å¤§å™¨ (Difference Amplifier) æ”¾å¤§å…©å€‹è¼¸å…¥ä¿¡è™Ÿçš„å·®è€ŒæŠ‘åˆ¶å…©å€‹è¼¸å…¥çš„å…±æ¨¡ä¿¡è™Ÿ (Common-mode signal)\nå…¬å¼\n$v_O=\\frac{R_2(1+R_1/R_2)}{R1(1+R_3/R_4)}v_2-\\frac{R_2}{R_1}v_1$ å¦‚æœ $R_2=R_1$ ä¸” $R_3=R_4$ï¼Œå‹•å·®æ”¾å¤§å™¨ç‚ºæ¸›æ³•å™¨ (subtractor)\n$v_O=v_2-v_1$ ä¸²ç´šé‹ç®—æ”¾å¤§å™¨é›»è·¯ (Cascaded Op Amp Circuits) ä¸²ç´š å…©å€‹ä»¥ä¸Šçš„é‹ç®—æ”¾å¤§å™¨é¦–å°¾ç›¸æ¥ï¼Œå‰ä¸€ç´šçš„è¼¸å‡ºæ˜¯ä¸‹ä¸€ç´šçš„è¼¸å…¥ å¤šå€‹é‹ç®—æ”¾å¤§å™¨ä¸²ç´šæ™‚ï¼Œæ¯å€‹é›»è·¯éƒ½ç¨±ç‚ºä¸€ç´š (stage) é‹ç®—æ”¾å¤§å™¨çš„å„ªé» ä¸²ç´šä¸æœƒæ”¹è®Šå„è‡ªè¼¸å…¥-è¼¸å‡º å› ç‚ºç†æƒ³çš„é‹ç®—æ”¾å¤§å™¨è¼¸å…¥é›»é˜»ç„¡çª®å¤§ï¼Œè¼¸å‡ºé›»é˜»ç‚º 0 ç¸½å¢ç›Šç‚ºå€‹åˆ¥å¢ç›Šçš„ä¹˜ç© $A=A_1A_2A_3$ æ•¸ä½-é¡æ¯”è½‰æ›å™¨ (Digital-to-Analog Converter, DAC) DAC æŠŠæ•¸ä½ä¿¡è™Ÿè½‰æˆé¡æ¯”ä¿¡è™Ÿ å¯¦ç¾æ–¹æ³• äºŒé€²ä½åŠ æ¬Šéšæ¢¯é›»è·¯ (binary weighted ladder) æŠŠæ¬Šé‡è¨­è¨ˆæˆäºŒé€²ä½çš„åŠ æ³•æ”¾å¤§å™¨ è¼¸å…¥ æœ€é«˜ä½å…ƒ (most significant bit, MSB) æœ€ä½ä½å…ƒ (least significant bit, LSB) å„€è¡¨æ”¾å¤§å™¨ (Instrumentation Amplifiers) å·®å‹•æ”¾å¤§å™¨çš„å»¶ä¼¸ é›»å®¹å™¨èˆ‡é›»æ„Ÿå™¨ ä»‹ç´¹ é›»å®¹å™¨èˆ‡é›»æ„Ÿå™¨æ˜¯èƒ½å„²å­˜èƒ½é‡çš„å„²èƒ½å…ƒä»¶ (storage element) é›»å®¹å™¨ (Capacitors) å°‡èƒ½é‡å„²å­˜åœ¨é›»å ´ä¸­çš„è¢«å‹•å…ƒä»¶\nç”±å…©ç‰‡å°é›»æ¿å¤¾è‘—çµ•ç·£é«” (é›»ä»‹è³ª) çµ„æˆ\nå…¬å¼\n$q=Cv$ q æ˜¯å„²å­˜çš„é›»è·é‡ C æ˜¯æ¯”ä¾‹å¸¸æ•¸ï¼Œåˆç¨±é›»å®¹ (capacitance) å–®ä½æ˜¯æ³•æ‹‰ (farad, F) C ä¸æ˜¯ç”± q å’Œ v æ±ºå®š $C=\\frac{\\epsilon A}{d}$ $\\epsilon$ æ˜¯ä»‹é›»å¸¸æ•¸ $A$ æ˜¯å°é›»æ¥µç‰ˆçš„æˆªé¢ç© $d$ æ˜¯å…©æ¥µæ¿çš„é–“è· $v(t)=\\frac{1}{C}\\int_{t_0}^t i (\\tau)d\\tau + v(t_0)$ $w=\\frac{1}{2}Cv^2$ é›»å ´å„²å­˜çš„èƒ½é‡ ç·šæ€§é›»å®¹ (linear capacitor)\næ»¿è¶³ $i=C\\frac{dv}{dt}$ éç·šæ€§é›»å®¹ (nonlinear capacitor)\né›»æµé›»å£“é—œä¿‚æ›²ç·šéç›´ç·šï¼Œä¸éå¤šæ•¸é›»å®¹æ˜¯ç·šæ€§çš„ é‡è¦æ€§è³ª\né›»å®¹å™¨åœ¨ç›´æµä¸‹å·¥ä½œï¼Œç­‰åŒé–‹è·¯ é›»å£“ä¸éš¨æ™‚é–“æ”¹è®Šçš„è©±é›»æµæ˜¯ 0 é›»å®¹å™¨ä¸Šçš„é›»å£“å¿…é ˆæ˜¯é€£çºŒçš„ å› ç‚ºä¸é€£çºŒè®ŠåŒ–çš„é›»å£“éœ€è¦ç„¡é™å¤§çš„é›»æµ é›»å®¹æœƒåæŠ—é›»å£“çš„çªç„¶æ”¹è®Š ç†æƒ³é›»å®¹å™¨ä¸æ¶ˆè€—èƒ½é‡ å¯¦éš›çš„éç†æƒ³é›»å®¹å™¨æœƒä¸¦è¯ä¸€å€‹æ¼é›»é˜»ï¼Œå¯é«˜é” $100M \\Omega$ï¼Œåœ¨å¤šæ•¸æƒ…æ³å¯å¿½ç•¥ä¸è¨ˆ é›»å®¹å™¨ä¸²ä¸¦è¯ ä¸¦è¯ $C_{eq} = C_1 + C_2 + C_3 + \u0026hellip; + C_N$ ä¸²è¯ $\\frac{1}{C_{eq}} = \\frac{1}{C_{1}} + \\frac{1}{C_{2}} + \\frac{1}{C_{3}} + \u0026hellip; + \\frac{1}{C_{N}}$ é›»æ„Ÿå™¨ (Inductors) å°‡èƒ½é‡å„²å­˜æ–¼ç£å ´ä¸­çš„è¢«å‹•å…ƒä»¶\nå…¬å¼\n$v=L\\frac{di}{dt}$ L æ˜¯æ¯”ä¾‹å¸¸æ•¸ï¼Œåˆç¨±ç‚ºé›»æ„Ÿ (inductance) å–®ä½æ˜¯äº¨åˆ© (henry, H) ç”±ç‰©ç†å°ºå¯¸å’Œçµæ§‹æ±ºå®š $i=\\frac{1}{L}\\int_{t_0}^t v (\\tau)d\\tau + i(t_0)$ $w=\\frac{1}{2}Li^2$ å„²å­˜çš„èƒ½é‡ é›»æ„Ÿåæ‡‰é›»æ„Ÿå™¨åæŠ—é›»æµè®ŠåŒ–çš„ç‰¹æ€§\nç·šæ€§é›»æ„Ÿ (linear inductor)\næ»¿è¶³ $v=L\\frac{di}{dt}$ éç·šæ€§é›»æ„Ÿ (nonlinear inductor)\n$v$ å’Œ $di/dt$ é—œä¿‚æ›²ç·šéç›´ç·š é‡è¦æ€§è³ª\nåœ¨ç›´æµä¸­ï¼Œé›»æ„Ÿå™¨ç­‰åŒçŸ­è·¯ é›»æ„Ÿå™¨ä¸Šçš„é›»æµå¿…é ˆæ˜¯é€£çºŒçš„ å› ç‚ºä¸é€£çºŒè®ŠåŒ–çš„é›»æµéœ€è¦ç„¡é™å¤§çš„é›»å£“ é›»å®¹æœƒåæŠ—é›»æµçš„çªç„¶æ”¹è®Š ç†æƒ³é›»æ„Ÿå™¨ä¸æ¶ˆè€—èƒ½é‡ å¯¦éš›çš„éç†æƒ³é›»å®¹å™¨æœƒä¸²è¯ä¸€å€‹ç¹ç·šé›»é˜» (winding resistance)ï¼Œç”±è£½æˆé›»æ„Ÿçš„å°é›»ææ–™ç”¢ç”Ÿï¼Œé€šå¸¸å¾ˆå°ã€‚ä¸¦ç”±æ–¼ç·šåœˆé–“çš„é›»å®¹æ€§è€¦åˆï¼Œä¹Ÿå­˜åœ¨ç¹ç·šé›»å®¹ (winding capacitance) é›»æ„Ÿå™¨ä¸²ä¸¦è¯ ä¸²è¯ $L_{eq} = L_1 + L_2 + L_3 + \u0026hellip; + L_N$ ä¸¦è¯ $\\frac{1}{L_{eq}} = \\frac{1}{L_{1}} + \\frac{1}{L_{2}} + \\frac{1}{L_{3}} + \u0026hellip; + \\frac{1}{L_{N}}$ æ‡‰ç”¨ é›»æ„Ÿé›»å®¹çš„ç‰¹æ®Šæ€§è³ª èƒ½å„²å­˜èƒ½é‡ï¼Œä½œç‚ºæš«æ™‚çš„é›»å£“æºæˆ–é›»æµæºï¼Œå¯åœ¨çŸ­æ™‚é–“å…§ç”¢ç”Ÿå¤§é›»æµæˆ–é›»å£“ é›»å®¹å™¨åæŠ—é›»å£“çš„çªç„¶æ”¹è®Šã€é›»æ„Ÿå™¨åæŠ—é›»æµçš„çªç„¶æ”¹è®Š é›»å®¹å™¨å’Œé›»æ„Ÿå™¨å°é »ç‡å¾ˆéˆæ•ï¼Œå¯ä»¥å€åˆ¥ä¸åŒé »ç‡ï¼Œé€™æ¢ç”¨åœ¨äº¤æµé›»è·¯ä¸­ ç©åˆ†å™¨ (Integrator) æ¡ç”¨å„²èƒ½å…ƒä»¶çš„é‹ç®—æ”¾å¤§å™¨çµ„æˆçš„ç©åˆ†å™¨ï¼Œè¼¸å‡ºè¨Šè™Ÿå’Œè¼¸å…¥è¨Šè™Ÿçš„ç©åˆ†æˆæ­£æ¯” $v_0=-\\frac{1}{RC}\\int_0^tv_i(\\tau)d\\tau$ å¾®åˆ†å™¨ (Differentiator) æ¡ç”¨å„²èƒ½å…ƒä»¶çš„é‹ç®—æ”¾å¤§å™¨çµ„æˆçš„å¾®åˆ†å™¨ï¼Œè¼¸å‡ºè¨Šè™Ÿå’Œè¼¸å…¥è¨Šè™Ÿçš„è®Šç‡æˆæ­£æ¯” $v_0=-RC\\frac{dv_i}{dt}$ é¡æ¯”è¨ˆç®—æ©Ÿ (Analog Computer) ç”±å„ç¨®é‹ç®—æ”¾å¤§å™¨ç¶œåˆä½¿ç”¨ï¼Œå¯ç®—å‡ºä»»æ„å¾®åˆ†æ–¹ç¨‹å¼\n","date":"2023-05-08T00:00:54+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E9%9B%BB%E8%B7%AF%E5%AD%B8-iii/","title":"é›»è·¯å­¸ - III"},{"content":"ç°¡ä»‹ Timer å’Œ Counter çš„å·®åˆ¥æ˜¯ Timer æ˜¯å®šæœŸçš„æ•¸æ•¸\nTiming functions å®šæœŸå° CPU ç™¼é€ interrupt ç”¢ç”Ÿæº–ç¢ºæ™‚é–“çš„ delay ç”¢ç”Ÿ pulses æˆ– periodic waveforms PWM é‡æ¸¬ duration STM32 Timer / Counter å¾ Basic åˆ° Advancedï¼Œè¿½åŠ æ›´å¤šåŠŸèƒ½\nBasic TImer (Simple Timer)\n16 bit auto-reload register programmable pre-scaler å¯ä»¥ output åˆ° DAC update event CNT=ARR(up-count) CNT=0 (down-count) reset CNT to 0 or ARR set UIF flag in status register update event interrupt å¦‚æœ enabled (UIE=1) UIF è¢«è¨­ç½®çš„æ™‚å€™ç™¼é€è¨Šè™Ÿ $T_{EVENT}=Prescale \\times Count \\times T_{CK \\_ INT} \\\\ =(PSC+1)\\times(ARR+1)\\times T_{CK \\_ INT}$\n$T_{EVENT}$ æ˜¯å…©æ¬¡äº‹ä»¶ç™¼ç”Ÿçš„é–“éš”æ™‚é–“ PSC æ˜¯è¨­å®š (æ•¸å€¼ - 1)ï¼Œæ‰€ä»¥ Prescale æ˜¯ 1 çš„è©±ï¼Œè¦è¨­ 0 Control register\nCEN æ˜¯å¦å•Ÿç”¨ counter UDIS æ˜¯å¦å•Ÿç”¨ update event URS è¨­å®šç”¢ç”Ÿ update event çš„ source OPM æ˜¯å¦åªç®—ä¸€æ¬¡ counter å°±åœ ARPE é—œæ–¼ä¸­é€”æ”¹ ARR çš„ reload è¨­å®š UIF interrupt General Purpose Timer\n16-bit or 32-bit auto-reload register use for a variety of puposes measuring lengths of input signals (Input Capture)\nInput Capture æ¸¬é‡ pulse width (é«˜é›»ä½çš„æ™‚é–“) æˆ– period (ä¸€å€‹é€±é•·) generating output waveforms (Output Compare and PWM Generation)\none pulse mode output Up to 4 independent channel Interrupt / DMA generation event counter overflow / underflow counter initialization trigger event input capture output compare Advanced Control Timer\n16-bit auto-reload register ç‰¹æ®Š timer\nlow power timer å¯ä»¥ç”¨åœ¨æ¯”å¦‚ç¡çœ ç‹€æ…‹ è£œå…… 24 bits system timer (SysTick) reload åœ¨ overflow æ™‚å›åˆ° register è¨­å®šçš„æ•¸å€¼ STM32 Timer å·®ç•° å¯ä»¥å» Datasheet æ‰¾æ¯å€‹ Timer çš„åŠŸèƒ½\nCounter resolution\n16/32 bit æ±ºå®šèƒ½å¾ 0 æ•¸åˆ°å¤šå°‘å€‹ Counter Type\næ±ºå®šèƒ½å¾€ä¸Šæ•¸æˆ–å¾€ä¸‹æ•¸æˆ–éƒ½å¯ä»¥ Prescaler factor\nå¯ä»¥æŠŠé€²ä¾†çš„æ•¸å­—å…ˆé™¤ä»¥æŸå€‹æ•¸ï¼Œæ¸›ç·©é€Ÿåº¦ DMA request generation\nèƒ½å¦ç”¨ DMA access è¨˜æ†¶é«” Capture / Compare channels\nä¸€å€‹ Timer å¯èƒ½å¯ä»¥ç™¼å¤šå€‹è¨Šè™Ÿå‡ºå»ï¼Œä¸¦ä¸”ç¶“éå¤šå€‹ Compare registerï¼Œæ¯”å°ä¸åŒ event functions Compare å’Œæ¯”å° registerï¼Œæ¯”åˆ°äº†å°±é€ event Capture ç´€éŒ„ä¸‹ channel çš„å€¼ Complementary output\næœ‰äº›é¦¬é”æ§åˆ¶éœ€è¦åå‘æ³¢ï¼Œå°±è¦é€™å€‹ Max interface clock (MHz) and Max timer clock (MHz)\né€²å»å’Œå‡ºä¾†çš„é€Ÿåº¦ System Clock - Clock tree Timer æºé ­å°±æ˜¯ clock\næœ‰å››ç¨®ä¾†æºå¹«å¿™é©…å‹• system clock (SYSCLK)\nHSI16 (high speed internal) 16 MHz RC oscillator clock MSI (multispeed internal) RC oscillator clock HSE (high speed external) oscillator clock, from 4 to 48 MHz PLL clock SYSCLK å¾€ä¸‹æ¥åˆ° AHBï¼Œå†æ¥åˆ° APB1ã€APB2\nFlash Read Access Latency èª¿æ•´ clock ä¹Ÿè¦èª¿æ•´é€™éƒ¨åˆ† Register TIMx_CR1 control register TIMx_PSC è¨­å®š prescale TIMx_ARR auto-reload register ","date":"2023-05-04T01:32:54+08:00","permalink":"https://roykesydon.github.io/Blog/p/stm32-timer-/-counter-%E4%BB%8B%E7%B4%B9/","title":"STM32 Timer / Counter ä»‹ç´¹"},{"content":"paper: Self-Instruct: Aligning Language Model with Self Generated Instructions\nAbstract å¤§å‹ \u0026ldquo;instruction-tuned\u0026rdquo; èªè¨€æ¨¡å‹ (ç¶“éå¾®èª¿å¥½å›æ‡‰ instruction) å·²ç¶“å±•ç¾å‡ºåœ¨æ–°ä»»å‹™ä¸Š zero-shot çš„èƒ½åŠ›ã€‚\nç„¶è€Œä»–å€‘åš´é‡ä¾è³´äººå·¥ç·¨å¯«çš„æŒ‡ä»¤ï¼Œåœ¨æ•¸é‡ã€å¤šæ¨£æ€§å’Œå‰µé€ åŠ›ä¸Šéƒ½å—åˆ°äº†é™åˆ¶ï¼Œé˜»ç¤™äº†æ¨¡å‹çš„é€šç”¨æ€§ã€‚\nä½œè€…ä»‹ç´¹äº† Self-Instruct é€™å€‹æ¡†æ¶ï¼Œå¯ä»¥é€éè‡ªå·±ç”Ÿæˆçš„æŒ‡ä»¤ï¼Œä¾†å¢å¼·é è¨“ç·´æ¨¡å‹éµå¾ªæŒ‡ä»¤çš„èƒ½åŠ›ã€‚\nå°‡ä½œè€…çš„æ–¹æ³•æ‡‰ç”¨åœ¨ GPT3ï¼Œåœ¨ SuperNaturalInstructions ç²å¾—äº†æ¯”åŸå§‹æ¨¡å‹é«˜ 33% çš„æ”¹é€²ï¼Œèˆ‡ä½¿ç”¨ private user data å’Œ human annotations çš„ $InstructGPT_{001}$ æ€§èƒ½ç›¸ç•¶ã€‚\nç‚ºäº†é€²ä¸€æ­¥è©•ä¼°ï¼Œæˆ‘å€‘ç‚ºæ–°ä»»å‹™æ•´ç†ä¸€çµ„å°ˆå®¶ç·¨å¯«çš„æŒ‡ä»¤ï¼Œä¸¦é€šéäººå·¥è©•ä¼°ï¼Œé¡¯ç¤ºå‡ºä½¿ç”¨ Self-Instruction èª¿æ•´ GPT3 çš„æ€§èƒ½å¤§å¤§å„ªæ–¼ä½¿ç”¨ç¾æœ‰å…¬å…±æŒ‡ä»¤è³‡æ–™é›†ï¼Œåªæ¯” $InstructGPT_{001}$ è½å¾Œ 5% çš„å·®è·ã€‚\nSelf-Instruct æä¾›ä¸€å€‹å¹¾ä¹ annotation-free çš„æ–¹æ³•ï¼Œalign é è¨“ç·´æ¨¡å‹å’Œ instructionsï¼Œè€Œä¸”ä½œè€…é‡‹å‡ºäº†ä»–å€‘çš„å¤§å‹åˆæˆè³‡æ–™é›†ï¼Œä»¥ä¿ƒé€²æœªä¾†å° instruction tuning çš„ç ”ç©¶ã€‚\nIntroduction æœ€è¿‘çš„ NLP æ–‡ç»è¦‹è­‰äº†ã€Œå»ºæ§‹å¯ä»¥éµå¾ªè‡ªç„¶èªè¨€æŒ‡ä»¤çš„æ¨¡å‹æ–¹é¢ã€çš„å¤§é‡æ´»å‹•ã€‚\né€™äº›ç™¼å±•ç”±å…©å€‹é—œéµéƒ¨åˆ†çµ„æˆï¼š\nå¤§å‹é è¨“ç·´èªè¨€æ¨¡å‹ (LM) äººå·¥ç·¨å¯«çš„æŒ‡ä»¤è³‡æ–™ PromptSource å’Œ SuperNaturalInstructions æ˜¯æœ€è¿‘å…©å€‹è‘—åçš„è³‡æ–™é›†ã€‚ ä»–å€‘é€éå¤§é‡æ‰‹å‹•è¨»é‡‹ä¾†æ”¶é›†æŒ‡ä»¤ï¼Œä»¥å»ºé€  T0 å’Œ T$k$-Instructã€‚\nç„¶è€Œé€™éç¨‹ä»£åƒ¹é«˜æ˜‚ï¼Œè€Œä¸”ç”±æ–¼å¤§å¤šæ•¸äººå¾€å¾€ç”Ÿæˆçš„éƒ½æ˜¯æµè¡Œçš„ NLP ä»»å‹™ï¼Œä½¿å…¶æœªèƒ½æ¶µè“‹çœŸæ­£å¤šæ¨£çš„ä»»å‹™ï¼Œä¹Ÿä¸èƒ½æ¶µè“‹å„ç¨®æè¿°ä»»å‹™çš„ä¸åŒæ–¹å¼ï¼Œå› æ­¤å¤šæ¨£æ€§å—ä¾·é™ã€‚\né‘’æ–¼é€™äº›é™åˆ¶ï¼Œæƒ³è¦ç¹¼çºŒæå‡ instruction-tuned models çš„å“è³ªï¼Œéœ€è¦å¹« supervising instruction-tuned models ç™¼å±•æ›¿ä»£æ–¹æ¡ˆã€‚\næœ¬æ–‡ä»‹ç´¹äº† Self-Instructï¼Œé€™æ˜¯ä¸€ç¨® semi-automated çš„éç¨‹ï¼Œç”¨æ¨¡å‹è‡ªèº«çš„ instructional signals å° pretrained LM é€²è¡Œ instruction-tuningã€‚\næ•´å€‹æµç¨‹æ˜¯ä¸€ç¨® iterative bootstrapping algorithmï¼Œå¾æ‰‹å‹•ç·¨å¯«çš„ limited seed set å¼•å°ç”Ÿæˆã€‚\nåœ¨ç¬¬ä¸€éšæ®µï¼Œæ¨¡å‹è¦å¹«æ–°ä»»å‹™ç”ŸæˆæŒ‡ä»¤ã€‚ åˆ©ç”¨ç¾æœ‰çš„æŒ‡ä»¤é›†åˆï¼Œå‰µå»ºæ›´å»£æ³›çš„æŒ‡ä»¤ï¼Œå¥½å®šç¾© (é€šå¸¸æ˜¯æ–°çš„) ä»»å‹™ã€‚\nå°æ–¼æ–°ç”Ÿæˆçš„æŒ‡ä»¤é›†ï¼Œæ¡†æ¶ç‚ºä»–å€‘å‰µå»º input-output instancesï¼Œç¨å¾Œå¯ä»¥é€é supervising ç”¨æ–¼ instruction tuningã€‚\næœ€å¾Œï¼Œé€éå„ç¨®æ‰‹æ®µï¼Œåœ¨ä½å“è³ªå’Œé‡è¤‡çš„æŒ‡ä»¤åŠ åˆ° task pool å‰ï¼ŒæŠŠä»–å€‘ä¿®å‰ªæ‰ã€‚\nå¯ä»¥é‡è¤‡é€™å€‹æµç¨‹éå¸¸å¤šæ¬¡ï¼Œç›´åˆ°ç²å¾—å¤§é‡ä»»å‹™ã€‚\nè©²æ¨¡å‹çš„è·Œä»£éç¨‹ä¸­ç”¢ç”Ÿäº†å¤§ç´„ 52K å€‹æŒ‡ä»¤ï¼Œèˆ‡å¤§ç´„ 85K å€‹ instance inputs å’Œ target outputs é…å° (æœ‰äº›ç›¸åŒçš„æŒ‡ä»¤æœƒå°æ‡‰å¤šç¨®è¼¸å…¥è¼¸å‡º)ã€‚\nä½œè€…è§€å¯Ÿåˆ°ç”Ÿæˆçš„è³‡æ–™æä¾›äº†å„ç¨®æœ‰å‰µæ„çš„ä»»å‹™ï¼Œå…¶ä¸­è¶…é 50% çš„ä»»å‹™å’Œ seed instructions çš„ ROUGE-L overlap å°æ–¼ 0.3ã€‚\nåŸºæ–¼ä¸Šè¿°çµæœï¼Œä½œè€…é€šéå¾®èª¿ GPT3 (å’Œç”ŸæˆæŒ‡ä»¤è³‡æ–™æ˜¯åŒå€‹æ¨¡å‹) å»ºæ§‹äº† $GPT3_{SELF-INST}$ã€‚\nSuperNI çš„çµæœè¡¨æ˜ï¼Œ$GPT3_{SELF-INST}$ æ€§èƒ½å¤§å¤§å„ªæ–¼ GPT3 (åŸå§‹æ¨¡å‹)ï¼Œé«˜äº† 33.1%ï¼Œå¹¾ä¹å’Œ $InstructGPT_{001}$ çš„æ€§èƒ½ç›¸ç•¶ã€‚\næ­¤å¤–ï¼Œä½œè€…åœ¨æ–°å‰µå»ºçš„çš„æŒ‡ä»¤é›†ä¸Šé€²è¡Œäººå·¥è©•ä¼°ï¼Œ$GPT3_{SELF-INST}$ é¡¯ç¤ºå‡ºå»£æ³›çš„æŒ‡ä»¤éµå¾ªèƒ½åŠ›ï¼Œå„ªæ–¼åœ¨å…¶ä»–å…¬é–‹å¯ç”¨æŒ‡ä»¤æ•¸æ“šé›†ä¸Šè¨“ç·´çš„æ¨¡å‹ï¼Œåªæ¯” InstrcutGPT001 è½å¾Œ 5%ã€‚\næœ¬æ–‡è²¢ç»ï¼š\nSelf-Instructï¼šä¸€ç¨®ç”¨æœ€å°‘çš„äººå·¥æ¨™è¨˜æ•¸æ“šå¼•å°æŒ‡ä»¤éµå¾ªèƒ½åŠ›çš„ä½œæ³• é€šéå¤§é‡çš„ instruction-tuning å¯¦é©—ï¼Œè­‰æ˜äº†æœ‰æ•ˆæ€§ã€‚ ç™¼å¸ƒäº†ä¸€å€‹åŒ…å« 52K æŒ‡ä»¤çš„å¤§å‹ç¶œåˆè³‡æ–™é›†ï¼Œé‚„æœ‰ä¸€çµ„æ‰‹å‹•ç·¨å¯«çš„æ–°ä»»å‹™ï¼Œç”¨æ–¼å»ºæ§‹å’Œè©•ä¼°æœªä¾†çš„ instruction-following modelsã€‚ Related Work Instruction-following language models ä¸€ç³»åˆ—å·¥ä½œé¡¯ç¤ºï¼Œä½¿ç”¨ annotated \u0026ldquo;instructional\u0026rdquo; dataï¼Œå¯ä»¥ä½¿æ™®é€šèªè¨€æ¨¡å‹éµå¾ªä¸€èˆ¬èªè¨€çš„æŒ‡ä»¤ã€‚\nä¹Ÿé¡¯ç¤ºå‡º \u0026ldquo;instructional\u0026rdquo; data çš„å¤§å°å’Œå¤šæ¨£æ€§ç›´æ¥å½±éŸ¿æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚\næœ¬æ–‡çš„å·¥ä½œç›®çš„åœ¨æ¸›å°‘å°äººå·¥è¨»é‡‹è€…çš„ä¾è³´ã€‚\nLanguage models for data generation and augmentation è¨±å¤šå·¥ä½œä¾è³´ç”Ÿæˆå¼ LM ä¾†ç”Ÿæˆæ•¸æ“šæˆ–åš augmentationã€‚\né›–ç„¶ä½œè€…çš„å·¥ä½œå¯è¢«è¦–ç‚ºä¸€ç¨® augmentationï¼Œä½†å’Œé€™äº›å·¥ä½œçš„å·®åˆ¥åœ¨æ–¼ä¸é™æ–¼ç‰¹å®šä»»å‹™ã€‚\nSelf-Instruct çš„ä¸€å€‹æ˜é¡¯å‹•æ©Ÿæ˜¯å¼•å°å‡ºæ–°çš„ä»»å‹™å®šç¾©ï¼Œè€Œé€™äº›ä»»å‹™å¯èƒ½é‚„æœªè¢« NLP çš„ç ”ç©¶è€…å®šç¾©éã€‚\nSelf-training ä¸€ç¨®å…¸å‹çš„ self-training æ¡†æ¶é€éç¶“éè¨“ç·´çš„æ¨¡å‹ï¼Œå¹« unlabeled è³‡æ–™é€²è¡Œ labelï¼Œç„¶å¾Œç”¨é€™äº›è³‡æ–™æ”¹é€²æ¨¡å‹ã€‚\né›–ç„¶ Self-Instruct å’Œ self-training æœ‰ä¸€äº›ç›¸ä¼¼ä¹‹è™•ï¼Œä½†å¤šæ•¸ self-training çš„æ–¹æ³•éƒ½å‡è¨­äº†ä¸€å€‹ç‰¹å®šçš„ç›®æ¨™ä»»å‹™ã€‚\nç›¸æ¯”ä¹‹ä¸‹ï¼ŒSelf-Instruct å¾é ­é–‹å§‹ç”Ÿå‡ºå„ç¨®ä»»å‹™ã€‚\nKnowledge distillation é€™é‚Šæˆ‘æƒ³ä¸å¤ªé€šç‚ºä»€éº¼å¯ä»¥å’Œ Knowledge distillation æ‰¯ä¸Šé—œä¿‚\nKnowledge distillation é€šå¸¸æ¶‰åŠçŸ¥è­˜å¾è¼ƒå¤§æ¨¡å‹åˆ°è¼ƒå°æ¨¡å‹çš„è½‰ç§»\nSelf-Instruct ä¹Ÿå¯ä»¥çœ‹åšæ˜¯ Knowledge distillation çš„ä¸€ç¨®å½¢å¼ï¼Œä½†å€åˆ¥å¦‚ä¸‹\ndistillation çš„ä¾†æºå’Œç›®æ¨™æ˜¯ç›¸åŒçš„ï¼Œå³æ¨¡å‹çš„çŸ¥è­˜è¢« distill åˆ°ä»–è‡ªå·± distill çš„å…§å®¹ä»¥ instruction task çš„å½¢å¼å‡ºç¾ Method æ¨™è¨˜å¤§è¦æ¨¡æŒ‡ä»¤è³‡æ–™å°äººé¡ä¾†èªªå¯èƒ½å…·æœ‰æŒ‘æˆ°æ€§ï¼Œå› ç‚ºä»–éœ€è¦\nå‰µæ„ï¼Œå¥½æå‡ºæ–°ä»»å‹™ ç‚ºæ¯å€‹ä»»å‹™ç·¨å¯« labeled instances çš„å°ˆæ¥­çŸ¥è­˜ Defining Instruction Data æˆ‘å€‘è¦ç”Ÿæˆçš„æŒ‡ä»¤è³‡æ–™é›†åŒ…å« {$I_t$}ï¼Œæ¯å€‹æŒ‡ä»¤ç”¨è‡ªç„¶èªè¨€å®šç¾©äº†ä»»å‹™ $t$ã€‚\næ¯å€‹ä»»å‹™éƒ½æœ‰ä¸€å€‹æˆ–å¤šå€‹ input-output instances ($X_t,Y_t$)ã€‚\nçµ¦å®š task instruction $I_t$ï¼Œé‚„æœ‰ instance xï¼Œæ¨¡å‹ M è¦ç”Ÿå‡º yï¼š\n$M(I_t,x)=y, for (x,y) \\in (X_t,Y_t)$\nå€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œinstance input å’Œ instruction æ²’æœ‰åš´æ ¼åˆ†ç•Œã€‚\næ¯”å¦‚ Instruction:\u0026ldquo;write an essay about school safety\u0026rdquo; x:\u0026quot;\u0026quot;ï¼Œå¯ä»¥è¢«æ”¹ç‚º Instruction:\u0026ldquo;write an essay about the following topic\u0026rdquo; x:\u0026ldquo;school safety\u0026rdquo;\nAutomatic Instruction Data Generation ç”ŸæˆæŒ‡ä»¤è³‡æ–™çš„ pipeline åˆ†æˆå››å€‹æ­¥é©Ÿï¼š\næŒ‡ä»¤ç”Ÿæˆ è¾¨è­˜æŒ‡ä»¤æ˜¯å¦æ˜¯åˆ†é¡ä»»å‹™ ç”¨ input-first æˆ– output-first åš instance generation éæ¿¾æ‰ä½å“è³ªçš„è³‡æ–™ Instruction Generation Self-Instruct æ˜¯åŸºæ–¼ä¸€å€‹ç™¼ç¾ï¼Œä¹Ÿå°±æ˜¯å¤§å‹èªè¨€æ¨¡å‹å¯ä»¥é€é context ä¸­çš„ç¾æœ‰æŒ‡ä»¤ï¼Œç”Ÿå‡ºæ–°ç©çš„æŒ‡ä»¤ã€‚\nç‚ºä½œè€…æä¾›äº†ä¸€ç¨®å¾ä¸€å°çµ„äººé¡ç·¨å¯«çš„æŒ‡ä»¤ä¸­ï¼Œä½¿æŒ‡ä»¤è³‡æ–™å¢é•·çš„åšæ³•ã€‚\nä½œè€…ç”¨ä»–å€‘ç·¨å¯«çš„ 175 å€‹ä»»å‹™ (æ¯å€‹ä»»å‹™ 1 å€‹ instruction å’Œ 1 å€‹ instance) åˆå§‹åŒ– task poolã€‚\nåœ¨æ¯ä¸€å€‹ stepï¼Œä½œè€…å¾è£¡é¢ sample 8 å€‹ instructionsï¼Œä½œç‚º in-context çš„ç¯„ä¾‹ã€‚åœ¨é€™ 8 å€‹æŒ‡ä»¤ä¸­ï¼Œæœ‰ 6 æ¢ä¾†è‡ªäººå·¥ç·¨å¯«çš„ä»»å‹™ï¼Œå¦å¤–å…©æ¢ä¾†è‡ªå‰é¢æ­¥é©Ÿä¸­æ¨¡å‹ç”Ÿæˆçš„ä»»å‹™ï¼Œä»¥ä¿ƒé€²å¤šæ¨£æ€§ã€‚\nClassification Task Identification å› ç‚ºå°æ–¼åˆ†é¡å’Œéåˆ†é¡çš„ä»»å‹™ï¼Œä½œè€…æœƒæ¡å–å…©ç¨®åšæ³•ï¼Œæ‰€ä»¥ä½œè€…ä½¿ç”¨ä¾†è‡ª seed taks çš„ 12 æ¢åˆ†é¡æŒ‡ä»¤å’Œ 19 æ¢éåˆ†é¡æŒ‡ä»¤ï¼Œè®“ GPT3 é€é few-shot ä¾†åˆ¤åˆ¥ã€‚\nInstance Generation çµ¦äºˆæŒ‡ä»¤å’Œä»–å€‘çš„ä»»å‹™é¡åˆ¥ï¼Œä½œè€…ç¨ç«‹åœ°ç‚ºæ¯æ¢æŒ‡ä»¤ç”Ÿæˆ instanceã€‚\né€™å…·å‚™æŒ‘æˆ°æ€§ï¼ŒåŸå› åœ¨æ–¼ä»–éœ€è¦æ¨¡å‹ç­è§£ç›®æ¨™ä»»å‹™æ˜¯ä»€éº¼ï¼Œæ ¹æ“šæŒ‡ä»¤æ‰¾å‡ºéœ€è¦é‚£äº›é¡å¤–çš„è¼¸å…¥å…§å®¹ï¼Œä¸¦ç”Ÿæˆä»–å€‘ã€‚ (æ¨¡å‹è¦æ ¹æ“š instruction ç”Ÿå‡º instance input)\nä½œè€…ç™¼ç¾ï¼Œåœ¨ prompt ä¸­æ”¾å…¥å…¶ä»–åŒ…å« instruction-input-output çš„ä»»å‹™ç¯„ä¾‹çš„æ™‚å€™ï¼Œæ¨¡å‹å¯ä»¥å¯¦ç¾é€™é»ã€‚\nä¸€ç¨®è‡ªç„¶çš„æ–¹æ³•æ˜¯ Input-first Approachï¼Œå¯ä»¥è¦æ±‚èªè¨€æ¨¡å‹å…ˆæ ¹æ“šæŒ‡ä»¤æå‡º inputï¼Œå†ç”Ÿå‡ºç›¸æ‡‰çš„ outputã€‚\nç„¶è€Œï¼Œé€™ç¨®æ–¹æ³•åœ¨åˆ†é¡ä»»å‹™ä¸Šï¼Œå¯èƒ½æœƒåå‘æ–¼ç”ŸæˆæŸç¨® labelã€‚æ‰€ä»¥ï¼Œå°æ–¼åˆ†é¡ä»»å‹™ï¼Œä½œè€…æ¡ç”¨ Output-first Approachï¼Œå…ˆç”Ÿæˆå¯èƒ½çš„ labelï¼Œåœ¨æ¯å€‹ label ä¸Šå†ç”Ÿæˆè¼¸å…¥ã€‚\nFiltering and Postprocessing ç‚ºäº†é¼“å‹µå¤šæ¨£æ€§ï¼Œåªæœ‰ç•¶æ–°çš„æŒ‡ä»¤å’Œä»»ä½•ç¾æœ‰çš„æŒ‡ä»¤çš„ ROUGE-L overlapping å°æ–¼ 0.7 çš„æ™‚å€™ï¼Œæ‰æœƒè¢«æ·»åŠ åˆ° task poolã€‚\né‚„æ’é™¤äº†ä¸€äº›åŒ…å«äº†é€šå¸¸ä¸èƒ½è¢« LM è™•ç†çš„é—œéµå­— (e.g. images, pictures, graphs) çš„æŒ‡ä»¤ã€‚\nåœ¨ç‚ºæ¯å€‹æŒ‡ä»¤ç”Ÿæˆæ–°çš„ instance çš„æ™‚å€™ï¼Œæœƒéæ¿¾æ‰å®Œå…¨ç›¸åŒæˆ–è€…æ˜¯è¼¸å…¥ç›¸åŒä½†è¼¸å‡ºä¸åŒçš„ instanceã€‚\nFinetuning the LM to Follow Instructions åœ¨å‰µå»ºå¤§è¦æ¨¡æŒ‡ä»¤è³‡æ–™å¾Œï¼Œç”¨é€™äº›è³‡æ–™å°åŸå§‹èªè¨€æ¨¡å‹é€²è¡Œ fine-tuneã€‚\nç‚ºæ­¤ï¼Œå°‡ instruction å’Œ instance input é€£æ¥èµ·ä¾†ï¼Œä½œç‚º promptï¼Œç„¶å¾Œè¨“ç·´æ¨¡å‹é€éæ¨™æº–çš„ç›£ç£å¼å­¸ç¿’é€²è¡Œå¾®èª¿ã€‚\nç‚ºäº†è®“æ¨¡å‹å°ä¸åŒçš„æ ¼å¼ robustï¼Œä½¿ç”¨å¤šå€‹æ¨¡æ¿å°‡æŒ‡ä»¤å’Œè¼¸å…¥ encode åœ¨ä¸€èµ·ã€‚\nä¾‹å¦‚ï¼ŒæŒ‡ä»¤å¯ä»¥æœ‰æˆ–æ²’æœ‰ Task: å‰å¢œã€è¼¸å…¥å¯ä»¥æœ‰æˆ–æ²’æœ‰ Input: å‰å¢œï¼Œæˆ–æ˜¯ä¸­é–“å¯ä»¥æœ‰ä¸åŒæ•¸é‡çš„æ›è¡Œä¹‹é¡çš„ã€‚\nSelf-Instruct Data from GPT3 ä½œè€…é€é OpenAI API è¨ªå•æœ€å¤§çš„ GPT3 (davinci)\nStatistics Diversity Quality Experimental Results $GPT3_{SELF-INST}$: fine-tuning GPT3 on its own instruction data ä½¿ç”¨ç”Ÿå‡ºä¾†çš„æŒ‡ä»¤è³‡æ–™ï¼Œå° GPT3 é€²è¡Œå¾®èª¿ã€‚\nå¾®èª¿æ˜¯é€é OpenAI finetuning API\nBaselines Off-the-shelf language models T5-LM å’Œ GPT3 æ˜¯æ™®é€š LM baselines (åªæœ‰ pre-trainingï¼Œæ²’æœ‰é¡å¤– fine-tune)\né€™äº› baseline å°‡è¡¨æ˜ç¾æˆçš„ LM åœ¨é è¨“ç·´å¾Œï¼Œèƒ½å¤ ç«‹åˆ»è‡ªç„¶åœ°éµå¾ªæŒ‡ä»¤çš„ç¨‹åº¦ã€‚\nPublicly-available instruction-tuned models T0 å’Œ $T_k$-Instruct æ˜¯å…©å€‹ instruction-tuned modelsã€‚\nå…©è€…éƒ½æ˜¯å¾ T5 é€²è¡Œå¾®èª¿çš„ï¼Œå°é€™å…©ç¨®æ¨¡å‹ï¼Œéƒ½ä½¿ç”¨å…·æœ‰ 11B åƒæ•¸çš„æœ€å¤§ç‰ˆæœ¬ã€‚\nInstruction-tuned GPT3 models ä½œè€…è©•ä¼°äº† InstructGPTï¼Œå®ƒæ˜¯ OpenAI åŸºæ–¼ GPT3 é–‹ç™¼çš„ã€‚\nå°æ–¼ SuperNI çš„å¯¦é©—ï¼Œåªèˆ‡ text-davinci-001 engine é€²è¡Œæ¯”è¼ƒï¼Œå› ç‚ºæ›´æ–°çš„ engine ç”¨æœ€æ–°çš„ç”¨æˆ¶è³‡æ–™ï¼Œè€Œä¸”å¾ˆå¯èƒ½å·²ç¶“çœ‹é SuperNIã€‚\nå°æ–¼æ–°ç·¨å¯«çš„æŒ‡ä»¤ï¼Œè©•ä¼°æ™‚å‰‡åŒ…å«äº† 001ã€002 å’Œ 003ï¼Œä»¥ç¢ºä¿å®Œæ•´æ€§ã€‚\nç‚ºäº†é€²ä¸€æ­¥æ¯”è¼ƒ Self-Instruct åœ¨å…¶ä»–å…¬é–‹å¯ç”¨çš„æŒ‡ä»¤è¨“ç·´é›†è³‡æ–™ï¼Œä½¿ç”¨ PromptSource å’Œ SuperNI çš„è³‡æ–™å¾®èª¿ GPT3ï¼Œé€™äº›è³‡æ–™ç”¨æ–¼è¨“ç·´ T0 å’Œ $T_k$-Instruct æ¨¡å‹ã€‚\nåˆ†åˆ¥ç°¡ç¨±ç‚º T0 è¨“ç·´å’Œ SuperNI è¨“ç·´ã€‚\nExperiment 1: Zero-Shot Generalization on SUPERNI benchmark é¦–å…ˆä»¥ zero-shot çš„æ–¹å¼è©•ä¼°å…¸å‹ NLP ä»»å‹™éµå¾ªæŒ‡ä»¤çš„èƒ½åŠ›ã€‚\nResults Experiment 2: Generalization to User-oriented Instructions on Novel Tasks ç›¡ç®¡ SuperNI åœ¨ç¾æœ‰çš„ NLP ä»»å‹™å…·æœ‰å…¨é¢æ€§ï¼Œå¤šæ•¸çš„é€™äº›ä»»å‹™æ˜¯åˆæ–¼ç ”ç©¶ç†ç”±æå‡ºçš„ï¼Œè€Œä¸”åå‘åˆ†é¡ã€‚\nç‚ºäº†æ›´å¥½çš„ç²å–æŒ‡ä»¤éµå¾ªæ¨¡å‹çš„å¯¦ç”¨åƒ¹å€¼ï¼Œä½œè€…ä¸­çš„ä¸€éƒ¨åˆ†äººç­–åŠƒäº†ä¸€çµ„é¢å‘ç”¨æˆ¶æ‡‰ç”¨çš„æ–°æŒ‡ä»¤é›†ã€‚\nä»–å€‘å…ˆé‡å° Large LM å¯èƒ½å¯ä»¥æ‡‰ç”¨åˆ°çš„é ˜åŸŸé€²è¡Œ brainstormï¼Œä¸¦ä¸”åˆ¶å®šèˆ‡æ¯å€‹é ˜åŸŸç›¸é—œçš„ instruction å’Œ instanceã€‚\nç¸½å…±å‰µå»ºäº† 252 æ¢æŒ‡ä»¤ï¼Œæ¯æ¢æŒ‡ä»¤æœ‰ 1 å€‹ instanceã€‚\nHuman evaluation setup è©•ä¼°æ¨¡å‹åœ¨é€™äº›ä¸åŒä»»å‹™çš„æ¸¬è©¦é›†ä¸Šçš„è¡¨ç¾æ¥µå…·æŒ‘æˆ°æ€§ï¼Œå› ç‚ºä¸åŒçš„ä»»å‹™éœ€è¦ä¸åŒçš„å°ˆæ¥­çŸ¥è­˜ã€‚\nç‚ºäº†ç²å¾—æ›´å¿ å¯¦çš„è©•åƒ¹ï¼Œä½œè€…è«‹äº† instructions çš„ä½œè€…å°æ¨¡å‹çš„é æ¸¬çµæœé€²è¡Œè©•ä¼°ã€‚\nå¯¦æ–½ä¸€å€‹ four-level rating systemï¼š\nRating A å›è¦†æœ‰æ•ˆä¸”ä»¤äººæ»¿æ„ Rating B å›è¦†å¯æ¥å—ï¼Œä½†å­˜åœ¨å¯ä»¥æ”¹é€²çš„åœ°æ–¹ Rating C å›è¦†ç›¸é—œï¼Œä½†åœ¨å…§å®¹ä¸Šæœ‰é‡å¤§éŒ¯èª¤ Rating D å›è¦†ä¸ç›¸é—œæˆ–ç„¡æ•ˆï¼ŒåŒ…å«é‡è¤‡è¼¸å…¥çš„éƒ¨åˆ†ï¼Œå®Œå…¨ç„¡é—œçš„è¼¸å‡ºã€‚ Results å¦‚æœæŠŠ Rating B ä»¥ä¸Šè¦–ç‚ºæœ‰æ•ˆï¼Œ$GPT_{SELF-INST}$ åªå’Œ $InstructGPT_{001}$ ç›¸å·® 5%\nDiscussion and Limitation Why does SELF-INSTRUCT work? å€¼å¾—åæ€çš„æ˜¯ï¼Œåœ¨æœ€è¿‘æˆåŠŸçš„ instruction-tuning LMs ä¸­ï¼Œé«˜å“è³ªçš„ human feedback æ‰®æ¼”çš„è§’è‰²ã€‚\né€™è£¡æœ‰å…©å€‹æ¥µç«¯çš„å‡è¨­ï¼š\nHuman feedback æ˜¯ instruction-tuning ä¸­å¿…è¦ä¸”ä¸å¯æˆ–ç¼ºçš„è§’è‰²ï¼Œå› ç‚º LM éœ€è¦äº†è§£åœ¨é è¨“ç·´éç¨‹ä¸­æ²’å®Œå…¨äº†è§£åˆ°çš„å•é¡Œã€‚\nHuman feedback æ˜¯ instruction-tuning ä¸€å€‹å¯é¸çš„æ–¹å‘ï¼Œå› ç‚º LM åœ¨é è¨“ç·´å°±å·²ç¶“å¾ˆç†Ÿæ‚‰æŒ‡ä»¤äº†ã€‚\né›–ç„¶ç¾å¯¦å¯èƒ½ä»‹æ–¼é€™å…©å€‹æ¥µç«¯ä¹‹é–“ï¼Œä½œè€…æ¨æ¸¬å¯èƒ½æ›´å‚¾å‘æ–¼ç¬¬äºŒç¨®å‡è¨­ï¼Œå°¤å…¶æ˜¯å°æ–¼è¼ƒå¤§çš„æ¨¡å‹ã€‚\nç¬¬äºŒç¨®ï¼Œä¹Ÿæ˜¯äººé¡ç›´è¦ºï¼Œæ˜¯ Self- Instruct çš„é—œéµå‹•æ©Ÿï¼Œè€Œä¸”ä¹Ÿå¾æˆåŠŸçš„çµæœç²å¾—æ”¯æŒã€‚\nBroader Impact é™¤äº†æœ¬æ–‡çš„ç›´æ¥é—œæ³¨é»å¤–ï¼Œä½œè€…ç›¸ä¿¡ Self-Instruct å¯èƒ½æœ‰åŠ©æ–¼æ­éœ²å„ç¨® instruction tuning æ¨¡å‹ \u0026ldquo;å¹•å¾Œ\u0026rdquo; ç™¼ç”Ÿçš„äº‹æƒ…ã€‚\nä¸å¹¸çš„æ˜¯ï¼Œç”±æ–¼ä»–å€‘çš„è³‡æ–™é›†å°šæœªç™¼å¸ƒï¼Œé€™ç¨®æ¥­ç•Œæ¨¡å‹ä»è™•æ–¼ API ç‰†ä¹‹å¾Œã€‚\näººå€‘å°å…¶çµæ§‹ä»¥åŠç‚ºä½•èƒ½å±•ç¾ä»¤äººå°è±¡æ·±åˆ»çš„èƒ½åŠ›çŸ¥ä¹‹ç”šå°‘ã€‚\nLimitations of Self-Instruct Tail phenomena Self-Instruct ä¾è³´æ–¼ LMï¼Œç¹¼æ‰¿ LM çš„æ‰€æœ‰é™åˆ¶ã€‚\næœ€è¿‘çš„ç ”ç©¶é¡¯ç¤ºå‡º tail phenomena å° LM çš„æˆåŠŸæ§‹æˆåš´å³»çš„æŒ‘æˆ°ã€‚\næ›å¥è©±èªªï¼ŒLM çš„æœ€å¤§æ”¶ç›Šå‡ºç¾æ–¼èªè¨€ä¸­æœ€é »ç¹å‡ºç¾çš„éƒ¨åˆ† (èªè¨€åˆ†ä½ˆçš„é ­éƒ¨)ï¼Œè€Œä½é »ç‡å‡ºç¾çš„ä¸Šä¸‹æ–‡ä¸­ç²å¾—çš„æ”¶ç›Šæœ€å°ã€‚\nåŒæ¨£çš„ï¼Œåœ¨é€™é …å·¥ä½œèƒŒæ™¯ä¸‹ï¼Œå¦‚æœ Self-Instruct å¤§éƒ¨åˆ†çš„æ”¶ç›Šåå‘é è¨“ç·´ corpus ä¸­é »ç¹å‡ºç¾çš„ä»»å‹™æˆ–æŒ‡ä»¤ï¼Œé‚£ä¹Ÿä¸ä»¤äººæ„Ÿåˆ°æ„å¤–ã€‚\nå› æ­¤ï¼Œè©²æ–¹æ³•åœ¨ä¸å¸¸è¦‹å’Œæœ‰å‰µæ„çš„æŒ‡ä»¤ä¸‹ï¼Œå¯èƒ½æœƒé¡¯ç¾å‡ºè„†å¼±æ€§ã€‚\nDependence on large models å› ç‚º Self-Instruct ä¾è³´æ–¼å¾ LM ä¸­æå–åˆçš„ inductive biasï¼Œå› æ­¤å®ƒå¯èƒ½é©åˆ larger modelã€‚\nå¦‚æœé€™æ˜¯å°çš„ï¼Œé€™æœƒå°é‚£äº›æ²’æœ‰å¤§é‡è¨ˆç®—è³‡æºçš„äººé€ æˆé˜»ç¤™ã€‚\nReinforcing LM biases ä½œè€…æ“”å¿ƒé€™ç¨®è¿­ä»£ä½œæ³•å¯èƒ½æœƒç”¢ç”Ÿæ„æ–™ä¹‹å¤–çš„çµæœï¼Œæ¯”å¦‚å°‡æœ‰å•é¡Œçš„ç¤¾æœƒåè¦‹æ”¾å¤§ã€‚\n","date":"2023-04-30T00:00:12+08:00","permalink":"https://roykesydon.github.io/Blog/p/self-instruct-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"Self-Instruct è«–æ–‡é–±è®€"},{"content":"Memory Map CPU å° I/O æ“ä½œæ–¹æ³•\nPort I/O ç”¨ç‰¹æ®Š CPU æŒ‡ä»¤ I/O è¨­å‚™å’Œè¨˜æ†¶é«”ä¸å…±äº«åœ°å€ç©ºé–“ Memory-Mapped I/O I/O è¨­å‚™å’Œè¨˜æ†¶é«”å…±äº«åœ°å€ç©ºé–“ åƒä¸€èˆ¬æ§åˆ¶è¨˜æ†¶é«” é€™å¡Šè¨˜æ†¶é«”å…·æœ‰å››å€‹è²¬ä»»\nCommand Status Output Data Input Data GPIO çµæ§‹ GPIO mode Open-Drain ç”±å¤–éƒ¨é›»å£“æ±ºå®šè¼¸å‡ºé›»å£“ Output Register æ˜¯ 0 æœƒå•Ÿç”¨ N-MOSï¼Œ1 çš„è©±é å¤–éƒ¨é›»å£“æ¨ å¥½è™•æ˜¯å¤–éƒ¨é›»å£“å¯ä»¥è‡ªå·±æ±ºå®š Push-Pull ç”±å…§éƒ¨é›»å£“æ±ºå®šè¼¸å‡ºé›»å£“ Output Register æ˜¯ 0 æˆ– 1 æœƒæ±ºå®šå•Ÿç”¨ N-MOS æˆ–æ˜¯ P-MOS æœ‰é—œ Register Clock enable register AHB2 peripheral clock enable regisetr (RCC_AHB2ENR) Control register GPIO port mode register GPIO port output type register GPIO port output speed register GPIO port pull-up/pull-down register Data register Output Input ä½¿ç”¨ GPIO å…ˆå» Memory map æ‰¾ Boudary address\næ ¹æ“š table ç¢ºèªè¦è¨­ç½®çš„æ•¸å€¼\nè¨­å®š RCC enable\næŠŠä¸Šé¢èªªçš„å„ç¨® Control register è¨­å®šå¥½\næ¯”å¦‚ PUPDR BSRR\nä¿®æ”¹ ODR æœƒä¸€æ¬¡æ”¹åˆ°æ•´å€‹ GPIO portï¼Œè‹¥åªè¦æ”¹æŸå€‹ pinï¼Œå¯ä»¥ç”¨ BSRR Delay\nCPU 4 MHz 1 cycle = 0.25$\\mu$S å¯ä»¥æŸ¥æ¯å€‹çµ„åˆèªè¨€æŒ‡ä»¤è¦å¹¾å€‹ cycle æ©Ÿæ¢°æŒ‰éˆ•æœƒæœ‰ Bouncing\nDebounce Hardware method åŠ ä¸Šæ¿¾æ³¢é›»å®¹ Software method è®€å–å¾Œç­‰å¾…ä¸€æ®µæ™‚é–“æ‰å†æ¬¡è®€å– é€£çºŒè®€å– N æ¬¡ï¼Œçœ‹æ•¸å€¼æ˜¯å¦ç©©å®šæ”¹è®Š 7-Segment COM åˆ†å…±é™½ã€å…±é™°\n8 å€‹ä¸ƒæ®µé¡¯ç¤ºå™¨å°±è¦åƒæ‰ 8 * 8 å€‹ GPIO æ¥è…³ï¼Œå¯ä»¥æ¯æ¬¡åªé¡¯ç¤ºä¸€å€‹ï¼Œé‚£åªéœ€è¦ 8 å€‹ GPIO æ¥è…³ï¼Œå¿«é€Ÿé–ƒé\nä¹Ÿå¯ç”¨ Max 7219 æ§åˆ¶ï¼Œä»–æœ‰ä¸‰å€‹è¼¸å…¥ DINã€LOADã€CLK\nDIN è¼¸å…¥è³‡æ–™ CLK ä¸Šå‡çš„æ™‚å€™æ¡æ¨£ï¼Œæœ€å¤š 10 MHz LOAD(CS) æ¡ç”¨æœ€å¾Œè¼¸é€²å»çš„ 16 bits æœ€æ—©çš„æ˜¯ MSB ","date":"2023-04-26T01:32:54+08:00","permalink":"https://roykesydon.github.io/Blog/p/stm32-gpio-%E4%BB%8B%E7%B4%B9/","title":"STM32 GPIO ä»‹ç´¹"},{"content":"é‡æ§‹ åœ¨ä¸æ”¹è®Šè»Ÿé«”è¡Œç‚ºçš„æƒ…æ³ä¸‹ï¼Œå°è»Ÿé«”å…§éƒ¨æ§‹é€ é€²è¡Œæ”¹å–„\nCode Smell ä¹Ÿç¨± Bad Smellï¼Œä»£è¡¨ç¨‹å¼ç¢¼ä¸­éœ€è¦é‡æ§‹çš„éƒ¨åˆ†\nDuplicated Code é‡è¤‡ç¨‹å¼ç¢¼ åœ¨åŒå€‹ Class Extract Method åœ¨ä¸åŒ Class Extract Class Long Method ç”¨ Extract Method æ‹†è§£éé•·çš„ function Long Parameter List Preserve Whole Object æŠŠä¾†è‡ªåŒä¸€ç‰©ä»¶çš„è³‡æ–™ç›´æ¥è©²ç‰©ä»¶å–ä»£ Introduce Parameter Object æŠŠç›¸é—œçš„è³‡æ–™åŒ…æˆä¸€å€‹ Object Large Class ä¸€å€‹ Class æœ‰å¤ªå¤š fields / methods / lines Magic Number ç‰¹æ®Šæ•¸å€¼ç›´æ¥ç”¨æ•¸å­—è¡¨ç¤ºï¼Œæ—¥å¾Œä¿®æ”¹æ¯å€‹åœ°æ–¹éƒ½è¦æ”¹ Lack of Comments åŠ è¨»è§£çš„å¥½æ™‚æ©Ÿï¼šå¯«ç¨‹å¼å‰å¯«ä¸Š Switch Statements å¯åˆ©ç”¨ã€Œå¤šå‹ (Polymorphism)ã€è§£æ±º Divergent Change ä¸€å€‹é¡åˆ¥æœ‰å¤ªå¤šæ”¹è®Šçš„åŸå›  ç›¡é‡è®“å…¶éµå®ˆ SRP Shotgun Surgery æŸå€‹è²¬ä»»è¢«åˆ†æ•£åˆ°å¤§é‡çš„ Class èº«ä¸Šï¼Œä½¿ä¿®æ”¹å…¶æ™‚è¦å¤§é‡ä¿®æ”¹ Feature Envy å­˜å–åˆ¥çš„ Object çš„ Data çš„æƒ…å½¢æ¯”è‡ªå·±çš„é‚„é »ç¹ é€™æ–¹æ³•å¯èƒ½æ‡‰è©²å±¬æ–¼å¦ä¸€å€‹ Object Data Clumps å¸¸ä¸€èµ·å‡ºç¾çš„è³‡æ–™ç¾¤æ‡‰è©²è¢«å–®ç¨æŠ½æˆä¸€å€‹ Class Primitive Obsession éåº¦ä½¿ç”¨åŸºæœ¬é¡åˆ¥ï¼Œé€ æˆ Shotgun Surgery Message Chains Client è«‹æ±‚ A ç‰©ä»¶ï¼ŒA ç‰©ä»¶åˆè«‹æ±‚ B ç‰©ä»¶ Lazy Class æŠŠå†—å“¡é¡åˆ¥ç§»é™¤ Temporary Field Instance variable åªæœ‰åœ¨ç‰¹æ®Šæƒ…å½¢æ‰è¢«ä½¿ç”¨ï¼Œæ‡‰è©²æ”¹ç‚ºå€åŸŸè®Šæ•¸æˆ–åƒæ•¸ Inappropriate Intimacy Classes é–“é »ç¹è®€å–å°æ–¹è³‡æ–™ ç†è§£ç¨‹å¼è¦åŒæ™‚çœ‹æ‡‚å…©è€… Alternative Classes with Different Interfaces å…©å€‹ Class å…·æœ‰åŠŸèƒ½ç›¸åŒã€å‘½åä¸åŒçš„ function å¯æ±²å–å…±åŒéƒ¨åˆ†ç‚º Super Class ä¾†è§£æ±º ","date":"2023-04-25T14:26:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E9%87%8D%E6%A7%8B-refactoring/","title":"é‡æ§‹ Refactoring"},{"content":"èªªæ˜ æœ¬æ–‡å¯«æ–¼ Swin Transformer è«–æ–‡é–±è®€ ä¹‹å¾Œï¼Œç•¶æ™‚å° Relatvie position çš„ç†è§£ä¸å¤ æ¸…æ¥šï¼Œæœ¬æ–‡å°‡æœƒåšè§£é‡‹ï¼Œä¸¦é™„ä¸ŠåŸè«–æ–‡çš„ç­†è¨˜ã€‚\nä»¥ä¸‹å°‡æœƒå…ˆç”¨é•·åº¦ç‚º 3 çš„åºåˆ—ä½œç‚ºç¤ºç¯„ã€‚\nAbsolute Position Encodings Absolute Position Encodings çš„åšæ³•æ˜¯æŠŠç”¨æŸç¨®æ–¹å¼ç”Ÿæˆæˆ–å¯å­¸ç¿’çš„å‘é‡åŠ åœ¨è¼¸å…¥ï¼Œç¬¬ä¸€å€‹ä½ç½®ç”¨ $w_1$ï¼Œç¬¬äºŒå€‹ä½ç½®ç”¨ $w_2$ï¼Œç¬¬ä¸‰å€‹ä½ç½®ç”¨ $w_3$ã€‚\nRelative Position Encodings Relative Position Encodings é¡§åæ€ç¾©ï¼Œå°±æ˜¯æ”¹ç”¨ç›¸å°ä½ç½®ä¾†åšé€™äº›å‘é‡ã€‚\nä¸Šåœ–ä¸­ï¼ŒPosition Encoding çš„éƒ¨åˆ†å¾ 3 å€‹å‘é‡è®Šæˆ 3*3 å€‹å‘é‡ï¼Œå› ç‚ºç¾åœ¨æœƒä»¥æ¯å€‹ token ç‚ºåŸºæº–ï¼Œç”Ÿå‡º 3 å€‹ç›¸å°ä½ç½®å‘é‡ã€‚\næˆ‘å€‘ä»¥ $w_0$ï¼Œä»£è¡¨è™•æ–¼åŸé»ï¼Œ$w_x$ ä»£è¡¨å¾€å³ $x$ æ ¼ï¼Œ$w_{-x}$ ä»£è¡¨å¾€å·¦ $x$ æ ¼ï¼Œå…¶ä¸­ $x$ æ˜¯æ­£æ•´æ•¸ã€‚\nç¬¬ä¸€å€‹ row æœ‰ $w_0$ã€$w_1$ã€$w_2$ï¼Œæ„æ€æ˜¯ä»¥ç¬¬ 0 å€‹å‘é‡ (I) ç‚ºåŸºæº–ï¼Œä»–çš„ä½ç½®æ˜¯ $w_0$ï¼Œå°ç¬¬ 0 å€‹å‘é‡ä¾†èªªï¼Œç¬¬ 1 å€‹å‘é‡ (like) æ˜¯ $w_1$ï¼Œç¬¬ 2 å€‹å‘é‡ (cat) æ˜¯ $w_2$ã€‚\nè¼ªæµä»¥ $n$ å€‹ token ç‚ºåŸºæº–ï¼Œå°±æœƒç”Ÿå‡º n*n å€‹ç›¸å°ä½ç½®å‘é‡ï¼Œè€Œä¸æ˜¯åŸå…ˆçš„ n å€‹çµ•å°ä½ç½®å‘é‡ã€‚\nå…¶ä¸­ $w_i$ å’Œ $w_j$ å¦‚æœ $i=j$ï¼Œä»–å€‘æœƒå…±ç”¨åŒæ¨£çš„ weightï¼Œä¸Šåœ–æ˜¯ä»¥ç›¸åŒé¡è‰²è¡¨ç¤ºã€‚\nå¦‚æœåºåˆ—é•·åº¦æ˜¯ $n$ï¼Œå°±æœƒæœ‰ $2n-1$ å€‹å‘é‡è¦å­¸ã€‚\nn*n é€™å€‹æ•¸é‡ä½¿å…¶é©åˆåŠ å…¥åˆ° self-attentionï¼ŒåŸå§‹è«–æ–‡çš„åŠ å…¥æ–¹å¼å¯ä»¥åƒè€ƒä¸‹æ–¹è«–æ–‡ç­†è¨˜ï¼Œé€™é‚Šæ™šé»æœƒä»‹ç´¹å¾ŒçºŒè¡ç”Ÿçš„ç°¡åŒ–ç‰ˆã€‚\nSwin Transformer å¦‚ä½•å°å…¥ Relative Position Encodings Swin Transformer æ˜¯å€Ÿé‘’è¨±å¤š CNN æ¶æ§‹ï¼Œç‚ºäº† CV è€Œç¶“éä¿®æ”¹çš„ vision transformerã€‚\nå…¶ä¸­ä¸€å€‹é‡é»æ˜¯ï¼Œä»–æœƒåœ¨ä¸€å°å€å¡Šçš„ç‰¹å¾µåœ–ä¸Šåš self-attentionï¼Œè€Œä¸”æ˜¯ç”¨ Relative Position Encodingsã€‚\nå’Œå‰›å‰›çš„å·®åˆ¥åœ¨æ–¼ï¼Œç¾åœ¨è¦åœ¨äºŒç¶­ç©ºé–“åš Relative Position Encodingsã€‚\nå‡è¨­æœ‰ä¸€å¼µ 2*2 çš„ feature mapï¼Œæˆ‘å€‘å…ˆè¨­å®šå¥½ feature map å„å€‹ token çš„çµ•å°ä½ç½®åº§æ¨™ã€‚\nç„¶å¾Œæˆ‘å€‘è¼ªæµæŠŠ feature map çš„æ¯ä¸€å€‹ token ä½œç‚ºåŸºæº–é»ï¼ŒæŠŠ feature map çš„æ¯å€‹ token çš„åº§æ¨™æ¸›å»åŸºæº–é»çš„åº§æ¨™ï¼Œå°±å¯ä»¥å¾—åˆ°ç›¸å°ä½ç½®åº§æ¨™ã€‚\nå¦‚æœæˆ‘å€‘æŠŠå››å€‹ç›¸å°ä½ç½®åº§æ¨™å„åˆ¥æ”¤å¹³ (æŒ‰ç…§å·¦ä¸Š -\u0026gt; å³ä¸Š -\u0026gt; å·¦ä¸‹ -\u0026gt; å³ä¸‹çš„é †åº)ï¼Œä¸¦ä¸”å¾ä¸Šåˆ°ä¸‹æ’å¥½ï¼Œä»–æœƒçœ‹èµ·ä¾†å¦‚ä¸‹åœ–ã€‚\næ­¤æ™‚æˆ‘å€‘å¹¾ä¹å®Œæˆäº†ç›¸å°ä½ç½®çš„è¡¨ï¼Œå’Œå‰›å‰›åºåˆ—ä¸€æ¨£ç”Ÿå‡ºäº† n*n å€‹ç›¸å°ä½ç½®ã€‚\næˆ‘å€‘æ¥ä¸‹ä¾†è¦åšçš„äº‹æƒ…æ˜¯æŠŠé€™å€‹è¡¨çµ¦ç·¨è™Ÿï¼ŒæŠŠ (0, 0) éƒ½ç·¨æˆæŸå€‹æ•¸å­—ï¼ŒæŠŠ (1, 0) éƒ½ç·¨æˆæŸå€‹æ•¸å­—ã€‚\nåœ¨æ­¤ä¹‹å‰ï¼Œå…ˆè€ƒæ…®ç¸½å…±æœƒæœ‰å¹¾ç¨®å¯èƒ½çš„ç›¸å°åº§æ¨™ï¼Œå°æ–¼é‚Šé•· $M$ çš„ feature map (é€™è£¡ M=2)ï¼Œå› ç‚ºå…©è»¸å¯èƒ½çš„æ•¸å­—çš†æœ‰ (2M-1) ç¨®ï¼Œå…±æœƒæœ‰ (2M-1)*(2M-1) ç¨®å¯èƒ½æ€§ï¼Œé€™è£¡ç­‰æ–¼ 9ã€‚\næ‰€ä»¥æˆ‘å€‘ç­‰ç­‰æœƒæŠŠæ‰€æœ‰åº§æ¨™ç·¨ç‚º 0~8ã€‚\næƒ³å¾åº§æ¨™ç”Ÿå‡ºç·¨è™Ÿ 0~8 å¯ä»¥è€ƒæ…®æŠŠåº§æ¨™å…©è»¸çš„æ•¸å­—ç›¸åŠ ï¼Œä½†ç”±æ–¼æœ‰è² æ•¸çš„å­˜åœ¨ï¼Œè¦å…ˆæŠŠå…©è»¸çš„æ•¸å­—éƒ½è®Šæˆéè² æ•´æ•¸ï¼Œæ‰€ä»¥å…ˆæŠŠå…©è»¸çš„åº§æ¨™éƒ½å„åˆ¥åŠ  M-1ã€‚\næ­¤æ™‚å¦‚æœç›¸åŠ ï¼Œæœƒä½¿ (2, 1) å’Œ (1, 2) éƒ½å°æ‡‰åˆ°æ•¸å­— 3ï¼Œæ‰€ä»¥æˆ‘å€‘å…ˆæŠŠ row åº§æ¨™ä¹˜ä¸Š 2M-1 å†ç›¸åŠ ï¼Œæ­¤æ™‚å°±å¯ä»¥ç²å¾—ä¸€å€‹ n*n çš„ index table ï¼Œå°æ‡‰ä¸€çµ„ç›¸å°ä½ç½®å‘é‡ã€‚\nSwin Transformer æ˜¯ç”¨ç°¡åŒ–ç‰ˆçš„ä½œæ³•ä¾†å¼•å…¥ç›¸å°ä½ç½®ï¼Œå…¬å¼å¦‚ä¸‹\n$Attention(Q,K,V)=SoftMax(QK^T/\\sqrt{d}+B)V$ $B$ æ˜¯ relative position biasï¼Œ$B \\in R^{M^2 * M^2}$ $a_{ij}$ æ˜¯ç´”é‡ï¼Œä¸æ˜¯å‘é‡ï¼Œå’ŒåŸå§‹è«–æ–‡ä¸åŒ è«–æ–‡å‡ºè™• paper: Self-Attention with Relative Position Representations\nAbstract ä¾è³´æ–¼ attention æ©Ÿåˆ¶çš„ Transformer åœ¨æ©Ÿå™¨ç¿»è­¯æ–¹é¢å–å¾— SOTAï¼Œä½†åœ¨çµæ§‹ä¸­æ²’æœ‰ç›¸å°æˆ–çµ•å°çš„ä½ç½®è³‡è¨Šï¼Œä»–éœ€è¦åœ¨è¼¸å…¥ä¸­æ·»åŠ çµ•å°ä½ç½®çš„è³‡è¨Šã€‚\nå› æ­¤æœ¬æ–‡æå‡ºä¸€ç¨®æ›¿ä»£æ–¹æ¡ˆï¼Œæ‹“å±• self-attention ï¼Œè€ƒæ…®ç›¸å°ä½ç½®çš„è¡¨ç¤ºï¼Œä¸¦åœ¨ä¸€äº›ä»»å‹™ä¸­ç²å¾—æ›´å¥½çš„çµæœã€‚\nå€¼å¾—ä¸€é¡Œçš„äº‹ï¼Œä½œè€…è§€å¯Ÿåˆ°çµåˆç›¸å°å’Œçµ•å°ä½ç½®ä¸æœƒé€²ä¸€æ­¥æé«˜ç¿»è­¯å“è³ªã€‚\nè©²æ©Ÿåˆ¶å¯ä»¥æ‹“å±•åˆ°ä»»æ„ graph-labeled çš„è¼¸å…¥\nIntroduction Non-recurrent models ä¸ä¸€å®šæŒ‰é †åºè€ƒæ…®è¼¸å…¥å…ƒç´ ï¼Œå› æ­¤å¯èƒ½éœ€è¦æ˜ç¢ºçš„ position encoding æ‰æ‰èƒ½ç”¨åºåˆ—é †åºã€‚\nä¸€ç¨®å¸¸è¦‹çš„æ–¹æ³•æ˜¯ä½¿ç”¨èˆ‡è¼¸å…¥å…ƒç´ çµåˆçš„ position encodingï¼Œä»¥å‘æ¨¡å‹å‚³é”ä½ç½®è³‡è¨Šã€‚\nå¯ä»¥æ˜¯ deterministic functionï¼Œæˆ–æ˜¯ learned representationsã€‚\nCNN å¯ä»¥æ•æ‰ kernel çš„ç›¸å°ä½ç½®è³‡è¨Šï¼Œä½†è¢«è­‰æ˜ä»å—ç›Šæ–¼ position encodingã€‚\nå°æ–¼æ—¢ä¸ä½¿ç”¨å·ç©ä¹Ÿä¸ä½¿ç”¨éæ­¸çš„ Transformerï¼Œçµåˆä½ç½®ä¿¡æ¯çš„ representation æ˜¯ä¸€å€‹ç‰¹åˆ¥é‡è¦çš„è€ƒæ…®å› ç´ ï¼Œå› ç‚ºè©²æ¨¡å‹åœ¨å…¶ä»–æ–¹é¢å°åºåˆ—æ’åºå®Œå…¨ä¸è®Šã€‚\næœ¬æ–‡æå‡ºä¸€ç¨®å°‡ç›¸å°ä½ç½®åˆä½µåˆ° Transformer çš„ self-attention çš„åšæ³•ï¼Œå³ä½¿å®Œå…¨æ›æ‰çµ•å°ä½ç½®ç·¨ç¢¼ï¼Œä¹Ÿä½¿å…©å€‹æ©Ÿå™¨ç¿»è­¯ä»»å‹™çš„å“è³ªæœ‰é¡¯è‘—æé«˜ã€‚\nBackground åŸå§‹ self-attention\n$z_i=\\displaystyle\\sum_{j=1}^n\\alpha_{ij}(x_jW^V)$\n$\\alpha_{ij}=\\frac{\\text{exp } e_{ij}}{\\sum_{k=1}^n\\text{exp } e_{ik}}$\n$e_{ij}=\\frac{(x_iW^Q)(x_jW^K)^T}{\\sqrt{d_z}}$\nProposed Architecture Relation-aware Self-Attention æœ‰å…©å€‹è¦å¼•å…¥ relative position çš„åœ°æ–¹ï¼Œè€Œä¸”éƒ½æ˜¯å‘é‡\n$z_i = \\displaystyle\\sum_{j=1}^n \\alpha_{ij}(x_jW^V+a_{ij}^V)$\n$e_{ij}=\\frac{x_iW^Q(x_jW^K+a_{ij}^K)^T}{\\sqrt{d_z}}$\nRelative Position Representations å¯ä»¥å¼•å…¥ clipï¼ŒæŠŠç·šæ€§åºåˆ—ä¸­ï¼Œé«˜æ–¼é•·åº¦ k çš„ä¿®å‰ªæˆæœ€å¤§å€¼\n$a_{ij}^K=w_{clip(j-i,k)}^K$ $a_{ij}^V=w_{clip(j-i,k)}^V$ $clip(x,k)=max(-k,min(k,x))$ Experiments Model Variations clipping çš„å¯¦é©— V å’Œ K çš„ ablation study ","date":"2023-04-24T01:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/relative-position-%E4%BB%8B%E7%B4%B9--%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"Relative Position ä»‹ç´¹ + è«–æ–‡é–±è®€"},{"content":"paper: Swin Transformer: Hierarchical Vision Transformer using Shifted Windows\nAbstract æœ¬æ–‡æå‡ºä¸€å€‹æ–°çš„ vision Transformerï¼Œç¨±ä½œ Swin Transformerï¼Œå¯ä»¥è¢«ç”¨ä½œ computer vision ä¸­çš„ general-purpose backboneã€‚\næŠŠ Transformer å¾ language ç§»åˆ° vision å…·å‚™æŒ‘æˆ°æ€§ï¼Œæ¯”å¦‚åŒä¸€å€‹ visual entity åœ¨å¤§å°ä¸Šå…·å‚™å¾ˆå¤§çš„ varianceã€‚é‚„æœ‰ high resolution ä¸‹ pixel å’Œ word çš„æ•¸é‡å·®ç•°å¤ªå¤§ã€‚\nç‚ºäº†è§£æ±ºé€™äº›å·®ç•°ï¼Œä½œè€…æå‡º hierachical Transformerï¼Œç”¨ shifted windows ä¾†ç®—å‡º representationã€‚\nshifted windowing é€éæŠŠ self-attention é™åˆ¶åœ¨ non-overlapping çš„ local window å’Œå…è¨± cross-windows connection ä¾†æé«˜æ•ˆç‡ã€‚\né€™ç¨® hierarchical architecture å¯ä»¥éˆæ´»åœ°åœ¨å„ç¨® scale ä¸‹æ“´å±• modelï¼Œé‚„å¯ä»¥å°åœ–åƒå¤§å°æœ‰ç·šæ€§çš„è¨ˆç®—æ™‚é–“è¤‡é›œåº¦ã€‚\nIntroduction ViT æŠŠåœ–ç‰‡æ‰“æˆ patchï¼Œæ¯å€‹ patch æ˜¯ 16*16ï¼Œfeature maps ç”± single low resolution çš„è¼¸å…¥ç”Ÿæˆï¼Œè€Œä¸”ç”±æ–¼è‡ªæ³¨æ„åŠ›å§‹çµ‚éƒ½æ˜¯åœ¨å…¨å±€ä¸Šè¨ˆç®—çš„ (patch å’Œ patch é–“åšè‡ªæ³¨æ„åŠ›)ï¼Œæ‰€ä»¥æ™‚é–“è¤‡é›œåº¦æ˜¯ quadratic computation complexityã€‚\nSwin Transformer å¾å° patch é–‹å§‹ï¼Œä¸¦åœ¨æ›´æ·±çš„ Transformer layers åˆä½µç›¸é„°çš„ patchesã€‚\næœ‰äº†é€™äº› hierarchical feature mapsï¼Œå¯ä»¥ç”¨åœ¨åƒæ˜¯ FPN æˆ–æ˜¯ U-Netã€‚\nä¸€å€‹ Swin Transformer çš„é—œéµè¨­è¨ˆå› ç´ æ˜¯ shifted windowã€‚\né€é bridge ä¸åŒ layer çš„ windows ä¾†æä¾›ä»–å€‘é€£æ¥ã€‚\nMethod Overall Architecture Patch Merging åŸæœ¬ç‰¹å¾µåœ–æ˜¯ H * W * C ä»¥ä¸Šä¸‹ stride=2 è¡Œèµ°ï¼Œæœƒå¾—åˆ°å››å¼µ H/2 * W/2 * C concatenate èµ·ä¾†ï¼Œè®Šæˆ H/2 * W/2 * 4C åš linearï¼Œè®Šæˆ H/2 * W/2 * 2C Swin Transformer block Swin Transformer æ˜¯é€éæŠŠ Transformer block ä¸­çš„ multi-head self attention(MSA) æ›æˆåŸºæ–¼ shifted windows çš„ module æ§‹æˆã€‚\nShifted Window based Self-Attention æ¨™æº–çš„ Transformer æ¶æ§‹æœƒç®— global self-attentionï¼Œè¨ˆç®—æ‰€æœ‰ token é–“å½¼æ­¤çš„é—œä¿‚ï¼Œå°è‡´ quadratic complexityï¼Œä½¿å…¶ä¸é©ç”¨æ–¼éœ€è¦å¤§é‡ token çš„è¨±å¤š CV å•é¡Œ\nSelf-attention in non-overlapped windows åŸä¾†çš„åœ–ç‰‡æœƒä»¥ non-overlapping çš„æ–¹å¼åˆ‡å‰²ã€‚\nå‡è¨­æ¯å€‹ windows æœ‰ M * M å€‹ patchesï¼Œç„¶å¾Œä¸€å¼µåœ–åƒæœ‰ h * w å¡Š patchesï¼Œè¨ˆç®—è¤‡é›œåº¦å¦‚ä¸‹ï¼š\n$\\Omega(MSA)=4hwC^2+2(hw)^2C$ $\\Omega(W-MSA)=4hwC^2+2M^2hwC$ Shifted window partitioning in successive blocks window-based self-attention module ç¼ºä¹äº† windows é–“å½¼æ­¤çš„é€£æ¥ï¼Œæœƒé™åˆ¶æ¨¡å‹èƒ½åŠ›ã€‚\nä½œè€…æå‡ºäº†ä¸€ç¨® shifted window çš„æ–¹æ³•ï¼Œä¿æŒ non-overlapping windows çš„é«˜æ•ˆè¨ˆç®—ï¼ŒåŒæ™‚å¼•å…¥ windows é–“çš„é€£æ¥ã€‚\nå†å…©å€‹é€£çºŒçš„ windows é–“ï¼Œæœƒç§»å‹• $(âŒŠ \\frac{M}{2} âŒ‹, âŒŠ \\frac{M}{2} âŒ‹)$\nEfficient batch computation for shifted configuration shifted window æœ‰å€‹å•é¡Œæ˜¯ï¼Œæœƒå°è‡´æ›´å¤šçš„ windowsï¼Œå¾ $âŒˆ \\frac{h}{M} âŒ‰ * âŒˆ \\frac{w}{M} âŒ‰$ åˆ° $(âŒˆ \\frac{h}{M} âŒ‰+1) * (âŒˆ \\frac{w}{M} âŒ‰+1)$ï¼Œè€Œä¸”æœ‰äº› window æœƒå°æ–¼ M*Mã€‚\né€™æ¨£æœƒå°è‡´ç„¡æ³•æŠŠé€™äº›çµ¦å£“æˆä¸€å€‹ batch å¿«é€Ÿè¨ˆç®—ã€‚\nä¸€ç¨® naive çš„è§£æ³•å°±æ˜¯ç›´æ¥åœ¨å¤–é¢åŠ  zero paddingï¼Œä½†æœƒå¢åŠ è¨ˆç®—é‡ï¼Œç•¶ windows æ•¸é‡è¼ƒå°‘æ™‚ï¼Œè¨ˆç®—é‡æœƒè®Šå¾ˆå¯è§€ (å¾ 2 * 2 å€‹ windows è®Šæˆ 3 * 3 å€‹ windowsï¼Œå¢åŠ äº† 2.25 å€)\nä½œè€…æå‡ºå¦å¤–ä¸€ç¨®å·§å¦™çš„åšæ³•ï¼ŒæŠŠä¸€äº›éƒ¨åˆ†æŒªç§»ã€‚\nä½†ç¾åœ¨æœ‰äº› window è£¡æœ‰å¤šå€‹ä¸è©²ç›¸äº’åš attention çš„éƒ¨åˆ†ï¼Œæ‰€ä»¥è¦ç”¨ mask çš„æ–¹å¼è¨ˆç®—ã€‚\nä¸åŒ windowsï¼Œåš self-attention å¾Œï¼ŒæŠŠä¸ç›¸å¹²çš„éƒ¨åˆ†åšçš„ attention æ¸›å»ä¸€å€‹å¾ˆå¤§çš„æ•¸å€¼ï¼Œæœ€å¾Œå†é softmaxã€‚\nä¸Šåœ–ä¾†è‡ªä½œè€…åœ¨ github æä¾›çš„å¯è¦–åŒ–\næœ€å¾Œå†æŠŠå®ƒæŒªå›åŸæœ¬çš„ä½ç½®ã€‚\nRelative position bias åƒè€ƒé€™å€‹: https://blog.csdn.net/qq_37541097/article/details/121119988\nArchitecture Variants window size é è¨­æ˜¯ M = 7\nquery dimension of each head æ˜¯ d = 32\nexpansion layer of each MLP is $\\alpha$ = 4\nC æ˜¯ first stage çš„ hidden layers çš„ channel numbers\nSwin-T\nC = 96 layer numbers = {2, 2, 6, 2} å¤§å°å’Œè¨ˆç®—é‡æ˜¯ Base çš„å¤§ç´„ 0.25 å€ complexity æ¥è¿‘ ResNet-50 Swin-S\nC = 96 layer numbers = {2, 2, 18, 2} å¤§å°å’Œè¨ˆç®—é‡æ˜¯ Base çš„å¤§ç´„ 0.5 å€ complexity æ¥è¿‘ ResNet-101 Swin-B\nC = 128 layer numbers = {2, 2, 18, 2} Swin-L\nC = 192 layer numbers = {2, 2, 18, 2} å¤§å°å’Œè¨ˆç®—é‡æ˜¯ Base çš„å¤§ç´„ 2 å€ Experiments Image Classification on ImageNet-1K Object Detection on COCO Semantic Segmentation on ADE20K Ablation Study Conclusion åŸºæ–¼ self-attention çš„ shifted window æ˜¯ Swin Transformer é—œéµéƒ¨åˆ†ï¼Œè¢«é¡¯ç¤ºå‡ºä»–åœ¨ CV é ˜åŸŸæœ‰æ•ˆç‡ä¸”æœ‰æ•ˆï¼Œä¸¦æœŸæœ›æœªä¾†æŠŠå®ƒæ‡‰ç”¨åœ¨ NLPã€‚\n","date":"2023-04-14T01:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/swin-transformer-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"Swin Transformer è«–æ–‡é–±è®€"},{"content":"åˆ†ææ–¹æ³• ç¯€é»åˆ†æ (Nodal Analysis) è§£ç¯€é»é›»å£“ é¸å–ä¸€å€‹ç¯€é»åšç‚ºåƒè€ƒç¯€é» (reference node) æˆ–å·²çŸ¥ç¯€é» (datum node)ï¼Œå…¶ä»–ç¯€é»çš„é›»å£“ç›¸å°æ–¼å®ƒ å‡è¨­å®ƒé›»ä½ç‚º 0ï¼Œç¨±ç‚º ground æŠŠ KCL ç”¨åœ¨å‰©ä¸‹çš„ n-1 å€‹åƒè€ƒç¯€é» (å‡è¨­é›»æµæ–¹å‘ï¼Œå¯ä»¥éš¨ä¾¿å‡è¨­ï¼Œåªè¦ä¸€è‡´ï¼Œä¸è¦å…©ç«¯é›»æµéƒ½æµå…¥åŒå€‹é›»é˜») æ±‚è§£è¯ç«‹æ–¹ç¨‹å¼ï¼Œå¾—åˆ°å„ç¯€é»é›»å£“ åŒ…å«é›»å£“æºçš„ç¯€é»åˆ†æ (Nodal Analysis with Voltage Sources) å¦‚æœé›»å£“æºé€£æ¥æ–¼å…©å€‹éåƒè€ƒç¯€é»é–“ï¼Œå¯ä»¥æŠŠé›»å£“æºå’Œé€™å…©å€‹ç¯€é»å’Œèˆ‡å…¶ä¸¦è¯çš„å…ƒä»¶çœ‹åšä¸€å€‹è¶…ç¯€é» (supernode) æˆ–å»£ç¾©ç¯€é» (generalized node)ï¼Œè§£æ±ºç„¡æ³•çŸ¥é“æµéé›»å£“æºçš„é›»æµçš„å•é¡Œ è¶…ç¯€é»çš„å±¬æ€§ è¶…ç¯€é»å…§éƒ¨çš„é›»å£“æºæä¾›é™åˆ¶æ–¹ç¨‹å¼ è¶…ç¯€é»æœ¬èº«æ²’é›»å£“ è¶…ç¯€é»è¦åŒæ™‚ç”¨ KCL å’Œ KVL ç¶²ç›®åˆ†æ (Mesh Analysis) åªèƒ½é©ç”¨å¹³é¢é›»è·¯ (planer circuit)ï¼Œä¸èƒ½ç”¨åœ¨éå¹³é¢é›»è·¯ (nonplaner circuit)\nåœ¨ä¸€å€‹å¹³é¢ä¸Šæ²’æœ‰äº¤äº’é€£æ¥çš„åˆ†æ”¯ ç¶²ç›® (Mesh)\nä¸åŒ…å«å­è¿´è·¯çš„å–®ä¸€è¿´è·¯ ç¶²ç›®é›»æµ (mesh current)\næµç¶“ç¶²ç›®çš„é›»æµ æ±ºå®šç¶²ç›®é›»æµæ­¥é©Ÿ\nåœ¨ n å€‹ç¶²ç›®ä¸­ï¼ŒæŒ‡å®š n å€‹ç¶²ç›®é›»æµ å° n å€‹ç¶²ç›®å€‹åˆ¥æ‡‰ç”¨ KVLï¼ŒæŠŠæ­å§†å®šå¾‹æ‡‰ç”¨åœ¨ç¶²ç›®é›»æµä¸Šï¼Œä»¥è¡¨ç¤ºé›»å£“ æ±‚è§£ n å€‹è¯ç«‹æ–¹ç¨‹å¼ï¼Œè¨ˆç®—ç¶²ç›®é›»æµ åŒ…å«é›»æµæºçš„ç¶²ç›®åˆ†æ (Mesh Analysis with Current Sources) å¦‚æœæœ‰å…©å€‹ Mesh å…±ç”¨åŒä¸€å€‹é›»æµæºï¼Œæœƒå½¢æˆè¶…ç¶²ç›® (supermesh)ï¼ŒæŠŠå…¬ç”¨çš„é›»æµæºé‚„æœ‰ä¸²è¯çš„å…ƒä»¶çµ¦ç§»é™¤æ‰ è¦–å¯Ÿæ³• å¾…è£œ ç¯€é»åˆ†æ vs ç¶²ç›®åˆ†æ ç¯€é»æ¯”ç¶²ç›®å°‘é¸ç¯€é»åˆ†æï¼Œåä¹‹ä¹Ÿæ˜¯ è¦æ±‚é›»å£“ç¯€é»ï¼Œæ±‚é›»æµç¶²ç›® å¯ä»¥ç”¨ä¸€ç¨®é©—è­‰å¦ä¸€ç¨®çš„çµæœ æœ‰äº›ç‰¹æ®Šå•é¡Œåªèƒ½ç”¨å…¶ä¸­ä¸€ç¨®æ–¹æ³• ç›´æµé›»æ™¶é«”é›»è·¯ é›»å­ç”¢å“ä¸­çš„åŸºæœ¬å…ƒä»¶æœ‰ä¸‰ç«¯ä¸»å‹•å…ƒä»¶\u0026ndash;é›»æ™¶é«” (transistor)\nç¨®é¡ é›™æ¥µæ€§æ¥é¢é›»æ™¶é«” (biopolar junction transistor, BJT) æœ¬ç¯€åªè¨è«–é€™ç¨® å ´æ•ˆé›»æ™¶é«” (field-effect transistor, FET) BJT é¡å‹\nNPN PNP Part\nå°„æ¥µ (emitter, E) åŸºæ¥µ (base, B) é›†æ¥µ (collector, C) å·¥ä½œæ¨¡å¼\nä½œç”¨ $I_C=\\alpha I_E$ $\\alpha$ æ˜¯å…±åŸºæ¥µé›»æµå¢ç›Š (common-base current gain)ï¼Œè¡¨ç¤ºå°„æ¥µæ³¨å…¥çš„é›»å­è¢«åŸºæ¥µæ”¶é›†çš„æ¯”ä¾‹ $I_C=\\beta I_B$ $\\beta$ æ˜¯å…±å°„æ¥µé›»æµå¢ç›Š (common-emitter current gain) $I_E=(1+\\beta) I_B$ $\\beta=\\frac{\\alpha}{1-\\alpha}$ å› ç‚º $\\beta$ å¾ˆå¤§ï¼Œä¸€å€‹å°çš„åŸºæ¥µé›»æµå¯ä»¥æ§åˆ¶å¤§é›»æµçš„è¼¸å‡ºï¼Œå› æ­¤ï¼Œé›™æ¥µæ€§é›»æ™¶é«”å¯ä»¥ç•¶ä½œæ”¾å¤§å™¨ æˆªæ­¢ é£½å’Œ é›»è·¯ç†è«– ç·šæ€§æ€§è³ª (Linear Property) ç·šæ€§\né½Šæ¬¡æ€§ è¼¸å…¥ ( æ¿€ç™¼ excitation) ä¹˜ä»¥ä¸€å€‹å¸¸æ•¸ï¼Œè¼¸å‡º ( éŸ¿æ‡‰ response) ä¹Ÿæœƒä¹˜ä»¥ç›¸åŒçš„å¸¸æ•¸ $kiR=kv$ å¯åŠ æ€§ è¼¸å…¥ç¸½å’Œçš„ response ç­‰æ–¼å€‹åˆ¥è¼¸å…¥çš„ response çš„ç¸½å’Œ $v=(i_1+i_2)R=i_1R+i_2R=v_1+v_2$ å› æ­¤ç¨±é›»é˜»æ˜¯ä¸€å€‹ç·šæ€§å…ƒä»¶ï¼Œå› ç‚ºé›»é˜»ã€é›»å£“ã€é›»æµçš„é—œä¿‚æ»¿è¶³é½Šæ¬¡æ€§å’Œå¯åŠ æ€§\nå¦‚æœé›»è·¯æ»¿è¶³å¯åŠ æ€§å’Œé½Šæ¬¡æ€§ï¼Œç¨±æ­¤é›»è·¯ç‚ºç·šæ€§é›»è·¯\nç·šæ€§é›»è·¯æ˜¯è¼¸å‡ºèˆ‡è¼¸å…¥ç‚ºç·šæ€§é—œä¿‚çš„é›»è·¯ çµ„æˆ ç·šæ€§å…ƒä»¶ ç·šæ€§ç›¸ä¾é›»æº ç¨ç«‹é›»æº é‡ç–Š (Superposition) æœ‰å…©å€‹æˆ–æ›´å¤šçš„ç¨ç«‹é›»æºæ™‚ï¼Œé™¤äº†ç¯€é»å’Œç¶²ç›®åˆ†æï¼Œå¯ä»¥æ±‚å„ç¨ç«‹æºå°è®Šæ•¸çš„è²¢ç»ï¼Œæœ€å¾Œç›¸åŠ èµ·ä¾†ï¼Œé€™å°±æ˜¯é‡ç–Š é‡ç–Šå®šç† åœ¨ä¸€å€‹ç·šæ€§é›»è·¯ä¸­ï¼Œè·¨æ¥æ–¼å…ƒä»¶ä¸Šçš„é›»å£“(æµç¶“å…ƒä»¶çš„é›»æµ) = æ¯å€‹ç¨ç«‹é›»æºå–®ç¨ä½œç”¨æ–¼è©²å…ƒä»¶äºŒç«¯çš„é›»å£“(å–®ç¨æµç¶“è©²å…ƒä»¶çš„é›»æµ)çš„ä»£æ•¸å’Œ\næ³¨æ„äº‹é …\nåŒä¸€æ™‚é–“åªè€ƒæ…®ä¸€å€‹ç¨ç«‹é›»æºï¼ŒæŠŠå…¶ä»–çš„é›»å£“æºç•¶ä½œ 0 V(çŸ­è·¯)ã€é›»æµæºç•¶ä½œ 0 A(é–‹è·¯) ç›¸ä¾é›»æºå—é›»è·¯è®Šæ•¸æ§åˆ¶ï¼Œä¿æŒä¸è®Š æ­¥é©Ÿ\nä¿ç•™ä¸€å€‹ç¨ç«‹é›»æºï¼Œç®—å®ƒçš„è¼¸å‡º(é›»å£“æˆ–é›»æµ) å°æ¯å€‹é›»æºåšæ­¥é©Ÿ 1 æŠŠæ¯å€‹ç¨ç«‹é›»æºçš„è²¢ç»ç›¸åŠ  é›»æºè®Šæ› (Source Transformation) æŠŠé›»é˜»ä¸¦è¯çš„é›»æµæºå’Œé›»é˜»ä¸²è¯çš„é›»å£“æºåšè½‰æ›(æˆ–åéä¾†) é›»æºè®Šæ›æ¢ä»¶ $V_s=i_sR$ ä¹Ÿæ˜¯ç”¨ç›¸ä¾é›»æºï¼Œä½†ä¹Ÿè¦éµå®ˆæ¢ä»¶ æˆ´ç¶­å¯§å®šç† (Thevenin\u0026rsquo;s Theorem) å¸¸æœ‰ä¸€ç¨®æƒ…å¢ƒï¼Œé›»è·¯ç¨®æœ‰ä¸€å€‹ç‰¹æ®Šçš„å…ƒä»¶æ˜¯å¯è®Šçš„ï¼Œåˆç¨±è² è¼‰ (load)ï¼Œæ¯”å¦‚æ’åº§å¯èƒ½é€£æ¥ä¸åŒå®¶é›»æ‰€çµ„æˆçš„è² è¼‰ï¼Œè€Œæ¯ç•¶ load æ”¹è®Šï¼Œå°±è¦é‡æ–°åˆ†æé›»è·¯ã€‚æˆ´ç¶­å¯§å®šç†å¯ä»¥æŠŠå›ºå®šçš„éƒ¨åˆ†æ›æˆä¸€å€‹ç­‰æ•ˆé›»è·¯ æˆ´ç¶­å¯§å®šç† ç·šæ€§äºŒç«¯é›»è·¯å¯è¢«ç”±é›»å£“æº $V_{Th}$ å’Œé›»é˜» $R_{Th}$ ä¸²è¯æ‰€çµ„æˆçš„æˆ´ç¶­å¯§ç­‰æ•ˆé›»è·¯ (Thevenin equivalent circuit) å–ä»£ $V_{Th}$ æ˜¯äºŒç«¯çš„é–‹è·¯é›»å£“ $R_{Th}$ æ˜¯é—œé–‰ç¨ç«‹é›»æºå¾Œï¼Œç«¯é»ä¸Šçš„è¼¸å…¥æˆ–ç­‰æ•ˆé›»é˜» é—œé–‰æ‰€æœ‰ç¨ç«‹é›»æº(æ ¹æ“š é›»å£“/é›»æµ ä¾† çŸ­è·¯/é–‹è·¯)ï¼Œä½†è€ƒæ…®ç›¸ä¾é›»æº $R_{Th}$ æœ‰å¯èƒ½æ±‚å‡ºè² å€¼ï¼Œé€™ä»£è¡¨è©²é›»è·¯æä¾›åŠŸç‡ï¼Œè£¡é¢æœ‰ç›¸ä¾é›»æºï¼Œé›–ç„¶ä¸å¯èƒ½å‡ºç¾åœ¨è¢«å‹•å…ƒä»¶ä¸Šï¼Œä½†ç­‰æ•ˆé›»è·¯æ˜¯ä¸»å‹•å…ƒä»¶ å‡è¨­å¤–æ¥ä¸€å€‹é›»å£“æºï¼Œæ±‚å¤–é¢çš„ v å’Œ i å³å¯ç®—å‡º $R_{Th}$ è«¾é “å®šç† (Norton\u0026rsquo;s Theorem) å’Œæˆ´ç¶­å¯§å®šç†å¾ˆåƒï¼Œä½†æ˜¯ç­‰æ•ˆé›»è·¯æ”¹æˆé›»æµæºå’Œä¸¦è¯çš„é›»é˜»ï¼Œå¯¦éš›ä¸Šï¼Œæ ¹æ“šé›»æºè®Šæ›ï¼Œå¯ä»¥çŸ¥é“è«¾é “å®šç†å’Œæˆ´ç¶­å¯§å®šç†çš„ç­‰æ•ˆé›»é˜»ç›¸ç­‰\n$R_N=R_{Th}$\n$I_N=\\frac{V_{Th}}{R_{Th}}$\nè¨ˆç®—æˆ´ç¶­å¯§æˆ–è«¾é “ç­‰æ•ˆé›»è·¯ï¼Œè¦å…ˆæ±‚ $v_{oc}$ã€$i_{sc}$ã€$R_{in}$\næ±‚å‡ºå…©å€‹å°±å¯ä»¥ç®—ç¬¬ä¸‰å€‹ $V_{Th}=v_{oc}$ $v_{oc}$ æ˜¯ a å’Œ b å…©ç«¯çš„é–‹è·¯é›»å£“ $I_N=i_{sc}$ $i_{sc}$ æ˜¯ a å’Œ b å…©ç«¯çš„çŸ­è·¯é›»æµ $R_{Th}=\\frac{v_{oc}}{i_{sc}}=R_N$ æœ€å¤§åŠŸç‡è½‰ç§» (Maximum Power Transfer) è½‰ç§»åˆ° load çš„åŠŸç‡æ˜¯ $p=i^2R_{L}=(\\frac{V_{Th}}{R_{Th}+R_L})^2R_L$ æœ€å¤§å€¼å‡ºç¾åœ¨ $R_L=R_{Th}$ æœ€å¤§åŠŸç‡å®šç† (maximum power theorem) $p_{max}=\\frac{V_{Th}^2}{4R_{Th}}$ é›»æºå»ºæ¨¡ (Source Modeling) å¯¦éš›çš„é›»æºéç†æƒ³é›»æº é›»å£“æºæœ‰ä¸²è¯çš„å…§éƒ¨é›»é˜» (internal resistance) ä¸‹é¢ç¨±ç‚º $R_s$ è¦ç†æƒ³è¦è¶¨è¿‘æ–¼ 0 è‹¥ä¸é€£æ¥ load (é–‹è·¯)ï¼Œ$v_{oc}=v_s$ $v_s$ å¯ä»¥çœ‹åšç„¡è² è¼‰æºé›»å£“ (unloaded source voltage)ï¼Œé€£æ¥ load æœƒä½¿ç«¯é›»å£“ä¸‹é™ï¼Œé€™å°±æ˜¯è² è¼‰æ•ˆæ‡‰ (loading effect) $R_L$ è¶Šå¤§æœƒè¶Šæ¥è¿‘ç†æƒ³é›»å£“ é‡æ¸¬ $v_s$ å’Œå…§éƒ¨é›»é˜» é‡é–‹è·¯é›»å£“ $v_s=v_{oc}$ load ç«¯é€£æ¥å¯è®Šé›»é˜»ï¼Œèª¿åˆ° $v_L=v_{oc}/2$ æ­¤æ™‚ $R_L=R_{Th}=R_s$ é›»æµæºæœ‰ä¸¦è¯çš„é›»æºé›»é˜» (source resistance) è¦ç†æƒ³è¦è¶¨è¿‘æ–¼ç„¡çª®å¤§ $R_L$ è¶Šå°è¶Šæ¥è¿‘ç†æƒ³é›»æº é›»é˜»é‡æ¸¬ (Resistance Measurement) æƒ æ–¯ç™»é›»æ©‹ (Wheatstone bridge) å¹³è¡¡é›»æ©‹ (balanced bridge) éå¹³è¡¡é›»æ©‹ (unbalanced bridge) ","date":"2023-04-10T00:00:54+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E9%9B%BB%E8%B7%AF%E5%AD%B8-ii/","title":"é›»è·¯å­¸ - II"},{"content":"ä»‹ç´¹ è©¦ç”¨ STM32 UART åŠŸèƒ½\næœƒé€é RealTerm å’Œ STM32L476RG æºé€šï¼Œä¸¦ç”¨ DMA æ¥æ”¶è¨Šæ¯\næ ¹æ“š User manualï¼ŒUSART2 é è¨­æœƒé€£æ¥ ST-LINKï¼Œè¦é€£æ¥å¤–éƒ¨è¨­å‚™çš„è©±è¦ä¿®æ”¹ solder bridge\nioc è¨­ç½® Connectivity å¯ä»¥è¨­ç½® USART2 mode å¾ disable æ”¹é¸ Asynchronous Parameters Settings å¯ä»¥è¨­ç½®å„ç¨®è³‡è¨Š Baud Rate Word Length Parity Stop Bits DMA Setting Add ä¸€å€‹ RX Mode æ”¹æˆ circularï¼Œä¸¦æ‰“é–‹ memory çš„ increment address increment address æ˜¯å› ç‚ºè³‡æ–™æ˜¯ç”¨ array å­˜ circular æ˜¯ç•¶è³‡æ–™æ»¿äº†å¾Œï¼Œæœƒå›åˆ° zero position NVIC Setting è¨­ç½® DMA æ‡‰è©²å°±æœƒè‡ªå‹•è¨­ç½®ä¸€å€‹ interruptï¼Œæª¢æŸ¥ä¸€ä¸‹ ç¨‹å¼ç¢¼ ç™¼é€\n1 2 uint8_t myTxData[13] = \u0026#34;Hello World\\r\\n\u0026#34;; HAL_UART_Transmit(\u0026amp;huart2, myTxData, 13, 10); æ¥æ”¶\n1 2 3 4 UART_HandleTypeDef huart2; // generated code uint8_t myRxData[20]; HAL_UART_Receive_DMA(\u0026amp;huart2, myRxData, 20); // åœ¨ Init å¾Œï¼Œåœ¨ main ä¸­åŸ·è¡Œä¸€æ¬¡å°±å¥½ interrupt\nåœ¨ hal_uart.c æœ‰\n1 2 3 4 5 6 7 8 9 __weak void HAL_UART_RxCpltCallback(UART_HandleTypeDef *huart) { /* Prevent unused argument(s) compilation warning */ UNUSED(huart); /* NOTE : This function should not be modified, when the callback is needed, the HAL_UART_RxCpltCallback can be implemented in the user file. */ } ç•¶ DMA æ»¿äº†å°±æœƒå‘¼å«é€™å€‹ function\nå¯¦é©— 1 2 3 4 5 6 7 8 9 10 void HAL_UART_RxCpltCallback(UART_HandleTypeDef *huart) { /* Prevent unused argument(s) compilation warning */ UNUSED(huart); /* NOTE : This function should not be modified, when the callback is needed, the HAL_UART_RxCpltCallback can be implemented in the user file. */ HAL_UART_Transmit(\u0026amp;huart2, myRxData, 20, 10); } ç•¶ 20 å€‹ Bytes å„²å­˜æ»¿äº†å°±å›å‚³è³‡è¨Šçµ¦é›»è…¦\nRealTerm Display å‹¾é¸ Half Duplex ç™¼é€çš„è¨Šæ¯æœƒé¡¯ç¤ºç¶ è‰²ï¼Œæ¥æ”¶çš„æ˜¯é»ƒè‰² Port è¨­ç½® Baud å’Œå…¶ä»–æœ‰çš„æ²’çš„ é¸ open Send EOL å¯ä»¥å‹¾é¸ CRLF æ‰“ä¸€äº›æ–‡å­—å¾ŒæŒ‰ Send ASCII çµæœ ç¨‹å¼ç¢¼\n","date":"2023-04-09T01:32:54+08:00","permalink":"https://roykesydon.github.io/Blog/p/stm32-uart-%E5%AF%A6%E9%A9%97/","title":"STM32 UART å¯¦é©—"},{"content":"åŸºæœ¬æ¦‚å¿µ å¸¸è¦‹åè© é›»è·¯ (electric circuit) å…ƒä»¶ (element) é›»è·¯çµ„æˆçš„éƒ¨åˆ† å–®ä½ç³»çµ± åœ‹éš›å–®ä½åˆ¶ (International System of Units ,SI) é›»è·èˆ‡é›»æµ é›»è· (electric charge)\nçµ„æˆåŸå­çš„åŸºæœ¬ç‰©è³ª åº«å€« (C) é›»è·å®ˆæ†å®šå¾‹ (law of conservation of charge) é›»è·ä¸èƒ½è¢«å‰µé€ ã€ç ´å£ï¼Œåªèƒ½è½‰ç§»ï¼Œç³»çµ±ä¸­çš„é›»è·ç¸½æ•¸ä¸è®Šã€‚ é›»æµ (electric current)\né›»è·çš„æ™‚é–“è®ŠåŒ–ç‡ é›»æµæ˜¯é›»è·çš„ç§»å‹•ï¼Œè€Œä¸”æœ‰æ–¹å‘æ€§ å®‰åŸ¹ (A) å…¬å¼ $i \\triangleq \\frac{dq}{dt}$ $Q \\triangleq \\int_{t_0}^{t}i\\text{ }dt$ ç›´æµé›» (direct current, dc) æ†å®šå¸¸æ•¸çš„é›»æµ äº¤æµé›» (alternating current, ac) éš¨è‘—æ™‚é–“ä»¥æ­£å¼¦æ³¢è®ŠåŒ–çš„é›»æµ é›»å£“ é›»å‹•å‹¢ (electromotive force, emf) é©…å‹•å°é«”å…§çš„é›»å­å¾€æŸæ–¹å‘ç§»å‹• é›»å£“ (voltage)ã€é›»ä½å·® (potential difference) ä¼ç‰¹ (V) $v_{ab}\\triangleq\\frac{dw}{dq}$ å–®ä½é›»è·å¾ b ç§»å‹•åˆ° a éœ€è¦åšçš„åŠŸ $w$ æ˜¯èƒ½é‡ï¼Œå–®ä½æ˜¯ç„¦è€³(J) $q$ æ˜¯é›»è·ï¼Œå–®ä½æ˜¯åº«å€«(C) å£“é™ (voltage drop)ã€å£“å‡ (voltage rise) ç›´æµé›»å£“ (dc voltage)ã€äº¤æµé›»å£“ (ac voltage) åŠŸç‡èˆ‡èƒ½é‡ æ¶ˆè€—æˆ–å¸æ”¶èƒ½é‡çš„æ™‚é–“è®ŠåŒ–ç‡ï¼Œå–®ä½æ˜¯ç“¦ç‰¹(walt, W)\nå…¬å¼\n$p \\triangleq\\frac{dw}{dt}$ $p=iv$ è¢«å‹•ç¬¦è™Ÿè¦å‰‡ (passive sign convention)\né›»æµå¾é›»å£“çš„æ­£æ¥µæµå…¥å…ƒä»¶ ($p=+vi$)ï¼Œè¡¨ç¤ºè©²å…ƒä»¶å¸æ”¶åŠŸç‡ é›»æµå¾é›»å£“çš„æ­£æ¥µæµå‡ºå…ƒä»¶ ($p=-vi$)ï¼Œè¡¨ç¤ºè©²å…ƒä»¶ä¾›æ‡‰åŠŸç‡ èƒ½é‡å®ˆæ†å®šå¾‹ (law of conservation of energy)\né›»è·¯ä¸­ä»»ä½•æ™‚åˆ»çš„åŠŸç‡ç¸½å’Œç‚º 0 $\\sum p=0$ é›»è·¯å…ƒä»¶ è¢«å‹•å…ƒä»¶ (passive element) ä¸å…·å‚™ç”¢ç”Ÿèƒ½é‡çš„èƒ½åŠ› é›»é˜»å™¨ (resistor)ã€é›»å®¹å™¨ (capacitor)ã€é›»æ„Ÿå™¨ (inductor) ä¸»å‹•å…ƒä»¶ (active element) å…·å‚™ç”¢ç”Ÿèƒ½é‡çš„èƒ½åŠ› ç™¼é›»æ©Ÿ (generator)ã€é›»æ±  (battery)ã€é‹ç®—æ”¾å¤§å™¨ (operational amplifier) é›»æº é›»å£“æºã€é›»æµæº æä¾›ç©©å®šé›»å£“ç”¢ç”Ÿé›»æµã€æä¾›ç©©å®šé›»æµç”¢ç”Ÿé›»å£“ ç¨ç«‹é›»æº ç¨ç«‹é›»æºæä¾›æŒ‡å®šé›»å£“æˆ–é›»æµçš„ä¸»å‹•å…ƒä»¶ï¼Œèˆ‡é›»è·¯ä¸­å…¶ä»–å…ƒä»¶ç„¡é—œã€‚ é›»æ± å’Œç™¼é›»æ©Ÿå¯è¢«ç•¶ä½œè¿‘ä¼¼ç†æƒ³çš„é›»å£“æº ç›¸ä¾é›»æº æä¾›çš„é›»å£“æˆ–é›»æµå—å¦ä¸€å€‹é›»æµæˆ–é›»å£“æ§åˆ¶çš„ä¸»å‹•å…ƒä»¶ é¡å‹ é›»å£“æ§åˆ¶é›»å£“æº (voltage-controlled voltage source, VCVS) é›»æµæ§åˆ¶é›»å£“æº (current-controlled voltage source, CCVS) é›»å£“æ§åˆ¶é›»æµæº (voltage-controlled current source, VCCS) é›»æµæ§åˆ¶é›»æµæº (current-controlled current source, CCCS) åŸºæœ¬å®šå¾‹ æ­å§†å®šå¾‹ (Ohm\u0026rsquo;s Law) ä¸€èˆ¬ææ–™å…·å‚™é˜»æ­¢é›»è·æµé€šçš„ç‰¹æ€§ï¼Œç¨±ç‚ºé›»é˜» (resistance)\nå‡å‹»æˆªé¢ç©ä¸‹ï¼Œ$R=\\rho \\frac{l}{A}$\n$\\rho$ æ˜¯ææ–™çš„é›»é˜»ç‡ (resistivity) é›»è·¯ä¸­æŠ‘åˆ¶é›»æµçš„ææ–™ç¨±ç‚ºé›»é˜»å™¨ (resistor)\n$v=iR$\nçŸ­è·¯ (short circuit)ã€é–‹è·¯ (open circuit)\nçŸ­è·¯: é›»å£“æ˜¯ 0ï¼Œé›»æµå¯èƒ½æ˜¯ä»»æ„å€¼ï¼Œé›»é˜»å€¼æ¥è¿‘ 0 é–‹è·¯: é›»å£“å¯èƒ½æ˜¯ä»»æ„å€¼ï¼Œé›»æµæ˜¯ 0ï¼Œé›»é˜»å€¼æ¥è¿‘ç„¡é™å¤§ å›ºå®šé›»é˜»ã€å¯è®Šé›»é˜»\né˜»å€¼å¯èª¿èˆ‡å¦ å¸¸ç”¨çš„å¯è®Šé›»é˜»æ˜¯é›»ä½å™¨ (potentiometer) ä¸æ˜¯æ‰€æœ‰é›»é˜»éƒ½éµå®ˆæ­å§†å®šå¾‹\néµå®ˆæ­å§†å®šå¾‹çš„ç¨±ç‚ºç·šæ€§é›»é˜» (linear resistor)ï¼Œåä¹‹å‰‡ç‚ºéç·šæ€§é›»é˜» (nonlinear resistor)ï¼Œé˜»å€¼éš¨é›»æµè®ŠåŒ– é›»å° (conductance)\né›»é˜» R çš„å€’æ•¸ å…ƒä»¶å°é€šé›»æµçš„èƒ½åŠ› $G=\\frac{1}{R}=\\frac{i}{v}$ å–®ä½å§†æ­ (mho, $\\mho$) æˆ–è¥¿é–€å­ (siemens, S) $1 S = 1 \\mho = 1 A/V$ Node, Branches, and Loops åˆ†æ (Branch)\nä»»æ„çš„å…©ç«¯å…ƒä»¶ï¼Œæ¯”å¦‚é›»å£“æºã€é›»é˜» ç¯€é» (Node)\næŒ‡é€£æ¥äºŒå€‹æˆ–å¤šå€‹åˆ†æ”¯çš„æ¥é» è¿´è·¯ (Loop)\næ˜¯é›»è·¯ä¸­çš„ä»»ä¸€å°é–‰è·¯å¾‘ å¾ä¸€å€‹ç¯€é»é–‹å§‹ï¼Œç¶“éä¸€çµ„ç¯€é»ï¼Œæœ€å¾Œå›åˆ°ä¸€é–‹å§‹çš„ç¯€é»ï¼Œé€”ä¸­æ¯å€‹ç¯€é»åªç¶“éä¸€æ¬¡ ä¸²è¯\nå¤šå€‹å…ƒä»¶å…±äº«å–®ä¸€ç¯€é» ä¸¦é€£\nå¤šå€‹å…ƒä»¶é€£æ¥åˆ°ç›¸åŒçš„å…©å€‹ç¯€é» ç¨ç«‹è¿´è·¯ (independent loop)\nè‡³å°‘åŒ…å«ä¸€å€‹ä¸å±¬æ–¼å…¶ä»–ç¨ç«‹è¿´è·¯çš„ branch $b=l+n-1$ b æ˜¯ branchï¼Œl æ˜¯ç¨ç«‹è¿´è·¯ï¼Œn æ˜¯ node å…‹å¸Œè·å¤«å®šå¾‹ (Kirchhoff\u0026rsquo;s Laws) Kirchhoff\u0026rsquo;s current law (KCL)\næµå…¥ä»»ä¸€ node æˆ–å°é–‰é‚Šç•Œçš„é›»æµç¸½å’Œç‚º 0 æˆ–æ˜¯èªªæµå…¥æŸä¸€ç¯€é»çš„é›»æµå’Œç­‰æ–¼æµå‡ºçš„é›»æµå’Œ $\\sum_{n=1}^{N}i_n=0$ $N$ æ˜¯é€£åˆ° node çš„ branch æ•¸ Kirchhoff\u0026rsquo;s voltage law (KVL)\nä¸€æ¢å°é–‰è·¯å¾‘(æˆ–è¿´è·¯)ä¸­çš„é›»å£“ç¸½å’Œç‚ºé›¶ æˆ–æ˜¯èªª voltage drop çš„ç¸½å’Œ = voltage rise çš„ç¸½å’Œ $\\sum_{m=1}^{M}n_m=0$ $M$ æ˜¯è¿´è·¯ä¸­çš„ branch æ•¸ ä¸²ä¸¦è¯é›»é˜» ä¸²è¯\n$R_{eq}=\\sum_{n=1}^N R_n$ $R_{eq}$ æ˜¯ç­‰æ•ˆé›»é˜» (equivalent resistance) åˆ†å£“å®šç† (principle of voltage division) é›»å£“å’Œå„é›»é˜»çš„é˜»å€¼æˆæ­£æ¯”ï¼Œé˜»å€¼è¶Šå¤§ï¼Œå£“é™è¶Šå¤§ åˆ†å£“å™¨ (voltage divider) $v_1=\\frac{R_1}{R_1+R_2}v$ ä¸¦è¯\n$\\frac{1}{R_{eq}}=\\frac{1}{R_1}+\\frac{1}{R_2}+\u0026hellip;+\\frac{1}{R_N}$ $R_{eq}$ æ°¸é å°æ–¼ä¸¦è¯é›»é˜»ä¸­æœ€å°çš„é›»é˜»å€¼ $G_{eq} = G_{1}+G_2+\u0026hellip;+G_N$ åˆ†æµå®šç† (principle of current division) å„åˆ†æ”¯é›»æµèˆ‡é›»é˜»å€¼æˆåæ¯” åˆ†æµå™¨ (current divider) $i_1=\\frac{R_2}{R_1+R_2}i$ Y - $\\Delta$ è½‰æ› (Wye-Delta Transformations) é‡åˆ°é›»é˜»ä¸æ˜¯ä¸²è¯ä¹Ÿä¸æ˜¯ä¸¦è¯çš„æƒ…æ³ï¼Œè¦å¦‚ä½•è½‰æ› æœ‰æ™‚å€™æŠŠ Y å‹ç¶²è·¯å’Œ $\\Delta$ å‹ç¶²è·¯ç›¸äº’è½‰æ›æœƒæ¯”è¼ƒå¥½ç®— Y å‹ç¶²è·¯ = T å‹ç¶²è·¯ $\\Delta$ ç¶²è·¯ = $\\Pi$ ç¶²è·¯ $\\Delta$ - Y è½‰æ› (Delta to Wye conversion) Y ç¶²è·¯çš„æ¯å€‹é›»é˜»æ˜¯ $\\Delta$ ä¸­çš„å…©å€‹ç›¸é„°é›»é˜»çš„ç›¸ä¹˜é™¤ä»¥ $\\Delta$ ä¸­çš„ä¸‰å€‹é›»é˜»ç¸½å’Œ Y - $\\Delta$ è½‰æ› (Wye to Delta conversion) $\\Delta$ ç¶²è·¯çš„æ¯å€‹é›»é˜»æ˜¯ Y ä¸­çš„å…©å…©é›»é˜»çš„ç›¸ä¹˜ç¸½å’Œé™¤ä»¥ Y ä¸­çš„å°è§’é›»é˜»\nå¹³è¡¡\næ¢ä»¶ $R_1=R_2=R_3=R_Y$ $R_a=R_b=R_c=R_{\\Delta}$ çµæœ $R_Y=\\frac{R_\\Delta}{3}$ ","date":"2023-04-09T00:00:54+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E9%9B%BB%E8%B7%AF%E5%AD%B8-i/","title":"é›»è·¯å­¸ - I"},{"content":"ç›®çš„ æœ¬æ–‡æœƒè©¦ç”¨ GPIO output / input / interrupt\nGPIO æ¶æ§‹ Output ä»‹ç´¹ åœ¨ ioc é‚£é‚Šé¸å€‹ pinï¼Œé¸ GPIO_Output\nåœ¨å·¦é‚Šæ¬„ä½ System Core é¸æ“‡ GPIO\næœ‰äº”å€‹æ¬„ä½å¯ä»¥è¨­å®š\nGPIO output level\nåˆå§‹é›»ä½ GPIO mode\npush pull å’Œ open drain ä½æ–¼æ¶æ§‹åœ–ä¸‹æ–¹é‚£éƒ¨åˆ†ï¼Œpush pull å¯ä»¥ç”¨ PMOS å’Œ NMOS ä¾†å¾—åˆ°é«˜ä½é›»ä½ï¼Œopen drain æœƒ disable PMOSï¼Œè®“ä½ å¯ä»¥åœ¨å¤–é¢è‡ªå·±æ¥ä¸Šæ‹‰é›»é˜» GPIO Pull-up/Pull-down\nMaximum output speed\nUser Label\nç”¨å®Œè¨˜å¾— ctrl+s è®“ä»– generate code\n1 2 3 4 5 6 7 8 9 /*Configure GPIO pin : PtPin */ GPIO_InitStruct.Pin = RED_LED_Pin; GPIO_InitStruct.Mode = GPIO_MODE_OUTPUT_PP; GPIO_InitStruct.Pull = GPIO_NOPULL; GPIO_InitStruct.Speed = GPIO_SPEED_FREQ_LOW; HAL_GPIO_Init(RED_LED_GPIO_Port, \u0026amp;GPIO_InitStruct); /*Configure GPIO pin Output Level */ HAL_GPIO_WritePin(RED_LED_GPIO_Port, RED_LED_Pin, GPIO_PIN_RESET); 1 2 3 4 HAL_GPIO_WritePin(RED_LED_GPIO_Port, RED_LED_Pin, GPIO_PIN_RESET); // ä½é›»ä½ HAL_GPIO_WritePin(RED_LED_GPIO_Port, RED_LED_Pin, GPIO_PIN_SET); // é«˜é›»ä½ HAL_Delay(1000); //ç­‰ä¸€ç§’ HAL_GPIO_TogglePin(RED_LED_GPIO_Port, RED_LED_Pin) æ ¹æ“šæ¶æ§‹åœ–å·¦å´ï¼Œä½ å¯ä»¥é€éä¿®æ”¹ BSRR ä¾†ä¿®æ”¹ ODRï¼Œé”åˆ°ä¿®æ”¹è¼¸å‡ºçš„æ•ˆæœï¼Œè«‹è¦‹ Reference Manualsï¼Œå¯¦éš›ä¸Š HAL_GPIO_WritePin ä¹Ÿæ˜¯é€™æ¨£å¯¦ç¾çš„\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 void HAL_GPIO_WritePin(GPIO_TypeDef* GPIOx, uint16_t GPIO_Pin, GPIO_PinState PinState) { /* Check the parameters */ assert_param(IS_GPIO_PIN(GPIO_Pin)); assert_param(IS_GPIO_PIN_ACTION(PinState)); if(PinState != GPIO_PIN_RESET) { GPIOx-\u0026gt;BSRR = (uint32_t)GPIO_Pin; } else { GPIOx-\u0026gt;BRR = (uint32_t)GPIO_Pin; } } Input ä»‹ç´¹ çœ‹æ¶æ§‹åœ–ä¸Šæ–¹ï¼Œç”¨ Schmitt trigger å–å¾—é«˜ä½é›»ä½è³‡æ–™ï¼Œä»–æœ‰ upper threshold å’Œ lower thresholdï¼Œè€Œä¸æ˜¯ç”¨ single threshold\n1 2 3 4 5 /*Configure GPIO pin : PtPin */ GPIO_InitStruct.Pin = GREEN_LED_INPUT_Pin; GPIO_InitStruct.Mode = GPIO_MODE_INPUT; GPIO_InitStruct.Pull = GPIO_NOPULL; HAL_GPIO_Init(GREEN_LED_INPUT_GPIO_Port, \u0026amp;GPIO_InitStruct); 1 uint8_t green_led_input = HAL_GPIO_ReadPin(GREEN_LED_INPUT_GPIO_Port, GREEN_LED_INPUT_Pin); Interrupt ioc é¸å€‹ pinï¼Œè¨­å®š GPIO_EXTIï¼Œé€™é‚Šæˆ‘é¸ B1(PC13)ï¼Œä¹Ÿå°±æ˜¯é–‹ç™¼ç‰ˆä¸Šçš„è—è‰²æŒ‰éˆ•\nå¯ä»¥é¸ GPIO modeï¼Œé€™é‚Šé¸ Falling Edge Triggerï¼Œå€¼å¾—ä¸€æçš„æ˜¯ä»–çš„è¨­è¨ˆæ˜¯ä¸Šæ‹‰é›»é˜»ï¼Œæ‰€ä»¥é€™æ¨£ä¸æ˜¯æ”¾é–‹å¾Œè§¸ç™¼ï¼Œæ˜¯æŒ‰ä¸‹å¾Œè§¸ç™¼ã€‚\nioc çš„ System Core çš„ NVIC é‚„è¦æŠŠ EXTI line[15:10] interrupts çµ¦ enabledï¼Œç„¶å¾Œ Code generation æ‰“é–‹ Generate IRQ handlerï¼Œé‚„æœ‰ Call HAL handlerã€‚\nåœ¨ stm32l4xx_it.c è£¡ï¼Œ ç¾åœ¨æœƒæœ‰\n1 2 3 4 5 6 7 8 9 10 void EXTI15_10_IRQHandler(void) { /* USER CODE BEGIN EXTI15_10_IRQn 0 */ /* USER CODE END EXTI15_10_IRQn 0 */ HAL_GPIO_EXTI_IRQHandler(B1_Pin); /* USER CODE BEGIN EXTI15_10_IRQn 1 */ /* USER CODE END EXTI15_10_IRQn 1 */ } é€™å…©è¡Œå„åˆ¥æ˜¯å› ç‚ºæˆ‘å€‘å‰›å‰›é–‹çš„åŠŸèƒ½ç”Ÿçš„\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 void HAL_GPIO_EXTI_IRQHandler(uint16_t GPIO_Pin) { /* EXTI line interrupt detected */ if(__HAL_GPIO_EXTI_GET_IT(GPIO_Pin) != 0x00u) { __HAL_GPIO_EXTI_CLEAR_IT(GPIO_Pin); HAL_GPIO_EXTI_Callback(GPIO_Pin); } } __weak void HAL_GPIO_EXTI_Callback(uint16_t GPIO_Pin) { /* Prevent unused argument(s) compilation warning */ UNUSED(GPIO_Pin); /* NOTE: This function should not be modified, when the callback is needed, the HAL_GPIO_EXTI_Callback could be implemented in the user file */ } __weak ä»£è¡¨æœ‰åŒå function çš„è©±ï¼Œå°±æœƒæ¡ç”¨æ²’ __weak prefix çš„\næ‰€ä»¥æˆ‘å€‘å¯ä»¥åœ¨ gpio.c æ”¾ä¸‹é¢çš„ç¨‹å¼ç¢¼\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #include \u0026lt;stdbool.h\u0026gt; void HAL_GPIO_EXTI_Callback(uint16_t GPIO_Pin) { if(GPIO_Pin == B1_Pin){ static bool prev_val = false; if(prev_val == false){ HAL_GPIO_WritePin(RED_LED_GPIO_Port, RED_LED_Pin, GPIO_PIN_SET); prev_val = true; } else{ HAL_GPIO_WritePin(RED_LED_GPIO_Port, RED_LED_Pin, GPIO_PIN_RESET); prev_val = false; } } } å¯¦é©— è¨­å®šå…©å€‹è¼¸å…¥ï¼Œä¸€å€‹è¼¸å‡ºï¼Œä¸€å€‹ interrupt\nç•¶æŒ‰ä¸‹æŒ‰éˆ•æ™‚ï¼Œåˆ‡æ›ç´…è‰² LED çš„äº®æ»…ï¼Œä¸¦ä¸”è®“æ¿å­ä¸Šçš„ç¶ è‰² LED è¼¸å‡ºå’Œç´…è‰² LED ç›¸åçš„çµæœ\nB1(PC13ã€è—è‰²æŒ‰éˆ•) æŒ‰ä¸‹å»çš„æ™‚å€™ï¼Œæœƒç™¼å‡º interruptï¼Œä¸¦è®“ RED_LED(PC10) è¼¸å‡ºå’Œä¸Šæ¬¡ç›¸åçš„é›»ä½ï¼Œè®“éºµåŒ…ç‰ˆä¸Šçš„ç´…è‰² LED äº®æ»…ï¼Œæ­£æ¥µé‚£é‚Šæ¥ä¸€æ¢æœé‚¦ç·šçµ¦ GREEN_LED_INPUT (PC12)ï¼Œä¸¦ä¸” LD2(PA5ã€æ¿å­ä¸Šçš„ç¶ è‰² LED) æœƒè¼¸å‡ºå’Œç´…è‰² LED ç›¸åçš„çµæœã€‚\nç¨‹å¼ç¢¼\n","date":"2023-04-02T01:32:54+08:00","permalink":"https://roykesydon.github.io/Blog/p/stm32-gpio-%E5%AF%A6%E9%A9%97/","title":"STM32 GPIO å¯¦é©—"},{"content":"ä½¿ç”¨çš„æ¿å­ STM32L476RG\né–‹ç™¼æ–‡ä»¶ é–‹ç™¼å‰éœ€è¦å…ˆå» ST å®˜ç¶²ï¼Œæ ¹æ“šä½ çš„æ¿å­è¼‰å››å€‹é‡è¦æ–‡ä»¶\nDatasheet ä¸Šåœ–æ˜¯å…¶ä¸­çš„ block diagram\nReference Manuals\nProgramming Manuals\nSchematic\nå‰µå»º project File -\u0026gt; New -\u0026gt; STM32 Project Board Selector æœç´¢ NUCLEO-L476RGï¼Œé¸å–ä¸¦ Next è¨­ç½® Project Nameï¼Œå…¶ä»–ä¸å‹•ï¼ŒNext Copy only the necessary library filesï¼ŒFinish ioc å°ˆæ¡ˆæœƒæœ‰å€‹ .ioc æª”ï¼Œå¯ä»¥é€é GUI ç”Ÿæˆè¨­å®š pin çš„ç¨‹å¼ç¢¼\nå»ºè­° Project Manager çš„ Code Generator å‹¾é¸ Generate peripheral initialization as a pair \u0026lsquo;.c/.h\u0026rsquo; files per peripheralï¼Œé–‹ç™¼èµ·ä¾†æ¯”è¼ƒæ–¹ä¾¿\nCompile é»é¸ä¸Šé¢çš„ hammer\nClock Configuration ioc é‚£é‚Šé‚„å¯ä»¥è¨­ç½® clock\nExternal clock LSE å’Œ HSE æ˜¯ (Low / High Speed External)ï¼Œä½ æœ‰ oscillator çš„è©±å¯ä»¥è‡ªå·±å¼„\nä½ å¯ä»¥èª¿ sysclk æˆ– peripheral clock\nProgramming åœ¨ USER CODE section å¯«ä¸Šç¨‹å¼ç¢¼ é€™æ˜¯ç”±æ–¼ç”Ÿæˆç¨‹å¼ç¢¼çš„æ©Ÿåˆ¶æ‰€è‡´\né¸å–çš„éƒ¨åˆ†å¯ä»¥æŒ‰ F3ï¼Œçœ‹ä»–æ˜¯å¾å“ªé‚Šä¾†çš„ï¼Œæˆ–çœ‹ macro ä¹‹é¡çš„\næŒ‰ä¸‹ alt + / æœƒå‡ºç¾è‡ªå‹•è£œå…¨çš„æç¤º\nDEBUG ä¸Šé¢æœ‰å€‹ BUG ç¬¦è™Ÿçš„æ±è¥¿ï¼Œæ—é‚Šçš„ç®­é ­å¯ä»¥ç”¨ DEBUG çš„è¨­å®š\nåˆå»º STM32 C/C++ Applicationï¼Œå¯ä»¥ New æ–°è¨­å®š\nC/C++ Application é‚£é‚Šé¸ä½  compile çš„ elf æª”\nDebugger é–‹å•Ÿ ST-LINK S/Nï¼Œä¸¦ä¸”æƒæï¼Œå¦‚æœä½ çš„é›»è…¦æœ‰æ¥ä¸Š MCUï¼Œæ‡‰è©²æœƒç›´æ¥æ‰¾åˆ°\n","date":"2023-04-02T00:32:54+08:00","permalink":"https://roykesydon.github.io/Blog/p/stm32cubeide-%E5%9F%BA%E6%9C%AC%E9%96%8B%E7%99%BC%E4%BD%BF%E7%94%A8/","title":"STM32CubeIDE åŸºæœ¬é–‹ç™¼ä½¿ç”¨"},{"content":"paper: GIT: A Generative Image-to-text Transformer for Vision and Language\n1 2 3 4 5 6 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•”â•â•â•â•â• â–ˆâ–ˆâ•‘â•šâ•â•â–ˆâ–ˆâ•”â•â•â• â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘ â•šâ•â•â•â•â•â• â•šâ•â• â•šâ•â• Abstract è¨­è¨ˆäº†ä¸€å€‹ Generative Image-to-text Transformerï¼Œçµ±ä¸€ vision-language tasksï¼Œåƒæ˜¯ image/video captioning æˆ–æ˜¯å•ç­”ã€‚\né›–ç„¶ generative models åœ¨é è¨“ç·´å’Œå¾®èª¿çš„æ™‚å€™æ˜¯åŒæ¨£çš„ç¶²è·¯æ¶æ§‹ï¼Œç¾æœ‰çš„å·¥ä½œé€šå¸¸éƒ½åŒ…å«è¤‡é›œçš„æ¶æ§‹ (uni/multi-modal encoder/decoder)ï¼Œ è€Œä¸”ä¾è³´æ–¼å¤–éƒ¨æ¨¡çµ„ï¼Œæ¯”å¦‚ç‰©ä»¶åµæ¸¬æˆ– optical character recognition (OCR)ã€‚\nåœ¨ GITï¼Œæˆ‘å€‘ç°¡åŒ–ç‚º single language modeling task ä¸‹çš„ä¸€å€‹ image encoder å’Œä¸€å€‹ text decoderã€‚\næ“´å¤§äº†é è¨“ç·´è³‡æ–™å’Œæ¨¡å‹å¤§å°ä»¥æé«˜æ¨¡å‹æ€§èƒ½ã€‚\nåœ¨è¨±å¤šå…·æœ‰æŒ‘æˆ°æ€§çš„ benchmarks ä¸Šå–å¾— SOTAã€‚\næ¯”å¦‚é¦–æ¬¡åœ¨ TextCpas ä¸Šè¶…è¶Šäººé¡çš„è¡¨ç¾ã€‚\næå‡ºäº†ä¸€ç¨® generation-based image classification and scene text recognition çš„æ–°æ–¹æ¡ˆã€‚\nIntroduction è¿‘å¹´ä¾†åœ¨ vision-languageï¼ˆVLï¼‰é è¨“ç·´æ–¹é¢å–å¾—äº†å·¨å¤§é€²å±•ï¼Œç‰¹åˆ¥æ˜¯åŸºæ–¼ image-text pairs çš„å¤§è¦æ¨¡æ•¸æ“šï¼Œä¾‹å¦‚ CLIPã€Florence å’Œ SimVLMã€‚\nå­¸ç¿’åˆ°çš„ representation å¾ˆå¥½çš„æé«˜äº†ä¸‹æ¸¸ä»»å‹™çš„æ€§èƒ½ï¼Œæ¯”å¦‚ image captioningã€visual question answering å’Œ image-text retrievalã€‚\nåœ¨é è¨“ç·´éç¨‹ä¸­ï¼ŒMasked Language Modeling (MLM) å’Œ Image-Text Matching (ITM) è¢«å»£æ³›ä½¿ç”¨ã€‚\nç„¶è€Œé€™äº› loss å’Œä¸‹æ¸¸ä»»å‹™ä¸åŒï¼Œå¿…é ˆåš task-specific adaptationã€‚\næ¯”å¦‚ï¼Œ image captioning è¦ç§»é™¤ ITMï¼ŒVQA éœ€è¦é¡å¤–éš¨æ©Ÿåˆå§‹çš„ MLPã€‚\nç‚ºäº†æ¸›å°‘é€™ç¨®å·®ç•°ï¼Œæœ€è¿‘çš„ç ”ç©¶è©¦åœ–ç‚ºé è¨“ç·´æ¨¡å‹è¨­è¨ˆ unified generative models ä¾†é è¨“ç·´ï¼Œå› ç‚ºå¤§å¤šæ•¸ VL çš„å•é¡Œå¯ä»¥è½‰åŒ–ç‚ºç”Ÿæˆå•é¡Œã€‚\né€™äº›æ–¹æ³•é€šå¸¸åˆ©ç”¨ multi-modal encoder å’Œ text decoderï¼Œä¸¦ç²¾å¿ƒè¨­è¨ˆ text input å’Œ text targetã€‚\nç‚ºäº†é€²ä¸€æ­¥æ¨å‹•é€™æ–¹å‘çš„ç ”ç©¶ï¼Œä½œè€…è¨­è¨ˆäº†ä¸€å€‹ç°¡å–®çš„ Generative Image-to-text Transformerï¼Œç¨±ä½œ GITï¼ŒåªåŒ…å«ä¸€å€‹ image encoder å’Œ text decoderã€‚\né è¨“ç·´ä»»å‹™åªæ˜¯æŠŠè¼¸å…¥çš„åœ–åƒæ˜ å°„åˆ°ç›¸é—œè¯çš„æ–‡å­—æè¿°ã€‚\nç›¡ç®¡ä»–å¾ˆç°¡å–®ï¼Œä½†é‚„æ˜¯åœ¨çœ¾å¤šå…·æœ‰æŒ‘æˆ°æ€§çš„ benchmark å–å¾— SOTAã€‚\nimage encoder æ˜¯ Swin-like vision transformerï¼Œåœ¨å¤§é‡çš„ image-text pairs ä¸Šåš pretrainï¼ŒåŸºæ–¼ contrastive taskã€‚\né€™æ¶ˆé™¤äº†ç¾æœ‰è¨±å¤šæ–¹æ³•ä¸­å° object detector çš„ä¾è³´ã€‚\nç‚ºäº†å°‡å…¶æ“´å±•åˆ°å½±ç‰‡é ˜åŸŸï¼Œæˆ‘å€‘æŠŠå¤šå€‹ frame çš„ç‰¹å¾µ concatenateï¼Œä½œç‚º video è¡¨ç¤ºã€‚\ntext decoder æ˜¯ä¸€å€‹ç”¨ä¾†é æ¸¬ç›¸é—œè¯æ–‡å­—çš„ transformerã€‚\næ•´å€‹ç¶²è·¯éƒ½æ˜¯åŸºæ–¼ language modeling task ä¾†è¨“ç·´ã€‚\nå°æ–¼ VQAï¼Œinput question è¢«çœ‹ä½œ text prefixï¼Œä¸¦ä»¥ auto-regressive çš„æ–¹æ³•ç”Ÿå‡ºç­”æ¡ˆã€‚\næ­¤å¤–ï¼Œä½œè€…æå‡ºäº†ä¸€ç¨® generation-based çš„ ImageNet classification æ–°æ–¹æ¡ˆï¼Œé æ¸¬æ¨™ç±¤ç›´æ¥æ ¹æ“šä½œè€…çš„ç”Ÿæˆæ¨¡å‹ï¼Œè€Œä¸ç”¨é å…ˆå®šç¾©è©å½™è¡¨ã€‚\næˆ‘å€‘çš„ä½œæ³•å¾ˆç°¡å–®ï¼Œä½†åœ¨æ“´å¤§é è¨“ç·´è³‡æ–™å’Œæ¨¡å‹å¤§å°å¾Œï¼Œæˆæœé©šäººã€‚\nä¸»è¦è²¢ç»å¦‚ä¸‹ï¼š\næˆ‘å€‘å±•ç¤ºäº† GITï¼Œåƒ…ç”±ä¸€å€‹ image encoder å’Œä¸€å€‹ text decoder çµ„æˆï¼Œé€é language modeling taskï¼Œåœ¨ 0.8 billion image-text pairs ä¸Š pretrainã€‚\nåœ¨ image/video captioning å’Œ QA ä¸Šï¼Œæ²’æœ‰åŸºæ–¼ object detectorsï¼Œobject tags å’Œ OCRï¼Œå°±åœ¨å¤šå€‹ä»»å‹™ä¸Šå–å¾— SOTAã€‚è­‰æ˜ç°¡å–®çš„ç¶²è·¯æ¶æ§‹ä¹Ÿå¯ä»¥é€é scaling å–å¾—å¼·å¤§çš„æ€§èƒ½ã€‚\næˆ‘å€‘è­‰æ˜ GIT é›–ç„¶ pretrain åœ¨ image-text pairsï¼Œä¹Ÿèƒ½åœ¨ video tasks ä¸Šå–å¾— SOTAï¼Œä¸éœ€è¦ video dedicated encodersã€‚\næˆ‘å€‘æå‡ºäº†ä¸€ç¨®æ–°çš„ generation-based image classification æ–¹æ¡ˆï¼Œåœ¨ ImageNet-1K ä¸Šï¼Œå–å¾—ä¸éŒ¯çš„æ€§èƒ½ã€‚\nRelated Work åœ¨ VL pre-training ä¸­ï¼Œå¤š multi-task pre-training è¢«å»£æ³›ä½¿ç”¨ï¼Œè³¦äºˆç¶²è·¯å¤šç¨®æˆ–å¢å¼·çš„èƒ½åŠ›ã€‚\næ¯”å¦‚ï¼ŒMLM å’Œ ITM æ˜¯å»£æ³›æ¡ç”¨çš„é è¨“ç·´ä»»å‹™ï¼Œæœ€è¿‘ä¹Ÿæœ‰ç ”ç©¶åŠ å…¥ image-text contrastive lossã€‚\nç”±æ–¼å¤šæ•¸ VL ä»»å‹™éƒ½å¯ä»¥è¡¨ç¤ºæˆ text generation taskï¼Œæ‰€ä»¥å¯ä»¥è¨“ç·´ä¸€å€‹ç”Ÿæˆæ¨¡å‹ä¾†æ”¯æŒå„ç¨®ä¸‹æ¸¸ä»»å‹™ã€‚\nè¼¸å…¥å’Œè¼¸å‡ºæ–‡æœ¬é€šå¸¸éƒ½æœƒç¶“éç²¾å¿ƒè¨­è¨ˆï¼Œä»¥é è¨“ç·´é€™æ¨£çš„ç”Ÿæˆæ¨¡å‹ã€‚\nå°æ–¼ image representationï¼ŒFaster RCNN è¢«å¤§å¤šæ•¸ç¾æœ‰æ–¹æ³•ç”¨ä¾†æå–å€åŸŸç‰¹å¾µã€‚\nåŒæ™‚ï¼Œä¹Ÿå¾ˆå®¹æ˜“ä»¥ end-to-end çš„æ–¹æ³•è¨“ç·´æ•´å€‹ç¶²è·¯ã€‚\né™¤äº† feature mapï¼Œobject tagsï¼Œä¹Ÿå¾ˆå¸¸è¢«ç”¨ä¾†æ–¹ä¾¿ transformer ç†è§£ä¸Šä¸‹æ–‡ï¼Œç‰¹åˆ¥æ˜¯ novel objectsã€‚\nå°æ–¼èˆ‡å ´æ™¯æ–‡æœ¬ç›¸é—œçš„ä»»å‹™ï¼Œèª¿ç”¨ OCR ä»¥ç”Ÿæˆå ´æ™¯æ–‡æœ¬ä½œç‚ºé™„åŠ ç¶²è·¯è¼¸å…¥ã€‚\nå°æ–¼ text predictionï¼Œå¸¸ç”¨ transformer networkï¼Œçµåˆ cross-attention module ä¾†èåˆ image tokensã€‚\næˆ–è€…åªæ˜¯å–®ç´” concatenate text tokens å’Œ image tokensï¼Œç„¶å¾Œç”¨ self-attentionã€‚\nåœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘å€‘æœ‰ 9 å€‹ä¸åŒçš„ benchmarkï¼Œ3 ç¨®ä¸åŒæ¨¡å‹å¤§å°å’Œ 3 ç¨®ä¸åŒé è¨“ç·´è³‡æ–™è¦æ¨¡ã€‚\nGenerative Image-to-text Transformer Network Architecture image encoder åŸºæ–¼ contrastive pre-trained modelã€‚\nè¼¸å…¥æ˜¯åŸå§‹åœ–åƒï¼Œè¼¸å‡ºæ˜¯ compact 2D feature mapï¼Œè¢« flatten æˆ list of featuresã€‚\né€éä¸€å€‹é¡å¤–çš„ linear layer å’Œä¸€å€‹ layernorm layerï¼Œimage features è¢« project åˆ° D dimensionsï¼Œä¹Ÿå°±æ˜¯ text encoder çš„ inputã€‚\nä½œè€…ä½¿ç”¨åš contrastive tasks pretraining çš„ image encoderï¼Œå› ç‚ºæœ€è¿‘çš„ç ”ç©¶è¡¨æ˜é€™ç¨® image encoder æœ‰æ›´å¥½çš„æ€§èƒ½ã€‚\nåœ¨å¾Œé¢çš„ç« ç¯€ï¼Œé‚„è§€å¯Ÿåˆ° VL performence æ˜é¡¯åœ°éš¨è‘—æ›´å¼·çš„ image encoder è€Œæœ‰æ‰€æå‡ã€‚ é€™å’Œ object detection-based çš„æ–¹æ³•è§€å¯Ÿåˆ°çš„çµæœä¸€è‡´ã€‚\nCoCa çš„ concurrent work çµ±ä¸€äº† contrastive task å’Œ the generation taskï¼Œä½œç‚ºä¸€å€‹é è¨“ç·´éšæ®µã€‚\nä½œè€…çš„æ–¹æ³•ç›¸ç•¶æ–¼æ˜¯æŒ‰é †åºåˆ†é›¢å…©å€‹ä»»å‹™:\nç”¨ contrastive task è¨“ç·´ image encoder ç”¨ generation task pretrain image encoder å’Œ text decoder text decoder æ˜¯ä¸€å€‹ç”¨æ–¼é æ¸¬æ–‡æœ¬æè¿°çš„ transformer moduleï¼Œç”±å¤šå€‹ transformer block çµ„æˆï¼Œæ¯å€‹ transformer block ç”±ä¸€å€‹ self-attention layer å’Œ feed-forward layer çµ„æˆã€‚\ntext è¢« tokenize å’Œ embed åˆ° D dimensionsï¼Œä¸¦æ·»åŠ  positional encoding å’Œ layernorm layerã€‚\nimage features å’Œ text embeddings è¢« concatenate èµ·ä¾†ä½œç‚º transformer module çš„è¼¸å…¥ã€‚\ntext ä»¥ [BOS] é–‹å§‹ï¼Œä¸¦ä»¥ auto regressive çš„æ–¹å¼ decodeï¼Œç›´åˆ° [EOS] æˆ– maximum stepsã€‚\nattention mask æ ¹æ“šä¸Šåœ–è¨­è¨ˆï¼Œä½¿çš„ text token åªèƒ½ä¾è³´æ–¼å‰é¢çš„ text token å’Œ image tokenï¼Œè€Œ image token å¯ä»¥äº’ç›¸åš attentionã€‚\né€™å’Œ unidirectional attention mask ä¸åŒï¼Œunidirectional attention mask ä¸¦éæ¯å€‹ image token éƒ½å¯ä»¥ä¾è³´æ–¼å…¶ä»–çš„ Image tokenã€‚\nä½œè€…å¾ˆå¥½åœ°åˆå§‹åŒ– image encoderï¼Œå»éš¨æ©Ÿåˆå§‹åŒ– text decoderã€‚\né€™ç¨®è¨­è¨ˆå‹•æ©Ÿæ˜¯åŸºæ–¼[MiniVLM: A Smaller and Faster Vision-Language Model]ï¼Œè©²ç ”ç©¶éš¨æ©Ÿåˆå§‹åŒ–é¡¯ç¤ºå‡ºèˆ‡ BERT åˆå§‹åŒ–ç›¸ä¼¼åœ°æ€§èƒ½ã€‚\nåŸå› å¯èƒ½åœ¨æ–¼ BERT åœ°åˆå§‹åŒ–ç„¡æ³•ç†è§£åœ–åƒä¿¡è™Ÿï¼Œé€™å°æ–¼ VL ä»»å‹™è‡³é—œé‡è¦ã€‚\n[Flamingo: a Visual Language Model for Few-Shot Learning] æ¡ç”¨äº†é¡ä¼¼çš„ image encoder + text decoderï¼Œä½†æ˜¯ä»–å€‘çš„ decoder ç¶“é pretrainï¼Œä¸¦ä¸”æœ‰ freezeï¼Œå¥½ä¿ç•™å¤§å‹èªè¨€æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚\nGIT çš„æ‰€æœ‰åƒæ•¸éƒ½æœƒæ›´æ–°ï¼Œä»¥æ›´å¥½åœ°é©æ‡‰ VL çš„ä»»å‹™ã€‚\nå¦ä¸€ç¨®æ¶æ§‹æ˜¯ cross-attention-based çš„ decoderï¼Œç”¨æ–¼ incorporate image signalsï¼Œè€Œä¸æ˜¯ concatenation å†ç”¨ self-attentionã€‚\næ ¹æ“šå¯¦é©—ï¼Œlarge-scale çš„ pre-trainingï¼Œself-attention-based æœƒæœ‰æ›´å¥½çš„æ€§èƒ½ï¼Œå°è¦æ¨¡çš„å‰‡æ˜¯ cross-attention-basedã€‚\nä¸€å€‹åˆç†çš„è§£é‡‹æ˜¯ï¼Œç¶“éå……åˆ†è¨“ç·´ï¼Œdecoder å¯ä»¥å¾ˆå¥½åœ°è™•ç†åœ–åƒå’Œæ–‡æœ¬ï¼Œè€Œä¸” image token å¯ä»¥ç‚ºäº† text generation æ›´å¥½åœ°æ›´æ–°ã€‚\nè€Œ cross-attention è®“ image token æ²’è¾¦æ³• attend å½¼æ­¤ã€‚\nPre-training è¨“ç·´æ¡ç”¨ language modeling (LM) lossã€‚\n$I$ æ˜¯ image $y_i,i \\in $ { $ 1,\u0026hellip;,N $ } æ˜¯æ–‡å­— tokenï¼Œ$y_0$ æ˜¯ [BOS]ï¼Œ$y_{N+1}$ æ˜¯ [EOS] CE æ˜¯æœ‰ 0.1 label smoothing çš„ cross-entropy å¦ä¸€ç¨®é¸æ“‡æ˜¯ MLMï¼Œåœ¨æ¯å€‹ epoch ä¸­é æ¸¬ 15% çš„è¼¸å…¥ tokenï¼Œè¦é æ¸¬æ‰€æœ‰ token è‡³å°‘éœ€è¦ 1 / 0.15 = 6.7 å€‹ epochsï¼Œå°æ–¼ LMï¼Œæ¯å€‹ epoch éƒ½å¯ä»¥é æ¸¬æ‰€æœ‰ tokenï¼Œå°æ–¼å¤§è¦æ¨¡é è¨“ç·´è³‡æ–™ä¾†èªªæ•ˆç‡æ›´é«˜ã€‚\nablation studies é¡¯ç¤ºå‡º LM å¯ä»¥åœ¨æœ‰é™çš„ epoch å…§å¯¦ç¾æ›´å¥½çš„æ€§èƒ½ã€‚ åœ¨å¤§è¦æ¨¡è¨“ç·´ä¸­ï¼Œç”±æ–¼è¨ˆç®—è³‡è¨Šçš„é™åˆ¶ï¼Œåªæœ‰å…©å€‹ epochï¼Œæ‰€ä»¥é¸æ“‡ LMã€‚ èˆ‡æ­¤åŒæ™‚ï¼Œå¤§éƒ¨åˆ†æœ€è¿‘çš„ large-scale language model ä¹Ÿæ˜¯åŸºæ–¼ LMã€‚\nå¦‚æœæ²’æœ‰åœ–åƒè¼¸å…¥ï¼Œè©²æ¨¡å‹å°‡ç°¡åŒ–ç‚º decoder-only çš„èªè¨€æ¨¡å‹ï¼Œæ¶æ§‹é¡ä¼¼æ–¼ GPT-3ã€‚\nå› æ­¤ï¼Œé€™ç¨®è¨­è¨ˆé‚„å¯ä»¥åˆ©ç”¨ text-only çš„è³‡æ–™ä¾†æå‡ scaled-up decoder çš„èƒ½åŠ›ï¼ŒæŠŠé€™ä¿ç•™çµ¦æœªä¾†çš„å·¥ä½œã€‚\nFine-tuning å°æ–¼ image captioningï¼Œç”±æ–¼è¨“ç·´æ•¸æ“šæ ¼å¼å’Œé è¨“ç·´ç›¸åŒï¼Œæ‰€ä»¥ç”¨åŒæ¨£çš„ LM task ä¾†å¾®èª¿ GITã€‚ å°æ–¼ visual question answeringï¼Œå•é¡Œå’Œ GT åœ¨å¾®èª¿çš„æ™‚å€™è¢«çœ‹åš special captionï¼Œä½† LM loss åƒ…ç”¨æ–¼ç­”æ¡ˆå’Œ [EOS]ã€‚\næ¨ç†éç¨‹ä¸­ï¼Œquestion è¢«ç•¶ä½œ caption çš„ prefixï¼Œå®Œæˆçš„éƒ¨åˆ†æ˜¯é æ¸¬ã€‚\nVQAv2 ç¾æœ‰çš„å·¥ä½œæ”¶é›†å€™é¸ç­”æ¡ˆï¼Œå†é‡æ§‹æˆåˆ†é¡å•é¡Œï¼Œé æ¸¬ä¸€æ¬¡ã€‚ ä½œè€…çš„å·¥ä½œæœ‰æ›´å¤šæŒ‘æˆ°ï¼Œå› ç‚ºæ˜¯ç”Ÿæˆå¼çš„ï¼Œéœ€è¦ç”Ÿå‡ºè‡³å°‘å…©å€‹æ­£ç¢ºçš„ tokenï¼Œç­”æ¡ˆå’Œ [EOS]ã€‚\nç„¶è€Œè€ƒæ…®åˆ°è‡ªç”±å½¢å¼ç­”æ¡ˆçš„å¥½è™•ï¼Œä½œè€…é¸æ“‡äº†ç”Ÿæˆæ–¹æ³•ã€‚\nç”±æ–¼ç”Ÿæˆæ¨¡å‹çš„é›£åº¦ï¼ŒVQAv2 æ¯”ç¾æœ‰çš„åˆ¤åˆ¥å·¥ä½œç•¥å·®ã€‚\nå°æ–¼å’Œ scene-text related VQA ä»»å‹™ï¼Œç¾æœ‰æ–¹æ³•é€šå¸¸åˆ©ç”¨ OCR ç”Ÿæˆ 5 å€‹ scene text ä¸¦ç”¨ dynamic pointer network æ±ºå®šç•¶å‰è¼¸å‡ºæ‡‰è©²æ˜¯ OCR é‚„æ˜¯ general textã€‚\nä½†ç”±æ–¼ä½œè€…çš„æ–¹æ³•ä¸ä¾è³´æ–¼ OCRï¼Œå› æ­¤ä¹Ÿä¸ä¾è³´æ–¼ dynamic pointer networkã€‚\næ ¹æ“šå¯¦é©—ï¼Œä½œè€…ç™¼ç¾æ¨¡å‹é€éå¤§è¦æ¨¡é è¨“ç·´è³‡æ–™å­¸æœƒå¦‚ä½•é–±è®€å ´æ™¯æ–‡æœ¬ï¼Œä¸¦ä¸”ä½œè€…çš„æ¨¡å‹ä¸æ˜¯å°ˆé–€ç‚ºäº†å½±ç‰‡é ˜åŸŸè¨­è¨ˆçš„ï¼Œä½†å¯ä»¥é€éç°¡å–®çš„æ¶æ§‹æ›´æ”¹å°±å–å¾—å…·æœ‰ç«¶çˆ­åŠ›æˆ–ç”šè‡³ SOTA çš„æˆæœï¼Œä¹Ÿå°±æ˜¯ä½œè€…å¯ä»¥å¾æ¯å€‹å½±ç‰‡æ¡æ¨£å¤šå€‹ frameï¼Œä¸¦é€é image encoder ç¨ç«‹åœ°ç‚ºæ¯å€‹ frame ç·¨ç¢¼ã€‚ æœ€å¾Œæ·»åŠ ä¸€å€‹ learnable temporal embedding (åˆå§‹åŒ–ç‚º 0)ï¼Œä¸¦ concatenate sampled frames çš„ç‰¹å¾µã€‚\nä½œè€…é‚„ç”¨æ–¼åœ–ç‰‡åˆ†é¡ï¼ŒæŠŠ class name ç”¨æ–¼ captionã€‚\né€™å’Œç¾æœ‰å·¥ä½œä¸ä¸€æ¨£ï¼Œç¾æœ‰å·¥ä½œé€šå¸¸å…ˆå®šç¾©è©å½™è¡¨ï¼Œä¸¦ç”¨ç·šæ€§å±¤é æ¸¬æ¯å€‹é¡åˆ¥çš„å¯èƒ½æ€§ã€‚\nç•¶æ–°æ•¸æ“šå’Œæ–°é¡åˆ¥è¢«æ·»åŠ åˆ°ç¾æœ‰æ•¸æ“šçš„æ™‚å€™ï¼Œé€™ç¨®æ–°ä¸€ä»£çš„æ–¹æ¡ˆæ˜¯æœ‰ç›Šçš„ï¼Œå› ç‚ºé€™æ¨£å¯ä»¥åœ¨ä¸å¼•å…¥æ–°åƒæ•¸çš„æƒ…æ³ä¸‹å°æ–°æ•¸æ“šé€²è¡Œè¨“ç·´ã€‚\nExperiments Setting æ”¶é›† 0.8B çš„ image-text pairs ä¾†é è¨“ç·´ã€‚\nimage encoder æ˜¯æ ¹æ“š pre-trained contrastive model åˆå§‹åŒ–çš„ã€‚\nhidden dimension (D) = 768\ntext decoder æœ‰ 6 å€‹ randomly-initialized transformer blocks\nå…±æœ‰ 0.7b çš„åƒæ•¸\nimage decoder å’Œ text encoder çš„ learning rate å„åˆ¥æ˜¯ 1e-5 å’Œ 5e-5ï¼Œéƒ½ cosine decay åˆ° 0\næ¨è«–éšæ®µ beam size æ˜¯ 4ï¼Œlength penalty æ˜¯ 0.6ã€‚\nSupplementary materials å±•ç¤ºäº†å°æ¨¡å‹è®Šé«” (GITB and GITL) å’Œæ›´å¤§æ¨¡å‹ (GIT2) çš„çµæœ\nResults on Image Classification è¼¸å‡ºå¿…é ˆèˆ‡é¡åˆ¥åç¨±å®Œå…¨åŒ¹é…ï¼Œç”šè‡³è€ƒæ…®å¤šæˆ–å°‘çš„ç©ºæ ¼ã€‚\nç”±æ–¼ä¸çŸ¥é“è©å½™è¡¨ï¼Œç²¾ç¢ºåŒ¹è¢«æº–ç¢ºåº¦åªæœ‰ 1.93%ï¼Œå¦‚æœé æ¸¬åŒ…å« GT å°±å°ï¼Œé‚£æœ‰ 40.88%ã€‚\né€šéå¾®èª¿æ¯å€‹é¡åˆ¥åªæœ‰ 1 shot æˆ– 5 shotï¼Œæº–ç¢ºåº¦æœƒé¡¯è‘—æé«˜ï¼Œ è¡¨æ˜åªç”¨å°‘é‡è¨“ç·´æ¨£æœ¬ï¼Œä¹Ÿå¯ä»¥è¼•é¬†é©æ‡‰ä¸‹æ¸¸ä»»å‹™ã€‚\nèˆ‡ Flamingo ç›¸æ¯”ï¼ŒGIT å¯¦ç¾æ›´é«˜çš„æº–ç¢ºåº¦ã€‚\nFlamingo åœ¨æ²’æœ‰åƒæ•¸æ›´æ–°çš„æƒ…æ³ä¸‹é€²è¡Œå°æ¨£æœ¬å­¸ç¿’ï¼Œä½†éœ€è¦é¡å¤–çš„ç¶²è·¯è¼¸å…¥ï¼Œå¯èƒ½æœƒå¢åŠ æ¨ç†æˆæœ¬ã€‚\nç›¸æ¯”ä¹‹ä¸‹ï¼ŒGIT é€éä¸€æ¬¡ lightweight fine-tuningï¼Œæ¨ç†éç¨‹ä¸­ä¸éœ€è¦é€™äº› training shotã€‚\nAnalysis Model and data scaling å°æ–¼ç¶²è·¯æ¶æ§‹ï¼Œä½œè€…çš„æ¨¡å‹è¢«ç¨±ä½œ Hugeï¼ŒæŠŠ image encoder æ›æˆ CLIP çš„ ViT-B/16 å’Œ ViT-L/14 çš„å‰‡æ˜¯ Base å’Œ Largeã€‚\nå¯ä»¥çœ‹å‡ºè¼ƒå¤§çš„ image encoder å¸¶ä¾†çš„å¥½è™•ï¼Œä½†æ ¹æ“šå¯¦é©—ï¼Œ ä½œè€…ç™¼ç¾å¾ˆé›£æœ‰æ•ˆåœ°æ“´å±• text decoderï¼ŒåŸå› å¯èƒ½æ˜¯ LM å¾ˆé›£ç”¨ limited amount of text ä¾†è¨“ç·´ã€‚\nå¦ä¸€å€‹å¯èƒ½çš„åŸå› æ˜¯ image encoder è² è²¬ object recognitionï¼Œè€Œ decoder è² è²¬ä»¥ NLP çš„æ–¹æ³•çµ„ç¹” object termsã€‚ å¾Œä¸€é …ä»»å‹™å¯èƒ½å¾ˆå®¹æ˜“ï¼Œå› ç‚ºå¤§å¤šæ•¸æè¿°éƒ½éµå¾ªç›¸ä¼¼çš„æ¨¡å¼ï¼Œæ¯”å¦‚ Object + verb + subjectï¼Œæ‰€ä»¥åªè¦ä¸€å€‹ small decoderï¼Œè¼ƒå¤§çš„ decoder å¯èƒ½æœƒå¢åŠ å­¸ç¿’é›£åº¦ã€‚\nFlamingo çš„ç ”ç©¶é¡¯ç¤ºæ›´å¤§çš„ Decoder å¯ä»¥æé«˜æ€§èƒ½ï¼Œä½†æ˜¯ä»–å€‘çš„ decoder æœ‰ pretrain éï¼Œè€Œä¸”åœ¨ VL é è¨“ç·´çš„æ™‚å€™ frozenï¼Œé¿é–‹äº†å¦‚ä½•æœ‰æ•ˆè¨“ç·´ decoder çš„å•é¡Œã€‚\nLEMON çš„ transformer å¯ä»¥æ“´å±•åˆ° 32 å±¤ï¼Œå¯èƒ½æ˜¯å› ç‚ºä»–å€‘ä½¿ç”¨ MLM è€Œä¸æ˜¯ LMï¼Œå¾Œè€…å¯èƒ½æ›´åŠ å›°é›£ã€‚\nScene text in pre-training data ç‚ºäº†ç­è§£ scene text comprehension çš„èƒ½åŠ›ï¼Œä½œè€…æª¢æŸ¥äº† pretrain data æœ‰å¤šå°‘ image-text pairs æœ‰ scene textã€‚\nä½œè€…ç”¨ Microsoft Azure OCR API4 å°ä¸€äº›è³‡æ–™åš OCRï¼Œç„¶å¾ŒæŠŠ OCR çµæœå’Œ associated text åšæ¯”å°ï¼Œåªæœ‰åŒ…å«é•·åº¦è¶…é 5 å€‹å­—å…ƒçš„ OCR çµæœæ‰æœƒç®—æ¯”å°ã€‚ æœ‰ 15% çš„ CC12M å’Œ 31% çš„ä¸‹è¼‰åœ–åƒ(500K) åŒ…å« scene text æè¿°ã€‚ ç”±æ–¼ä»»å‹™æ˜¯è¨“ç·´é æ¸¬ textï¼Œç¶²è·¯é€æ¼¸å­¸æœƒé–±è®€ scene textã€‚\nConclusion Limitations æ ¹æ“šå¯¦é©—ï¼Œç›®å‰ä¸æ¸…æ¥šå¦‚ä½•æ§åˆ¶ç”Ÿæˆçš„ caption ä»¥åŠå¦‚ä½•åœ¨ä¸æ›´æ–°åƒæ•¸çš„æƒ…æ³ä¸‹åŸ·è¡Œ in-context learningï¼ŒæŠŠé€™ç•™çµ¦æœªä¾†çš„å·¥ä½œã€‚\nSocietal impact è©²æ¨¡å‹åœ¨å¤§è¦æ¨¡æ•¸æ“šé›†ä¸Šé è¨“ç·´ï¼Œä¸èƒ½ä¿è­‰æ•¸æ“šä¸å« toxic languageï¼Œå¯èƒ½æœƒ poison outputã€‚\nå…¶ä»– A.3 Network è¬›è¶…åƒæ•¸\n","date":"2023-03-29T01:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/git-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"GIT è«–æ–‡é–±è®€"},{"content":"paper: RoBERTa: A Robustly Optimized BERT Pretraining Approach\n1 2 3 4 5 6 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â•šâ•â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â• â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â• â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘ â•šâ•â• â•šâ•â• â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â•â•â•šâ•â• â•šâ•â• â•šâ•â• â•šâ•â• â•šâ•â• Abstract ç™¼ç¾ BERT è¨“ç·´ä¸è¶³ï¼Œä¸¦ä¸”ä½œè€…çš„æ¨¡å‹åœ¨ 4/9 çš„ GLUE ä»»å‹™, RACE å’Œ SQuAD å–å¾— SOTAã€‚\nIntroduction è‡ªç›£ç£çš„è¨“ç·´æ–¹æ³•å¸¶ä¾†äº†é¡¯è‘—çš„æ€§èƒ½æå‡ï¼Œä½†è¦ç¢ºå®šé€™ä¸€å †æ–¹æ³•ä¸­çš„å“ªäº›æ–¹é¢è²¢ç»æœ€å¤§ï¼Œå…·å‚™æŒ‘æˆ°æ€§ã€‚\nè¨“ç·´çš„è¨ˆç®—é‡æ˜¯æ˜‚è²´çš„ï¼Œä½¿ fine-tune å—é™ï¼Œè€Œä¸”é€šå¸¸éƒ½æ˜¯ç”¨ä¸åŒå¤§å°çš„ private training dataï¼Œä½¿è©•ä¼°æ¨¡å‹æ›´åŠ å›°é›£ã€‚\nä½œè€…æå‡ºäº†å° BERT é è¨“ç·´çš„ replication studyï¼ŒåŒ…æ‹¬å°è¶…åƒæ•¸çš„èª¿æ•´ï¼Œä»¥åŠå°è¨“ç·´é›†å¤§å°çš„ä»”ç´°è©•ä¼°ã€‚\nä½œè€…ç™¼ç¾ BERT è¨“ç·´ä¸è¶³ï¼Œä¸¦æå‡ºäº†ä¸€ç¨®æ”¹é€²æ–¹æ³•ï¼Œç¨±ç‚º RoBERTaï¼Œå¯ä»¥é”åˆ°æˆ–è¶…éæ‰€æœ‰ post-BERT çš„æ–¹æ³•ã€‚\nä¿®æ”¹å¦‚ä¸‹:\nè¨“ç·´æ¨¡å‹çš„æ™‚é–“æ›´é•·ï¼Œbatch æ›´å¤§ï¼Œç”¨æ›´å¤š data ç§»é™¤ next sentence prediction objective è¨“ç·´æ›´é•·çš„åºåˆ— å‹•æ…‹åœ°æ”¹è®Šç”¨æ–¼è¨“ç·´è³‡æ–™çš„ masking pattern è²¢ç»:\næå‡ºä¸€çµ„é‡è¦çš„ BERT è¨­è¨ˆé¸æ“‡å’Œè¨“ç·´ç­–ç•¥ ä½¿ç”¨äº†æ–°çš„ datasetï¼Œå«åš CCNEWSï¼Œä¸¦è­‰æ˜ç”¨æ›´å¤šçš„è³‡æ–™ä¾†é è¨“ç·´ï¼Œå¯ä»¥æé«˜ä¸‹æ¸¸ä»»å‹™çš„è¡¨ç¾ è¨“ç·´è¡¨æ˜ï¼Œåœ¨æ­£ç¢ºçš„è¨­è¨ˆé¸æ“‡ä¸‹ï¼Œpretrained masked language model å’Œå…¶ä»–æœ€è¿‘çš„æ–¹æ³•æ¯”ï¼Œå…·æœ‰ç«¶çˆ­åŠ› Background å° BERT åšå›é¡§\nArchitecture L layers A self-attention heads H hidden dimension Training Objectives é è¨“ç·´çš„æ™‚å€™ï¼ŒBERT æœ‰å…©å€‹ç›®æ¨™: masked language modeling å’Œ next sentence prediction\nMasked Language Model (MLM) BERT éš¨æ©Ÿé¸æ“‡ 15% çš„ token é€²è¡Œå¯èƒ½çš„æ›¿æ›\n80% æ›æˆ [MASK]ï¼Œ10% ä¿æŒä¸è®Šï¼Œ10% è¢«é¸ç‚ºä¸€å€‹éš¨ä¾¿çš„ vocabulary token\nNext Sentence Prediction (NSP) åˆ†é¡ç¬¬äºŒå¥æ˜¯ä¸æ˜¯ä¸‹ä¸€å¥ï¼Œæ˜¯äºŒå…ƒåˆ†é¡ã€‚\næ­£ä¾‹ç”±æå–é€£çºŒçš„å¥å­ç”¢ç”Ÿï¼Œè² ä¾‹ç”±ä¸åŒçš„ç‰‡æ®µé…å°ç”¢ç”Ÿã€‚\næ­£ä¾‹å’Œè² ä¾‹ä»¥ç›¸ç­‰æ©Ÿç‡ç”¢ç”Ÿã€‚\nOptimization Adam $\\beta_1$ = 0.9, $\\beta_2$ = 0.999, $\\epsilon$ = 1e-6 $L_2$ weight decay of 0.01 Learning rate å‰ 10,000 step warm up åˆ° 1e-4ï¼Œç„¶å¾Œ linear decay å…¨éƒ¨çš„ layer å’Œ attention weight éƒ½ dropout 0.1 GELU æ¿€æ´»å‡½æ•¸ 1,000,000 æ¬¡ updateï¼Œbatch size 256ï¼Œåºåˆ—é•·åº¦ 512 Data BERT åœ¨ BookCorpus å’Œ English Wikipedia æ··å’Œçš„è³‡æ–™é›†ä¸Šè¨“ç·´ï¼Œå…±æœ‰ 16GB çš„æœªå£“ç¸®æ–‡æœ¬\nExperimental Setup æè¿°å°æ–¼ BERT çš„ replication study çš„å¯¦é©—è¨­ç½®\nImplementation ä½œè€…ç”¨ FAIRSEQ é‡æ–°å¯¦ç¾äº† BERTã€‚\nä¸»è¦éµå¾ª [Background-Optimization] ä¸­çš„ BERT åŸå§‹è¶…åƒæ•¸ï¼Œä½† peak learning rate å’Œ warmup step é™¤å¤–ï¼Œä»–å€‘é‡å°æ¯å€‹è¨­ç½®å–®ç¨èª¿æ•´ã€‚\nä½œè€…ç™¼ç¾è¨“ç·´å° Adam epsilon éå¸¸æ•æ„Ÿã€‚\nä½œè€…ç™¼ç¾è¨­ç½® $\\beta_2$ = 0.98ï¼Œåœ¨å¤§ batch size çš„æƒ…æ³ä¸‹ï¼Œå¯ä»¥æé«˜è¨“ç·´æ™‚çš„ç©©å®šæ€§ã€‚\nç”¨æœ€å¤š 512 å€‹ token é è¨“ç·´ã€‚\nä½œè€…ä¸æœƒéš¨æ©Ÿæ³¨å…¥çŸ­åºåˆ—ï¼Œä¹Ÿä¸æœƒç‚ºå‰ 90% çš„æ›´æ–°ç¸®çŸ­è¼¸å…¥çš„é•·åº¦ã€‚\nä½œè€…åªè¨“ç·´ full-length çš„ sequencesã€‚\nData BERT-style çš„é è¨“ç·´ä»°è³´å¤§é‡æ–‡æœ¬ã€‚\nå·²æœ‰ç ”ç©¶è­‰æ˜å¢åŠ æ•¸æ“šé‡å¯ä»¥æé«˜ end-task çš„æ€§èƒ½ã€‚\nå·²æœ‰ä¸€äº›ç ”ç©¶ï¼Œç”¨æ¯”åŸå§‹ BERT æ›´å¤šæ¨£æ›´å¤§çš„æ•¸æ“šé›†ï¼Œä½†ä¸æ˜¯æ‰€æœ‰çš„æ•¸æ“šé›†éƒ½æœ‰å…¬é–‹ã€‚\næœ¬ç ”ç©¶ç”¨äº†äº”å€‹ä¸åŒå¤§å°å’Œé ˜åŸŸçš„è‹±æ–‡æ–‡æœ¬ï¼Œå…±æœ‰è¶…é 160 GB çš„æœªå£“ç¸®æ–‡æœ¬ã€‚\nä½¿ç”¨ä»¥ä¸‹æ•¸æ“šé›†:\nBookCorpus + English Wikipedia BERT åŸæœ¬ä½¿ç”¨çš„ã€‚ 16 GB CC-News ä½œè€…å¾ CommonCrawl News dataset çš„è‹±æ–‡éƒ¨åˆ†ä¸­è’é›†ï¼ŒåŒ…å«äº† 2016 å¹´ 9 æœˆåˆ° 2019 å¹´ 2 æœˆçš„ 6300 è¬ç¯‡è‹±æ–‡æ–°èã€‚ éæ¿¾å¾Œæœ‰ 76 GB OpenWebText WebText çš„é–‹æºé‡å»ºç‰ˆï¼Œå¾ Reddit ä¸Šè‡³å°‘æœ‰ 3 å€‹ upvotes çš„ shared URLs æå–å‡ºçš„ Web å…§å®¹ã€‚ 38 GB Stories åŒ…å« CommonCrawl data çš„ä¸€å€‹å­é›†åˆï¼Œç¶“ééæ¿¾ï¼Œä»¥åŒ¹é… story-like style of Winograd schemas 31 GB Evaluation ä½¿ç”¨ä»¥ä¸‹ä¸‰å€‹ benchmarks è©•ä¼°é è¨“ç·´æ¨¡å‹\nGLUE The General Language Understanding Evaluation\nç”¨æ–¼è©•ä¼°è‡ªç„¶èªè¨€ç†è§£çš„ 9 å€‹æ•¸æ“šé›†çš„é›†åˆï¼Œä»»å‹™è¢«å®šç¾©ç‚º single-sentence åˆ†é¡æˆ– sentence-pair åˆ†é¡ä»»å‹™ã€‚\nfinetune çš„æµç¨‹éµå¾ªåŸå§‹ BERT paper\nSQuAD The Stanford Question Answering Dataset\næä¾›ä¸€æ®µ context ä»¥åŠä¸€å€‹å•é¡Œ\nå…·æœ‰å…©å€‹ç‰ˆæœ¬ V1.1 å’Œ V2.0\nV1.1 context ç¸½æ˜¯åŒ…å«ä¸€å€‹ç­”æ¡ˆ è©•ä¼° V1.1 çš„æ™‚å€™ï¼Œä½œè€…æ¡ç”¨å’Œ BERT ç›¸åŒçš„ span prediction method V2.0 ä¸€äº›å•é¡Œåœ¨æä¾›çš„ context ä¸­æ²’æœ‰å›ç­”ï¼Œä½¿ä»»å‹™æ›´æœ‰æŒ‘æˆ°æ€§ è©•ä¼° V2.0 çš„æ™‚å€™ï¼Œä½œè€…æœƒç”¨ä¸€å€‹é¡å¤–çš„äºŒå…ƒåˆ†é¡å™¨é æ¸¬å•é¡Œæ˜¯å¦å¯ä»¥å›ç­”ï¼Œåœ¨è©•ä¼°çš„æ™‚å€™ï¼Œåªé æ¸¬è¢«åˆ†é¡ç‚ºå¯å›ç­”çš„ RACE The ReAding Comprehension from Examinations å¤§å‹é–±è®€ç†è§£æ•¸æ“šé›†ï¼Œæœ‰è¶…é 28,000 ç¯‡æ–‡ç«  ä»¥åŠå°‡è¿‘ 100,000 å€‹å•é¡Œ å¾ä¸­åœ‹çš„è‹±æ–‡è€ƒè©¦è’é›†çš„ï¼Œé€™äº›è€ƒè©¦æ˜¯ç‚ºåœ‹ä¸­ç”Ÿå’Œé«˜ä¸­ç”Ÿè¨­è¨ˆçš„ æ¯ç¯‡æ–‡ç« éƒ½èˆ‡å¤šå€‹å•é¡Œç›¸é—œè¯ å°æ¯å€‹å•é¡Œï¼Œè¦å¾å››å€‹é¸é …ä¸­é¸å‡ºä¸€å€‹å°çš„ context æ¯”èµ·å…¶ä»–é–±è®€ç†è§£çš„æ•¸æ“šé›†è¦é•·ï¼Œè€Œä¸”è¦æ¨ç†çš„å•é¡Œæ¯”ä¾‹å¾ˆå¤§ Training Procedure Analysis æ¢è¨å“ªäº›é¸æ“‡å°æˆåŠŸé è¨“ç·´ BERT å¾ˆé‡è¦ã€‚\nä½œè€…æŠŠæ¶æ§‹å›ºå®šï¼Œä¹Ÿå°±æ˜¯è¨“ç·´å’Œ$BERT_{BASE}$ (L=12, H=768, A=12, 110M params)ä¸€æ¨£æ¶æ§‹çš„ BERT models\nStatic vs. Dynamic Masking BERT åœ¨ preprocessing çš„æ™‚å€™è™•ç† maskingï¼Œç”¢ç”Ÿå–®å€‹ static maskã€‚ ä½œè€…ç‚ºäº†é¿å…åœ¨æ¯å€‹ epoch éƒ½å°æ¯å€‹ instance ç”¨ç›¸åŒçš„ maskï¼Œå°‡æ•¸æ“šè¤‡è£½äº† 10 æ¬¡ï¼Œåœ¨ 40 å€‹ epochs è£¡ï¼Œä»¥ 10 ç¨®ä¸åŒçš„æ–¹å¼ maskã€‚æ‰€ä»¥ä¸€æ¬¡è¨“ç·´éç¨‹ä¸­ï¼Œç›¸åŒçš„ mask æœƒå‡ºç¾å››æ¬¡ã€‚\nä½œè€…æœƒä»¥ä¸Šè¿°ç­–ç•¥å’Œ Dynamic masking é€²è¡Œæ¯”è¼ƒï¼ŒDynamic masking æ˜¯åœ¨æ¯æ¬¡é¤µ model å‰ï¼Œæ‰ç”Ÿæˆ maskã€‚\nä½œè€…ç™¼ç¾ Dynamic Masking ç›¸æ¯” staticï¼Œè¦ä¸æ˜¯å·®ä¸å¤šï¼Œå°±æ˜¯ç•¥å¥½ï¼ŒåŸºæ–¼çµæœå’Œæ•ˆç‡çš„å„ªå‹¢è€ƒé‡ï¼Œå…¶ä»–å¯¦é©—ä¸­éƒ½ç”¨ dynamic maskingã€‚\nModel Input Format and Next Sentence Prediction åŸå§‹çš„ BERT é è¨“ç·´ä¸­ï¼Œå…©å€‹å¥å­è¦ä¸æ˜¯åŒä¸€å€‹æ–‡ä»¶çš„é€£çºŒå¥å­(p = 0.5)ï¼Œä¸ç„¶å°±æ˜¯ä¸åŒçš„ document åšæ¡æ¨£\nä»¥å¾€æœ‰ç ”ç©¶æŒ‡å‡ºç§»é™¤ NSP æœƒæå®³æ€§èƒ½ï¼Œä½†ä¹Ÿæœ‰ç ”ç©¶è³ªç–‘å¿…è¦æ€§ï¼Œæ‰€ä»¥æœ¬æ–‡æ¯”è¼ƒäº†å¹¾ç¨®æ›¿ä»£è¨“ç·´æ ¼å¼ï¼š\nSEGMENT-PAIR+NSP æœ€åŸå§‹çš„æ–¹æ³•ï¼Œæ¯å€‹ segment å¯ä»¥æœ‰å¤šå€‹è‡ªç„¶å¥å­ SENTENCE-PAIR+NSP åªåŒ…å«ä¸€å°å¥å­ï¼Œç”±æ–¼è¼¸å…¥æ˜é¡¯å°‘æ–¼ 512 tokenï¼Œæ‰€ä»¥æœƒå¢åŠ  batch size è®“ token ç¸½æ•¸å’Œå‰è€…å·®ä¸å¤š FULL-SENTENCES åŒ…å«å¾ä¸€å€‹æˆ–å¤šå€‹æ–‡ä»¶ä¸­é€£çºŒæ¡æ¨£çš„å®Œæ•´å¥å­ï¼Œå¯èƒ½æœƒè·¨è¶Šæ–‡ä»¶é‚Šç•Œï¼Œåœ¨æ–‡ä»¶é‚Šç•Œé–“æœƒåŠ å€‹é¡å¤–çš„åˆ†éš”ç¬¦ ç§»é™¤äº† NSP DOC-SENTENCES å’Œ FULL-SENTENCES å·®ä¸å¤šï¼Œä½†ä¸èƒ½è·¨è¶Š documentï¼Œåœ¨ document å°¾å·´çš„éƒ¨åˆ†æœƒå®¹æ˜“å°‘æ–¼ 512ï¼Œæ‰€ä»¥æœƒå‹•æ…‹å¢åŠ  batch sizeï¼Œè®“ token ç¸½æ•¸å’Œ FULL-SENTENCES å·®ä¸å¤š ç§»é™¤äº† NSP ç™¼ç¾ DOC-SENTENCES æ˜¯æœ€æ£’çš„ï¼Œä½†ç”±æ–¼ DOC-SENTENCES æœƒè®“ batch sizes å¤§å°å¯è®Šï¼Œæ‰€ä»¥å…¶ä»–å¯¦é©—æœƒç”¨ FULL-SENTENCESï¼Œæ¯”è¼ƒå¥½å’Œå…¶ä»–ç›¸é—œå·¥ä½œæ¯”è¼ƒã€‚\nTraining with large batches æ ¹æ“šéå»ç¥ç¶“ç¶²è·¯æ©Ÿå™¨ç¿»è­¯çš„å·¥ä½œï¼Œç•¶ learning rate é©ç•¶å¢åŠ çš„æ™‚å€™ï¼Œç”¨éå¸¸å¤§çš„çš„ mini-bathces å¯ä»¥æé«˜ optimization çš„é€Ÿåº¦å’Œ end-task æ€§èƒ½ã€‚\næœ€è¿‘çš„ç ”ç©¶ä¹Ÿé¡¯ç¤º BERT é©ç”¨æ–¼ large batch trainingã€‚\nText Encoding Byte-Pair Encoding (BPE) æ˜¯ä¸€ç¨®ä»‹æ–¼å­—ç¬¦ç´šåˆ¥å’Œè©ç´šåˆ¥è¡¨ç¤ºä¹‹é–“çš„æ··åˆè¡¨ç¤ºæ–¹æ³•ï¼Œå®ƒå…è¨±è™•ç†è‡ªç„¶èªè¨€èªæ–™åº«ä¸­å¸¸è¦‹çš„å¤§è©å½™é‡ã€‚\nBPE ä¸ä¾è³´æ–¼å®Œæ•´çš„å–®è©ï¼Œè€Œæ˜¯ä¾é  subwords unitsï¼Œé€šéå°è¨“ç·´èªæ–™é€²è¡Œçµ±è¨ˆåˆ†æä¾†æå–é€™äº› subwords unitsã€‚\nBPE è©å½™è¡¨çš„å¤§å°é€šå¸¸åœ¨ 10K-100K çš„ subword unitsã€‚\nåœ¨ \u0026ldquo;Language Models are Unsupervised Multitask Learners\u0026rdquo; æ–‡ä¸­ï¼Œæåˆ°äº†ä¸€ç¨®å·§å¦™çš„ BPE å¯¦ç¾ï¼Œä¸æ˜¯ç”¨ unicode charactersï¼Œè€Œæ˜¯ç”¨ bytes ä½œç‚º base subword unitsã€‚å¯ä»¥ç”Ÿå‡º 50K å¤§å°çš„è©å½™è¡¨ï¼Œè€Œä¸”ä¸ç”¨å¼•å…¥ä»»ä½•çš„ \u0026ldquo;unknown\u0026rdquo;ã€‚\nåŸå§‹çš„ BERT ç”¨ character-level BPE vocabularyï¼Œå¤§å°ç‚º 30Kã€‚\næœ¬æ–‡è€ƒæ…®ç”¨ 50K byte-level BPE vocabularyï¼Œè€Œä¸å°è¼¸å…¥åšé¡å¤–çš„ preprocessing æˆ– tokenizationï¼Œ\u0026ldquo;Language Models are Unsupervised Multitask Learners\u0026rdquo; çš„ç ”ç©¶é¡¯ç¤ºé€™äº› Encoding çš„æ–¹æ³•åœ¨æœ€çµ‚æ•ˆèƒ½ä¸Šä¸¦ç„¡å¤ªå¤§å·®åˆ¥ï¼Œåªåœ¨æŸäº›ä»»å‹™ä¸Š end-task performance è¡¨ç¾ç¨å·®ã€‚\nä½†ä½œè€…ç›¸ä¿¡ universal encoding scheme çš„å„ªå‹¢è¶…éäº†è¼•å¾®çš„æ€§èƒ½ä¸‹é™ï¼Œå…¶ä»–å¯¦é©—ä¹Ÿæœƒç”¨é€™ç¨®é‚Šç¢¼æ–¹å¼ã€‚\nRoBERTa æ•´ç†ä¸Šé¢èªªçš„æ”¹é€²ã€‚\nRoBERTa ç”¨ä»¥ä¸‹é…ç½®:\ndynamic masking FULL-SENTENCES without NSP loss large mini-batches larger byte-level BPE æ­¤å¤–ï¼Œé‚„èª¿æŸ¥äº†å…©å€‹ä¹‹å‰çš„å·¥ä½œæ²’å¼·èª¿çš„é‡è¦å› ç´ :\nç”¨æ–¼é è¨“ç·´çš„ data è¨“ç·´é data çš„æ¬¡æ•¸ ç‚ºäº†æŠŠé€™äº›å› ç´ çš„é‡è¦æ€§å’Œå…¶ä»–æ¨¡å‹é¸æ“‡åˆ†éš”é–‹ï¼Œå…ˆæŒ‰ç…§ $BERT_{LARGE}$ (L = 24, H = 1024, A = 16, 355M parameters) è¨“ç·´ RoBERTaã€‚\nä½œè€…åœ¨ BOOKCORPUS plus WIKIPEDIA dataset é€²è¡Œäº† 100K step çš„é è¨“ç·´ã€‚\nåœ¨æ§åˆ¶ training data çš„æƒ…æ³ä¸‹ï¼Œ RoBERTa æ¯” $BERT_{LARGE}$ çš„çµæœæœ‰å¤§å¹…åº¦çš„æ”¹é€²ï¼Œé‡ç”³äº†å‰é¢è¨­è¨ˆé¸æ“‡çš„é‡è¦æ€§ã€‚\næ¥ä¸‹ä¾†ï¼Œçµåˆä¹‹å‰èªªçš„é¡å¤– datasetï¼Œä¸¦ç”¨ç›¸åŒçš„æ­¥æ•¸(100K) è¨“ç·´ RoBERTaï¼Œè§€å¯Ÿåˆ°ä¸‹æ¸¸ä»»å‹™çš„æ€§èƒ½é€²ä¸€æ­¥æé«˜ï¼Œé©—è­‰äº†æ•¸æ“šå¤§å°å’Œå¤šæ¨£æ€§çš„é‡è¦æ€§ã€‚\næœ€å¾Œï¼Œå° RoBERTa åšæ›´é•·æ™‚é–“çš„é è¨“ç·´ï¼Œå°‡æ­¥æ•¸æé«˜åˆ° 300K å’Œ 500Kï¼Œå†æ¬¡è§€å¯Ÿåˆ°ä¸‹æ¸¸ä»»å‹™æ€§èƒ½é¡¯è‘—æå‡ã€‚\nä½œè€…ä¹Ÿæ³¨æ„åˆ°ï¼Œå³ä½¿æ˜¯ä»–å€‘è¨“ç·´æ™‚é–“æœ€é•·çš„æ¨¡å‹ï¼Œä¹Ÿä¸æœƒ overfit ä»–å€‘çš„æ•¸æ“šã€‚\næœ¬æ–‡çš„å…¶ä»–éƒ¨åˆ†åœ¨ä¸‰å€‹ benchmark è©•ä¼°å¥½å£: GLUEã€SQuaD å’Œ RACE\nGLUE Results é›–ç„¶å¾ˆå¤š GLUE æ’è¡Œæ¦œçš„æäº¤éƒ½æ˜¯ depend on multi-task finetuningï¼Œä½†ä½œè€…çš„ submission æ˜¯ depends only on single-task finetuningã€‚\næ­¤å¤–ï¼Œå°æ–¼ RTEã€STS å’Œ MRPCï¼Œå¾ MNLI çš„æ¨¡å‹å¾®èª¿æœƒæ¯” baseline çš„ RoBERTa æœ‰å¹«åŠ©è¨±å¤šã€‚\nåœ¨ç¬¬ä¸€å€‹è¨­ç½® (single-task, dev) ä¸­ï¼ŒRoBERTa åœ¨æ‰€æœ‰ 9 å€‹ GLUE ä»»å‹™ dev set ä¸Šéƒ½å–å¾—äº†æœ€å…ˆé€²çš„çµæœã€‚\nåœ¨ç¬¬äºŒå€‹è¨­ç½® (ensembles, test) ä¸­ï¼Œä½œè€…å°‡ RoBERTa æäº¤åˆ° GLUE æ’è¡Œæ¦œï¼Œä¸¦åœ¨ 9 å€‹ä»»å‹™ä¸­çš„ 4 å€‹ä¸Šå–å¾—äº† SOTA å’Œè¿„ä»Šç‚ºæ­¢çš„æœ€é«˜å¹³å‡åˆ†ã€‚\né€™ä»¤äººèˆˆå¥®çš„åœ°æ–¹åœ¨æ–¼ï¼Œèˆ‡å¤šæ•¸ top submissions ä¸åŒï¼ŒRoBERTa ä¸æ˜¯ depend on multi-tasking finetuning\nConclusion åœ¨é è¨“ç·´ BERT æ¨¡å‹æ™‚ï¼Œä½œè€…ä»”ç´°è©•ä¼°äº†è¨±å¤šè¨­è¨ˆæ±ºç­–ã€‚\nä½œè€…ç™¼ç¾ï¼Œé€šéå°æ¨¡å‹é€²è¡Œæ›´é•·æ™‚é–“çš„è¨“ç·´ã€ä½¿ç”¨æ›´å¤§çš„æ‰¹æ¬¡è™•ç†æ›´å¤šçš„æ•¸æ“šã€å»é™¤ NSPã€è¨“ç·´æ›´é•·çš„åºåˆ—ã€dynamic maskingï¼Œå¯ä»¥é¡¯è‘—æé«˜æ€§èƒ½ã€‚\nä½œè€…æ”¹é€²çš„é è¨“ç·´ç¨‹åºï¼Œæˆ‘å€‘ç¨±ä¹‹ç‚º RoBERTaï¼Œåœ¨ GLUEã€RACE å’Œ SQuAD ä¸Šå¯¦ç¾äº† SOTAï¼Œè€Œç„¡éœ€ç‚º GLUE é€²è¡Œå¤šä»»å‹™å¾®èª¿æˆ–ç‚º SQuAD æä¾›é¡å¤–çš„æ•¸æ“šã€‚\né€™äº›çµæœèªªæ˜äº†é€™äº›ä»¥å‰è¢«å¿½è¦–çš„è¨­è¨ˆæ±ºç­–çš„é‡è¦æ€§ï¼Œä¸¦è¡¨æ˜ BERT çš„é è¨“ç·´ç›®æ¨™èˆ‡æœ€è¿‘æå‡ºçš„æ›¿ä»£æ–¹æ¡ˆç›¸æ¯”ä»ç„¶å…·æœ‰ç«¶çˆ­åŠ›ã€‚\n","date":"2023-03-22T01:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/roberta-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"RoBERTa è«–æ–‡é–±è®€"},{"content":"é–‹ç™¼ç’°å¢ƒ IDE SW4STM32 æ”¯æ´ STM32 GCC C/C++ compiler GDB-based debugger æ¿å­ STM32 Bucleo Board Cortex-M4 ST-LINK debugger Memories 1MB Flash 128KB SRAM Debug Interface JTAG Joint Test Action Group standard ASICs hardware debug interface SWD Serial Wire Debug åªå¾ JTAG ç”¨ 5 wires Bootup Code Reset\nBoot Loader\n0x00000000 çš„ç¨‹å¼ æŠŠ CPU é‡ç½® Reset handler\nStstem initialization C startup code\nApplication(main)\nMemory map è¦‹å®˜ç¶² memory map\nåªç”¨åˆ° SRAM çš„ 128KB(SRAM)ï¼Œé‚„æœ‰ Code çš„ 1MB(Flash)\nSections .data å„²å­˜è³‡æ–™ .text å„²å­˜ç¨‹å¼ç¢¼ åŒ section æœƒæ”¾åœ¨ä¸€å¡Šæ˜¯ç‚ºäº†è¨­å®š read-only æ–¹ä¾¿ï¼Œæ¯”å¦‚ .text çš„è¦é ç¡¬é«”å¯¦ç¾ read-only\né‡è¦çš„é¡å¤–æ–‡ä»¶ Linker Script å®šç¾©äº†ä¸åŒ section è©²å­˜æ”¾çš„åœ°æ–¹ï¼Œä»¥åŠ memory ç›¸é—œå®šç¾© 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 MEMORY { RAM (xrw)\t: ORIGIN = 0x20000000, LENGTH = 96K ROM (rx)\t: ORIGIN = 0x8000000, LENGTH = 1024K } SECTIONS { /* The program code and other data into ROM memory */ .text : { . = ALIGN(8); *(.text) /* .text sections (code) */ *(.text*) /* .text* sections (code) */ *(.glue_7) /* glue arm to thumb code */ *(.glue_7t) /* glue thumb to arm code */ *(.eh_frame) KEEP (*(.init)) KEEP (*(.fini)) . = ALIGN(8); _etext = .; /* define a global symbols at end of code */ } \u0026gt;ROM .data : { . = ALIGN(8); _sdata = .; /* create a global symbol at data start */ *(.data) /* .data sections */ *(.data*) /* .data* sections */ . = ALIGN(8); _edata = .; /* define a global symbol at data end */ } \u0026gt;RAM AT\u0026gt; ROM } Make File æè¿°å¦‚ä½•ç·¨è­¯å’Œé€£æ¥çš„è¦å‰‡ æŠŠ startup çš„ .sæª”åŠ é€²å» startup_stm32.s ç·¨è­¯å¥½å¾Œæ“ºåœ¨ binary é ­çš„åœ°æ–¹\nvector table\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 /****************************************************************************** * * The STM32L476RGTx vector table. Note that the proper constructs * must be placed on this to ensure that it ends up at physical address * 0x0000.0000. * ******************************************************************************/ .section .isr_vector,\u0026#34;a\u0026#34;,%progbits .type g_pfnVectors, %object .size g_pfnVectors, .-g_pfnVectors g_pfnVectors: .word _estack .word Reset_Handler .word NMI_Handler .word HardFault_Handler .word\tMemManage_Handler .word\tBusFault_Handler .word\tUsageFault_Handler .word\t0 .word\t0 .word\t0 .word\t0 .word\tSVC_Handler Reset_Handler 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 Reset_Handler: ldr r0, =_estack mov sp, r0 /* set stack pointer */ /* Copy the data segment initializers from flash to SRAM */ ldr r0, =_sdata ldr r1, =_edata ldr r2, =_sidata movs r3, #0 b LoopCopyDataInit LoopCopyDataInit: adds r4, r0, r3 cmp r4, r1 bcc CopyDataInit /* Zero fill the bss segment. */ ldr r2, =_sbss ldr r4, =_ebss movs r3, #0 b LoopFillZerobss LoopFillZerobss: cmp r2, r4 bcc FillZerobss /* Call the clock system intitialization function.*/ bl SystemInit /* Call static constructors */ bl __libc_init_array /* Call the application\u0026#39;s entry point.*/ bl main ARM Register ARM çš„å¯å­˜å–æš«å­˜å™¨ç‚º R0-R15\nr13: Stack Pointer r14: Link Register r15: Program Counter r0~r7 æ˜¯ low register r8~r15 æ˜¯ high register ç‹€æ…‹æš«å­˜å™¨\nCPSR (Current Processor Status Register) ç”¨ä¾†å„²å­˜å„ç¨®ç‹€æ…‹ï¼ŒåŒ…å« condition flagï¼Œæ¯”å¦‚ negative, zero, carry, overflow carry: ç„¡ç¬¦è™ŸåŠ æ³•æ“ä½œæ˜¯å¦æº¢å‡º overflow: æœ‰ç¬¦è™ŸåŠ æ³•æ“ä½œæ˜¯å¦æº¢å‡º ç•¶å…©å€‹éƒ½ç‚º 1 æˆ–éƒ½ç‚º 0 ä»£è¡¨é‹ç®—æ²’å•é¡Œ æœ‰å¤šç¨®æ¨¡å¼ï¼Œæœ‰äº›æ¨¡å¼æœ‰è‡ªå·±ç¨ç«‹çš„ r æš«å­˜å™¨ï¼Œä¸¦æœ‰ SPSRï¼Œç”¨ä¾†åœ¨ä¸­æ–·ç™¼ç”Ÿæ™‚ï¼ŒæŠŠ CPSR çš„è³‡è¨Š copy éå»\nSpecial-purpose registers\nAPSR, IPSR, EPSR Assembly syntax UAL: Unified Assembler Language è‡ªå·±å»ç¿» instruction set Instructions class Branch instructions B, BL, BX,\u0026hellip; Data-processing instructions MOV, ADD, SUB, MUL,\u0026hellip; Load and store instructions LDR, STR,\u0026hellip; Status register access instructions MSR, MRS,\u0026hellip; Miscellaneous instructions Memory Barrier instructions Exception-Related instructions Pseudo instructions examples MOVS R0, #0x12\nR0=0x12 MOVS R1, #`A` R1=A(ASCII) NVIC_IRQ_SETEN EQU 0xE000E100\nå®£å‘Šå¸¸æ•¸ NVIC_IRQ_SETENï¼Œè³¦å€¼ 0xE000E100 LDR R0,=NVIC_IRQ_SETEN\næ”¾ 0xE000E100 é€² R0 é€™ä¸èƒ½æ”¹æˆ MOVS R0, #0xE000E100 ï¼Œå› ç‚ºæ¯å€‹ instruction åªæœ‰ 32 å€‹ bitsï¼Œé€™å‹¢å¿…å¡ä¸ä¸‹ï¼Œå¿…é ˆå¾è¨˜æ†¶é«” load é€²ä¾† NVIC_IRQ0_ENABLE EQU 0x1\nå®£å‘Šå¸¸æ•¸ NVIC_IRQ0_ENABLEï¼Œè³¦å€¼ 0x1 MOVS R1, #NVIC_IRQ0_ENABLE\nR1=0x1 STR R1, [R0]\næŠŠ 0x1 å­˜åˆ° 0xE000E100ï¼Œé€™è£¡å¯ä»¥ enable external interrupt IRQ#0 LDR rn [pc, #offset to literal pool]\nload register n with one word from the address [pc + offset] æœ€å¾Œçš„å½¢å¼ Operand2 å…±æœ‰ 12 bits è¨­è¨ˆæˆ 4 bits for rotate, 8 bits for Immediate ARM instrcution formats ADD vs ADDS æœ‰ S ä»£è¡¨æœƒå»æ›´æ–° status cond æ ¹æ“šä¹‹å‰çš„åŸ·è¡Œæƒ…æ³ï¼Œåˆ¤æ–·æŒ‡ä»¤è¦ä¸è¦åŸ·è¡Œ suffix Reverse Ordering Operations REV (Byte-Reverse Word) æŠŠ 4 å€‹ Byte å…¨æ•¸åè½‰ï¼Œç”¨åœ¨ä¸€å€‹æ˜¯ Little-Endian ä¸€å€‹æ˜¯ Big-Endian çš„æƒ…æ³ Load and Store Instructions examples LDR r0, [r1] r0 = [r1] LDM r0, {r1, r2} r1 = [r0] r2 = [r0+4] STM r0, {r1, r2} [r0] = r1 [r0+4] = r2 Status Register Access Instructions ä¸€èˆ¬ä¾†èªªä¸å¤ªæœƒç”¨åˆ°ï¼Œå› ç‚ºç”¨ suffix å°±å¯ä»¥çœ‹æ¢ä»¶ MRS: Register = Status Register MRS r0, IPSR MSR: Status Register = Register MSR APSR, r0 If-Then-Else ç”¨ CMP å’Œ conditional branches Example 1 2 CMP R0, #10 ;compare r0 to 10 BLE incr_counter ; if less or equal, then branch to incr_counter Branch Instructinos èƒ½è·³çš„è·é›¢å—é™æ–¼ operand é•·åº¦\nB-Branch èƒ½è·³ PC çš„ +/- 2046 bytes BL-Branch and Link èƒ½è·³ PC çš„ +/- 254 bytes Branch to subroutine çš„æ™‚å€™ï¼ŒæœƒæŠŠä¸‹ä¸€è¡ŒæŒ‡ä»¤æ”¾åˆ° Link register æ²’æœ‰ push åˆ° stackï¼Œæ‰€ä»¥è¦ç‰¹åˆ¥å°å¿ƒï¼Œregister æ˜¯å…±ç”¨çš„ï¼Œ å¯èƒ½è¦è¦–æƒ…æ³è‡ªå·±æ”¾åˆ° stack æ¯”å¦‚è¦é€²å…©å±¤ functionï¼Œå¯ä»¥ç”¨ push {r4-r6, LR} å’Œ POP {R4-R6, PC} é€™ç¨®åšæ³•ä¾†ä¿ç•™åƒæ•¸ BX-Branch and exchange return Stack memory access PUSH\nSP = SP - N*4 POP\nSP = SP + N*4 Ascending/Descending\nstack å¾€å“ªå€‹æ–¹å‘é•· Empty/Full\nstack æŒ‡å‘ä¸‹ä¸€å€‹ç©ºçš„ä½ç½®ï¼Œé‚„æ˜¯æœ€å¾Œä¸€å€‹ item é è¨­ä¸”å¸¸è¦‹çš„æ˜¯ fully descending\nSTM å’Œ LDM å¯ä»¥é€é suffix ä¾†å­˜åˆ° stack\nexample STMFD r13!, {r4-r7} æŠŠ r4 åˆ° r7 push åˆ° stack Memory Barrier Instructions DMB, SDB, ISB åœ¨ä¸‹å€‹æŒ‡ä»¤å‰ sync memory data Function Call and Parameter Passing caller å’Œ callee èª°è² è²¬ backup å’Œ restore caller è² è²¬ ä¸ç®¡ callee æ€æ¨£äº‚æéƒ½è¡Œ ä½†ä¸çŸ¥é“ callee è¦ç”¨å“ªäº›åƒæ•¸ï¼Œå…¨ backup å¯èƒ½å¤šæ­¤ä¸€èˆ‰ æ€éº¼å‚³éåƒæ•¸çµ¦ callee å¸¸æ”¾åœ¨ stackï¼Œä½†é€™æ¨£è¦é€é memoryï¼Œç›¸è¼ƒ register æ…¢ æ€éº¼ return value çµ¦ caller å’Œä¸Šå€‹å•é¡Œå·®ä¸å¤š ARM Procedure Call Standard åˆç¨± APCSï¼Œè¬›ä¸åŒçš„ register çš„ä¸€ç¨®ä½¿ç”¨è¦ç¯„\nr0-r3 ç”¨ä¾†ç•¶åƒæ•¸å’Œå›å‚³ r4-r11 ç”¨ä¾† local variableï¼Œcallee ä½¿ç”¨å‰å¯ä»¥å…ˆ backup r12-r15 ç‰¹æ®Šç”¨é€”ï¼Œæ²’äº‹åˆ¥äº‚å‹• ","date":"2023-03-21T01:32:54+08:00","permalink":"https://roykesydon.github.io/Blog/p/arm-%E7%B5%84%E5%90%88%E8%AA%9E%E8%A8%80%E4%BB%8B%E7%B4%B9/","title":"ARM çµ„åˆèªè¨€ä»‹ç´¹"},{"content":"paper: PatentSBERTa: A Deep NLP based Hybrid Model for Patent Distance and Classification using Augmented SBERT\nAbstract æœ¬ç ”ç©¶æä¾›äº†ä¸€å€‹è¨ˆç®— patent-to-patent (p2p) technological similarity çš„æœ‰æ•ˆæ–¹æ³•ã€‚\nä¸¦æå‡ºä¸€å€‹ hybrid frameworkï¼Œç”¨æ–¼æŠŠ p2p ç›¸ä¼¼æ€§çš„çµæœæ‡‰ç”¨æ–¼ semantic search å’Œ automated patent classificationã€‚\næŠŠ Sentence-BERT (SBERT) ç”¨åœ¨ claims ä¸Šä¾†ä½œ embeddingsã€‚\nç‚ºäº†é€²ä¸€æ­¥æå‡ embedding çš„å“è³ªï¼Œä½¿ç”¨åŸºæ–¼ SBERT å’Œ RoBERT çš„ transformer modelï¼Œç„¶å¾Œå†ç”¨ augmented approach åœ¨ in-domain supervised patent claims data(ç›¸å°æ–¼ out-domain) ä¾† fine-tune SBERTã€‚\nç”¨ KNN(Nearest Neighbors) ä¾†æ ¹æ“š p2p similarity åˆ†é¡æ¨¡å‹ã€‚\nIntroduction å‚³çµ±ä¸Šçš„ p2p ç›¸ä¼¼åº¦æ˜¯åŸºæ–¼é—œéµå­—ã€æŠ€è¡“é¡åˆ¥ç­‰ metadata æ±ºå®šçš„ï¼Œä½†è¿‘æœŸ semantic-based çš„æ–¹æ³•ä¹Ÿè¶Šä¾†è¶Šå—æ­¡è¿ã€‚\nç›®å‰é‡åˆ°çš„å•é¡Œ BERT ç”¨ä¾†è¨ˆç®— p2p ç›¸ä¼¼æ€§çš„æˆæœ¬å¾ˆé«˜ åŸºæ–¼ generic text çš„ pre-trained model åœ¨é‡åˆ°ç‰¹å®šé ˜åŸŸçš„å°ˆæ¥­è¡“èªæ™‚å¯èƒ½æœƒé‡åˆ°ä¾·é™ã€‚ åœ¨å°ˆåˆ©åš multi-label classification (MLC) æ˜¯å€‹æŒ‘æˆ° è²¢ç» æä¾›ä¸€å€‹å¿«é€Ÿé«˜æ•ˆçš„æ¡†æ¶ï¼Œåˆ©ç”¨ Transformer æ¶æ§‹è¨ˆç®— p2p ç›¸ä¼¼åº¦ é€é augmented SBERTï¼Œå°‡ transformer model fine-tune åˆ° domain-specific language æå‡ºä¸€å€‹åŸºæ–¼ Transformer å’Œ å‚³çµ± ML æ¨¡å‹çš„æ··å’Œæ¶æ§‹ï¼Œå¯ä»¥æ‰“æ•— multi-label å’Œ multi-class çš„å°ˆåˆ©åˆ†é¡ SOTA æ¨¡å‹ ç”¨ç°¡å–®çš„ KNN é€²è¡Œå°ˆåˆ©åˆ†é¡ï¼Œæä¾›äº†ä¸€ç¨®ç°¡å–®çš„æ–¹æ³•ä¾†æª¢æŸ¥ã€ç†è§£å’Œè§£é‡‹æ¨¡å‹çš„é æ¸¬çµæœ Data Dataset Description æœ¬ç ”ç©¶ä½¿ç”¨ PatentsView datasetï¼ŒPatentsView å¹³å°å»ºç«‹åœ¨ä¸€å€‹å®šæœŸæ›´æ–°çš„ database ä¸Šã€‚\ndataset å·²ç”¨æ–¼ä¹‹å‰é¡ä¼¼çš„ç ”ç©¶ï¼Œæ¯”å¦‚ DeepPatentã€PatentBERTã€‚\næœ¬ç ”ç©¶ä½¿ç”¨äº† 2013-2017 çš„æ‰€æœ‰å°ˆåˆ©ï¼Œé€™äº›å°ˆåˆ©è‡³å°‘è¦åœ¨ BigQuery ä¸Šæœ‰ä¸€æ¢ claimã€‚\næœ¬ç ”ç©¶çš„ record æœ‰ 1,492,294 é …å°ˆåˆ©ï¼Œä¸¦ç”¨ 8% ä½œç‚ºæ¸¬è©¦é›†ã€‚\næ­¤å¤–ï¼Œæœ¬ç ”ç©¶åˆªé™¤äº†æœ‰é‡è¤‡å°ˆåˆ© ID å’Œ claim text çš„ recordã€‚\nTextual Data: Patent Claims æœ¬ç ”ç©¶ä½¿ç”¨ claim ä½œç‚ºè¼¸å…¥ã€‚\nclaim è¢«èªç‚ºæ˜¯æº–å‚™å°ˆåˆ©æ–‡ä»¶çš„åˆå§‹æ¡†æ¶ï¼Œå…¶ä»–æ–‡ä»¶éƒ½æ˜¯æ ¹æ“š claim æº–å‚™çš„ï¼Œ å› æ­¤ï¼Œclaim æ¯”å…¶ä»–æ–‡ä»¶åŒ…å«æ›´å…¨é¢å’Œæº–ç¢ºçš„è¨Šæ¯ã€‚\nclaim å…·æœ‰å±¤æ¬¡çµæ§‹ï¼Œfirst claim è¢«è¦–ç‚ºè©²æ¶æ§‹çš„ä¸»å¹¹ã€‚\næœ¬ç ”ç©¶åƒ…ä½¿ç”¨ first claimï¼Œä½†åœ¨ä»¥å¾Œçš„ç ”ç©¶ä¸­ï¼Œå¸Œæœ›æ ¹æ“š tree structure çµ„åˆæ‰€æœ‰ claimï¼Œä¸¦è¨ˆç®— semantic similarityï¼Œä¸¦åšå¤šæ¨™ç±¤åˆ†é¡ã€‚\nåœ¨ç ”ç©¶æ¨£æœ¬ä¸­ï¼Œ claim å¹³å‡æœ‰ 17 å€‹ã€‚\nclaim çš„å¹³å‡é•·åº¦æ˜¯ 162ï¼Œæœ¬ç ”ç©¶ä¸­ï¼ŒBERT çš„ max_seq_length æ˜¯ 510ã€‚\nPatent Classification: CPC Classes CPCç³»çµ±å’ŒIPCï¼ˆåœ‹éš›å°ˆåˆ©åˆ†é¡ï¼‰ç³»çµ±æ˜¯æœ€å¸¸ç”¨çš„å…©ç¨®åˆ†é¡ç³»çµ±ï¼ŒCPC æ˜¯ IPC ç³»çµ±çš„æ›´å…·é«”å’Œè©³ç´°çš„ç‰ˆæœ¬ã€‚\nCPC å…·æœ‰ç”¨æ–¼åˆ†é¡çš„å±¤æ¬¡çµæ§‹ï¼ŒåŒ…æ‹¬ Sectionã€Classã€Subclass å’Œ Groupï¼Œ åœ¨å­é¡ç´šåˆ¥ï¼ŒCPC æœ‰ 667 å€‹æ¨™ç±¤ã€‚\nåœ¨æ•¸æ“šé›†ä¸­æˆ‘å€‘æœ‰ 663 å€‹æ¨™ç±¤ï¼Œå…¶ä¸­ 159 å€‹åœ¨æ•¸æ“šé›†ä¸­çš„æ¨£æœ¬å°‘æ–¼ 350 å€‹ï¼Œé€™ç¨®æ¨™ç±¤åˆ†ä½ˆå°è‡´äº† KNN ä¸å¥½è™•ç†ï¼Œä¸€èˆ¬ä¾†èªªï¼Œéš¨è‘— instance æ•¸é‡çš„å¢åŠ ï¼Œæˆ‘å€‘å¯ä»¥æé«˜æ¨¡å‹çš„æº–ç¢ºæ€§ã€‚\nMethod and experimental setup Pretrained Language Models (LMs) åœ¨ NLP ä¸­è®Šå¾—ååˆ†æµè¡Œã€‚\nåœ¨ pairwise sentence semantic similarityï¼ŒSBERT å’Œ BERT æ˜¯å…©ç¨®å…·æœ‰é¡¯è‘—ä¸åŒæ•ˆæœçš„æ–¹æ³•ã€‚\nBERT é€šå¸¸å¯ä»¥å–å¾—æ›´å¥½çš„æ€§èƒ½ï¼Œä½†åœ¨å¯¦éš›æ‡‰ç”¨ä¸Šä¾†èªªå¤ªæ…¢äº†ã€‚\nSBERT åœ¨å¯¦éš›æ‡‰ç”¨ä¸Šè¡¨ç¾é‚„è¡Œï¼Œä½†éœ€è¦ in-domain training data ä¸¦ä¸” finetuneã€‚\nä¸Šåœ–æ˜¯ Augmented SBERT In-domain approachã€‚\nin-domain sentence pairs é€é cross-encoder ä¾†æ¨™è¨˜ï¼Œå‡è¨­æœ‰ n å€‹ in-domain sentencesï¼Œæœƒæœ‰ $C_2^n$ çµ„å¯èƒ½çš„çµ„åˆã€‚\nä½¿ç”¨æ‰€æœ‰å¯èƒ½çš„çµ„åˆä¸¦ä¸æœƒæé«˜æ€§èƒ½ï¼Œæ‰€ä»¥è¦æœ‰æ­£ç¢ºçš„æ¡æ¨£ç­–ç•¥ï¼Œæ‰å¯æå‡æ€§èƒ½çš„åŒæ™‚ä¹Ÿæ¸›å°‘è¨ˆç®—é–‹éŠ·ã€‚\nä¸Šåœ–é‚£ç¨®çµåˆ cross-encoder å’Œ bi-encoder çš„ä½œæ³•è¢«ç¨±ç‚º Augmented SBERT (AugSBERT)ï¼Œ æ¶‰åŠä»¥ä¸‹ä¸‰å€‹æ­¥é©Ÿ:\nç”¨è³‡æ–™é›† Fine-tune RoBERTa ä»¥ç”Ÿå‡º cross-encoder ç”¨ cross-encoder ä¾†æŠŠæœªæ¨™è¨˜çš„è³‡æ–™æ¨™è¨˜ï¼ŒåŒæ™‚åŸºæ–¼æŸç¨®ç‰¹å®šçš„æ¡æ¨£ç­–ç•¥ï¼Œå¾ 652,653 ç¨®å¯èƒ½çš„çµ„åˆä¸­æŒ‘é¸ 3432 çµ„ æŠŠè³‡æ–™é›† + é¡å¤–çš„ 3432 çµ„è³‡æ–™ä¸€èµ·æ‹¿ä¾†è¨“ç·´ SBERT Results P2P similarity and semantic search Patent Semantic Search (PSS) æ˜¯å°ˆåˆ©åˆ†æçš„åŸºç¤éƒ¨åˆ†ã€‚\nTransformer æ¨¡å‹ç­‰èªç¾©ç›¸ä¼¼æ€§çš„è§£æ³•æ˜¯ä¸€ç¨®æ–°è§£æ³•ï¼Œå¯ä»¥ç”¨ä¾†è§£æ±ºåŸºæ–¼é—œéµå­—çš„æœå°‹æ–¹æ³•ä¸­ï¼Œ query terms å’Œå°ˆåˆ©å…§å®¹ä¸åŒ¹é…çš„å•é¡Œã€‚\nç‚ºäº†è©•ä¼°æ¨¡å‹çš„æº–ç¢ºæ€§ï¼Œæœªä¾†çš„ç ”ç©¶ä¸­ï¼Œä½œè€…å¸Œæœ›é€šé Mean Reciprocal Rank (MRR) ä¾†è©•ä¼°åˆ†é¡çµæœã€‚\nCPC Prediction Top-N æº–ç¢ºåº¦ç­‰æ–¼ GT èˆ‡é æ¸¬æœ‰æœ€é«˜æ¦‚ç‡çš„ä»»ä½• N å€‹é æ¸¬åŒ¹é…çš„é »ç‡ï¼Œ æ‰€ä»¥ Top-5 å°±æ˜¯æœ€é«˜çš„äº”å€‹åˆ†é¡ä¸­ä¸€å€‹å°±æœ‰ä¸­ã€‚\nConclusion æœ¬æ–‡ä½¿ç”¨ augmented SBERT ç²å¾— SOTA çš„å°ˆåˆ©æ–‡æœ¬ embeddingã€‚\nä»‹ç´¹äº†ä¸€ç¨® augmented çš„æ–¹æ³•ï¼ŒæŠŠ SBERT å¾®èª¿åˆ°é©åˆ patent claims çš„ domainã€‚\nSBERT çš„ä¸€å€‹ä¸»è¦å„ªé»æ˜¯å¯ä»¥æœ‰æ•ˆç‡åœ°ç²å¾— embedding distanceï¼Œä½¿æˆ‘å€‘èƒ½å¤ ç‚ºå¤§çš„å°ˆåˆ©è³‡æ–™é›†å»ºæ§‹ p2p similarityã€‚\né›–ç„¶åŸºæ–¼æ–‡æœ¬çš„ p2p similarity çš„æœ‰ç”¨æ€§å·²ç¶“åœ¨å„ç¨®æ‡‰ç”¨æ–¹é¢å¾—åˆ°è­‰æ˜ï¼Œä½†æœ¬æ–‡é€²ä¸€æ­¥è­‰æ˜ä½œè€…çš„ transformer-based p2p similarity å¯ä»¥è¢«ç”¨åœ¨ SOTA çš„å°ˆåˆ©åˆ†é¡ã€‚\nè€Œä¸”ä½¿ç”¨ç°¡å–®çš„ KNN æ–¹æ³•ï¼Œæª¢æŸ¥ä»–å€‘å¯ä»¥ä½¿æ¨¡å‹æ±ºç­–å…·å‚™ understandable å’Œ explainableã€‚\nLimitations \u0026amp; Future Research æœªä¾†å¸Œæœ›ç”¨ Annoy(Approximate Nearest Neighbor Oh Yeah!) ä¾†æ¸¬è©¦æ›´å¤§æ¨£æœ¬çš„æ¨¡å‹ä¸¦æ¯”è¼ƒçµæœã€‚\nAnnoy(Approximate Nearest Neighbor Oh Yeah!) æ˜¯æƒ³å°‹æ‰¾è¿‘ä¼¼ç›¸ä¼¼è€Œä¸æ˜¯ç²¾ç¢ºç›¸ä¼¼çš„å¥å­ã€‚\n","date":"2023-03-15T15:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/patentsberta-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"PatentSBERTa è«–æ–‡é–±è®€"},{"content":"Introduction çµåˆ policy-based å’Œ value-based\nA3C Actor-Critic æœ€çŸ¥åçš„æ–¹æ³• Advantage Actor-Critic æ˜¯ A2C Advantage Actor-Critic Review: Policy gradient\n$\\triangledown \\overline{R_{\\theta}}\\approx \\frac{1}{N}\\displaystyle\\sum_{n=1}^{N}\\displaystyle\\sum_{t=1}^{T_n}(\\displaystyle\\sum_{t^{\u0026rsquo;}=t}^{T_n}\\gamma^{t^{\u0026rsquo;}-t}r_{t^{\u0026rsquo;}}^n-b)\\triangledown log p_{\\theta}(a_t^n|s_t^n)$ $G_t^n=\\displaystyle\\sum_{t^{\u0026rsquo;}=t}^{T_n}\\gamma^{t^{\u0026rsquo;}-t}r_{t^{\u0026rsquo;}}^n-b$ G very unstableï¼Œå› ç‚ºçµ¦åŒæ¨£çš„ state ä½œåŒæ¨£çš„ action ä¸ä¸€å®šæœƒå¾—åˆ°åŒæ¨£çš„çµæœï¼ŒG æ˜¯å€‹ random variable æƒ³è¦æ”¹ç²å¾—æœŸæœ›å€¼ï¼Œå–ä»£æ‰ sample çš„å€¼(G çš„éƒ¨åˆ†)ï¼Œå¯ä»¥ç”¨ Q-Learning\n$E[G_t^n]=Q^{\\pi_\\theta}(s_t^n,a_t^n)$ Q function é€™æ¨£å®šç¾© æ‰€ä»¥æˆ‘å€‘å¯ä»¥æŠŠ G çš„éƒ¨åˆ†æ”¹ç”¨ Q æ›¿æ›æ‰ï¼Œå°±å¯ä»¥æŠŠ Actor å’Œ Critic çµåˆèµ·ä¾† baseline çš„éƒ¨åˆ†ä¹Ÿå¯ä»¥ç”¨ value function æ›¿æ›æ‰ ä½†ç”¨ $Q^{\\pi}(s_t^n,a_t^n)-V^{\\pi}(s_t^n)$ è¦ä¸€æ¬¡ estimate å…©å€‹ network\nå¯ä»¥æŠŠ Q ä»¥ V ä¾†è¡¨ç¤ºï¼Œé‚£åªéœ€è¦ä¼°æ¸¬ V $Q^{\\pi}(s_t^n,a_t^n)=E[r_t^n+V^{\\pi}(s_{t+1}^n)]$ é›–ç„¶æœ‰éš¨æ©Ÿæ€§(ç²å¾—çš„ reward å’Œè·³åˆ°ä»€éº¼ state ä¸ä¸€å®š)ï¼Œä½†å…ˆä¸ç®¡æœŸæœ›å€¼ $Q^{\\pi}(s_t^n,a_t^n)=r_t^n+V^{\\pi}(s_{t+1}^n)$ ç¾åœ¨é›–ç„¶å¤šå€‹ä¸€å€‹ rï¼Œæœ‰ä¸€äº› varianceï¼Œä½†ä¹Ÿæ¯” G å¥½ $\\triangledown \\overline{R_{\\theta}}\\approx \\frac{1}{N}\\displaystyle\\sum_{n=1}^{N}\\displaystyle\\sum_{t=1}^{T_n}(r_t^n+V^{\\pi}(s_{t+1}^n)-V^{\\pi}(s_t^n))\\triangledown log p_{\\theta}(a_t^n|s_t^n)$\nTips actor $\\pi(s)$ å’Œ critic $V^{\\pi}(s)$ çš„æ¬Šé‡å¯ä»¥å…±äº«\nå‰é¢å¹¾å€‹ layer å¯ä»¥ share å° $\\pi$ çš„ output ä¸‹ constrainï¼Œè®“ä»–çš„ entropy ä¸è¦å¤ªå°ï¼Œé”åˆ° exploration çš„æ•ˆæœ\nAsynchronous Advantage Actor-Critic ä¸€é–‹å§‹æœ‰å€‹ global networkï¼Œé–‹ä¸€å † workerï¼Œæ¯æ¬¡å·¥ä½œå‰ï¼ŒæŠŠ global network çš„åƒæ•¸ copy éå» å€‹åˆ¥å»å’Œç’°å¢ƒä½œäº’å‹•ï¼Œæ›´æ–°çš„æ¢¯åº¦æ–½åŠ åœ¨ global network ä¸Š Pathwise Derivative Policy Gradient å¯ä»¥ç•¶ä½œæ˜¯ Q-Learning è§£ continuous action çš„ä¸€ç¨®æ–¹æ³• è¨“ç·´ä¸€å€‹ actorï¼Œç›®æ¨™æ˜¯ç”Ÿå‡ºçš„ a é¤µçµ¦ Q å¾Œï¼Œå¯ä»¥è®“ Q function çš„è¼¸å‡ºè¶Šå¤§è¶Šå¥½ åªæœƒèª¿ actor çš„åƒæ•¸ï¼Œæœƒ fix Q çš„ å°±æ˜¯å€‹ GAN åœ¨æ¯å€‹ episode\nå°æ–¼æ¯å€‹ time step t âš ï¸çµ¦ state $s_t$ï¼Œæ ¹æ“š $\\pi$ åŸ·è¡Œ action $a_t$ (epsilon greedy)âš ï¸ ç²å¾— reward $r_t$ï¼Œåˆ°é” $s_{t+1}$ æŠŠ {$s_t,a_t,r_t,s_{t+1}$} å­˜åˆ° buffer å¾ buffer sample {$s_t,a_t,r_t,s_{t+1}$}(é€šå¸¸æ˜¯ä¸€å€‹ batch) âš ï¸Target $y=r_i+\\hat{Q}(s_{i+1},\\hat{\\pi}(s_{i+1}))$âš ï¸ Update Q çš„åƒæ•¸ï¼Œå¥½è®“ $Q(s_i,a_i)$ æ›´æ¥è¿‘ y(regression) âš ï¸Update $\\pi$ çš„åƒæ•¸ï¼Œè®“ $Q(s_i,\\pi(s_i))$ æœ€å¤§åŒ–âš ï¸ æ¯ C æ­¥ reset $\\hat{Q}=Q$ âš ï¸æ¯ C æ­¥ reset $\\hat{\\pi}=\\pi$âš ï¸ âš ï¸ æ˜¯å’Œ Q-Learning ä¸ä¸€æ¨£çš„åœ°æ–¹\n","date":"2023-03-14T16:21:23+08:00","permalink":"https://roykesydon.github.io/Blog/p/actor-critic/","title":"Actor-Critic"},{"content":"Normalization ç›®çš„ é¿å… redundent information æ›´å®¹æ˜“ understandã€enhanceã€extend é¿å… anomalies éš¨è‘— 1NF ~ 5NFï¼Œæœ‰æ›´å¤šçš„ safety guarantee\n1NF é•åæ¢ä»¶ ç”¨ row order å‚³é”è³‡è¨Š mixing data types in single column ä½† relational database ä¸æœƒè®“ä½ é€™æ¨£åš å­˜åœ¨æ²’æœ‰ primary key çš„ table repeating groups åŒä¸€å€‹ column æœ‰å¤šå€‹æ•¸å€¼ï¼Œæˆ–æ˜¯åœ¨åŒä¸€å€‹ row å­˜å¤šå€‹åŒé¡å‹çš„æ•¸å€¼ã€‚ ex : player item roy 1 item_1, 4 item_2 star 4 item_4 player item_type1 quantity1 item_type2 quantity2 roy item1 1 item2 4 star item_4 4 2NF æ‰€æœ‰çš„ non-key attribute éƒ½è¦ depend on æ•´å€‹ PK éæ­£å¼å®šç¾©ï¼Œæœ‰é»ç´°å¾®å·®ç•° functional dependency ex: {player_id, item_type} -\u0026gt; {item_Quantity} 3NF transitive dependency {A} -\u0026gt; {B} -\u0026gt; {C} æ‰€æœ‰ non-key attribute éƒ½è¦ depend on the whole keyï¼Œä¸èƒ½ depend on å…¶ä»– non-key attribute Boyce-Codd Normal Form æ‰€æœ‰ attribute éƒ½è¦ depend on the whole keyï¼Œä¸èƒ½ depend on å…¶ä»– non-key attribute 4NF multivalued dependency ä¸åƒ functional dependencyï¼Œç®­é ­å¾Œæ–¹çš„é‚£é …å¯ä»¥æœ‰å¤šå€‹ value {Model} $\\twoheadrightarrow$ {Color} ä¸€å€‹ table ä¸­çš„æ‰€æœ‰ multivalued dependency å¿…é ˆä¾è³´æ–¼ key 5NF æ²’æœ‰ Join Dependency table ä¸èƒ½è¡¨ç¤ºæˆå…¶ä»– table join èµ·ä¾†çš„çµæœ ","date":"2023-03-14T10:26:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/database-normalization/","title":"Database Normalization"},{"content":"paper: Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks\nAbstract BERT å’Œ RoBERTa åœ¨ semantic textual similarity (STS) ä¸Šå¤ªèŠ±æ™‚é–“ï¼Œå› ç‚ºä»–éœ€è¦å°‡å…©å€‹å¥å­éƒ½è¼¸å…¥ç¶²è·¯ï¼Œä¸¦ä¸”å…©å…©æ¯”å°ã€‚\nSentence-BERT(SBERT) å°é è¨“ç·´çš„ BERT ä½œäº†ä¸€äº›ä¿®æ”¹ï¼Œé€é siamese å’Œ triplet network çš„çµæ§‹ä¾†ç”Ÿå‡ºæœ‰æ„ç¾©çš„ embeddingsï¼Œä½¿å…¶æœ€å¾Œå¯ä»¥é€é cosine-similarity æ¯”è¼ƒç›¸ä¼¼åº¦ã€‚\nIntroduction SBERT ä½¿ BERT å¯ä»¥ç”¨æ–¼æŸäº›è¿„ä»Šç‚ºæ­¢ä¸é©ç”¨æ–¼ BERT çš„ä»»å‹™ï¼Œæ¯”å¦‚ large-scale semantic similarity comparisonã€clustering é‚„æœ‰ information retrieval via semantic searchã€‚\nä»¥å¾€çš„ç›¸é—œç ”ç©¶æ˜¯æŠŠå–®å€‹å¥å­è¼¸å…¥ BERTï¼Œæœ€å¾Œ average BERT output layerï¼Œæˆ–æ˜¯ä½¿ç”¨ç¬¬ä¸€å€‹ outputï¼Œä½†é€™æ¨£æœƒç”¢ç”Ÿç³Ÿç³•çš„ sentence embeddingsã€‚\nSentEval æ˜¯ä¸€å€‹ evaluation toolkit for sentence embeddings\nRelated Work BERT é€éè¼¸å…¥å…©å€‹å¥å­ï¼Œä»¥ [SEP] éš”é–‹ï¼Œå¯ä»¥åœ¨ STS å–å¾— SOTAã€‚\nä½†é€™æ¨£ç„¡æ³•è¨ˆç®—ç¨ç«‹çš„ sentence embeddingï¼Œæ‰€ä»¥éå¾€çš„ç ”ç©¶äººå“¡æŠŠå–®å€‹å¥å­è¼¸å…¥ BERTï¼Œæœ€å¾Œ average BERT output layerï¼Œæˆ–æ˜¯ä½¿ç”¨ç¬¬ä¸€å€‹ outputã€‚\nModel SBERT åœ¨ BERT / RoBERTa çš„è¼¸å‡ºä¸­æ·»åŠ äº† poolingï¼Œä½œè€…å˜—è©¦äº†ä¸‰ç¨®ç­–ç•¥ï¼ŒCLS-token çš„è¼¸å‡ºã€æ‰€ä»¥è¼¸å‡ºå‘é‡çš„å¹³å‡ã€max-over-time of the output vectorsï¼Œé»˜èªæ˜¯ MEANã€‚\nå¯¦é©—ä»¥ä¸‹çµæ§‹å’Œç›®æ¨™å‡½æ•¸:\nClassification Objective Function\nRegression Objective Function\nç”¨ mean squared-error loss\nTriplet Objective Function\nTraining Details Dataset SNLI çµåˆ Multi-Genre NLI SNLI: 570,000 å€‹ å¥å­ pairï¼Œæœ‰ä¸‰é¡ï¼Œcontradiction, eintailment, and neutral MultiNLI: 430,000 å€‹å¥å­ pair 3-way softmax Classification Objective Function 1-epoch batch-size: 16 Adam lr: 2e-5 warm-up: è¶…é 10% of the training data é»˜èª pooling ç­–ç•¥: MEAN Evaluation å­¸ç¿’ä¸€å€‹è¤‡é›œçš„å›æ­¸å‡½æ•¸åˆ†æ STS å¸¸æ˜¯ SOTAï¼Œä½†æ˜¯ç”±æ–¼ä»–æ˜¯ pair-wiseï¼Œé‡åˆ° combinatorial explosionï¼Œä¸å¥½æ‹“å±•ã€‚\næœ¬æ–‡ç”¨ cosine-similarity æ¯”è¼ƒå…©å€‹ embeddings çš„ç›¸ä¼¼åº¦ï¼Œä¹Ÿç”¨ negative Manhatten å’Œ negative Euclidean distancesï¼Œä½†å¾—åˆ°å·®ä¸å¤šçš„çµæœã€‚\nConclusion ç”¨ BERT ç”Ÿå‡ºçš„ embeddings ä¸é©åˆå¸¸è¦‹çš„ç›¸ä¼¼åº¦æ¸¬é‡æ–¹æ³•ï¼Œæ¯”å¦‚ cosine-similarityã€‚\næœ¬æ–‡æå‡º SBERT æ”¹é€²ï¼Œåœ¨ siamese / triplet ç¶²è·¯æ¶æ§‹ä¸­å¾®èª¿ BERTã€‚\nç”¨ RoBERTa æ›¿æ›æ‰ BERT ä¸¦æ²’æœ‰ä»€éº¼é¡¯è‘—æ”¹é€²ã€‚\n","date":"2023-03-12T10:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/sentence-bert-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"Sentence-BERT è«–æ–‡é–±è®€"},{"content":"UML é¡åˆ¥åœ– Relationship Dependency \u0026ldquo;uses-a\u0026rdquo; Association \u0026ldquo;knows-a\u0026rdquo; Composition \u0026ldquo;has-a\u0026rdquo; child çš„å­˜åœ¨ä¾è³´æ–¼ parentï¼Œè‹¥åˆªé™¤ parentï¼Œchild ä¹Ÿæœƒéš¨ä¹‹åˆªé™¤ Aggregation \u0026ldquo;has-a\u0026rdquo; child çš„å­˜åœ¨ç¨ç«‹æ–¼ parentï¼Œè‹¥åˆªé™¤ parentï¼Œchild ä¸æœƒéš¨ä¹‹åˆªé™¤ Inheritance \u0026ldquo;is-a\u0026rdquo; Implementation \u0026ldquo;can-do\u0026rdquo; å¯¦ç¾ interface other features Navigation ç•¶å…©å€‹ class éƒ½å¯ä»¥çœ‹åˆ°å°æ–¹ï¼Œå°±ç”¨æ²’ç®­é ­çš„é—œè¯ç·šï¼Œå¦å‰‡æœ‰ç®­é ­ Role Name é¡åˆ¥ä¸­çš„ Attribute Multiplicity é—œè¯ç«¯é»ä¸Šå¯ä»¥å¯«æ•¸é‡ï¼Œä»£è¡¨ç‰©ä»¶å€‹æ•¸ Self-Association åŒå€‹é¡åˆ¥çš„ç‰©ä»¶å½¼æ­¤æœ‰é—œä¿‚ è»Ÿé«”è¨­è¨ˆåŸå‰‡ Encapsulate What Varies æŠŠç¶“å¸¸æ”¹è®Šçš„ç¨‹å¼ç¢¼å°è£èµ·ä¾†ï¼Œä½¿æ—¥å¾Œä¿®æ”¹æ™‚ä¸æœƒå½±éŸ¿å…¶ä»–å€å¡Šçš„ç¨‹å¼ç¢¼ å¯¦éš›ä½¿ç”¨çš„æƒ…å¢ƒï¼Œå¯ä»¥æŠŠå¸¸æ”¹è®Šçš„æ±è¥¿æ”¾åœ¨ interface å¾Œï¼Œä½¿æ—¥å¾Œæ”¹è®Šå¯¦ä½œæ™‚ä¸å½±éŸ¿å‘¼å«è©² interface çš„ç¨‹å¼ç¢¼ Favor Composition over Inheritance Composition(çµ„åˆ)åœ¨å¾ˆå¤šæƒ…å¢ƒå¯ä»¥å–ä»£æ‰ Inheritance(ç¹¼æ‰¿)ï¼Œç”šè‡³å¯¦ç¾ Polymorphism(å¤šå‹) åªæœ‰ç•¶ is-a çš„æƒ…å¢ƒå‡ºç¾ï¼Œæ‰ç”¨ç¹¼æ‰¿æ¯”è¼ƒå¥½ Composition ä½¿ç”¨èµ·ä¾†æ›´æœ‰å½ˆæ€§ SOLID è¨­è¨ˆåŸå‰‡ Single Responsibility Principle, SRP å–®ä¸€è·è²¬åŸå‰‡ A class should have only one reason to change. å¯ä»¥æŠŠä¸€å€‹è¤‡é›œçš„ module æ‹†æˆå¤šå€‹ Open-Close Principle, OCP é–‹æ”¾å°é–‰åŸå‰‡ You should be able to extend the behavior of a system without having to modify that system. è¦å¯ä»¥æ“´å……ï¼ŒåŒæ™‚ä¸ä¿®æ”¹åˆ°åŸç³»çµ± LiskovSubstitution Principle, LSP é‡Œæ°æ›¿æ›åŸå‰‡ çˆ¶é¡åˆ¥æœ‰çš„åŠŸèƒ½ï¼Œå­é¡åˆ¥å¿…é ˆéµå¾ï¼Œçˆ¶é¡åˆ¥çš„éƒ¨åˆ†è¦å¯ä»¥ç›´æ¥æ›¿æ›æˆå­é¡åˆ¥ Interface Segregation Principle, ISP ä»‹é¢éš”é›¢åŸå‰‡ No client should be forced to depend on methods it does not use ä»¥ interface ä¾†èªªï¼Œä¸è©²è®“ module å¯¦ç¾å®ƒä¸éœ€è¦çš„åŠŸèƒ½ï¼Œå¯ä»¥æŠŠ interface æ‹†å° Dependency Inversion Principle, DIP åå‘ä¾è³´åŸå‰‡ é«˜éšæ¨¡çµ„ä¸æ‡‰è©²ä¾è³´ä½éšæ¨¡çµ„ï¼Œå…©è€…éƒ½æ‡‰ä¾è³´æŠ½è±¡å±¤ ","date":"2023-03-08T14:26:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E8%BB%9F%E9%AB%94%E8%A8%AD%E8%A8%88%E5%8E%9F%E5%89%87/","title":"è»Ÿé«”è¨­è¨ˆåŸå‰‡"},{"content":"paper: PatentBERT: Patent Classification with Fine-Tuning a pre-trained BERT Model\nAbstract æŠŠ fine-tune BERT æ‡‰ç”¨åœ¨å°ˆåˆ©åˆ†é¡ä¸Šï¼Œç•¶æ‡‰ç”¨æ–¼è¶…é 200 è¬ä»¶å°ˆåˆ©çš„è³‡æ–™é›†æ™‚ï¼Œè©²æ–¹æ³•è¶…è¶Šäº†çµåˆ word-embedding çš„ CNN çš„ SOTA ä½œæ³•ã€‚\nè²¢ç»: ä¸€å€‹ç”¨é è¨“ç·´çš„ BERT å» fine-tune çš„ SOTA æ–¹æ³• ä¸€å€‹å«åš USPTO-3M çš„å¤§å‹è³‡æ–™é›†ï¼Œå±¬æ–¼ CPC subclass levelï¼Œä¸¦æä¾› SQL èªå¥è®“å¾ŒçºŒçš„ç ”ç©¶è€…ä½¿ç”¨ èˆ‡å‚³çµ±è§€å¿µç›¸åï¼Œåªéœ€è¦ claim å°±è¶³ä»¥å®Œæˆåˆ†é¡ä»»å‹™ Introduction å°ˆåˆ©åˆ†é¡æ˜¯ä¸€å€‹ multi-label çš„åˆ†é¡ä»»å‹™ã€‚\nç”±æ–¼æ¨™ç±¤çš„æ•¸é‡å¯èƒ½å¾ˆå¤§ï¼Œæ‰€ä»¥æ˜¯å€‹å…·æœ‰æŒ‘æˆ°æ€§çš„ä»»å‹™ã€‚\nä½œè€…æº–å‚™äº†ä¸€å€‹åŸºæ–¼ CPC çš„æ–°è³‡æ–™é›†ï¼Œæœ‰è¶…éä¸‰ç™¾è¬é …ç¾åœ‹å°ˆåˆ©ã€‚\nCPC Cooperative Patent Classification æ˜¯ IPC æ›´å…·é«”å’Œè©³ç´°çš„ç‰ˆæœ¬ å¯é è¦‹å°‡å–ä»£ IPC æˆç‚ºæ–°çš„æ¨™æº– åªæ˜¯ç”±æ–¼ CLEP-IP ç«¶è³½ï¼Œå¤§éƒ¨åˆ†è«–æ–‡éƒ½åŸºæ–¼ IPC è³‡æ–™é›†åŒ…å« 1978 åˆ° 2009 æäº¤çš„å°ˆåˆ© IPC International Patent Classification æ­¤å¤–ï¼Œä½œè€…çš„ dataset åŸºæ–¼ patent claims\npatent claims é‡è¦æ€§åœ¨éå¾€è¢«ä½ä¼° åœ¨èµ·è‰å°ˆåˆ©ç”³è«‹æ™‚ï¼Œå°ˆåˆ©æ¥­è€…æœƒå…ˆèµ·è‰ patent claims å°ˆåˆ©æ–‡ä»¶çš„å…¶é¤˜éƒ¨åˆ†ç”± claim åšå»¶ä¼¸ åœ¨å°ˆåˆ©æ³•ä¸­ï¼Œclaims å®šç¾©äº†å°ˆåˆ©ç™¼æ˜çš„ç•Œç·šï¼Œç¢ºå®šäº†å°ˆåˆ©æ¬Šç¯„åœ ç‚ºä½¿æ¨¡å‹æ›´ç°¡å–®ï¼Œåªé—œæ³¨ patent claimsï¼Œä¸¦ä¸”åƒ…ç”¨ç¬¬ä¸€é … claimã€‚\nç›¸é—œå·¥ä½œ éå¾€æœ‰äº›ç ”ç©¶åªé¡¯ç¤ºäº† precisionï¼Œä½†æ²’æœ‰ F1 value æˆ– recallï¼Œé›£ä»¥å…¬å¹³æ¯”è¼ƒã€‚\nä»¥ DeepPatent\nData éå¾€è³‡æ–™åŸºæ–¼ CLEF-IP æˆ– patent officesã€‚\nä½œè€…ç™¼ç¾åœ¨ BigQuery ç”¨ Google Patents Public Datasets æ›´å®¹æ˜“ã€‚\nè€Œä¸”å¯ç”¨ SQL statementsï¼Œä½œè€…èªç‚ºæ¯”å…±äº«å‚³çµ±è³‡æ–™é›†æ›´å¥½ï¼ŒåŸå› å¦‚ä¸‹:\nSeperation of concerns å¦‚æœè³‡æ–™åŒ…å«å‰è™•ç†æˆ–å¾Œè™•ç†ï¼Œå…¶ä»–ç ”ç©¶äººå“¡éœ€è¦ä¸åŒæ“ä½œæ™‚æœƒå¾ˆé ­ç—›ã€‚ Clarity and flexibility SQL statement ç²¾ç¢ºä¸”å®¹æ˜“æ ¹æ“šä¸åŒæ¢ä»¶é€²è¡Œä¿®æ”¹ã€‚ åœ¨å’Œ DeepPatent æ¯”è¼ƒçš„æ™‚å€™ï¼Œå¯ä»¥çš„è©±ï¼Œæœƒç”¨ USPTO2M é€²è¡Œæ¸¬è©¦ï¼Œå¦‚æœä¸è¡Œï¼Œæ‰æœƒåˆä½µä¾†è‡ª USPTO-3M çš„è³‡æ–™ï¼Œæ¯”å¦‚ USPTO-2M æ²’æœ‰ claims çš„æƒ…æ³ã€‚\nç‚ºäº†æ¯”è¼ƒ claim å¦‚ä½•å½±éŸ¿æ€§èƒ½ï¼Œå°‡åˆä½µå…©å€‹è³‡æ–™é›†ã€‚\nMethod \u0026amp; Experimental Setup ç”¨ BERT-Base å°±å¯ä»¥æ‰“æ•— DeepPatentã€‚\néµå¾ª BERT Project ä¸­çµ¦çš„ fine-tune ç¯„ä¾‹ã€‚\nç‚ºäº† multilabelï¼Œç”¨ sigmoid cross entropy with logits function è€Œä¸æ˜¯ç”¨ softmaxã€‚\nConclusion å°ˆåˆ©åˆ†é¡ä½œç‚ºå…·æœ‰æŒ‘æˆ°æ€§çš„ä»»å‹™ï¼Œå¹¾åå¹´ä¾†ä¸€ç›´æ²’æœ‰ä»¤äººæ»¿æ„çš„è¡¨ç¾ã€‚\næœ¬æ–‡æå‡ºä¸€å€‹åŸºæ–¼ fine-tune BERT çš„æ–¹æ³•ï¼Œæ€§èƒ½å„ªæ–¼ DeepPatentã€‚\nä¸¦ä¸”çµæœè¡¨æ˜åªç”¨ patent claim å°±å¯ä»¥å®Œæˆåˆ†é¡ä»»å‹™ã€‚\n","date":"2023-03-02T16:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/patentbert-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"PatentBERT è«–æ–‡é–±è®€"},{"content":"linear equation $a_1x_1+a_2x_2+\u0026hellip;+a_nx_n = b$ $a$ æ˜¯ coefficient $x$ æ˜¯ variables $b$ æ˜¯ constant term Systems of linear equations m equations, n variables\n$a_{11}x_1+a_{12}x_2+\u0026hellip;+a_{1n}x_n = b_1\\\\ a_{21}x_1+a_{22}x_2+\u0026hellip;+a_{2n}x_n = b_2\\\\ \u0026hellip;\\\\ a_{m1}x_1+a_{m2}x_2+\u0026hellip;+a_{mn}x_n = b_m$\nsolution\n$[s_1~s_2~\u0026hellip;~s_n]^T$ æ˜¯ä¸€çµ„è§£ï¼Œä»£æ›åˆ° $x_1$~$x_n$ å¾Œæ»¿è¶³æ‰€æœ‰ equation çš„å‘é‡ æ‰€æœ‰ Systems of linear equations éƒ½æœ‰\nno solution exactly one solution infinitely many solutions consistent/inconsistent\nå¦‚æœæœ‰ä¸€çµ„ä»¥ä¸Šçš„è§£å°±æ˜¯ consistent ç„¡è§£å°±æ˜¯ inconsistent equivalent\nå¦‚æœå…©çµ„ Systems of linear equations çš„ solution set ä¸€æ¨£ï¼Œç¨±ç‚º equivalent elementary row operations\nä¸æœƒå½±éŸ¿ solution set types Interchange å…© row äº’æ› Scaling æŸ row ä¹˜æŸå€‹ nonzero scalar Row addition æŠŠæŸ row ä¹˜æŸå€‹ scalar å¾ŒåŠ åˆ°æŸ row property æ‰€æœ‰ elementary row operations éƒ½æ˜¯ reversible ç”¨ä¾†æ±‚è§£ coefficient matrix\n$a_{11}x_1+a_{12}x_2+\u0026hellip;+a_{1n}x_n = b_1\\\\ a_{21}x_1+a_{22}x_2+\u0026hellip;+a_{2n}x_n = b_2\\\\ \u0026hellip;\\\\ a_{m1}x_1+a_{m2}x_2+\u0026hellip;+a_{mn}x_n = b_m$ å¯ä»¥æ‹†ç‚º $Ax=b$\n$A=\\begin{bmatrix} a_{11}\u0026amp; a_{12}\u0026amp;\u0026hellip;\u0026amp; a_{1n} \\\\ a_{21}\u0026amp; a_{22}\u0026amp;\u0026hellip;\u0026amp; a_{2n} \\\\ \u0026hellip;\u0026amp; \u0026hellip;\u0026amp;\u0026hellip;\u0026amp; \u0026hellip; \\\\ a_{m1}\u0026amp; a_{m2}\u0026amp;\u0026hellip;\u0026amp; a_{mn} \\end{bmatrix}$\nA å°±æ˜¯ coefficient matrix $x=\\begin{bmatrix} x_1\\\\ x_2\\\\ \u0026hellip;\\\\ x_n \\end{bmatrix}$\n$x$ æ˜¯ variable vector $[A|b]=\\begin{bmatrix} a_{11}\u0026amp; a_{12}\u0026amp;\u0026hellip;\u0026amp; a_{1n} \u0026amp; b_1 \\\\ a_{21}\u0026amp; a_{22}\u0026amp;\u0026hellip;\u0026amp; a_{2n} \u0026amp; b_2\\\\ \u0026hellip;\u0026amp; \u0026hellip;\u0026amp;\u0026hellip;\u0026amp; \u0026hellip; \u0026amp; \u0026hellip;\\\\ a_{m1}\u0026amp; a_{m2}\u0026amp;\u0026hellip;\u0026amp; a_{mn} \u0026amp; b_m \\end{bmatrix}$\nå«åš augmented matrix ","date":"2023-02-21T15:42:47+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E7%B7%9A%E6%80%A7%E4%BB%A3%E6%95%B8-ii/","title":"ç·šæ€§ä»£æ•¸ - II"},{"content":"matrix a rectangular array of scalars\nsize\nm by n å«åš square if m = n equal\nå…©å€‹çŸ©é™£çš„ size å’Œæ¯å€‹ entry éƒ½ä¸€æ¨£ submatrix\nå¾ä¸€å€‹å¤§çŸ©é™£åˆªæ‰ rows æˆ– columns addition\nå…©å€‹å¤§å°ç›¸åŒçš„çŸ©é™£ï¼Œæ¯å€‹å°æ‡‰ä½ç½®çš„ entry å…©å…©ç›¸åŠ  scalar multiplication\nä¸€å€‹çŸ©é™£çš„æ‰€æœ‰ entry ä¹˜ä»¥æŸå€‹ scalar zero matrix\næ‰€æœ‰ entry éƒ½æ˜¯ 0ï¼Œè©²çŸ©é™£å¸¸ä»¥ $O_{n \\times m}$ ä¾†è¡¨ç¤º æ€§è³ª $A = O + A$ $0 \\cdot A = O $ subtraction\n$A-B=A+(-B)$ transpose\n$A^T$ çš„ $(i,j)$-entry æ˜¯ $A$ çš„ $(j,i)$-entry Properties $(A+B)^T=A^T+B^T$ $(sA)^T=sA^T$ $(A^T)^T=A$ vectors type\nrow vector åªæœ‰ 1 row çš„ matrix column vector åªæœ‰ 1 column çš„ matrix components\nthe entries of a vector ç”¨ the $i$ th component ä»£è¡¨ $v_i$ addition, scalar multiplication\nå’Œ matrix ä¸€æ¨£ çŸ©é™£è¡¨ç¤º\nä¸€å€‹çŸ©é™£å¸¸è¢«è¡¨ç¤ºç‚º a stack of row vectors a cross list of column vectors linear combination $c_1u_1+c_2u_2+\u0026hellip;+c_ku_k$\nscalars\n$c_1,c_2,\u0026hellip;,c_k$ åˆè¢«ç¨±ä½œ linear combination çš„ coefficients vectors\n$u_1,u_2,\u0026hellip;,u_k$ å¦‚æœ $u,v$ éå¹³è¡ŒäºŒç¶­å‘é‡ï¼Œå‰‡äºŒç¶­ç©ºé–“ä¸­æ‰€æœ‰å‘é‡çš†æ˜¯ $u,v$ çš„ linear combinationï¼Œä¸”æ˜¯ unique çš„\nstandard vectors $e_1 = \\begin{bmatrix} 1 \\\\ 0 \\\\ \u0026hellip; \\\\ 0 \\end{bmatrix} ,e_2 = \\begin{bmatrix} 0 \\\\ 1 \\\\ \u0026hellip; \\\\ 0 \\end{bmatrix},\u0026hellip;, e_n = \\begin{bmatrix} 0 \\\\ 0 \\\\ \u0026hellip; \\\\ 1 \\end{bmatrix}$\n$R^n$ çš„ä»»ä½•ä¸€å€‹å‘é‡éƒ½å¯ä»¥è¢« standard vectors è¡¨ç¤ºæˆ uniquely linearly combined\nçŸ©é™£å‘é‡ä¹˜æ³• $Av=v_1a_1+v_2a_2+\u0026hellip;+v_na_n$ Identity Matrix å°æ•´æ•¸ nï¼Œ$n \\times n$ identity matrix $I_n$ æ¯å€‹ columns æ˜¯ standard vectors $e_1, e_2, \u0026hellip;, e_n$ in $R^n$ Stochastic Matrix å°æ•´æ•¸ nï¼Œ$n \\times n$ stochastic matrix æ‰€æœ‰ entry éƒ½å¿…é ˆéè²  æ¯å€‹ column çš„ entry ç¸½å’Œå¿…é ˆæ˜¯ unity (ç›¸åŠ ç‚º 1) ","date":"2023-02-21T14:42:47+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E7%B7%9A%E6%80%A7%E4%BB%A3%E6%95%B8-i/","title":"ç·šæ€§ä»£æ•¸ - I"},{"content":"Process Scheduling å¯èƒ½æ™‚æ©Ÿ\nrunning -\u0026gt; waiting running -\u0026gt; ready waiting -\u0026gt; ready running -\u0026gt; terminate Process Scheduler\nPreemptive scheduler (Time slice) å¯ä»¥è¢«æ¶å  Non-Preemptive scheduler åˆç¨± cooperative scheduling åªå¯èƒ½å‡ºç¾åœ¨æ™‚æ©Ÿ 1 æˆ– 4 Classification fo Processes(related to scheduling)\nInteractive Processes (50 - 150 ms) Batch Processes Real time Processes Hard Soft Classification of Processes(related to CPU usage)\nCPU Bound I/O Bound Standard Scheduling Algorithm FCFS SJF SRTF Priority Based Highest Response Ratio Next Round Robin Virtual RR Multi-Level Queue Scheduler Multi-Level Feed Back Queue Scheduler Rotating Staircase Deadline Scheduler UNIX SVR3 Scheduler æœ‰ 32 å€‹ runqueueï¼Œæ¯å€‹ runqueue è² è²¬ 4 å€‹ priority values\n128 Priority values\n0-49: Kernel 50-127: User $Priority_j=Base_j+CPU_j(i)+nice_j$\nBase: 0-127 $CPU_j(i) = DR * CPU_j(i-1)$ DR = $\\frac{1}{2}$ nice: -20 ~ +19 å¯ä»¥ç”¨ nice å’Œ renice æ”¹ process nice value Schedtool Query \u0026amp; set per process scheduling parameters\nScheduling Policy Real time SCHED_RR SCHED_FIFO Conventional SCHED_NORMAL (default) SCHED_BATCH (CPU intensive) SCHED_ISO (unused) SCHED_IDLEPRIO (low pri jobs) Nice Value (-20 to +19) Static Priority (1-99) CPU affinity process æƒ³é‹è¡Œåœ¨æŸå€‹æŒ‡å®šçš„ CPU ä¸Šï¼Œä¸è¢«è½‰ç§»åˆ°å…¶ä»– CPUï¼Œæ‰ä¸æœƒé™ä½æŒ‡å®š CPU çš„ cache å‘½ä¸­ç‡ soft CPU affinity hard CPU affinity cpus_allowed ä¸€å€‹ç”¨ä¾†æŒ‡å®š CPU çš„ mask 1 schedtool \u0026lt;PID\u0026gt; ","date":"2023-02-20T21:12:52+08:00","permalink":"https://roykesydon.github.io/Blog/p/process-scheduling/","title":"Process Scheduling"},{"content":"RL æ–¹æ³• Policy-based learn åšäº‹çš„ actor Value-based ä¸ç›´æ¥ learn policyï¼Œè€Œæ˜¯ Learn criticï¼Œè² è²¬æ‰¹è©• Q-learning å±¬æ–¼é€™ç¨® Critic ä¸ç›´æ¥æ±ºå®š action çµ¦äºˆ actor $\\pi$ï¼Œè©•ä¼° actor $\\pi$ æœ‰å¤šå¥½ critic çš„ output ä¾è³´æ–¼ actor çš„è¡¨ç¾ State Value Function State value function $V^{\\pi}(s)$ ç”¨ actor $\\pi$ï¼Œçœ‹åˆ° s å¾Œç©åˆ°çµæŸï¼Œcumulated reward expectation æ˜¯å¤šå°‘ è©•ä¼°æ–¹æ³• Monte-Carlo(MC) based approach\ncritic çœ‹ $\\pi$ ç©éŠæˆ² è¨“ç·´ä¸€å€‹ networkï¼Œçœ‹åˆ°ä¸åŒçš„ state ï¼Œè¼¸å‡º cumulated reward(ç›´åˆ°éŠæˆ²çµæŸï¼Œä»¥ä¸‹ç¨±ç‚º $G_a$)ï¼Œè§£ regression å•é¡Œ Temporal-difference(TD) approach\nMC çš„æ–¹æ³•è‡³å°‘è¦ç©åˆ°éŠæˆ²çµæŸæ‰å¯ä»¥ update networkï¼Œä½†æœ‰äº›éŠæˆ²è¶…é•· TD åªéœ€è¦ {$s_t,a_t,r_t,s_{t+1}$} $V^{\\pi}(s_t)=V^{\\pi}(s_{t+1})+r_t$ MS v.s. TD\nMC Larger variance æ¯æ¬¡çš„è¼¸å‡ºå·®ç•°å¾ˆå¤§ TD smaller variance ç›¸è¼ƒ $G_a$ è¼ƒå°ï¼Œå› ç‚ºé€™é‚Šçš„ random variable æ˜¯ rï¼Œä½† $G_a$ æ˜¯ç”±å¾ˆå¤š r çµ„åˆè€Œæˆ V å¯èƒ½ä¼°å¾—ä¸æº–ç¢º é‚£ learn å‡ºä¾†çš„çµæœè‡ªç„¶ä¹Ÿä¸å‡† è¼ƒå¸¸è¦‹ Another Critic State-action value function $Q^\\pi(s,a)$\nåˆå« Q function ç•¶ç”¨ actor $\\pi$ æ™‚ï¼Œåœ¨ state s æ¡å– a é€™å€‹ action å¾Œçš„ cumulated reward expectation æœ‰ä¸€å€‹è¦æ³¨æ„çš„åœ°æ–¹æ˜¯ï¼Œactor çœ‹åˆ° s ä¸ä¸€å®šæœƒæ¡å– a åªè¦æœ‰ Q functionï¼Œå°±å¯ä»¥æ‰¾åˆ°\u0026quot;æ›´å¥½çš„\u0026quot; policyï¼Œå†æ›¿æ›æ‰åŸæœ¬çš„ policy \u0026ldquo;æ›´å¥½çš„\u0026quot;å®šç¾© $V^{\\pi^{\u0026rsquo;}} \\ge V^{\\pi}(s), \\text{for all state s}$ $\\pi^{\u0026rsquo;}(s)=arg \\underset{a}{max}Q^{\\pi}(s,a)$ $\\pi^{\u0026rsquo;}$ æ²’æœ‰å¤šé¤˜çš„åƒæ•¸ï¼Œå°±å–®ç´”é  Q function æ¨å‡ºä¾† é€™é‚Šå¦‚æœ a æ˜¯ continuous çš„æœƒæœ‰å•é¡Œï¼Œç­‰ç­‰è§£æ±º é€™æ¨£å°±å¯ä»¥é”åˆ°\u0026quot;æ›´å¥½çš„\u0026quot;policyï¼Œä¸éå°±ä¸åˆ—è­‰æ˜äº† Basic Tip Target network åœ¨ training çš„æ™‚å€™ï¼ŒæŠŠå…¶ä¸­ä¸€å€‹ Q å›ºå®šä½ï¼Œä¸ç„¶è¦å­¸çš„ target æ˜¯ä¸å›ºå®šçš„ï¼Œæœƒä¸å¥½ train Exploration policy å®Œå…¨ depend on Q function å¦‚æœ action ç¸½æ˜¯å›ºå®šï¼Œé€™ä¸æ˜¯å¥½çš„ data collection æ–¹æ³•ï¼Œè¦åœ¨ s æ¡å– a éï¼Œæ‰æ¯”è¼ƒå¥½ä¼°è¨ˆ Q(s, a)ï¼Œå¦‚æœ Q function æ˜¯ table å°±æ ¹æœ¬ä¸å¯èƒ½ä¼°å‡ºä¾†ï¼Œnetwork ä¹Ÿæœƒæœ‰ä¸€æ¨£çš„å•é¡Œï¼Œåªæ˜¯æ²’é‚£éº¼åš´é‡ã€‚ è§£æ³• Epsilon Greedy $a=\\begin{cases} arg \\underset{a}{max}Q(s,a), \u0026amp; \\text{with probability } 1-\\varepsilon \\\\ random, \u0026amp; otherwise \\end{cases}$ é€šå¸¸ $\\varepsilon$ æœƒéš¨æ™‚é–“éæ¸›ï¼Œå› ç‚ºä½ ä¸€é–‹å§‹ train çš„æ™‚å€™ä¸çŸ¥é“æ€éº¼æ¯”è¼ƒå¥½ Boltzmann Exploration $P(a|s)=\\frac{exp(Q(s,a))}{\\sum_a exp(Q(s,a))}$ Replay Buffer æŠŠä¸€å †çš„ {$s_t,a_t,r_t,s_{t+1}$} å­˜æ”¾åœ¨ä¸€å€‹ buffer {$s_t,a_t,r_t,s_{t+1}$} ç°¡ç¨±ç‚º exp è£¡é¢çš„ exp å¯èƒ½ä¾†è‡ªæ–¼ä¸åŒçš„ policy åœ¨ buffer è£æ»¿çš„æ™‚å€™æ‰æŠŠèˆŠçš„è³‡æ–™ä¸Ÿæ‰ æ¯æ¬¡å¾ buffer éš¨æ©ŸæŒ‘ä¸€å€‹ batch å‡ºä¾†ï¼Œupdate Q function å¥½è™• è·Ÿç’°å¢ƒä½œäº’å‹•å¾ˆèŠ±æ™‚é–“ï¼Œé€™æ¨£å¯ä»¥æ¸›å°‘è·Ÿç’°å¢ƒä½œäº’å‹•çš„æ¬¡æ•¸ æœ¬ä¾†å°±å¸Œæœ› batch è£¡çš„ data è¶Š diverse è¶Šå¥½ï¼Œä¸æœƒå¸Œæœ› batch è£¡çš„ data éƒ½æ˜¯åŒæ€§è³ªçš„ issue æˆ‘å€‘è¦è§€å¯Ÿ $\\pi$ çš„ valueï¼Œæ··é›œäº†ä¸€äº›ä¸æ˜¯ $\\pi$ çš„ exp åˆ°åº•æœ‰æ²’æœ‰é—œä¿‚? ç†è«–ä¸Šæ²’å•é¡Œï¼Œä½†æè€å¸«æ²’è§£é‡‹ Typical Q-learning æ¼”ç®—æ³• åˆå§‹åŒ– Q-fucntion Qï¼Œtarget Q-function $\\hat{Q}=Q$ åœ¨æ¯å€‹ episode å°æ–¼æ¯å€‹ time step t çµ¦ state $s_t$ï¼Œæ ¹æ“š Q åŸ·è¡Œ action $a_t$ (epsilon greedy) ç²å¾— reward $r_t$ï¼Œåˆ°é” $s_{t+1}$ æŠŠ {$s_t,a_t,r_t,s_{t+1}$} å­˜åˆ° buffer å¾ buffer sample {$s_t,a_t,r_t,s_{t+1}$}(é€šå¸¸æ˜¯ä¸€å€‹ batch) Target $y=r_i+\\underset{a}{max}\\hat{Q}(s_{i+1},a)$ Update Q çš„åƒæ•¸ï¼Œå¥½è®“ $Q(s_i,a_i)$ æ›´æ¥è¿‘ y(regression) æ¯ C æ­¥ reset $\\hat{Q}=Q$ Adveanced Tip Double DQN Q Value å¾€å¾€è¢«é«˜ä¼° æˆ‘å€‘çš„ç›®çš„æ˜¯è¦è®“ $Q(s_t, a_t)$ å’Œ $r_t+\\underset{a}{max}Q(s_{t+1},a)$ è¶Šæ¥è¿‘è¶Šå¥½(å¾Œè€…å°±æ˜¯ target) target å¸¸å¸¸ä¸å°å¿ƒè¨­å¤ªé«˜ï¼Œå› ç‚ºå¦‚æœæœ‰ action è¢«é«˜ä¼°äº†ï¼Œå°±æœƒé¸é‚£å€‹ç•¶ target Double DQN: å…©å€‹å‡½å¼ $Q$ å’Œ $Q^{\u0026rsquo;}$ æŠŠ target æ›æˆ $r_t+Q^{\u0026rsquo;}(s_{t+1},arg \\underset{a}{max}Q(s_{t+1},a))$ é¸ action äº¤çµ¦ $Q$ï¼Œå¯¦éš›ç®—äº¤çµ¦ $Q^{\u0026rsquo;}$ å¦‚æœ $Q$ é¸äº†é«˜ä¼°çš„ actionï¼Œ$Q^{\u0026rsquo;}$ æœ‰å¯èƒ½ä¿®æ­£å›ä¾† å¦‚æœ $Q^{\u0026rsquo;}$ é«˜ä¼°ï¼Œ$Q$ ä¸ä¸€å®šæœƒé¸åˆ° $Q^{\u0026rsquo;}$ æ˜¯ target network(å›ºå®šä¸å‹•) Dueling DQN æ”¹è®Š network æ¶æ§‹ åˆ†æˆå…©æ¢ path ç¬¬ä¸€æ¢ç®— scalar ç¬¬äºŒæ¢ç®— vectorï¼Œæ¯å€‹ action éƒ½æœ‰å€‹ value æŠŠ scalar åŠ åˆ°æ¯ä¸€å€‹ç¶­åº¦ åªæ›´æ”¹åˆ° V(s) çš„æ™‚å€™ï¼Œæœƒå…¨éƒ¨çš„ action éƒ½æ”¹åˆ°ï¼Œå¯èƒ½æœƒæ˜¯ä¸€å€‹æ¯”è¼ƒæœ‰æ•ˆç‡çš„æ–¹å¼ï¼Œä¸ç”¨ sample æ‰€æœ‰çš„ action ä½†æœ‰å¯èƒ½æ¨¡å‹ä¸ç®¡ V(s)ï¼Œç›´æ¥è¨­ 0ï¼Œåªæ”¹ A æ‰€ä»¥æœƒå° A ä¸‹ constrainï¼Œè®“ network å‚¾å‘æ–¼æ”¹ V æ¯”å¦‚åŒå€‹ state ä¸‹çš„æ‰€æœ‰ action è¦ç”Ÿå‡º A(s,a) ç¸½å’Œç‚º 0 åœ¨ A çš„è¼¸å‡ºåŠ å€‹ normalization å³å¯è¾¦åˆ°ï¼Œé€™å€‹ normalization å°±æ˜¯æŠŠæ¯å€‹ç¶­åº¦éƒ½æ¸›æ‰å¹³å‡ Prioritized Replay åŸæœ¬æ˜¯ uniform çš„å¾ buffer sample data æ”¹è®“ ã€Œæœ‰æ›´å¤§çš„ TD errorã€çš„ data æœ‰æ›´é«˜çš„æ©Ÿç‡è¢« sample TD error å°±æ˜¯ $Q(s_t, a_t)$ å’Œ target çš„å·®è· å¯¦éš›åœ¨åšçš„æ™‚å€™æœ‰é¡å¤–çš„ç´°ç¯€ï¼Œä¸æœƒåªæ”¹ sampling çš„ processï¼Œé‚„è¦æ”¹ update åƒæ•¸çš„æ–¹æ³• Multi-step Balance between MC å’Œ TD TD åªéœ€è¦å­˜ {$s_t,a_t,r_t,s_{t+1}$} æ”¹å­˜ {$s_t,a_t,r_t,\u0026hellip;,s_{t+N},a_{t+N},r_{t+N}, s_{t+N+1}$} æˆ‘å€‘çš„ç›®çš„æ˜¯è¦è®“ $Q(s_t, a_t)$ å’Œ $\\displaystyle\\sum_{t^{\u0026rsquo;}=t}^{t+N} r_{t^{\u0026rsquo;}}+\\hat{Q}(s_{t+N+1},a_{t+N+1})$ è¶Šæ¥è¿‘è¶Šå¥½(å¾Œè€…å°±æ˜¯ target) $a_{t+N+1}=arg\\underset{a}{max}\\hat{Q}(s_{t+N+1},a)$ åŒæ™‚æœ‰ MC å’Œ TD çš„å¥½è™•å’Œå£è™• ä¼°æ¸¬çš„å½±éŸ¿æ¯”è¼ƒè¼•å¾® r æ¯”è¼ƒå¤šé …ï¼Œvariance æ¯”è¼ƒå¤§ Noisy Net improve exploration Noise on Action Epsilon Greedy(ä¹‹å‰çš„å›é¡§) $f_X(x) = \\begin{cases} arg \\underset{a}{max}Q(s,a), \u0026amp; \\text{with probability }1-\\varepsilon \\\\ random, \u0026amp; ,otherwise \\end{cases}$ çµ¦åŒæ¨£çš„ stateï¼Œæ¡å–çš„ action ä¸ä¸€å®šä¸€æ¨£ æ²’æœ‰çœŸå¯¦çš„ policy æœƒé€™æ¨£é‹ä½œ Noise on Parameters $a = arg \\underset{a}{max}\\tilde{Q}(s,a)$\nåœ¨æ¯å€‹ episode å‰›é–‹å§‹çš„æ™‚å€™ï¼Œåœ¨ Q-function çš„åƒæ•¸ä¸Šé¢åŠ ä¸Š gaussian noise çµ¦åŒæ¨£çš„ stateï¼Œæ¡å–åŒæ¨£çš„ action\nå«åš state-dependent exploration explore in a consistent way\nDistributional Q-function Q-function ç”Ÿå‡ºçš„æ±è¥¿æ˜¯ cumulated reward çš„æœŸæœ›å€¼ æ‰€ä»¥æˆ‘å€‘æ˜¯åœ¨å° distribution å– meanï¼Œä½†ä¸åŒçš„ distribution ä¹Ÿå¯èƒ½æœ‰åŒæ¨£çš„ mean æƒ³åšçš„äº‹æƒ…æ˜¯ model distribution å¦‚æœæœ‰åšé€™å€‹ï¼Œå°±æ¯”è¼ƒä¸æœƒæœ‰ over estimate reward çš„çµæœï¼Œåè€Œå®¹æ˜“ under estimateï¼Œä½¿ double æ¯”è¼ƒæ²’ç”¨ output çš„ range ä¸å¯èƒ½ç„¡é™å¯¬ï¼Œè¶…éé‚Šç•Œçš„ reward æœƒè¢«ä¸Ÿæ‰ Rainbow ç¶œåˆä¸€å †æ–¹æ³• Continuous actions Q learning ä¸å®¹æ˜“è™•ç† continuous action Solution sample n å€‹å¯èƒ½çš„ aï¼Œéƒ½ä¸Ÿ Q function çœ‹èª°æœ€å¤§\ngradient descent\næŠŠ a ç•¶ä½œ parameterï¼Œè¦æ‰¾ä¸€çµ„ a å» maximize Q function é‹ç®—é‡å¤§ï¼Œè¦ iterative çš„ update a ä¸ä¸€å®šå¯ä»¥æ‰¾åˆ° global çš„æœ€ä½³è§£ ç‰¹åˆ¥è¨­è¨ˆ Q networkï¼Œè®“è§£ optimization çš„å•é¡Œè®Šå®¹æ˜“\nç¯„ä¾‹ Q network è¼¸å‡º $\\mu(s)$ã€$\\Sigma(s)$ã€$V(s)$ï¼Œå€‹åˆ¥æ˜¯ vectorã€matrixã€scalar a æ˜¯ continuous çš„ Actionï¼Œæ˜¯ä¸€å€‹ vectorï¼Œæ¯å€‹ç¶­åº¦éƒ½æ˜¯å¯¦æ•¸ $\\Sigma(s)$ æ˜¯ positive definite çš„ï¼Œå¯¦ä½œçš„æ™‚å€™æœƒæŠŠ $\\Sigma$ å’Œå®ƒçš„ transpose ç›¸ä¹˜ $Q(s,a)=-(a-\\mu(s))^T\\Sigma(s)(a-\\mu(s))+V(s)$ $(a-\\mu(s))^T\\Sigma(s)(a-\\mu(s))$ é€™é …å¿…ç‚ºæ­£ï¼Œæ‰€ä»¥ $a=\\mu(s)$ çš„æ™‚å€™å°±æ˜¯æœ€ä½³è§£ ä¸è¦ç”¨ Q-learning\n","date":"2023-02-20T16:21:23+08:00","permalink":"https://roykesydon.github.io/Blog/p/q-learning/","title":"Q-learning"},{"content":"On/Off-policy On-policy å­¸ç¿’çš„ agent å’Œèˆ‡ç’°å¢ƒäº’å‹•çš„ agent æ˜¯åŒä¸€å€‹ Off-policy å­¸ç¿’çš„ agent å’Œèˆ‡ç’°å¢ƒäº’å‹•çš„ agent æ˜¯ä¸åŒå€‹ æƒ³å¾ On-policy è½‰ Off-policy On-policy æ¯æ¬¡éƒ½è¦é‡æ–°è’é›†è³‡æ–™ï¼Œå¾ˆèŠ±æ™‚é–“ ç”±å¦ä¸€å€‹ $\\pi_{\\theta^{\u0026rsquo;}}$ å» train $\\theta$ï¼Œ$\\theta^{\u0026rsquo;}$æ˜¯å›ºå®šçš„ï¼Œæ‰€ä»¥æˆ‘å€‘å¯ä»¥ re-use sample data Importance Sampling æ˜¯ä¸€å€‹ general çš„æƒ³æ³•ï¼Œä¸é™æ–¼ RL\n$E_{x \\text{\\textasciitilde} p}[f(x)]\\approx \\frac{1}{N}\\displaystyle\\sum_{i=1}^N f(x^i)$\n$x^i$ is sampled from p(x) æˆ‘å€‘é‡åˆ°çš„å•é¡Œæ˜¯æ²’è¾¦æ³•å¾ p ä¾† sample dataï¼Œåªèƒ½é€é q(x) å» sample $x^i$\nå¯ä»¥æŠŠä¸Šå¼æ”¹å¯«æˆ $E_{x \\text{\\textasciitilde} p}[f(x)]=E_{x \\text{\\textasciitilde} q}[f(x)\\frac{p(x)}{q(x)}]$\nIssue é›–ç„¶ç†è«–ä¸Š q å¯ä»¥ä»»æ„é¸ï¼Œåªè¦ä¸è¦ q(x) æ˜¯ 0 çš„æ™‚å€™ p(x) ä¸æ˜¯ 0ï¼Œå¯¦ä½œä¸Š p å’Œ q ä¸èƒ½å·®å¤ªå¤šï¼Œä¸ç„¶æœƒæœ‰å•é¡Œ\né€™å…©é …çš„ Variance ä¸ä¸€æ¨£ï¼Œå¦‚æœ p é™¤ä»¥ q å·®è·å¾ˆå¤§ï¼Œå³é‚Šçš„ Variance æœƒå¾ˆå¤§ï¼Œå¦‚æœ sample ä¸å¤ å¤šæ¬¡å°±æœƒæœ‰å•é¡Œ è½‰æ› åŸæœ¬\n$\\triangledown \\overline{R_{\\theta}}=E_{\\tau \\text{\\textasciitilde}p_{\\theta}(\\tau)}[R(\\tau)\\triangledown log p_{\\theta} (\\tau)]$ æ”¹ç‚º\n$\\triangledown \\overline{R_{\\theta}}=E_{\\tau \\text{\\textasciitilde}p_{\\theta^{\u0026rsquo;}}(\\tau)}[\\frac{p_{\\theta}(\\tau)}{p_{\\theta^{\u0026rsquo;}}(\\tau)}R(\\tau)\\triangledown log p_{\\theta} (\\tau)]$ å¾ $\\theta^{\u0026rsquo;}$ sample è³‡æ–™ æ›´æ–° $\\theta$ å¤šæ¬¡ Advantage function åŸæœ¬\n$E_{(s_t,a_t)\\text{\\textasciitilde}\\pi_{\\theta}}[A^{\\theta}(s_t,a_t)\\triangledown log p_\\theta(a_t^n|s_t^n)]$ æ”¹ç‚º\n$E_{(s_t,a_t)\\text{\\textasciitilde}\\pi_{\\theta^{\u0026rsquo;}}}[\\frac{P_\\theta(s_t,a_t)}{P_{\\theta^{\u0026rsquo;}}(s_t,a_t)}A^{\\theta^{\u0026rsquo;}}(s_t,a_t)\\triangledown log p_\\theta(a_t^n|s_t^n)]$ è¦æ³¨æ„ Advantage çš„çµæœè¦ç”± $\\theta^{\u0026rsquo;}$ å¾—å‡ºï¼Œæ˜¯ $\\theta^{\u0026rsquo;}$åœ¨å’Œç’°å¢ƒäº’å‹• æ–°çš„ objective function\n$J^{\\theta^{\u0026rsquo;}}(\\theta)=E_{(s_t,a_t)\\text{\\textasciitilde}\\pi_{\\theta^{\u0026rsquo;}}}[\\frac{p_\\theta(a_t|s_t)}{p_{\\theta^{\u0026rsquo;}}(a_t|s_t)}A^{\\theta^{\u0026rsquo;}}(s_t,a_t)]$ PPO ç¢ºä¿ $\\theta$ å’Œ $\\theta^{\u0026rsquo;}$ ä¸æœƒå·®å¤ªå¤š $J_{PPO}^{\\theta^{\u0026rsquo;}}(\\theta)=J^{\\theta^{\u0026rsquo;}}(\\theta)-\\beta KL(\\theta, \\theta^{\u0026rsquo;})$ å‰èº« TRPO Trust Region Policy Optimization $J_{TRPO}^{\\theta^{\u0026rsquo;}}(\\theta)=E_{(s_t,a_t)\\text{\\textasciitilde}\\pi_{\\theta^{\u0026rsquo;}}}[\\frac{p_\\theta(a_t|s_t)}{p_{\\theta^{\u0026rsquo;}}(a_t|s_t)}A^{\\theta^{\u0026rsquo;}}(s_t,a_t)], KL(\\theta, \\theta^{\u0026rsquo;})\u0026lt;\\delta$ constrain å¾ˆé›£è™•ç† KL divergence é€™é‚Šä¸æ˜¯ $\\theta$ å’Œ $\\theta^{\u0026rsquo;}$ åƒæ•¸ä¸Šçš„è·é›¢ï¼Œè€Œæ˜¯ behavior çš„è·é›¢ åƒæ•¸ä¸Šçš„è·é›¢æ˜¯æŒ‡é€™å…©å€‹åƒæ•¸æœ‰å¤šåƒ æ˜¯çµ¦åŒæ¨£çš„ state ç”Ÿå‡º action çš„ distribution è¦åƒ algorithm åˆå§‹åƒæ•¸ $\\theta^0$ æ¯å€‹ iteration ç”¨ $\\theta^k$ å’Œç’°å¢ƒäº’å‹•ï¼Œè’é›†{$s_t,a_t$}ï¼Œä¸¦è¨ˆç®— advantage $A^{\\theta^k}(s_t,a_t)$\næ‰¾å‡º theta æœ€ä½³åŒ– $J_{PPO}(\\theta)$\n$J_{PPO}^{\\theta^{k}}(\\theta)=J^{\\theta^{k}}(\\theta)-\\beta KL(\\theta, \\theta^{k})$ å¯ä»¥æ›´æ–°å¾ˆå¤šæ¬¡ å‹•æ…‹èª¿æ•´ $\\beta$\nAdaptive KL Penalty è¨­å¯æ¥å—çš„ KL æ•¸å€¼ç¯„åœ if $KL(\\theta,\\theta^k)\u0026gt;KL_{max},\\text{increase} \\beta$ if $KL(\\theta,\\theta^k)\u0026lt;KL_{min},\\text{decrease} \\beta$ PPO2 PPO\n$J_{PPO}^{\\theta^{k}}(\\theta)=J^{\\theta^{k}}(\\theta)-\\beta KL(\\theta, \\theta^{k})$ PPO2\n$J_{PPO2}^{\\theta^{k}}(\\theta)\\approx \\displaystyle\\sum_{(s_t,a_t)}min(\\frac{p_{\\theta}(a_t|s_t)}{p_{\\theta^k}(a_t|s_t)}A^{\\theta^k}(s_t,a_t), \\\\ clip(\\frac{p_{\\theta}(a_t|s_t)}{p_{\\theta^k}(a_t|s_t)}, 1-\\varepsilon, 1+\\varepsilon)A^{\\theta^k}(s_t,a_t))$ ","date":"2023-02-20T12:35:56+08:00","permalink":"https://roykesydon.github.io/Blog/p/proximal-policy-optimizationppo/","title":"Proximal Policy Optimization(PPO)"},{"content":"Basic Components Actor Policy $\\pi$ is a network with parameter $\\theta$ Env Reward Function Trajectory åœ¨ä¸€å ´éŠæˆ²ï¼ŒæŠŠ env è¼¸å‡ºçš„ s å’Œ actor è¼¸å‡ºçš„ a ä¸²èµ·ä¾†ï¼Œæ˜¯ä¸€å€‹ Trajectory Trajectory $\\tau$ = {$s_1,a_1,s_2,a_2,\u0026hellip;,s_T,a_T$} $p_{\\theta}(\\tau)=p(s_1)\\displaystyle\\prod_{t=1}^Tp_{\\theta}(a_t|s_t)p(s_{t+1}|s_t,a_t)$ Update $\\theta \\leftarrow \\theta + \\eta \\triangledown \\overline{R}_{\\theta}$\n$\\triangledown \\overline{R_{\\theta}} = \\displaystyle\\sum_{\\tau} R(\\tau) \\triangledown p_{\\theta} (\\tau) \\\\ =\\frac{1}{N}\\displaystyle\\sum_{n=1}^{N}\\displaystyle\\sum_{t=1}^{T_n}R(\\tau^n)\\triangledown log p_{\\theta} (a_t^n|s_t^n)$\nå¯¦ä½œ å¸¸è¦‹å…¬å¼ $\\triangledown f(x)=f(x)\\triangledown logf(x)$ ç”¨ç•¶å‰æ¨¡å‹è’é›†ä¸€å † Trajectory æ›´æ–°æ¨¡å‹ å›åˆ°ç¬¬ä¸€æ­¥ ç´°ç¯€ åšä¸€å€‹åˆ†é¡å•é¡Œï¼ŒæŠŠ state ç•¶ä½œåˆ†é¡å™¨çš„ Inputï¼ŒæŠŠ action ç•¶ä½œåˆ†é¡å™¨çš„ ground truth ä½œè¨“ç·´ åœ¨å¯¦ä½œåˆ†é¡å•é¡Œçš„æ™‚å€™ï¼Œobjective function éƒ½æœƒå¯«æˆ minimize cross entropyï¼Œå°±æ˜¯ maximize log likelihood RL å’Œä¸€èˆ¬åˆ†é¡çš„å€åˆ¥æ˜¯ï¼Œè¦è¨˜å¾—åœ¨ loss å‰é¢ä¹˜ä¸Š $R(\\tau^n)$ Tip Add a Baseline $R(\\tau^n)$ æœ‰å¯èƒ½æ°¸é éƒ½ç‚ºæ­£ æ­¤æ™‚ç­‰æ–¼å‘Šè¨´ Model èªªï¼Œä»Šå¤©ä¸ç®¡æ˜¯ä»€éº¼ actionï¼Œéƒ½è¦æé«˜å®ƒçš„æ©Ÿç‡ã€‚ä¸ä¸€å®šæœƒæœ‰å•é¡Œï¼Œå› ç‚ºé›–ç„¶éƒ½æ˜¯æ­£çš„ï¼Œä½†æ­£çš„é‡æœ‰å¤§æœ‰å°ï¼Œå¯èƒ½æŸäº› action ä¸Šå‡çš„å¹…åº¦æœƒæ›´å¤§ã€‚å› ç‚ºæˆ‘å€‘æ˜¯åœ¨åš samplingï¼Œä¸ä¸€å®šæœƒ sample åˆ°æŸäº› actionï¼Œæœ¬ä¾†æƒ³çš„æƒ…æ³æ˜¯æ‰€æœ‰çš„ trajectory éƒ½æœƒå‡ºç¾æ‰æ²’å•é¡Œã€‚ è§£æ³•: å¸Œæœ› reward ä¸è¦ç¸½æ˜¯æ­£çš„ $\\triangledown \\overline{R_{\\theta}}\\approx \\frac{1}{N}\\displaystyle\\sum_{n=1}^{N}\\displaystyle\\sum_{t=1}^{T_n}(R(\\tau^n)-b)\\triangledown log p_{\\theta}(a_t^n|s_t^n)$ $b \\approx E[R(\\tau)]$ Assign Suitable Credit åŸæœ¬æ•´å ´éŠæˆ²çš„æ‰€æœ‰ action éƒ½æœƒä¹˜ä¸Š $R(\\tau)$ï¼Œä½†é€™ä¸å¤ªå…¬å¹³ï¼Œå› ç‚ºå°±ç®—çµæœæ˜¯å¥½çš„ï¼Œä¸ä»£è¡¨æ‰€æœ‰ action éƒ½æ˜¯å°çš„ï¼Œåä¹‹äº¦ç„¶ã€‚åœ¨ç†æƒ³çš„æƒ…æ³ä¸‹ï¼Œå¦‚æœ sample å¤ å¤šï¼Œå°±å¯ä»¥è§£æ±ºé€™å•é¡Œã€‚ è§£æ³• åªè¨ˆç®—å¾é€™å€‹ action å¾Œçš„ reward ç¸½å’Œ å› ç‚ºå‰é¢çš„ reward å’Œä½ åšäº†ä»€éº¼æ²’é—œä¿‚ æ¥çºŒè§£æ³• 1ï¼ŒæŠŠæ¯”è¼ƒæœªä¾†çš„ reward åš discount ä¹˜æŸå€‹å°æ–¼ 1 çš„ $\\gamma^{t^{\u0026rsquo;}-t}$ Advantage function base å¯ä»¥æ˜¯ state-dependentï¼Œå¯ä»¥æ ¹æ“š network å¾—å‡ºï¼Œä»¥å¾Œå†èªª $(Reward-b)$ å¯ä»¥åˆèµ·ä¾†çœ‹åš Advantage function $A^{\\theta}(s_t,a_t)$ é€™é‚Š Reward ä¸ç®¡ä½ æ˜¯ä»€éº¼å½¢å¼ï¼Œæœ‰æ²’æœ‰ discountã€‚ å®ƒçš„æ„ç¾©æ˜¯ï¼Œé€™å€‹ action ç›¸è¼ƒæ–¼å…¶ä»–çš„ action æœ‰å¤šå¥½ï¼Œè€Œä¸æ˜¯çµ•å°å¥½ é€™å€‹ A é€šå¸¸å¯ä»¥ç”±æŸå€‹é¡ç¥ç¶“ç¶²è·¯ä¼°è¨ˆï¼Œé‚£å€‹é¡ç¥ç¶“ç¶²è·¯å«åš criticï¼Œä»¥å¾Œè¬› Actor-Critic çš„æ™‚å€™å†èªª ","date":"2023-02-19T17:16:14+08:00","permalink":"https://roykesydon.github.io/Blog/p/policy-gradient/","title":"Policy Gradient"},{"content":"paper: Masked Autoencoders Are Scalable Vision Learners\nAbstract é€™ç¯‡è«–æ–‡é¡¯ç¤ºå‡º MAE æ˜¯ CV ä¸­çš„ scalable self-supervised learnersã€‚\nMAE çš„æ–¹æ³•å¾ˆç°¡å–®\néš¨æ©Ÿè“‹ä½è¼¸å…¥å½±åƒçš„ä¸€äº› patch é‡å»º missing pixels å…·å‚™å…©å€‹æ ¸å¿ƒè¨­è¨ˆ\néå°ç¨±çš„ encoder-decoder æ¶æ§‹ï¼Œencoder åªä½œç”¨æ–¼å¯è¦‹çš„ patch å­é›†åˆ(æ²’æœ‰ mask tokens)ï¼Œlightweight decoder å‰‡æ ¹æ“š latent representation å’Œ make tokens ä¾†é‡å»ºåœ–ç‰‡ã€‚ ç•¶é®ä½é«˜æ¯”ä¾‹(æ¯”å¦‚ 75%)çš„å½±åƒæ™‚ï¼Œæœƒå¾—åˆ°ä¸€å€‹ nontrivial å’Œ meaningful çš„ self-supervisory task çµåˆé€™å…©é»è¨­è¨ˆï¼Œå¯ä»¥æœ‰æ•ˆåœ°è¨“ç·´å¤§æ¨¡å‹ã€‚ ä»¥ ViT-Huge ç”¨ ImageNet-1K è¨“ç·´(è¨“ç·´é›†ä¸€ç™¾å¤šè¬å¼µç…§ç‰‡)å¯é”åˆ° 87.8% çš„æº–ç¢ºåº¦ã€‚\nIntroduction åœ¨ CV ä¸­ï¼Œå¸¸éœ€è¦å¤§é‡ labeled imagesã€‚ NLP ä¸­ï¼Œè‡ªç›£ç£é è¨“ç·´è™•ç†äº†éœ€è¦å¤§é‡æ¨™è¨»è³‡æ–™çš„å•é¡Œã€‚ masked autoencoders æ˜¯ä¸€ç¨®æ›´ general çš„ denoising autoencoders çš„å½¢å¼ã€‚ BERT éå¸¸æˆåŠŸï¼Œautoencoding methods åœ¨ CV çš„ç ”ç©¶å»è½å¾Œ NLPï¼Œä½œè€…æ€è€ƒæ˜¯ä»€éº¼è®“ masked autoencoding åœ¨ CV å’Œ NLP ç”¢ç”Ÿä¸åŒã€‚ æœ‰ä»¥ä¸‹è§€é»\nç›´åˆ°å‰é™£å­ï¼ŒCV ä¸­çš„ CNN æ˜¯ä¸»æµï¼Œä½†å·ç©å±¤ä¸å¥½å¼•å…¥ mask tokens æˆ– positional embedding é€™äº› indicatorã€‚ä½†é€™äº›å¯ä»¥é€é ViT ä¾†è§£æ±ºï¼Œä¸æ‡‰æˆç‚ºå•é¡Œã€‚ èªè¨€å’Œè¦–è¦ºçš„ Information density ä¸åŒï¼Œèªè¨€æ˜¯ highly semantic å’Œ information-denseï¼Œä½¿å¡«å­—æœ¬èº«ä¸æ˜¯å¾ˆç°¡å–®çš„äº‹æƒ…ï¼Œä½†å½±åƒå«æœ‰å¤§é‡å†—é¤˜çš„è¨Šæ¯ï¼Œç¼ºå¤±çš„éƒ¨åˆ†æ¯”è¼ƒå¥½å¾ç›¸é„°çš„ patch é‡å»ºï¼Œæ¯”å¦‚ç›´æ¥æ’å€¼ï¼Œæ‰€ä»¥ä½œè€…ç”¨ä¸€ç¨®ç°¡å–®çš„ç­–ç•¥ï¼Œéš¨æ©Ÿ mask å¾ˆå¤§ä¸€éƒ¨åˆ†çš„ patchï¼Œå‰µé€ ä¸€å€‹å…·æœ‰æŒ‘æˆ°æ€§çš„è‡ªç›£ç£ä»»å‹™ï¼Œå¼·è¿«æ¨¡å‹é—œæ³¨ global çš„è³‡è¨Šã€‚ é—œæ–¼ decoderï¼ŒCV é‚„åŸ pixelï¼Œpixel å±¬æ–¼ lower semantic levelï¼ŒNLP é‚„åŸ wordï¼Œword çš„ semantic information è¼ƒé«˜ã€‚ä½œè€…ç™¼ç¾ï¼Œé›–ç„¶åœ¨ BERT ä¸­ï¼Œå¯ä»¥ç”¨ç°¡å–®çš„ decoder é‚„åŸ(ä¸€å€‹ MLP)ï¼Œä½† CV ä¸­ decoder çš„è¨­è¨ˆå°±å¾ˆé‡è¦ã€‚ åŸºæ–¼ä»¥ä¸Šè§€é»ï¼Œä½œè€…æå‡º MAEï¼Œéš¨æ©Ÿé®ä½å¤§é‡çš„ patchï¼Œä¸¦åœ¨ pixel space é‡å»ºå¤±å»çš„ patchã€‚è€Œä¸”æ˜¯éå°ç¨± encoder-decoder æ¶æ§‹ï¼Œencoder åªæœƒçœ‹åˆ°å¯è¦‹çš„ patchï¼Œä½† docoder é™¤äº† latent representationï¼Œé‚„æœƒçœ‹åˆ° mask tokensã€‚é€™ç¨®è¨­è¨ˆåœ¨éå¸¸é«˜çš„æ©è“‹ç‡(æ¯”å¦‚ 75%)ä¸‹ä¸ä½†å¯ä»¥æé«˜æº–ç¢ºåº¦ï¼Œé‚„å¯ä»¥è®“ encoder åªè™•ç†è¼ƒå°‘æ¯”ä¾‹(æ¯”å¦‚ 25%)çš„ patchï¼Œå°‡è¨“ç·´æ™‚é–“æ¸›å°‘ 3 å€æˆ–æ›´å¤šï¼Œä½¿ MAE å¯ä»¥è¼•é¬†æ“´å±•æˆæ›´å¤§çš„æ¨¡å‹ã€‚\nåœ¨é€™æ¨£çš„æ¶æ§‹ä¸‹ï¼Œç”¨ MAE çš„ pre-trainingï¼Œå¯ä»¥è¨“ç·´éå¸¸åƒ data çš„æ¨¡å‹ï¼Œæ¯”å¦‚ ViT-Large/-Hugeï¼Œè€Œåªä½¿ç”¨ ImageNet-1Kã€‚\nç”¨ ImageNet-1K åœ¨ vanilla ViT-Huge ä¸Š fine-tune å¯é”åˆ° 87.8% æº–ç¢ºåº¦ï¼Œæ¯”ä»¥å¾€åªä½¿ç”¨ ImageNet-1K çš„çµæœéƒ½é«˜ã€‚\nåœ¨ obejct detectionã€instance segmentationã€semantic segmentation ä¸Šåš transfer learning éƒ½é”åˆ°ä¸éŒ¯çš„æ•ˆæœï¼Œå¯ä»¥æ‰“æ•—ç”¨ç›£ç£å¼é è¨“ç·´æ¨¡å‹çš„å°æ‰‹ã€‚\nç›¸é—œå·¥ä½œ Autoencoding MAE æ˜¯ä¸€ç¨® denoising autoencoding çš„å½¢å¼ï¼Œä½†å’Œ DAE é‚„æ˜¯å·®åˆ¥å¾ˆå¤§ã€‚ Masked image encoding iGPTã€ViTã€BEiT Approach Masking\nå’Œ ViT ä¸€æ¨£ï¼ŒæŠŠåœ–ç‰‡åˆ‡æˆå¤šå€‹ patchï¼Œå°æ–¼ patch å‡å‹»éš¨æ©Ÿåœ°æ¡æ¨£ä¿ç•™ï¼Œå‰©ä¸‹åœ°é®ä½ MAE encoder\nViT ä¹Ÿæœ‰ positional embedding MAE decoder\nTransformer block è¼¸å…¥ encoded visible patches mask tokens shared, learned vector éƒ½æœƒåŠ å…¥ positional embedding ç”¨ç›¸è¼ƒ encoder è¼•é‡çš„è§£ç¢¼å™¨ï¼Œæ‰€æœ‰çš„ patch ç”±é€™å€‹è¼•é‡çš„ decoder è™•ç†ï¼Œæ¸›å°‘é è¨“ç·´æ™‚é–“ Reconstruction target\ndecoder çš„æœ€å¾Œä¸€å±¤æ˜¯ linear projectionï¼Œä¹‹å¾Œå† reshape æˆä½ è¦çš„ patch loss function mean squared error(MSE) åªç®— masked patched çš„ MSEï¼Œåƒ BERT Simple implementation\nå…ˆå–å¾—ä¸€ç³»åˆ— token(patch åš linear projection + positional embedding) randomly shuffleï¼Œæ ¹æ“šæ¯”ä¾‹ç§»é™¤å°¾ç«¯ä¸€éƒ¨ä»½ encoding å¾Œï¼Œå°¾ç«¯æ¥ä¸Š mask tokensï¼Œä¸¦ä¸” unshuffle åŠ ä¸Š positional embedding å¾Œï¼Œçµ¦ decoder ImageNet Experiments åœ¨ ImageNet-1K ä¸Šåšè‡ªç›£ç£çš„é è¨“ç·´ï¼Œç„¶å¾Œåš\nend-to-end fine-tuning æ‰€æœ‰åƒæ•¸éƒ½å¯æ”¹ linear probing åªæ”¹æœ€å¾Œä¸€å±¤ç·šæ€§å±¤ optimal masking ratio æ„å¤–åœ°é«˜ï¼Œç›¸æ¯” BERT åªæœ‰ 15%\nè¨è«–å’Œçµè«– åœ¨ CV å¯¦ç”¨çš„é è¨“ç·´åšæ³•ä¸»æµæ˜¯ç›£ç£å¼çš„ï¼ŒCV ä¸­è‡ªç›£ç£çš„åšæ³•å¯èƒ½æ­£è·Ÿè‘— NLP çš„è»Œè·¡èµ°ã€‚\nè¦ä»”ç´°è™•ç†åœ–åƒå’Œèªè¨€çš„å€åˆ¥ï¼Œä½œè€…å»é™¤åœ–ç‰‡ä¸­å¾ˆå¯èƒ½ä¸æ§‹æˆ semantic segment çš„éƒ¨åˆ†ï¼Œè€Œä¸æ˜¯ç§»é™¤æŸå€‹ objectã€‚\n","date":"2023-02-15T16:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/mae-%E8%AB%96%E6%96%87/","title":"MAE è«–æ–‡"},{"content":"paper: An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale\nAbstract åœ¨ CV é ˜åŸŸ transformer è¡¨ç¾æœ‰é™ï¼Œç›®å‰ attention å¸¸å¸¸æ˜¯å’Œå·ç©ç¥ç¶“ç¶²è·¯ä¸€èµ·ç”¨ï¼Œæˆ–æ˜¯ç”¨ä¾†æŠŠä¸€äº›å·ç©å±¤æ›æˆ self-attentionï¼Œä½†æ•´é«”æ¶æ§‹ä¸è®Šã€‚é€™ç¯‡è«–æ–‡æƒ³å±•ç¾ä¸€å€‹ç´” Transformer å¯ä»¥ç›´æ¥åœ¨å½±åƒåˆ†é¡ä¸Šè¡¨ç¾å¾ˆå¥½ã€‚å¦‚æœç”¨å¤§é‡è³‡æ–™ä½œé è¨“ç·´ï¼Œå†é·ç§»åˆ°ä¸­å°å‹çš„è³‡æ–™é›†ï¼Œå¯ä»¥å’Œ SOTA çš„ CNN è¡¨ç¾å¾—ä¸€æ¨£å¥½ï¼Œé‚„éœ€è¦è¼ƒå°‘çš„è¨“ç·´è³‡æºä½œè¨“ç·´ã€‚\nIntroduction self-attention-based æ¶æ§‹ï¼Œç‰¹åˆ¥æ˜¯ Transformerï¼Œå·²ç¶“æ˜¯ NLP çš„é‡è¦é¸æ“‡ã€‚ä¸»æµçš„ä½œæ³•æ˜¯åœ¨å¤§å‹æ–‡å­—è³‡æ–™é›†ä¸Šä½œè¨“ç·´ï¼Œå†é‡å°å°å‹ä»»å‹™è³‡æ–™é›†ä½œ fine-tuneã€‚ç”±æ–¼ Transformer çš„è¨ˆç®—æ•ˆç‡é«˜ï¼Œé‚„æœ‰å¯æ“´å±•æ€§ï¼Œå¯ä»¥ train ä¸€äº›å¾ˆå¤§çš„ modelï¼Œéš¨è‘— model å’Œè³‡æ–™é›†å¢å¤§ï¼Œç›®å‰é‚„æ²’çœ‹å‡ºé£½å’Œçš„ç¾è±¡ã€‚\nç„¶è€Œåœ¨ CVï¼ŒCNN é‚„æ˜¯ä¸»æµï¼Œä¸€äº›å·¥ä½œå˜—è©¦ç”¨ self-attention çµåˆ CNN-like çš„æ¶æ§‹ï¼Œæ¯”å¦‚æŠŠ feature map ç•¶ transformer çš„è¼¸å…¥ï¼Œå› ç‚ºåŸå§‹ pixel å¤ªå¤šï¼Œæˆ–ç”šè‡³æŠŠå·ç©å±¤å…¨æ›æˆ self-attentionï¼Œé›–ç„¶å¾Œè€…ç†è«–ä¸Šæ•ˆç‡å¾ˆé«˜(åŸè«–æ–‡ä¸­æœ‰å¦å¤– cite å…©ç¯‡ä½œæ³•)ï¼Œä½†å› ç‚ºä»–å€‘åšæ³•ç‰¹æ®Šï¼Œåœ¨ç¾ä»£ç¡¬é«”ä¸Šå¾ˆé›£åŠ é€Ÿï¼Œæ‰€ä»¥ç„¡æ³•å¾ˆæœ‰æ•ˆåœ°æ“´å±•ã€‚åœ¨ large-scale çš„å½±åƒè­˜åˆ¥ä¸Šï¼Œ ResNet-like çš„æ¶æ§‹é‚„æ˜¯ SOTAã€‚\nè©²å¯¦é©—ç›´æ¥æŠŠä¸€å€‹æ¨™æº–çš„ Transformer ä½œç”¨æ–¼åœ–ç‰‡ä¸Šï¼Œåªä½œæœ€å°‘çš„ä¿®æ”¹ã€‚æŠŠå½±åƒåˆ†æˆå¤šå€‹ patchï¼Œä¸¦æŠŠå®ƒå€‘è®Šæˆä¸€ç³»åˆ—çš„ linear embeddingï¼Œç•¶ä½œ NLP ä¸­çš„ tokens(words) ä¾†è™•ç†ã€‚\nç•¶åœ¨ä¸­å‹å¤§å°çš„è³‡æ–™é›†(e.g. ImageNet)ä¸Šè¨“ç·´ï¼Œå¦‚æœæ²’æœ‰ strong regularizationï¼ŒViT æœƒç•¥è¼¸åŒç­‰å¤§å°çš„ ResNets\né€™ç¯‡è«–æ–‡åœ¨æ›´å¤§çš„è³‡æ–™é›†(14M-300M çš„å½±åƒ)ä¸Šè¨“ç·´ï¼Œå°±æ‰“æ•—äº† inductive biasã€‚åœ¨å¤§é‡è³‡æ–™ä¸Šä½œé è¨“ç·´å°±å¾ˆè®šã€‚\nRelated Work å¤§å‹çš„ Transformer-based æ¨¡å‹å¸¸å¸¸æ˜¯å…ˆåœ¨å¤§è³‡æ–™é›†ä¸Šé è¨“ç·´ç„¶å¾Œæ ¹æ“šä»»å‹™ fine-tuneï¼Œæ¯”å¦‚ BERT å’Œ GPTã€‚\nè¦æŠŠ self-attention ç”¨åœ¨ CV ä¸Šï¼Œæœ€ç°¡å–®çš„åšæ³•å°±æ˜¯æŠŠæ¯å€‹ Pixel ç•¶ä¸€å€‹å…ƒç´ ï¼Œä½† self-attention æ˜¯å¹³æ–¹è¤‡é›œåº¦ï¼Œåœ¨ç¾å¯¦çš„åœ–ç‰‡å¾ˆé›£æ‡‰ç”¨ã€‚ä¸€å€‹æ‡‰ç”¨ Transformer çš„åšæ³•æ˜¯åªæŠŠ self-attention ç”¨åœ¨ local neighborhoodï¼Œå¦å¤–ä¸€å€‹æ˜¯ç”¨ Sparse Transformerï¼Œé‚„æœ‰ä¸€å †ç‰¹æ®Šçš„æ–¹æ³•ï¼Œé›–ç„¶è¡¨ç¾ä¸éŒ¯ï¼Œä½†è¦ç”¨ç¡¬é«”åŠ é€Ÿèµ·ä¾†ä¸å®¹æ˜“ã€‚\nå¦ä¸€å€‹æœ‰é—œçš„æ¨¡å‹æ˜¯ iGPTï¼Œåœ¨ reduce image resolution å’Œ color space å¾ŒæŠŠ transformer æ‡‰ç”¨åœ¨ image pixels ä¸Šã€‚å®ƒç”¨éç›£ç£å¼è¨“ç·´å¾Œï¼Œå† fine-tune æˆ–åš linear probing(åªæ›´æ–°æœ€å¾Œçš„ linear layer) åˆ†é¡ä»»å‹™ï¼Œè¡¨ç¾å¾ˆå¥½ã€‚\nå·²ç¶“æœ‰é¡ä¼¼çš„å·¥ä½œäº†ï¼ŒæŠ½å– patches of size 2 * 2ï¼Œæœ€å¾Œå†æ¥ full self-attentionï¼ŒåŸºæœ¬ä¸Šå’Œ ViT éå¸¸åƒï¼Œé€™ç¯‡è«–æ–‡é€²ä¸€æ­¥è­‰æ˜äº†ä½œå¤§è¦æ¨¡çš„é è¨“ç·´å¯ä»¥è®“ Transformer å’Œ SOTA çš„ CNN ç›¸æ¯”ï¼Œè€Œä¸” ViT å› ç‚º patch æ¯”è¼ƒå¤§ï¼Œå¯ä»¥è™•ç† medium-resolution çš„åœ–ç‰‡ã€‚é€™å•é¡Œæ˜¯å¯é æœŸçš„ï¼Œå› ç‚º Transformer ç¼ºå°‘äº†ä¸€äº› inductive biasesã€‚\ninductive biases ä¸€äº›å‡è¨­ æ¯”å¦‚ CNN å¸¸æœ‰å››å€‹å‡è¨­ locality translation invariance with pooling layers å¹³ç§»ä¸è®Šæ€§ translation equivariance f(g(x)) = g(f(x)) å·ç©å’Œå¹³ç§»çš„å…ˆå¾Œé †åºæ²’å·® Method æ¨¡å‹ç›¡å¯èƒ½é¡ä¼¼åŸå§‹ Transformerï¼Œé€™æ¨£å¯ä»¥æŠŠä¸€äº› NLP ä¸ŠæˆåŠŸçš„ Transformer æ¶æ§‹æ‹¿ä¾†ç”¨ï¼Œé‚„å¯ä»¥ç”¨ä¸€äº›å¾ˆæœ‰æ•ˆç‡çš„ implementation\nembedding ç¶­åº¦æ˜¯ 768 = 16 * 16 * 3 position embedding çš„åšæ³•æ˜¯ standard learnable 1D positional embeddingsï¼Œå°±æ˜¯ BERT çš„åšæ³•ï¼Œç°¡å–®ä¾†èªªå°±æ˜¯ç”Ÿå‡ºä¸€å¼µå¯ä»¥è¨“ç·´çš„è¡¨ï¼Œ(åºåˆ—é•·åº¦, embedding size)ï¼Œä½œè€…ä¹Ÿæœ‰å˜—è©¦å…¶ä»–æ–¹æ³•ï¼Œä½†ç™¼ç¾æˆæ•ˆå·®ä¸å¤šï¼Œæ¯”å¦‚ 2D positional embeddingï¼Œæ¦‚å¿µå°±æ˜¯å¾ç”Ÿå‡º(åºåˆ—é•·åº¦, embedding size)è®Šæˆç”Ÿå‡º 2 å€‹(sqrt(åºåˆ—é•·åº¦), embedding size)ã€‚\n[class] çš„æ¦‚å¿µæ˜¯ NLP å‡ºä¾†çš„ï¼ŒResNet-like çš„æ¶æ§‹å¸¸è¦‹çš„åšæ³•ä¹Ÿæœ‰é€šé globally average-pooling (GAP)ä¾†ç”Ÿå‡ºå‘é‡ï¼Œå†æ¥ä¸Šåˆ†é¡å™¨åšé æ¸¬ã€‚å¯¦é©—ç™¼ç¾ç›´æ¥åœ¨ transformer çš„è¼¸å‡ºåš GAP å’Œ [class] éƒ½å¯ä»¥é”åˆ°ä¸éŒ¯çš„æ•ˆæœã€‚\nConclusion æ‹¿æ¨™æº–çš„ Transformer ä¾†ä½œ Image recognitionï¼Œå’Œä»¥å¾€ç”¨ self-attention åœ¨ CV çš„æ–¹æ³•ä¸ä¸€æ¨£ï¼Œé™¤äº†ä¸€é–‹å§‹çš„ initial patch extractionï¼Œæ²’æœ‰å¼•å…¥å…¶ä»–å½±åƒç‰¹æœ‰çš„ inductive biasesã€‚ç›´æ¥æŠŠåœ–ç‰‡ç•¶æˆæ˜¯ä¸€ç³»åˆ—çš„ patchï¼Œç„¶å¾Œç›´æ¥ç”¨ Transformer encoder ç•¶ä¸€èˆ¬ NLP ä»»å‹™è™•ç†ã€‚åœ¨å¾ˆå¤šå½±åƒåˆ†é¡è¨“ç·´é›†ä¸Šè¡¨ç¾å¾—æ›´å¥½é‚„åœ¨ pre-train ä¸Šç›¸å°ä¾¿å®œã€‚\né‚„æœ‰ä¸€äº›å€¼å¾—æŒ‘æˆ°çš„åœ°æ–¹ï¼Œæ¯”å¦‚æŠŠ ViT æ‡‰ç”¨åœ¨å…¶ä»– CV ä»»å‹™ï¼Œæ¯”å¦‚ detection å’Œ segmentationã€‚å¦ä¸€å€‹æŒ‘æˆ°æ˜¯æ¢ç´¢è‡ªç›£ç£é è¨“ç·´çš„æ–¹æ³•ã€‚é€™ç¯‡è«–æ–‡å…¶å¯¦æœ‰å¯¦é©—è‡ªç›£ç£ï¼Œè¡¨ç¾ OKï¼Œä½†å’Œç›£ç£å¼é‚„æ˜¯æœ‰å¾ˆå¤§çš„è½å·®ã€‚æ“´å¤§ ViT å¯èƒ½æœ‰æ›´å¥½çš„çµæœã€‚\n","date":"2023-02-12T00:27:55+08:00","permalink":"https://roykesydon.github.io/Blog/p/vit-%E8%AB%96%E6%96%87/","title":"ViT è«–æ–‡"},{"content":"éš¨æ©Ÿè®Šæ•¸ä¹‹å’Œ Z=X+Y\n$p_Z(z)=\\displaystyle\\sum_{x=-\\infty}^{\\infty}p_{X,Y}(x,z-x)\\\\ =\\displaystyle\\sum_{y=-\\infty}^{\\infty}p_{X,Y}(z-y,y)$\n$f_Z(z)=\\int_{-\\infty}^{\\infty}f_{X,Y}(x,z-x)dx\\\\ =\\int_{-\\infty}^{\\infty}f_{X,Y}(z-y,y)dy$\nå¦‚æœ X, Y ç¨ç«‹\né›¢æ•£\n$p_Z(z)=\\displaystyle\\sum_{x=-\\infty}^{\\infty}p_{X}(x)\\cdot p_Y(z-x)\\\\ =\\displaystyle\\sum_{y=-\\infty}^{\\infty}p_{X}(z-y)\\cdot p_Y(y)$ é€™å…©å€‹ç­‰å¼æ˜¯ discrete convolution $=p_X(z) * p_Y(z)$ é€£çºŒ\n$f_Z(z)=\\int_{-\\infty}^{\\infty}f_{X}(x) f_Y(z-x) dx\\\\ =\\int_{-\\infty}^{\\infty}f_{X}(z-y) f_Y(y) dy$ é€™å…©å€‹ç­‰å¼æ˜¯ continuous convolution $=f_X(z) * f_Y(z)$ å¦‚æœæœ‰ n å€‹ç¨ç«‹éš¨æ©Ÿè®Šæ•¸\n$X=X_1+X_2+\u0026hellip;+X_n$ å¦‚æœ $X_1,\u0026hellip;,X_n$ ç¨ç«‹ $p_X(x)=p_{X_1}(x) * p_{X_2}(x) * p_{X_3}(x) * \u0026hellip; * p_{X_n}(x)$ é€£çºŒåš convolution $f_X(x)=f_{X_1}(x) * f_{X_2}(x) * f_{X_3}(x) * \u0026hellip; * f_{X_n}(x)$ é€£çºŒåš convolution MGF moment generating function\nconvolution å¾ˆé›£ç®—\næµç¨‹\nå¦‚æœæœ‰å¤šå€‹é€£çºŒ convolution ä¹Ÿé©ç”¨ä¸‹é¢æµç¨‹ï¼Œå…¨éƒ¨ä¸€æ¬¡ä¸€èµ·ç›¸ä¹˜ çµ¦å®š $p_{X_1}(x), p_{X_2}(x)$ï¼Œç›®æ¨™æ˜¯æ±‚ $p_{X_1}(x) * p{X_2}(x)$\nè½‰æ›åˆ° MGF\n$\\phi_{X_1}(s)=E \\lbrack e^{sX_1} \\rbrack\\\\ = \\displaystyle\\sum_{x=-\\infty}^{\\infty}e^{sx}\\cdot p_{X_1}(x)$\n$\\phi_{X_2}(s)=E \\lbrack e^{sX_2} \\rbrack$\nç›¸ä¹˜ $\\phi_{X_1}(s) \\cdot \\phi_{X_2}(s)$\né€†è½‰æ›\næŸ¥è¡¨ $\\phi_X(s)$ å®šç¾©\n$\\phi_X(s)=E \\lbrack e^{sX} \\rbrack = \\begin{cases} \\displaystyle\\sum_{x=-\\infty}^{\\infty} e^{sx} \\cdot p_{X}(x) \u0026amp; é›¢æ•£, \\\\ \\int_{-\\infty}^{\\infty} e^{sx} \\cdot f_{X}(x)dx \u0026amp; é€£çºŒ \\end{cases}$ æ€§è³ª\nY = aX + b $\\phi_Y(s) = e^{sb} \\cdot \\phi_X(as) $ å¸¸è¦‹é›¢æ•£æ©Ÿç‡åˆ†ä½ˆçš„ MGF\n$X$~$Bernoulli(p)$ $\\phi_X(s)=1-p+pe^s$ $X$~$BIN(n, p)$ ä½œ n æ¬¡å¯¦é©—æˆåŠŸæ¬¡æ•¸ç­‰æ–¼å€‹å¯¦é©—å®¤æˆåŠŸæ¬¡æ•¸çš„ç¸½å’Œ $X = X_1 + X_2 + \u0026hellip; + X_n, X_i ç¨ç«‹, Xi$~$Bernoulli(p)$ $\\phi_{X_i}(s)=1-p+pe^s$ $\\phi_{X}(s)=\\lbrack 1-p+pe^s \\rbrack ^n$ $X$~$Geometric(p)$ è‡ªè¡Œæ¨å° $X$~$Pascal(k,p)$ çœ‹åˆ°ç¬¬ k æ¬¡æˆåŠŸï¼ŒèŠ±çš„ç¸½å¯¦é©—å®¤æ¬¡æ•¸ç­‰æ–¼ç¬¬ 1 è™ŸæˆåŠŸèŠ±å¤šå°‘æ¬¡ + ç¬¬ 2 è™Ÿ +\u0026hellip;+ ç¬¬ k è™Ÿ $X = X_1 + X_2 + \u0026hellip; + X_n, X_i ç¨ç«‹, Xi$~$Gemetric(p)$ $X$~$Exponential(\\lambda)$ è‡ªè¡Œæ¨å° $X$~$Erlang(n,\\lambda)$ $X = X_1 + X_2 + \u0026hellip; + X_n, X_i ç¨ç«‹, Xi$~$Exponential(\\lambda)$ å¤šå€‹éš¨æ©Ÿè®Šæ•¸ä¹‹å’Œ ç¨ç«‹éš¨æ©Ÿè®Šæ•¸ä¹‹å’Œ $X_1, X_2, \u0026hellip;$ç¨ç«‹ï¼Œä¸”å„è‡ªæœ‰ä¸€æ¨¡ä¸€æ¨£çš„æ©Ÿç‡åˆ†ä½ˆ { $X_i$ } $I.I.D.$\nIndependently and Identically Distributed $X = X_1+X_2+\u0026hellip;+X_n$ï¼Œn ç‚ºå¸¸æ•¸ï¼Œè«‹å• X çš„æ©Ÿç‡åˆ†ä½ˆ\n$p_X(x)=p_{X_1}(x) * p_{X_1}(x) * p_{X_1}(x) * \u0026hellip; * p_{X_1}(x)$ $f_X(x)=f_{X_1}(x) * f_{X_1}(x) * f_{X_1}(x) * \u0026hellip; * f_{X_1}(x)$ å› ç‚ºä»–å€‘æ©Ÿç‡åˆ†ä½ˆä¸€æ¨¡ä¸€æ¨£ï¼Œæ‰€ä»¥åº•ä¸‹éƒ½æ˜¯ $X_1$ $\\phi_X(s)=\\lbrack \\phi_{X_1}(s) \\rbrack ^n$ e.g. å‡è¨­å£½å¸ç†æƒ³é‡é‡æ˜¯ 13gï¼ŒæŠ“é£¯é‡æ˜¯å¸¸æ…‹åˆ†ä½ˆï¼ŒæœŸæœ›å€¼æ˜¯ 14ï¼Œæ¨™æº–å·®æ˜¯ 3ï¼Œæ¯å¤©è¦ä½œ 100 å€‹ï¼Œæ¯å¤©é£¯é‡çš„æ©Ÿç‡åˆ†ä½ˆæ˜¯?\n$X_i$ : ç¬¬ i å€‹å£½å¸çš„é£¯é‡ï¼Œ{ $X_i$ } I.I.D. $X_i$~$N(14,9)\\\\ \\Rightarrow \\phi_{X_i}(s)=\\phi_{X_1}(s)\\\\ =e^{\\mu S + \\frac{\\sigma^2}{2}s^2} = e^{14 s + \\frac{9}{2}s^2}$ $X=X_1+X_2+\u0026hellip;+X_{100}$ $\\phi_X(s)=\\lbrack \\phi_{X_1}(s) \\rbrack^{100}\\\\ =e^{1400 s + \\frac{900}{2}s^2}$ é€™å€‹æ±è¥¿æ˜¯ $X$~$N(1400,900)$ çš„ MGFï¼Œæ‰€ä»¥å¯ä»¥é€†æ¨å›ä¾†æ©Ÿç‡åˆ†ä½ˆ éš¨æ©Ÿè®Šæ•¸ä¹‹ç¨ç«‹éš¨æ©Ÿè®Šæ•¸å’Œ $X_1,X_2,\u0026hellip;I.I.D.$\n$X = X_1 + X_2 + \u0026hellip; + X_N$\nN æœ¬èº«ä¹Ÿæ˜¯éš¨æ©Ÿè®Šæ•¸ï¼Œå…¶æ©Ÿç‡åˆ†ä½ˆå·²çŸ¥\n$\\phi_X(s)=\\phi_N(ln(\\phi_{X_1}(s)))$\nä¸­å¤®æ¥µé™å®šç† central limit theorem(CLT)\nè‹¥ $X_1,X_2,\u0026hellip;,X_n$ ç‚º $I.I.D.$ï¼Œç•¶ n è¶¨è¿‘æ–¼ç„¡çª®å¤§æ™‚\n$X=X_1+X_2+\u0026hellip;+X_n$~$N(\\mu_{X_1+X_2\u0026hellip;+X_n}, \\sigma^2_{X_1+X_2+\u0026hellip;+X_n})$ $\\mu_{X_1+X_2+\u0026hellip;+X_n}=\\mu_{X_1}+\\mu_{X_2}+\u0026hellip;+\\mu_{X_n}=n\\mu_{X_1}$ $\\sigma^2_{X_1+X_2+\u0026hellip;+X_n}=\\sigma^2_{X_1}+\\sigma^2_{X_2}+\u0026hellip;+\\sigma^2_{X_n}=n\\sigma^2_{X_1}$ æ‡‰ç”¨\nè¦è™•ç†å¤šå€‹ç¨ç«‹çš„éš¨æ©Ÿè®Šæ•¸çš„å’Œæ™‚ï¼Œå¯ä»¥ç”¨ CLT å°‡å…¶æ©Ÿç‡åˆ†ä½ˆè¿‘ä¼¼ç‚ºå¸¸æ…‹åˆ†ä½ˆå¾Œè¨ˆç®—æ©Ÿç‡ æ¯”å¦‚é›œè¨Šå¸¸ç•¶ä½œå¸¸æ…‹åˆ†ä½ˆ å¦‚æœæŸæ©Ÿç‡åˆ†ä½ˆç­‰æ–¼å¤šå€‹ç¨ç«‹éš¨æ©Ÿè®Šæ•¸çš„å’Œï¼Œæ­¤æ©Ÿç‡åˆ†ä½ˆå¯ä»¥ç”¨å¸¸æ…‹åˆ†ä½ˆè¿‘ä¼¼ï¼Œå†ç®—æ©Ÿç‡ e.g. $X$~$BIN(100,0.3)$ $X=X_1+X_2+\u0026hellip;+X_100$ {$X_i$} $I.I.D., X_i$~$Bernoulli(0.3)$ ç¯„ä¾‹\nå¤©åœ˜ç²‰çµ²æœ‰ 0.2 çš„æ©Ÿç‡è²· CDï¼Œå…±æœ‰100è¬å€‹ç²‰çµ²ï¼Œç™¼å”® CD è¶…é 200800 å¼µçš„æ©Ÿç‡ç‚ºä½• $X$~$BIN(1000000,0.2)$ $P(X\u0026gt;200800)=\\displaystyle\\sum_{x=200801}^{10^6}(\\overset{1000000}{x})0.2^x0.8^{10^6-x}$ $(\\overset{1000000}{x})=\\frac{1000000!}{200801!799199!}$ ç®—ä¸å‡ºä¾† $X=X_1+X_2+\u0026hellip;+X_{1000000}, X_i$~$Bernoulli(0.2)\\\\ \\Rightarrow \\mu_{X_1}=0.2, \\sigma_{X_1}^2=0.16$ By CLT $\\Rightarrow X$~$N(200000,160000)$ $P(X\u0026gt;200800)\\\\ =P(\\frac{X-200000}{400} \u0026gt; \\frac{200800-200000}{400})\\\\ =P(Z\u0026gt;2) =Q(2) \\approx0.023$ De Moivre - Laplace Formula å¦‚æœæ˜¯é›¢æ•£çš„éš¨æ©Ÿè®Šæ•¸å’Œï¼Œå¯ä»¥ç®—çš„æ›´ç²¾ç¢º $P(k_1 \\le X \\le k_2) \\approx \\Phi(\\frac{k_2+0.5-n\\mu_{X_1}}{\\sqrt{n}\\sigma_{X_1}}) - \\Phi(\\frac{k_1-0.5-n\\mu_{X_1}}{\\sqrt{n}\\sigma_{X_1}})$ ","date":"2023-02-05T15:18:41+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E6%A9%9F%E7%8E%87%E8%AB%96-iv/","title":"æ©Ÿç‡è«– - IV"},{"content":"éš¨æ©Ÿè®Šæ•¸çš„å‡½æ•¸ éš¨æ©Ÿè®Šæ•¸ X çš„ä»»æ„å‡½æ•¸ g(x) ä¹Ÿæ˜¯ä¸€å€‹éš¨æ©Ÿè®Šæ•¸ï¼Œå¸¸è¢«ç¨±ç‚º Derived Random Variable æ±‚ g(x) çš„æ©Ÿç‡åˆ†ä½ˆ X æ˜¯é›¢æ•£ ç›´æ¥æ¨ g(X) çš„ PMF X æ˜¯é›¢æ•£éš¨æ©Ÿè®Šæ•¸ï¼ŒY = g(X) ä¹Ÿæ˜¯é›¢æ•£éš¨æ©Ÿè®Šæ•¸ $p_{g(X)}(y) = \\displaystyle\\sum_{æœƒè®“g(x)=y çš„æ‰€æœ‰x}p_X(x)$ X æ˜¯é€£çºŒ å…ˆæ¨ g(x) çš„ CDFï¼Œå†å¾®åˆ†å¾— PDF\nå…ˆç®— g(X) çš„ CDF $F_{g(X)}(y)=P\\lbrack g(X) \\le y \\rbrack$ è‹¥ g(X) å¯ä»¥å¾®åˆ†ï¼Œå†å° y å¾®åˆ†å¾— PDF $f_{g(X)}(y)=\\frac{d}{dy}F_{g(X)}(y)$ e.g. è‹¥ Y=3X+2ï¼Œè«‹å• Y çš„ PDF èˆ‡ $f_X(x) çš„é—œä¿‚?$\n$F_Y(y)=P(Y \\le y)\\\\ =P(3X+2 \\le y)\\\\ =P(X \\le \\frac{y-2}{3})\\\\ =F_X(\\frac{y-2}{3})$ $f_Y(y)=\\frac{d}{dy}F_Y(y)\\\\ =\\frac{d}{dy}F_X(\\frac{y-2}{3})\\\\ =\\frac{dF_X(\\frac{y-2}{3})}{d(\\frac{y-2}{3})} \\cdot \\frac{d \\frac{y-2}{3}}{dy}\\\\ =f_X(\\frac{y-2}{3}) \\cdot \\frac{1}{3}$ è‹¥ Y=aX+b\n$f_Y(y)=\\frac{1}{|a|}f_X(\\frac{y-b}{a})$ æ¢ä»¶æ©Ÿç‡åˆ†ä½ˆ è‹¥ X æ˜¯é›¢æ•£éš¨æ©Ÿè®Šæ•¸ï¼ŒPMF æ˜¯ $p_X(x)$ï¼ŒæŸäº‹ä»¶ B å·²ç™¼ç”Ÿ PMF: $p_{X|B}(x)= x = \\begin{cases} x \\in B: \u0026amp; \\frac{p_X(x)}{p(B)}, \\ x \\notin B: \u0026amp; 0 \\end{cases}$ CDF: $F_{X|B}(x)\\\\ =\\displaystyle\\sum_{u \\le x}p_{X|B}(u)\\\\ =\\displaystyle\\sum_{u \\le x, u \\in B} \\frac{p_X(u)}{P(B)}$ è‹¥ X æ˜¯é€£çºŒéš¨æ©Ÿè®Šæ•¸ï¼ŒæŸäº‹ä»¶ B å·²ç™¼ç”Ÿ PDF: $f_{X|B}(x)\\\\ =\\begin{cases} x \\in B: \u0026amp; \\frac{f_X(x)}{P(B)}, \\ x \\notin B: \u0026amp; 0 \\end{cases}$ CDF: $F_{X|B}(x)\\\\ =\\int_{-\\infty \\le u \\le x, u \\in B} \\frac{f_X(u)}{P(B)} du$ æ¢ä»¶æœŸæœ›å€¼ Conditional Excpectation $E \\lbrack X|B \\rbrack\\\\ =\\begin{cases} \\displaystyle\\sum_{x=-\\infty}^{\\infty} x \\cdot p_{X|B}(x) \u0026amp; é›¢æ•£, \\\\ \\int_{-\\infty}^{\\infty} x \\cdot f_{X|B}(x)dx \u0026amp; é€£çºŒ \\end{cases}$\n$E \\lbrack g(X)|B \\rbrack\\\\ =\\begin{cases} \\displaystyle\\sum_{x=-\\infty}^{\\infty} g(x) \\cdot p_{X|B}(x) \u0026amp; é›¢æ•£, \\\\ \\int_{-\\infty}^{\\infty} g(x) \\cdot f_{X|B}(x)dx \u0026amp; é€£çºŒ \\end{cases}$\n$Var(X|B) = E\\lbrack X^2 | B \\rbrack - (\\mu_{X|B})^2$\nå¤±æ†¶æ€§ Memoryless Geometric å’Œ Exponential æ©Ÿç‡åˆ†ä½ˆéƒ½æœ‰å¤±æ†¶æ€§ ä¸ç®¡äº‹æƒ…å·²ç¶“é€²è¡Œå¤šä¹…ï¼Œå°æ–¼äº‹æƒ…ä¹‹å¾Œçš„é€²è¡Œä¸€é»å½±éŸ¿éƒ½æ²’æœ‰ è¯åˆæ©Ÿç‡åˆ†ä½ˆ joint probability distribution åŒæ™‚è€ƒæ…®å¤šå€‹éš¨æ©Ÿè®Šæ•¸çš„æ©Ÿç‡åˆ†ä½ˆ Joint PMF X, Y çš†ç‚ºé›¢æ•£ï¼Œè¯åˆPMF\n$p_{X,Y}(x,y)=P(X=x, Y=y)$ æ€§è³ª\n$0 \\le p_{X,Y}(x,y) \\le 1$ $\\Sigma^{\\infty}{x=-\\infty}\\Sigma^{\\infty}{y=-\\infty} p_{X,Y}(x,y)=1$ X, Y ç¨ç«‹ $P_{X,Y}(x,y)\\\\ =P(X=x,Y=y)\\\\ =P_X(x)P_Y(y)$ å°ä»»ä½•äº‹ä»¶ B $P(B)=\\Sigma_{(x,y)\\in B}P_{X,Y}(x,y)$ Joint CDF $F_{X,Y}(x,y)=P(X \\le x, Y \\le y)$\næ€§è³ª\n$0 \\le F_{X,Y}(x, y) \\le 1$ è‹¥ $x_1 \\le x_2$ ä¸” $y_1 \\le y_2$ï¼Œå‰‡ $F_{X,Y}(x_1,y_1) \\le F_{X,Y} (x_2, y_2)$ $F_{X,Y}(x, \\infty) = F_X(x)$ $F_{X,Y}(\\infty, y) = F_Y(y)$ $F_{X,Y}(\\infty, \\infty) = 1$ $F_{X,Y}(x, -\\infty)\\\\ = P(X \\le x, Y \\le -\\infty)\\\\ \\le P(Y \\le -\\infty) \\\\ = 0$ $F_{X,Y}(-\\infty, y) = 0$ $P(x_1 \u0026lt; X \\le x_2, y_1 \u0026lt; Y \\le y_2)\\\\ =F_{X,Y}(x_2,y_2)-F_{X,Y}(x_2,y_1)-F_{X,Y}(x_1,y_2)+F_{X,Y}(x_1,y_1)$ Joint PDF $f_{X,Y}(x,y)= \\frac{\\partial^2F_{X,Y}(x,y)}{\\partial x \\partial y}$\n$F_{X,Y}(x,y) = \\int_{-\\infty}^{x} \\int_{-\\infty}^{y} f_{X,Y}(u,v)dv du$\næ€§è³ª\n$f_{X,Y}(x,y) \\ge 0$ $\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}f_{X,Y}(x,y)dxdy=1$ å¦‚æœ X,Y ç¨ç«‹ $f_{X,Y}(x,y)=f_X(x) \\cdot f_Y(y)$ å°ä»»ä½•äº‹ä»¶ B $P(B)=\\int\\int_{(x,y)\\in B}f_{X,Y}(x,y)dxdy$ é‚Šéš› PMF Marginal PMF å·²çŸ¥è¯åˆ PMF : $p_{X,Y}(x,y)$ï¼Œæ±‚ $p_X(x), p_Y(y)$ï¼Œç¨±ç‚ºé‚Šéš› PMF $p_X(x)=\\displaystyle\\sum_{y=-\\infty}^{\\infty}P_{X,Y}(x,y)$ $p_Y(y)=\\displaystyle\\sum_{x=-\\infty}^{\\infty}P_{X,Y}(x,y)$ å·²çŸ¥è¯åˆ PDF : $p_{X,Y}(x,y)$ï¼Œæ±‚ $f_X(x), f_Y(y)$ï¼Œç¨±ç‚ºé‚Šéš› PDF $f_X(x)=\\int_{-\\infty}^{\\infty}f_{X,Y}(x,y)dy$ $f_Y(y)=\\int_{-\\infty}^{\\infty}f_{X,Y}(x,y)dx$ é›™è®Šæ•¸æœŸæœ›å€¼ è¯åˆ PMF ä¸‹çš„æœŸæœ›å€¼\n$E\\lbrack h(X,Y) \\rbrack = \\displaystyle\\sum_{x=-\\infty}^{\\infty}\\displaystyle\\sum_{y=-\\infty}^{\\infty}h(x,y)\\cdot p_{X,Y}(x,y)$ h(X,Y) ä¹Ÿå¯ä»¥åªå’Œ X æœ‰é—œï¼Œæ¯”å¦‚å®ƒå¯ä»¥æ˜¯ $x^2$ è¯åˆ PDF ä¸‹çš„æœŸæœ›å€¼\n$E\\lbrack h(X,Y) \\rbrack = \\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}h(x,y)\\cdot f_{X,Y}(x,y) dxdy$ e.g. å·²çŸ¥ $f_{X,Y}(x,y)=\\begin{cases} 0.5, \u0026amp; \\text{if } 0 \\le y \\le x \\le 2, \\\\ 0, \u0026amp; otherwise \\end{cases}$ $E \\lbrack X + Y \\rbrack \\\\ = \\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}(x+y)\\cdot f_{X,Y}(x,y) dxdy\\\\ = \\int_{0}^{2}\\int_{y}^{2}(x+y)\\cdot 0.5 dxdy$ æœŸæœ›å€¼æ€§è³ª\n$E\\lbrack \\alpha h_1(X,Y)+ \\beta h_2(X,Y) \\rbrack\\\\ =\\alpha E\\lbrack h_1(X,Y)\\rbrack + \\beta E\\lbrack h_2(X,Y) \\rbrack$ è‹¥ X,Y ç¨ç«‹ $E\\lbrack g(X)h(Y) \\rbrack = E \\lbrack g(X) \\rbrack \\cdot E \\lbrack h(Y) \\rbrack$ Variance æ€§è³ª\n$Var(X+Y)=Var(X)+Var(Y)+2 \\cdot Cov(X,Y)$ $Cov(X,Y)=E\\lbrack (X-\\mu_X)(Y -\\mu_Y) \\rbrack$ å¦‚æœ X, Y ç¨ç«‹ $2E\\lbrack (X-\\mu_X)(Y -\\mu_Y) \\rbrack \\\\ = 2E\\lbrack (X-\\mu_X) \\rbrack E\\lbrack (Y -\\mu_Y) \\rbrack \\\\ = 0$ ","date":"2023-02-02T15:18:41+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E6%A9%9F%E7%8E%87%E8%AB%96-iii/","title":"æ©Ÿç‡è«– - III"},{"content":"æ©Ÿç‡å¯†åº¦å‡½æ•¸ PDF probability density function PMF åœ¨ é€£çºŒR.V. ä¸Šï¼Œå‡å¦‚ $X\\text{\\textasciitilde}[0,1)$ï¼Œ$p_X(0.7)$ = 0ï¼Œå› ç‚ºæœ‰ç„¡çª®å¤šå€‹æ•¸å­— å…¬å¼ $f_X(x)=\\lim\\limits_{\\Delta x \\rightarrow 0} \\frac{P(x \\le X \\le x + \\Delta x)}{\\Delta x} \\\\ = \\lim\\limits_{\\Delta x \\rightarrow 0} \\frac{F_X(x+\\Delta x) - F_X(x)}{\\Delta x} \\\\ = F^{\\prime}_X(x) $ å’Œ CDF çš„é—œä¿‚ $CDF: F_X(x) = PDF: f_X(x)$ $\\int^x_{-\\infty}$ å¯ä»¥å¾ PDF è½‰åˆ° CDF\n$\\frac{d}{dx} å¯ä»¥å¾ CDF è½‰åˆ° PDF$\nè·Ÿæ©Ÿç‡çš„é—œä¿‚ $P(a \u0026lt; X \\le b) = F_X(b) - F_X(a) \\\\ = \\int^b_{-\\infty} f_X(x)dx - \\int^a_{-\\infty} f_X(x)dx \\\\ = \\int^a_b f_X(x)dx$ $f_X(x)=\\lim\\limits_{\\Delta x \\rightarrow 0} \\frac{P(x \\le X \\le x + \\Delta x)}{\\Delta x}$ ç•¶ $\\Delta x$ å¾ˆå°æ™‚ $P(x \\le X \\le x + \\Delta x) \\approx f_X(x) \\cdot \\Delta x$ æ€§è³ª $f_X(x) = F^{\\prime}_X(x)$ $F_X(x)=\\int^x_{-\\infty}f_X(u)du$ $P(a \\le X \\le b)=\\int^b_a f_X(x) dx$ $\\int^{\\infty}_{-\\infty}f_X(x)dx=1$ $f_X(x) \\ge 0$ $f_X(x)$ å¯ä»¥æ¯” 1 å¤§ é€£çºŒæ©Ÿç‡åˆ†ä½ˆ Uniform æ©Ÿç‡åˆ†ä½ˆ $X \\text{\\textasciitilde}UNIF(a,b)$ PDF $f_X(x) = \\begin{cases} \\frac{1}{b-a} \u0026amp; ,a \\le x \\le b \\\\ 0 \u0026amp; ,otherwise \\end{cases}$ CDF $F_X(x) = \\begin{cases} 0 \u0026amp; ,x \\le a \\\\ \\frac{x-a}{b-a} \u0026amp; ,a \u0026lt; x \\le b\\\\ 1 \u0026amp; ,x \u0026gt; b \\end{cases}$ Exponential æ©Ÿç‡åˆ†ä½ˆ æœ‰å¤±æ†¶æ€§(memoryless)ï¼Œå¸¸è¢«ç”¨ä¾† model æœ‰é€™ç¨®æ€§è³ªçš„äº‹æƒ… $X \\text{\\textasciitilde}Exponential(\\lambda)$ PDF $f_X(x) = \\begin{cases} \\lambda e^{-\\lambda x} \u0026amp; ,x \\ge 0 \\\\ 0 \u0026amp; ,otherwise \\end{cases}$ CDF $F_X(x) = 1-e^{-\\lambda x}$ Erlang æ©Ÿç‡åˆ†ä½ˆ Gamma Distribution $X \\text{\\textasciitilde}Erlang(n,\\lambda)$ PDF $f_X(x) = \\begin{cases} \\frac{1}{(n-1)!}\\lambda^n x^{n-1} e^{-\\lambda x} \u0026amp; ,x \\ge 0 \\\\ 0 \u0026amp; ,otherwise \\end{cases}$ $f_X(x)=(\\lambda e^{-\\lambda x}) * (\\lambda e^{-\\lambda x}) * \u0026hellip; * (\\lambda e^{-\\lambda x})$ è‡ªå·±å’Œè‡ªå·±åš n æ¬¡ convolution CDF $F_X(x) = \\begin{cases} 1 - \\Sigma^{n-1}_{k=0}\\frac{(\\lambda x)^k}{k!}e^{-\\lambda x} \u0026amp; ,x \\ge 0 \\\\ 0 \u0026amp; ,otherwise \\end{cases}$ å¸¸è¦‹ç”¨æ³• ç”¨ä¾† model ä¸€ä»¶æœ‰å¤šå€‹é—œå¡äº‹æƒ…çš„ç¸½æ™‚é–“ï¼Œè€Œæ¯å€‹é—œå¡æ‰€éœ€æ™‚é–“æ˜¯éš¨æ©Ÿçš„ é—œå¡æ•¸: n æ¯é—œå¡æ‰€éœ€æ™‚é–“ä¹‹æ©Ÿç‡åˆ†ä½ˆ $Exponential(\\lambda)$ e.g. æ‰“é›»å‹•éä¸‰é—œæ‰€éœ€æ™‚é–“ $Erlang(3, \\lambda)$ Normal æ©Ÿç‡åˆ†ä½ˆ (å¸¸æ…‹åˆ†ä½ˆ) åœ¨è‡ªç„¶ç•Œå¸¸å‡ºç¾\nå¸¸è¢«ç”¨åšã€Œå¾ˆå¤šéš¨æ©Ÿé‡çš„ç¸½å’Œã€çš„æ©Ÿç‡æ¨¡å‹\nåˆç¨± Gaussian æ©Ÿç‡åˆ†ä½ˆ\n$X \\text{\\textasciitilde}Gaussian(\\mu,\\sigma)$\nPDF\n$f_X(x)=\\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}$ ä¹Ÿå¸¸ç”¨ $X \\text{\\textasciitilde}N(\\mu,\\sigma^2)$\næ³¨æ„ $\\sigma$ ä¸ä¸€æ¨£ CDF\nå¤ªé›£ç®—ï¼Œç©ä¸å‡ºä¾†\né‡å°æŸçµ„ç‰¹åˆ¥çš„ $\\mu, \\sigma$ çš„ CDF å»ºè¡¨ï¼ŒæŠŠå…¶ä»–å¸¸æ…‹åˆ†ä½ˆçš„ CDF å’Œé€™çµ„ç”¢ç”Ÿé—œè¯ æ¨™æº–å¸¸æ…‹åˆ†ä½ˆ\n$Z \\text{\\textasciitilde}N(0,1)$ $f_Z(z)=\\frac{1}{\\sqrt{2 \\pi}}e^{-\\frac{z^2}{2}}$ CDF è¡¨ç¤ºç‚º $\\Phi(z)$ $\\Phi(z)=\\int^z_{-\\infty}\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{u^2}{2}}du$\nç©ä¸å‡ºä¾†ï¼Œä»¥æ•¸å€¼æ–¹æ³•è¿‘ä¼¼å‡ºä¾†å¾Œå»ºè¡¨çµ¦äººå®¶æŸ¥ æŸ¥ standard normal table e.g. $F_Z(1.325)=?$\næŸ¥è¡¨ $F_Z(1.32)=0.9066$ï¼Œ$F_Z(1.33)=0.9082$ ç”¨å…§æ’ç´„ç•¥å¾— 0.9074 æ€§è³ª\n$\\Phi(-z) = 1 - \\Phi(z)$ ä»»æ„ $\\mu, \\sigma$ çš„ CDF\nå°ä»»ä½• $X \\text{\\textasciitilde}N(\\mu,\\sigma^2)$ $\\frac{X-\\mu}{\\sigma}\\text{\\textasciitilde}N(0,1)$ $F_X(x)=\\Phi(\\frac{x-\\mu}{\\sigma})$ æœŸæœ›å€¼ Expectation å¤§æ•¸æ³•å‰‡ $P(A)=\\lim\\limits_{N \\rightarrow \\infty}\\frac{N_A}{N}$ åŸºæœ¬ä¸ŠæœŸæœ›å€¼æ˜¯åˆ©ç”¨å¤§æ•¸æ³•å‰‡ç®—çš„ mean å€¼ï¼Œé›–ç„¶å¹³å‡å€¼æ˜¯ R.V.ï¼Œä½†ç•¶å¯¦é©—ç„¡çª®å¤šæ¬¡æ™‚ï¼Œæœƒæ”¶æ–‚åˆ°å¸¸æ•¸ï¼Œå› æ­¤ä»¥é€™ç‚ºä¼°ç®—å€¼ Mean å€¼åˆç¨±åšæœŸæœ›å€¼ é›¢æ•£éš¨æ©Ÿè®Šæ•¸ $E\\lbrack X \\rbrack=\\mu_X=\\displaystyle\\sum^{\\infty}_{x=-\\infty}x \\cdot P_X(x)$ é›¢æ•£éš¨æ©Ÿè®Šæ•¸çš„å‡½æ•¸çš„æœŸæœ›å€¼ å°é›¢æ•£éš¨æ©Ÿè®Šæ•¸ X è€Œè¨€ï¼Œå…¶ä»»æ„å‡½æ•¸ g(x) ä¹Ÿæ˜¯ä¸€éš¨æ©Ÿè®Šæ•¸ï¼Œä¹Ÿæœ‰æœŸæœ›å€¼ $g(X)$ çš„æœŸæœ›å€¼å®šç¾©ç‚º $E \\lbrack g(X) \\rbrack=\\displaystyle\\sum^{\\infty}_{x=-\\infty}g(x)\\cdot P_X(x)$ æ€§è³ª $E\\lbrack \\alpha g(X) \\rbrack = \\alpha \\cdot E \\lbrack g(X) \\rbrack$ $E\\lbrack \\alpha g(X) + \\beta h(X) \\rbrack \\\\ =\\alpha \\cdot E \\lbrack g(X) \\rbrack + \\beta \\cdot E \\lbrack h(X) \\rbrack$ $E\\lbrack \\alpha \\rbrack = \\alpha$ å¸¸è¦‹éš¨æ©Ÿè®Šæ•¸å‡½æ•¸çš„æœŸæœ›å€¼ $X$ çš„ $n^{th} moment$ $E \\lbrack X^n \\rbrack = \\displaystyle\\sum^{\\infty}_{x=-\\infty}x^n \\cdot P_X(x)$ X çš„è®Šç•°æ•¸(variance) $E \\lbrack (X-\\mu_X)^2 \\rbrack = \\displaystyle\\sum^{\\infty}_{x=-\\infty} (x-\\mu_X)^2 \\cdot P_X(x)$ è®Šç•°æ•¸ Variance Variance é€šå¸¸ç¬¦è™Ÿè¡¨ç¤ºç‚º $\\sigma^2_X=E \\lbrack (X-\\mu_X)^2 \\rbrack$ éš±å«éš¨æ©Ÿè®Šæ•¸ X å¤šã€Œäº‚ã€çš„è³‡è¨Š variance å¤§çš„è©±ï¼ŒX ä¸è¦‹å¾—æ¥è¿‘ $\\mu_X$ è®Šç•°æ•¸é–‹æ ¹è™Ÿæ˜¯æ¨™æº–å·®(standard deviation) $\\sigma_X = \\sqrt{Variance} \\ge 0$ ç®—æ³• $\\sigma^2_X=E \\lbrack X^2 \\rbrack - \\mu^2_X\\\\ \\Rightarrow E \\lbrack X^2 \\rbrack = \\sigma^2_X + \\mu^2_X$\nå¸¸è¦‹é›¢æ•£åˆ†ä½ˆçš„æœŸæœ›å€¼ / è®Šç•°æ•¸ $X\\text{\\textasciitilde}Bernouli(p)$\n$\\mu_X=1 \\cdot p + 0 \\cdot (1-p) \\\\ = p$\n$\\sigma^2_X = E \\lbrack X^2 \\rbrack - \\mu^2_X \\\\ = \\displaystyle\\sum^1_{x=0}x^2\\cdot p_X(x)-\\mu_X^2 \\\\ =1^2 \\cdot p + 0^2 \\cdot (1-p) - p^2\\\\ =p(1-p)$\n$X$~$BIN(n,p)$\n$\\mu_X = np$\n$\\sigma^2_X = np(1-p)$\n$X$~$GEO(p)$\n$\\mu_X = \\frac{1}{p}$\n$\\sigma^2_X = \\frac{(1-p)}{p^2}$\n$X$~$PASKAL(k,p)$\n$\\mu_X = \\frac{k}{p}$\n$\\sigma^2_X = \\frac{k(1-p)}{p^2}$\n$X$~$POI(\\alpha)$\n$\\mu_X = \\alpha$\n$\\sigma^2_X = \\alpha$\n$X$~$UNIF(a,b)$\n$\\mu_X = \\frac{a+b}{2}$\n$\\sigma^2_X = \\frac{1}{12}(b-a)(b-a+2)$\né€£çºŒéš¨æ©Ÿè®Šæ•¸ å°é€£çºŒçš„éš¨æ©Ÿè®Šæ•¸ X è€Œè¨€ï¼Œå°‡ X çš„å€¼ä»¥ $\\Delta$ ç‚ºå–®ä½ç„¡æ¢ä»¶æ¨å»ä¾†è¿‘ä¼¼ï¼Œä»¥éš¨æ©Ÿè®Šæ•¸ Y è¡¨ç¤º(ç•¶ $\\Delta \\rightarrow$ 0 æ™‚ï¼Œ$X \\approx Y$)ï¼Œç„¶å¾Œå†ç•¶åš PMF è™•ç†ã€‚\n$E \\lbrack X \\rbrack = \\int^{\\infty}_{-\\infty}xf_X(x)dx$ é€£çºŒéš¨æ©Ÿè®Šæ•¸çš„å‡½æ•¸çš„æœŸæœ›å€¼ å°é€£çºŒéš¨æ©Ÿè®Šæ•¸ X è€Œè¨€ï¼Œå…¶ä»»æ„å‡½æ•¸ g(x) ä¹Ÿæ˜¯ä¸€éš¨æ©Ÿè®Šæ•¸ï¼Œä¹Ÿæœ‰æœŸæœ›å€¼ $g(X)$ çš„æœŸæœ›å€¼å®šç¾©ç‚º $E \\lbrack g(X) \\rbrack=\\int^{\\infty}_{-\\infty}g(x)\\cdot f_X(x)dx$ æ€§è³ª $E\\lbrack \\alpha g(X) \\rbrack = \\alpha \\cdot E \\lbrack g(X) \\rbrack$ $E\\lbrack \\alpha g(X) + \\beta h(X) \\rbrack \\\\ =\\alpha \\cdot E \\lbrack g(X) \\rbrack + \\beta \\cdot E \\lbrack h(X) \\rbrack$ $E\\lbrack \\alpha \\rbrack = \\alpha$ å¸¸è¦‹éš¨æ©Ÿè®Šæ•¸å‡½æ•¸çš„æœŸæœ›å€¼ $X$ çš„ $n^{th} moment$ $E \\lbrack X^n \\rbrack = \\int^{\\infty}_{-\\infty}x^n \\cdot f_X(x)dx$ X çš„è®Šç•°æ•¸(variance) $E \\lbrack (X-\\mu_X)^2 \\rbrack = \\int^{\\infty}_{-\\infty} (x-\\mu_X)^2 \\cdot f_X(x)dx$ è®Šç•°æ•¸ Variance å’Œé›¢æ•£éš¨æ©Ÿè®Šæ•¸çš„è³‡è¨Šä¸€æ¨£ å¸¸è¦‹é€£çºŒåˆ†ä½ˆä¹‹æœŸæœ›å€¼/è®Šç•°æ•¸ $X$~$Exponential(\\lambda)$\n$\\mu_X = \\frac{1}{\\lambda}$\n$\\sigma^2_X = \\frac{1}{\\lambda^2}$\n$X$~$Erlang(n, \\lambda)$\n$\\mu_X = \\frac{n}{\\lambda}$\n$\\sigma^2_X = \\frac{n}{\\lambda^2}$\n$X$~$Gaussian(\\mu,\\sigma)$\n$\\mu_X = \\mu$\n$\\sigma^2_X = \\sigma^2$\n$X$~$UNIF(a,b)$\n$\\mu_X = \\frac{a+b}{2}$\n$\\sigma^2_X = \\frac{1}{12}(b-a)^2$\n","date":"2023-02-01T15:18:41+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E6%A9%9F%E7%8E%87%E8%AB%96-ii/","title":"æ©Ÿç‡è«– - II"},{"content":"é›†åˆè«– åè© å­é›†åˆ(Subset) B æ˜¯ C çš„å­é›†(B ä¸èƒ½ç­‰æ–¼ C) $B \\subset C$ è£œé›†(Complement) C æ˜¯ A çš„è£œé›† $C=A^C$ ä¸ç›¸äº¤(Disjoint) $X \\cap Y = \\{\\}$ äº’æ–¥(Mutually Exclusive) ä¸€ç¾¤é›†åˆ $X_1, X_2, \u0026hellip;, X_n$ ä¸­ä»»é¸å…©å€‹é›†åˆ $X_i, X_j$ éƒ½ä¸ç›¸äº¤ï¼Œå‰‡ $X_1, X_2, \u0026hellip;, X_n$ é€™ç¾¤é›†åˆäº’æ–¥ å…¬å¼ De Morgan\u0026rsquo;s Law ${(A \\cup B)}^C=A^C \\cap B^C$ æ©Ÿç‡åè© Outcome (çµæœ) å¯¦é©—ä¸­å¯èƒ½çš„çµæœ Sample Space (æ¨£æœ¬ç©ºé–“) æ©Ÿç‡å¯¦é©—æ‰€æœ‰å¯èƒ½çš„çµæœçš„é›†åˆï¼Œå¸¸ä»¥ $S$ è¡¨ç¤º Event (äº‹ä»¶) å°æ–¼å¯¦é©—çµæœçš„æŸç¨®æ•˜è¿° äº‹ä»¶å¯ä»¥çœ‹åšæ˜¯ outcome çš„é›†åˆï¼Œä¹Ÿæ˜¯ sample space çš„å­é›† æ©Ÿç‡æ˜¯ä¸€å€‹å‡½æ•¸ï¼Œå…¶è‡ªè®Šæ•¸æ˜¯ eventï¼Œæ•…å¯çœ‹åšæ˜¯ä¸€å€‹æ˜ å°„ å…¬ç† Axioms å°ä»»ä½•äº‹ä»¶ $A$ è€Œè¨€, $P(A) \\geq 0$\n$P(S) = 1$\näº‹ä»¶ $A_1, A_2, \u0026hellip;$ äº’æ–¥ $\\Rightarrow$ $P(A_1 \\cup A_2 \\cup A_3 \\cup \u0026hellip;)$\n$=P(A_1)+P(A_2)+P(A_3)+\u0026hellip;$\nè¡ç”Ÿå…¬å¼ Boole\u0026rsquo;s ä¸ç­‰å¼\nå°ä»»æ„ $n$ å€‹äº‹ä»¶ $A_1, A_2, \u0026hellip;, A_n$ è€Œè¨€ $P(\\cup^n_{i=1}A_i \\leq \\Sigma^n_{i=1}P(A_i))$ Bonferroni\u0026rsquo;s ä¸ç­‰å¼\nå°ä»»æ„ $n$ å€‹äº‹ä»¶ $A_1, A_2, \u0026hellip;, A_n$ è€Œè¨€ $P(\\cap^n_{i=1} A_i) \\geq 1 - \\Sigma^n_{i=1} P(A^C_i)$ æ¢ä»¶æ©Ÿç‡ å…¬å¼ $P(X|Y) = \\frac{P(X \\cap Y)}{P(Y)}$ $P(X \\cap Y) = P(X|Y) * {P(Y)} = P(Y|X) * P(X)$ æ€§è³ª $P(X|Y) \\geq 0$ $P(Y|Y) = 1$ $A, B$ äº’æ–¥ $\\Rightarrow P(A \\cup B |Y) = \\frac{P(A)}{P(Y)} + \\frac{P(B)}{P(Y)} = P(A|Y)+P(B|Y)$ å®šç† Total Probability å®šç† è‹¥ $C_1, C_2, \u0026hellip;, C_n$ äº’æ–¥ä¸” $C_1 \\cup C_2 \\cup \u0026hellip; \\cup C_n = S$ï¼Œå‰‡å°ä»»æ„äº‹ä»¶ $A$ $P(A) = P(A|C_1)P(C_1) + P(A|C_2)P(C_2) + \u0026hellip; + P(A|C_n)P(C_n)$ Bayes\u0026rsquo; Rule è²å¼å®šç† è‹¥ $C_1, C_2, \u0026hellip;, C_n$ äº’æ–¥ä¸” $C_1 \\cup C_2 \\cup \u0026hellip; \\cup C_n = S$ï¼Œå‰‡å°ä»»æ„äº‹ä»¶ $A$ $P(C_j|A)=\\frac{P(A|C_j) * P(C_j)}{\\Sigma^n_{i=1}P(A|C_i)*P(C_i)}$\n$= \\frac{P(C_j \\cap A)}{P(A)}$\nç¨ç«‹æ€§ Independence è‹¥å…©äº‹ä»¶ $A, B$ ä¹‹æ©Ÿç‡æ»¿è¶³\n$P(A \\cap B) = P(A) * P(B)$ æˆ–ä»¥ $P(A|B) = P(A)$ è¡¨ç¤º å‰‡ $A, B$ å…©äº‹ä»¶ç¨±ç‚ºæ©Ÿç‡ä¸Šçš„ç¨ç«‹äº‹ä»¶\nè‹¥äº‹ä»¶ $A_1, A_2, \u0026hellip; A_n$ æ»¿è¶³ä¸‹åˆ—æ¢ä»¶ï¼Œå‰‡ç¨±æ­¤ $n$ äº‹ä»¶ç¨ç«‹ $(n\u0026gt;2)$\nå¾ä¸­ä»»é¸ $m$ äº‹ä»¶ $A_{i_1}, A_{i_2}, \u0026hellip; A_{i_m}$ å‡æ»¿è¶³ $P(A_{i_1} \\cap A_{i_2} \\cap \u0026hellip; \\cap A_{i_m}) = P(A_{i_1})P(A_{i_2})\u0026hellip;P(A_{i_m}) , m=2, 3, \u0026hellip;, n$ æ’åˆ—çµ„åˆ äºŒé …å¼ä¿‚æ•¸(binomial coefficient) $(^n_k)$ æœ‰ $n$ å€‹ç•°ç‰©ï¼Œå¾ä¸­å–å‡º $k$ å€‹ å¤šé …å¼ä¿‚æ•¸(multinomial coefficient) $\\frac{n!}{n_1!n_2!\u0026hellip;n_m!}$ æœ‰ m ç¨®ç•°ç‰©ï¼Œæ¯æ¬¡é¸ç‰©å¾ä¸­é¸ä¸€å¾Œæ”¾å›ï¼Œä¾åºé¸ n æ¬¡ï¼Œå…±æœ‰ $m^n$ ç¨® outcomeï¼Œåœ¨æ‰€æœ‰å¯¦é©—çµæœä¸­ï¼Œç¬¬ä¸€ç¨®å‡ºç¾ $n_1$ æ¬¡ï¼Œä»¥æ­¤é¡æ¨ï¼Œé€™æ¨£çš„å¯¦é©—çµæœæœ‰å¤šå°‘ç¨® éš¨æ©Ÿè®Šæ•¸ Random Variable, R.V. ç”¨ä¾†æŠŠ outcome æ•¸å­—åŒ–çš„è¡¨ç¤ºæ–¹å¼ é€šå¸¸ç”¨å¤§å¯«è‹±æ–‡å­—æ¯ æ˜¯å°‡ outcome è½‰æˆå°æ‡‰æ•¸å­—çš„å‡½æ•¸ $X: S \\rightarrow R$ å¾æ¨£æœ¬ç©ºé–“æ˜ å°„åˆ°å¯¦æ•¸ éš¨æ©Ÿè®Šæ•¸çš„å‡½æ•¸ï¼Œä¹Ÿæ˜¯ä¸€å€‹éš¨æ©Ÿè®Šæ•¸ ç¨®é¡ é›¢æ•£éš¨æ©Ÿè®Šæ•¸ (Discrete R.V.)\nå€¼æ˜¯æœ‰é™å€‹ï¼Œæˆ–æ˜¯ã€Œå¯æ•¸çš„ã€ç„¡çª®å¤šå€‹ é€£çºŒéš¨æ©Ÿè®Šæ•¸ (Continuous R.V.)\nå€¼æœ‰ç„¡çª®å¤šå€‹ï¼Œè€Œä¸”ã€Œä¸å¯æ•¸ã€ å¯æ•¸ã€ä¸å¯æ•¸ å¯æ•¸ åŒ…å«çš„æ±è¥¿å¯ä¸€å€‹å€‹è¢«æ•¸ï¼Œç¸½æœ‰ä¸€å¤©æœƒè¢«æ•¸åˆ° e.g. æ­£å¶æ•¸é›†åˆ ä¸å¯æ•¸çš„ ä¸ç®¡æ€éº¼æ•¸ï¼Œè£¡é¢ä¸€å®šæœ‰å€‹æ±è¥¿æœƒæ²’æ•¸åˆ° e.g. 0~1 ä¹‹é–“çš„æ‰€æœ‰æ•¸å­— ç´¯ç©åˆ†ä½ˆå‡½æ•¸ CDF cumulative distribution function\nå°ä»»ä¸€å€‹éš¨æ©Ÿè®Šæ•¸ $X$ï¼Œå®šç¾© CDF ç‚º\n$F_X(x) \\overset{def}{=}P(X \\leq x)$ æ°¸é ç”¨ $F$ è¡¨ç¤º å¸¸è¦‹ç”¨é€”\nç®— X è½åœ¨æŸç¯„åœçš„æ©Ÿç‡ $P(A \u0026lt; X \\le b) = F_X(b)-F_X(a)$ $P(A \\le X \\le b) = F_X(b)-F_X(a)+P(X=a)$ $P(A \u0026lt; X \u0026lt; b) = P(A \u0026lt; X \\le b^-)$ æ€§è³ª é›¢æ•£éš¨æ©Ÿè®Šæ•¸çš„ CDF $F_X(x^+)=F_X(x)$ $F_X(x^-)=F_X(x)-P(X=x)$ é€£çºŒéš¨æ©Ÿè®Šæ•¸çš„ CDF $F_X(x^-)=F_X(x)=F_X(x^+)$ å…±åŒ $F_X(- \\infty)=P(X \\le - \\infty)=0$ $F_X(\\infty)=P(X \\le \\infty) = 1$ $0 \\le F_X(x) \\le 1$ æ©Ÿç‡è³ªé‡å‡½æ•¸ PMF probability mass function å°ä»»ä¸€å€‹ã€Œé›¢æ•£ã€éš¨æ©Ÿè®Šæ•¸ $X$ï¼Œå…¶ PMF ç‚º $p_X(x) \\overset{def}{=}P(X=x)$ PMF å’Œ CDF çš„é—œä¿‚ å°ä»»ä½• $x$ $F_X(x) = \\displaystyle\\sum^{\\lfloor x \\rfloor}_{n=-\\infty}p_X(n)$ $P_X(x)=F_X(x^+)-F_X(x^-)$ æ©Ÿç‡åˆ†ä½ˆ(Probability Distribution) PMF å’Œ PDF éƒ½æ˜¯ä¸€ç¨®æ©Ÿç‡åˆ†ä½ˆ å°‡ç¸½å’Œç‚º 1 çš„æ©Ÿç‡åˆ†ä½ˆåœ¨é»ä¸Š é›¢æ•£æ©Ÿç‡åˆ†ä½ˆ Bernoulli æ©Ÿç‡åˆ†ä½ˆ 1 æ¬¡å¯¦é©—ï¼Œ2 ç¨®çµæœï¼Œåœ¨æ„æŸçµæœç™¼ç”Ÿèˆ‡å¦ $X \\text{\\textasciitilde}Bernoulli(p)$ PMF $p_X(x) = \\begin{cases} p \u0026amp; ,x=1 \\\\ 1-p \u0026amp; x=0 \\\\ 0 \u0026amp; ,otherwise \\end{cases}$ CDF $F_X(x) = \\begin{cases} 0 \u0026amp; ,x\u0026lt;0 \\\\ 1-p \u0026amp; 0 \\leq x \u0026lt;1 \\\\ 1 \u0026amp; ,x \\geq 1 \\end{cases}$ Binomial æ©Ÿç‡åˆ†ä½ˆ å¯¦é©—æˆåŠŸæ©Ÿç‡ç‚º pï¼Œåš n æ¬¡å¯¦é©—ï¼ŒX è¡¨æˆåŠŸæ¬¡æ•¸ $X \\text{\\textasciitilde}BIN(p)$ PMF $p_X(x) = (^n_x)p^x(1-p)^{n-x}$ æˆåŠŸ $x$ æ¬¡ CDF $F_X(x) = \\displaystyle\\sum^{\\lfloor x \\rfloor}_{m=-\\infty} (^n_m)\\cdot p^m \\cdot (1-p)^{n-m}$ Uniform æ©Ÿç‡åˆ†ä½ˆ 1 æ¬¡å¯¦é©—ï¼Œn ç¨®çµæœï¼Œå„çµæœæ©Ÿç‡å‡ç­‰ï¼Œåœ¨æ„æŸçµæœç™¼ç”Ÿå¦ $X \\text{\\textasciitilde}UNIF(a,b)$ PMF $p_X(x) = \\begin{cases} \\frac{1}{b-a+1} \u0026amp; ,x=a,a+1,\u0026hellip;,b \\\\ 0 \u0026amp; ,otherwise \\end{cases}$ CDF $F_X(x) = \\begin{cases} 0 \u0026amp; ,x\u0026lt;a \\\\ \\frac{\\lfloor x \\rfloor - a + 1}{b-a+1} \u0026amp; ,a \\leq x\u0026lt; b\\\\ 1 \u0026amp; ,x \\geq b \\end{cases}$ Geometric æ©Ÿç‡åˆ†ä½ˆ è‹¥å¯¦é©—æˆåŠŸæ©Ÿç‡ç‚º pï¼Œåˆ°æˆåŠŸç‚ºæ­¢ï¼Œåšäº† X æ¬¡å˜—è©¦ æœ‰å¤±æ†¶æ€§ $X \\text{\\textasciitilde}Geometric(p)$ PMF $p_X(x) = \\begin{cases} (1-p)^{x-1} \\cdot p \u0026amp; ,x=1, 2, 3, \u0026hellip; \\\\ 0 \u0026amp; ,otherwise \\end{cases}$ CDF $F_X(x) = \\begin{cases} 1-(1-p)^{\\lfloor x \\rfloor} \u0026amp; ,x \\ge 1 \\\\ 0 \u0026amp; ,otherwise \\end{cases}$ Pascal æ©Ÿç‡åˆ†ä½ˆ è‹¥å¯¦é©—æˆåŠŸæ©Ÿç‡ç‚º pï¼Œåˆ°ç¬¬ k æ¬¡æˆåŠŸç‚ºæ­¢ï¼Œå…±åšäº† X æ¬¡å˜—è©¦ $X \\text{\\textasciitilde}Pascal(k, p)$ PMF $p_X(x) = \\begin{cases} \\binom{x-1}{k-1}(1-p)^{x-k} p^k \u0026amp; ,x=k, k+1, \u0026hellip; \\\\ 0 \u0026amp; ,otherwise \\end{cases}$ CDF $F_X(x) = P(X \\le x) \\\\ = P(åœ¨ x æ¬¡å¯¦é©—ä¸­ \\ge k æ¬¡æˆåŠŸ)\\\\ = P(Y \\ge k), Y~BIN (x,p) \\\\ $ æ•… Pascal åˆç¨± Negative Binomial Poisson æ©Ÿç‡åˆ†ä½ˆ å·²çŸ¥æŸäº‹ç™¼ç”Ÿé€Ÿç‡ç‚ºæ¯å–®ä½æ™‚é–“ $\\lambda$ æ¬¡ï¼Œè§€å¯Ÿæ™‚é–“ç‚º $T$ æ™‚é–“å–®ä½ï¼Œ$X$ ç‚ºè©²è§€å¯Ÿæ™‚é–“å…§ç™¼ç”Ÿè©²äº‹çš„ç¸½æ¬¡æ•¸ã€‚ $X \\text{\\textasciitilde}POI(\\lambda T)$ æœ‰æ™‚å€™ä¹Ÿæœƒä»¥ $\\mu$ ä¾†è¡¨ç¤º $\\lambda T$ PMF $p_X(x) = e^{-\\lambda T} \\cdot \\frac{(\\lambda T)^x}{x!}$ CDF $F_X(x) = \\begin{cases} \\displaystyle\\sum^{\\lfloor x \\rfloor}_{n=-\\infty}e^{-\\lambda T} \\cdot \\frac{(\\lambda T)^n}{n!} \u0026amp; ,x = 0,1,2,\u0026hellip; \\\\ 0 \u0026amp; ,otherwise \\end{cases}$ ","date":"2023-01-31T15:18:41+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E6%A9%9F%E7%8E%87%E8%AB%96-i/","title":"æ©Ÿç‡è«– - I"},{"content":"Share information between processes é€éç¡¬ç¢Ÿä¸Šçš„æ–‡ä»¶æºé€š è¶…æ…¢ é€é kernel buffer æ»¿å¿«çš„ï¼Œä½†é€™æ¨£è¦ä¸€ç›´åœ¨ user mode å’Œ kernel mode ä¾†å›åˆ‡æ›ï¼Œå› ç‚ºkernel buffer åœ¨ kernel space é€é shared memory region shared memory region åœ¨ user space Mechanisms Signals\nCommunication\nData transfer Byte Stream Pipes FIFOs(Named Pipes) stream sockets Message Passing SystemV MsgQ POSIX MsgQ datagram sockets Shared Memory SystemV S.M POSIX S.M Memory Mapping anonymous memory mapping memory mapped file Synchronization\nPipes Related processes parent-child sibling Executing on same machine ç”¨æ³• cmd1 | cmd2 cmd1 ä¸æ˜¯è¼¸å‡ºåˆ° stdoutï¼Œè€Œæ˜¯ç”± kernel ç¶­è­·çš„ bufferï¼Œä¹Ÿå°±æ˜¯ pipe cmd ä¸æ˜¯å¾ stdin ç²å–è¼¸å…¥ï¼Œè€Œæ˜¯å¾ pipe ç²å– cmd1 | cmd2 | \u0026hellip; | cmdn Named Pipes / FIFOs Related / Unrelated processes\nExecuting on same machine\ncreat a FIFO\ncommands mkfifo mknod å˜—è©¦å¯«å…¥æˆ–è®€å– FIFO æ™‚ï¼Œæœƒè¢« redirect åˆ° pipe\nSignal Handling Signal Used by OS to notify running process some event has occured without the process needing to pull for that event process æ”¶åˆ° signal å¾Œæœƒå…ˆåœæ­¢åŸ·è¡Œä¸¦åŸ·è¡Œ signal handler A process did something SIGSEGV(11), SIGFPE(8), SIGILL(4), SIGPIPE(13)\u0026hellip; A process wants to tell another process something SIGCHILD(17) child process terminated User sends sig to foreground processes Ctrl + C SIGINT(2) Ctrl + \\ SIGQUIT(3) Ctrl + Z SIGTSTP(20) disposition æ±ºå®š process é‡åˆ° signal æ™‚è©²æ€éº¼è™•ç†\nTerm teminate process Ign ignore Core terminate the process and dump core Stop stop the process Cont continue the process if it is stopped Signal can\u0026rsquo;t not be caught SIGKILL(9) SIGSTOP(19) Commands trap\nå¯ä»¥ handle signal\nkill kill - L å¯ä»¥çœ‹åˆ° standard signal å’Œ real-time signal\nstandard signal é–‹é ­æ˜¯ SIGï¼Œrealt-time signal æ˜¯ SIGRT\n","date":"2023-01-28T15:31:50+08:00","permalink":"https://roykesydon.github.io/Blog/p/ipc--inter-process-communication/","title":"IPC -- Inter-Process Communication"},{"content":"paper: Training language models to follow instructions with human feedback\nAbstract æŠŠèªè¨€æ¨¡å‹è®Šå¤§ä¸ä»£è¡¨ä»–å€‘æœƒæ›´å¥½åœ°éµå¾ªç”¨æˆ¶çš„æ„åœ–ã€‚\nå¤§çš„èªè¨€æ¨¡å‹æœ‰å¯èƒ½æœƒç”Ÿæˆ untruthful, toxic, not helpful çš„ç­”æ¡ˆã€‚\nè©²è«–æ–‡é€é fine-tuning with human feedback ä¾†è§£æ±ºé€™å•é¡Œã€‚\nä¸€é–‹å§‹æº–å‚™ä¸€ç³»åˆ—äººå·¥æ¨™è¨»çš„ promptsï¼Œç„¶å¾Œç”¨é€™ dataset å° GPT-3 åš fine-tuneã€‚\næ¥ä¸‹ä¾†å†è’é›†ä¸€å€‹ datasetï¼Œå­˜æ”¾ rankings of model outputsï¼Œç”±äººå·¥åˆ¤æ–·è¼¸å‡ºå¥½å£ï¼Œå†ç”¨ RL æŠŠå‰›å‰› fine-tune éçš„ model ç¹¼çºŒ fine-tuneã€‚\næœ€å¾Œæœ‰ 1.3B åƒæ•¸çš„ InstructGPT è¡¨ç¾çš„çµæœæ¯” 175B åƒæ•¸çš„ GPT-3 é‚„å¥½ã€‚\nIntroduction Large language models(LMs) å¯ä»¥é€é \u0026ldquo;prompt\u0026rdquo; ä¾†åŸ·è¡Œå„ç¨® NLP ä»»å‹™ã€‚\nä½†é€™äº›æ¨¡å‹ä¹Ÿå¸¸æœ‰ä¸€äº›éç›®çš„æ€§çš„è¡Œç‚ºï¼Œè«¸å¦‚æé€ äº‹å¯¦ç­‰ç­‰ã€‚\nåŸå› æ˜¯å‡ºåœ¨ç›®æ¨™å‡½æ•¸ä¸Šï¼Œå¤šæ•¸ LMs çš„ç›®æ¨™å‡½æ•¸æ˜¯æ ¹æ“šç¶²è·¯ä¸Šçš„æ–‡æœ¬ç”Ÿå‡ºä¸‹ä¸€å€‹å­—è©ã€‚\né€™å’Œã€Œæ ¹æ“šä½¿ç”¨è€…æŒ‡ä»¤ç”Ÿå‡ºå®‰å…¨ä¸”æœ‰å¹«åŠ©çš„ç­”æ¡ˆä¸åŒã€ã€‚\nä¸Šè¿°çš„å·®ç•°ä½¿èªè¨€æ¨¡å‹çš„ç›®æ¨™æ˜¯ misalignedã€‚\nä½œè€…çš„ç›®æ¨™æ˜¯ç”Ÿå‡º helpfulã€ honest(æ²’æœ‰èª¤å°æ€§è³‡è¨Š)ã€harmless çš„ modelã€‚\nå…·é«”ä½œæ³•ï¼Œä½¿ç”¨ reinforcement learning from human feedback(RLHF)ã€‚\nè¨“ç·´æ­¥é©Ÿ çµæœ Labelers æ˜é¡¯åå¥½ InstructGPT çš„ç­”æ¡ˆï¼Œå‹é GPT-3 çš„ç­”æ¡ˆ\nInstructGPT çš„ç­”æ¡ˆåœ¨ truthfulness å‹é GPT-3 çš„ç­”æ¡ˆ\nInstructGPT çš„ç­”æ¡ˆåœ¨ toxicity ä¸Šå°å‹ GPT-3 çš„ç­”æ¡ˆï¼Œä½†åœ¨ bias ä¸Šæ²’æœ‰\nMethods Dataset æ¨™è¨»äººå“¡å¯«å¾ˆå¤š prompts\nPlain: éš¨ä¾¿å¯«ä»»æ„ä»»å‹™ Few-shot: æƒ³å€‹ instructionï¼Œä¸¦å¯« multiple query/response pairs for that instruction User-based: æ ¹æ“šä¸€äº›ç”³è«‹ä½¿ç”¨ OpenAI API çš„ç”¨æˆ¶ï¼Œæå‡ºæœ‰é—œçš„ prompts ç„¶å¾Œæ ¹æ“šé€™å€‹è¨“ç·´åˆæ­¥æ¨¡å‹ï¼Œä¸¦æŠŠé€™å€‹åˆæ­¥æ¨¡å‹æ”¾åˆ°ä»–å€‘çš„ Playground çµ¦ç”¨æˆ¶ä½¿ç”¨ã€‚\nå†æŠŠç”¨æˆ¶å•çš„å•é¡Œè’é›†å›ä¾†ï¼Œä¸¦åšç¯©é¸ã€‚\nè¨“ç·´ SFT çš„æ¨¡å‹ç”¨ 13k training prompts\nè¨“ç·´ RM çš„æ¨¡å‹ç”¨ 33k training prompts\nè¨“ç·´ PPO çš„æ¨¡å‹ç”¨ 31k training prompts\nModel Supervised fine-tuning(SFT)\næ‹¿ GPT-3 å»è¨“ç·´ 16 å€‹ epochs è·‘ä¸€å€‹ epoch å°±ç™¼ç¾ overfittingï¼Œä½†ç™¼ç¾è¨“ç·´æ›´å¤š epoches å°å¾Œé¢çš„ RM æœ‰ç”¨ï¼Œè€Œä¸”é€™å€‹ model ä¹Ÿåªæ˜¯éæ¸¡ç”¢å“ Reward modeling(RM)\næŠŠ SFT å¾Œé¢çš„ unembedding layer å»é™¤æ‰ï¼Œæ¥ä¸Šç·šæ€§å±¤ï¼Œæœ€å¾Œè¼¸å‡ºä¸€å€‹ scalar reward\nç”¨ 6B RMs\né€™æ¨¡å‹æœƒåƒ prompt å’Œ response\näººå·¥æ¨™è¨˜çš„æ˜¯æ’åºï¼Œä¸æ˜¯åˆ†æ•¸\nå°æ¯å€‹ prompt ç”Ÿå‡º 9 å€‹ç­”æ¡ˆ\nåŸæœ¬æ˜¯ 4 å€‹ï¼Œä½†æ’ 9 å€‹èŠ±çš„æ™‚é–“å¯èƒ½ä¸æœƒåˆ° 4 å€‹çš„å…©å€ï¼Œå› ç‚ºä¸»è¦å¿ƒåŠ›æœƒèŠ±åœ¨è®€ promptã€‚ä½†æ¨™è¨»è¨Šæ¯æœƒå¤šå¾ˆå¤šï¼Œå› ç‚ºéƒ½æ˜¯å…©å…©æ¯”è¼ƒã€‚ è€Œä¸”åœ¨ loss ä¸­æœ€å¤šåªè¦ä¸Ÿå…¥ RM 9 æ¬¡ï¼Œå› ç‚ºå¯ä»¥é‡ç”¨ Pairwise Ranking Loss\nå°ä¸€å€‹ prompt(å‡è¨­æ˜¯ x)ï¼Œå–å‡ºä¸€å°å›è¦†(å‡è¨­æ˜¯ $y_w$ å’Œ $y_l$)ï¼Œç®—å‡º RM(x, $y_w$) å’Œ RM(x, $y_l$)ï¼Œå‡è¨­ $y_w$ æ¯” $y_l$ æ’åºé«˜ï¼Œè®“ RM(x, $y_w$) - RM(x, $y_l$) çš„æ•¸å€¼è¶Šå¤§è¶Šå¥½ Reinforcement learning(RL)\nPPO\n$\\beta$ é‚£é …æ˜¯ KL divergence $\\gamma$ é‚£é …æ˜¯ä¸æƒ³è¦è®“é€™ model å¤ªå°ˆæ³¨åœ¨å¾®èª¿çš„ä»»å‹™ï¼Œè€Œå¤±å»åŸæœ¬åœ¨å…¶ä»– NLP ä»»å‹™ä¹Ÿè¡¨ç¾å¾ˆå¥½çš„åŠŸèƒ½ã€‚ $D_{pretrain}$ æ˜¯ pretraining distribution å¦‚æœ $\\gamma$ ç‚º 0ï¼Œåœ¨è©²å¯¦é©—ä¸­å«åš PPOï¼Œå¦å‰‡ï¼Œç¨±ç‚º PPO-ptx Result ","date":"2023-01-27T17:39:12+08:00","permalink":"https://roykesydon.github.io/Blog/p/instructgpt/","title":"InstructGPT"},{"content":"ä»‹ç´¹ ä¸€ç¨®ç”¨æ–¼è‡ªå‹•åŒ–æ‰¾è¶…åƒæ•¸çš„æ–¹æ³•ï¼Œç”¨åœ¨æ¡æ¨£æ˜‚è²´è€Œä¸”æ˜¯é»‘ç›’å­çš„æƒ…æ³\næµç¨‹ å–æ¨£ä¸€äº›è³‡æ–™é» ç”Ÿå‡ºä¸€å€‹ Surrogate Model(å¯æ¡ç”¨ Gaussian Process) åè¦†åšä»¥ä¸‹äº‹æƒ… ç”¨ Acquisition Function æŒ‘é¸ä¸‹ä¸€å€‹è¦æ¡æ¨£çš„é» é‡æ–°è©•ä¼° Surrogate Model Gaussian Process æœ€çµ‚çš„ prediction æ˜¯ä¸€å€‹ distribution è€Œä¸æ˜¯å–®ä¸€å€‹æ•¸å­— ç”Ÿæˆæ–¹æ³•éœ€å€ŸåŠ© kernel functionï¼Œå¸¸ç”¨ RBF(Radial Basis Function)\n$K(x, x^{\u0026rsquo;}|\\tau)=\\sigma^2exp(-\\frac{1}{2}(\\frac{x-x^{\u0026rsquo;}}{l})^2)$\n$\\sigma$ å’Œ $l$ æ˜¯å…©å€‹å¯ä»¥èª¿æ•´çš„è¶…åƒæ•¸\nAcquisition Function å¯ç”¨è¶…åƒæ•¸ä¾†èª¿ç¯€ exploitation å’Œ exploitation\nUCB(Upper confidence bound) PI(probability of improvement) EI(Expected improvement) ","date":"2023-01-26T01:36:53+08:00","permalink":"https://roykesydon.github.io/Blog/p/bayesian-optimization/","title":"Bayesian Optimization"},{"content":"PPFDT per process file descriptor table æ¯å€‹ process éƒ½æœ‰ å­˜æ”¾ file descriptors file descriptors æ˜¯ä¸€å€‹å”¯ä¸€çš„æ•´æ•¸ï¼Œç”¨ä¾†è­˜åˆ¥ä½œæ¥­ç³»çµ±ä¸Šçš„ open file 0, 1, 2 æ˜¯ Standard input / ouput / error å¤§å°å—é™æ–¼ OPEN_MAXï¼Œäº¦å³èƒ½åŒæ™‚é–“èƒ½é–‹çš„æœ€å¤šæª”æ¡ˆæ•¸ Redirection Input redirection $ wc \u0026lt; /etc/passwd æŠŠ wc çš„ PPFDT çš„ stdin æ”¹æˆ /etc/passwd å¦‚æœæ˜¯ $ wc /etc/passwdï¼Œå‰‡æ˜¯åœ¨ PPFDT è¿½åŠ  /etc/passwd Ouput redirection $ wc \u0026gt; f1 æŠŠ wc çš„ PPFDT çš„ stdout æ”¹æˆ f1 Input \u0026amp; output redirection å…©å€‹å¯ä»¥åŒæ™‚ç”¨\n$ cat \u0026lt; f1 \u0026gt; f2 \u0026gt;\u0026gt; å¯ä»¥ append $ \u0026lt; f1 cat \u0026gt; f2 å¯ä»¥äº‚æ›ä½ç½® Error redirection $ find / -name f1 2\u0026gt; error 1\u0026gt; outputs é€™æ¨£å°±æœƒæŠŠé‚£äº› Permission denied çš„çµ¦åˆ° errorsï¼ŒæˆåŠŸçš„çµ¦åˆ° outputs 2\u0026gt;/dev/null /dev/null æœƒæŠŠä¸Ÿé€²ä¾†çš„æ±è¥¿éƒ½ä¸Ÿæ£„ Copy Descripter é€™å…©è€…ç­‰åƒ¹ $ cat f1 1\u0026gt;op_err 2\u0026gt;op_err $ cat f1 1\u0026gt;op_err 2\u0026gt;\u0026amp;1 make 2 a copy of 1 ","date":"2023-01-21T02:20:43+08:00","permalink":"https://roykesydon.github.io/Blog/p/io-redirection/","title":"IO Redirection"},{"content":"Compile C 4-steps pre-processing compilation assembly linking Types of Object Files Executable object file Relocatable object file Shared object file Core file Formats of Object Files a.out initial version of UNIX COFF SVR3 UNIX PE Win. NT ELF SVR4 Linux ELF format of a program ELF Header Program Header Table .text .rodata .data .bss .symtab .rel.text .rel.data .debug .line .strtab Section Header Table å¯åƒè€ƒ: http://ccckmit.wikidot.com/lk:elf\nProcess Instance of a program running on a computer\nProcess Control Block task_struct\nProcess Identification PID, PPID, SID, UID, EUID.. Process State Information Process Control Information ","date":"2023-01-21T00:08:25+08:00","permalink":"https://roykesydon.github.io/Blog/p/process-management/","title":"Process Management"},{"content":"Features Process control Variables Flow control Functions File \u0026amp; cmd name completions Cmd line editng Cmd history Command Mode Interactive Non- Interactive Command Type internal / Builtin command\næŒ‡ä»¤çš„ç¨‹å¼ç¢¼æ˜¯ shell çš„ä¸€éƒ¨åˆ† e.g., cd, exit ä¸æœƒç”¢ç”Ÿ child process æœ‰äº› internal commandï¼Œæ¯”å¦‚ echo, pwdï¼Œæœƒ internal å’Œ external éƒ½æœ‰å¯¦ä½œ external command\næŒ‡ä»¤çš„ç¨‹å¼ç¢¼åœ¨ç¡¬ç¢Ÿä¸Šçš„æŸå€‹ binary file e.g., clear, ls æœƒç”¢ç”Ÿ child process Common Commands æ¯”è¼ƒå¯¦ç”¨æˆ–å¸¸ç”¨çš„\ngrep\næ‰¾å­—è©\ngrep \u0026lt;string/pattern\u0026gt; -i å¤§å°å¯«ä¸æ•æ„Ÿ -v ä¸åŒ…å«é—œéµå­—çš„ cut æ‰¾ column\n-f æ‰¾å“ªäº› column -d åˆ†éš”ç¬¦æ˜¯ä»€éº¼ æ¯”è¼ƒå…©å€‹æª”æ¡ˆ\ncomm\né¡¯ç¤º file1 ç¨æœ‰çš„åˆ—ã€ file2 ç¨æœ‰çš„åˆ—ã€file1 å’Œ file2 å…±æœ‰çš„åˆ—\ncmp, diff\nå›å‚³ä¸ä¸€æ¨£çš„åˆ—è³‡è¨Š\nunset\næŠŠæŒ‡å®šçš„è®Šæ•¸ç§»é™¤æ‰\ntee\nåƒ stdin è¼¸å‡ºåˆ° stdout å’Œå…¶ä»–æª”æ¡ˆ\nless\nè®€æª”æ¡ˆç”¨\nExpansions White space Control Operators ; è®“æŒ‡ä»¤æ¥è‘—åŸ·è¡Œ \u0026amp; æ”¾åœ¨çµå°¾ï¼Œè®“æŒ‡ä»¤åœ¨èƒŒæ™¯åŸ·è¡Œ \u0026amp;\u0026amp; logical AND || logical OR\nå‰é¢å¤±æ•—æ‰æœƒè·‘å¾Œé¢\n# è¨»è§£ç”¨ \\ escape special characters æ”¾çµå°¾å¥½æ›è¡Œç¹¼çºŒè¼¸å…¥ $? ä¸€å€‹ç‰¹åˆ¥çš„è®Šæ•¸ï¼Œæœ‰ä¸Šå€‹æŒ‡ä»¤çš„ exit code Shell variables User defined Env var Shell history File Globing *, ?, [], -, ! ","date":"2023-01-19T23:00:02+08:00","permalink":"https://roykesydon.github.io/Blog/p/shell/","title":"Shell"},{"content":"GPT æœ¬è³ªä¸Šå°±æ˜¯ Transformer çš„ decoder\nGPT-1 paper: Improving Language Understanding by Generative Pre-Training\nç”¨ semi-supervisedï¼Œå¾Œä¾†è¢«æ­¸ç‚º self-supervised\nUnsupervised pre-training $L_1(U)=\\sum_i logP(u_i|u_{i-k},\u0026hellip;,u_{i-1};\\theta)$\n$U= \\{ u_1,\u0026hellip;,u_n \\}$\n$U$ æ˜¯ä¸€ç³»åˆ—æœªæ¨™è¨˜çš„æ–‡æœ¬ token\n$k$ æ˜¯çª—å£å¤§å°\næ¨¡å‹å¤§è‡´æ¶æ§‹ $h_0=UW_e+W_p$\n$h_1=transformer \\_ block(h_{i-1})\\forall i \\in[1,n]$\n$P(u)=softmax(h_nW^T_e)$\n$U=\\{u_{-k},\u0026hellip;,u_{-1}\\}$\nSupervised fine-tuning $P(y|x^1,\u0026hellip;,x^m)=softmax(h^m_lW_y)$\n$L2(C)=\\sum_{(x,y)}log P(y|x^1,\u0026hellip;,x^m)$\n$L_3(C)=L_2(C)+\\lambda*L_1(C)$\n$C$ æ˜¯ labeled çš„è³‡æ–™é›†ï¼Œå¾®èª¿åŸºæœ¬ä¸Šå°±æ˜¯åœ¨å¾Œé¢åŠ ä¸Šç·šæ€§å±¤\nä½œè€…æœ€å¤§åŒ– likelihood çš„æ™‚å€™æ˜¯ç”¨ $L_3$ è€Œéå–®ç´”çš„ $L_2$\nå¾®èª¿æ‡‰ç”¨ç¯„ä¾‹ è³‡æ–™é›† ç”¨ BooksCorpus è¨“ç·´å‡ºä¾†çš„\næœ‰è¶…é 7000 æœ¬æœªå‡ºç‰ˆçš„æ›¸\næ¨¡å‹çµæ§‹ 12 å±¤ transformer çš„ decoder 768 ç¶­ word embedding 12 å€‹ attention heads å’Œ BERT BASE æ¯”è¼ƒ BERT è«–æ–‡æ¯”è¼ƒæ™šå‡ºï¼Œä½† BASE çš„æ¨¡å‹æ¶æ§‹å’Œ GPT æœ‰ç›¸ä¼¼ä¹‹è™•ï¼Œ\nBASE æ˜¯ 12 å±¤çš„ decoderï¼Œword embedding å’Œ attention head çš„ç¶­åº¦æˆ–æ•¸é‡å’Œ GPT-1 ç›¸åŒ\nGPT-2 paper: Language Models are Unsupervised Multitask Learner\nGPT-2 é™¤äº†ç”¨æ›´å¤§çš„çš„æ¨¡å‹å’Œæ›´å¤§çš„è³‡æ–™é›†ï¼ŒæŠŠé‡é»æ”¾åœ¨ zero-shot ä¸Šï¼Œé›–ç„¶åœ¨ GPT-1 çš„è«–æ–‡å°±æœ‰æé zero-shot\nè³‡æ–™é›† é€™æ¬¡åšäº†ä¸€å€‹å«åš WebText çš„è³‡æ–™é›†ï¼Œæœ‰ç™¾è¬ç´šåˆ¥çš„ç¶²é \nCommon Crawl å¤§å‹çˆ¬èŸ²å°ˆæ¡ˆï¼Œæœ‰å¤§é‡ç¶²é è³‡æ–™ï¼Œä½†å……æ–¥äº†åƒåœ¾è¨Šæ¯\nWebText WebText çš„è³‡æ–™ä¾†æºæ˜¯ reddit ä¸Šçš„å¤–éƒ¨é€£çµï¼Œåªè¦æœ‰è‡³å°‘ä¸‰å€‹ karmaï¼Œå°±æœƒè¢«æ¡ç´ï¼Œç”±æ­¤å–å¾—å“è³ªè¼ƒå¥½çš„ç¶²é è³‡æ–™ã€‚é€éé€™ç¨®æ–¹æ³•ï¼Œå–å¾—äº† 4500 è¬å€‹é€£çµã€‚ä¸¦ç”¨Dragnet (Peters \u0026amp; Lecocq, 2013) and Newspaper content extractors æŠŠæ–‡å­—è¨Šæ¯å¾ HTML ä¸­æŠ“å‡ºä¾†\næ¶æ§‹ å’ŒåŸæœ¬å·®ä¸å¤šï¼Œè®Šæˆæœ‰ 1.5B åƒæ•¸çš„ Transformer decoder\nzero-shot ä¸éœ€è¦ä¸‹æ¸¸ä»»å‹™çš„æ¨™è¨˜è³‡æ–™\næ”¹æŠŠä»»å‹™è¼¸å…¥é€²æ¨¡å‹\nç›®å‰å•é¡Œ ç¾åœ¨çš„æ¨¡å‹æ³›åŒ–èƒ½åŠ›ä¸å¤ªå¥½ Multitask learning åœ¨ NLP ä¸Šä¸å¤ªå¸¸ç”¨ï¼ŒNLP ç¾åœ¨ä¸»æµé‚„æ˜¯åœ¨é è¨“ç·´æ¨¡å‹ä¸Šåšå¾®èª¿ä»¥æ‡‰å°ä¸‹æ¸¸ä»»å‹™ å°æ¯å€‹ä¸‹æ¸¸ä»»å‹™éƒ½å¾—é‡æ–°è¨“ç·´æ¨¡å‹ å¾—è’é›† labeled è³‡æ–™ çµæœ GPT-3 paper: Language Models are Few-Shot Learners\næ‘˜è¦ æœ‰ 175B çš„åƒæ•¸ï¼Œç”±æ–¼æ¨¡å‹æ¥µå¤§ï¼Œè¦åœ¨å­ä»»å‹™å¾®èª¿æœƒæˆæœ¬å¾ˆå¤§ï¼Œæ‰€ä»¥ä¸åšä»»ä½•æ¢¯åº¦æ›´æ–° åœ¨å¾ˆå¤š NLP ä»»å‹™æœ‰å‚‘å‡ºçš„æˆæœ å¯ä»¥ç”Ÿå‡ºäººé¡é›£ä»¥å€åˆ†çš„æ–°èæ–‡ç«  ç›®å‰æœ‰çš„å•é¡Œ è¦åœ¨å­ä»»å‹™å¾®èª¿ï¼Œéœ€è¦è³‡æ–™é›† å¾®èª¿å¾Œåœ¨æœ‰äº›å­ä»»å‹™ä¸Šè¡¨ç¾å¥½ä¸ä»£è¡¨ä½ é è¨“ç·´æ¨¡å‹ä¸€å®šæ³›åŒ–èƒ½åŠ›é«˜ äººé¡ä¸éœ€è¦å¤§é‡ labeled è³‡æ–™å»å®Œæˆå°ä»»å‹™ è©•ä¼°æ–¹å¼ åˆ†ç‚ºä¸‰ç¨®ï¼Œfew / one / zero-shot learning æ¶æ§‹ åŸºæœ¬ä¸Š GPT-3 å’Œ GPT-2 æ¶æ§‹ä¸€æ¨£\nç›¸åŒ modified initialization pre-normalization reversible tokenization described therein ä¸åŒ æŠŠ Sparse Transformer çš„ä¸€äº›ä¿®æ”¹æ‹¿éä¾†ç”¨ GPT-3 Small æ˜¯ GPT-1 çš„å¤§å° GPT-3 Medium æ˜¯ BERT Large çš„å¤§å° GPT-3 XL å’Œ GPT-2 ç›¸è¿‘ï¼Œæ¯”è¼ƒæ·ºä¹Ÿæ¯”è¼ƒå¯¬\nBatch Size å¤§å° æ¨¡å‹å°çš„æ™‚å€™éœ€è¦å°ä¸€é»ï¼Œé€éé€™ç¨®é¡å¤–çš„ noise ä¾†é¿å… overfitting(ä¸ç¢ºå®šæ˜¯ä¸æ˜¯çŒœæƒ³)\nè³‡æ–™é›† Common Crawl æ¶æ§‹æ¯” GPT-2 å¤§å¾ˆå¤šï¼Œæ‰€ä»¥å›é ­è€ƒæ…®é€™å€‹è³‡æ–™é›†\nä¸‰æ­¥é©Ÿ å…ˆéæ¿¾ï¼Œé€é reddit é‚£å€‹é«˜å“è³ªçš„è³‡æ–™é›†ï¼Œä¾†è¨“ç·´ä¸€å€‹æ¨¡å‹åˆ†é¡é«˜å“è³ªå’Œä½å“è³ªçš„ç¶²é ã€‚ é€é LSH æ¼”ç®—æ³•æŠŠç›¸ä¼¼çš„æ–‡æœ¬éæ¿¾æ‰ æŠŠä¸€äº›å·²çŸ¥é«˜å“è³ªçš„è³‡æ–™é›†ä¹ŸåŠ é€²ä¾† é€™æ˜¯ä¸€å€‹ Batch è£¡æœ‰ 60% ä¾†è‡ª Common Crawl(filtered) çš„æ„æ€ Wikipedia é›–ç„¶ç¸½é‡æ¯”è¼ƒå°‘ï¼Œä½†ä¹Ÿæœ‰ 3% çš„æ¡æ¨£ç‡\nçµæœ è¨ˆç®—é‡æŒ‡æ•¸å¢é•·ï¼Œloss å»æ˜¯ç·šæ€§çš„å¾€ä¸‹é™\npaper è£¡æœ‰å¾ˆå¤šä»»å‹™çš„å¯¦é©—çµæœï¼Œé€™é‚Šå°±ä¸é™„ä¸Šäº†\nLimitations åœ¨æ–‡æœ¬ç”Ÿæˆä¸Šé‚„æ˜¯æ¯”è¼ƒå¼±ï¼Œç”Ÿå¾ˆé•·çš„æ±è¥¿ï¼Œå¯èƒ½æœƒé‡è¤‡è‡ªå·±èªªéçš„è©±ã€å¤±å»é€£è²«æ€§ã€è‡ªç›¸çŸ›ç›¾ç­‰ç­‰\nåœ¨æœ‰äº›é›™å‘æ€§çš„ä»»å‹™ä¸Šå¯èƒ½è¡¨ç¾æ›´å·®\nå½±éŸ¿ å¯èƒ½è¢«ç”¨ä¾†æ•£å¸ƒä¸å¯¦æ¶ˆæ¯ã€åƒåœ¾éƒµä»¶ç­‰ç­‰ åè¦‹ çµè«– åœ¨å¾ˆå¤š NLP ä»»å‹™å¯ä»¥åšåˆ°æ¥è¿‘ SOTA å¾®èª¿æ¨¡å‹çš„æˆæœ\n","date":"2023-01-19T01:50:07+08:00","permalink":"https://roykesydon.github.io/Blog/p/gpt-%E4%B8%89%E9%83%A8%E6%9B%B2/","title":"GPT ä¸‰éƒ¨æ›²"},{"content":"VM A software implementation of a machine\nSystem VM æä¾›å¯ä»¥åŸ·è¡Œ GuestOS çš„ complete system platform Process VM åƒä¸€å€‹ä¸€èˆ¬çš„ app ä¸€æ¨£åœ¨ hostOS è·‘ï¼Œæ”¯æ´å–®ä¸€å€‹ process Hypervisor åˆç¨±è™›æ“¬æ©Ÿå™¨ç›£è¦–å™¨ï¼ˆè‹±èªï¼švirtual machine monitorï¼Œç¸®å¯«ç‚ºVMMï¼‰ ç”¨ä¾†ç®¡ç† VM\nå…è¨±å¤šå€‹ GuestOS è·‘åœ¨ host computer\nType-1\nbare-metal hypervisors ç›´æ¥åœ¨ç¡¬é«”ä¸ŠåŸ·è¡Œ Type-2\nhosted hypervisors åœ¨ hostOS ä¸ŠåŸ·è¡Œ directories Binary\ne.g., bin, sbin, lib, opt bin: æœ‰é—œ user çš„æŒ‡ä»¤ sbin: ç®¡ç†å“¡æœƒç”¨çš„æŒ‡ä»¤ opt: optional softwareï¼Œå¤šæ•¸æ©Ÿå™¨ä¸­é€™æ˜¯ç©ºçš„ Configuration\ne.g., boot, etc, Data\ne.g., home, root, srv, media, mnt, temp In memory å­—é¢ä¸Šçš„æ„æ€ï¼Œä¸åœ¨ hard diskï¼Œåœ¨ memory\ne.g., dev, proc, sys System Resources\ne.g., usr Variable Data\ne.g., var ","date":"2023-01-19T01:50:07+08:00","permalink":"https://roykesydon.github.io/Blog/p/linux-%E7%91%A3%E4%BA%8B/","title":"Linux ç‘£äº‹"}]