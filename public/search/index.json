[{"content":"paper: BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\n現在回頭寫 BERT 論文筆記感覺有點怪，之前已經寫過什麼 RoBERTa 之類的。\n不過現在因應實驗室讀書會要求，還是看一下論文也寫一下筆記。\nAbstract 本文提出了 BERT，一種基於 Transformer Bidirectional Encoder 的語言表示模型。\nBERT 旨在透過 unlabeled text 進行 pretrain。\n因此，只需要一個額外的輸出層就可以對預訓練的 BERT 進行微調，在各種任務上取得 SOTA。\nIntroduction 「語言模型做預訓練」已被證明可以有效改善多種 NLP 任務。\n將預訓練模型應用在下游任務，有兩種策略：\nFeature-based 把 pretrained 的 representations 作為額外的特徵 Fine-tuning 根據特定任務引入額外參數，並簡單地微調所有參數 這兩種方法在預訓練期間共用同個 objective function，並用單向語言模型來學習 representation。\n作者認為當前的技術限制了預訓練的表示能力，特別是在 Fine-tuning 方法上。\n主要的問題在於語言模型是單向的，限制了預訓練期間可以使用的架構的選擇。這種單向的架構可能在一些任務有害，特別是對於那些需要兩個方向的 context 的任務。\n本文提出的 BERT 改善了現有的 Fine-tuning 方法，用 Transformer 的 Bidirectional Encoder 來訓練語言模型。\nBERT 透過受到 Cloze task（填空）啟發的 masked language model(MLM)，作為預訓練目標。MLM 隨機地遮蔽一些輸入的一些 token，目標是根據上下文來回推原詞，使 representation 可以融合左右兩邊的 context。\n除了 MLM，作者還利用 next sentence prediction（NSP）任務來訓練 BERT。\n本文貢獻如下：\nBERT 證明了雙向預訓練對 representation 的重要性。\nBERT 展現出預訓練的 representation 減少了許多針對 NLP 任務精心設計架構的需求。 BERT 是第一個基於 Fine-tuning，在大量 sentence-level 和 token-level 任務上取得 SOTA 的模型。\nBERT 推進了 11 個 NLP 任務的 SOTA。\nRelated Work Unsupervised Feature-based Approaches 學習廣泛適用的 representation of words 一直是活躍的研究領域，甚至在非神經網路的領域也是。\n預訓練的 word embeddings 與從頭訓練的 embedding 相比，有顯著改進。\n這些方法頁被推廣到 coarser granularities，像是 sentence embedding 或是 paragraph embedding。\n有研究證明 cloze task 提高了生成模型的 robustness。\nBERT 框架有兩步驟：\nPre-training 在不同的預訓練任務中，用 unlabeled data 來 fine-tune。 Fine-tuning 使用預訓練的參數初始化，在利用下游任務的 labeled data 對所有參數微調。 BERT 的一個特點是他具備跨不同任務的統一架構，預訓練架構和下游任務最終架構差異不大。\nModel Architecture\n本文表示方法\nL: Transformer 的層數 H: hidden size A: self-attention heads 的數量 model size\nBASE: L=12, H=768, A=12, 110M parameters 和 GPT 相同 LARGE: L=24, H=1024, A=16, 340M parameters Input/Output Representations\nInput representation 可以在 token sequence 中明確表示單個 sentence 和一對 sentence。\nsentence 可以是連續文本的任意範圍，而不是實際的句子。 sequence 是輸入的 token sequence，可以是單個 sentence 或是一對 sentence。 每個 sequence 的第一個 token 始終是特殊的分類 token \u0026ndash; [CLS] 對於兩個句子放在一個序列的情況，用 [SEP] 隔開 Token Embeddings\n作者使用 WordPiece embeddings，有 30000 個詞彙。 learned embedding\n對每個 token 添加這個東西，表示屬於 sentence A 還 sentence B Pre-training BERT Masked LM 直觀上，有理由相信深度的雙向模型會比單像串連起來的淺層模型更強大。\n不幸的是 standard condition language model 只能單向訓練，因為雙向會允許每個單詞「間接看到自己」。\n為了訓練 deep bidirectional representations，本文隨機遮蔽了一定比例的 tokens，並預測這些 token，這種方法稱為 masked language model，或常被稱為 cloze task。\n作者會用 [MASK] 做預訓練，但有個問題是 [MASK] 在 fine-tuning 期間不會出現，造成預訓練和微調之間的 mismatching，為了緩減這種情況，並不會總是用 [MASK] 替代 masked token。\n要替換 token 的時候，有 80% 的時間是 [MASK]，10% 是隨機 token，10% 是原本的 token。\nNext Sentence Prediction (NSP) 許多重要下游任務，比如 Question Answering (QA) 和 Natural Language Inference (NLI) 是基於兩個句子間的關係。\nNSP 就是為了理解句子間的關係而用的。\n每次挑句子 A 和 B 的時候，有 50% 的機會 B 是 A 的下一個句子，有 50% 是隨機的。\n針對 NSP 的預訓練對 QA 和 NLI 都很有用。\n預訓練資料 用 BookCorpus 和 English Wikipedia 來訓練 BERT。\n對於 English Wikipedia，只提取 text passages，忽略 lists, tables, headers。\n為了提取長的連續序列，用 document-level 的 corpus 而不是打亂的 sentence-level corpus 非常重要。\nAblation Studies Effect of Pre-training Tasks No NSP 只有 MLM LTR \u0026amp; No NSP Left-to-Right 只看左邊的 context 發現刪除 NSP 會顯著傷害對 QNLI 等資料集的性能。\nLTR 在所有任務上都比 MLM 差。\n雖然可以像 ELMo 單獨訓練 LTR 和 RTL，並且把他們結合起來\n但有以下缺點：\n比單向模型貴兩倍 對 QA 任務不直觀，因為 RTL 無法根據問題給出答案 不如深度雙向模型強大，因為其可以直接在每一層看到左右的 context Feature-based Approach with BERT 作者也研究了用 feature-based 的效果，發現具備競爭力。\n在他的實驗中，用預訓練 Transformer 的 top 4 隱藏層的 token 串街效果最好。\n","date":"2023-08-05T00:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/bert-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"BERT 論文閱讀"},{"content":"圖簡介 Graph\n表示 Entity (nodes) 間的 relations (edges) 組成 Vertex attributes (V) Edge attributes and directions (E) Global attributes (U) 下文簡稱 U, V, E 可以表示成圖的範例\nImages 相鄰 pixel 建無向邊 Text 詞和下一個詞建單向邊 Molecules 分子的連接處建無向邊 Social networks 人和人之間建無向邊 定義問題 種類 Graph-level Node-level Edge-level 個別講的是基於什麼東西做分類，比如對每個人（node）分類一個陣營，就算 Node-level 挑戰 儲存邊的關係 鄰接矩陣 在節點多的情況下佔用空間大，而且可能非常稀疏 同一張圖，換個點的順序後鄰接矩陣看起來就會不同 難以保證這些東西餵入神經網路後輸出相同 可以用兩個 list，一個儲存邊的向量，另一個是 Adjacency list，依序紀錄邊的關係 稀疏矩陣 難以用 GPU 運算 Graph Neural Network GNN 是對圖上所有屬性的 optimizable transformation，而且可以保持 graph symmetries (permutation invariances，把 node 排序後結果不變)\n下文用的 GNN 是 message passing neural network\ngraph-in, graph-out 不改變圖的 connectivity 最簡單的 GNN U, V, E 個別餵給不同的 MLP，組成一個 GNN 的 layer MLP 單獨餵入每一個點，不考慮連接訊息，保持了 graph symmetries 預測 假如要對每個頂點做預測，最後再加個全連接層分類 pooling 假如要對一個沒有向量的頂點做預測，我們可以用 pooling，蒐集相鄰邊和全局向量的資訊 對於沒有頂點資訊的圖，我們可以用 pooling layer 獲取全部點的資訊，再做分類 對於沒有邊資訊的圖，我們也可以用 pooling 去從相鄰點和全局向量獲得資訊 對於沒有全局向量的圖，我們可以用 pooling 去從全部的點或邊獲得資訊 缺陷 中間的 layer 沒有利用圖的訊息，都是各自進入各自的 MLP 做轉換 Passing messages 在做轉換前，先做一些 pooling\n匯聚頂點資訊 不是單單把點向量進行轉換，而是和相鄰的點一起做 aggregation 後再做轉換 如果 aggregation 是加總，和卷積有一點像，只不過是權重一樣的版本 匯聚頂點和邊的資訊 可以先把頂點匯聚給邊，再把邊匯聚回頂點，反之亦然 順序不同會導致不同結果 兩種方法可以一起同步做，交替更新 全局資訊 每次 layer 只看鄰居，要傳遞到遠的點須要走很多層 導入 master node (context vector)，他連接了所有的點和邊 相關主題 採樣\n考量到計算梯度可能需要儲存過多的中間資訊，可以考慮採樣一些點，只在子圖上做計算 Batch\n每個點鄰居各數不同，使做 batch 成為有挑戰性的問題。 Inductive Bias\ngraph symmetries Aggregation\n目前沒有一個最佳選擇 Graph Convolutional Network\nnode 是根據鄰居 node 去做某種 aggregate，事後再做更新 由於每次都看鄰居，假如有 k 層，可以把圖看做解 n 個子圖，每個子圖就是基於每個點去走 k 步所形成的 Graph Attention Network\n用 attention 決定其它點的權重，而不像 GCN 一樣把鄰居加起來 ","date":"2023-08-04T00:27:55+08:00","permalink":"https://roykesydon.github.io/Blog/p/gnn-%E4%BB%8B%E7%B4%B9/","title":"GNN 介紹"},{"content":"paper: Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset\nAbstract 目前的動作分類資料集 (UCF-101 和 HMDB-51) 的影片非常缺乏，使辨識「良好的影像架構」變得困難， 使多數方法在現有的小規模 benchmark 的表現差不多。為此本文根據新的 Kinetics Human Action Video dataset 對 SOTA 架構進行了重新評估。\nKinetics 有 400 個人類動作類別。每個類別有 400 個 clip。從 YouTube 上獲取的，而且每個 clip 來自 unique 的 youtube 影片。\n本文分析了當前架構在 Kinetics 上動作分類任務的表現，也評估 Kinetcis 用作預訓練的效果。\n本文提出了一種基於 2D ConvNet inflation 的 Two-Stream Inflated 3D ConvNet (I3D)。\nI3D 的擴展方法讓 ImageNet 上已經取得成功的架構可以被利用在解決影像任務上。\n結果表明，經過在 Kinetics 上預訓練後，I3D 在動作分類方面顯著提高了 SOTA，在 HMDB-51 上達到 80.9%，在 UCF-101 上達到 98.0%。\nIntroduction 在 ImageNet 上預訓練模型的效果很好，但在影片領域，預訓練成效一直是一個未知的問題。因為流行的動作識別 benchmark 都非常小，約略只有 10k 個影片。\nKinetics 有 400 個人類動作類別。每個類別有 400 個 clip，而且每個 clip 都來自一個 unique 的 Youtube 影片。\n本文實驗策略是在 Kinetics 上預訓練，再在 HMDB-51 和 USC-101 上微調，結果顯示出預訓練總是能提高性能，但提升多寡因架構而異。\n本文提出新架構，稱為「Two-Stream Inflated 3D ConvNets」(I3D)，建立在 SOTA 的影像分類架構上，並將 filters 和 pooling kernel 膨脹成 3D。\n基於 Inceptionv1 的 I3D 在 Knetics 上預訓練後，性能遠超過當前的 SOTA 架構。\n在本文的模型中，並沒有考慮更多經典方法，比如 bag-of-visual-words representation，但 Kinetics 是公開的，因此其他人可以進行後續研究。\nAction Classification Architectures 目前影片架構中的一些主要區別如下：\n卷積是 2D 還 3D 的 是否只是 RGB 影片，還是包含事先計算的 optical flow 對於 2D ConvNets，訊息是怎麼在 frame 之間傳遞的 這部分可以使用 temporally-recurrent layers，比如 LSTM，或是用隨時間的 feature aggregation 來完成。 在本文中，考慮了涵蓋大部分現有架構的模型子集：\n2D ConvNets 頂部有 LSTM 的 ConvNet 有兩種 stream fusion 的 two-stream networks 3D ConvNets C3D 由於參數維度較高，以及缺乏 labeled video data，以前的 3D ConvNet 相對較淺（最多 8 層）。\n本文發現諸如 VGG-16 和 ResNet 等很深的影像分類網路可以輕鬆擴展成 spatio-temporal feature extractors，並且他們的預訓練權重也可以提供有價值的初始化。\n本文也發現 two-stream 的作法依然有用。\nfig2. K 是影片中的 frame 的總數，N 是相鄰 frames 的子集合。\n上圖是本文實驗的五種架構，前四種是之前的做法，最後一種是提出的新作法。 上圖中除了 C3D 外都有用到 ImageNet 預訓練的模型。\n時間是根據 input 的 frame 換算出來的，fps 是 25，除了 LSTM 那個比較特別，因為 LSTM 那個是每 5 frame 取 1 frame，所以時間是 5 倍。\n之前的做法 ConvNet+LSTM\n有一種做法是把每個 frame 獨立餵給 2D Conv，然後再把預測做彙整，符合 bag of words image modeling 的精神，但這樣會忽略時間結構上的資訊，比如無法判斷開門或關門。\n所以最好在後面加一個 recurrent layer，所以這邊就用 Inception-V1 結合 LSTM。\n原始的影片 stream 是 25 fps，這邊每 5 frame 採樣一次。\n3D ConvNets\n和一般的卷積神經網路差不多，只是具有 spatio-temporal filters。\n但由於額外的 kernel 維度，相比 2D Conv 會有更多參數，也使他們更難訓練。\n而且這樣會無法發揮 ImageNet 預訓練的好處，因此之前的工作都定義了相對淺層的架構，並且從頭訓練。\nbenchmark 中的表現備受期待，但和 SOTA 比沒有競爭力，也因此成為本文實驗的良好候選者。\n本文用的是 C3D 的小變體，差異在於所有卷積層和 FC 層的後面都用了 BN。 而且在第一個 pooling layer 用的 stride 是 2，好減少記憶體的使用，比用更大的 batch，這在 BN 中非常重要。\nTwo-Stream Networks\nRoy：這裡由於比較複雜，我要改提 two-stream 的原始論文（Two-Stream Convolutional Networks for Action Recognition in Videos）說明這東西是什麼\n簡而言之就是分成兩個部分：\n空間資訊：\n用影片的一個 frame　經過卷積神經網路達成，這個 frame 用來提取影像中的物件資訊，比如打排球這動作可能辨識出排球就非常好判定，所以用某個 frame 來提取空間資訊。\n動作資訊：\n這邊用一連串的光流（optical flow）圖來達成，光流是物體（pixel）在兩個 frame 間的位移向量，估計方法有很多，這裡不一一舉例。\n上圖出自 Two-Stream Convolutional Networks for Action Recognition in Videos，圖 c 就是光流，具有兩個方向，指出像素的位移，圖 d 是水平方向的視覺化，圖 e 是垂直方向的視覺化。\n再把這些光流圖餵給卷積神經網路，用作動作資訊的判別。\n值得一提的是他是 late fusion，而且是用加權平均，不是像一般想的把特徵結合再做其他處理。\nThe New: Two-Stream Inflated 3D ConvNets 作者把成功的 2D 分類模型簡單地轉換為 3D\nInflating 做法是把方形的 filter 改成立方體，把 N x N 的 filter 改成 N x N x N 的 filter，但這只有架構上的參考。\nBootstraping 把權重也給轉換到 3D 架構的方法。\n作者觀察到影像可以透過反覆複製貼上來生出一個「不會動的無聊影片」， 透過這些影片，3D 模型可以透過這種方式在 ImageNet 上 implicitly pretrain，做法就是讓 3D filter 吃無聊影片的輸出和 2D filter 吃單一 frame 的輸出相同，做法如下：\n我們可以沿時間維度重複 2D filter N 次，把這權重給 3D filter，同時把權重除以 N，達到這種效果。\nPacing receptive field growth in space, time and network depth 以往在圖片上對水平和垂直軸的對待是平等的，pooling kernel 和 stride 都一樣。 使感受野在兩個維度上隨著模型越來越深，慢慢平等增長。\n但是時間軸用對稱的感受野不一定最好，而該取決於 frame rate 和 image dimensinos。 如果時間相對於空間增長太快，可能會混淆不同對象的邊緣，影響早期的特徵檢測。如果增長太慢，可能無法很好地捕捉場景動態。\n實驗中，輸入影片的 fps 是 25。\n作者發現在前兩個 max pooling layer 不在時間軸 pooling（透過用 1 x 3 x 3 的 kernel，並且時間軸的 stride 是 1），並在其他 max pooling layer 都用 symmetric kernels 和 stride 是有幫助的。\n最後的 average pooling layer 是用 2 x 7 x 7 的 kernel。\n作者用 64 frame 訓練，但用整個影片測試。（averaging predictions temporally）\n我想了一下，250 / 64 除不進，但是我看 code 發現他好像寬高 224 * 224 的照片會在最後經過 Average pool 後變成 1 * 1，所以他可以直接用 1 * 1 * 1 的卷積核把輸入通道改成分類數，再把時間軸的結果平均。\nTwo 3D Streams 分別訓練兩個網路，並在測試階段對預測進行平均。\n這邊作者說光流的演算法某種意義上是 recurrent（例如，對於 flow fields 進行 iterative optimization），我不太懂這邊是什麼意思，我想作者用的光流演算法應該是透過某種類似 EM 演算法那種不斷迭代去逼近數值的演算法，但作者提到「或許是因為缺乏 recurrence，我們發現雙流有價值」，我不太懂為什麼需要 recurrence 效果才會好。\n但結論是 two-stream 依然具備價值。\nImplementation Details 這邊講滿詳細的，有興趣可以去原文看。 只提一下幾點:\n光流演算法是用 TV-L1。 除了類似 C3D 的 3D ConvNet 都用使用 ImageNet 預訓練的 Inception-V1 作為 base network。 對於較短的影片，會重複循環以滿足模型的輸入介面 測試時會在中間剪裁 224 x 224 The Kinetics Human Action Video Dataset Kinetics 有 400 個人類動作類別。每個類別有 400 個 clip，而且每個 clip 都來自一個 unique 的 Youtube 影片，共有 24 萬個訓練影片。\n每個 clip 都大約 10 秒，而且沒有未剪的影片。\n測試集每個 class 包含 100 個 clip。\nExperimental Comparison of Architectures I3D 在所有資料集上都表現最好，甚至是在 UCF-101 和 HMDB-51 這種小資料集上也是如此，這意味著 ImageNet 預訓練的好處有成功擴展到 3D ConvNet。\n多數模型在 UCF 上都表現得比 Kinetics 上好，顯現出資料集的難度差距。\n但是在 HMDB 表現得較差，原因可能是 HMDB 故意弄得很難，作者有舉例，很多 clip 在完全相同的場景會有不同的動作。\n作者有提到說 I3D 特徵比較好遷移的一種解釋是它具備 high temporal resolution， I3D 在 25 fps 的影片中用 64 frames 做訓練，使它能捕捉動作的 fine-grained 時間結構。\nExperimental Evaluation of Features Kinetics 上做預訓練效果明顯比 ImageNet 好。\nDiscussion Kinetics 上的預訓練對於遷移學習有明顯好處，但對於其他影像任務，比如影像語義分割是否有好處仍待觀察。\n目前對於架構沒有全面探索，比如沒有採用 action tubes 或是 attention 機制。\n","date":"2023-07-23T00:27:55+08:00","permalink":"https://roykesydon.github.io/Blog/p/i3d-%E8%AB%96%E6%96%87/","title":"I3D 論文"},{"content":"前言 要弄 Hololens 2 的開發環境要一堆有的沒的麻煩東西，紀錄一下避免之後要重裝\n原本很怕版本對不上很麻煩，但實際用起來好像還好\n注意，這不是最小安裝，有些東西我不確定是不是必要的，但我怕麻煩就裝了\n後續請參考微軟的教學\n計畫版本紀錄 (2023/07/03) Unity 2020.3.48f1 (LTS) MRTK 2.8.3 Mixed Reality OpenXR Plugin 1.8.0 我個人的版本紀錄 (2021/07/03) Unity 2021.3.27f1 (LTS) 我沒注意到我一開始選錯，但也可以跑，之後 MRTK 2.8.3 Visual Studio 2022 Mixed Reality OpenXR Plugin 1.8.0 作業系統要求 必須是 Windows 專業版以上，因為要用 Hyper-V 先去 BIOS 開 Virtualization Technology 開啟 Hyper-V 前置步驟 安裝 windows SDK\n聽說裝完最新的後，建議再多裝幾個版本 我個人只有裝最新的 安裝 visual studio\n好像會根據 MRTK 的版本有對應的版本要求，不能無腦裝最新 據說要選 「C++ 開發」和「通用 Windows 平台開發」 右邊好像還要選 USB 設備連接 C++ 通用 Windows 平台工具 安裝 Hololens 2 模擬器\n這是給 build 好的程式用的，不是在說 Unity Editor 裡面的手 安裝 Unity\n建議透過 Unity Hub 管理 Unity 版本 據說裝的 Unity 要裝以下兩個 module Universal Windows Platform Build Support Windows Build Support (IL2CPP) Windows 和 Hololens 都要開啟「開發者模式」\n下載 Mixed Reality Feature Tool\n注意看這不是 MRTK 這可以往 Unity 專案導入 MRTK 可以導入 MRTK 2.6 以後的工具包 創建專案 Unity 開個 3D 專案\nFile -\u0026gt; Build Settings 選擇 Universal Windows Platform 點選 Switch Platform 開啟 Mixed Reality Feature Tool\n針對專案安裝 MRTK 必裝\nMRTK Foundation Mixed Reality OpenXR Plugin 可選\nMRTK Examples Extensions Tools TestUtilities 在模擬器上執行 這坑真的有夠多，我結合上 stack overflow 的解法，所用的步驟:\n要用管理員模式開 Visual Studio，不然有可能遇到權限問題\nVisual studio 要部屬程式的時候，會自己開一個 Hololens 2 Simulator，但他會開超久，然後造成 Timeout，無法部屬，部屬失敗後不要選繼續，也不要關掉模擬器\n這時候再看情況按 實心 / 空心綠色三角形 (without debugging)\n有可能可以 deploy，但運行時有問題，此時按紅色方塊終止，繼續綠色三角形，不要關掉模擬器\n","date":"2023-07-03T00:00:01+08:00","permalink":"https://roykesydon.github.io/Blog/p/hololens-2-%E9%96%8B%E7%99%BC%E7%92%B0%E5%A2%83%E8%A8%AD%E7%BD%AE/","title":"Hololens 2 開發環境設置"},{"content":"Use Cases Cache 把常用的資料回傳，省略長時間的 IO 操作 Shared Session 在 stateless server 間共享 session Distributed lock 用在程式間想共用某種資源的時候 用 setnx (set if not exists) atomic Rate Limiter 用 increment 和 expiration 實現 Feature NoSQL In-memory Key-Value Basic Command redis-server default port: 6379 redis-cli Access data set \u0026lt;key\u0026gt; \u0026lt;value\u0026gt;\nPretty much everything stored in Redis is going to be a type of string by default get \u0026lt;key\u0026gt;\ndel \u0026lt;key\u0026gt;\nexists \u0026lt;key\u0026gt;\nkeys \u0026lt;pattern\u0026gt;\nfind keys with certain pattern keys * get all keys flushall\nget rid of everything Expiration ttl \u0026lt;key\u0026gt;\nshow time to live \u0026ldquo;-1\u0026rdquo; for no expiration \u0026ldquo;-2\u0026rdquo; already expired expire \u0026lt;key\u0026gt; \u0026lt;second\u0026gt;\nsetex \u0026lt;key\u0026gt; \u0026lt;seconds\u0026gt; \u0026lt;value\u0026gt;\nset with expiration Data Structure List lpush/rpush \u0026lt;key\u0026gt; \u0026lt;value\u0026gt; lrange \u0026lt;key\u0026gt; \u0026lt;start index\u0026gt; \u0026lt;end index\u0026gt; \u0026lt;end index\u0026gt; can be -1 lpop/rpop \u0026lt;key\u0026gt; Set sadd \u0026lt;key\u0026gt; \u0026lt;value\u0026gt; smembers \u0026lt;key\u0026gt; srem \u0026lt;key\u0026gt; \u0026lt;value\u0026gt; remove Hash Key-value in Key-value\nhset \u0026lt;key\u0026gt; \u0026lt;field\u0026gt; \u0026lt;value\u0026gt; hget \u0026lt;key\u0026gt; \u0026lt;field\u0026gt; hgetall \u0026lt;key\u0026gt; get everything about \u0026lt;key\u0026gt; hdel hexists \u0026lt;key\u0026gt; \u0026lt;field\u0026gt; Redis doesn\u0026rsquo;t support nested hash struct 刪除過期 key 定期刪除 在固定間隔時間隨機抽 key 檢查並刪除\n惰性刪除 在訪問 key 的時候發現過期就刪除\nmaxmemory-policy (Eviction) 可以設定這些 policy，在記憶體依然額滿的情況下做對應的處理\nnoeviction allkeys-lru allkeys-lfu volatile-lru volatile-lfu allkeys-random volatile-random volatile-ttl 快取情境問題 快取雪崩 Cache Avalanche 某個時刻大量 cache 失效，使資料庫需要承擔很大的流量。 解法 幫 cache 加上額外的隨機過期時間 快取擊穿 Hotspot Invalid 某個 hotspot 的 cache 失效，使大量請求跑到資料庫 解法 讓 hotspot 永不過期 查詢資料庫的部分加上 lock 快取穿透 Cache Penetration client request 不存在的資料，因為同時不存在於 cache 和資料庫中，所以直接跑到資料庫 解法 在 application 先過濾掉非法請求 Bloom Filter 布隆過濾器 Persistence RDB 固定時間對所有資料做快照，memory dump 出來 recovery 比 AOF 快 save、bgsave AOF 紀錄操作流程 檔案比較肥 Rewrite 當 AOF 太大，Redis 會生一個新文件取代舊的，用最少操作生出目前的資料\n混合 在 AOF 重寫的時候也利用 RDB 前面是 RDB，後面是 AOF\nAvailability 主從同步 一主多從，把讀取壓力分擔到 slave 上\n哨兵模式 Sentinel 會有哨兵不斷地 Ping 主從伺服器，確認是否有異常\n如果哨兵是集群，有哨兵檢測到異常，會判斷某伺服器主觀下線，當有一定數量的哨兵投票認為伺服器不可能用，就會變成客觀下線，進行 failover\nCluster 分擔寫入壓力\nRedis 有 16384 個 slot，透過 hash 分配 key 到不同的 slot\n預設會另外用 port 16379 來讓節點間溝通\n可以混和主從同步達到高可用\n","date":"2023-06-05T00:00:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/redis/","title":"Redis"},{"content":"前言 軟體要對 domain 做 Modeling，呈現出 domain 裡的核心概念，才能滿足使用者需求，因此不乏與領域專家的討論\n寫這篇的時候我還沒嗑完 Eric 的聖經，可能嗑完了之後會回來修改\n通用語言 Ubiquitous Language 鑒於程式開發人員與領域專家熟悉知識的差異，會產生交流困難\n因此領域專家和開發團隊要訂定共同的語言，並且盡可能少用自己知道的術語\nUML UML 適合用在小型模型上，它擅長表達類別間的關係，但對於抽象概念卻沒那麼好傳達\n因此用 UML 建構模型時，理想上要添加額外的文字，傳達一些圖所不能表達的 behavior 和 constraint\n並且不能一次寫過於複雜，而是分塊處理\nLayered Architecture 分為四個概念層，只會往下調用，可能會跨層\n可以達到關注點分離 (separation of concerns)，提高各個方面的 cohesive\nUser Interface (Presentation Layer) 呈現給 user 的 UI，User 可能是另一個系統 Application Layer 不含 bussiness logic，指揮表達領域概念的物件來完成任務 Domain Layer 有關 domain 的資訊都在這裡，業務邏輯在此處理 表達業務概念、狀態、規則 劃分出這層是 Model-Driven Design 的關鍵 Infrastructure layer supporting library 保存業務狀態的技術細節在此實作 為前三個 layer 服務 Entity 具備 identity identity 在 status 經過改變後依然不變 追蹤 entity 需要高成本 mutable Value Object 沒有 identity 只關心 obejct 的 value 可以輕易創建丟棄 immutable (不變的) 如果想修改數值就創新的 可被共用 Service 有些動作不屬於某個 Entity 或 Value Object，因為它是跨物件的 Stateless 每個請求不互相影響 Aggregate 把複雜關聯的物件圈在一起考量 確保 consistency 和 inveraints consistency (一致性) 相關物件的資料一致 invariants (不變量) 資料改變時要維護的規則 Aggregate root 具備 global identity，其他內部 entity 只有 local identity 通常是 entity 擔任 外部只能存取它，不能存取 aggregate 的其他 entity 或 value obejct Factory 若創建 aggregate、entity、value object 的過程很複雜，或是涉及專業知識，就該用 factory 包起來 對於不複雜的情況，或是想控制更多細節，可以只依賴於簡單的建構函式 Repository 如果大家都直接存取資料庫的各種物件，會破壞原本精心設計的結構，破壞封裝性\nRepositoy 用來存取物件，封裝了資料庫操作\nDomain event Domain 中重要的事情 可以用在其他物件和 aggrgate 訂閱，讓 aggregate 通知他們 domain event 的發生 Anti-Pattern 應該避免的情形 Smart UI 超肥的萬能 UI Anemic Domain Model 貧血模型 只有 getter 和 setter，沒有業務邏輯的模型 Subdomain 把 domain 切分成小塊，理想上 subdomain 和 bounded context 有 one-to-one 的關係\nTypes core subdomain 和其他競爭者相比不同的部分，最核心的業務，比如搜尋引擎中的搜尋演算法 generic subdomain 大家都會弄的部分，比如登入系統 supporting subdomain 用來輔助 core subdomain 的部分，比如篩選網頁 Bounded Context 劃出 boundary，確保 boundary 內用的概念、規則皆一致 同個名詞可能出現在不同的 context，但有不同意思 Context Map 描述 BC 和 BC 間的關係\n上下游 (U/D) 上游提供下游 (下游依賴上游) Shared Kernel 兩個 BC 共用的部份 違反 BC 的基本原則，是一種例外設計 Customer-Supplier 一個子系統重度依賴另一個子系統 Conformist Customer 完全配合 Supplier Partnership 兩個 BC 互相合作，沒有以誰為主 一起成功或一起失敗 Anticorruption Layer (ACL) 開發系統和外部系統的中間層 可能出現在調用 legacy system 常用到 Facade 和 Adapter Open Host Service (OHS) 如果外部子系統要給一堆用戶端子系統調用，就得在所有用戶端子系統搞 ACL 外部系統做為服務提供，常會搭配 Published Language (PL) PL 是協定傳送資料的格式，比如 XML、JSON 或是 Protocol Buffer Pratical DDD The strangler migration 透過 Facade，把一些服務慢慢移植給新系統，最後取代 legacy ","date":"2023-05-22T00:00:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E9%A0%98%E5%9F%9F%E9%A9%85%E5%8B%95%E8%A8%AD%E8%A8%88-domain-driven-design/","title":"領域驅動設計 Domain-Driven Design"},{"content":"運算放大器 (Operational Amplifiers) 介紹 運算放大器 (Operational Amplifiers) 特性 類似於電壓控制電壓相依電源的電子元件 主動電路元件 用於執行加、減、乘、除、微分與積分等運數學運算的主動電路元件 由電阻、電晶體、電容和二極體等所構成的電子元件，但因內部電路的討論已超出範圍，先看作是電路模組 封裝形式 DIP 輸出電壓 $v_O$ $v_O=Av_d=A(v_2-v_1)$ $v_2$ 是非反相輸入 (noninverting input) $v_1$ 是反相輸入 (inverting input) $A$ 是開迴路電壓增益 (open-loop voltage gain) 是沒有任何從輸出到輸入的回授 (feedback) 時，運算放大器的增益 回授 負回授 (negative feedback) 輸出回授至反相輸入端 閉迴路增益 (closed-loop gain) 如果存在由輸出到輸入的回授，輸出電壓與輸入電壓的比例稱為閉迴路增益 對負回授電路而言，可以證明閉迴路增益和開迴路增益無關，因此運算放大器總是用於具回授的電路中 工作模式 正飽和區 $v_O=V_{CC}$ 線性區 $-V_{CC} \\leq v_O = Av_d \\leq V_{CC}$ 負飽和區 $v_O=-V_{CC}$ 符號 $v_O$ 是輸出電壓 $v_d$ 是輸入電壓差 理想運算放大器 (Ideal Op Amp) 假定運算放大器是理想的是符合實際的，因位目前絕大多數運算放大器都有很大的增益和輸入電阻 具有以下特性的運算放大器，稱為理想運算放大器 $A \\simeq \\inf$ 開迴路增益無窮大 $R_i \\simeq \\inf$ 輸入電阻無窮大 $R_O \\simeq 0$ 輸出電阻為零 特性 流入兩個輸入端的電流均為 0，因為輸入電阻無窮大，輸入端間開路 輸入端間的電壓差等於零，$v_d=v_2-v_1=0$ 反相放大器 (Inverting Amplifier) 對輸入信號放大的同時反轉極性 公式 $v_0=-\\frac{R_f}{R_1}v_i$ $R_f$ 是回授電阻 $R_1$ 是進到負回授節點前的電阻 非反相放大器 (Noninverting Amplifier) 提供正電壓增益的運算放大器電路\n公式\n$v_0=(1+\\frac{R_f}{R_1})v_i$ 電壓隨耦器 (voltage follewer)\n又稱單位增益放大器 (unity gain amplifier) 條件 $R_f=0 或 R_1=\\inf 或 (R_f=0 且 R_1=\\inf)$ 公式 $v_0=v_i$ 加法放大器 (Summing Amplifier) 將多個輸入結合，在輸出產生輸入的加權總合 公式 $v_O=-(\\frac{R_f}{R_1}v_1+\\frac{R_f}{R_2}v_2+\\frac{R_f}{R_3}v_3)$ 差動放大器 (Difference Amplifier) 放大兩個輸入信號的差而抑制兩個輸入的共模信號 (Common-mode signal)\n公式\n$v_O=\\frac{R_2(1+R_1/R_2)}{R1(1+R_3/R_4)}v_2-\\frac{R_2}{R_1}v_1$ 如果 $R_2=R_1$ 且 $R_3=R_4$，動差放大器為減法器 (subtractor)\n$v_O=v_2-v_1$ 串級運算放大器電路 (Cascaded Op Amp Circuits) 串級 兩個以上的運算放大器首尾相接，前一級的輸出是下一級的輸入 多個運算放大器串級時，每個電路都稱為一級 (stage) 運算放大器的優點 串級不會改變各自輸入-輸出 因為理想的運算放大器輸入電阻無窮大，輸出電阻為 0 總增益為個別增益的乘積 $A=A_1A_2A_3$ 數位-類比轉換器 (Digital-to-Analog Converter, DAC) DAC 把數位信號轉成類比信號 實現方法 二進位加權階梯電路 (binary weighted ladder) 把權重設計成二進位的加法放大器 輸入 最高位元 (most significant bit, MSB) 最低位元 (least significant bit, LSB) 儀表放大器 (Instrumentation Amplifiers) 差動放大器的延伸 電容器與電感器 介紹 電容器與電感器是能儲存能量的儲能元件 (storage element) 電容器 (Capacitors) 將能量儲存在電場中的被動元件\n由兩片導電板夾著絕緣體 (電介質) 組成\n公式\n$q=Cv$ q 是儲存的電荷量 C 是比例常數，又稱電容 (capacitance) 單位是法拉 (farad, F) C 不是由 q 和 v 決定 $C=\\frac{\\epsilon A}{d}$ $\\epsilon$ 是介電常數 $A$ 是導電極版的截面積 $d$ 是兩極板的間距 $v(t)=\\frac{1}{C}\\int_{t_0}^t i (\\tau)d\\tau + v(t_0)$ $w=\\frac{1}{2}Cv^2$ 電場儲存的能量 線性電容 (linear capacitor)\n滿足 $i=C\\frac{dv}{dt}$ 非線性電容 (nonlinear capacitor)\n電流電壓關係曲線非直線，不過多數電容是線性的 重要性質\n電容器在直流下工作，等同開路 電壓不隨時間改變的話電流是 0 電容器上的電壓必須是連續的 因為不連續變化的電壓需要無限大的電流 電容會反抗電壓的突然改變 理想電容器不消耗能量 實際的非理想電容器會並聯一個漏電阻，可高達 $100M \\Omega$，在多數情況可忽略不計 電容器串並聯 並聯 $C_{eq} = C_1 + C_2 + C_3 + \u0026hellip; + C_N$ 串聯 $\\frac{1}{C_{eq}} = \\frac{1}{C_{1}} + \\frac{1}{C_{2}} + \\frac{1}{C_{3}} + \u0026hellip; + \\frac{1}{C_{N}}$ 電感器 (Inductors) 將能量儲存於磁場中的被動元件\n公式\n$v=L\\frac{di}{dt}$ L 是比例常數，又稱為電感 (inductance) 單位是亨利 (henry, H) 由物理尺寸和結構決定 $i=\\frac{1}{L}\\int_{t_0}^t v (\\tau)d\\tau + i(t_0)$ $w=\\frac{1}{2}Li^2$ 儲存的能量 電感反應電感器反抗電流變化的特性\n線性電感 (linear inductor)\n滿足 $v=L\\frac{di}{dt}$ 非線性電感 (nonlinear inductor)\n$v$ 和 $di/dt$ 關係曲線非直線 重要性質\n在直流中，電感器等同短路 電感器上的電流必須是連續的 因為不連續變化的電流需要無限大的電壓 電容會反抗電流的突然改變 理想電感器不消耗能量 實際的非理想電容器會串聯一個繞線電阻 (winding resistance)，由製成電感的導電材料產生，通常很小。並由於線圈間的電容性耦合，也存在繞線電容 (winding capacitance) 電感器串並聯 串聯 $L_{eq} = L_1 + L_2 + L_3 + \u0026hellip; + L_N$ 並聯 $\\frac{1}{L_{eq}} = \\frac{1}{L_{1}} + \\frac{1}{L_{2}} + \\frac{1}{L_{3}} + \u0026hellip; + \\frac{1}{L_{N}}$ 應用 電感電容的特殊性質 能儲存能量，作為暫時的電壓源或電流源，可在短時間內產生大電流或電壓 電容器反抗電壓的突然改變、電感器反抗電流的突然改變 電容器和電感器對頻率很靈敏，可以區別不同頻率，這條用在交流電路中 積分器 (Integrator) 採用儲能元件的運算放大器組成的積分器，輸出訊號和輸入訊號的積分成正比 $v_0=-\\frac{1}{RC}\\int_0^tv_i(\\tau)d\\tau$ 微分器 (Differentiator) 採用儲能元件的運算放大器組成的微分器，輸出訊號和輸入訊號的變率成正比 $v_0=-RC\\frac{dv_i}{dt}$ 類比計算機 (Analog Computer) 由各種運算放大器綜合使用，可算出任意微分方程式\n","date":"2023-05-08T00:00:54+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E9%9B%BB%E8%B7%AF%E5%AD%B8-iii/","title":"電路學 - III"},{"content":"簡介 Timer 和 Counter 的差別是 Timer 是定期的數數\nTiming functions 定期對 CPU 發送 interrupt 產生準確時間的 delay 產生 pulses 或 periodic waveforms PWM 量測 duration STM32 Timer / Counter 從 Basic 到 Advanced，追加更多功能\nBasic TImer (Simple Timer)\n16 bit auto-reload register programmable pre-scaler 可以 output 到 DAC update event CNT=ARR(up-count) CNT=0 (down-count) reset CNT to 0 or ARR set UIF flag in status register update event interrupt 如果 enabled (UIE=1) UIF 被設置的時候發送訊號 $T_{EVENT}=Prescale \\times Count \\times T_{CK \\_ INT} \\\\ =(PSC+1)\\times(ARR+1)\\times T_{CK \\_ INT}$\n$T_{EVENT}$ 是兩次事件發生的間隔時間 PSC 是設定 (數值 - 1)，所以 Prescale 是 1 的話，要設 0 Control register\nCEN 是否啟用 counter UDIS 是否啟用 update event URS 設定產生 update event 的 source OPM 是否只算一次 counter 就停 ARPE 關於中途改 ARR 的 reload 設定 UIF interrupt General Purpose Timer\n16-bit or 32-bit auto-reload register use for a variety of puposes measuring lengths of input signals (Input Capture)\nInput Capture 測量 pulse width (高電位的時間) 或 period (一個週長) generating output waveforms (Output Compare and PWM Generation)\none pulse mode output Up to 4 independent channel Interrupt / DMA generation event counter overflow / underflow counter initialization trigger event input capture output compare Advanced Control Timer\n16-bit auto-reload register 特殊 timer\nlow power timer 可以用在比如睡眠狀態 補充 24 bits system timer (SysTick) reload 在 overflow 時回到 register 設定的數值 STM32 Timer 差異 可以去 Datasheet 找每個 Timer 的功能\nCounter resolution\n16/32 bit 決定能從 0 數到多少個 Counter Type\n決定能往上數或往下數或都可以 Prescaler factor\n可以把進來的數字先除以某個數，減緩速度 DMA request generation\n能否用 DMA access 記憶體 Capture / Compare channels\n一個 Timer 可能可以發多個訊號出去，並且經過多個 Compare register，比對不同 event functions Compare 和比對 register，比到了就送 event Capture 紀錄下 channel 的值 Complementary output\n有些馬達控制需要反向波，就要這個 Max interface clock (MHz) and Max timer clock (MHz)\n進去和出來的速度 System Clock - Clock tree Timer 源頭就是 clock\n有四種來源幫忙驅動 system clock (SYSCLK)\nHSI16 (high speed internal) 16 MHz RC oscillator clock MSI (multispeed internal) RC oscillator clock HSE (high speed external) oscillator clock, from 4 to 48 MHz PLL clock SYSCLK 往下接到 AHB，再接到 APB1、APB2\nFlash Read Access Latency 調整 clock 也要調整這部分 Register TIMx_CR1 control register TIMx_PSC 設定 prescale TIMx_ARR auto-reload register ","date":"2023-05-04T01:32:54+08:00","permalink":"https://roykesydon.github.io/Blog/p/stm32-timer-/-counter-%E4%BB%8B%E7%B4%B9/","title":"STM32 Timer / Counter 介紹"},{"content":"paper: Self-Instruct: Aligning Language Model with Self Generated Instructions\nAbstract 大型 \u0026ldquo;instruction-tuned\u0026rdquo; 語言模型 (經過微調好回應 instruction) 已經展現出在新任務上 zero-shot 的能力。\n然而他們嚴重依賴人工編寫的指令，在數量、多樣性和創造力上都受到了限制，阻礙了模型的通用性。\n作者介紹了 Self-Instruct 這個框架，可以透過自己生成的指令，來增強預訓練模型遵循指令的能力。\n將作者的方法應用在 GPT3，在 SuperNaturalInstructions 獲得了比原始模型高 33% 的改進，與使用 private user data 和 human annotations 的 $InstructGPT_{001}$ 性能相當。\n為了進一步評估，我們為新任務整理一組專家編寫的指令，並通過人工評估，顯示出使用 Self-Instruction 調整 GPT3 的性能大大優於使用現有公共指令資料集，只比 $InstructGPT_{001}$ 落後 5% 的差距。\nSelf-Instruct 提供一個幾乎 annotation-free 的方法，align 預訓練模型和 instructions，而且作者釋出了他們的大型合成資料集，以促進未來對 instruction tuning 的研究。\nIntroduction 最近的 NLP 文獻見證了「建構可以遵循自然語言指令的模型方面」的大量活動。\n這些發展由兩個關鍵部分組成：\n大型預訓練語言模型 (LM) 人工編寫的指令資料 PromptSource 和 SuperNaturalInstructions 是最近兩個著名的資料集。 他們透過大量手動註釋來收集指令，以建造 T0 和 T$k$-Instruct。\n然而這過程代價高昂，而且由於大多數人往往生成的都是流行的 NLP 任務，使其未能涵蓋真正多樣的任務，也不能涵蓋各種描述任務的不同方式，因此多樣性受侷限。\n鑒於這些限制，想要繼續提升 instruction-tuned models 的品質，需要幫 supervising instruction-tuned models 發展替代方案。\n本文介紹了 Self-Instruct，這是一種 semi-automated 的過程，用模型自身的 instructional signals 對 pretrained LM 進行 instruction-tuning。\n整個流程是一種 iterative bootstrapping algorithm，從手動編寫的 limited seed set 引導生成。\n在第一階段，模型要幫新任務生成指令。 利用現有的指令集合，創建更廣泛的指令，好定義 (通常是新的) 任務。\n對於新生成的指令集，框架為他們創建 input-output instances，稍後可以透過 supervising 用於 instruction tuning。\n最後，透過各種手段，在低品質和重複的指令加到 task pool 前，把他們修剪掉。\n可以重複這個流程非常多次，直到獲得大量任務。\n該模型的跌代過程中產生了大約 52K 個指令，與大約 85K 個 instance inputs 和 target outputs 配對 (有些相同的指令會對應多種輸入輸出)。\n作者觀察到生成的資料提供了各種有創意的任務，其中超過 50% 的任務和 seed instructions 的 ROUGE-L overlap 小於 0.3。\n基於上述結果，作者通過微調 GPT3 (和生成指令資料是同個模型) 建構了 $GPT3_{SELF-INST}$。\nSuperNI 的結果表明，$GPT3_{SELF-INST}$ 性能大大優於 GPT3 (原始模型)，高了 33.1%，幾乎和 $InstructGPT_{001}$ 的性能相當。\n此外，作者在新創建的的指令集上進行人工評估，$GPT3_{SELF-INST}$ 顯示出廣泛的指令遵循能力，優於在其他公開可用指令數據集上訓練的模型，只比 InstrcutGPT001 落後 5%。\n本文貢獻：\nSelf-Instruct：一種用最少的人工標記數據引導指令遵循能力的作法 通過大量的 instruction-tuning 實驗，證明了有效性。 發布了一個包含 52K 指令的大型綜合資料集，還有一組手動編寫的新任務，用於建構和評估未來的 instruction-following models。 Related Work Instruction-following language models 一系列工作顯示，使用 annotated \u0026ldquo;instructional\u0026rdquo; data，可以使普通語言模型遵循一般語言的指令。\n也顯示出 \u0026ldquo;instructional\u0026rdquo; data 的大小和多樣性直接影響模型的泛化能力。\n本文的工作目的在減少對人工註釋者的依賴。\nLanguage models for data generation and augmentation 許多工作依賴生成式 LM 來生成數據或做 augmentation。\n雖然作者的工作可被視為一種 augmentation，但和這些工作的差別在於不限於特定任務。\nSelf-Instruct 的一個明顯動機是引導出新的任務定義，而這些任務可能還未被 NLP 的研究者定義過。\nSelf-training 一種典型的 self-training 框架透過經過訓練的模型，幫 unlabeled 資料進行 label，然後用這些資料改進模型。\n雖然 Self-Instruct 和 self-training 有一些相似之處，但多數 self-training 的方法都假設了一個特定的目標任務。\n相比之下，Self-Instruct 從頭開始生出各種任務。\nKnowledge distillation 這邊我想不太通為什麼可以和 Knowledge distillation 扯上關係\nKnowledge distillation 通常涉及知識從較大模型到較小模型的轉移\nSelf-Instruct 也可以看做是 Knowledge distillation 的一種形式，但區別如下\ndistillation 的來源和目標是相同的，即模型的知識被 distill 到他自己 distill 的內容以 instruction task 的形式出現 Method 標記大規模指令資料對人類來說可能具有挑戰性，因為他需要\n創意，好提出新任務 為每個任務編寫 labeled instances 的專業知識 Defining Instruction Data 我們要生成的指令資料集包含 {$I_t$}，每個指令用自然語言定義了任務 $t$。\n每個任務都有一個或多個 input-output instances ($X_t,Y_t$)。\n給定 task instruction $I_t$，還有 instance x，模型 M 要生出 y：\n$M(I_t,x)=y, for (x,y) \\in (X_t,Y_t)$\n值得注意的是，instance input 和 instruction 沒有嚴格分界。\n比如 Instruction:\u0026ldquo;write an essay about school safety\u0026rdquo; x:\u0026quot;\u0026quot;，可以被改為 Instruction:\u0026ldquo;write an essay about the following topic\u0026rdquo; x:\u0026ldquo;school safety\u0026rdquo;\nAutomatic Instruction Data Generation 生成指令資料的 pipeline 分成四個步驟：\n指令生成 辨識指令是否是分類任務 用 input-first 或 output-first 做 instance generation 過濾掉低品質的資料 Instruction Generation Self-Instruct 是基於一個發現，也就是大型語言模型可以透過 context 中的現有指令，生出新穎的指令。\n為作者提供了一種從一小組人類編寫的指令中，使指令資料增長的做法。\n作者用他們編寫的 175 個任務 (每個任務 1 個 instruction 和 1 個 instance) 初始化 task pool。\n在每一個 step，作者從裡面 sample 8 個 instructions，作為 in-context 的範例。在這 8 個指令中，有 6 條來自人工編寫的任務，另外兩條來自前面步驟中模型生成的任務，以促進多樣性。\nClassification Task Identification 因為對於分類和非分類的任務，作者會採取兩種做法，所以作者使用來自 seed taks 的 12 條分類指令和 19 條非分類指令，讓 GPT3 透過 few-shot 來判別。\nInstance Generation 給予指令和他們的任務類別，作者獨立地為每條指令生成 instance。\n這具備挑戰性，原因在於他需要模型瞭解目標任務是什麼，根據指令找出需要那些額外的輸入內容，並生成他們。 (模型要根據 instruction 生出 instance input)\n作者發現，在 prompt 中放入其他包含 instruction-input-output 的任務範例的時候，模型可以實現這點。\n一種自然的方法是 Input-first Approach，可以要求語言模型先根據指令提出 input，再生出相應的 output。\n然而，這種方法在分類任務上，可能會偏向於生成某種 label。所以，對於分類任務，作者採用 Output-first Approach，先生成可能的 label，在每個 label 上再生成輸入。\nFiltering and Postprocessing 為了鼓勵多樣性，只有當新的指令和任何現有的指令的 ROUGE-L overlapping 小於 0.7 的時候，才會被添加到 task pool。\n還排除了一些包含了通常不能被 LM 處理的關鍵字 (e.g. images, pictures, graphs) 的指令。\n在為每個指令生成新的 instance 的時候，會過濾掉完全相同或者是輸入相同但輸出不同的 instance。\nFinetuning the LM to Follow Instructions 在創建大規模指令資料後，用這些資料對原始語言模型進行 fine-tune。\n為此，將 instruction 和 instance input 連接起來，作為 prompt，然後訓練模型透過標準的監督式學習進行微調。\n為了讓模型對不同的格式 robust，使用多個模板將指令和輸入 encode 在一起。\n例如，指令可以有或沒有 Task: 前墜、輸入可以有或沒有 Input: 前墜，或是中間可以有不同數量的換行之類的。\nSelf-Instruct Data from GPT3 作者透過 OpenAI API 訪問最大的 GPT3 (davinci)\nStatistics Diversity Quality Experimental Results $GPT3_{SELF-INST}$: fine-tuning GPT3 on its own instruction data 使用生出來的指令資料，對 GPT3 進行微調。\n微調是透過 OpenAI finetuning API\nBaselines Off-the-shelf language models T5-LM 和 GPT3 是普通 LM baselines (只有 pre-training，沒有額外 fine-tune)\n這些 baseline 將表明現成的 LM 在預訓練後，能夠立刻自然地遵循指令的程度。\nPublicly-available instruction-tuned models T0 和 $T_k$-Instruct 是兩個 instruction-tuned models。\n兩者都是從 T5 進行微調的，對這兩種模型，都使用具有 11B 參數的最大版本。\nInstruction-tuned GPT3 models 作者評估了 InstructGPT，它是 OpenAI 基於 GPT3 開發的。\n對於 SuperNI 的實驗，只與 text-davinci-001 engine 進行比較，因為更新的 engine 用最新的用戶資料，而且很可能已經看過 SuperNI。\n對於新編寫的指令，評估時則包含了 001、002 和 003，以確保完整性。\n為了進一步比較 Self-Instruct 在其他公開可用的指令訓練集資料，使用 PromptSource 和 SuperNI 的資料微調 GPT3，這些資料用於訓練 T0 和 $T_k$-Instruct 模型。\n分別簡稱為 T0 訓練和 SuperNI 訓練。\nExperiment 1: Zero-Shot Generalization on SUPERNI benchmark 首先以 zero-shot 的方式評估典型 NLP 任務遵循指令的能力。\nResults Experiment 2: Generalization to User-oriented Instructions on Novel Tasks 盡管 SuperNI 在現有的 NLP 任務具有全面性，多數的這些任務是初於研究理由提出的，而且偏向分類。\n為了更好的獲取指令遵循模型的實用價值，作者中的一部分人策劃了一組面向用戶應用的新指令集。\n他們先針對 Large LM 可能可以應用到的領域進行 brainstorm，並且制定與每個領域相關的 instruction 和 instance。\n總共創建了 252 條指令，每條指令有 1 個 instance。\nHuman evaluation setup 評估模型在這些不同任務的測試集上的表現極具挑戰性，因為不同的任務需要不同的專業知識。\n為了獲得更忠實的評價，作者請了 instructions 的作者對模型的預測結果進行評估。\n實施一個 four-level rating system：\nRating A 回覆有效且令人滿意 Rating B 回覆可接受，但存在可以改進的地方 Rating C 回覆相關，但在內容上有重大錯誤 Rating D 回覆不相關或無效，包含重複輸入的部分，完全無關的輸出。 Results 如果把 Rating B 以上視為有效，$GPT_{SELF-INST}$ 只和 $InstructGPT_{001}$ 相差 5%\nDiscussion and Limitation Why does SELF-INSTRUCT work? 值得反思的是，在最近成功的 instruction-tuning LMs 中，高品質的 human feedback 扮演的角色。\n這裡有兩個極端的假設：\nHuman feedback 是 instruction-tuning 中必要且不可或缺的角色，因為 LM 需要了解在預訓練過程中沒完全了解到的問題。\nHuman feedback 是 instruction-tuning 一個可選的方向，因為 LM 在預訓練就已經很熟悉指令了。\n雖然現實可能介於這兩個極端之間，作者推測可能更傾向於第二種假設，尤其是對於較大的模型。\n第二種，也是人類直覺，是 Self- Instruct 的關鍵動機，而且也從成功的結果獲得支持。\nBroader Impact 除了本文的直接關注點外，作者相信 Self-Instruct 可能有助於揭露各種 instruction tuning 模型 \u0026ldquo;幕後\u0026rdquo; 發生的事情。\n不幸的是，由於他們的資料集尚未發布，這種業界模型仍處於 API 牆之後。\n人們對其結構以及為何能展現令人印象深刻的能力知之甚少。\nLimitations of Self-Instruct Tail phenomena Self-Instruct 依賴於 LM，繼承 LM 的所有限制。\n最近的研究顯示出 tail phenomena 對 LM 的成功構成嚴峻的挑戰。\n換句話說，LM 的最大收益出現於語言中最頻繁出現的部分 (語言分佈的頭部)，而低頻率出現的上下文中獲得的收益最小。\n同樣的，在這項工作背景下，如果 Self-Instruct 大部分的收益偏向預訓練 corpus 中頻繁出現的任務或指令，那也不令人感到意外。\n因此，該方法在不常見和有創意的指令下，可能會顯現出脆弱性。\nDependence on large models 因為 Self-Instruct 依賴於從 LM 中提取初的 inductive bias，因此它可能適合 larger model。\n如果這是對的，這會對那些沒有大量計算資源的人造成阻礙。\nReinforcing LM biases 作者擔心這種迭代作法可能會產生意料之外的結果，比如將有問題的社會偏見放大。\n","date":"2023-04-30T00:00:12+08:00","permalink":"https://roykesydon.github.io/Blog/p/self-instruct-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"Self-Instruct 論文閱讀"},{"content":"Memory Map CPU 對 I/O 操作方法\nPort I/O 用特殊 CPU 指令 I/O 設備和記憶體不共享地址空間 Memory-Mapped I/O I/O 設備和記憶體共享地址空間 像一般控制記憶體 這塊記憶體具有四個責任\nCommand Status Output Data Input Data GPIO 結構 GPIO mode Open-Drain 由外部電壓決定輸出電壓 Output Register 是 0 會啟用 N-MOS，1 的話靠外部電壓推 好處是外部電壓可以自己決定 Push-Pull 由內部電壓決定輸出電壓 Output Register 是 0 或 1 會決定啟用 N-MOS 或是 P-MOS 有關 Register Clock enable register AHB2 peripheral clock enable regisetr (RCC_AHB2ENR) Control register GPIO port mode register GPIO port output type register GPIO port output speed register GPIO port pull-up/pull-down register Data register Output Input 使用 GPIO 先去 Memory map 找 Boudary address\n根據 table 確認要設置的數值\n設定 RCC enable\n把上面說的各種 Control register 設定好\n比如 PUPDR BSRR\n修改 ODR 會一次改到整個 GPIO port，若只要改某個 pin，可以用 BSRR Delay\nCPU 4 MHz 1 cycle = 0.25$\\mu$S 可以查每個組合語言指令要幾個 cycle 機械按鈕會有 Bouncing\nDebounce Hardware method 加上濾波電容 Software method 讀取後等待一段時間才再次讀取 連續讀取 N 次，看數值是否穩定改變 7-Segment COM 分共陽、共陰\n8 個七段顯示器就要吃掉 8 * 8 個 GPIO 接腳，可以每次只顯示一個，那只需要 8 個 GPIO 接腳，快速閃過\n也可用 Max 7219 控制，他有三個輸入 DIN、LOAD、CLK\nDIN 輸入資料 CLK 上升的時候採樣，最多 10 MHz LOAD(CS) 採用最後輸進去的 16 bits 最早的是 MSB ","date":"2023-04-26T01:32:54+08:00","permalink":"https://roykesydon.github.io/Blog/p/stm32-gpio-%E4%BB%8B%E7%B4%B9/","title":"STM32 GPIO 介紹"},{"content":"重構 在不改變軟體行為的情況下，對軟體內部構造進行改善\nCode Smell 也稱 Bad Smell，代表程式碼中需要重構的部分\nDuplicated Code 重複程式碼 在同個 Class Extract Method 在不同 Class Extract Class Long Method 用 Extract Method 拆解過長的 function Long Parameter List Preserve Whole Object 把來自同一物件的資料直接該物件取代 Introduce Parameter Object 把相關的資料包成一個 Object Large Class 一個 Class 有太多 fields / methods / lines Magic Number 特殊數值直接用數字表示，日後修改每個地方都要改 Lack of Comments 加註解的好時機：寫程式前寫上 Switch Statements 可利用「多型 (Polymorphism)」解決 Divergent Change 一個類別有太多改變的原因 盡量讓其遵守 SRP Shotgun Surgery 某個責任被分散到大量的 Class 身上，使修改其時要大量修改 Feature Envy 存取別的 Object 的 Data 的情形比自己的還頻繁 這方法可能應該屬於另一個 Object Data Clumps 常一起出現的資料群應該被單獨抽成一個 Class Primitive Obsession 過度使用基本類別，造成 Shotgun Surgery Message Chains Client 請求 A 物件，A 物件又請求 B 物件 Lazy Class 把冗員類別移除 Temporary Field Instance variable 只有在特殊情形才被使用，應該改為區域變數或參數 Inappropriate Intimacy Classes 間頻繁讀取對方資料 理解程式要同時看懂兩者 Alternative Classes with Different Interfaces 兩個 Class 具有功能相同、命名不同的 function 可汲取共同部分為 Super Class 來解決 ","date":"2023-04-25T14:26:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E9%87%8D%E6%A7%8B-refactoring/","title":"重構 Refactoring"},{"content":"說明 本文寫於 Swin Transformer 論文閱讀 之後，當時對 Relatvie position 的理解不夠清楚，本文將會做解釋，並附上原論文的筆記。\n以下將會先用長度為 3 的序列作為示範。\nAbsolute Position Encodings Absolute Position Encodings 的做法是把用某種方式生成或可學習的向量加在輸入，第一個位置用 $w_1$，第二個位置用 $w_2$，第三個位置用 $w_3$。\nRelative Position Encodings Relative Position Encodings 顧名思義，就是改用相對位置來做這些向量。\n上圖中，Position Encoding 的部分從 3 個向量變成 3*3 個向量，因為現在會以每個 token 為基準，生出 3 個相對位置向量。\n我們以 $w_0$，代表處於原點，$w_x$ 代表往右 $x$ 格，$w_{-x}$ 代表往左 $x$ 格，其中 $x$ 是正整數。\n第一個 row 有 $w_0$、$w_1$、$w_2$，意思是以第 0 個向量 (I) 為基準，他的位置是 $w_0$，對第 0 個向量來說，第 1 個向量 (like) 是 $w_1$，第 2 個向量 (cat) 是 $w_2$。\n輪流以 $n$ 個 token 為基準，就會生出 n*n 個相對位置向量，而不是原先的 n 個絕對位置向量。\n其中 $w_i$ 和 $w_j$ 如果 $i=j$，他們會共用同樣的 weight，上圖是以相同顏色表示。\n如果序列長度是 $n$，就會有 $2n-1$ 個向量要學。\nn*n 這個數量使其適合加入到 self-attention，原始論文的加入方式可以參考下方論文筆記，這邊晚點會介紹後續衍生的簡化版。\nSwin Transformer 如何導入 Relative Position Encodings Swin Transformer 是借鑒許多 CNN 架構，為了 CV 而經過修改的 vision transformer。\n其中一個重點是，他會在一小區塊的特徵圖上做 self-attention，而且是用 Relative Position Encodings。\n和剛剛的差別在於，現在要在二維空間做 Relative Position Encodings。\n假設有一張 2*2 的 feature map，我們先設定好 feature map 各個 token 的絕對位置座標。\n然後我們輪流把 feature map 的每一個 token 作為基準點，把 feature map 的每個 token 的座標減去基準點的座標，就可以得到相對位置座標。\n如果我們把四個相對位置座標各別攤平 (按照左上 -\u0026gt; 右上 -\u0026gt; 左下 -\u0026gt; 右下的順序)，並且從上到下排好，他會看起來如下圖。\n此時我們幾乎完成了相對位置的表，和剛剛序列一樣生出了 n*n 個相對位置。\n我們接下來要做的事情是把這個表給編號，把 (0, 0) 都編成某個數字，把 (1, 0) 都編成某個數字。\n在此之前，先考慮總共會有幾種可能的相對座標，對於邊長 $M$ 的 feature map (這裡 M=2)，因為兩軸可能的數字皆有 (2M-1) 種，共會有 (2M-1)*(2M-1) 種可能性，這裡等於 9。\n所以我們等等會把所有座標編為 0~8。\n想從座標生出編號 0~8 可以考慮把座標兩軸的數字相加，但由於有負數的存在，要先把兩軸的數字都變成非負整數，所以先把兩軸的座標都各別加 M-1。\n此時如果相加，會使 (2, 1) 和 (1, 2) 都對應到數字 3，所以我們先把 row 座標乘上 2M-1 再相加，此時就可以獲得一個 n*n 的 index table ，對應一組相對位置向量。\nSwin Transformer 是用簡化版的作法來引入相對位置，公式如下\n$Attention(Q,K,V)=SoftMax(QK^T/\\sqrt{d}+B)V$ $B$ 是 relative position bias，$B \\in R^{M^2 * M^2}$ $a_{ij}$ 是純量，不是向量，和原始論文不同 論文出處 paper: Self-Attention with Relative Position Representations\nAbstract 依賴於 attention 機制的 Transformer 在機器翻譯方面取得 SOTA，但在結構中沒有相對或絕對的位置資訊，他需要在輸入中添加絕對位置的資訊。\n因此本文提出一種替代方案，拓展 self-attention ，考慮相對位置的表示，並在一些任務中獲得更好的結果。\n值得一題的事，作者觀察到結合相對和絕對位置不會進一步提高翻譯品質。\n該機制可以拓展到任意 graph-labeled 的輸入\nIntroduction Non-recurrent models 不一定按順序考慮輸入元素，因此可能需要明確的 position encoding 才才能用序列順序。\n一種常見的方法是使用與輸入元素結合的 position encoding，以向模型傳達位置資訊。\n可以是 deterministic function，或是 learned representations。\nCNN 可以捕捉 kernel 的相對位置資訊，但被證明仍受益於 position encoding。\n對於既不使用卷積也不使用遞歸的 Transformer，結合位置信息的 representation 是一個特別重要的考慮因素，因為該模型在其他方面對序列排序完全不變。\n本文提出一種將相對位置合併到 Transformer 的 self-attention 的做法，即使完全換掉絕對位置編碼，也使兩個機器翻譯任務的品質有顯著提高。\nBackground 原始 self-attention\n$z_i=\\displaystyle\\sum_{j=1}^n\\alpha_{ij}(x_jW^V)$\n$\\alpha_{ij}=\\frac{\\text{exp } e_{ij}}{\\sum_{k=1}^n\\text{exp } e_{ik}}$\n$e_{ij}=\\frac{(x_iW^Q)(x_jW^K)^T}{\\sqrt{d_z}}$\nProposed Architecture Relation-aware Self-Attention 有兩個要引入 relative position 的地方，而且都是向量\n$z_i = \\displaystyle\\sum_{j=1}^n \\alpha_{ij}(x_jW^V+a_{ij}^V)$\n$e_{ij}=\\frac{x_iW^Q(x_jW^K+a_{ij}^K)^T}{\\sqrt{d_z}}$\nRelative Position Representations 可以引入 clip，把線性序列中，高於長度 k 的修剪成最大值\n$a_{ij}^K=w_{clip(j-i,k)}^K$ $a_{ij}^V=w_{clip(j-i,k)}^V$ $clip(x,k)=max(-k,min(k,x))$ Experiments Model Variations clipping 的實驗 V 和 K 的 ablation study ","date":"2023-04-24T01:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/relative-position-%E4%BB%8B%E7%B4%B9--%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"Relative Position 介紹 + 論文閱讀"},{"content":"paper: Swin Transformer: Hierarchical Vision Transformer using Shifted Windows\nAbstract 本文提出一個新的 vision Transformer，稱作 Swin Transformer，可以被用作 computer vision 中的 general-purpose backbone。\n把 Transformer 從 language 移到 vision 具備挑戰性，比如同一個 visual entity 在大小上具備很大的 variance。還有 high resolution 下 pixel 和 word 的數量差異太大。\n為了解決這些差異，作者提出 hierachical Transformer，用 shifted windows 來算出 representation。\nshifted windowing 透過把 self-attention 限制在 non-overlapping 的 local window 和允許 cross-windows connection 來提高效率。\n這種 hierarchical architecture 可以靈活地在各種 scale 下擴展 model，還可以對圖像大小有線性的計算時間複雜度。\nIntroduction ViT 把圖片打成 patch，每個 patch 是 16*16，feature maps 由 single low resolution 的輸入生成，而且由於自注意力始終都是在全局上計算的 (patch 和 patch 間做自注意力)，所以時間複雜度是 quadratic computation complexity。\nSwin Transformer 從小 patch 開始，並在更深的 Transformer layers 合併相鄰的 patches。\n有了這些 hierarchical feature maps，可以用在像是 FPN 或是 U-Net。\n一個 Swin Transformer 的關鍵設計因素是 shifted window。\n透過 bridge 不同 layer 的 windows 來提供他們連接。\nMethod Overall Architecture Patch Merging 原本特徵圖是 H * W * C 以上下 stride=2 行走，會得到四張 H/2 * W/2 * C concatenate 起來，變成 H/2 * W/2 * 4C 做 linear，變成 H/2 * W/2 * 2C Swin Transformer block Swin Transformer 是透過把 Transformer block 中的 multi-head self attention(MSA) 換成基於 shifted windows 的 module 構成。\nShifted Window based Self-Attention 標準的 Transformer 架構會算 global self-attention，計算所有 token 間彼此的關係，導致 quadratic complexity，使其不適用於需要大量 token 的許多 CV 問題\nSelf-attention in non-overlapped windows 原來的圖片會以 non-overlapping 的方式切割。\n假設每個 windows 有 M * M 個 patches，然後一張圖像有 h * w 塊 patches，計算複雜度如下：\n$\\Omega(MSA)=4hwC^2+2(hw)^2C$ $\\Omega(W-MSA)=4hwC^2+2M^2hwC$ Shifted window partitioning in successive blocks window-based self-attention module 缺乏了 windows 間彼此的連接，會限制模型能力。\n作者提出了一種 shifted window 的方法，保持 non-overlapping windows 的高效計算，同時引入 windows 間的連接。\n再兩個連續的 windows 間，會移動 $(⌊ \\frac{M}{2} ⌋, ⌊ \\frac{M}{2} ⌋)$\nEfficient batch computation for shifted configuration shifted window 有個問題是，會導致更多的 windows，從 $⌈ \\frac{h}{M} ⌉ * ⌈ \\frac{w}{M} ⌉$ 到 $(⌈ \\frac{h}{M} ⌉+1) * (⌈ \\frac{w}{M} ⌉+1)$，而且有些 window 會小於 M*M。\n這樣會導致無法把這些給壓成一個 batch 快速計算。\n一種 naive 的解法就是直接在外面加 zero padding，但會增加計算量，當 windows 數量較少時，計算量會變很可觀 (從 2 * 2 個 windows 變成 3 * 3 個 windows，增加了 2.25 倍)\n作者提出另外一種巧妙的做法，把一些部分挪移。\n但現在有些 window 裡有多個不該相互做 attention 的部分，所以要用 mask 的方式計算。\n不同 windows，做 self-attention 後，把不相干的部分做的 attention 減去一個很大的數值，最後再過 softmax。\n上圖來自作者在 github 提供的可視化\n最後再把它挪回原本的位置。\nRelative position bias 參考這個: https://blog.csdn.net/qq_37541097/article/details/121119988\nArchitecture Variants window size 預設是 M = 7\nquery dimension of each head 是 d = 32\nexpansion layer of each MLP is $\\alpha$ = 4\nC 是 first stage 的 hidden layers 的 channel numbers\nSwin-T\nC = 96 layer numbers = {2, 2, 6, 2} 大小和計算量是 Base 的大約 0.25 倍 complexity 接近 ResNet-50 Swin-S\nC = 96 layer numbers = {2, 2, 18, 2} 大小和計算量是 Base 的大約 0.5 倍 complexity 接近 ResNet-101 Swin-B\nC = 128 layer numbers = {2, 2, 18, 2} Swin-L\nC = 192 layer numbers = {2, 2, 18, 2} 大小和計算量是 Base 的大約 2 倍 Experiments Image Classification on ImageNet-1K Object Detection on COCO Semantic Segmentation on ADE20K Ablation Study Conclusion 基於 self-attention 的 shifted window 是 Swin Transformer 關鍵部分，被顯示出他在 CV 領域有效率且有效，並期望未來把它應用在 NLP。\n","date":"2023-04-14T01:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/swin-transformer-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"Swin Transformer 論文閱讀"},{"content":"分析方法 節點分析 (Nodal Analysis) 解節點電壓 選取一個節點做為參考節點 (reference node) 或已知節點 (datum node)，其他節點的電壓相對於它 假設它電位為 0，稱為 ground 把 KCL 用在剩下的 n-1 個參考節點 (假設電流方向，可以隨便假設，只要一致，不要兩端電流都流入同個電阻) 求解聯立方程式，得到各節點電壓 包含電壓源的節點分析 (Nodal Analysis with Voltage Sources) 如果電壓源連接於兩個非參考節點間，可以把電壓源和這兩個節點和與其並聯的元件看做一個超節點 (supernode) 或廣義節點 (generalized node)，解決無法知道流過電壓源的電流的問題 超節點的屬性 超節點內部的電壓源提供限制方程式 超節點本身沒電壓 超節點要同時用 KCL 和 KVL 網目分析 (Mesh Analysis) 只能適用平面電路 (planer circuit)，不能用在非平面電路 (nonplaner circuit)\n在一個平面上沒有交互連接的分支 網目 (Mesh)\n不包含子迴路的單一迴路 網目電流 (mesh current)\n流經網目的電流 決定網目電流步驟\n在 n 個網目中，指定 n 個網目電流 對 n 個網目個別應用 KVL，把歐姆定律應用在網目電流上，以表示電壓 求解 n 個聯立方程式，計算網目電流 包含電流源的網目分析 (Mesh Analysis with Current Sources) 如果有兩個 Mesh 共用同一個電流源，會形成超網目 (supermesh)，把公用的電流源還有串聯的元件給移除掉 視察法 待補 節點分析 vs 網目分析 節點比網目少選節點分析，反之也是 要求電壓節點，求電流網目 可以用一種驗證另一種的結果 有些特殊問題只能用其中一種方法 直流電晶體電路 電子產品中的基本元件有三端主動元件\u0026ndash;電晶體 (transistor)\n種類 雙極性接面電晶體 (biopolar junction transistor, BJT) 本節只討論這種 場效電晶體 (field-effect transistor, FET) BJT 類型\nNPN PNP Part\n射極 (emitter, E) 基極 (base, B) 集極 (collector, C) 工作模式\n作用 $I_C=\\alpha I_E$ $\\alpha$ 是共基極電流增益 (common-base current gain)，表示射極注入的電子被基極收集的比例 $I_C=\\beta I_B$ $\\beta$ 是共射極電流增益 (common-emitter current gain) $I_E=(1+\\beta) I_B$ $\\beta=\\frac{\\alpha}{1-\\alpha}$ 因為 $\\beta$ 很大，一個小的基極電流可以控制大電流的輸出，因此，雙極性電晶體可以當作放大器 截止 飽和 電路理論 線性性質 (Linear Property) 線性\n齊次性 輸入 ( 激發 excitation) 乘以一個常數，輸出 ( 響應 response) 也會乘以相同的常數 $kiR=kv$ 可加性 輸入總和的 response 等於個別輸入的 response 的總和 $v=(i_1+i_2)R=i_1R+i_2R=v_1+v_2$ 因此稱電阻是一個線性元件，因為電阻、電壓、電流的關係滿足齊次性和可加性\n如果電路滿足可加性和齊次性，稱此電路為線性電路\n線性電路是輸出與輸入為線性關係的電路 組成 線性元件 線性相依電源 獨立電源 重疊 (Superposition) 有兩個或更多的獨立電源時，除了節點和網目分析，可以求各獨立源對變數的貢獻，最後相加起來，這就是重疊 重疊定理 在一個線性電路中，跨接於元件上的電壓(流經元件的電流) = 每個獨立電源單獨作用於該元件二端的電壓(單獨流經該元件的電流)的代數和\n注意事項\n同一時間只考慮一個獨立電源，把其他的電壓源當作 0 V(短路)、電流源當作 0 A(開路) 相依電源受電路變數控制，保持不變 步驟\n保留一個獨立電源，算它的輸出(電壓或電流) 對每個電源做步驟 1 把每個獨立電源的貢獻相加 電源變換 (Source Transformation) 把電阻並聯的電流源和電阻串聯的電壓源做轉換(或反過來) 電源變換條件 $V_s=i_sR$ 也是用相依電源，但也要遵守條件 戴維寧定理 (Thevenin\u0026rsquo;s Theorem) 常有一種情境，電路種有一個特殊的元件是可變的，又稱負載 (load)，比如插座可能連接不同家電所組成的負載，而每當 load 改變，就要重新分析電路。戴維寧定理可以把固定的部分換成一個等效電路 戴維寧定理 線性二端電路可被由電壓源 $V_{Th}$ 和電阻 $R_{Th}$ 串聯所組成的戴維寧等效電路 (Thevenin equivalent circuit) 取代 $V_{Th}$ 是二端的開路電壓 $R_{Th}$ 是關閉獨立電源後，端點上的輸入或等效電阻 關閉所有獨立電源(根據 電壓/電流 來 短路/開路)，但考慮相依電源 $R_{Th}$ 有可能求出負值，這代表該電路提供功率，裡面有相依電源，雖然不可能出現在被動元件上，但等效電路是主動元件 假設外接一個電壓源，求外面的 v 和 i 即可算出 $R_{Th}$ 諾頓定理 (Norton\u0026rsquo;s Theorem) 和戴維寧定理很像，但是等效電路改成電流源和並聯的電阻，實際上，根據電源變換，可以知道諾頓定理和戴維寧定理的等效電阻相等\n$R_N=R_{Th}$\n$I_N=\\frac{V_{Th}}{R_{Th}}$\n計算戴維寧或諾頓等效電路，要先求 $v_{oc}$、$i_{sc}$、$R_{in}$\n求出兩個就可以算第三個 $V_{Th}=v_{oc}$ $v_{oc}$ 是 a 和 b 兩端的開路電壓 $I_N=i_{sc}$ $i_{sc}$ 是 a 和 b 兩端的短路電流 $R_{Th}=\\frac{v_{oc}}{i_{sc}}=R_N$ 最大功率轉移 (Maximum Power Transfer) 轉移到 load 的功率是 $p=i^2R_{L}=(\\frac{V_{Th}}{R_{Th}+R_L})^2R_L$ 最大值出現在 $R_L=R_{Th}$ 最大功率定理 (maximum power theorem) $p_{max}=\\frac{V_{Th}^2}{4R_{Th}}$ 電源建模 (Source Modeling) 實際的電源非理想電源 電壓源有串聯的內部電阻 (internal resistance) 下面稱為 $R_s$ 要理想要趨近於 0 若不連接 load (開路)，$v_{oc}=v_s$ $v_s$ 可以看做無負載源電壓 (unloaded source voltage)，連接 load 會使端電壓下降，這就是負載效應 (loading effect) $R_L$ 越大會越接近理想電壓 量測 $v_s$ 和內部電阻 量開路電壓 $v_s=v_{oc}$ load 端連接可變電阻，調到 $v_L=v_{oc}/2$ 此時 $R_L=R_{Th}=R_s$ 電流源有並聯的電源電阻 (source resistance) 要理想要趨近於無窮大 $R_L$ 越小越接近理想電源 電阻量測 (Resistance Measurement) 惠斯登電橋 (Wheatstone bridge) 平衡電橋 (balanced bridge) 非平衡電橋 (unbalanced bridge) ","date":"2023-04-10T00:00:54+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E9%9B%BB%E8%B7%AF%E5%AD%B8-ii/","title":"電路學 - II"},{"content":"介紹 試用 STM32 UART 功能\n會透過 RealTerm 和 STM32L476RG 溝通，並用 DMA 接收訊息\n根據 User manual，USART2 預設會連接 ST-LINK，要連接外部設備的話要修改 solder bridge\nioc 設置 Connectivity 可以設置 USART2 mode 從 disable 改選 Asynchronous Parameters Settings 可以設置各種資訊 Baud Rate Word Length Parity Stop Bits DMA Setting Add 一個 RX Mode 改成 circular，並打開 memory 的 increment address increment address 是因為資料是用 array 存 circular 是當資料滿了後，會回到 zero position NVIC Setting 設置 DMA 應該就會自動設置一個 interrupt，檢查一下 程式碼 發送\n1 2 uint8_t myTxData[13] = \u0026#34;Hello World\\r\\n\u0026#34;; HAL_UART_Transmit(\u0026amp;huart2, myTxData, 13, 10); 接收\n1 2 3 4 UART_HandleTypeDef huart2; // generated code uint8_t myRxData[20]; HAL_UART_Receive_DMA(\u0026amp;huart2, myRxData, 20); // 在 Init 後，在 main 中執行一次就好 interrupt\n在 hal_uart.c 有\n1 2 3 4 5 6 7 8 9 __weak void HAL_UART_RxCpltCallback(UART_HandleTypeDef *huart) { /* Prevent unused argument(s) compilation warning */ UNUSED(huart); /* NOTE : This function should not be modified, when the callback is needed, the HAL_UART_RxCpltCallback can be implemented in the user file. */ } 當 DMA 滿了就會呼叫這個 function\n實驗 1 2 3 4 5 6 7 8 9 10 void HAL_UART_RxCpltCallback(UART_HandleTypeDef *huart) { /* Prevent unused argument(s) compilation warning */ UNUSED(huart); /* NOTE : This function should not be modified, when the callback is needed, the HAL_UART_RxCpltCallback can be implemented in the user file. */ HAL_UART_Transmit(\u0026amp;huart2, myRxData, 20, 10); } 當 20 個 Bytes 儲存滿了就回傳資訊給電腦\nRealTerm Display 勾選 Half Duplex 發送的訊息會顯示綠色，接收的是黃色 Port 設置 Baud 和其他有的沒的 選 open Send EOL 可以勾選 CRLF 打一些文字後按 Send ASCII 結果 程式碼\n","date":"2023-04-09T01:32:54+08:00","permalink":"https://roykesydon.github.io/Blog/p/stm32-uart-%E5%AF%A6%E9%A9%97/","title":"STM32 UART 實驗"},{"content":"基本概念 常見名詞 電路 (electric circuit) 元件 (element) 電路組成的部分 單位系統 國際單位制 (International System of Units ,SI) 電荷與電流 電荷 (electric charge)\n組成原子的基本物質 庫倫 (C) 電荷守恆定律 (law of conservation of charge) 電荷不能被創造、破壞，只能轉移，系統中的電荷總數不變。 電流 (electric current)\n電荷的時間變化率 電流是電荷的移動，而且有方向性 安培 (A) 公式 $i \\triangleq \\frac{dq}{dt}$ $Q \\triangleq \\int_{t_0}^{t}i\\text{ }dt$ 直流電 (direct current, dc) 恆定常數的電流 交流電 (alternating current, ac) 隨著時間以正弦波變化的電流 電壓 電動勢 (electromotive force, emf) 驅動導體內的電子往某方向移動 電壓 (voltage)、電位差 (potential difference) 伏特 (V) $v_{ab}\\triangleq\\frac{dw}{dq}$ 單位電荷從 b 移動到 a 需要做的功 $w$ 是能量，單位是焦耳(J) $q$ 是電荷，單位是庫倫(C) 壓降 (voltage drop)、壓升 (voltage rise) 直流電壓 (dc voltage)、交流電壓 (ac voltage) 功率與能量 消耗或吸收能量的時間變化率，單位是瓦特(walt, W)\n公式\n$p \\triangleq\\frac{dw}{dt}$ $p=iv$ 被動符號規則 (passive sign convention)\n電流從電壓的正極流入元件 ($p=+vi$)，表示該元件吸收功率 電流從電壓的正極流出元件 ($p=-vi$)，表示該元件供應功率 能量守恆定律 (law of conservation of energy)\n電路中任何時刻的功率總和為 0 $\\sum p=0$ 電路元件 被動元件 (passive element) 不具備產生能量的能力 電阻器 (resistor)、電容器 (capacitor)、電感器 (inductor) 主動元件 (active element) 具備產生能量的能力 發電機 (generator)、電池 (battery)、運算放大器 (operational amplifier) 電源 電壓源、電流源 提供穩定電壓產生電流、提供穩定電流產生電壓 獨立電源 獨立電源提供指定電壓或電流的主動元件，與電路中其他元件無關。 電池和發電機可被當作近似理想的電壓源 相依電源 提供的電壓或電流受另一個電流或電壓控制的主動元件 類型 電壓控制電壓源 (voltage-controlled voltage source, VCVS) 電流控制電壓源 (current-controlled voltage source, CCVS) 電壓控制電流源 (voltage-controlled current source, VCCS) 電流控制電流源 (current-controlled current source, CCCS) 基本定律 歐姆定律 (Ohm\u0026rsquo;s Law) 一般材料具備阻止電荷流通的特性，稱為電阻 (resistance)\n均勻截面積下，$R=\\rho \\frac{l}{A}$\n$\\rho$ 是材料的電阻率 (resistivity) 電路中抑制電流的材料稱為電阻器 (resistor)\n$v=iR$\n短路 (short circuit)、開路 (open circuit)\n短路: 電壓是 0，電流可能是任意值，電阻值接近 0 開路: 電壓可能是任意值，電流是 0，電阻值接近無限大 固定電阻、可變電阻\n阻值可調與否 常用的可變電阻是電位器 (potentiometer) 不是所有電阻都遵守歐姆定律\n遵守歐姆定律的稱為線性電阻 (linear resistor)，反之則為非線性電阻 (nonlinear resistor)，阻值隨電流變化 電導 (conductance)\n電阻 R 的倒數 元件導通電流的能力 $G=\\frac{1}{R}=\\frac{i}{v}$ 單位姆歐 (mho, $\\mho$) 或西門子 (siemens, S) $1 S = 1 \\mho = 1 A/V$ Node, Branches, and Loops 分枝 (Branch)\n任意的兩端元件，比如電壓源、電阻 節點 (Node)\n指連接二個或多個分支的接點 迴路 (Loop)\n是電路中的任一封閉路徑 從一個節點開始，經過一組節點，最後回到一開始的節點，途中每個節點只經過一次 串聯\n多個元件共享單一節點 並連\n多個元件連接到相同的兩個節點 獨立迴路 (independent loop)\n至少包含一個不屬於其他獨立迴路的 branch $b=l+n-1$ b 是 branch，l 是獨立迴路，n 是 node 克希荷夫定律 (Kirchhoff\u0026rsquo;s Laws) Kirchhoff\u0026rsquo;s current law (KCL)\n流入任一 node 或封閉邊界的電流總和為 0 或是說流入某一節點的電流和等於流出的電流和 $\\sum_{n=1}^{N}i_n=0$ $N$ 是連到 node 的 branch 數 Kirchhoff\u0026rsquo;s voltage law (KVL)\n一條封閉路徑(或迴路)中的電壓總和為零 或是說 voltage drop 的總和 = voltage rise 的總和 $\\sum_{m=1}^{M}n_m=0$ $M$ 是迴路中的 branch 數 串並聯電阻 串聯\n$R_{eq}=\\sum_{n=1}^N R_n$ $R_{eq}$ 是等效電阻 (equivalent resistance) 分壓定理 (principle of voltage division) 電壓和各電阻的阻值成正比，阻值越大，壓降越大 分壓器 (voltage divider) $v_1=\\frac{R_1}{R_1+R_2}v$ 並聯\n$\\frac{1}{R_{eq}}=\\frac{1}{R_1}+\\frac{1}{R_2}+\u0026hellip;+\\frac{1}{R_N}$ $R_{eq}$ 永遠小於並聯電阻中最小的電阻值 $G_{eq} = G_{1}+G_2+\u0026hellip;+G_N$ 分流定理 (principle of current division) 各分支電流與電阻值成反比 分流器 (current divider) $i_1=\\frac{R_2}{R_1+R_2}i$ Y - $\\Delta$ 轉換 (Wye-Delta Transformations) 遇到電阻不是串聯也不是並聯的情況，要如何轉換 有時候把 Y 型網路和 $\\Delta$ 型網路相互轉換會比較好算 Y 型網路 = T 型網路 $\\Delta$ 網路 = $\\Pi$ 網路 $\\Delta$ - Y 轉換 (Delta to Wye conversion) Y 網路的每個電阻是 $\\Delta$ 中的兩個相鄰電阻的相乘除以 $\\Delta$ 中的三個電阻總和 Y - $\\Delta$ 轉換 (Wye to Delta conversion) $\\Delta$ 網路的每個電阻是 Y 中的兩兩電阻的相乘總和除以 Y 中的對角電阻\n平衡\n條件 $R_1=R_2=R_3=R_Y$ $R_a=R_b=R_c=R_{\\Delta}$ 結果 $R_Y=\\frac{R_\\Delta}{3}$ ","date":"2023-04-09T00:00:54+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E9%9B%BB%E8%B7%AF%E5%AD%B8-i/","title":"電路學 - I"},{"content":"目的 本文會試用 GPIO output / input / interrupt\nGPIO 架構 Output 介紹 在 ioc 那邊選個 pin，選 GPIO_Output\n在左邊欄位 System Core 選擇 GPIO\n有五個欄位可以設定\nGPIO output level\n初始電位 GPIO mode\npush pull 和 open drain 位於架構圖下方那部分，push pull 可以用 PMOS 和 NMOS 來得到高低電位，open drain 會 disable PMOS，讓你可以在外面自己接上拉電阻 GPIO Pull-up/Pull-down\nMaximum output speed\nUser Label\n用完記得 ctrl+s 讓他 generate code\n1 2 3 4 5 6 7 8 9 /*Configure GPIO pin : PtPin */ GPIO_InitStruct.Pin = RED_LED_Pin; GPIO_InitStruct.Mode = GPIO_MODE_OUTPUT_PP; GPIO_InitStruct.Pull = GPIO_NOPULL; GPIO_InitStruct.Speed = GPIO_SPEED_FREQ_LOW; HAL_GPIO_Init(RED_LED_GPIO_Port, \u0026amp;GPIO_InitStruct); /*Configure GPIO pin Output Level */ HAL_GPIO_WritePin(RED_LED_GPIO_Port, RED_LED_Pin, GPIO_PIN_RESET); 1 2 3 4 HAL_GPIO_WritePin(RED_LED_GPIO_Port, RED_LED_Pin, GPIO_PIN_RESET); // 低電位 HAL_GPIO_WritePin(RED_LED_GPIO_Port, RED_LED_Pin, GPIO_PIN_SET); // 高電位 HAL_Delay(1000); //等一秒 HAL_GPIO_TogglePin(RED_LED_GPIO_Port, RED_LED_Pin) 根據架構圖左側，你可以透過修改 BSRR 來修改 ODR，達到修改輸出的效果，請見 Reference Manuals，實際上 HAL_GPIO_WritePin 也是這樣實現的\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 void HAL_GPIO_WritePin(GPIO_TypeDef* GPIOx, uint16_t GPIO_Pin, GPIO_PinState PinState) { /* Check the parameters */ assert_param(IS_GPIO_PIN(GPIO_Pin)); assert_param(IS_GPIO_PIN_ACTION(PinState)); if(PinState != GPIO_PIN_RESET) { GPIOx-\u0026gt;BSRR = (uint32_t)GPIO_Pin; } else { GPIOx-\u0026gt;BRR = (uint32_t)GPIO_Pin; } } Input 介紹 看架構圖上方，用 Schmitt trigger 取得高低電位資料，他有 upper threshold 和 lower threshold，而不是用 single threshold\n1 2 3 4 5 /*Configure GPIO pin : PtPin */ GPIO_InitStruct.Pin = GREEN_LED_INPUT_Pin; GPIO_InitStruct.Mode = GPIO_MODE_INPUT; GPIO_InitStruct.Pull = GPIO_NOPULL; HAL_GPIO_Init(GREEN_LED_INPUT_GPIO_Port, \u0026amp;GPIO_InitStruct); 1 uint8_t green_led_input = HAL_GPIO_ReadPin(GREEN_LED_INPUT_GPIO_Port, GREEN_LED_INPUT_Pin); Interrupt ioc 選個 pin，設定 GPIO_EXTI，這邊我選 B1(PC13)，也就是開發版上的藍色按鈕\n可以選 GPIO mode，這邊選 Falling Edge Trigger，值得一提的是他的設計是上拉電阻，所以這樣不是放開後觸發，是按下後觸發。\nioc 的 System Core 的 NVIC 還要把 EXTI line[15:10] interrupts 給 enabled，然後 Code generation 打開 Generate IRQ handler，還有 Call HAL handler。\n在 stm32l4xx_it.c 裡， 現在會有\n1 2 3 4 5 6 7 8 9 10 void EXTI15_10_IRQHandler(void) { /* USER CODE BEGIN EXTI15_10_IRQn 0 */ /* USER CODE END EXTI15_10_IRQn 0 */ HAL_GPIO_EXTI_IRQHandler(B1_Pin); /* USER CODE BEGIN EXTI15_10_IRQn 1 */ /* USER CODE END EXTI15_10_IRQn 1 */ } 這兩行各別是因為我們剛剛開的功能生的\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 void HAL_GPIO_EXTI_IRQHandler(uint16_t GPIO_Pin) { /* EXTI line interrupt detected */ if(__HAL_GPIO_EXTI_GET_IT(GPIO_Pin) != 0x00u) { __HAL_GPIO_EXTI_CLEAR_IT(GPIO_Pin); HAL_GPIO_EXTI_Callback(GPIO_Pin); } } __weak void HAL_GPIO_EXTI_Callback(uint16_t GPIO_Pin) { /* Prevent unused argument(s) compilation warning */ UNUSED(GPIO_Pin); /* NOTE: This function should not be modified, when the callback is needed, the HAL_GPIO_EXTI_Callback could be implemented in the user file */ } __weak 代表有同名 function 的話，就會採用沒 __weak prefix 的\n所以我們可以在 gpio.c 放下面的程式碼\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #include \u0026lt;stdbool.h\u0026gt; void HAL_GPIO_EXTI_Callback(uint16_t GPIO_Pin) { if(GPIO_Pin == B1_Pin){ static bool prev_val = false; if(prev_val == false){ HAL_GPIO_WritePin(RED_LED_GPIO_Port, RED_LED_Pin, GPIO_PIN_SET); prev_val = true; } else{ HAL_GPIO_WritePin(RED_LED_GPIO_Port, RED_LED_Pin, GPIO_PIN_RESET); prev_val = false; } } } 實驗 設定兩個輸入，一個輸出，一個 interrupt\n當按下按鈕時，切換紅色 LED 的亮滅，並且讓板子上的綠色 LED 輸出和紅色 LED 相反的結果\nB1(PC13、藍色按鈕) 按下去的時候，會發出 interrupt，並讓 RED_LED(PC10) 輸出和上次相反的電位，讓麵包版上的紅色 LED 亮滅，正極那邊接一條杜邦線給 GREEN_LED_INPUT (PC12)，並且 LD2(PA5、板子上的綠色 LED) 會輸出和紅色 LED 相反的結果。\n程式碼\n","date":"2023-04-02T01:32:54+08:00","permalink":"https://roykesydon.github.io/Blog/p/stm32-gpio-%E5%AF%A6%E9%A9%97/","title":"STM32 GPIO 實驗"},{"content":"使用的板子 STM32L476RG\n開發文件 開發前需要先去 ST 官網，根據你的板子載四個重要文件\nDatasheet 上圖是其中的 block diagram\nReference Manuals\nProgramming Manuals\nSchematic\n創建 project File -\u0026gt; New -\u0026gt; STM32 Project Board Selector 搜索 NUCLEO-L476RG，選取並 Next 設置 Project Name，其他不動，Next Copy only the necessary library files，Finish ioc 專案會有個 .ioc 檔，可以透過 GUI 生成設定 pin 的程式碼\n建議 Project Manager 的 Code Generator 勾選 Generate peripheral initialization as a pair \u0026lsquo;.c/.h\u0026rsquo; files per peripheral，開發起來比較方便\nCompile 點選上面的 hammer\nClock Configuration ioc 那邊還可以設置 clock\nExternal clock LSE 和 HSE 是 (Low / High Speed External)，你有 oscillator 的話可以自己弄\n你可以調 sysclk 或 peripheral clock\nProgramming 在 USER CODE section 寫上程式碼\n選取的部分可以按 F3，看他是從哪邊來的，或看 macro 之類的\nDEBUG 上面有個 BUG 符號的東西，旁邊的箭頭可以用 DEBUG 的設定\n又建 STM32 C/C++ Application，可以 New 新設定\nC/C++ Application 那邊選你 compile 的 elf 檔\nDebugger 開啟 ST-LINK S/N，並且掃描，如果你的電腦有接上 MCU，應該會直接找到\n","date":"2023-04-02T00:32:54+08:00","permalink":"https://roykesydon.github.io/Blog/p/stm32cubeide-%E5%9F%BA%E6%9C%AC%E9%96%8B%E7%99%BC%E4%BD%BF%E7%94%A8/","title":"STM32CubeIDE 基本開發使用"},{"content":"paper: GIT: A Generative Image-to-text Transformer for Vision and Language\n1 2 3 4 5 6 ██████╗ ██╗████████╗ ██╔════╝ ██║╚══██╔══╝ ██║ ███╗██║ ██║ ██║ ██║██║ ██║ ╚██████╔╝██║ ██║ ╚═════╝ ╚═╝ ╚═╝ Abstract 設計了一個 Generative Image-to-text Transformer，統一 vision-language tasks，像是 image/video captioning 或是問答。\n雖然 generative models 在預訓練和微調的時候是同樣的網路架構，現有的工作通常都包含複雜的架構 (uni/multi-modal encoder/decoder)， 而且依賴於外部模組，比如物件偵測或 optical character recognition (OCR)。\n在 GIT，我們簡化為 single language modeling task 下的一個 image encoder 和一個 text decoder。\n擴大了預訓練資料和模型大小以提高模型性能。\n在許多具有挑戰性的 benchmarks 上取得 SOTA。\n比如首次在 TextCpas 上超越人類的表現。\n提出了一種 generation-based image classification and scene text recognition 的新方案。\nIntroduction 近年來在 vision-language（VL）預訓練方面取得了巨大進展，特別是基於 image-text pairs 的大規模數據，例如 CLIP、Florence 和 SimVLM。\n學習到的 representation 很好的提高了下游任務的性能，比如 image captioning、visual question answering 和 image-text retrieval。\n在預訓練過程中，Masked Language Modeling (MLM) 和 Image-Text Matching (ITM) 被廣泛使用。\n然而這些 loss 和下游任務不同，必須做 task-specific adaptation。\n比如， image captioning 要移除 ITM，VQA 需要額外隨機初始的 MLP。\n為了減少這種差異，最近的研究試圖為預訓練模型設計 unified generative models 來預訓練，因為大多數 VL 的問題可以轉化為生成問題。\n這些方法通常利用 multi-modal encoder 和 text decoder，並精心設計 text input 和 text target。\n為了進一步推動這方向的研究，作者設計了一個簡單的 Generative Image-to-text Transformer，稱作 GIT，只包含一個 image encoder 和 text decoder。\n預訓練任務只是把輸入的圖像映射到相關聯的文字描述。\n盡管他很簡單，但還是在眾多具有挑戰性的 benchmark 取得 SOTA。\nimage encoder 是 Swin-like vision transformer，在大量的 image-text pairs 上做 pretrain，基於 contrastive task。\n這消除了現有許多方法中對 object detector 的依賴。\n為了將其擴展到影片領域，我們把多個 frame 的特徵 concatenate，作為 video 表示。\ntext decoder 是一個用來預測相關聯文字的 transformer。\n整個網路都是基於 language modeling task 來訓練。\n對於 VQA，input question 被看作 text prefix，並以 auto-regressive 的方法生出答案。\n此外，作者提出了一種 generation-based 的 ImageNet classification 新方案，預測標籤直接根據作者的生成模型，而不用預先定義詞彙表。\n我們的作法很簡單，但在擴大預訓練資料和模型大小後，成果驚人。\n主要貢獻如下：\n我們展示了 GIT，僅由一個 image encoder 和一個 text decoder 組成，透過 language modeling task，在 0.8 billion image-text pairs 上 pretrain。\n在 image/video captioning 和 QA 上，沒有基於 object detectors，object tags 和 OCR，就在多個任務上取得 SOTA。證明簡單的網路架構也可以透過 scaling 取得強大的性能。\n我們證明 GIT 雖然 pretrain 在 image-text pairs，也能在 video tasks 上取得 SOTA，不需要 video dedicated encoders。\n我們提出了一種新的 generation-based image classification 方案，在 ImageNet-1K 上，取得不錯的性能。\nRelated Work 在 VL pre-training 中，多 multi-task pre-training 被廣泛使用，賦予網路多種或增強的能力。\n比如，MLM 和 ITM 是廣泛採用的預訓練任務，最近也有研究加入 image-text contrastive loss。\n由於多數 VL 任務都可以表示成 text generation task，所以可以訓練一個生成模型來支持各種下游任務。\n輸入和輸出文本通常都會經過精心設計，以預訓練這樣的生成模型。\n對於 image representation，Faster RCNN 被大多數現有方法用來提取區域特徵。\n同時，也很容易以 end-to-end 的方法訓練整個網路。\n除了 feature map，object tags，也很常被用來方便 transformer 理解上下文，特別是 novel objects。\n對於與場景文本相關的任務，調用 OCR 以生成場景文本作為附加網路輸入。\n對於 text prediction，常用 transformer network，結合 cross-attention module 來融合 image tokens。\n或者只是單純 concatenate text tokens 和 image tokens，然後用 self-attention。\n在本文中，我們有 9 個不同的 benchmark，3 種不同模型大小和 3 種不同預訓練資料規模。\nGenerative Image-to-text Transformer Network Architecture image encoder 基於 contrastive pre-trained model。\n輸入是原始圖像，輸出是 compact 2D feature map，被 flatten 成 list of features。\n透過一個額外的 linear layer 和一個 layernorm layer，image features 被 project 到 D dimensions，也就是 text encoder 的 input。\n作者使用做 contrastive tasks pretraining 的 image encoder，因為最近的研究表明這種 image encoder 有更好的性能。\n在後面的章節，還觀察到 VL performence 明顯地隨著更強的 image encoder 而有所提升。 這和 object detection-based 的方法觀察到的結果一致。\nCoCa 的 concurrent work 統一了 contrastive task 和 the generation task，作為一個預訓練階段。\n作者的方法相當於是按順序分離兩個任務:\n用 contrastive task 訓練 image encoder 用 generation task pretrain image encoder 和 text decoder text decoder 是一個用於預測文本描述的 transformer module，由多個 transformer block 組成，每個 transformer block 由一個 self-attention layer 和 feed-forward layer 組成。\ntext 被 tokenize 和 embed 到 D dimensions，並添加 positional encoding 和 layernorm layer。\nimage features 和 text embeddings 被 concatenate 起來作為 transformer module 的輸入。\ntext 以 [BOS] 開始，並以 auto regressive 的方式 decode，直到 [EOS] 或 maximum steps。\nattention mask 根據上圖設計，使的 text token 只能依賴於前面的 text token 和 image token，而 image token 可以互相做 attention。\n這和 unidirectional attention mask 不同，unidirectional attention mask 並非每個 image token 都可以依賴於其他的 Image token。\n作者很好地初始化 image encoder，卻隨機初始化 text decoder。\n這種設計動機是基於[MiniVLM: A Smaller and Faster Vision-Language Model]，該研究隨機初始化顯示出與 BERT 初始化相似地性能。\n原因可能在於 BERT 地初始化無法理解圖像信號，這對於 VL 任務至關重要。\n[Flamingo: a Visual Language Model for Few-Shot Learning] 採用了類似的 image encoder + text decoder，但是他們的 decoder 經過 pretrain，並且有 freeze，好保留大型語言模型的泛化能力。\nGIT 的所有參數都會更新，以更好地適應 VL 的任務。\n另一種架構是 cross-attention-based 的 decoder，用於 incorporate image signals，而不是 concatenation 再用 self-attention。\n根據實驗，large-scale 的 pre-training，self-attention-based 會有更好的性能，小規模的則是 cross-attention-based。\n一個合理的解釋是，經過充分訓練，decoder 可以很好地處理圖像和文本，而且 image token 可以為了 text generation 更好地更新。\n而 cross-attention 讓 image token 沒辦法 attend 彼此。\nPre-training 訓練採用 language modeling (LM) loss。\n$I$ 是 image $y_i,i \\in $ { $ 1,\u0026hellip;,N $ } 是文字 token，$y_0$ 是 [BOS]，$y_{N+1}$ 是 [EOS] CE 是有 0.1 label smoothing 的 cross-entropy 另一種選擇是 MLM，在每個 epoch 中預測 15% 的輸入 token，要預測所有 token 至少需要 1 / 0.15 = 6.7 個 epochs，對於 LM，每個 epoch 都可以預測所有 token，對於大規模預訓練資料來說效率更高。\nablation studies 顯示出 LM 可以在有限的 epoch 內實現更好的性能。 在大規模訓練中，由於計算資訊的限制，只有兩個 epoch，所以選擇 LM。 與此同時，大部分最近的 large-scale language model 也是基於 LM。\n如果沒有圖像輸入，該模型將簡化為 decoder-only 的語言模型，架構類似於 GPT-3。\n因此，這種設計還可以利用 text-only 的資料來提升 scaled-up decoder 的能力，把這保留給未來的工作。\nFine-tuning 對於 image captioning，由於訓練數據格式和預訓練相同，所以用同樣的 LM task 來微調 GIT。 對於 visual question answering，問題和 GT 在微調的時候被看做 special caption，但 LM loss 僅用於答案和 [EOS]。\n推理過程中，question 被當作 caption 的 prefix，完成的部分是預測。\nVQAv2 現有的工作收集候選答案，再重構成分類問題，預測一次。 作者的工作有更多挑戰，因為是生成式的，需要生出至少兩個正確的 token，答案和 [EOS]。\n然而考慮到自由形式答案的好處，作者選擇了生成方法。\n由於生成模型的難度，VQAv2 比現有的判別工作略差。\n對於和 scene-text related VQA 任務，現有方法通常利用 OCR 生成 5 個 scene text 並用 dynamic pointer network 決定當前輸出應該是 OCR 還是 general text。\n但由於作者的方法不依賴於 OCR，因此也不依賴於 dynamic pointer network。\n根據實驗，作者發現模型透過大規模預訓練資料學會如何閱讀場景文本，並且作者的模型不是專門為了影片領域設計的，但可以透過簡單的架構更改就取得具有競爭力或甚至 SOTA 的成果，也就是作者可以從每個影片採樣多個 frame，並透過 image encoder 獨立地為每個 frame 編碼。 最後添加一個 learnable temporal embedding (初始化為 0)，並 concatenate sampled frames 的特徵。\n作者還用於圖片分類，把 class name 用於 caption。\n這和現有工作不一樣，現有工作通常先定義詞彙表，並用線性層預測每個類別的可能性。\n當新數據和新類別被添加到現有數據的時候，這種新一代的方案是有益的，因為這樣可以在不引入新參數的情況下對新數據進行訓練。\nExperiments Setting 收集 0.8B 的 image-text pairs 來預訓練。\nimage encoder 是根據 pre-trained contrastive model 初始化的。\nhidden dimension (D) = 768\ntext decoder 有 6 個 randomly-initialized transformer blocks\n共有 0.7b 的參數\nimage decoder 和 text encoder 的 learning rate 各別是 1e-5 和 5e-5，都 cosine decay 到 0\n推論階段 beam size 是 4，length penalty 是 0.6。\nSupplementary materials 展示了小模型變體 (GITB and GITL) 和更大模型 (GIT2) 的結果\nResults on Image Classification 輸出必須與類別名稱完全匹配，甚至考慮多或少的空格。\n由於不知道詞彙表，精確匹被準確度只有 1.93%，如果預測包含 GT 就對，那有 40.88%。\n通過微調每個類別只有 1 shot 或 5 shot，準確度會顯著提高， 表明只用少量訓練樣本，也可以輕鬆適應下游任務。\n與 Flamingo 相比，GIT 實現更高的準確度。\nFlamingo 在沒有參數更新的情況下進行小樣本學習，但需要額外的網路輸入，可能會增加推理成本。\n相比之下，GIT 透過一次 lightweight fine-tuning，推理過程中不需要這些 training shot。\nAnalysis Model and data scaling 對於網路架構，作者的模型被稱作 Huge，把 image encoder 換成 CLIP 的 ViT-B/16 和 ViT-L/14 的則是 Base 和 Large。\n可以看出較大的 image encoder 帶來的好處，但根據實驗， 作者發現很難有效地擴展 text decoder，原因可能是 LM 很難用 limited amount of text 來訓練。\n另一個可能的原因是 image encoder 負責 object recognition，而 decoder 負責以 NLP 的方法組織 object terms。 後一項任務可能很容易，因為大多數描述都遵循相似的模式，比如 Object + verb + subject，所以只要一個 small decoder，較大的 decoder 可能會增加學習難度。\nFlamingo 的研究顯示更大的 Decoder 可以提高性能，但是他們的 decoder 有 pretrain 過，而且在 VL 預訓練的時候 frozen，避開了如何有效訓練 decoder 的問題。\nLEMON 的 transformer 可以擴展到 32 層，可能是因為他們使用 MLM 而不是 LM，後者可能更加困難。\nScene text in pre-training data 為了瞭解 scene text comprehension 的能力，作者檢查了 pretrain data 有多少 image-text pairs 有 scene text。\n作者用 Microsoft Azure OCR API4 對一些資料做 OCR，然後把 OCR 結果和 associated text 做比對，只有包含長度超過 5 個字元的 OCR 結果才會算比對。 有 15% 的 CC12M 和 31% 的下載圖像(500K) 包含 scene text 描述。 由於任務是訓練預測 text，網路逐漸學會閱讀 scene text。\nConclusion Limitations 根據實驗，目前不清楚如何控制生成的 caption 以及如何在不更新參數的情況下執行 in-context learning，把這留給未來的工作。\nSocietal impact 該模型在大規模數據集上預訓練，不能保證數據不含 toxic language，可能會 poison output。\n其他 A.3 Network 講超參數\n","date":"2023-03-29T01:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/git-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"GIT 論文閱讀"},{"content":"paper: RoBERTa: A Robustly Optimized BERT Pretraining Approach\n1 2 3 4 5 6 ██████╗ ██████╗ ██████╗ ███████╗██████╗ ████████╗ █████╗ ██╔══██╗██╔═══██╗██╔══██╗██╔════╝██╔══██╗╚══██╔══╝██╔══██╗ ██████╔╝██║ ██║██████╔╝█████╗ ██████╔╝ ██║ ███████║ ██╔══██╗██║ ██║██╔══██╗██╔══╝ ██╔══██╗ ██║ ██╔══██║ ██║ ██║╚██████╔╝██████╔╝███████╗██║ ██║ ██║ ██║ ██║ ╚═╝ ╚═╝ ╚═════╝ ╚═════╝ ╚══════╝╚═╝ ╚═╝ ╚═╝ ╚═╝ ╚═╝ Abstract 發現 BERT 訓練不足，並且作者的模型在 4/9 的 GLUE 任務, RACE 和 SQuAD 取得 SOTA。\nIntroduction 自監督的訓練方法帶來了顯著的性能提升，但要確定這一堆方法中的哪些方面貢獻最大，具備挑戰性。\n訓練的計算量是昂貴的，使 fine-tune 受限，而且通常都是用不同大小的 private training data，使評估模型更加困難。\n作者提出了對 BERT 預訓練的 replication study，包括對超參數的調整，以及對訓練集大小的仔細評估。\n作者發現 BERT 訓練不足，並提出了一種改進方法，稱為 RoBERTa，可以達到或超過所有 post-BERT 的方法。\n修改如下:\n訓練模型的時間更長，batch 更大，用更多 data 移除 next sentence prediction objective 訓練更長的序列 動態地改變用於訓練資料的 masking pattern 貢獻:\n提出一組重要的 BERT 設計選擇和訓練策略 使用了新的 dataset，叫做 CCNEWS，並證明用更多的資料來預訓練，可以提高下游任務的表現 訓練表明，在正確的設計選擇下，pretrained masked language model 和其他最近的方法比，具有競爭力 Background 對 BERT 做回顧\nArchitecture L layers A self-attention heads H hidden dimension Training Objectives 預訓練的時候，BERT 有兩個目標: masked language modeling 和 next sentence prediction\nMasked Language Model (MLM) BERT 隨機選擇 15% 的 token 進行可能的替換\n80% 換成 [MASK]，10% 保持不變，10% 被選為一個隨便的 vocabulary token\nNext Sentence Prediction (NSP) 分類第二句是不是下一句，是二元分類。\n正例由提取連續的句子產生，負例由不同的片段配對產生。\n正例和負例以相等機率產生。\nOptimization Adam $\\beta_1$ = 0.9, $\\beta_2$ = 0.999, $\\epsilon$ = 1e-6 $L_2$ weight decay of 0.01 Learning rate 前 10,000 step warm up 到 1e-4，然後 linear decay 全部的 layer 和 attention weight 都 dropout 0.1 GELU 激活函數 1,000,000 次 update，batch size 256，序列長度 512 Data BERT 在 BookCorpus 和 English Wikipedia 混和的資料集上訓練，共有 16GB 的未壓縮文本\nExperimental Setup 描述對於 BERT 的 replication study 的實驗設置\nImplementation 作者用 FAIRSEQ 重新實現了 BERT。\n主要遵循 [Background-Optimization] 中的 BERT 原始超參數，但 peak learning rate 和 warmup step 除外，他們針對每個設置單獨調整。\n作者發現訓練對 Adam epsilon 非常敏感。\n作者發現設置 $\\beta_2$ = 0.98，在大 batch size 的情況下，可以提高訓練時的穩定性。\n用最多 512 個 token 預訓練。\n作者不會隨機注入短序列，也不會為前 90% 的更新縮短輸入的長度。\n作者只訓練 full-length 的 sequences。\nData BERT-style 的預訓練仰賴大量文本。\n已有研究證明增加數據量可以提高 end-task 的性能。\n已有一些研究，用比原始 BERT 更多樣更大的數據集，但不是所有的數據集都有公開。\n本研究用了五個不同大小和領域的英文文本，共有超過 160 GB 的未壓縮文本。\n使用以下數據集:\nBookCorpus + English Wikipedia BERT 原本使用的。 16 GB CC-News 作者從 CommonCrawl News dataset 的英文部分中蒐集，包含了 2016 年 9 月到 2019 年 2 月的 6300 萬篇英文新聞。 過濾後有 76 GB OpenWebText WebText 的開源重建版，從 Reddit 上至少有 3 個 upvotes 的 shared URLs 提取出的 Web 內容。 38 GB Stories 包含 CommonCrawl data 的一個子集合，經過過濾，以匹配 story-like style of Winograd schemas 31 GB Evaluation 使用以下三個 benchmarks 評估預訓練模型\nGLUE The General Language Understanding Evaluation\n用於評估自然語言理解的 9 個數據集的集合，任務被定義為 single-sentence 分類或 sentence-pair 分類任務。\nfinetune 的流程遵循原始 BERT paper\nSQuAD The Stanford Question Answering Dataset\n提供一段 context 以及一個問題\n具有兩個版本 V1.1 和 V2.0\nV1.1 context 總是包含一個答案 評估 V1.1 的時候，作者採用和 BERT 相同的 span prediction method V2.0 一些問題在提供的 context 中沒有回答，使任務更有挑戰性 評估 V2.0 的時候，作者會用一個額外的二元分類器預測問題是否可以回答，在評估的時候，只預測被分類為可回答的 RACE The ReAding Comprehension from Examinations 大型閱讀理解數據集，有超過 28,000 篇文章 以及將近 100,000 個問題 從中國的英文考試蒐集的，這些考試是為國中生和高中生設計的 每篇文章都與多個問題相關聯 對每個問題，要從四個選項中選出一個對的 context 比起其他閱讀理解的數據集要長，而且要推理的問題比例很大 Training Procedure Analysis 探討哪些選擇對成功預訓練 BERT 很重要。\n作者把架構固定，也就是訓練和$BERT_{BASE}$ (L=12, H=768, A=12, 110M params)一樣架構的 BERT models\nStatic vs. Dynamic Masking BERT 在 preprocessing 的時候處理 masking，產生單個 static mask。 作者為了避免在每個 epoch 都對每個 instance 用相同的 mask，將數據複製了 10 次，在 40 個 epochs 裡，以 10 種不同的方式 mask。所以一次訓練過程中，相同的 mask 會出現四次。\n作者會以上述策略和 Dynamic masking 進行比較，Dynamic masking 是在每次餵 model 前，才生成 mask。\n作者發現 Dynamic Masking 相比 static，要不是差不多，就是略好，基於結果和效率的優勢考量，其他實驗中都用 dynamic masking。\nModel Input Format and Next Sentence Prediction 原始的 BERT 預訓練中，兩個句子要不是同一個文件的連續句子(p = 0.5)，不然就是不同的 document 做採樣\n以往有研究指出移除 NSP 會損害性能，但也有研究質疑必要性，所以本文比較了幾種替代訓練格式：\nSEGMENT-PAIR+NSP 最原始的方法，每個 segment 可以有多個自然句子 SENTENCE-PAIR+NSP 只包含一對句子，由於輸入明顯少於 512 token，所以會增加 batch size 讓 token 總數和前者差不多 FULL-SENTENCES 包含從一個或多個文件中連續採樣的完整句子，可能會跨越文件邊界，在文件邊界間會加個額外的分隔符 移除了 NSP DOC-SENTENCES 和 FULL-SENTENCES 差不多，但不能跨越 document，在 document 尾巴的部分會容易少於 512，所以會動態增加 batch size，讓 token 總數和 FULL-SENTENCES 差不多 移除了 NSP 發現 DOC-SENTENCES 是最棒的，但由於 DOC-SENTENCES 會讓 batch sizes 大小可變，所以其他實驗會用 FULL-SENTENCES，比較好和其他相關工作比較。\nTraining with large batches 根據過去神經網路機器翻譯的工作，當 learning rate 適當增加的時候，用非常大的的 mini-bathces 可以提高 optimization 的速度和 end-task 性能。\n最近的研究也顯示 BERT 適用於 large batch training。\nText Encoding Byte-Pair Encoding (BPE) 是一種介於字符級別和詞級別表示之間的混合表示方法，它允許處理自然語言語料庫中常見的大詞彙量。\nBPE 不依賴於完整的單詞，而是依靠 subwords units，通過對訓練語料進行統計分析來提取這些 subwords units。\nBPE 詞彙表的大小通常在 10K-100K 的 subword units。\n在 \u0026ldquo;Language Models are Unsupervised Multitask Learners\u0026rdquo; 文中，提到了一種巧妙的 BPE 實現，不是用 unicode characters，而是用 bytes 作為 base subword units。可以生出 50K 大小的詞彙表，而且不用引入任何的 \u0026ldquo;unknown\u0026rdquo;。\n原始的 BERT 用 character-level BPE vocabulary，大小為 30K。\n本文考慮用 50K byte-level BPE vocabulary，而不對輸入做額外的 preprocessing 或 tokenization，\u0026ldquo;Language Models are Unsupervised Multitask Learners\u0026rdquo; 的研究顯示這些 Encoding 的方法在最終效能上並無太大差別，只在某些任務上 end-task performance 表現稍差。\n但作者相信 universal encoding scheme 的優勢超過了輕微的性能下降，其他實驗也會用這種邊碼方式。\nRoBERTa 整理上面說的改進。\nRoBERTa 用以下配置:\ndynamic masking FULL-SENTENCES without NSP loss large mini-batches larger byte-level BPE 此外，還調查了兩個之前的工作沒強調的重要因素:\n用於預訓練的 data 訓練過 data 的次數 為了把這些因素的重要性和其他模型選擇分隔開，先按照 $BERT_{LARGE}$ (L = 24, H = 1024, A = 16, 355M parameters) 訓練 RoBERTa。\n作者在 BOOKCORPUS plus WIKIPEDIA dataset 進行了 100K step 的預訓練。\n在控制 training data 的情況下， RoBERTa 比 $BERT_{LARGE}$ 的結果有大幅度的改進，重申了前面設計選擇的重要性。\n接下來，結合之前說的額外 dataset，並用相同的步數(100K) 訓練 RoBERTa，觀察到下游任務的性能進一步提高，驗證了數據大小和多樣性的重要性。\n最後，對 RoBERTa 做更長時間的預訓練，將步數提高到 300K 和 500K，再次觀察到下游任務性能顯著提升。\n作者也注意到，即使是他們訓練時間最長的模型，也不會 overfit 他們的數據。\n本文的其他部分在三個 benchmark 評估好壞: GLUE、SQuaD 和 RACE\nGLUE Results 雖然很多 GLUE 排行榜的提交都是 depend on multi-task finetuning，但作者的 submission 是 depends only on single-task finetuning。\n此外，對於 RTE、STS 和 MRPC，從 MNLI 的模型微調會比 baseline 的 RoBERTa 有幫助許多。\n在第一個設置 (single-task, dev) 中，RoBERTa 在所有 9 個 GLUE 任務 dev set 上都取得了最先進的結果。\n在第二個設置 (ensembles, test) 中，作者將 RoBERTa 提交到 GLUE 排行榜，並在 9 個任務中的 4 個上取得了 SOTA 和迄今為止的最高平均分。\n這令人興奮的地方在於，與多數 top submissions 不同，RoBERTa 不是 depend on multi-tasking finetuning\nConclusion 在預訓練 BERT 模型時，作者仔細評估了許多設計決策。\n作者發現，通過對模型進行更長時間的訓練、使用更大的批次處理更多的數據、去除 NSP、訓練更長的序列、dynamic masking，可以顯著提高性能。\n作者改進的預訓練程序，我們稱之為 RoBERTa，在 GLUE、RACE 和 SQuAD 上實現了 SOTA，而無需為 GLUE 進行多任務微調或為 SQuAD 提供額外的數據。\n這些結果說明了這些以前被忽視的設計決策的重要性，並表明 BERT 的預訓練目標與最近提出的替代方案相比仍然具有競爭力。\n","date":"2023-03-22T01:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/roberta-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"RoBERTa 論文閱讀"},{"content":"開發環境 IDE SW4STM32 支援 STM32 GCC C/C++ compiler GDB-based debugger 板子 STM32 Bucleo Board Cortex-M4 ST-LINK debugger Memories 1MB Flash 128KB SRAM Debug Interface JTAG Joint Test Action Group standard ASICs hardware debug interface SWD Serial Wire Debug 只從 JTAG 用 5 wires Bootup Code Reset\nBoot Loader\n0x00000000 的程式 把 CPU 重置 Reset handler\nStstem initialization C startup code\nApplication(main)\nMemory map 見官網 memory map\n只用到 SRAM 的 128KB(SRAM)，還有 Code 的 1MB(Flash)\nSections .data 儲存資料 .text 儲存程式碼 同 section 會放在一塊是為了設定 read-only 方便，比如 .text 的要靠硬體實現 read-only\n重要的額外文件 Linker Script 定義了不同 section 該存放的地方，以及 memory 相關定義 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 MEMORY { RAM (xrw)\t: ORIGIN = 0x20000000, LENGTH = 96K ROM (rx)\t: ORIGIN = 0x8000000, LENGTH = 1024K } SECTIONS { /* The program code and other data into ROM memory */ .text : { . = ALIGN(8); *(.text) /* .text sections (code) */ *(.text*) /* .text* sections (code) */ *(.glue_7) /* glue arm to thumb code */ *(.glue_7t) /* glue thumb to arm code */ *(.eh_frame) KEEP (*(.init)) KEEP (*(.fini)) . = ALIGN(8); _etext = .; /* define a global symbols at end of code */ } \u0026gt;ROM .data : { . = ALIGN(8); _sdata = .; /* create a global symbol at data start */ *(.data) /* .data sections */ *(.data*) /* .data* sections */ . = ALIGN(8); _edata = .; /* define a global symbol at data end */ } \u0026gt;RAM AT\u0026gt; ROM } Make File 描述如何編譯和連接的規則 把 startup 的 .s檔加進去 startup_stm32.s 編譯好後擺在 binary 頭的地方\nvector table\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 /****************************************************************************** * * The STM32L476RGTx vector table. Note that the proper constructs * must be placed on this to ensure that it ends up at physical address * 0x0000.0000. * ******************************************************************************/ .section .isr_vector,\u0026#34;a\u0026#34;,%progbits .type g_pfnVectors, %object .size g_pfnVectors, .-g_pfnVectors g_pfnVectors: .word _estack .word Reset_Handler .word NMI_Handler .word HardFault_Handler .word\tMemManage_Handler .word\tBusFault_Handler .word\tUsageFault_Handler .word\t0 .word\t0 .word\t0 .word\t0 .word\tSVC_Handler Reset_Handler 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 Reset_Handler: ldr r0, =_estack mov sp, r0 /* set stack pointer */ /* Copy the data segment initializers from flash to SRAM */ ldr r0, =_sdata ldr r1, =_edata ldr r2, =_sidata movs r3, #0 b LoopCopyDataInit LoopCopyDataInit: adds r4, r0, r3 cmp r4, r1 bcc CopyDataInit /* Zero fill the bss segment. */ ldr r2, =_sbss ldr r4, =_ebss movs r3, #0 b LoopFillZerobss LoopFillZerobss: cmp r2, r4 bcc FillZerobss /* Call the clock system intitialization function.*/ bl SystemInit /* Call static constructors */ bl __libc_init_array /* Call the application\u0026#39;s entry point.*/ bl main ARM Register ARM 的可存取暫存器為 R0-R15\nr13: Stack Pointer r14: Link Register r15: Program Counter r0~r7 是 low register r8~r15 是 high register 狀態暫存器\nCPSR (Current Processor Status Register) 用來儲存各種狀態，包含 condition flag，比如 negative, zero, carry, overflow carry: 無符號加法操作是否溢出 overflow: 有符號加法操作是否溢出 當兩個都為 1 或都為 0 代表運算沒問題 有多種模式，有些模式有自己獨立的 r 暫存器，並有 SPSR，用來在中斷發生時，把 CPSR 的資訊 copy 過去\nSpecial-purpose registers\nAPSR, IPSR, EPSR Assembly syntax UAL: Unified Assembler Language 自己去翻 instruction set Instructions class Branch instructions B, BL, BX,\u0026hellip; Data-processing instructions MOV, ADD, SUB, MUL,\u0026hellip; Load and store instructions LDR, STR,\u0026hellip; Status register access instructions MSR, MRS,\u0026hellip; Miscellaneous instructions Memory Barrier instructions Exception-Related instructions Pseudo instructions examples MOVS R0, #0x12\nR0=0x12 MOVS R1, #`A` R1=A(ASCII) NVIC_IRQ_SETEN EQU 0xE000E100\n宣告常數 NVIC_IRQ_SETEN，賦值 0xE000E100 LDR R0,=NVIC_IRQ_SETEN\n放 0xE000E100 進 R0 這不能改成 MOVS R0, #0xE000E100 ，因為每個 instruction 只有 32 個 bits，這勢必塞不下，必須從記憶體 load 進來 NVIC_IRQ0_ENABLE EQU 0x1\n宣告常數 NVIC_IRQ0_ENABLE，賦值 0x1 MOVS R1, #NVIC_IRQ0_ENABLE\nR1=0x1 STR R1, [R0]\n把 0x1 存到 0xE000E100，這裡可以 enable external interrupt IRQ#0 LDR rn [pc, #offset to literal pool]\nload register n with one word from the address [pc + offset] 最後的形式 Operand2 共有 12 bits 設計成 4 bits for rotate, 8 bits for Immediate ARM instrcution formats ADD vs ADDS 有 S 代表會去更新 status cond 根據之前的執行情況，判斷指令要不要執行 suffix Reverse Ordering Operations REV (Byte-Reverse Word) 把 4 個 Byte 全數反轉，用在一個是 Little-Endian 一個是 Big-Endian 的情況 Load and Store Instructions examples LDR r0, [r1] r0 = [r1] LDM r0, {r1, r2} r1 = [r0] r2 = [r0+4] STM r0, {r1, r2} [r0] = r1 [r0+4] = r2 Status Register Access Instructions 一般來說不太會用到，因為用 suffix 就可以看條件 MRS: Register = Status Register MRS r0, IPSR MSR: Status Register = Register MSR APSR, r0 If-Then-Else 用 CMP 和 conditional branches Example 1 2 CMP R0, #10 ;compare r0 to 10 BLE incr_counter ; if less or equal, then branch to incr_counter Branch Instructinos 能跳的距離受限於 operand 長度\nB-Branch 能跳 PC 的 +/- 2046 bytes BL-Branch and Link 能跳 PC 的 +/- 254 bytes Branch to subroutine 的時候，會把下一行指令放到 Link register 沒有 push 到 stack，所以要特別小心，register 是共用的， 可能要視情況自己放到 stack 比如要進兩層 function，可以用 push {r4-r6, LR} 和 POP {R4-R6, PC} 這種做法來保留參數 BX-Branch and exchange return Stack memory access PUSH\nSP = SP - N*4 POP\nSP = SP + N*4 Ascending/Descending\nstack 往哪個方向長 Empty/Full\nstack 指向下一個空的位置，還是最後一個 item 預設且常見的是 fully descending\nSTM 和 LDM 可以透過 suffix 來存到 stack\nexample STMFD r13!, {r4-r7} 把 r4 到 r7 push 到 stack Memory Barrier Instructions DMB, SDB, ISB 在下個指令前 sync memory data Function Call and Parameter Passing caller 和 callee 誰負責 backup 和 restore caller 負責 不管 callee 怎樣亂搞都行 但不知道 callee 要用哪些參數，全 backup 可能多此一舉 怎麼傳遞參數給 callee 常放在 stack，但這樣要透過 memory，相較 register 慢 怎麼 return value 給 caller 和上個問題差不多 ARM Procedure Call Standard 又稱 APCS，講不同的 register 的一種使用規範\nr0-r3 用來當參數和回傳 r4-r11 用來 local variable，callee 使用前可以先 backup r12-r15 特殊用途，沒事別亂動 ","date":"2023-03-21T01:32:54+08:00","permalink":"https://roykesydon.github.io/Blog/p/arm-%E7%B5%84%E5%90%88%E8%AA%9E%E8%A8%80%E4%BB%8B%E7%B4%B9/","title":"ARM 組合語言介紹"},{"content":"paper: PatentSBERTa: A Deep NLP based Hybrid Model for Patent Distance and Classification using Augmented SBERT\nAbstract 本研究提供了一個計算 patent-to-patent (p2p) technological similarity 的有效方法。\n並提出一個 hybrid framework，用於把 p2p 相似性的結果應用於 semantic search 和 automated patent classification。\n把 Sentence-BERT (SBERT) 用在 claims 上來作 embeddings。\n為了進一步提升 embedding 的品質，使用基於 SBERT 和 RoBERT 的 transformer model，然後再用 augmented approach 在 in-domain supervised patent claims data(相對於 out-domain) 來 fine-tune SBERT。\n用 KNN(Nearest Neighbors) 來根據 p2p similarity 分類模型。\nIntroduction 傳統上的 p2p 相似度是基於關鍵字、技術類別等 metadata 決定的，但近期 semantic-based 的方法也越來越受歡迎。\n目前遇到的問題 BERT 用來計算 p2p 相似性的成本很高 基於 generic text 的 pre-trained model 在遇到特定領域的專業術語時可能會遇到侷限。 在專利做 multi-label classification (MLC) 是個挑戰 貢獻 提供一個快速高效的框架，利用 Transformer 架構計算 p2p 相似度 透過 augmented SBERT，將 transformer model fine-tune 到 domain-specific language 提出一個基於 Transformer 和 傳統 ML 模型的混和架構，可以打敗 multi-label 和 multi-class 的專利分類 SOTA 模型 用簡單的 KNN 進行專利分類，提供了一種簡單的方法來檢查、理解和解釋模型的預測結果 Data Dataset Description 本研究使用 PatentsView dataset，PatentsView 平台建立在一個定期更新的 database 上。\ndataset 已用於之前類似的研究，比如 DeepPatent、PatentBERT。\n本研究使用了 2013-2017 的所有專利，這些專利至少要在 BigQuery 上有一條 claim。\n本研究的 record 有 1,492,294 項專利，並用 8% 作為測試集。\n此外，本研究刪除了有重複專利 ID 和 claim text 的 record。\nTextual Data: Patent Claims 本研究使用 claim 作為輸入。\nclaim 被認為是準備專利文件的初始框架，其他文件都是根據 claim 準備的， 因此，claim 比其他文件包含更全面和準確的訊息。\nclaim 具有層次結構，first claim 被視為該架構的主幹。\n本研究僅使用 first claim，但在以後的研究中，希望根據 tree structure 組合所有 claim，並計算 semantic similarity，並做多標籤分類。\n在研究樣本中， claim 平均有 17 個。\nclaim 的平均長度是 162，本研究中，BERT 的 max_seq_length 是 510。\nPatent Classification: CPC Classes CPC系統和IPC（國際專利分類）系統是最常用的兩種分類系統，CPC 是 IPC 系統的更具體和詳細的版本。\nCPC 具有用於分類的層次結構，包括 Section、Class、Subclass 和 Group， 在子類級別，CPC 有 667 個標籤。\n在數據集中我們有 663 個標籤，其中 159 個在數據集中的樣本少於 350 個，這種標籤分佈導致了 KNN 不好處理，一般來說，隨著 instance 數量的增加，我們可以提高模型的準確性。\nMethod and experimental setup Pretrained Language Models (LMs) 在 NLP 中變得十分流行。\n在 pairwise sentence semantic similarity，SBERT 和 BERT 是兩種具有顯著不同效果的方法。\nBERT 通常可以取得更好的性能，但在實際應用上來說太慢了。\nSBERT 在實際應用上表現還行，但需要 in-domain training data 並且 finetune。\n上圖是 Augmented SBERT In-domain approach。\nin-domain sentence pairs 透過 cross-encoder 來標記，假設有 n 個 in-domain sentences，會有 $C_2^n$ 組可能的組合。\n使用所有可能的組合並不會提高性能，所以要有正確的採樣策略，才可提升性能的同時也減少計算開銷。\n上圖那種結合 cross-encoder 和 bi-encoder 的作法被稱為 Augmented SBERT (AugSBERT)， 涉及以下三個步驟:\n用資料集 Fine-tune RoBERTa 以生出 cross-encoder 用 cross-encoder 來把未標記的資料標記，同時基於某種特定的採樣策略，從 652,653 種可能的組合中挑選 3432 組 把資料集 + 額外的 3432 組資料一起拿來訓練 SBERT Results P2P similarity and semantic search Patent Semantic Search (PSS) 是專利分析的基礎部分。\nTransformer 模型等語義相似性的解法是一種新解法，可以用來解決基於關鍵字的搜尋方法中， query terms 和專利內容不匹配的問題。\n為了評估模型的準確性，未來的研究中，作者希望通過 Mean Reciprocal Rank (MRR) 來評估分類結果。\nCPC Prediction Top-N 準確度等於 GT 與預測有最高概率的任何 N 個預測匹配的頻率， 所以 Top-5 就是最高的五個分類中一個就有中。\nConclusion 本文使用 augmented SBERT 獲得 SOTA 的專利文本 embedding。\n介紹了一種 augmented 的方法，把 SBERT 微調到適合 patent claims 的 domain。\nSBERT 的一個主要優點是可以有效率地獲得 embedding distance，使我們能夠為大的專利資料集建構 p2p similarity。\n雖然基於文本的 p2p similarity 的有用性已經在各種應用方面得到證明，但本文進一步證明作者的 transformer-based p2p similarity 可以被用在 SOTA 的專利分類。\n而且使用簡單的 KNN 方法，檢查他們可以使模型決策具備 understandable 和 explainable。\nLimitations \u0026amp; Future Research 未來希望用 Annoy(Approximate Nearest Neighbor Oh Yeah!) 來測試更大樣本的模型並比較結果。\nAnnoy(Approximate Nearest Neighbor Oh Yeah!) 是想尋找近似相似而不是精確相似的句子。\n","date":"2023-03-15T15:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/patentsberta-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"PatentSBERTa 論文閱讀"},{"content":"Introduction 結合 policy-based 和 value-based\nA3C Actor-Critic 最知名的方法 Advantage Actor-Critic 是 A2C Advantage Actor-Critic Review: Policy gradient\n$\\triangledown \\overline{R_{\\theta}}\\approx \\frac{1}{N}\\displaystyle\\sum_{n=1}^{N}\\displaystyle\\sum_{t=1}^{T_n}(\\displaystyle\\sum_{t^{\u0026rsquo;}=t}^{T_n}\\gamma^{t^{\u0026rsquo;}-t}r_{t^{\u0026rsquo;}}^n-b)\\triangledown log p_{\\theta}(a_t^n|s_t^n)$ $G_t^n=\\displaystyle\\sum_{t^{\u0026rsquo;}=t}^{T_n}\\gamma^{t^{\u0026rsquo;}-t}r_{t^{\u0026rsquo;}}^n-b$ G very unstable，因為給同樣的 state 作同樣的 action 不一定會得到同樣的結果，G 是個 random variable 想要改獲得期望值，取代掉 sample 的值(G 的部分)，可以用 Q-Learning\n$E[G_t^n]=Q^{\\pi_\\theta}(s_t^n,a_t^n)$ Q function 這樣定義 所以我們可以把 G 的部分改用 Q 替換掉，就可以把 Actor 和 Critic 結合起來 baseline 的部分也可以用 value function 替換掉 但用 $Q^{\\pi}(s_t^n,a_t^n)-V^{\\pi}(s_t^n)$ 要一次 estimate 兩個 network\n可以把 Q 以 V 來表示，那只需要估測 V $Q^{\\pi}(s_t^n,a_t^n)=E[r_t^n+V^{\\pi}(s_{t+1}^n)]$ 雖然有隨機性(獲得的 reward 和跳到什麼 state 不一定)，但先不管期望值 $Q^{\\pi}(s_t^n,a_t^n)=r_t^n+V^{\\pi}(s_{t+1}^n)$ 現在雖然多個一個 r，有一些 variance，但也比 G 好 $\\triangledown \\overline{R_{\\theta}}\\approx \\frac{1}{N}\\displaystyle\\sum_{n=1}^{N}\\displaystyle\\sum_{t=1}^{T_n}(r_t^n+V^{\\pi}(s_{t+1}^n)-V^{\\pi}(s_t^n))\\triangledown log p_{\\theta}(a_t^n|s_t^n)$\nTips actor $\\pi(s)$ 和 critic $V^{\\pi}(s)$ 的權重可以共享\n前面幾個 layer 可以 share 對 $\\pi$ 的 output 下 constrain，讓他的 entropy 不要太小，達到 exploration 的效果\nAsynchronous Advantage Actor-Critic 一開始有個 global network，開一堆 worker，每次工作前，把 global network 的參數 copy 過去 個別去和環境作互動，更新的梯度施加在 global network 上 Pathwise Derivative Policy Gradient 可以當作是 Q-Learning 解 continuous action 的一種方法 訓練一個 actor，目標是生出的 a 餵給 Q 後，可以讓 Q function 的輸出越大越好 只會調 actor 的參數，會 fix Q 的 就是個 GAN 在每個 episode\n對於每個 time step t ⚠️給 state $s_t$，根據 $\\pi$ 執行 action $a_t$ (epsilon greedy)⚠️ 獲得 reward $r_t$，到達 $s_{t+1}$ 把 {$s_t,a_t,r_t,s_{t+1}$} 存到 buffer 從 buffer sample {$s_t,a_t,r_t,s_{t+1}$}(通常是一個 batch) ⚠️Target $y=r_i+\\hat{Q}(s_{i+1},\\hat{\\pi}(s_{i+1}))$⚠️ Update Q 的參數，好讓 $Q(s_i,a_i)$ 更接近 y(regression) ⚠️Update $\\pi$ 的參數，讓 $Q(s_i,\\pi(s_i))$ 最大化⚠️ 每 C 步 reset $\\hat{Q}=Q$ ⚠️每 C 步 reset $\\hat{\\pi}=\\pi$⚠️ ⚠️ 是和 Q-Learning 不一樣的地方\n","date":"2023-03-14T16:21:23+08:00","permalink":"https://roykesydon.github.io/Blog/p/actor-critic/","title":"Actor-Critic"},{"content":"Normalization 目的 避免 redundent information 更容易 understand、enhance、extend 避免 anomalies 隨著 1NF ~ 5NF，有更多的 safety guarantee\n1NF 違反條件 用 row order 傳達資訊 mixing data types in single column 但 relational database 不會讓你這樣做 存在沒有 primary key 的 table repeating groups 同一個 column 有多個數值，或是在同一個 row 存多個同類型的數值。 ex : player item roy 1 item_1, 4 item_2 star 4 item_4 player item_type1 quantity1 item_type2 quantity2 roy item1 1 item2 4 star item_4 4 2NF 所有的 non-key attribute 都要 depend on 整個 PK 非正式定義，有點細微差異 functional dependency ex: {player_id, item_type} -\u0026gt; {item_Quantity} 3NF transitive dependency {A} -\u0026gt; {B} -\u0026gt; {C} 所有 non-key attribute 都要 depend on the whole key，不能 depend on 其他 non-key attribute Boyce-Codd Normal Form 所有 attribute 都要 depend on the whole key，不能 depend on 其他 non-key attribute 4NF multivalued dependency 不像 functional dependency，箭頭後方的那項可以有多個 value {Model} $\\twoheadrightarrow$ {Color} 一個 table 中的所有 multivalued dependency 必須依賴於 key 5NF 沒有 Join Dependency table 不能表示成其他 table join 起來的結果 ","date":"2023-03-14T10:26:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/database-normalization/","title":"Database Normalization"},{"content":"paper: Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks\nAbstract BERT 和 RoBERTa 在 semantic textual similarity (STS) 上太花時間，因為他需要將兩個句子都輸入網路，並且兩兩比對。\nSentence-BERT(SBERT) 對預訓練的 BERT 作了一些修改，透過 siamese 和 triplet network 的結構來生出有意義的 embeddings，使其最後可以透過 cosine-similarity 比較相似度。\nIntroduction SBERT 使 BERT 可以用於某些迄今為止不適用於 BERT 的任務，比如 large-scale semantic similarity comparison、clustering 還有 information retrieval via semantic search。\n以往的相關研究是把單個句子輸入 BERT，最後 average BERT output layer，或是使用第一個 output，但這樣會產生糟糕的 sentence embeddings。\nSentEval 是一個 evaluation toolkit for sentence embeddings\nRelated Work BERT 透過輸入兩個句子，以 [SEP] 隔開，可以在 STS 取得 SOTA。\n但這樣無法計算獨立的 sentence embedding，所以過往的研究人員把單個句子輸入 BERT，最後 average BERT output layer，或是使用第一個 output。\nModel SBERT 在 BERT / RoBERTa 的輸出中添加了 pooling，作者嘗試了三種策略，CLS-token 的輸出、所以輸出向量的平均、max-over-time of the output vectors，默認是 MEAN。\n實驗以下結構和目標函數:\nClassification Objective Function\nRegression Objective Function\n用 mean squared-error loss\nTriplet Objective Function\nTraining Details Dataset SNLI 結合 Multi-Genre NLI SNLI: 570,000 個 句子 pair，有三類，contradiction, eintailment, and neutral MultiNLI: 430,000 個句子 pair 3-way softmax Classification Objective Function 1-epoch batch-size: 16 Adam lr: 2e-5 warm-up: 超過 10% of the training data 默認 pooling 策略: MEAN Evaluation 學習一個複雜的回歸函數分析 STS 常是 SOTA，但是由於他是 pair-wise，遇到 combinatorial explosion，不好拓展。\n本文用 cosine-similarity 比較兩個 embeddings 的相似度，也用 negative Manhatten 和 negative Euclidean distances，但得到差不多的結果。\nConclusion 用 BERT 生出的 embeddings 不適合常見的相似度測量方法，比如 cosine-similarity。\n本文提出 SBERT 改進，在 siamese / triplet 網路架構中微調 BERT。\n用 RoBERTa 替換掉 BERT 並沒有什麼顯著改進。\n","date":"2023-03-12T10:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/sentence-bert-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"Sentence-BERT 論文閱讀"},{"content":"UML 類別圖 Relationship Dependency \u0026ldquo;uses-a\u0026rdquo; Association \u0026ldquo;knows-a\u0026rdquo; Composition \u0026ldquo;has-a\u0026rdquo; child 的存在依賴於 parent，若刪除 parent，child 也會隨之刪除 Aggregation \u0026ldquo;has-a\u0026rdquo; child 的存在獨立於 parent，若刪除 parent，child 不會隨之刪除 Inheritance \u0026ldquo;is-a\u0026rdquo; Implementation \u0026ldquo;can-do\u0026rdquo; 實現 interface other features Navigation 當兩個 class 都可以看到對方，就用沒箭頭的關聯線，否則有箭頭 Role Name 類別中的 Attribute Multiplicity 關聯端點上可以寫數量，代表物件個數 Self-Association 同個類別的物件彼此有關係 軟體設計原則 Encapsulate What Varies 把經常改變的程式碼封裝起來，使日後修改時不會影響其他區塊的程式碼 實際使用的情境，可以把常改變的東西放在 interface 後，使日後改變實作時不影響呼叫該 interface 的程式碼 Favor Composition over Inheritance Composition(組合)在很多情境可以取代掉 Inheritance(繼承)，甚至實現 Polymorphism(多型) 只有當 is-a 的情境出現，才用繼承比較好 Composition 使用起來更有彈性 SOLID 設計原則 Single Responsibility Principle, SRP 單一職責原則 A class should have only one reason to change. 可以把一個複雜的 module 拆成多個 Open-Close Principle, OCP 開放封閉原則 You should be able to extend the behavior of a system without having to modify that system. 要可以擴充，同時不修改到原系統 LiskovSubstitution Principle, LSP 里氏替換原則 父類別有的功能，子類別必須遵從，父類別的部分要可以直接替換成子類別 Interface Segregation Principle, ISP 介面隔離原則 No client should be forced to depend on methods it does not use 以 interface 來說，不該讓 module 實現它不需要的功能，可以把 interface 拆小 Dependency Inversion Principle, DIP 反向依賴原則 高階模組不應該依賴低階模組，兩者都應依賴抽象層 ","date":"2023-03-08T14:26:17+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E8%BB%9F%E9%AB%94%E8%A8%AD%E8%A8%88%E5%8E%9F%E5%89%87/","title":"軟體設計原則"},{"content":"paper: PatentBERT: Patent Classification with Fine-Tuning a pre-trained BERT Model\nAbstract 把 fine-tune BERT 應用在專利分類上，當應用於超過 200 萬件專利的資料集時，該方法超越了結合 word-embedding 的 CNN 的 SOTA 作法。\n貢獻: 一個用預訓練的 BERT 去 fine-tune 的 SOTA 方法 一個叫做 USPTO-3M 的大型資料集，屬於 CPC subclass level，並提供 SQL 語句讓後續的研究者使用 與傳統觀念相反，只需要 claim 就足以完成分類任務 Introduction 專利分類是一個 multi-label 的分類任務。\n由於標籤的數量可能很大，所以是個具有挑戰性的任務。\n作者準備了一個基於 CPC 的新資料集，有超過三百萬項美國專利。\nCPC Cooperative Patent Classification 是 IPC 更具體和詳細的版本 可預見將取代 IPC 成為新的標準 只是由於 CLEP-IP 競賽，大部分論文都基於 IPC 資料集包含 1978 到 2009 提交的專利 IPC International Patent Classification 此外，作者的 dataset 基於 patent claims\npatent claims 重要性在過往被低估 在起草專利申請時，專利業者會先起草 patent claims 專利文件的其餘部分由 claim 做延伸 在專利法中，claims 定義了專利發明的界線，確定了專利權範圍 為使模型更簡單，只關注 patent claims，並且僅用第一項 claim。\n相關工作 過往有些研究只顯示了 precision，但沒有 F1 value 或 recall，難以公平比較。\n以 DeepPatent\nData 過往資料基於 CLEF-IP 或 patent offices。\n作者發現在 BigQuery 用 Google Patents Public Datasets 更容易。\n而且可用 SQL statements，作者認為比共享傳統資料集更好，原因如下:\nSeperation of concerns 如果資料包含前處理或後處理，其他研究人員需要不同操作時會很頭痛。 Clarity and flexibility SQL statement 精確且容易根據不同條件進行修改。 在和 DeepPatent 比較的時候，可以的話，會用 USPTO2M 進行測試，如果不行，才會合併來自 USPTO-3M 的資料，比如 USPTO-2M 沒有 claims 的情況。\n為了比較 claim 如何影響性能，將合併兩個資料集。\nMethod \u0026amp; Experimental Setup 用 BERT-Base 就可以打敗 DeepPatent。\n遵循 BERT Project 中給的 fine-tune 範例。\n為了 multilabel，用 sigmoid cross entropy with logits function 而不是用 softmax。\nConclusion 專利分類作為具有挑戰性的任務，幾十年來一直沒有令人滿意的表現。\n本文提出一個基於 fine-tune BERT 的方法，性能優於 DeepPatent。\n並且結果表明只用 patent claim 就可以完成分類任務。\n","date":"2023-03-02T16:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/patentbert-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/","title":"PatentBERT 論文閱讀"},{"content":"linear equation $a_1x_1+a_2x_2+\u0026hellip;+a_nx_n = b$ $a$ 是 coefficient $x$ 是 variables $b$ 是 constant term Systems of linear equations m equations, n variables\n$a_{11}x_1+a_{12}x_2+\u0026hellip;+a_{1n}x_n = b_1\\\\ a_{21}x_1+a_{22}x_2+\u0026hellip;+a_{2n}x_n = b_2\\\\ \u0026hellip;\\\\ a_{m1}x_1+a_{m2}x_2+\u0026hellip;+a_{mn}x_n = b_m$\nsolution\n$[s_1~s_2~\u0026hellip;~s_n]^T$ 是一組解，代換到 $x_1$~$x_n$ 後滿足所有 equation 的向量 所有 Systems of linear equations 都有\nno solution exactly one solution infinitely many solutions consistent/inconsistent\n如果有一組以上的解就是 consistent 無解就是 inconsistent equivalent\n如果兩組 Systems of linear equations 的 solution set 一樣，稱為 equivalent elementary row operations\n不會影響 solution set types Interchange 兩 row 互換 Scaling 某 row 乘某個 nonzero scalar Row addition 把某 row 乘某個 scalar 後加到某 row property 所有 elementary row operations 都是 reversible 用來求解 coefficient matrix\n$a_{11}x_1+a_{12}x_2+\u0026hellip;+a_{1n}x_n = b_1\\\\ a_{21}x_1+a_{22}x_2+\u0026hellip;+a_{2n}x_n = b_2\\\\ \u0026hellip;\\\\ a_{m1}x_1+a_{m2}x_2+\u0026hellip;+a_{mn}x_n = b_m$ 可以拆為 $Ax=b$\n$A=\\begin{bmatrix} a_{11}\u0026amp; a_{12}\u0026amp;\u0026hellip;\u0026amp; a_{1n} \\\\ a_{21}\u0026amp; a_{22}\u0026amp;\u0026hellip;\u0026amp; a_{2n} \\\\ \u0026hellip;\u0026amp; \u0026hellip;\u0026amp;\u0026hellip;\u0026amp; \u0026hellip; \\\\ a_{m1}\u0026amp; a_{m2}\u0026amp;\u0026hellip;\u0026amp; a_{mn} \\end{bmatrix}$\nA 就是 coefficient matrix $x=\\begin{bmatrix} x_1\\\\ x_2\\\\ \u0026hellip;\\\\ x_n \\end{bmatrix}$\n$x$ 是 variable vector $[A|b]=\\begin{bmatrix} a_{11}\u0026amp; a_{12}\u0026amp;\u0026hellip;\u0026amp; a_{1n} \u0026amp; b_1 \\\\ a_{21}\u0026amp; a_{22}\u0026amp;\u0026hellip;\u0026amp; a_{2n} \u0026amp; b_2\\\\ \u0026hellip;\u0026amp; \u0026hellip;\u0026amp;\u0026hellip;\u0026amp; \u0026hellip; \u0026amp; \u0026hellip;\\\\ a_{m1}\u0026amp; a_{m2}\u0026amp;\u0026hellip;\u0026amp; a_{mn} \u0026amp; b_m \\end{bmatrix}$\n叫做 augmented matrix ","date":"2023-02-21T15:42:47+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E7%B7%9A%E6%80%A7%E4%BB%A3%E6%95%B8-ii/","title":"線性代數 - II"},{"content":"matrix a rectangular array of scalars\nsize\nm by n 叫做 square if m = n equal\n兩個矩陣的 size 和每個 entry 都一樣 submatrix\n從一個大矩陣刪掉 rows 或 columns addition\n兩個大小相同的矩陣，每個對應位置的 entry 兩兩相加 scalar multiplication\n一個矩陣的所有 entry 乘以某個 scalar zero matrix\n所有 entry 都是 0，該矩陣常以 $O_{n \\times m}$ 來表示 性質 $A = O + A$ $0 \\cdot A = O $ subtraction\n$A-B=A+(-B)$ transpose\n$A^T$ 的 $(i,j)$-entry 是 $A$ 的 $(j,i)$-entry Properties $(A+B)^T=A^T+B^T$ $(sA)^T=sA^T$ $(A^T)^T=A$ vectors type\nrow vector 只有 1 row 的 matrix column vector 只有 1 column 的 matrix components\nthe entries of a vector 用 the $i$ th component 代表 $v_i$ addition, scalar multiplication\n和 matrix 一樣 矩陣表示\n一個矩陣常被表示為 a stack of row vectors a cross list of column vectors linear combination $c_1u_1+c_2u_2+\u0026hellip;+c_ku_k$\nscalars\n$c_1,c_2,\u0026hellip;,c_k$ 又被稱作 linear combination 的 coefficients vectors\n$u_1,u_2,\u0026hellip;,u_k$ 如果 $u,v$ 非平行二維向量，則二維空間中所有向量皆是 $u,v$ 的 linear combination，且是 unique 的\nstandard vectors $e_1 = \\begin{bmatrix} 1 \\\\ 0 \\\\ \u0026hellip; \\\\ 0 \\end{bmatrix} ,e_2 = \\begin{bmatrix} 0 \\\\ 1 \\\\ \u0026hellip; \\\\ 0 \\end{bmatrix},\u0026hellip;, e_n = \\begin{bmatrix} 0 \\\\ 0 \\\\ \u0026hellip; \\\\ 1 \\end{bmatrix}$\n$R^n$ 的任何一個向量都可以被 standard vectors 表示成 uniquely linearly combined\n矩陣向量乘法 $Av=v_1a_1+v_2a_2+\u0026hellip;+v_na_n$ Identity Matrix 對整數 n，$n \\times n$ identity matrix $I_n$ 每個 columns 是 standard vectors $e_1, e_2, \u0026hellip;, e_n$ in $R^n$ Stochastic Matrix 對整數 n，$n \\times n$ stochastic matrix 所有 entry 都必須非負 每個 column 的 entry 總和必須是 unity (相加為 1) ","date":"2023-02-21T14:42:47+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E7%B7%9A%E6%80%A7%E4%BB%A3%E6%95%B8-i/","title":"線性代數 - I"},{"content":"Process Scheduling 可能時機\nrunning -\u0026gt; waiting running -\u0026gt; ready waiting -\u0026gt; ready running -\u0026gt; terminate Process Scheduler\nPreemptive scheduler (Time slice) 可以被搶占 Non-Preemptive scheduler 又稱 cooperative scheduling 只可能出現在時機 1 或 4 Classification fo Processes(related to scheduling)\nInteractive Processes (50 - 150 ms) Batch Processes Real time Processes Hard Soft Classification of Processes(related to CPU usage)\nCPU Bound I/O Bound Standard Scheduling Algorithm FCFS SJF SRTF Priority Based Highest Response Ratio Next Round Robin Virtual RR Multi-Level Queue Scheduler Multi-Level Feed Back Queue Scheduler Rotating Staircase Deadline Scheduler UNIX SVR3 Scheduler 有 32 個 runqueue，每個 runqueue 負責 4 個 priority values\n128 Priority values\n0-49: Kernel 50-127: User $Priority_j=Base_j+CPU_j(i)+nice_j$\nBase: 0-127 $CPU_j(i) = DR * CPU_j(i-1)$ DR = $\\frac{1}{2}$ nice: -20 ~ +19 可以用 nice 和 renice 改 process nice value Schedtool Query \u0026amp; set per process scheduling parameters\nScheduling Policy Real time SCHED_RR SCHED_FIFO Conventional SCHED_NORMAL (default) SCHED_BATCH (CPU intensive) SCHED_ISO (unused) SCHED_IDLEPRIO (low pri jobs) Nice Value (-20 to +19) Static Priority (1-99) CPU affinity process 想運行在某個指定的 CPU 上，不被轉移到其他 CPU，才不會降低指定 CPU 的 cache 命中率 soft CPU affinity hard CPU affinity cpus_allowed 一個用來指定 CPU 的 mask 1 schedtool \u0026lt;PID\u0026gt; ","date":"2023-02-20T21:12:52+08:00","permalink":"https://roykesydon.github.io/Blog/p/process-scheduling/","title":"Process Scheduling"},{"content":"RL 方法 Policy-based learn 做事的 actor Value-based 不直接 learn policy，而是 Learn critic，負責批評 Q-learning 屬於這種 Critic 不直接決定 action 給予 actor $\\pi$，評估 actor $\\pi$ 有多好 critic 的 output 依賴於 actor 的表現 State Value Function State value function $V^{\\pi}(s)$ 用 actor $\\pi$，看到 s 後玩到結束，cumulated reward expectation 是多少 評估方法 Monte-Carlo(MC) based approach\ncritic 看 $\\pi$ 玩遊戲 訓練一個 network，看到不同的 state ，輸出 cumulated reward(直到遊戲結束，以下稱為 $G_a$)，解 regression 問題 Temporal-difference(TD) approach\nMC 的方法至少要玩到遊戲結束才可以 update network，但有些遊戲超長 TD 只需要 {$s_t,a_t,r_t,s_{t+1}$} $V^{\\pi}(s_t)=V^{\\pi}(s_{t+1})+r_t$ MS v.s. TD\nMC Larger variance 每次的輸出差異很大 TD smaller variance 相較 $G_a$ 較小，因為這邊的 random variable 是 r，但 $G_a$ 是由很多 r 組合而成 V 可能估得不準確 那 learn 出來的結果自然也不准 較常見 Another Critic State-action value function $Q^\\pi(s,a)$\n又叫 Q function 當用 actor $\\pi$ 時，在 state s 採取 a 這個 action 後的 cumulated reward expectation 有一個要注意的地方是，actor 看到 s 不一定會採取 a 只要有 Q function，就可以找到\u0026quot;更好的\u0026quot; policy，再替換掉原本的 policy \u0026ldquo;更好的\u0026quot;定義 $V^{\\pi^{\u0026rsquo;}} \\ge V^{\\pi}(s), \\text{for all state s}$ $\\pi^{\u0026rsquo;}(s)=arg \\underset{a}{max}Q^{\\pi}(s,a)$ $\\pi^{\u0026rsquo;}$ 沒有多餘的參數，就單純靠 Q function 推出來 這邊如果 a 是 continuous 的會有問題，等等解決 這樣就可以達到\u0026quot;更好的\u0026quot;policy，不過就不列證明了 Basic Tip Target network 在 training 的時候，把其中一個 Q 固定住，不然要學的 target 是不固定的，會不好 train Exploration policy 完全 depend on Q function 如果 action 總是固定，這不是好的 data collection 方法，要在 s 採取 a 過，才比較好估計 Q(s, a)，如果 Q function 是 table 就根本不可能估出來，network 也會有一樣的問題，只是沒那麼嚴重。 解法 Epsilon Greedy $a=\\begin{cases} arg \\underset{a}{max}Q(s,a), \u0026amp; \\text{with probability } 1-\\varepsilon \\\\ random, \u0026amp; otherwise \\end{cases}$ 通常 $\\varepsilon$ 會隨時間遞減，因為你一開始 train 的時候不知道怎麼比較好 Boltzmann Exploration $P(a|s)=\\frac{exp(Q(s,a))}{\\sum_a exp(Q(s,a))}$ Replay Buffer 把一堆的 {$s_t,a_t,r_t,s_{t+1}$} 存放在一個 buffer {$s_t,a_t,r_t,s_{t+1}$} 簡稱為 exp 裡面的 exp 可能來自於不同的 policy 在 buffer 裝滿的時候才把舊的資料丟掉 每次從 buffer 隨機挑一個 batch 出來，update Q function 好處 跟環境作互動很花時間，這樣可以減少跟環境作互動的次數 本來就希望 batch 裡的 data 越 diverse 越好，不會希望 batch 裡的 data 都是同性質的 issue 我們要觀察 $\\pi$ 的 value，混雜了一些不是 $\\pi$ 的 exp 到底有沒有關係? 理論上沒問題，但李老師沒解釋 Typical Q-learning 演算法 初始化 Q-fucntion Q，target Q-function $\\hat{Q}=Q$ 在每個 episode 對於每個 time step t 給 state $s_t$，根據 Q 執行 action $a_t$ (epsilon greedy) 獲得 reward $r_t$，到達 $s_{t+1}$ 把 {$s_t,a_t,r_t,s_{t+1}$} 存到 buffer 從 buffer sample {$s_t,a_t,r_t,s_{t+1}$}(通常是一個 batch) Target $y=r_i+\\underset{a}{max}\\hat{Q}(s_{i+1},a)$ Update Q 的參數，好讓 $Q(s_i,a_i)$ 更接近 y(regression) 每 C 步 reset $\\hat{Q}=Q$ Adveanced Tip Double DQN Q Value 往往被高估 我們的目的是要讓 $Q(s_t, a_t)$ 和 $r_t+\\underset{a}{max}Q(s_{t+1},a)$ 越接近越好(後者就是 target) target 常常不小心設太高，因為如果有 action 被高估了，就會選那個當 target Double DQN: 兩個函式 $Q$ 和 $Q^{\u0026rsquo;}$ 把 target 換成 $r_t+Q^{\u0026rsquo;}(s_{t+1},arg \\underset{a}{max}Q(s_{t+1},a))$ 選 action 交給 $Q$，實際算交給 $Q^{\u0026rsquo;}$ 如果 $Q$ 選了高估的 action，$Q^{\u0026rsquo;}$ 有可能修正回來 如果 $Q^{\u0026rsquo;}$ 高估，$Q$ 不一定會選到 $Q^{\u0026rsquo;}$ 是 target network(固定不動) Dueling DQN 改變 network 架構 分成兩條 path 第一條算 scalar 第二條算 vector，每個 action 都有個 value 把 scalar 加到每一個維度 只更改到 V(s) 的時候，會全部的 action 都改到，可能會是一個比較有效率的方式，不用 sample 所有的 action 但有可能模型不管 V(s)，直接設 0，只改 A 所以會對 A 下 constrain，讓 network 傾向於改 V 比如同個 state 下的所有 action 要生出 A(s,a) 總和為 0 在 A 的輸出加個 normalization 即可辦到，這個 normalization 就是把每個維度都減掉平均 Prioritized Replay 原本是 uniform 的從 buffer sample data 改讓 「有更大的 TD error」的 data 有更高的機率被 sample TD error 就是 $Q(s_t, a_t)$ 和 target 的差距 實際在做的時候有額外的細節，不會只改 sampling 的 process，還要改 update 參數的方法 Multi-step Balance between MC 和 TD TD 只需要存 {$s_t,a_t,r_t,s_{t+1}$} 改存 {$s_t,a_t,r_t,\u0026hellip;,s_{t+N},a_{t+N},r_{t+N}, s_{t+N+1}$} 我們的目的是要讓 $Q(s_t, a_t)$ 和 $\\displaystyle\\sum_{t^{\u0026rsquo;}=t}^{t+N} r_{t^{\u0026rsquo;}}+\\hat{Q}(s_{t+N+1},a_{t+N+1})$ 越接近越好(後者就是 target) $a_{t+N+1}=arg\\underset{a}{max}\\hat{Q}(s_{t+N+1},a)$ 同時有 MC 和 TD 的好處和壞處 估測的影響比較輕微 r 比較多項，variance 比較大 Noisy Net improve exploration Noise on Action Epsilon Greedy(之前的回顧) $f_X(x) = \\begin{cases} arg \\underset{a}{max}Q(s,a), \u0026amp; \\text{with probability }1-\\varepsilon \\\\ random, \u0026amp; ,otherwise \\end{cases}$ 給同樣的 state，採取的 action 不一定一樣 沒有真實的 policy 會這樣運作 Noise on Parameters $a = arg \\underset{a}{max}\\tilde{Q}(s,a)$\n在每個 episode 剛開始的時候，在 Q-function 的參數上面加上 gaussian noise 給同樣的 state，採取同樣的 action\n叫做 state-dependent exploration explore in a consistent way\nDistributional Q-function Q-function 生出的東西是 cumulated reward 的期望值 所以我們是在對 distribution 取 mean，但不同的 distribution 也可能有同樣的 mean 想做的事情是 model distribution 如果有做這個，就比較不會有 over estimate reward 的結果，反而容易 under estimate，使 double 比較沒用 output 的 range 不可能無限寬，超過邊界的 reward 會被丟掉 Rainbow 綜合一堆方法 Continuous actions Q learning 不容易處理 continuous action Solution sample n 個可能的 a，都丟 Q function 看誰最大\ngradient descent\n把 a 當作 parameter，要找一組 a 去 maximize Q function 運算量大，要 iterative 的 update a 不一定可以找到 global 的最佳解 特別設計 Q network，讓解 optimization 的問題變容易\n範例 Q network 輸出 $\\mu(s)$、$\\Sigma(s)$、$V(s)$，個別是 vector、matrix、scalar a 是 continuous 的 Action，是一個 vector，每個維度都是實數 $\\Sigma(s)$ 是 positive definite 的，實作的時候會把 $\\Sigma$ 和它的 transpose 相乘 $Q(s,a)=-(a-\\mu(s))^T\\Sigma(s)(a-\\mu(s))+V(s)$ $(a-\\mu(s))^T\\Sigma(s)(a-\\mu(s))$ 這項必為正，所以 $a=\\mu(s)$ 的時候就是最佳解 不要用 Q-learning\n","date":"2023-02-20T16:21:23+08:00","permalink":"https://roykesydon.github.io/Blog/p/q-learning/","title":"Q-learning"},{"content":"On/Off-policy On-policy 學習的 agent 和與環境互動的 agent 是同一個 Off-policy 學習的 agent 和與環境互動的 agent 是不同個 想從 On-policy 轉 Off-policy On-policy 每次都要重新蒐集資料，很花時間 由另一個 $\\pi_{\\theta^{\u0026rsquo;}}$ 去 train $\\theta$，$\\theta^{\u0026rsquo;}$是固定的，所以我們可以 re-use sample data Importance Sampling 是一個 general 的想法，不限於 RL\n$E_{x \\text{\\textasciitilde} p}[f(x)]\\approx \\frac{1}{N}\\displaystyle\\sum_{i=1}^N f(x^i)$\n$x^i$ is sampled from p(x) 我們遇到的問題是沒辦法從 p 來 sample data，只能透過 q(x) 去 sample $x^i$\n可以把上式改寫成 $E_{x \\text{\\textasciitilde} p}[f(x)]=E_{x \\text{\\textasciitilde} q}[f(x)\\frac{p(x)}{q(x)}]$\nIssue 雖然理論上 q 可以任意選，只要不要 q(x) 是 0 的時候 p(x) 不是 0，實作上 p 和 q 不能差太多，不然會有問題\n這兩項的 Variance 不一樣，如果 p 除以 q 差距很大，右邊的 Variance 會很大，如果 sample 不夠多次就會有問題 轉換 原本\n$\\triangledown \\overline{R_{\\theta}}=E_{\\tau \\text{\\textasciitilde}p_{\\theta}(\\tau)}[R(\\tau)\\triangledown log p_{\\theta} (\\tau)]$ 改為\n$\\triangledown \\overline{R_{\\theta}}=E_{\\tau \\text{\\textasciitilde}p_{\\theta^{\u0026rsquo;}}(\\tau)}[\\frac{p_{\\theta}(\\tau)}{p_{\\theta^{\u0026rsquo;}}(\\tau)}R(\\tau)\\triangledown log p_{\\theta} (\\tau)]$ 從 $\\theta^{\u0026rsquo;}$ sample 資料 更新 $\\theta$ 多次 Advantage function 原本\n$E_{(s_t,a_t)\\text{\\textasciitilde}\\pi_{\\theta}}[A^{\\theta}(s_t,a_t)\\triangledown log p_\\theta(a_t^n|s_t^n)]$ 改為\n$E_{(s_t,a_t)\\text{\\textasciitilde}\\pi_{\\theta^{\u0026rsquo;}}}[\\frac{P_\\theta(s_t,a_t)}{P_{\\theta^{\u0026rsquo;}}(s_t,a_t)}A^{\\theta^{\u0026rsquo;}}(s_t,a_t)\\triangledown log p_\\theta(a_t^n|s_t^n)]$ 要注意 Advantage 的結果要由 $\\theta^{\u0026rsquo;}$ 得出，是 $\\theta^{\u0026rsquo;}$在和環境互動 新的 objective function\n$J^{\\theta^{\u0026rsquo;}}(\\theta)=E_{(s_t,a_t)\\text{\\textasciitilde}\\pi_{\\theta^{\u0026rsquo;}}}[\\frac{p_\\theta(a_t|s_t)}{p_{\\theta^{\u0026rsquo;}}(a_t|s_t)}A^{\\theta^{\u0026rsquo;}}(s_t,a_t)]$ PPO 確保 $\\theta$ 和 $\\theta^{\u0026rsquo;}$ 不會差太多 $J_{PPO}^{\\theta^{\u0026rsquo;}}(\\theta)=J^{\\theta^{\u0026rsquo;}}(\\theta)-\\beta KL(\\theta, \\theta^{\u0026rsquo;})$ 前身 TRPO Trust Region Policy Optimization $J_{TRPO}^{\\theta^{\u0026rsquo;}}(\\theta)=E_{(s_t,a_t)\\text{\\textasciitilde}\\pi_{\\theta^{\u0026rsquo;}}}[\\frac{p_\\theta(a_t|s_t)}{p_{\\theta^{\u0026rsquo;}}(a_t|s_t)}A^{\\theta^{\u0026rsquo;}}(s_t,a_t)], KL(\\theta, \\theta^{\u0026rsquo;})\u0026lt;\\delta$ constrain 很難處理 KL divergence 這邊不是 $\\theta$ 和 $\\theta^{\u0026rsquo;}$ 參數上的距離，而是 behavior 的距離 參數上的距離是指這兩個參數有多像 是給同樣的 state 生出 action 的 distribution 要像 algorithm 初始參數 $\\theta^0$ 每個 iteration 用 $\\theta^k$ 和環境互動，蒐集{$s_t,a_t$}，並計算 advantage $A^{\\theta^k}(s_t,a_t)$\n找出 theta 最佳化 $J_{PPO}(\\theta)$\n$J_{PPO}^{\\theta^{k}}(\\theta)=J^{\\theta^{k}}(\\theta)-\\beta KL(\\theta, \\theta^{k})$ 可以更新很多次 動態調整 $\\beta$\nAdaptive KL Penalty 設可接受的 KL 數值範圍 if $KL(\\theta,\\theta^k)\u0026gt;KL_{max},\\text{increase} \\beta$ if $KL(\\theta,\\theta^k)\u0026lt;KL_{min},\\text{decrease} \\beta$ PPO2 PPO\n$J_{PPO}^{\\theta^{k}}(\\theta)=J^{\\theta^{k}}(\\theta)-\\beta KL(\\theta, \\theta^{k})$ PPO2\n$J_{PPO2}^{\\theta^{k}}(\\theta)\\approx \\displaystyle\\sum_{(s_t,a_t)}min(\\frac{p_{\\theta}(a_t|s_t)}{p_{\\theta^k}(a_t|s_t)}A^{\\theta^k}(s_t,a_t), \\\\ clip(\\frac{p_{\\theta}(a_t|s_t)}{p_{\\theta^k}(a_t|s_t)}, 1-\\varepsilon, 1+\\varepsilon)A^{\\theta^k}(s_t,a_t))$ ","date":"2023-02-20T12:35:56+08:00","permalink":"https://roykesydon.github.io/Blog/p/proximal-policy-optimizationppo/","title":"Proximal Policy Optimization(PPO)"},{"content":"Basic Components Actor Policy $\\pi$ is a network with parameter $\\theta$ Env Reward Function Trajectory 在一場遊戲，把 env 輸出的 s 和 actor 輸出的 a 串起來，是一個 Trajectory Trajectory $\\tau$ = {$s_1,a_1,s_2,a_2,\u0026hellip;,s_T,a_T$} $p_{\\theta}(\\tau)=p(s_1)\\displaystyle\\prod_{t=1}^Tp_{\\theta}(a_t|s_t)p(s_{t+1}|s_t,a_t)$ Update $\\theta \\leftarrow \\theta + \\eta \\triangledown \\overline{R}_{\\theta}$\n$\\triangledown \\overline{R_{\\theta}} = \\displaystyle\\sum_{\\tau} R(\\tau) \\triangledown p_{\\theta} (\\tau) \\\\ =\\frac{1}{N}\\displaystyle\\sum_{n=1}^{N}\\displaystyle\\sum_{t=1}^{T_n}R(\\tau^n)\\triangledown log p_{\\theta} (a_t^n|s_t^n)$\n實作 常見公式 $\\triangledown f(x)=f(x)\\triangledown logf(x)$ 用當前模型蒐集一堆 Trajectory 更新模型 回到第一步 細節 做一個分類問題，把 state 當作分類器的 Input，把 action 當作分類器的 ground truth 作訓練 在實作分類問題的時候，objective function 都會寫成 minimize cross entropy，就是 maximize log likelihood RL 和一般分類的區別是，要記得在 loss 前面乘上 $R(\\tau^n)$ Tip Add a Baseline $R(\\tau^n)$ 有可能永遠都為正 此時等於告訴 Model 說，今天不管是什麼 action，都要提高它的機率。不一定會有問題，因為雖然都是正的，但正的量有大有小，可能某些 action 上升的幅度會更大。因為我們是在做 sampling，不一定會 sample 到某些 action，本來想的情況是所有的 trajectory 都會出現才沒問題。 解法: 希望 reward 不要總是正的 $\\triangledown \\overline{R_{\\theta}}\\approx \\frac{1}{N}\\displaystyle\\sum_{n=1}^{N}\\displaystyle\\sum_{t=1}^{T_n}(R(\\tau^n)-b)\\triangledown log p_{\\theta}(a_t^n|s_t^n)$ $b \\approx E[R(\\tau)]$ Assign Suitable Credit 原本整場遊戲的所有 action 都會乘上 $R(\\tau)$，但這不太公平，因為就算結果是好的，不代表所有 action 都是對的，反之亦然。在理想的情況下，如果 sample 夠多，就可以解決這問題。 解法 只計算從這個 action 後的 reward 總和 因為前面的 reward 和你做了什麼沒關係 接續解法 1，把比較未來的 reward 做 discount 乘某個小於 1 的 $\\gamma^{t^{\u0026rsquo;}-t}$ Advantage function base 可以是 state-dependent，可以根據 network 得出，以後再說 $(Reward-b)$ 可以合起來看做 Advantage function $A^{\\theta}(s_t,a_t)$ 這邊 Reward 不管你是什麼形式，有沒有 discount。 它的意義是，這個 action 相較於其他的 action 有多好，而不是絕對好 這個 A 通常可以由某個類神經網路估計，那個類神經網路叫做 critic，以後講 Actor-Critic 的時候再說 ","date":"2023-02-19T17:16:14+08:00","permalink":"https://roykesydon.github.io/Blog/p/policy-gradient/","title":"Policy Gradient"},{"content":"paper: Masked Autoencoders Are Scalable Vision Learners\nAbstract 這篇論文顯示出 MAE 是 CV 中的 scalable self-supervised learners。\nMAE 的方法很簡單\n隨機蓋住輸入影像的一些 patch 重建 missing pixels 具備兩個核心設計\n非對稱的 encoder-decoder 架構，encoder 只作用於可見的 patch 子集合(沒有 mask tokens)，lightweight decoder 則根據 latent representation 和 make tokens 來重建圖片。 當遮住高比例(比如 75%)的影像時，會得到一個 nontrivial 和 meaningful 的 self-supervisory task 結合這兩點設計，可以有效地訓練大模型。 以 ViT-Huge 用 ImageNet-1K 訓練(訓練集一百多萬張照片)可達到 87.8% 的準確度。\nIntroduction 在 CV 中，常需要大量 labeled images。 NLP 中，自監督預訓練處理了需要大量標註資料的問題。 masked autoencoders 是一種更 general 的 denoising autoencoders 的形式。 BERT 非常成功，autoencoding methods 在 CV 的研究卻落後 NLP，作者思考是什麼讓 masked autoencoding 在 CV 和 NLP 產生不同。 有以下觀點\n直到前陣子，CV 中的 CNN 是主流，但卷積層不好引入 mask tokens 或 positional embedding 這些 indicator。但這些可以透過 ViT 來解決，不應成為問題。 語言和視覺的 Information density 不同，語言是 highly semantic 和 information-dense，使填字本身不是很簡單的事情，但影像含有大量冗餘的訊息，缺失的部分比較好從相鄰的 patch 重建，比如直接插值，所以作者用一種簡單的策略，隨機 mask 很大一部分的 patch，創造一個具有挑戰性的自監督任務，強迫模型關注 global 的資訊。 關於 decoder，CV 還原 pixel，pixel 屬於 lower semantic level，NLP 還原 word，word 的 semantic information 較高。作者發現，雖然在 BERT 中，可以用簡單的 decoder 還原(一個 MLP)，但 CV 中 decoder 的設計就很重要。 基於以上觀點，作者提出 MAE，隨機遮住大量的 patch，並在 pixel space 重建失去的 patch。而且是非對稱 encoder-decoder 架構，encoder 只會看到可見的 patch，但 docoder 除了 latent representation，還會看到 mask tokens。這種設計在非常高的掩蓋率(比如 75%)下不但可以提高準確度，還可以讓 encoder 只處理較少比例(比如 25%)的 patch，將訓練時間減少 3 倍或更多，使 MAE 可以輕鬆擴展成更大的模型。\n在這樣的架構下，用 MAE 的 pre-training，可以訓練非常吃 data 的模型，比如 ViT-Large/-Huge，而只使用 ImageNet-1K。\n用 ImageNet-1K 在 vanilla ViT-Huge 上 fine-tune 可達到 87.8% 準確度，比以往只使用 ImageNet-1K 的結果都高。\n在 obejct detection、instance segmentation、semantic segmentation 上做 transfer learning 都達到不錯的效果，可以打敗用監督式預訓練模型的對手。\n相關工作 Autoencoding MAE 是一種 denoising autoencoding 的形式，但和 DAE 還是差別很大。 Masked image encoding iGPT、ViT、BEiT Approach Masking\n和 ViT 一樣，把圖片切成多個 patch，對於 patch 均勻隨機地採樣保留，剩下地遮住 MAE encoder\nViT 也有 positional embedding MAE decoder\nTransformer block 輸入 encoded visible patches mask tokens shared, learned vector 都會加入 positional embedding 用相較 encoder 輕量的解碼器，所有的 patch 由這個輕量的 decoder 處理，減少預訓練時間 Reconstruction target\ndecoder 的最後一層是 linear projection，之後再 reshape 成你要的 patch loss function mean squared error(MSE) 只算 masked patched 的 MSE，像 BERT Simple implementation\n先取得一系列 token(patch 做 linear projection + positional embedding) randomly shuffle，根據比例移除尾端一部份 encoding 後，尾端接上 mask tokens，並且 unshuffle 加上 positional embedding 後，給 decoder ImageNet Experiments 在 ImageNet-1K 上做自監督的預訓練，然後做\nend-to-end fine-tuning 所有參數都可改 linear probing 只改最後一層線性層 optimal masking ratio 意外地高，相比 BERT 只有 15%\n討論和結論 在 CV 實用的預訓練做法主流是監督式的，CV 中自監督的做法可能正跟著 NLP 的軌跡走。\n要仔細處理圖像和語言的區別，作者去除圖片中很可能不構成 semantic segment 的部分，而不是移除某個 object。\n","date":"2023-02-15T16:08:46+08:00","permalink":"https://roykesydon.github.io/Blog/p/mae-%E8%AB%96%E6%96%87/","title":"MAE 論文"},{"content":"paper: An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale\nAbstract 在 CV 領域 transformer 表現有限，目前 attention 常常是和卷積神經網路一起用，或是用來把一些卷積層換成 self-attention，但整體架構不變。這篇論文想展現一個純 Transformer 可以直接在影像分類上表現很好。如果用大量資料作預訓練，再遷移到中小型的資料集，可以和 SOTA 的 CNN 表現得一樣好，還需要較少的訓練資源作訓練。\nIntroduction self-attention-based 架構，特別是 Transformer，已經是 NLP 的重要選擇。主流的作法是在大型文字資料集上作訓練，再針對小型任務資料集作 fine-tune。由於 Transformer 的計算效率高，還有可擴展性，可以 train 一些很大的 model，隨著 model 和資料集增大，目前還沒看出飽和的現象。\n然而在 CV，CNN 還是主流，一些工作嘗試用 self-attention 結合 CNN-like 的架構，比如把 feature map 當 transformer 的輸入，因為原始 pixel 太多，或甚至把卷積層全換成 self-attention，雖然後者理論上效率很高(原論文中有另外 cite 兩篇作法)，但因為他們做法特殊，在現代硬體上很難加速，所以無法很有效地擴展。在 large-scale 的影像識別上， ResNet-like 的架構還是 SOTA。\n該實驗直接把一個標準的 Transformer 作用於圖片上，只作最少的修改。把影像分成多個 patch，並把它們變成一系列的 linear embedding，當作 NLP 中的 tokens(words) 來處理。\n當在中型大小的資料集(e.g. ImageNet)上訓練，如果沒有 strong regularization，ViT 會略輸同等大小的 ResNets\n這篇論文在更大的資料集(14M-300M 的影像)上訓練，就打敗了 inductive bias。在大量資料上作預訓練就很讚。\nRelated Work 大型的 Transformer-based 模型常常是先在大資料集上預訓練然後根據任務 fine-tune，比如 BERT 和 GPT。\n要把 self-attention 用在 CV 上，最簡單的做法就是把每個 Pixel 當一個元素，但 self-attention 是平方複雜度，在現實的圖片很難應用。一個應用 Transformer 的做法是只把 self-attention 用在 local neighborhood，另外一個是用 Sparse Transformer，還有一堆特殊的方法，雖然表現不錯，但要用硬體加速起來不容易。\n另一個有關的模型是 iGPT，在 reduce image resolution 和 color space 後把 transformer 應用在 image pixels 上。它用非監督式訓練後，再 fine-tune 或做 linear probing(只更新最後的 linear layer) 分類任務，表現很好。\n已經有類似的工作了，抽取 patches of size 2 * 2，最後再接 full self-attention，基本上和 ViT 非常像，這篇論文進一步證明了作大規模的預訓練可以讓 Transformer 和 SOTA 的 CNN 相比，而且 ViT 因為 patch 比較大，可以處理 medium-resolution 的圖片。這問題是可預期的，因為 Transformer 缺少了一些 inductive biases。\ninductive biases 一些假設 比如 CNN 常有四個假設 locality translation invariance with pooling layers 平移不變性 translation equivariance f(g(x)) = g(f(x)) 卷積和平移的先後順序沒差 Method 模型盡可能類似原始 Transformer，這樣可以把一些 NLP 上成功的 Transformer 架構拿來用，還可以用一些很有效率的 implementation\nembedding 維度是 768 = 16 * 16 * 3 position embedding 的做法是 standard learnable 1D positional embeddings，就是 BERT 的做法，簡單來說就是生出一張可以訓練的表，(序列長度, embedding size)，作者也有嘗試其他方法，但發現成效差不多，比如 2D positional embedding，概念就是從生出(序列長度, embedding size)變成生出 2 個(sqrt(序列長度), embedding size)。\n[class] 的概念是 NLP 出來的，ResNet-like 的架構常見的做法也有通過 globally average-pooling (GAP)來生出向量，再接上分類器做預測。實驗發現直接在 transformer 的輸出做 GAP 和 [class] 都可以達到不錯的效果。\nConclusion 拿標準的 Transformer 來作 Image recognition，和以往用 self-attention 在 CV 的方法不一樣，除了一開始的 initial patch extraction，沒有引入其他影像特有的 inductive biases。直接把圖片當成是一系列的 patch，然後直接用 Transformer encoder 當一般 NLP 任務處理。在很多影像分類訓練集上表現得更好還在 pre-train 上相對便宜。\n還有一些值得挑戰的地方，比如把 ViT 應用在其他 CV 任務，比如 detection 和 segmentation。另一個挑戰是探索自監督預訓練的方法。這篇論文其實有實驗自監督，表現 OK，但和監督式還是有很大的落差。擴大 ViT 可能有更好的結果。\n","date":"2023-02-12T00:27:55+08:00","permalink":"https://roykesydon.github.io/Blog/p/vit-%E8%AB%96%E6%96%87/","title":"ViT 論文"},{"content":"隨機變數之和 Z=X+Y\n$p_Z(z)=\\displaystyle\\sum_{x=-\\infty}^{\\infty}p_{X,Y}(x,z-x)\\\\ =\\displaystyle\\sum_{y=-\\infty}^{\\infty}p_{X,Y}(z-y,y)$\n$f_Z(z)=\\int_{-\\infty}^{\\infty}f_{X,Y}(x,z-x)dx\\\\ =\\int_{-\\infty}^{\\infty}f_{X,Y}(z-y,y)dy$\n如果 X, Y 獨立\n離散\n$p_Z(z)=\\displaystyle\\sum_{x=-\\infty}^{\\infty}p_{X}(x)\\cdot p_Y(z-x)\\\\ =\\displaystyle\\sum_{y=-\\infty}^{\\infty}p_{X}(z-y)\\cdot p_Y(y)$ 這兩個等式是 discrete convolution $=p_X(z) * p_Y(z)$ 連續\n$f_Z(z)=\\int_{-\\infty}^{\\infty}f_{X}(x) f_Y(z-x) dx\\\\ =\\int_{-\\infty}^{\\infty}f_{X}(z-y) f_Y(y) dy$ 這兩個等式是 continuous convolution $=f_X(z) * f_Y(z)$ 如果有 n 個獨立隨機變數\n$X=X_1+X_2+\u0026hellip;+X_n$ 如果 $X_1,\u0026hellip;,X_n$ 獨立 $p_X(x)=p_{X_1}(x) * p_{X_2}(x) * p_{X_3}(x) * \u0026hellip; * p_{X_n}(x)$ 連續做 convolution $f_X(x)=f_{X_1}(x) * f_{X_2}(x) * f_{X_3}(x) * \u0026hellip; * f_{X_n}(x)$ 連續做 convolution MGF moment generating function\nconvolution 很難算\n流程\n如果有多個連續 convolution 也適用下面流程，全部一次一起相乘 給定 $p_{X_1}(x), p_{X_2}(x)$，目標是求 $p_{X_1}(x) * p{X_2}(x)$\n轉換到 MGF\n$\\phi_{X_1}(s)=E \\lbrack e^{sX_1} \\rbrack\\\\ = \\displaystyle\\sum_{x=-\\infty}^{\\infty}e^{sx}\\cdot p_{X_1}(x)$\n$\\phi_{X_2}(s)=E \\lbrack e^{sX_2} \\rbrack$\n相乘 $\\phi_{X_1}(s) \\cdot \\phi_{X_2}(s)$\n逆轉換\n查表 $\\phi_X(s)$ 定義\n$\\phi_X(s)=E \\lbrack e^{sX} \\rbrack = \\begin{cases} \\displaystyle\\sum_{x=-\\infty}^{\\infty} e^{sx} \\cdot p_{X}(x) \u0026amp; 離散, \\\\ \\int_{-\\infty}^{\\infty} e^{sx} \\cdot f_{X}(x)dx \u0026amp; 連續 \\end{cases}$ 性質\nY = aX + b $\\phi_Y(s) = e^{sb} \\cdot \\phi_X(as) $ 常見離散機率分佈的 MGF\n$X$~$Bernoulli(p)$ $\\phi_X(s)=1-p+pe^s$ $X$~$BIN(n, p)$ 作 n 次實驗成功次數等於個實驗室成功次數的總和 $X = X_1 + X_2 + \u0026hellip; + X_n, X_i 獨立, Xi$~$Bernoulli(p)$ $\\phi_{X_i}(s)=1-p+pe^s$ $\\phi_{X}(s)=\\lbrack 1-p+pe^s \\rbrack ^n$ $X$~$Geometric(p)$ 自行推導 $X$~$Pascal(k,p)$ 看到第 k 次成功，花的總實驗室次數等於第 1 號成功花多少次 + 第 2 號 +\u0026hellip;+ 第 k 號 $X = X_1 + X_2 + \u0026hellip; + X_n, X_i 獨立, Xi$~$Gemetric(p)$ $X$~$Exponential(\\lambda)$ 自行推導 $X$~$Erlang(n,\\lambda)$ $X = X_1 + X_2 + \u0026hellip; + X_n, X_i 獨立, Xi$~$Exponential(\\lambda)$ 多個隨機變數之和 獨立隨機變數之和 $X_1, X_2, \u0026hellip;$獨立，且各自有一模一樣的機率分佈 { $X_i$ } $I.I.D.$\nIndependently and Identically Distributed $X = X_1+X_2+\u0026hellip;+X_n$，n 為常數，請問 X 的機率分佈\n$p_X(x)=p_{X_1}(x) * p_{X_1}(x) * p_{X_1}(x) * \u0026hellip; * p_{X_1}(x)$ $f_X(x)=f_{X_1}(x) * f_{X_1}(x) * f_{X_1}(x) * \u0026hellip; * f_{X_1}(x)$ 因為他們機率分佈一模一樣，所以底下都是 $X_1$ $\\phi_X(s)=\\lbrack \\phi_{X_1}(s) \\rbrack ^n$ e.g. 假設壽司理想重量是 13g，抓飯量是常態分佈，期望值是 14，標準差是 3，每天要作 100 個，每天飯量的機率分佈是?\n$X_i$ : 第 i 個壽司的飯量，{ $X_i$ } I.I.D. $X_i$~$N(14,9)\\\\ \\Rightarrow \\phi_{X_i}(s)=\\phi_{X_1}(s)\\\\ =e^{\\mu S + \\frac{\\sigma^2}{2}s^2} = e^{14 s + \\frac{9}{2}s^2}$ $X=X_1+X_2+\u0026hellip;+X_{100}$ $\\phi_X(s)=\\lbrack \\phi_{X_1}(s) \\rbrack^{100}\\\\ =e^{1400 s + \\frac{900}{2}s^2}$ 這個東西是 $X$~$N(1400,900)$ 的 MGF，所以可以逆推回來機率分佈 隨機變數之獨立隨機變數和 $X_1,X_2,\u0026hellip;I.I.D.$\n$X = X_1 + X_2 + \u0026hellip; + X_N$\nN 本身也是隨機變數，其機率分佈已知\n$\\phi_X(s)=\\phi_N(ln(\\phi_{X_1}(s)))$\n中央極限定理 central limit theorem(CLT)\n若 $X_1,X_2,\u0026hellip;,X_n$ 為 $I.I.D.$，當 n 趨近於無窮大時\n$X=X_1+X_2+\u0026hellip;+X_n$~$N(\\mu_{X_1+X_2\u0026hellip;+X_n}, \\sigma^2_{X_1+X_2+\u0026hellip;+X_n})$ $\\mu_{X_1+X_2+\u0026hellip;+X_n}=\\mu_{X_1}+\\mu_{X_2}+\u0026hellip;+\\mu_{X_n}=n\\mu_{X_1}$ $\\sigma^2_{X_1+X_2+\u0026hellip;+X_n}=\\sigma^2_{X_1}+\\sigma^2_{X_2}+\u0026hellip;+\\sigma^2_{X_n}=n\\sigma^2_{X_1}$ 應用\n要處理多個獨立的隨機變數的和時，可以用 CLT 將其機率分佈近似為常態分佈後計算機率 比如雜訊常當作常態分佈 如果某機率分佈等於多個獨立隨機變數的和，此機率分佈可以用常態分佈近似，再算機率 e.g. $X$~$BIN(100,0.3)$ $X=X_1+X_2+\u0026hellip;+X_100$ {$X_i$} $I.I.D., X_i$~$Bernoulli(0.3)$ 範例\n天團粉絲有 0.2 的機率買 CD，共有100萬個粉絲，發售 CD 超過 200800 張的機率為何 $X$~$BIN(1000000,0.2)$ $P(X\u0026gt;200800)=\\displaystyle\\sum_{x=200801}^{10^6}(\\overset{1000000}{x})0.2^x0.8^{10^6-x}$ $(\\overset{1000000}{x})=\\frac{1000000!}{200801!799199!}$ 算不出來 $X=X_1+X_2+\u0026hellip;+X_{1000000}, X_i$~$Bernoulli(0.2)\\\\ \\Rightarrow \\mu_{X_1}=0.2, \\sigma_{X_1}^2=0.16$ By CLT $\\Rightarrow X$~$N(200000,160000)$ $P(X\u0026gt;200800)\\\\ =P(\\frac{X-200000}{400} \u0026gt; \\frac{200800-200000}{400})\\\\ =P(Z\u0026gt;2) =Q(2) \\approx0.023$ De Moivre - Laplace Formula 如果是離散的隨機變數和，可以算的更精確 $P(k_1 \\le X \\le k_2) \\approx \\Phi(\\frac{k_2+0.5-n\\mu_{X_1}}{\\sqrt{n}\\sigma_{X_1}}) - \\Phi(\\frac{k_1-0.5-n\\mu_{X_1}}{\\sqrt{n}\\sigma_{X_1}})$ ","date":"2023-02-05T15:18:41+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E6%A9%9F%E7%8E%87%E8%AB%96-iv/","title":"機率論 - IV"},{"content":"隨機變數的函數 隨機變數 X 的任意函數 g(x) 也是一個隨機變數，常被稱為 Derived Random Variable 求 g(x) 的機率分佈 X 是離散 直接推 g(X) 的 PMF X 是離散隨機變數，Y = g(X) 也是離散隨機變數 $p_{g(X)}(y) = \\displaystyle\\sum_{會讓g(x)=y 的所有x}p_X(x)$ X 是連續 先推 g(x) 的 CDF，再微分得 PDF\n先算 g(X) 的 CDF $F_{g(X)}(y)=P\\lbrack g(X) \\le y \\rbrack$ 若 g(X) 可以微分，再對 y 微分得 PDF $f_{g(X)}(y)=\\frac{d}{dy}F_{g(X)}(y)$ e.g. 若 Y=3X+2，請問 Y 的 PDF 與 $f_X(x) 的關係?$\n$F_Y(y)=P(Y \\le y)\\\\ =P(3X+2 \\le y)\\\\ =P(X \\le \\frac{y-2}{3})\\\\ =F_X(\\frac{y-2}{3})$ $f_Y(y)=\\frac{d}{dy}F_Y(y)\\\\ =\\frac{d}{dy}F_X(\\frac{y-2}{3})\\\\ =\\frac{dF_X(\\frac{y-2}{3})}{d(\\frac{y-2}{3})} \\cdot \\frac{d \\frac{y-2}{3}}{dy}\\\\ =f_X(\\frac{y-2}{3}) \\cdot \\frac{1}{3}$ 若 Y=aX+b\n$f_Y(y)=\\frac{1}{|a|}f_X(\\frac{y-b}{a})$ 條件機率分佈 若 X 是離散隨機變數，PMF 是 $p_X(x)$，某事件 B 已發生 PMF: $p_{X|B}(x)= x = \\begin{cases} x \\in B: \u0026amp; \\frac{p_X(x)}{p(B)}, \\ x \\notin B: \u0026amp; 0 \\end{cases}$ CDF: $F_{X|B}(x)\\\\ =\\displaystyle\\sum_{u \\le x}p_{X|B}(u)\\\\ =\\displaystyle\\sum_{u \\le x, u \\in B} \\frac{p_X(u)}{P(B)}$ 若 X 是連續隨機變數，某事件 B 已發生 PDF: $f_{X|B}(x)\\\\ =\\begin{cases} x \\in B: \u0026amp; \\frac{f_X(x)}{P(B)}, \\ x \\notin B: \u0026amp; 0 \\end{cases}$ CDF: $F_{X|B}(x)\\\\ =\\int_{-\\infty \\le u \\le x, u \\in B} \\frac{f_X(u)}{P(B)} du$ 條件期望值 Conditional Excpectation $E \\lbrack X|B \\rbrack\\\\ =\\begin{cases} \\displaystyle\\sum_{x=-\\infty}^{\\infty} x \\cdot p_{X|B}(x) \u0026amp; 離散, \\\\ \\int_{-\\infty}^{\\infty} x \\cdot f_{X|B}(x)dx \u0026amp; 連續 \\end{cases}$\n$E \\lbrack g(X)|B \\rbrack\\\\ =\\begin{cases} \\displaystyle\\sum_{x=-\\infty}^{\\infty} g(x) \\cdot p_{X|B}(x) \u0026amp; 離散, \\\\ \\int_{-\\infty}^{\\infty} g(x) \\cdot f_{X|B}(x)dx \u0026amp; 連續 \\end{cases}$\n$Var(X|B) = E\\lbrack X^2 | B \\rbrack - (\\mu_{X|B})^2$\n失憶性 Memoryless Geometric 和 Exponential 機率分佈都有失憶性 不管事情已經進行多久，對於事情之後的進行一點影響都沒有 聯合機率分佈 joint probability distribution 同時考慮多個隨機變數的機率分佈 Joint PMF X, Y 皆為離散，聯合PMF\n$p_{X,Y}(x,y)=P(X=x, Y=y)$ 性質\n$0 \\le p_{X,Y}(x,y) \\le 1$ $\\Sigma^{\\infty}{x=-\\infty}\\Sigma^{\\infty}{y=-\\infty} p_{X,Y}(x,y)=1$ X, Y 獨立 $P_{X,Y}(x,y)\\\\ =P(X=x,Y=y)\\\\ =P_X(x)P_Y(y)$ 對任何事件 B $P(B)=\\Sigma_{(x,y)\\in B}P_{X,Y}(x,y)$ Joint CDF $F_{X,Y}(x,y)=P(X \\le x, Y \\le y)$\n性質\n$0 \\le F_{X,Y}(x, y) \\le 1$ 若 $x_1 \\le x_2$ 且 $y_1 \\le y_2$，則 $F_{X,Y}(x_1,y_1) \\le F_{X,Y} (x_2, y_2)$ $F_{X,Y}(x, \\infty) = F_X(x)$ $F_{X,Y}(\\infty, y) = F_Y(y)$ $F_{X,Y}(\\infty, \\infty) = 1$ $F_{X,Y}(x, -\\infty)\\\\ = P(X \\le x, Y \\le -\\infty)\\\\ \\le P(Y \\le -\\infty) \\\\ = 0$ $F_{X,Y}(-\\infty, y) = 0$ $P(x_1 \u0026lt; X \\le x_2, y_1 \u0026lt; Y \\le y_2)\\\\ =F_{X,Y}(x_2,y_2)-F_{X,Y}(x_2,y_1)-F_{X,Y}(x_1,y_2)+F_{X,Y}(x_1,y_1)$ Joint PDF $f_{X,Y}(x,y)= \\frac{\\partial^2F_{X,Y}(x,y)}{\\partial x \\partial y}$\n$F_{X,Y}(x,y) = \\int_{-\\infty}^{x} \\int_{-\\infty}^{y} f_{X,Y}(u,v)dv du$\n性質\n$f_{X,Y}(x,y) \\ge 0$ $\\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}f_{X,Y}(x,y)dxdy=1$ 如果 X,Y 獨立 $f_{X,Y}(x,y)=f_X(x) \\cdot f_Y(y)$ 對任何事件 B $P(B)=\\int\\int_{(x,y)\\in B}f_{X,Y}(x,y)dxdy$ 邊際 PMF Marginal PMF 已知聯合 PMF : $p_{X,Y}(x,y)$，求 $p_X(x), p_Y(y)$，稱為邊際 PMF $p_X(x)=\\displaystyle\\sum_{y=-\\infty}^{\\infty}P_{X,Y}(x,y)$ $p_Y(y)=\\displaystyle\\sum_{x=-\\infty}^{\\infty}P_{X,Y}(x,y)$ 已知聯合 PDF : $p_{X,Y}(x,y)$，求 $f_X(x), f_Y(y)$，稱為邊際 PDF $f_X(x)=\\int_{-\\infty}^{\\infty}f_{X,Y}(x,y)dy$ $f_Y(y)=\\int_{-\\infty}^{\\infty}f_{X,Y}(x,y)dx$ 雙變數期望值 聯合 PMF 下的期望值\n$E\\lbrack h(X,Y) \\rbrack = \\displaystyle\\sum_{x=-\\infty}^{\\infty}\\displaystyle\\sum_{y=-\\infty}^{\\infty}h(x,y)\\cdot p_{X,Y}(x,y)$ h(X,Y) 也可以只和 X 有關，比如它可以是 $x^2$ 聯合 PDF 下的期望值\n$E\\lbrack h(X,Y) \\rbrack = \\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}h(x,y)\\cdot f_{X,Y}(x,y) dxdy$ e.g. 已知 $f_{X,Y}(x,y)=\\begin{cases} 0.5, \u0026amp; \\text{if } 0 \\le y \\le x \\le 2, \\\\ 0, \u0026amp; otherwise \\end{cases}$ $E \\lbrack X + Y \\rbrack \\\\ = \\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}(x+y)\\cdot f_{X,Y}(x,y) dxdy\\\\ = \\int_{0}^{2}\\int_{y}^{2}(x+y)\\cdot 0.5 dxdy$ 期望值性質\n$E\\lbrack \\alpha h_1(X,Y)+ \\beta h_2(X,Y) \\rbrack\\\\ =\\alpha E\\lbrack h_1(X,Y)\\rbrack + \\beta E\\lbrack h_2(X,Y) \\rbrack$ 若 X,Y 獨立 $E\\lbrack g(X)h(Y) \\rbrack = E \\lbrack g(X) \\rbrack \\cdot E \\lbrack h(Y) \\rbrack$ Variance 性質\n$Var(X+Y)=Var(X)+Var(Y)+2 \\cdot Cov(X,Y)$ $Cov(X,Y)=E\\lbrack (X-\\mu_X)(Y -\\mu_Y) \\rbrack$ 如果 X, Y 獨立 $2E\\lbrack (X-\\mu_X)(Y -\\mu_Y) \\rbrack \\\\ = 2E\\lbrack (X-\\mu_X) \\rbrack E\\lbrack (Y -\\mu_Y) \\rbrack \\\\ = 0$ ","date":"2023-02-02T15:18:41+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E6%A9%9F%E7%8E%87%E8%AB%96-iii/","title":"機率論 - III"},{"content":"機率密度函數 PDF probability density function PMF 在 連續R.V. 上，假如 $X\\text{\\textasciitilde}[0,1)$，$p_X(0.7)$ = 0，因為有無窮多個數字 公式 $f_X(x)=\\lim\\limits_{\\Delta x \\rightarrow 0} \\frac{P(x \\le X \\le x + \\Delta x)}{\\Delta x} \\\\ = \\lim\\limits_{\\Delta x \\rightarrow 0} \\frac{F_X(x+\\Delta x) - F_X(x)}{\\Delta x} \\\\ = F^{\\prime}_X(x) $ 和 CDF 的關係 $CDF: F_X(x) = PDF: f_X(x)$ $\\int^x_{-\\infty}$ 可以從 PDF 轉到 CDF\n$\\frac{d}{dx} 可以從 CDF 轉到 PDF$\n跟機率的關係 $P(a \u0026lt; X \\le b) = F_X(b) - F_X(a) \\\\ = \\int^b_{-\\infty} f_X(x)dx - \\int^a_{-\\infty} f_X(x)dx \\\\ = \\int^a_b f_X(x)dx$ $f_X(x)=\\lim\\limits_{\\Delta x \\rightarrow 0} \\frac{P(x \\le X \\le x + \\Delta x)}{\\Delta x}$ 當 $\\Delta x$ 很小時 $P(x \\le X \\le x + \\Delta x) \\approx f_X(x) \\cdot \\Delta x$ 性質 $f_X(x) = F^{\\prime}_X(x)$ $F_X(x)=\\int^x_{-\\infty}f_X(u)du$ $P(a \\le X \\le b)=\\int^b_a f_X(x) dx$ $\\int^{\\infty}_{-\\infty}f_X(x)dx=1$ $f_X(x) \\ge 0$ $f_X(x)$ 可以比 1 大 連續機率分佈 Uniform 機率分佈 $X \\text{\\textasciitilde}UNIF(a,b)$ PDF $f_X(x) = \\begin{cases} \\frac{1}{b-a} \u0026amp; ,a \\le x \\le b \\\\ 0 \u0026amp; ,otherwise \\end{cases}$ CDF $F_X(x) = \\begin{cases} 0 \u0026amp; ,x \\le a \\\\ \\frac{x-a}{b-a} \u0026amp; ,a \u0026lt; x \\le b\\\\ 1 \u0026amp; ,x \u0026gt; b \\end{cases}$ Exponential 機率分佈 有失憶性(memoryless)，常被用來 model 有這種性質的事情 $X \\text{\\textasciitilde}Exponential(\\lambda)$ PDF $f_X(x) = \\begin{cases} \\lambda e^{-\\lambda x} \u0026amp; ,x \\ge 0 \\\\ 0 \u0026amp; ,otherwise \\end{cases}$ CDF $F_X(x) = 1-e^{-\\lambda x}$ Erlang 機率分佈 Gamma Distribution $X \\text{\\textasciitilde}Erlang(n,\\lambda)$ PDF $f_X(x) = \\begin{cases} \\frac{1}{(n-1)!}\\lambda^n x^{n-1} e^{-\\lambda x} \u0026amp; ,x \\ge 0 \\\\ 0 \u0026amp; ,otherwise \\end{cases}$ $f_X(x)=(\\lambda e^{-\\lambda x}) * (\\lambda e^{-\\lambda x}) * \u0026hellip; * (\\lambda e^{-\\lambda x})$ 自己和自己做 n 次 convolution CDF $F_X(x) = \\begin{cases} 1 - \\Sigma^{n-1}_{k=0}\\frac{(\\lambda x)^k}{k!}e^{-\\lambda x} \u0026amp; ,x \\ge 0 \\\\ 0 \u0026amp; ,otherwise \\end{cases}$ 常見用法 用來 model 一件有多個關卡事情的總時間，而每個關卡所需時間是隨機的 關卡數: n 每關卡所需時間之機率分佈 $Exponential(\\lambda)$ e.g. 打電動過三關所需時間 $Erlang(3, \\lambda)$ Normal 機率分佈 (常態分佈) 在自然界常出現\n常被用做「很多隨機量的總和」的機率模型\n又稱 Gaussian 機率分佈\n$X \\text{\\textasciitilde}Gaussian(\\mu,\\sigma)$\nPDF\n$f_X(x)=\\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}$ 也常用 $X \\text{\\textasciitilde}N(\\mu,\\sigma^2)$\n注意 $\\sigma$ 不一樣 CDF\n太難算，積不出來\n針對某組特別的 $\\mu, \\sigma$ 的 CDF 建表，把其他常態分佈的 CDF 和這組產生關聯 標準常態分佈\n$Z \\text{\\textasciitilde}N(0,1)$ $f_Z(z)=\\frac{1}{\\sqrt{2 \\pi}}e^{-\\frac{z^2}{2}}$ CDF 表示為 $\\Phi(z)$ $\\Phi(z)=\\int^z_{-\\infty}\\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{u^2}{2}}du$\n積不出來，以數值方法近似出來後建表給人家查 查 standard normal table e.g. $F_Z(1.325)=?$\n查表 $F_Z(1.32)=0.9066$，$F_Z(1.33)=0.9082$ 用內插約略得 0.9074 性質\n$\\Phi(-z) = 1 - \\Phi(z)$ 任意 $\\mu, \\sigma$ 的 CDF\n對任何 $X \\text{\\textasciitilde}N(\\mu,\\sigma^2)$ $\\frac{X-\\mu}{\\sigma}\\text{\\textasciitilde}N(0,1)$ $F_X(x)=\\Phi(\\frac{x-\\mu}{\\sigma})$ 期望值 Expectation 大數法則 $P(A)=\\lim\\limits_{N \\rightarrow \\infty}\\frac{N_A}{N}$ 基本上期望值是利用大數法則算的 mean 值，雖然平均值是 R.V.，但當實驗無窮多次時，會收斂到常數，因此以這為估算值 Mean 值又稱做期望值 離散隨機變數 $E\\lbrack X \\rbrack=\\mu_X=\\displaystyle\\sum^{\\infty}_{x=-\\infty}x \\cdot P_X(x)$ 離散隨機變數的函數的期望值 對離散隨機變數 X 而言，其任意函數 g(x) 也是一隨機變數，也有期望值 $g(X)$ 的期望值定義為 $E \\lbrack g(X) \\rbrack=\\displaystyle\\sum^{\\infty}_{x=-\\infty}g(x)\\cdot P_X(x)$ 性質 $E\\lbrack \\alpha g(X) \\rbrack = \\alpha \\cdot E \\lbrack g(X) \\rbrack$ $E\\lbrack \\alpha g(X) + \\beta h(X) \\rbrack \\\\ =\\alpha \\cdot E \\lbrack g(X) \\rbrack + \\beta \\cdot E \\lbrack h(X) \\rbrack$ $E\\lbrack \\alpha \\rbrack = \\alpha$ 常見隨機變數函數的期望值 $X$ 的 $n^{th} moment$ $E \\lbrack X^n \\rbrack = \\displaystyle\\sum^{\\infty}_{x=-\\infty}x^n \\cdot P_X(x)$ X 的變異數(variance) $E \\lbrack (X-\\mu_X)^2 \\rbrack = \\displaystyle\\sum^{\\infty}_{x=-\\infty} (x-\\mu_X)^2 \\cdot P_X(x)$ 變異數 Variance Variance 通常符號表示為 $\\sigma^2_X=E \\lbrack (X-\\mu_X)^2 \\rbrack$ 隱含隨機變數 X 多「亂」的資訊 variance 大的話，X 不見得接近 $\\mu_X$ 變異數開根號是標準差(standard deviation) $\\sigma_X = \\sqrt{Variance} \\ge 0$ 算法 $\\sigma^2_X=E \\lbrack X^2 \\rbrack - \\mu^2_X\\\\ \\Rightarrow E \\lbrack X^2 \\rbrack = \\sigma^2_X + \\mu^2_X$\n常見離散分佈的期望值 / 變異數 $X\\text{\\textasciitilde}Bernouli(p)$\n$\\mu_X=1 \\cdot p + 0 \\cdot (1-p) \\\\ = p$\n$\\sigma^2_X = E \\lbrack X^2 \\rbrack - \\mu^2_X \\\\ = \\displaystyle\\sum^1_{x=0}x^2\\cdot p_X(x)-\\mu_X^2 \\\\ =1^2 \\cdot p + 0^2 \\cdot (1-p) - p^2\\\\ =p(1-p)$\n$X$~$BIN(n,p)$\n$\\mu_X = np$\n$\\sigma^2_X = np(1-p)$\n$X$~$GEO(p)$\n$\\mu_X = \\frac{1}{p}$\n$\\sigma^2_X = \\frac{(1-p)}{p^2}$\n$X$~$PASKAL(k,p)$\n$\\mu_X = \\frac{k}{p}$\n$\\sigma^2_X = \\frac{k(1-p)}{p^2}$\n$X$~$POI(\\alpha)$\n$\\mu_X = \\alpha$\n$\\sigma^2_X = \\alpha$\n$X$~$UNIF(a,b)$\n$\\mu_X = \\frac{a+b}{2}$\n$\\sigma^2_X = \\frac{1}{12}(b-a)(b-a+2)$\n連續隨機變數 對連續的隨機變數 X 而言，將 X 的值以 $\\Delta$ 為單位無條件捨去來近似，以隨機變數 Y 表示(當 $\\Delta \\rightarrow$ 0 時，$X \\approx Y$)，然後再當做 PMF 處理。\n$E \\lbrack X \\rbrack = \\int^{\\infty}_{-\\infty}xf_X(x)dx$ 連續隨機變數的函數的期望值 對連續隨機變數 X 而言，其任意函數 g(x) 也是一隨機變數，也有期望值 $g(X)$ 的期望值定義為 $E \\lbrack g(X) \\rbrack=\\int^{\\infty}_{-\\infty}g(x)\\cdot f_X(x)dx$ 性質 $E\\lbrack \\alpha g(X) \\rbrack = \\alpha \\cdot E \\lbrack g(X) \\rbrack$ $E\\lbrack \\alpha g(X) + \\beta h(X) \\rbrack \\\\ =\\alpha \\cdot E \\lbrack g(X) \\rbrack + \\beta \\cdot E \\lbrack h(X) \\rbrack$ $E\\lbrack \\alpha \\rbrack = \\alpha$ 常見隨機變數函數的期望值 $X$ 的 $n^{th} moment$ $E \\lbrack X^n \\rbrack = \\int^{\\infty}_{-\\infty}x^n \\cdot f_X(x)dx$ X 的變異數(variance) $E \\lbrack (X-\\mu_X)^2 \\rbrack = \\int^{\\infty}_{-\\infty} (x-\\mu_X)^2 \\cdot f_X(x)dx$ 變異數 Variance 和離散隨機變數的資訊一樣 常見連續分佈之期望值/變異數 $X$~$Exponential(\\lambda)$\n$\\mu_X = \\frac{1}{\\lambda}$\n$\\sigma^2_X = \\frac{1}{\\lambda^2}$\n$X$~$Erlang(n, \\lambda)$\n$\\mu_X = \\frac{n}{\\lambda}$\n$\\sigma^2_X = \\frac{n}{\\lambda^2}$\n$X$~$Gaussian(\\mu,\\sigma)$\n$\\mu_X = \\mu$\n$\\sigma^2_X = \\sigma^2$\n$X$~$UNIF(a,b)$\n$\\mu_X = \\frac{a+b}{2}$\n$\\sigma^2_X = \\frac{1}{12}(b-a)^2$\n","date":"2023-02-01T15:18:41+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E6%A9%9F%E7%8E%87%E8%AB%96-ii/","title":"機率論 - II"},{"content":"集合論 名詞 子集合(Subset) B 是 C 的子集(B 不能等於 C) $B \\subset C$ 補集(Complement) C 是 A 的補集 $C=A^C$ 不相交(Disjoint) $X \\cap Y = \\{\\}$ 互斥(Mutually Exclusive) 一群集合 $X_1, X_2, \u0026hellip;, X_n$ 中任選兩個集合 $X_i, X_j$ 都不相交，則 $X_1, X_2, \u0026hellip;, X_n$ 這群集合互斥 公式 De Morgan\u0026rsquo;s Law ${(A \\cup B)}^C=A^C \\cap B^C$ 機率名詞 Outcome (結果) 實驗中可能的結果 Sample Space (樣本空間) 機率實驗所有可能的結果的集合，常以 $S$ 表示 Event (事件) 對於實驗結果的某種敘述 事件可以看做是 outcome 的集合，也是 sample space 的子集 機率是一個函數，其自變數是 event，故可看做是一個映射 公理 Axioms 對任何事件 $A$ 而言, $P(A) \\geq 0$\n$P(S) = 1$\n事件 $A_1, A_2, \u0026hellip;$ 互斥 $\\Rightarrow$ $P(A_1 \\cup A_2 \\cup A_3 \\cup \u0026hellip;)$\n$=P(A_1)+P(A_2)+P(A_3)+\u0026hellip;$\n衍生公式 Boole\u0026rsquo;s 不等式\n對任意 $n$ 個事件 $A_1, A_2, \u0026hellip;, A_n$ 而言 $P(\\cup^n_{i=1}A_i \\leq \\Sigma^n_{i=1}P(A_i))$ Bonferroni\u0026rsquo;s 不等式\n對任意 $n$ 個事件 $A_1, A_2, \u0026hellip;, A_n$ 而言 $P(\\cap^n_{i=1} A_i) \\geq 1 - \\Sigma^n_{i=1} P(A^C_i)$ 條件機率 公式 $P(X|Y) = \\frac{P(X \\cap Y)}{P(Y)}$ $P(X \\cap Y) = P(X|Y) * {P(Y)} = P(Y|X) * P(X)$ 性質 $P(X|Y) \\geq 0$ $P(Y|Y) = 1$ $A, B$ 互斥 $\\Rightarrow P(A \\cup B |Y) = \\frac{P(A)}{P(Y)} + \\frac{P(B)}{P(Y)} = P(A|Y)+P(B|Y)$ 定理 Total Probability 定理 若 $C_1, C_2, \u0026hellip;, C_n$ 互斥且 $C_1 \\cup C_2 \\cup \u0026hellip; \\cup C_n = S$，則對任意事件 $A$ $P(A) = P(A|C_1)P(C_1) + P(A|C_2)P(C_2) + \u0026hellip; + P(A|C_n)P(C_n)$ Bayes\u0026rsquo; Rule 貝式定理 若 $C_1, C_2, \u0026hellip;, C_n$ 互斥且 $C_1 \\cup C_2 \\cup \u0026hellip; \\cup C_n = S$，則對任意事件 $A$ $P(C_j|A)=\\frac{P(A|C_j) * P(C_j)}{\\Sigma^n_{i=1}P(A|C_i)*P(C_i)}$\n$= \\frac{P(C_j \\cap A)}{P(A)}$\n獨立性 Independence 若兩事件 $A, B$ 之機率滿足\n$P(A \\cap B) = P(A) * P(B)$ 或以 $P(A|B) = P(A)$ 表示 則 $A, B$ 兩事件稱為機率上的獨立事件\n若事件 $A_1, A_2, \u0026hellip; A_n$ 滿足下列條件，則稱此 $n$ 事件獨立 $(n\u0026gt;2)$\n從中任選 $m$ 事件 $A_{i_1}, A_{i_2}, \u0026hellip; A_{i_m}$ 均滿足 $P(A_{i_1} \\cap A_{i_2} \\cap \u0026hellip; \\cap A_{i_m}) = P(A_{i_1})P(A_{i_2})\u0026hellip;P(A_{i_m}) , m=2, 3, \u0026hellip;, n$ 排列組合 二項式係數(binomial coefficient) $(^n_k)$ 有 $n$ 個異物，從中取出 $k$ 個 多項式係數(multinomial coefficient) $\\frac{n!}{n_1!n_2!\u0026hellip;n_m!}$ 有 m 種異物，每次選物從中選一後放回，依序選 n 次，共有 $m^n$ 種 outcome，在所有實驗結果中，第一種出現 $n_1$ 次，以此類推，這樣的實驗結果有多少種 隨機變數 Random Variable, R.V. 用來把 outcome 數字化的表示方式 通常用大寫英文字母 是將 outcome 轉成對應數字的函數 $X: S \\rightarrow R$ 從樣本空間映射到實數 隨機變數的函數，也是一個隨機變數 種類 離散隨機變數 (Discrete R.V.)\n值是有限個，或是「可數的」無窮多個 連續隨機變數 (Continuous R.V.)\n值有無窮多個，而且「不可數」 可數、不可數 可數 包含的東西可一個個被數，總有一天會被數到 e.g. 正偶數集合 不可數的 不管怎麼數，裡面一定有個東西會沒數到 e.g. 0~1 之間的所有數字 累積分佈函數 CDF cumulative distribution function\n對任一個隨機變數 $X$，定義 CDF 為\n$F_X(x) \\overset{def}{=}P(X \\leq x)$ 永遠用 $F$ 表示 常見用途\n算 X 落在某範圍的機率 $P(A \u0026lt; X \\le b) = F_X(b)-F_X(a)$ $P(A \\le X \\le b) = F_X(b)-F_X(a)+P(X=a)$ $P(A \u0026lt; X \u0026lt; b) = P(A \u0026lt; X \\le b^-)$ 性質 離散隨機變數的 CDF $F_X(x^+)=F_X(x)$ $F_X(x^-)=F_X(x)-P(X=x)$ 連續隨機變數的 CDF $F_X(x^-)=F_X(x)=F_X(x^+)$ 共同 $F_X(- \\infty)=P(X \\le - \\infty)=0$ $F_X(\\infty)=P(X \\le \\infty) = 1$ $0 \\le F_X(x) \\le 1$ 機率質量函數 PMF probability mass function 對任一個「離散」隨機變數 $X$，其 PMF 為 $p_X(x) \\overset{def}{=}P(X=x)$ PMF 和 CDF 的關係 對任何 $x$ $F_X(x) = \\displaystyle\\sum^{\\lfloor x \\rfloor}_{n=-\\infty}p_X(n)$ $P_X(x)=F_X(x^+)-F_X(x^-)$ 機率分佈(Probability Distribution) PMF 和 PDF 都是一種機率分佈 將總和為 1 的機率分佈在點上 離散機率分佈 Bernoulli 機率分佈 1 次實驗，2 種結果，在意某結果發生與否 $X \\text{\\textasciitilde}Bernoulli(p)$ PMF $p_X(x) = \\begin{cases} p \u0026amp; ,x=1 \\\\ 1-p \u0026amp; x=0 \\\\ 0 \u0026amp; ,otherwise \\end{cases}$ CDF $F_X(x) = \\begin{cases} 0 \u0026amp; ,x\u0026lt;0 \\\\ 1-p \u0026amp; 0 \\leq x \u0026lt;1 \\\\ 1 \u0026amp; ,x \\geq 1 \\end{cases}$ Binomial 機率分佈 實驗成功機率為 p，做 n 次實驗，X 表成功次數 $X \\text{\\textasciitilde}BIN(p)$ PMF $p_X(x) = (^n_x)p^x(1-p)^{n-x}$ 成功 $x$ 次 CDF $F_X(x) = \\displaystyle\\sum^{\\lfloor x \\rfloor}_{m=-\\infty} (^n_m)\\cdot p^m \\cdot (1-p)^{n-m}$ Uniform 機率分佈 1 次實驗，n 種結果，各結果機率均等，在意某結果發生否 $X \\text{\\textasciitilde}UNIF(a,b)$ PMF $p_X(x) = \\begin{cases} \\frac{1}{b-a+1} \u0026amp; ,x=a,a+1,\u0026hellip;,b \\\\ 0 \u0026amp; ,otherwise \\end{cases}$ CDF $F_X(x) = \\begin{cases} 0 \u0026amp; ,x\u0026lt;a \\\\ \\frac{\\lfloor x \\rfloor - a + 1}{b-a+1} \u0026amp; ,a \\leq x\u0026lt; b\\\\ 1 \u0026amp; ,x \\geq b \\end{cases}$ Geometric 機率分佈 若實驗成功機率為 p，到成功為止，做了 X 次嘗試 有失憶性 $X \\text{\\textasciitilde}Geometric(p)$ PMF $p_X(x) = \\begin{cases} (1-p)^{x-1} \\cdot p \u0026amp; ,x=1, 2, 3, \u0026hellip; \\\\ 0 \u0026amp; ,otherwise \\end{cases}$ CDF $F_X(x) = \\begin{cases} 1-(1-p)^{\\lfloor x \\rfloor} \u0026amp; ,x \\ge 1 \\\\ 0 \u0026amp; ,otherwise \\end{cases}$ Pascal 機率分佈 若實驗成功機率為 p，到第 k 次成功為止，共做了 X 次嘗試 $X \\text{\\textasciitilde}Pascal(k, p)$ PMF $p_X(x) = \\begin{cases} \\binom{x-1}{k-1}(1-p)^{x-k} p^k \u0026amp; ,x=k, k+1, \u0026hellip; \\\\ 0 \u0026amp; ,otherwise \\end{cases}$ CDF $F_X(x) = P(X \\le x) \\\\ = P(在 x 次實驗中 \\ge k 次成功)\\\\ = P(Y \\ge k), Y~BIN (x,p) \\\\ $ 故 Pascal 又稱 Negative Binomial Poisson 機率分佈 已知某事發生速率為每單位時間 $\\lambda$ 次，觀察時間為 $T$ 時間單位，$X$ 為該觀察時間內發生該事的總次數。 $X \\text{\\textasciitilde}POI(\\lambda T)$ 有時候也會以 $\\mu$ 來表示 $\\lambda T$ PMF $p_X(x) = e^{-\\lambda T} \\cdot \\frac{(\\lambda T)^x}{x!}$ CDF $F_X(x) = \\begin{cases} \\displaystyle\\sum^{\\lfloor x \\rfloor}_{n=-\\infty}e^{-\\lambda T} \\cdot \\frac{(\\lambda T)^n}{n!} \u0026amp; ,x = 0,1,2,\u0026hellip; \\\\ 0 \u0026amp; ,otherwise \\end{cases}$ ","date":"2023-01-31T15:18:41+08:00","permalink":"https://roykesydon.github.io/Blog/p/%E6%A9%9F%E7%8E%87%E8%AB%96-i/","title":"機率論 - I"},{"content":"Share information between processes 透過硬碟上的文件溝通 超慢 透過 kernel buffer 滿快的，但這樣要一直在 user mode 和 kernel mode 來回切換，因為kernel buffer 在 kernel space 透過 shared memory region shared memory region 在 user space Mechanisms Signals\nCommunication\nData transfer Byte Stream Pipes FIFOs(Named Pipes) stream sockets Message Passing SystemV MsgQ POSIX MsgQ datagram sockets Shared Memory SystemV S.M POSIX S.M Memory Mapping anonymous memory mapping memory mapped file Synchronization\nPipes Related processes parent-child sibling Executing on same machine 用法 cmd1 | cmd2 cmd1 不是輸出到 stdout，而是由 kernel 維護的 buffer，也就是 pipe cmd 不是從 stdin 獲取輸入，而是從 pipe 獲取 cmd1 | cmd2 | \u0026hellip; | cmdn Named Pipes / FIFOs Related / Unrelated processes\nExecuting on same machine\ncreat a FIFO\ncommands mkfifo mknod 嘗試寫入或讀取 FIFO 時，會被 redirect 到 pipe\nSignal Handling Signal Used by OS to notify running process some event has occured without the process needing to pull for that event process 收到 signal 後會先停止執行並執行 signal handler A process did something SIGSEGV(11), SIGFPE(8), SIGILL(4), SIGPIPE(13)\u0026hellip; A process wants to tell another process something SIGCHILD(17) child process terminated User sends sig to foreground processes Ctrl + C SIGINT(2) Ctrl + \\ SIGQUIT(3) Ctrl + Z SIGTSTP(20) disposition 決定 process 遇到 signal 時該怎麼處理\nTerm teminate process Ign ignore Core terminate the process and dump core Stop stop the process Cont continue the process if it is stopped Signal can\u0026rsquo;t not be caught SIGKILL(9) SIGSTOP(19) Commands trap\n可以 handle signal\nkill kill - L 可以看到 standard signal 和 real-time signal\nstandard signal 開頭是 SIG，realt-time signal 是 SIGRT\n","date":"2023-01-28T15:31:50+08:00","permalink":"https://roykesydon.github.io/Blog/p/ipc--inter-process-communication/","title":"IPC -- Inter-Process Communication"},{"content":"paper: Training language models to follow instructions with human feedback\nAbstract 把語言模型變大不代表他們會更好地遵循用戶的意圖。\n大的語言模型有可能會生成 untruthful, toxic, not helpful 的答案。\n該論文透過 fine-tuning with human feedback 來解決這問題。\n一開始準備一系列人工標註的 prompts，然後用這 dataset 對 GPT-3 做 fine-tune。\n接下來再蒐集一個 dataset，存放 rankings of model outputs，由人工判斷輸出好壞，再用 RL 把剛剛 fine-tune 過的 model 繼續 fine-tune。\n最後有 1.3B 參數的 InstructGPT 表現的結果比 175B 參數的 GPT-3 還好。\nIntroduction Large language models(LMs) 可以透過 \u0026ldquo;prompt\u0026rdquo; 來執行各種 NLP 任務。\n但這些模型也常有一些非目的性的行為，諸如捏造事實等等。\n原因是出在目標函數上，多數 LMs 的目標函數是根據網路上的文本生出下一個字詞。\n這和「根據使用者指令生出安全且有幫助的答案不同」。\n上述的差異使語言模型的目標是 misaligned。\n作者的目標是生出 helpful、 honest(沒有誤導性資訊)、harmless 的 model。\n具體作法，使用 reinforcement learning from human feedback(RLHF)。\n訓練步驟 結果 Labelers 明顯偏好 InstructGPT 的答案，勝過 GPT-3 的答案\nInstructGPT 的答案在 truthfulness 勝過 GPT-3 的答案\nInstructGPT 的答案在 toxicity 上小勝 GPT-3 的答案，但在 bias 上沒有\nMethods Dataset 標註人員寫很多 prompts\nPlain: 隨便寫任意任務 Few-shot: 想個 instruction，並寫 multiple query/response pairs for that instruction User-based: 根據一些申請使用 OpenAI API 的用戶，提出有關的 prompts 然後根據這個訓練初步模型，並把這個初步模型放到他們的 Playground 給用戶使用。\n再把用戶問的問題蒐集回來，並做篩選。\n訓練 SFT 的模型用 13k training prompts\n訓練 RM 的模型用 33k training prompts\n訓練 PPO 的模型用 31k training prompts\nModel Supervised fine-tuning(SFT)\n拿 GPT-3 去訓練 16 個 epochs 跑一個 epoch 就發現 overfitting，但發現訓練更多 epoches 對後面的 RM 有用，而且這個 model 也只是過渡產品 Reward modeling(RM)\n把 SFT 後面的 unembedding layer 去除掉，接上線性層，最後輸出一個 scalar reward\n用 6B RMs\n這模型會吃 prompt 和 response\n人工標記的是排序，不是分數\n對每個 prompt 生出 9 個答案\n原本是 4 個，但排 9 個花的時間可能不會到 4 個的兩倍，因為主要心力會花在讀 prompt。但標註訊息會多很多，因為都是兩兩比較。 而且在 loss 中最多只要丟入 RM 9 次，因為可以重用 Pairwise Ranking Loss\n對一個 prompt(假設是 x)，取出一對回覆(假設是 $y_w$ 和 $y_l$)，算出 RM(x, $y_w$) 和 RM(x, $y_l$)，假設 $y_w$ 比 $y_l$ 排序高，讓 RM(x, $y_w$) - RM(x, $y_l$) 的數值越大越好 Reinforcement learning(RL)\nPPO\n$\\beta$ 那項是 KL divergence $\\gamma$ 那項是不想要讓這 model 太專注在微調的任務，而失去原本在其他 NLP 任務也表現很好的功能。 $D_{pretrain}$ 是 pretraining distribution 如果 $\\gamma$ 為 0，在該實驗中叫做 PPO，否則，稱為 PPO-ptx Result ","date":"2023-01-27T17:39:12+08:00","permalink":"https://roykesydon.github.io/Blog/p/instructgpt/","title":"InstructGPT"},{"content":"介紹 一種用於自動化找超參數的方法，用在採樣昂貴而且是黑盒子的情況\n流程 取樣一些資料點 生出一個 Surrogate Model(可採用 Gaussian Process) 反覆做以下事情 用 Acquisition Function 挑選下一個要採樣的點 重新評估 Surrogate Model Gaussian Process 最終的 prediction 是一個 distribution 而不是單一個數字 生成方法需借助 kernel function，常用 RBF(Radial Basis Function)\n$K(x, x^{\u0026rsquo;}|\\tau)=\\sigma^2exp(-\\frac{1}{2}(\\frac{x-x^{\u0026rsquo;}}{l})^2)$\n$\\sigma$ 和 $l$ 是兩個可以調整的超參數\nAcquisition Function 可用超參數來調節 exploitation 和 exploitation\nUCB(Upper confidence bound) PI(probability of improvement) EI(Expected improvement) ","date":"2023-01-26T01:36:53+08:00","permalink":"https://roykesydon.github.io/Blog/p/bayesian-optimization/","title":"Bayesian Optimization"},{"content":"PPFDT per process file descriptor table 每個 process 都有 存放 file descriptors file descriptors 是一個唯一的整數，用來識別作業系統上的 open file 0, 1, 2 是 Standard input / ouput / error 大小受限於 OPEN_MAX，亦即能同時間能開的最多檔案數 Redirection Input redirection $ wc \u0026lt; /etc/passwd 把 wc 的 PPFDT 的 stdin 改成 /etc/passwd 如果是 $ wc /etc/passwd，則是在 PPFDT 追加 /etc/passwd Ouput redirection $ wc \u0026gt; f1 把 wc 的 PPFDT 的 stdout 改成 f1 Input \u0026amp; output redirection 兩個可以同時用\n$ cat \u0026lt; f1 \u0026gt; f2 \u0026gt;\u0026gt; 可以 append $ \u0026lt; f1 cat \u0026gt; f2 可以亂換位置 Error redirection $ find / -name f1 2\u0026gt; error 1\u0026gt; outputs 這樣就會把那些 Permission denied 的給到 errors，成功的給到 outputs 2\u0026gt;/dev/null /dev/null 會把丟進來的東西都丟棄 Copy Descripter 這兩者等價 $ cat f1 1\u0026gt;op_err 2\u0026gt;op_err $ cat f1 1\u0026gt;op_err 2\u0026gt;\u0026amp;1 make 2 a copy of 1 ","date":"2023-01-21T02:20:43+08:00","permalink":"https://roykesydon.github.io/Blog/p/io-redirection/","title":"IO Redirection"},{"content":"Compile C 4-steps pre-processing compilation assembly linking Types of Object Files Executable object file Relocatable object file Shared object file Core file Formats of Object Files a.out initial version of UNIX COFF SVR3 UNIX PE Win. NT ELF SVR4 Linux ELF format of a program ELF Header Program Header Table .text .rodata .data .bss .symtab .rel.text .rel.data .debug .line .strtab Section Header Table 可參考: http://ccckmit.wikidot.com/lk:elf\nProcess Instance of a program running on a computer\nProcess Control Block task_struct\nProcess Identification PID, PPID, SID, UID, EUID.. Process State Information Process Control Information ","date":"2023-01-21T00:08:25+08:00","permalink":"https://roykesydon.github.io/Blog/p/process-management/","title":"Process Management"},{"content":"Features Process control Variables Flow control Functions File \u0026amp; cmd name completions Cmd line editng Cmd history Command Mode Interactive Non- Interactive Command Type internal / Builtin command\n指令的程式碼是 shell 的一部分 e.g., cd, exit 不會產生 child process 有些 internal command，比如 echo, pwd，會 internal 和 external 都有實作 external command\n指令的程式碼在硬碟上的某個 binary file e.g., clear, ls 會產生 child process Common Commands 比較實用或常用的\ngrep\n找字詞\ngrep \u0026lt;string/pattern\u0026gt; -i 大小寫不敏感 -v 不包含關鍵字的 cut 找 column\n-f 找哪些 column -d 分隔符是什麼 比較兩個檔案\ncomm\n顯示 file1 獨有的列、 file2 獨有的列、file1 和 file2 共有的列\ncmp, diff\n回傳不一樣的列資訊\nunset\n把指定的變數移除掉\ntee\n吃 stdin 輸出到 stdout 和其他檔案\nless\n讀檔案用\nExpansions White space Control Operators ; 讓指令接著執行 \u0026amp; 放在結尾，讓指令在背景執行 \u0026amp;\u0026amp; logical AND || logical OR\n前面失敗才會跑後面\n# 註解用 \\ escape special characters 放結尾好換行繼續輸入 $? 一個特別的變數，有上個指令的 exit code Shell variables User defined Env var Shell history File Globing *, ?, [], -, ! ","date":"2023-01-19T23:00:02+08:00","permalink":"https://roykesydon.github.io/Blog/p/shell/","title":"Shell"},{"content":"GPT 本質上就是 Transformer 的 decoder\nGPT-1 paper: Improving Language Understanding by Generative Pre-Training\n用 semi-supervised，後來被歸為 self-supervised\nUnsupervised pre-training $L_1(U)=\\sum_i logP(u_i|u_{i-k},\u0026hellip;,u_{i-1};\\theta)$\n$U= \\{ u_1,\u0026hellip;,u_n \\}$\n$U$ 是一系列未標記的文本 token\n$k$ 是窗口大小\n模型大致架構 $h_0=UW_e+W_p$\n$h_1=transformer \\_ block(h_{i-1})\\forall i \\in[1,n]$\n$P(u)=softmax(h_nW^T_e)$\n$U=\\{u_{-k},\u0026hellip;,u_{-1}\\}$\nSupervised fine-tuning $P(y|x^1,\u0026hellip;,x^m)=softmax(h^m_lW_y)$\n$L2(C)=\\sum_{(x,y)}log P(y|x^1,\u0026hellip;,x^m)$\n$L_3(C)=L_2(C)+\\lambda*L_1(C)$\n$C$ 是 labeled 的資料集，微調基本上就是在後面加上線性層\n作者最大化 likelihood 的時候是用 $L_3$ 而非單純的 $L_2$\n微調應用範例 資料集 用 BooksCorpus 訓練出來的\n有超過 7000 本未出版的書\n模型結構 12 層 transformer 的 decoder 768 維 word embedding 12 個 attention heads 和 BERT BASE 比較 BERT 論文比較晚出，但 BASE 的模型架構和 GPT 有相似之處，\nBASE 是 12 層的 decoder，word embedding 和 attention head 的維度或數量和 GPT-1 相同\nGPT-2 paper: Language Models are Unsupervised Multitask Learner\nGPT-2 除了用更大的的模型和更大的資料集，把重點放在 zero-shot 上，雖然在 GPT-1 的論文就有提過 zero-shot\n資料集 這次做了一個叫做 WebText 的資料集，有百萬級別的網頁\nCommon Crawl 大型爬蟲專案，有大量網頁資料，但充斥了垃圾訊息\nWebText WebText 的資料來源是 reddit 上的外部連結，只要有至少三個 karma，就會被採納，由此取得品質較好的網頁資料。透過這種方法，取得了 4500 萬個連結。並用Dragnet (Peters \u0026amp; Lecocq, 2013) and Newspaper content extractors 把文字訊息從 HTML 中抓出來\n架構 和原本差不多，變成有 1.5B 參數的 Transformer decoder\nzero-shot 不需要下游任務的標記資料\n改把任務輸入進模型\n目前問題 現在的模型泛化能力不太好 Multitask learning 在 NLP 上不太常用，NLP 現在主流還是在預訓練模型上做微調以應對下游任務 對每個下游任務都得重新訓練模型 得蒐集 labeled 資料 結果 GPT-3 paper: Language Models are Few-Shot Learners\n摘要 有 175B 的參數，由於模型極大，要在子任務微調會成本很大，所以不做任何梯度更新 在很多 NLP 任務有傑出的成果 可以生出人類難以區分的新聞文章 目前有的問題 要在子任務微調，需要資料集 微調後在有些子任務上表現好不代表你預訓練模型一定泛化能力高 人類不需要大量 labeled 資料去完成小任務 評估方式 分為三種，few / one / zero-shot learning 架構 基本上 GPT-3 和 GPT-2 架構一樣\n相同 modified initialization pre-normalization reversible tokenization described therein 不同 把 Sparse Transformer 的一些修改拿過來用 GPT-3 Small 是 GPT-1 的大小 GPT-3 Medium 是 BERT Large 的大小 GPT-3 XL 和 GPT-2 相近，比較淺也比較寬\nBatch Size 大小 模型小的時候需要小一點，透過這種額外的 noise 來避免 overfitting(不確定是不是猜想)\n資料集 Common Crawl 架構比 GPT-2 大很多，所以回頭考慮這個資料集\n三步驟 先過濾，透過 reddit 那個高品質的資料集，來訓練一個模型分類高品質和低品質的網頁。 透過 LSH 演算法把相似的文本過濾掉 把一些已知高品質的資料集也加進來 這是一個 Batch 裡有 60% 來自 Common Crawl(filtered) 的意思 Wikipedia 雖然總量比較少，但也有 3% 的採樣率\n結果 計算量指數增長，loss 卻是線性的往下降\npaper 裡有很多任務的實驗結果，這邊就不附上了\nLimitations 在文本生成上還是比較弱，生很長的東西，可能會重複自己說過的話、失去連貫性、自相矛盾等等\n在有些雙向性的任務上可能表現更差\n影響 可能被用來散布不實消息、垃圾郵件等等 偏見 結論 在很多 NLP 任務可以做到接近 SOTA 微調模型的成果\n","date":"2023-01-19T01:50:07+08:00","permalink":"https://roykesydon.github.io/Blog/p/gpt-%E4%B8%89%E9%83%A8%E6%9B%B2/","title":"GPT 三部曲"},{"content":"VM A software implementation of a machine\nSystem VM 提供可以執行 GuestOS 的 complete system platform Process VM 像一個一般的 app 一樣在 hostOS 跑，支援單一個 process Hypervisor 又稱虛擬機器監視器（英語：virtual machine monitor，縮寫為VMM） 用來管理 VM\n允許多個 GuestOS 跑在 host computer\nType-1\nbare-metal hypervisors 直接在硬體上執行 Type-2\nhosted hypervisors 在 hostOS 上執行 directories Binary\ne.g., bin, sbin, lib, opt bin: 有關 user 的指令 sbin: 管理員會用的指令 opt: optional software，多數機器中這是空的 Configuration\ne.g., boot, etc, Data\ne.g., home, root, srv, media, mnt, temp In memory 字面上的意思，不在 hard disk，在 memory\ne.g., dev, proc, sys System Resources\ne.g., usr Variable Data\ne.g., var ","date":"2023-01-19T01:50:07+08:00","permalink":"https://roykesydon.github.io/Blog/p/linux-%E7%91%A3%E4%BA%8B/","title":"Linux 瑣事"}]