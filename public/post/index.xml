<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Posts on Roykesydon</title>
        <link>https://roykesydon.github.io/Blog/post/</link>
        <description>Recent content in Posts on Roykesydon</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <lastBuildDate>Thu, 10 Aug 2023 00:27:55 +0800</lastBuildDate><atom:link href="https://roykesydon.github.io/Blog/post/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>DETR 論文</title>
        <link>https://roykesydon.github.io/Blog/p/detr-%E8%AB%96%E6%96%87/</link>
        <pubDate>Thu, 10 Aug 2023 00:27:55 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/detr-%E8%AB%96%E6%96%87/</guid>
        <description>&lt;p&gt;paper: &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2005.12872&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;End-to-End Object Detection with Transformers&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;作者把 object detection 視作一個 set prediction 問題。&lt;/p&gt;
&lt;p&gt;簡化了 pipeline，消除了許多 hand-designed components，比如 non-maximum suppression 和 anchor generation，這些 component 由我們對於任務的先驗知識構成。&lt;/p&gt;
&lt;p&gt;提出了一個新的目標函數，透過二分匹配（bipartite matching）進行預測，也用 Transformer encoder-decoder 架構。&lt;/p&gt;
&lt;p&gt;給予一組固定的 learned object query，DETR 可以推理 objects 和 globol image context 的關係，並「並行」輸出一組預測集。&lt;/p&gt;
&lt;p&gt;DETR 概念非常簡單。&lt;/p&gt;
&lt;p&gt;DETR 在 COCO 上和 Faster RCNN baseline 在準確度和 performance 上相當。&lt;/p&gt;
&lt;p&gt;DETR 可以很簡單地推廣到 Panoptic Segmentation。&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;目標檢測的目標就是集合預測。&lt;/p&gt;
&lt;p&gt;但目前都用一些很間接的方式去做，像是用 proposals, anchors 或 window centers。&lt;/p&gt;
&lt;p&gt;但是這些方法性能明顯受限於後處理步驟，比如 non-maximum suppression，因為他們會產生大量冗餘的框。&lt;/p&gt;
&lt;p&gt;為了簡化 pipeline，作者提出了一種 End-to-End 的方法，以往也有一些嘗試，但他們要不添加了其他的先驗知識，不然就是在具有挑戰性的 benchmark 上表現不好。&lt;/p&gt;
&lt;p&gt;在 COCO 上和 Faster R-CNN 的性能相當，表現和速度都差不多。&lt;/p&gt;
&lt;p&gt;DETR 在大物體表現很好，可能是歸功於 Transformer non-local 的計算能力。
雖然 DETR 在小物體上表現倒不怎麼樣。&lt;/p&gt;
&lt;p&gt;DETR 需要超長的訓練時間，但 DETR 的設計理念可以拓展到 Panoptic Segmentation。&lt;/p&gt;
&lt;h2 id=&#34;related-work&#34;&gt;Related Work&lt;/h2&gt;
&lt;h3 id=&#34;set-prediction&#34;&gt;Set Prediction&lt;/h3&gt;
&lt;p&gt;沒有規範的深度學習模型可以直接預測集合。&lt;/p&gt;
&lt;p&gt;這些任務中的一個困難點是避免 near-dulicates（相近的重複檢測框） 當前多數檢測器用 NMS 來解決此問題，如果是 direct set prediction 就不用後處理。&lt;/p&gt;
&lt;h3 id=&#34;transformers-and-parallel-decoding&#34;&gt;Transformers and Parallel Decoding&lt;/h3&gt;
&lt;p&gt;Transformer 在各種地方表現出色，但推理成本令人望而生畏。&lt;/p&gt;
&lt;h3 id=&#34;object-detection&#34;&gt;Object detection&lt;/h3&gt;
&lt;p&gt;現在多數的目標檢測方法是基於一些初始的猜測，再去做預測。&lt;/p&gt;
&lt;p&gt;比如對於 two-stage 的方法，就是對於 proposals 往下做預測。&lt;/p&gt;
&lt;p&gt;對於 single-stage，初始猜測就是 anchors。&lt;/p&gt;
&lt;h4 id=&#34;set-based-loss&#34;&gt;Set-based loss&lt;/h4&gt;
&lt;p&gt;以前的一些作法比如 Learnable NMS 或 relation networks 都可以透過 attention 來處理不同預測之間的關係。&lt;/p&gt;
&lt;p&gt;用 direct set losses，他們不需要任何後處理。&lt;/p&gt;
&lt;p&gt;但是這些方法往往用額外的 hand-crafted context feature，比如 proposal box coordinates。作者尋找減少模型中先驗知識的方案。&lt;/p&gt;
&lt;h4 id=&#34;recurrent-detectors&#34;&gt;Recurrent detectors&lt;/h4&gt;
&lt;p&gt;以往有類似的工作，但他們是用 RNN。&lt;/p&gt;
&lt;h2 id=&#34;the-detr-model&#34;&gt;The DETR model&lt;/h2&gt;
&lt;h4 id=&#34;object-detection-set-prediction-loss&#34;&gt;Object detection set prediction loss&lt;/h4&gt;
&lt;p&gt;DETE 會給 N 個固定大小的集合預測。&lt;/p&gt;
&lt;p&gt;要解二分圖匹配，本文用 scipy 的 linear_sum_assignment 處理，他背後是匈牙利演算法。&lt;/p&gt;
&lt;p&gt;其實這種方法和 proposals 和 anchors 有差不多的作用，差別在於這裡會找一對一的匹配，而不用重複。&lt;/p&gt;
&lt;p&gt;目標函數：&lt;/p&gt;
&lt;p&gt;$L_{Hungarian}(y, \text{\^{y}}) = \displaystyle\sum^{N}_{i=1} [-log \text{\^{p}} $
$_{\^{\sigma}(i)}(c_i) + \text{1}$
$_\{$
$_{c_i \neq \text{\o}}$
$_\}$
$\mathcal{L}$
$_{\text{box}} (b_i, \text{\^{b}}$
$_{\^{\sigma}}(i))]$&lt;/p&gt;
&lt;p&gt;前面是分類的 loss，後面是 bounding box 的 loss。&lt;/p&gt;
&lt;p&gt;這邊有兩個改動，第一個是分類那邊不用 log，使值和 bounding box 的 loss 比較接近。&lt;/p&gt;
&lt;p&gt;另一個是 bounding box 那邊並不是用最常見的 L1，因為 L1 對於大的目標 loss 比較高，這裡除了 L1 還選用 generalized IoU loss，它在尺度上與 loss 無關。&lt;/p&gt;
&lt;h4 id=&#34;detr-architecture&#34;&gt;DETR architecture&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/DETR/fig2.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;用 CNN 從圖片抽特徵，拉直，餵給 Transformer encoder-decoder，得到一組預測集合。&lt;/p&gt;
&lt;p&gt;這裡 encoder 有助於特徵間彼此交互。&lt;/p&gt;
&lt;p&gt;訓練的時候，預測的框和 GT 做匹配，沒匹配到的就放到 &amp;ldquo;no object&amp;rdquo; class。&lt;/p&gt;
&lt;p&gt;decoder 會餵入 object queries，這些是 learnable positional encodings。&lt;/p&gt;
&lt;h2 id=&#34;experiments&#34;&gt;Experiments&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/DETR/table1.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/DETR/table2.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;ablations&#34;&gt;Ablations&lt;/h3&gt;
&lt;h4 id=&#34;number-of-encoder-layers&#34;&gt;Number of encoder layers&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/DETR/fig3.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;作者透過改變 Encoder layer 的數量來評估 global imagelevel self-attention 的重要性。&lt;/p&gt;
&lt;p&gt;作者推論 encoder 可能對於判斷分開對象很重要，圖 3 可視化了最後一個 encoder layer 的 attention map。&lt;/p&gt;
&lt;p&gt;encoder 看似已經分離了 instance，可能簡化了 decoder 對於 object extraction 和 localization 的工作。&lt;/p&gt;
&lt;h4 id=&#34;number-of-decoder-layers&#34;&gt;Number of decoder layers&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/DETR/fig6.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;在圖 6 做了 decoder 的注意力可視化，可以注意到觀察的注意力相當局部。&lt;/p&gt;
&lt;p&gt;推論是 encoder 主要分離實體，decoder 只需要關注四肢即可提取出對象的邊界和分類。&lt;/p&gt;
&lt;h3 id=&#34;analysis&#34;&gt;Analysis&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/DETR/fig7.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;圖 7 把 100 個預測槽中的 20 個做可視化。&lt;/p&gt;
&lt;p&gt;每個預測框代表一點，可以注意到不同的槽位會專注在不同區域。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>BERT 論文閱讀</title>
        <link>https://roykesydon.github.io/Blog/p/bert-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</link>
        <pubDate>Sat, 05 Aug 2023 00:08:46 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/bert-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</guid>
        <description>&lt;p&gt;paper: &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/1810.04805&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;現在回頭寫 BERT 論文筆記感覺有點怪，之前已經寫過什麼 RoBERTa 之類的。&lt;/p&gt;
&lt;p&gt;不過現在因應實驗室讀書會要求，還是看一下論文也寫一下筆記。&lt;/p&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;本文提出了 BERT，一種基於 Transformer Bidirectional Encoder 的語言表示模型。&lt;/p&gt;
&lt;p&gt;BERT 旨在透過 unlabeled text 進行 pretrain。&lt;/p&gt;
&lt;p&gt;因此，只需要一個額外的輸出層就可以對預訓練的 BERT 進行微調，在各種任務上取得 SOTA。&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;「語言模型做預訓練」已被證明可以有效改善多種 NLP 任務。&lt;/p&gt;
&lt;p&gt;將預訓練模型應用在下游任務，有兩種策略：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Feature-based
&lt;ul&gt;
&lt;li&gt;把 pretrained 的 representations 作為額外的特徵&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Fine-tuning
&lt;ul&gt;
&lt;li&gt;根據特定任務引入額外參數，並簡單地微調所有參數&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;這兩種方法在預訓練期間共用同個 objective function，並用單向語言模型來學習 representation。&lt;/p&gt;
&lt;p&gt;作者認為當前的技術限制了預訓練的表示能力，特別是在 Fine-tuning 方法上。&lt;/p&gt;
&lt;p&gt;主要的問題在於語言模型是單向的，限制了預訓練期間可以使用的架構的選擇。這種單向的架構可能在一些任務有害，特別是對於那些需要兩個方向的 context 的任務。&lt;/p&gt;
&lt;p&gt;本文提出的 BERT 改善了現有的 Fine-tuning 方法，用 Transformer 的 Bidirectional Encoder 來訓練語言模型。&lt;/p&gt;
&lt;p&gt;BERT 透過受到 Cloze task（填空）啟發的 masked language model(MLM)，作為預訓練目標。MLM 隨機地遮蔽一些輸入的一些 token，目標是根據上下文來回推原詞，使 representation 可以融合左右兩邊的 context。&lt;/p&gt;
&lt;p&gt;除了 MLM，作者還利用 next sentence prediction（NSP）任務來訓練 BERT。&lt;/p&gt;
&lt;p&gt;本文貢獻如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;BERT 證明了雙向預訓練對 representation 的重要性。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;BERT 展現出預訓練的 representation 減少了許多針對 NLP 任務精心設計架構的需求。 BERT 是第一個基於 Fine-tuning，在大量 sentence-level 和 token-level 任務上取得 SOTA 的模型。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;BERT 推進了 11 個 NLP 任務的 SOTA。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;related-work&#34;&gt;Related Work&lt;/h2&gt;
&lt;h3 id=&#34;unsupervised-feature-based-approaches&#34;&gt;Unsupervised Feature-based Approaches&lt;/h3&gt;
&lt;p&gt;學習廣泛適用的 representation of words 一直是活躍的研究領域，甚至在非神經網路的領域也是。&lt;/p&gt;
&lt;p&gt;預訓練的 word embeddings 與從頭訓練的 embedding 相比，有顯著改進。&lt;/p&gt;
&lt;p&gt;這些方法頁被推廣到 coarser granularities，像是 sentence embedding 或是 paragraph embedding。&lt;/p&gt;
&lt;p&gt;有研究證明 cloze task 提高了生成模型的 robustness。&lt;/p&gt;
&lt;h2 id=&#34;bert&#34;&gt;BERT&lt;/h2&gt;
&lt;p&gt;框架有兩步驟：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Pre-training
&lt;ul&gt;
&lt;li&gt;在不同的預訓練任務中，用 unlabeled data 來 fine-tune。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Fine-tuning
&lt;ul&gt;
&lt;li&gt;使用預訓練的參數初始化，在利用下游任務的 labeled data 對所有參數微調。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;BERT 的一個特點是他具備跨不同任務的統一架構，預訓練架構和下游任務最終架構差異不大。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Model Architecture&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;本文表示方法&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;L: Transformer 的層數&lt;/li&gt;
&lt;li&gt;H: hidden size&lt;/li&gt;
&lt;li&gt;A: self-attention heads 的數量&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;model size&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;BASE: L=12, H=768, A=12, 110M parameters
&lt;ul&gt;
&lt;li&gt;和 GPT 相同&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;LARGE: L=24, H=1024, A=16, 340M parameters&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Input/Output Representations&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Input representation 可以在 token sequence 中明確表示單個 sentence 和一對 sentence。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;sentence 可以是連續文本的任意範圍，而不是實際的句子。&lt;/li&gt;
&lt;li&gt;sequence 是輸入的 token sequence，可以是單個 sentence 或是一對 sentence。&lt;/li&gt;
&lt;li&gt;每個 sequence 的第一個 token 始終是特殊的分類 token &amp;ndash; [CLS]&lt;/li&gt;
&lt;li&gt;對於兩個句子放在一個序列的情況，用 [SEP] 隔開&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Token Embeddings&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;作者使用 WordPiece embeddings，有 30000 個詞彙。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;learned embedding&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;對每個 token 添加這個東西，表示屬於 sentence A 還 sentence B&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;pre-training-bert&#34;&gt;Pre-training BERT&lt;/h3&gt;
&lt;h4 id=&#34;masked-lm&#34;&gt;Masked LM&lt;/h4&gt;
&lt;p&gt;直觀上，有理由相信深度的雙向模型會比單像串連起來的淺層模型更強大。&lt;/p&gt;
&lt;p&gt;不幸的是 standard condition language model 只能單向訓練，因為雙向會允許每個單詞「間接看到自己」。&lt;/p&gt;
&lt;p&gt;為了訓練 deep bidirectional representations，本文隨機遮蔽了一定比例的 tokens，並預測這些 token，這種方法稱為 masked language model，或常被稱為 cloze task。&lt;/p&gt;
&lt;p&gt;作者會用 [MASK] 做預訓練，但有個問題是 [MASK] 在 fine-tuning 期間不會出現，造成預訓練和微調之間的 mismatching，為了緩減這種情況，並不會總是用 [MASK] 替代 masked token。&lt;/p&gt;
&lt;p&gt;要替換 token 的時候，有 80% 的時間是 [MASK]，10% 是隨機 token，10% 是原本的 token。&lt;/p&gt;
&lt;h4 id=&#34;next-sentence-prediction-nsp&#34;&gt;Next Sentence Prediction (NSP)&lt;/h4&gt;
&lt;p&gt;許多重要下游任務，比如 Question Answering (QA) 和 Natural Language Inference (NLI) 是基於兩個句子間的關係。&lt;/p&gt;
&lt;p&gt;NSP 就是為了理解句子間的關係而用的。&lt;/p&gt;
&lt;p&gt;每次挑句子 A 和 B 的時候，有 50% 的機會 B 是 A 的下一個句子，有 50% 是隨機的。&lt;/p&gt;
&lt;p&gt;針對 NSP 的預訓練對 QA 和 NLI 都很有用。&lt;/p&gt;
&lt;h4 id=&#34;預訓練資料&#34;&gt;預訓練資料&lt;/h4&gt;
&lt;p&gt;用 BookCorpus 和 English Wikipedia 來訓練 BERT。&lt;/p&gt;
&lt;p&gt;對於 English Wikipedia，只提取 text passages，忽略 lists, tables, headers。&lt;/p&gt;
&lt;p&gt;為了提取長的連續序列，用 document-level 的 corpus 而不是打亂的 sentence-level corpus 非常重要。&lt;/p&gt;
&lt;h2 id=&#34;ablation-studies&#34;&gt;Ablation Studies&lt;/h2&gt;
&lt;h3 id=&#34;effect-of-pre-training-tasks&#34;&gt;Effect of Pre-training Tasks&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;No NSP
&lt;ul&gt;
&lt;li&gt;只有 MLM&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;LTR &amp;amp; No NSP
&lt;ul&gt;
&lt;li&gt;Left-to-Right&lt;/li&gt;
&lt;li&gt;只看左邊的 context&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;發現刪除 NSP 會顯著傷害對 QNLI 等資料集的性能。&lt;/p&gt;
&lt;p&gt;LTR 在所有任務上都比 MLM 差。&lt;/p&gt;
&lt;p&gt;雖然可以像 ELMo 單獨訓練 LTR 和 RTL，並且把他們結合起來&lt;/p&gt;
&lt;p&gt;但有以下缺點：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;比單向模型貴兩倍&lt;/li&gt;
&lt;li&gt;對 QA 任務不直觀，因為 RTL 無法根據問題給出答案&lt;/li&gt;
&lt;li&gt;不如深度雙向模型強大，因為其可以直接在每一層看到左右的 context&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;feature-based-approach-with-bert&#34;&gt;Feature-based Approach with BERT&lt;/h3&gt;
&lt;p&gt;作者也研究了用 feature-based 的效果，發現具備競爭力。&lt;/p&gt;
&lt;p&gt;在他的實驗中，用預訓練 Transformer 的 top 4 隱藏層的 token 串街效果最好。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>GNN 介紹</title>
        <link>https://roykesydon.github.io/Blog/p/gnn-%E4%BB%8B%E7%B4%B9/</link>
        <pubDate>Fri, 04 Aug 2023 00:27:55 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/gnn-%E4%BB%8B%E7%B4%B9/</guid>
        <description>&lt;h2 id=&#34;圖簡介&#34;&gt;圖簡介&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Graph&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;表示 Entity (nodes) 間的 relations (edges)&lt;/li&gt;
&lt;li&gt;組成
&lt;ul&gt;
&lt;li&gt;Vertex attributes (V)&lt;/li&gt;
&lt;li&gt;Edge attributes and directions (E)&lt;/li&gt;
&lt;li&gt;Global attributes (U)&lt;/li&gt;
&lt;li&gt;下文簡稱 U, V, E&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;可以表示成圖的範例&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Images
&lt;ul&gt;
&lt;li&gt;相鄰 pixel 建無向邊&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Text
&lt;ul&gt;
&lt;li&gt;詞和下一個詞建單向邊&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Molecules
&lt;ul&gt;
&lt;li&gt;分子的連接處建無向邊&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Social networks
&lt;ul&gt;
&lt;li&gt;人和人之間建無向邊&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;定義問題&#34;&gt;定義問題&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;種類
&lt;ul&gt;
&lt;li&gt;Graph-level&lt;/li&gt;
&lt;li&gt;Node-level&lt;/li&gt;
&lt;li&gt;Edge-level&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;個別講的是基於什麼東西做分類，比如對每個人（node）分類一個陣營，就算 Node-level&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;挑戰&#34;&gt;挑戰&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;儲存邊的關係
&lt;ul&gt;
&lt;li&gt;鄰接矩陣
&lt;ul&gt;
&lt;li&gt;在節點多的情況下佔用空間大，而且可能非常稀疏&lt;/li&gt;
&lt;li&gt;同一張圖，換個點的順序後鄰接矩陣看起來就會不同
&lt;ul&gt;
&lt;li&gt;難以保證這些東西餵入神經網路後輸出相同&lt;/li&gt;
&lt;li&gt;可以用兩個 list，一個儲存邊的向量，另一個是 Adjacency list，依序紀錄邊的關係&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;稀疏矩陣
&lt;ul&gt;
&lt;li&gt;難以用 GPU 運算&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;graph-neural-network&#34;&gt;Graph Neural Network&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;GNN 是對圖上所有屬性的 optimizable transformation，而且可以保持 graph symmetries (permutation invariances，把 node 排序後結果不變)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;下文用的 GNN 是 message passing neural network&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;graph-in, graph-out&lt;/li&gt;
&lt;li&gt;不改變圖的 connectivity&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;最簡單的-gnn&#34;&gt;最簡單的 GNN&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;U, V, E 個別餵給不同的 MLP，組成一個 GNN 的 layer
&lt;ul&gt;
&lt;li&gt;MLP 單獨餵入每一個點，不考慮連接訊息，保持了 graph symmetries&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;預測&#34;&gt;預測&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;假如要對每個頂點做預測，最後再加個全連接層分類&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;pooling&#34;&gt;pooling&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;假如要對一個沒有向量的頂點做預測，我們可以用 pooling，蒐集相鄰邊和全局向量的資訊&lt;/li&gt;
&lt;li&gt;對於沒有頂點資訊的圖，我們可以用 pooling layer 獲取全部點的資訊，再做分類&lt;/li&gt;
&lt;li&gt;對於沒有邊資訊的圖，我們也可以用 pooling 去從相鄰點和全局向量獲得資訊&lt;/li&gt;
&lt;li&gt;對於沒有全局向量的圖，我們可以用 pooling 去從全部的點或邊獲得資訊&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;缺陷&#34;&gt;缺陷&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;中間的 layer 沒有利用圖的訊息，都是各自進入各自的 MLP 做轉換&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;passing-messages&#34;&gt;Passing messages&lt;/h3&gt;
&lt;p&gt;在做轉換前，先做一些 pooling&lt;/p&gt;
&lt;h4 id=&#34;匯聚頂點資訊&#34;&gt;匯聚頂點資訊&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;不是單單把點向量進行轉換，而是和相鄰的點一起做 aggregation 後再做轉換
&lt;ul&gt;
&lt;li&gt;如果 aggregation 是加總，和卷積有一點像，只不過是權重一樣的版本&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;匯聚頂點和邊的資訊&#34;&gt;匯聚頂點和邊的資訊&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;可以先把頂點匯聚給邊，再把邊匯聚回頂點，反之亦然
&lt;ul&gt;
&lt;li&gt;順序不同會導致不同結果&lt;/li&gt;
&lt;li&gt;兩種方法可以一起同步做，交替更新&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;全局資訊&#34;&gt;全局資訊&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;每次 layer 只看鄰居，要傳遞到遠的點須要走很多層&lt;/li&gt;
&lt;li&gt;導入 master node (context vector)，他連接了所有的點和邊&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;相關主題&#34;&gt;相關主題&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;採樣&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;考量到計算梯度可能需要儲存過多的中間資訊，可以考慮採樣一些點，只在子圖上做計算&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Batch&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每個點鄰居各數不同，使做 batch 成為有挑戰性的問題。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Inductive Bias&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;graph symmetries&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Aggregation&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;目前沒有一個最佳選擇&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Graph Convolutional Network&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;node 是根據鄰居 node 去做某種 aggregate，事後再做更新&lt;/li&gt;
&lt;li&gt;由於每次都看鄰居，假如有 k 層，可以把圖看做解 n 個子圖，每個子圖就是基於每個點去走 k 步所形成的&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Graph Attention Network&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;用 attention 決定其它點的權重，而不像 GCN 一樣把鄰居加起來&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>I3D 論文</title>
        <link>https://roykesydon.github.io/Blog/p/i3d-%E8%AB%96%E6%96%87/</link>
        <pubDate>Sun, 23 Jul 2023 00:27:55 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/i3d-%E8%AB%96%E6%96%87/</guid>
        <description>&lt;p&gt;paper: &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/1705.07750&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;目前的動作分類資料集 (UCF-101 和 HMDB-51) 的影片非常缺乏，使辨識「良好的影像架構」變得困難，
使多數方法在現有的小規模 benchmark 的表現差不多。為此本文根據新的 Kinetics Human Action Video dataset 對 SOTA 架構進行了重新評估。&lt;/p&gt;
&lt;p&gt;Kinetics 有 400 個人類動作類別。每個類別有 400 個 clip。從 YouTube 上獲取的，而且每個 clip 來自 unique 的 youtube 影片。&lt;/p&gt;
&lt;p&gt;本文分析了當前架構在 Kinetics 上動作分類任務的表現，也評估 Kinetcis 用作預訓練的效果。&lt;/p&gt;
&lt;p&gt;本文提出了一種基於 2D ConvNet inflation 的 Two-Stream Inflated 3D ConvNet (I3D)。&lt;/p&gt;
&lt;p&gt;I3D 的擴展方法讓 ImageNet 上已經取得成功的架構可以被利用在解決影像任務上。&lt;/p&gt;
&lt;p&gt;結果表明，經過在 Kinetics 上預訓練後，I3D 在動作分類方面顯著提高了 SOTA，在 HMDB-51 上達到 80.9%，在 UCF-101 上達到 98.0%。&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;在 ImageNet 上預訓練模型的效果很好，但在影片領域，預訓練成效一直是一個未知的問題。因為流行的動作識別 benchmark 都非常小，約略只有 10k 個影片。&lt;/p&gt;
&lt;p&gt;Kinetics 有 400 個人類動作類別。每個類別有 400 個 clip，而且每個 clip 都來自一個 unique 的 Youtube 影片。&lt;/p&gt;
&lt;p&gt;本文實驗策略是在 Kinetics 上預訓練，再在 HMDB-51 和 USC-101 上微調，結果顯示出預訓練總是能提高性能，但提升多寡因架構而異。&lt;/p&gt;
&lt;p&gt;本文提出新架構，稱為「Two-Stream Inflated 3D ConvNets」(I3D)，建立在 SOTA 的影像分類架構上，並將 filters 和 pooling kernel 膨脹成 3D。&lt;/p&gt;
&lt;p&gt;基於 Inceptionv1 的 I3D 在 Knetics 上預訓練後，性能遠超過當前的 SOTA 架構。&lt;/p&gt;
&lt;p&gt;在本文的模型中，並沒有考慮更多經典方法，比如 bag-of-visual-words representation，但 Kinetics 是公開的，因此其他人可以進行後續研究。&lt;/p&gt;
&lt;h2 id=&#34;action-classification-architectures&#34;&gt;Action Classification Architectures&lt;/h2&gt;
&lt;p&gt;目前影片架構中的一些主要區別如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;卷積是 2D 還 3D 的&lt;/li&gt;
&lt;li&gt;是否只是 RGB 影片，還是包含事先計算的 optical flow&lt;/li&gt;
&lt;li&gt;對於 2D ConvNets，訊息是怎麼在 frame 之間傳遞的
&lt;ul&gt;
&lt;li&gt;這部分可以使用 temporally-recurrent layers，比如 LSTM，或是用隨時間的 feature aggregation 來完成。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在本文中，考慮了涵蓋大部分現有架構的模型子集：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;2D ConvNets
&lt;ul&gt;
&lt;li&gt;頂部有 LSTM 的 ConvNet&lt;/li&gt;
&lt;li&gt;有兩種 stream fusion 的 two-stream networks&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;3D ConvNets
&lt;ul&gt;
&lt;li&gt;C3D&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;由於參數維度較高，以及缺乏 labeled video data，以前的 3D ConvNet 相對較淺（最多 8 層）。&lt;/p&gt;
&lt;p&gt;本文發現諸如 VGG-16 和 ResNet 等很深的影像分類網路可以輕鬆擴展成 spatio-temporal feature extractors，並且他們的預訓練權重也可以提供有價值的初始化。&lt;/p&gt;
&lt;p&gt;本文也發現 two-stream 的作法依然有用。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/i3d/fig2.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;
fig2. K 是影片中的 frame 的總數，N 是相鄰 frames 的子集合。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/i3d/table1.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;上圖是本文實驗的五種架構，前四種是之前的做法，最後一種是提出的新作法。
上圖中除了 C3D 外都有用到 ImageNet 預訓練的模型。&lt;/p&gt;
&lt;p&gt;時間是根據 input 的 frame 換算出來的，fps 是 25，除了 LSTM 那個比較特別，因為 LSTM 那個是每 5 frame 取 1 frame，所以時間是 5 倍。&lt;/p&gt;
&lt;h3 id=&#34;之前的做法&#34;&gt;之前的做法&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;ConvNet+LSTM&lt;/p&gt;
&lt;p&gt;有一種做法是把每個 frame 獨立餵給 2D Conv，然後再把預測做彙整，符合 bag of words image modeling 的精神，但這樣會忽略時間結構上的資訊，比如無法判斷開門或關門。&lt;/p&gt;
&lt;p&gt;所以最好在後面加一個 recurrent layer，所以這邊就用 Inception-V1 結合 LSTM。&lt;/p&gt;
&lt;p&gt;原始的影片 stream 是 25 fps，這邊每 5 frame 採樣一次。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;3D ConvNets&lt;/p&gt;
&lt;p&gt;和一般的卷積神經網路差不多，只是具有 spatio-temporal filters。&lt;/p&gt;
&lt;p&gt;但由於額外的 kernel 維度，相比 2D Conv 會有更多參數，也使他們更難訓練。&lt;/p&gt;
&lt;p&gt;而且這樣會無法發揮 ImageNet 預訓練的好處，因此之前的工作都定義了相對淺層的架構，並且從頭訓練。&lt;/p&gt;
&lt;p&gt;benchmark 中的表現備受期待，但和 SOTA 比沒有競爭力，也因此成為本文實驗的良好候選者。&lt;/p&gt;
&lt;p&gt;本文用的是 C3D 的小變體，差異在於所有卷積層和 FC 層的後面都用了 BN。
而且在第一個 pooling layer 用的 stride 是 2，好減少記憶體的使用，比用更大的 batch，這在 BN 中非常重要。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Two-Stream Networks&lt;/p&gt;
&lt;p&gt;Roy：這裡由於比較複雜，我要改提 two-stream 的原始論文（&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/1406.2199&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Two-Stream Convolutional Networks for Action Recognition in Videos&lt;/a&gt;）說明這東西是什麼&lt;/p&gt;
&lt;p&gt;簡而言之就是分成兩個部分：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;空間資訊：&lt;/p&gt;
&lt;p&gt;用影片的一個 frame　經過卷積神經網路達成，這個 frame 用來提取影像中的物件資訊，比如打排球這動作可能辨識出排球就非常好判定，所以用某個 frame 來提取空間資訊。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;動作資訊：&lt;/p&gt;
&lt;p&gt;這邊用一連串的光流（optical flow）圖來達成，光流是物體（pixel）在兩個 frame 間的位移向量，估計方法有很多，這裡不一一舉例。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/i3d/ex-fig2.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;上圖出自 &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/1406.2199&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Two-Stream Convolutional Networks for Action Recognition in Videos&lt;/a&gt;，圖 c 就是光流，具有兩個方向，指出像素的位移，圖 d 是水平方向的視覺化，圖 e 是垂直方向的視覺化。&lt;/p&gt;
&lt;p&gt;再把這些光流圖餵給卷積神經網路，用作動作資訊的判別。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;值得一提的是他是 late fusion，而且是用加權平均，不是像一般想的把特徵結合再做其他處理。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;the-new-two-stream-inflated-3d-convnets&#34;&gt;The New: Two-Stream Inflated 3D ConvNets&lt;/h3&gt;
&lt;p&gt;作者把成功的 2D 分類模型簡單地轉換為 3D&lt;/p&gt;
&lt;h4 id=&#34;inflating&#34;&gt;Inflating&lt;/h4&gt;
&lt;p&gt;做法是把方形的 filter 改成立方體，把 N x N 的 filter 改成 N x N x N 的 filter，但這只有架構上的參考。&lt;/p&gt;
&lt;h4 id=&#34;bootstraping&#34;&gt;Bootstraping&lt;/h4&gt;
&lt;p&gt;把權重也給轉換到 3D 架構的方法。&lt;/p&gt;
&lt;p&gt;作者觀察到影像可以透過反覆複製貼上來生出一個「不會動的無聊影片」，
透過這些影片，3D 模型可以透過這種方式在 ImageNet 上 implicitly pretrain，做法就是讓 3D filter 吃無聊影片的輸出和 2D filter 吃單一 frame 的輸出相同，做法如下：&lt;/p&gt;
&lt;p&gt;我們可以沿時間維度重複 2D filter N 次，把這權重給 3D filter，同時把權重除以 N，達到這種效果。&lt;/p&gt;
&lt;h4 id=&#34;pacing-receptive-field-growth-in-space-time-and-network-depth&#34;&gt;Pacing receptive field growth in space, time and network depth&lt;/h4&gt;
&lt;p&gt;以往在圖片上對水平和垂直軸的對待是平等的，pooling kernel 和 stride 都一樣。
使感受野在兩個維度上隨著模型越來越深，慢慢平等增長。&lt;/p&gt;
&lt;p&gt;但是時間軸用對稱的感受野不一定最好，而該取決於 frame rate 和 image dimensinos。
如果時間相對於空間增長太快，可能會混淆不同對象的邊緣，影響早期的特徵檢測。如果增長太慢，可能無法很好地捕捉場景動態。&lt;/p&gt;
&lt;p&gt;實驗中，輸入影片的 fps 是 25。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/i3d/fig3.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;作者發現在前兩個 max pooling layer 不在時間軸 pooling（透過用 1 x 3 x 3 的 kernel，並且時間軸的 stride 是 1），並在其他 max pooling layer 都用 symmetric kernels 和 stride 是有幫助的。&lt;/p&gt;
&lt;p&gt;最後的 average pooling layer 是用 2 x 7 x 7 的 kernel。&lt;/p&gt;
&lt;p&gt;作者用 64 frame 訓練，但用整個影片測試。（averaging predictions temporally）&lt;/p&gt;
&lt;p&gt;我想了一下，250 / 64 除不進，但是我看 code 發現他好像寬高 224 * 224 的照片會在最後經過 Average pool 後變成 1 * 1，所以他可以直接用 1 * 1 * 1 的卷積核把輸入通道改成分類數，再把時間軸的結果平均。&lt;/p&gt;
&lt;h4 id=&#34;two-3d-streams&#34;&gt;Two 3D Streams&lt;/h4&gt;
&lt;p&gt;分別訓練兩個網路，並在測試階段對預測進行平均。&lt;/p&gt;
&lt;p&gt;這邊作者說光流的演算法某種意義上是 recurrent（例如，對於 flow fields 進行 iterative optimization），我不太懂這邊是什麼意思，我想作者用的光流演算法應該是透過某種類似 EM 演算法那種不斷迭代去逼近數值的演算法，但作者提到「或許是因為缺乏 recurrence，我們發現雙流有價值」，我不太懂為什麼需要 recurrence 效果才會好。&lt;/p&gt;
&lt;p&gt;但結論是 two-stream 依然具備價值。&lt;/p&gt;
&lt;h4 id=&#34;implementation-details&#34;&gt;Implementation Details&lt;/h4&gt;
&lt;p&gt;這邊講滿詳細的，有興趣可以去原文看。
只提一下幾點:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;光流演算法是用 TV-L1。&lt;/li&gt;
&lt;li&gt;除了類似 C3D 的 3D ConvNet 都用使用 ImageNet 預訓練的 Inception-V1 作為 base network。&lt;/li&gt;
&lt;li&gt;對於較短的影片，會重複循環以滿足模型的輸入介面&lt;/li&gt;
&lt;li&gt;測試時會在中間剪裁 224 x 224&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;the-kinetics-human-action-video-dataset&#34;&gt;The Kinetics Human Action Video Dataset&lt;/h2&gt;
&lt;p&gt;Kinetics 有 400 個人類動作類別。每個類別有 400 個 clip，而且每個 clip 都來自一個 unique 的 Youtube 影片，共有 24 萬個訓練影片。&lt;/p&gt;
&lt;p&gt;每個 clip 都大約 10 秒，而且沒有未剪的影片。&lt;/p&gt;
&lt;p&gt;測試集每個 class 包含 100 個 clip。&lt;/p&gt;
&lt;h2 id=&#34;experimental-comparison-of-architectures&#34;&gt;Experimental Comparison of Architectures&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/i3d/table2and3.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;I3D 在所有資料集上都表現最好，甚至是在 UCF-101 和 HMDB-51 這種小資料集上也是如此，這意味著 ImageNet 預訓練的好處有成功擴展到 3D ConvNet。&lt;/p&gt;
&lt;p&gt;多數模型在 UCF 上都表現得比 Kinetics 上好，顯現出資料集的難度差距。&lt;/p&gt;
&lt;p&gt;但是在 HMDB 表現得較差，原因可能是 HMDB 故意弄得很難，作者有舉例，很多 clip 在完全相同的場景會有不同的動作。&lt;/p&gt;
&lt;p&gt;作者有提到說 I3D 特徵比較好遷移的一種解釋是它具備 high temporal resolution，
I3D 在 25 fps 的影片中用 64 frames 做訓練，使它能捕捉動作的 fine-grained 時間結構。&lt;/p&gt;
&lt;h2 id=&#34;experimental-evaluation-of-features&#34;&gt;Experimental Evaluation of Features&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/i3d/table4and5.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;Kinetics 上做預訓練效果明顯比 ImageNet 好。&lt;/p&gt;
&lt;h2 id=&#34;discussion&#34;&gt;Discussion&lt;/h2&gt;
&lt;p&gt;Kinetics 上的預訓練對於遷移學習有明顯好處，但對於其他影像任務，比如影像語義分割是否有好處仍待觀察。&lt;/p&gt;
&lt;p&gt;目前對於架構沒有全面探索，比如沒有採用 action tubes 或是 attention 機制。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Hololens 2 開發環境設置</title>
        <link>https://roykesydon.github.io/Blog/p/hololens-2-%E9%96%8B%E7%99%BC%E7%92%B0%E5%A2%83%E8%A8%AD%E7%BD%AE/</link>
        <pubDate>Mon, 03 Jul 2023 00:00:01 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/hololens-2-%E9%96%8B%E7%99%BC%E7%92%B0%E5%A2%83%E8%A8%AD%E7%BD%AE/</guid>
        <description>&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;要弄 Hololens 2 的開發環境要一堆有的沒的麻煩東西，紀錄一下避免之後要重裝&lt;/p&gt;
&lt;p&gt;原本很怕版本對不上很麻煩，但實際用起來好像還好&lt;/p&gt;
&lt;p&gt;注意，這不是最小安裝，有些東西我不確定是不是必要的，但我怕麻煩就裝了&lt;/p&gt;
&lt;p&gt;後續請參考微軟的教學&lt;/p&gt;
&lt;h2 id=&#34;計畫版本紀錄-20230703&#34;&gt;計畫版本紀錄 (2023/07/03)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Unity
&lt;ul&gt;
&lt;li&gt;2020.3.48f1 (LTS)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;MRTK
&lt;ul&gt;
&lt;li&gt;2.8.3&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Mixed Reality OpenXR Plugin
&lt;ul&gt;
&lt;li&gt;1.8.0&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;我個人的版本紀錄-20210703&#34;&gt;我個人的版本紀錄 (2021/07/03)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Unity
&lt;ul&gt;
&lt;li&gt;2021.3.27f1 (LTS)
&lt;ul&gt;
&lt;li&gt;我沒注意到我一開始選錯，但也可以跑，之後&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;MRTK
&lt;ul&gt;
&lt;li&gt;2.8.3&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Visual Studio
&lt;ul&gt;
&lt;li&gt;2022&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Mixed Reality OpenXR Plugin
&lt;ul&gt;
&lt;li&gt;1.8.0&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;作業系統要求&#34;&gt;作業系統要求&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;必須是 Windows 專業版以上，因為要用 Hyper-V
&lt;ol&gt;
&lt;li&gt;先去 BIOS 開 Virtualization Technology&lt;/li&gt;
&lt;li&gt;開啟 Hyper-V&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;前置步驟&#34;&gt;前置步驟&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;安裝 windows SDK&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;聽說裝完最新的後，建議再多裝幾個版本
&lt;ul&gt;
&lt;li&gt;我個人只有裝最新的&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;安裝 visual studio&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;好像會根據 MRTK 的版本有對應的版本要求，不能無腦裝最新&lt;/li&gt;
&lt;li&gt;據說要選 「C++ 開發」和「通用 Windows 平台開發」
&lt;ul&gt;
&lt;li&gt;右邊好像還要選
&lt;ul&gt;
&lt;li&gt;USB 設備連接&lt;/li&gt;
&lt;li&gt;C++ 通用 Windows 平台工具&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;安裝 Hololens 2 模擬器&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;這是給 build 好的程式用的，不是在說 Unity Editor 裡面的手&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;安裝 Unity&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;建議透過 Unity Hub 管理 Unity 版本&lt;/li&gt;
&lt;li&gt;據說裝的 Unity 要裝以下兩個 module
&lt;ul&gt;
&lt;li&gt;Universal Windows Platform Build Support&lt;/li&gt;
&lt;li&gt;Windows Build Support (IL2CPP)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Windows 和 Hololens 都要開啟「開發者模式」&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;下載 Mixed Reality Feature Tool&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;注意看這不是 MRTK&lt;/li&gt;
&lt;li&gt;這可以往 Unity 專案導入 MRTK&lt;/li&gt;
&lt;li&gt;可以導入 MRTK 2.6 以後的工具包&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;創建專案&#34;&gt;創建專案&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Unity 開個 3D 專案&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;File -&amp;gt; Build Settings&lt;/li&gt;
&lt;li&gt;選擇 Universal Windows Platform&lt;/li&gt;
&lt;li&gt;點選 Switch Platform&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;開啟 Mixed Reality Feature Tool&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;針對專案安裝 MRTK
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;必裝&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MRTK Foundation&lt;/li&gt;
&lt;li&gt;Mixed Reality OpenXR Plugin&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;可選&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MRTK
&lt;ul&gt;
&lt;li&gt;Examples&lt;/li&gt;
&lt;li&gt;Extensions&lt;/li&gt;
&lt;li&gt;Tools&lt;/li&gt;
&lt;li&gt;TestUtilities&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;在模擬器上執行&#34;&gt;在模擬器上執行&lt;/h2&gt;
&lt;p&gt;這坑真的有夠多，我結合上 stack overflow 的解法，所用的步驟:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;要用管理員模式開 Visual Studio，不然有可能遇到權限問題&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Visual studio 要部屬程式的時候，會自己開一個 Hololens 2 Simulator，但他會開超久，然後造成 Timeout，無法部屬，部屬失敗後不要選繼續，也不要關掉模擬器&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;這時候再看情況按 實心 / 空心綠色三角形 (without debugging)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;有可能可以 deploy，但運行時有問題，此時按紅色方塊終止，繼續綠色三角形，不要關掉模擬器&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>Redis</title>
        <link>https://roykesydon.github.io/Blog/p/redis/</link>
        <pubDate>Mon, 05 Jun 2023 00:00:17 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/redis/</guid>
        <description>&lt;h2 id=&#34;use-cases&#34;&gt;Use Cases&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Cache
&lt;ul&gt;
&lt;li&gt;把常用的資料回傳，省略長時間的 IO 操作&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Shared Session
&lt;ul&gt;
&lt;li&gt;在 stateless server 間共享 session&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Distributed lock
&lt;ul&gt;
&lt;li&gt;用在程式間想共用某種資源的時候&lt;/li&gt;
&lt;li&gt;用 &lt;code&gt;setnx&lt;/code&gt; (set if not exists)
&lt;ul&gt;
&lt;li&gt;atomic&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Rate Limiter
&lt;ul&gt;
&lt;li&gt;用 increment 和 expiration 實現&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;feature&#34;&gt;Feature&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;NoSQL&lt;/li&gt;
&lt;li&gt;In-memory&lt;/li&gt;
&lt;li&gt;Key-Value&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;basic-command&#34;&gt;Basic Command&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;redis-server&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;default port: 6379&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;redis-cli&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;access-data&#34;&gt;Access data&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;set &amp;lt;key&amp;gt; &amp;lt;value&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Pretty much everything stored in Redis is going to be a type of string by default&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;get &amp;lt;key&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;del &amp;lt;key&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;exists &amp;lt;key&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;keys &amp;lt;pattern&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;find keys with certain pattern&lt;/li&gt;
&lt;li&gt;&lt;code&gt;keys *&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;get all keys&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;flushall&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;get rid of everything&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;expiration&#34;&gt;Expiration&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;ttl &amp;lt;key&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;show time to live
&lt;ul&gt;
&lt;li&gt;&amp;ldquo;-1&amp;rdquo; for no expiration&lt;/li&gt;
&lt;li&gt;&amp;ldquo;-2&amp;rdquo; already expired&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;expire &amp;lt;key&amp;gt; &amp;lt;second&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;setex &amp;lt;key&amp;gt; &amp;lt;seconds&amp;gt; &amp;lt;value&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;set with expiration&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;data-structure&#34;&gt;Data Structure&lt;/h3&gt;
&lt;h4 id=&#34;list&#34;&gt;List&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;lpush/rpush &amp;lt;key&amp;gt; &amp;lt;value&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;lrange &amp;lt;key&amp;gt; &amp;lt;start index&amp;gt; &amp;lt;end index&amp;gt;&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;end index&amp;gt;&lt;/code&gt; can be -1&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;lpop/rpop &amp;lt;key&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;set&#34;&gt;Set&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;sadd &amp;lt;key&amp;gt; &amp;lt;value&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;smembers &amp;lt;key&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;srem &amp;lt;key&amp;gt; &amp;lt;value&amp;gt;&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;remove&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;hash&#34;&gt;Hash&lt;/h4&gt;
&lt;p&gt;Key-value in Key-value&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;hset &amp;lt;key&amp;gt; &amp;lt;field&amp;gt; &amp;lt;value&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;hget &amp;lt;key&amp;gt; &amp;lt;field&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;hgetall &amp;lt;key&amp;gt;&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;get everything about &lt;code&gt;&amp;lt;key&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;hdel&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;hexists &amp;lt;key&amp;gt; &amp;lt;field&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Redis doesn&amp;rsquo;t support nested hash struct&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;刪除過期-key&#34;&gt;刪除過期 key&lt;/h2&gt;
&lt;h3 id=&#34;定期刪除&#34;&gt;定期刪除&lt;/h3&gt;
&lt;p&gt;在固定間隔時間隨機抽 key 檢查並刪除&lt;/p&gt;
&lt;h3 id=&#34;惰性刪除&#34;&gt;惰性刪除&lt;/h3&gt;
&lt;p&gt;在訪問 key 的時候發現過期就刪除&lt;/p&gt;
&lt;h2 id=&#34;maxmemory-policy-eviction&#34;&gt;maxmemory-policy (Eviction)&lt;/h2&gt;
&lt;p&gt;可以設定這些 policy，在記憶體依然額滿的情況下做對應的處理&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;noeviction&lt;/li&gt;
&lt;li&gt;allkeys-lru&lt;/li&gt;
&lt;li&gt;allkeys-lfu&lt;/li&gt;
&lt;li&gt;volatile-lru&lt;/li&gt;
&lt;li&gt;volatile-lfu&lt;/li&gt;
&lt;li&gt;allkeys-random&lt;/li&gt;
&lt;li&gt;volatile-random&lt;/li&gt;
&lt;li&gt;volatile-ttl&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;快取情境問題&#34;&gt;快取情境問題&lt;/h2&gt;
&lt;h3 id=&#34;快取雪崩-cache-avalanche&#34;&gt;快取雪崩 Cache Avalanche&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;某個時刻大量 cache 失效，使資料庫需要承擔很大的流量。&lt;/li&gt;
&lt;li&gt;解法
&lt;ul&gt;
&lt;li&gt;幫 cache 加上額外的隨機過期時間&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;快取擊穿-hotspot-invalid&#34;&gt;快取擊穿 Hotspot Invalid&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;某個 hotspot 的 cache 失效，使大量請求跑到資料庫&lt;/li&gt;
&lt;li&gt;解法
&lt;ul&gt;
&lt;li&gt;讓 hotspot 永不過期&lt;/li&gt;
&lt;li&gt;查詢資料庫的部分加上 lock&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;快取穿透-cache-penetration&#34;&gt;快取穿透 Cache Penetration&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;client request 不存在的資料，因為同時不存在於 cache 和資料庫中，所以直接跑到資料庫&lt;/li&gt;
&lt;li&gt;解法
&lt;ul&gt;
&lt;li&gt;在 application 先過濾掉非法請求&lt;/li&gt;
&lt;li&gt;Bloom Filter 布隆過濾器&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;persistence&#34;&gt;Persistence&lt;/h2&gt;
&lt;h3 id=&#34;rdb&#34;&gt;RDB&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;固定時間對所有資料做快照，memory dump 出來&lt;/li&gt;
&lt;li&gt;recovery 比 AOF 快&lt;/li&gt;
&lt;li&gt;&lt;code&gt;save&lt;/code&gt;、&lt;code&gt;bgsave&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;aof&#34;&gt;AOF&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;紀錄操作流程&lt;/li&gt;
&lt;li&gt;檔案比較肥&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;rewrite&#34;&gt;Rewrite&lt;/h4&gt;
&lt;p&gt;當 AOF 太大，Redis 會生一個新文件取代舊的，用最少操作生出目前的資料&lt;/p&gt;
&lt;h3 id=&#34;混合&#34;&gt;混合&lt;/h3&gt;
&lt;p&gt;在 AOF 重寫的時候也利用 RDB
前面是 RDB，後面是 AOF&lt;/p&gt;
&lt;h2 id=&#34;availability&#34;&gt;Availability&lt;/h2&gt;
&lt;h3 id=&#34;主從同步&#34;&gt;主從同步&lt;/h3&gt;
&lt;p&gt;一主多從，把讀取壓力分擔到 slave 上&lt;/p&gt;
&lt;h3 id=&#34;哨兵模式-sentinel&#34;&gt;哨兵模式 Sentinel&lt;/h3&gt;
&lt;p&gt;會有哨兵不斷地 Ping 主從伺服器，確認是否有異常&lt;/p&gt;
&lt;p&gt;如果哨兵是集群，有哨兵檢測到異常，會判斷某伺服器主觀下線，當有一定數量的哨兵投票認為伺服器不可能用，就會變成客觀下線，進行 failover&lt;/p&gt;
&lt;h3 id=&#34;cluster&#34;&gt;Cluster&lt;/h3&gt;
&lt;p&gt;分擔寫入壓力&lt;/p&gt;
&lt;p&gt;Redis 有 16384 個 slot，透過 hash 分配 key 到不同的 slot&lt;/p&gt;
&lt;p&gt;預設會另外用 port 16379 來讓節點間溝通&lt;/p&gt;
&lt;p&gt;可以混和主從同步達到高可用&lt;/p&gt;
</description>
        </item>
        <item>
        <title>領域驅動設計 Domain-Driven Design</title>
        <link>https://roykesydon.github.io/Blog/p/%E9%A0%98%E5%9F%9F%E9%A9%85%E5%8B%95%E8%A8%AD%E8%A8%88-domain-driven-design/</link>
        <pubDate>Mon, 22 May 2023 00:00:17 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/%E9%A0%98%E5%9F%9F%E9%A9%85%E5%8B%95%E8%A8%AD%E8%A8%88-domain-driven-design/</guid>
        <description>&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;軟體要對 domain 做 Modeling，呈現出 domain 裡的核心概念，才能滿足使用者需求，因此不乏與領域專家的討論&lt;/p&gt;
&lt;p&gt;寫這篇的時候我還沒嗑完 Eric 的聖經，可能嗑完了之後會回來修改&lt;/p&gt;
&lt;h2 id=&#34;通用語言-ubiquitous-language&#34;&gt;通用語言 Ubiquitous Language&lt;/h2&gt;
&lt;p&gt;鑒於程式開發人員與領域專家熟悉知識的差異，會產生交流困難&lt;/p&gt;
&lt;p&gt;因此領域專家和開發團隊要訂定共同的語言，並且盡可能少用自己知道的術語&lt;/p&gt;
&lt;h2 id=&#34;uml&#34;&gt;UML&lt;/h2&gt;
&lt;p&gt;UML 適合用在小型模型上，它擅長表達類別間的關係，但對於抽象概念卻沒那麼好傳達&lt;/p&gt;
&lt;p&gt;因此用 UML 建構模型時，理想上要添加額外的文字，傳達一些圖所不能表達的 behavior 和 constraint&lt;/p&gt;
&lt;p&gt;並且不能一次寫過於複雜，而是分塊處理&lt;/p&gt;
&lt;h2 id=&#34;layered-architecture&#34;&gt;Layered Architecture&lt;/h2&gt;
&lt;p&gt;分為四個概念層，只會往下調用，可能會跨層&lt;/p&gt;
&lt;p&gt;可以達到關注點分離 (separation of concerns)，提高各個方面的 cohesive&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;User Interface (Presentation Layer)
&lt;ul&gt;
&lt;li&gt;呈現給 user 的 UI，User 可能是另一個系統&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Application Layer
&lt;ul&gt;
&lt;li&gt;不含 bussiness logic，指揮表達領域概念的物件來完成任務&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Domain Layer
&lt;ul&gt;
&lt;li&gt;有關 domain 的資訊都在這裡，業務邏輯在此處理&lt;/li&gt;
&lt;li&gt;表達業務概念、狀態、規則&lt;/li&gt;
&lt;li&gt;劃分出這層是 Model-Driven Design 的關鍵&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Infrastructure layer
&lt;ul&gt;
&lt;li&gt;supporting library&lt;/li&gt;
&lt;li&gt;保存業務狀態的技術細節在此實作&lt;/li&gt;
&lt;li&gt;為前三個 layer 服務&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;entity&#34;&gt;Entity&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;具備 identity&lt;/li&gt;
&lt;li&gt;identity 在 status 經過改變後依然不變&lt;/li&gt;
&lt;li&gt;追蹤 entity 需要高成本&lt;/li&gt;
&lt;li&gt;mutable&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;value-object&#34;&gt;Value Object&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;沒有 identity&lt;/li&gt;
&lt;li&gt;只關心 obejct 的 value&lt;/li&gt;
&lt;li&gt;可以輕易創建丟棄&lt;/li&gt;
&lt;li&gt;immutable (不變的)
&lt;ul&gt;
&lt;li&gt;如果想修改數值就創新的&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;可被共用&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;service&#34;&gt;Service&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;有些動作不屬於某個 Entity 或 Value Object，因為它是跨物件的&lt;/li&gt;
&lt;li&gt;Stateless
&lt;ul&gt;
&lt;li&gt;每個請求不互相影響&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;aggregate&#34;&gt;Aggregate&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;把複雜關聯的物件圈在一起考量&lt;/li&gt;
&lt;li&gt;確保 consistency 和 inveraints
&lt;ul&gt;
&lt;li&gt;consistency (一致性)
&lt;ul&gt;
&lt;li&gt;相關物件的資料一致&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;invariants (不變量)
&lt;ul&gt;
&lt;li&gt;資料改變時要維護的規則&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;aggregate-root&#34;&gt;Aggregate root&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;具備 global identity，其他內部 entity 只有 local identity&lt;/li&gt;
&lt;li&gt;通常是 entity 擔任&lt;/li&gt;
&lt;li&gt;外部只能存取它，不能存取 aggregate 的其他 entity 或 value obejct&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;factory&#34;&gt;Factory&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;若創建 aggregate、entity、value object 的過程很複雜，或是涉及專業知識，就該用 factory 包起來&lt;/li&gt;
&lt;li&gt;對於不複雜的情況，或是想控制更多細節，可以只依賴於簡單的建構函式&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;repository&#34;&gt;Repository&lt;/h2&gt;
&lt;p&gt;如果大家都直接存取資料庫的各種物件，會破壞原本精心設計的結構，破壞封裝性&lt;/p&gt;
&lt;p&gt;Repositoy 用來存取物件，封裝了資料庫操作&lt;/p&gt;
&lt;h2 id=&#34;domain-event&#34;&gt;Domain event&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Domain 中重要的事情&lt;/li&gt;
&lt;li&gt;可以用在其他物件和 aggrgate 訂閱，讓 aggregate 通知他們 domain event 的發生&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;anti-pattern&#34;&gt;Anti-Pattern&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;應該避免的情形&lt;/li&gt;
&lt;li&gt;Smart UI
&lt;ul&gt;
&lt;li&gt;超肥的萬能 UI&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Anemic Domain Model
&lt;ul&gt;
&lt;li&gt;貧血模型&lt;/li&gt;
&lt;li&gt;只有 getter 和 setter，沒有業務邏輯的模型&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;subdomain&#34;&gt;Subdomain&lt;/h2&gt;
&lt;p&gt;把 domain 切分成小塊，理想上 subdomain 和 bounded context 有 one-to-one 的關係&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Types
&lt;ul&gt;
&lt;li&gt;core subdomain
&lt;ul&gt;
&lt;li&gt;和其他競爭者相比不同的部分，最核心的業務，比如搜尋引擎中的搜尋演算法&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;generic subdomain
&lt;ul&gt;
&lt;li&gt;大家都會弄的部分，比如登入系統&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;supporting subdomain
&lt;ul&gt;
&lt;li&gt;用來輔助 core subdomain 的部分，比如篩選網頁&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;bounded-context&#34;&gt;Bounded Context&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;劃出 boundary，確保 boundary 內用的概念、規則皆一致&lt;/li&gt;
&lt;li&gt;同個名詞可能出現在不同的 context，但有不同意思&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;context-map&#34;&gt;Context Map&lt;/h2&gt;
&lt;p&gt;描述 BC 和 BC 間的關係&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;上下游 (U/D)
&lt;ul&gt;
&lt;li&gt;上游提供下游 (下游依賴上游)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Shared Kernel
&lt;ul&gt;
&lt;li&gt;兩個 BC 共用的部份&lt;/li&gt;
&lt;li&gt;違反 BC 的基本原則，是一種例外設計&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Customer-Supplier
&lt;ul&gt;
&lt;li&gt;一個子系統重度依賴另一個子系統&lt;/li&gt;
&lt;li&gt;Conformist
&lt;ul&gt;
&lt;li&gt;Customer 完全配合 Supplier&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Partnership
&lt;ul&gt;
&lt;li&gt;兩個 BC 互相合作，沒有以誰為主&lt;/li&gt;
&lt;li&gt;一起成功或一起失敗&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Anticorruption Layer (ACL)
&lt;ul&gt;
&lt;li&gt;開發系統和外部系統的中間層&lt;/li&gt;
&lt;li&gt;可能出現在調用 legacy system&lt;/li&gt;
&lt;li&gt;常用到 Facade 和 Adapter&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Open Host Service (OHS)
&lt;ul&gt;
&lt;li&gt;如果外部子系統要給一堆用戶端子系統調用，就得在所有用戶端子系統搞 ACL&lt;/li&gt;
&lt;li&gt;外部系統做為服務提供，常會搭配 Published Language (PL)
&lt;ul&gt;
&lt;li&gt;PL 是協定傳送資料的格式，比如 XML、JSON 或是 Protocol Buffer&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;pratical-ddd&#34;&gt;Pratical DDD&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The strangler migration
&lt;ul&gt;
&lt;li&gt;透過 Facade，把一些服務慢慢移植給新系統，最後取代 legacy&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>電路學 - III</title>
        <link>https://roykesydon.github.io/Blog/p/%E9%9B%BB%E8%B7%AF%E5%AD%B8-iii/</link>
        <pubDate>Mon, 08 May 2023 00:00:54 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/%E9%9B%BB%E8%B7%AF%E5%AD%B8-iii/</guid>
        <description>&lt;h2 id=&#34;運算放大器-operational-amplifiers&#34;&gt;運算放大器 (Operational Amplifiers)&lt;/h2&gt;
&lt;h3 id=&#34;介紹&#34;&gt;介紹&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;運算放大器 (Operational Amplifiers)
&lt;ul&gt;
&lt;li&gt;特性
&lt;ul&gt;
&lt;li&gt;類似於電壓控制電壓相依電源的電子元件&lt;/li&gt;
&lt;li&gt;主動電路元件&lt;/li&gt;
&lt;li&gt;用於執行加、減、乘、除、微分與積分等運數學運算的主動電路元件&lt;/li&gt;
&lt;li&gt;由電阻、電晶體、電容和二極體等所構成的電子元件，但因內部電路的討論已超出範圍，先看作是電路模組&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;封裝形式
&lt;ul&gt;
&lt;li&gt;DIP&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;輸出電壓 $v_O$
&lt;ul&gt;
&lt;li&gt;$v_O=Av_d=A(v_2-v_1)$
&lt;ul&gt;
&lt;li&gt;$v_2$ 是非反相輸入 (noninverting input)&lt;/li&gt;
&lt;li&gt;$v_1$ 是反相輸入  (inverting input)&lt;/li&gt;
&lt;li&gt;$A$ 是開迴路電壓增益 (open-loop voltage gain)
&lt;ul&gt;
&lt;li&gt;是沒有任何從輸出到輸入的回授 (feedback) 時，運算放大器的增益&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;回授
&lt;ul&gt;
&lt;li&gt;負回授 (negative feedback)
&lt;ul&gt;
&lt;li&gt;輸出回授至反相輸入端&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;閉迴路增益 (closed-loop gain)
&lt;ul&gt;
&lt;li&gt;如果存在由輸出到輸入的回授，輸出電壓與輸入電壓的比例稱為閉迴路增益&lt;/li&gt;
&lt;li&gt;對負回授電路而言，可以證明閉迴路增益和開迴路增益無關，因此運算放大器總是用於具回授的電路中&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;工作模式
&lt;ul&gt;
&lt;li&gt;正飽和區
&lt;ul&gt;
&lt;li&gt;$v_O=V_{CC}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;線性區
&lt;ul&gt;
&lt;li&gt;$-V_{CC} \leq v_O = Av_d \leq V_{CC}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;負飽和區
&lt;ul&gt;
&lt;li&gt;$v_O=-V_{CC}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;符號
&lt;ul&gt;
&lt;li&gt;$v_O$ 是輸出電壓&lt;/li&gt;
&lt;li&gt;$v_d$ 是輸入電壓差&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;理想運算放大器-ideal-op-amp&#34;&gt;理想運算放大器 (Ideal Op Amp)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;假定運算放大器是理想的是符合實際的，因位目前絕大多數運算放大器都有很大的增益和輸入電阻&lt;/li&gt;
&lt;li&gt;具有以下特性的運算放大器，稱為理想運算放大器
&lt;ul&gt;
&lt;li&gt;$A \simeq \inf$
&lt;ul&gt;
&lt;li&gt;開迴路增益無窮大&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;$R_i \simeq \inf$
&lt;ul&gt;
&lt;li&gt;輸入電阻無窮大&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;$R_O \simeq 0$
&lt;ul&gt;
&lt;li&gt;輸出電阻為零&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;特性
&lt;ul&gt;
&lt;li&gt;流入兩個輸入端的電流均為 0，因為輸入電阻無窮大，輸入端間開路&lt;/li&gt;
&lt;li&gt;輸入端間的電壓差等於零，$v_d=v_2-v_1=0$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;反相放大器-inverting-amplifier&#34;&gt;反相放大器 (Inverting Amplifier)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;對輸入信號放大的同時反轉極性&lt;/li&gt;
&lt;li&gt;公式
&lt;ul&gt;
&lt;li&gt;$v_0=-\frac{R_f}{R_1}v_i$
&lt;ul&gt;
&lt;li&gt;$R_f$ 是回授電阻&lt;/li&gt;
&lt;li&gt;$R_1$ 是進到負回授節點前的電阻&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;非反相放大器-noninverting-amplifier&#34;&gt;非反相放大器 (Noninverting Amplifier)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;提供正電壓增益的運算放大器電路&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;公式&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$v_0=(1+\frac{R_f}{R_1})v_i$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;電壓隨耦器 (voltage follewer)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;又稱單位增益放大器 (unity gain amplifier)&lt;/li&gt;
&lt;li&gt;條件
&lt;ul&gt;
&lt;li&gt;$R_f=0 或 R_1=\inf 或 (R_f=0 且 R_1=\inf)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;公式
&lt;ul&gt;
&lt;li&gt;$v_0=v_i$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;加法放大器-summing-amplifier&#34;&gt;加法放大器 (Summing Amplifier)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;將多個輸入結合，在輸出產生輸入的加權總合&lt;/li&gt;
&lt;li&gt;公式
&lt;ul&gt;
&lt;li&gt;$v_O=-(\frac{R_f}{R_1}v_1+\frac{R_f}{R_2}v_2+\frac{R_f}{R_3}v_3)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;差動放大器-difference-amplifier&#34;&gt;差動放大器 (Difference Amplifier)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;放大兩個輸入信號的差而抑制兩個輸入的共模信號 (Common-mode signal)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;公式&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$v_O=\frac{R_2(1+R_1/R_2)}{R1(1+R_3/R_4)}v_2-\frac{R_2}{R_1}v_1$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果 $R_2=R_1$ 且 $R_3=R_4$，動差放大器為減法器 (subtractor)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$v_O=v_2-v_1$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;串級運算放大器電路-cascaded-op-amp-circuits&#34;&gt;串級運算放大器電路 (Cascaded Op Amp Circuits)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;串級
&lt;ul&gt;
&lt;li&gt;兩個以上的運算放大器首尾相接，前一級的輸出是下一級的輸入&lt;/li&gt;
&lt;li&gt;多個運算放大器串級時，每個電路都稱為一級 (stage)&lt;/li&gt;
&lt;li&gt;運算放大器的優點
&lt;ul&gt;
&lt;li&gt;串級不會改變各自輸入-輸出
&lt;ul&gt;
&lt;li&gt;因為理想的運算放大器輸入電阻無窮大，輸出電阻為 0&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;總增益為個別增益的乘積
&lt;ul&gt;
&lt;li&gt;$A=A_1A_2A_3$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;數位-類比轉換器-digital-to-analog-converter-dac&#34;&gt;數位-類比轉換器 (Digital-to-Analog Converter, DAC)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;DAC 把數位信號轉成類比信號&lt;/li&gt;
&lt;li&gt;實現方法
&lt;ul&gt;
&lt;li&gt;二進位加權階梯電路 (binary weighted ladder)
&lt;ul&gt;
&lt;li&gt;把權重設計成二進位的加法放大器&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;輸入
&lt;ul&gt;
&lt;li&gt;最高位元 (most significant bit, MSB)&lt;/li&gt;
&lt;li&gt;最低位元 (least significant bit, LSB)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;儀表放大器-instrumentation-amplifiers&#34;&gt;儀表放大器 (Instrumentation Amplifiers)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;差動放大器的延伸&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;電容器與電感器&#34;&gt;電容器與電感器&lt;/h2&gt;
&lt;h3 id=&#34;介紹-1&#34;&gt;介紹&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;電容器與電感器是能儲存能量的儲能元件 (storage element)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;電容器-capacitors&#34;&gt;電容器 (Capacitors)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;將能量儲存在電場中的被動元件&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;由兩片導電板夾著絕緣體 (電介質) 組成&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;公式&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$q=Cv$
&lt;ul&gt;
&lt;li&gt;q 是儲存的電荷量&lt;/li&gt;
&lt;li&gt;C 是比例常數，又稱電容 (capacitance)
&lt;ul&gt;
&lt;li&gt;單位是法拉 (farad, F)&lt;/li&gt;
&lt;li&gt;C 不是由 q 和 v 決定
&lt;ul&gt;
&lt;li&gt;$C=\frac{\epsilon A}{d}$
&lt;ul&gt;
&lt;li&gt;$\epsilon$ 是介電常數&lt;/li&gt;
&lt;li&gt;$A$ 是導電極版的截面積&lt;/li&gt;
&lt;li&gt;$d$ 是兩極板的間距&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;$v(t)=\frac{1}{C}\int_{t_0}^t i (\tau)d\tau + v(t_0)$&lt;/li&gt;
&lt;li&gt;$w=\frac{1}{2}Cv^2$
&lt;ul&gt;
&lt;li&gt;電場儲存的能量&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;線性電容 (linear capacitor)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;滿足 $i=C\frac{dv}{dt}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;非線性電容 (nonlinear capacitor)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;電流電壓關係曲線非直線，不過多數電容是線性的&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;重要性質&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;電容器在直流下工作，等同開路
&lt;ul&gt;
&lt;li&gt;電壓不隨時間改變的話電流是 0&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;電容器上的電壓必須是連續的
&lt;ul&gt;
&lt;li&gt;因為不連續變化的電壓需要無限大的電流&lt;/li&gt;
&lt;li&gt;電容會反抗電壓的突然改變&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;理想電容器不消耗能量&lt;/li&gt;
&lt;li&gt;實際的非理想電容器會並聯一個漏電阻，可高達 $100M \Omega$，在多數情況可忽略不計&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;電容器串並聯&#34;&gt;電容器串並聯&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;並聯
&lt;ul&gt;
&lt;li&gt;$C_{eq} = C_1 + C_2 + C_3 + &amp;hellip; + C_N$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;串聯
&lt;ul&gt;
&lt;li&gt;$\frac{1}{C_{eq}} = \frac{1}{C_{1}} + \frac{1}{C_{2}} + \frac{1}{C_{3}} + &amp;hellip; + \frac{1}{C_{N}}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;電感器-inductors&#34;&gt;電感器 (Inductors)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;將能量儲存於磁場中的被動元件&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;公式&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$v=L\frac{di}{dt}$
&lt;ul&gt;
&lt;li&gt;L 是比例常數，又稱為電感 (inductance)
&lt;ul&gt;
&lt;li&gt;單位是亨利 (henry, H)&lt;/li&gt;
&lt;li&gt;由物理尺寸和結構決定&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;$i=\frac{1}{L}\int_{t_0}^t v (\tau)d\tau + i(t_0)$&lt;/li&gt;
&lt;li&gt;$w=\frac{1}{2}Li^2$
&lt;ul&gt;
&lt;li&gt;儲存的能量&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;電感反應電感器反抗電流變化的特性&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;線性電感 (linear inductor)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;滿足 $v=L\frac{di}{dt}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;非線性電感 (nonlinear inductor)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$v$ 和 $di/dt$ 關係曲線非直線&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;重要性質&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在直流中，電感器等同短路&lt;/li&gt;
&lt;li&gt;電感器上的電流必須是連續的
&lt;ul&gt;
&lt;li&gt;因為不連續變化的電流需要無限大的電壓&lt;/li&gt;
&lt;li&gt;電容會反抗電流的突然改變&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;理想電感器不消耗能量&lt;/li&gt;
&lt;li&gt;實際的非理想電容器會串聯一個繞線電阻 (winding resistance)，由製成電感的導電材料產生，通常很小。並由於線圈間的電容性耦合，也存在繞線電容 (winding capacitance)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;電感器串並聯&#34;&gt;電感器串並聯&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;串聯
&lt;ul&gt;
&lt;li&gt;$L_{eq} = L_1 + L_2 + L_3 + &amp;hellip; + L_N$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;並聯
&lt;ul&gt;
&lt;li&gt;$\frac{1}{L_{eq}} = \frac{1}{L_{1}} + \frac{1}{L_{2}} + \frac{1}{L_{3}} + &amp;hellip; + \frac{1}{L_{N}}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;應用&#34;&gt;應用&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;電感電容的特殊性質
&lt;ul&gt;
&lt;li&gt;能儲存能量，作為暫時的電壓源或電流源，可在短時間內產生大電流或電壓&lt;/li&gt;
&lt;li&gt;電容器反抗電壓的突然改變、電感器反抗電流的突然改變&lt;/li&gt;
&lt;li&gt;電容器和電感器對頻率很靈敏，可以區別不同頻率，這條用在交流電路中&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;積分器-integrator&#34;&gt;積分器 (Integrator)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;採用儲能元件的運算放大器組成的積分器，輸出訊號和輸入訊號的積分成正比
&lt;ul&gt;
&lt;li&gt;$v_0=-\frac{1}{RC}\int_0^tv_i(\tau)d\tau$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;微分器-differentiator&#34;&gt;微分器 (Differentiator)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;採用儲能元件的運算放大器組成的微分器，輸出訊號和輸入訊號的變率成正比
&lt;ul&gt;
&lt;li&gt;$v_0=-RC\frac{dv_i}{dt}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;類比計算機-analog-computer&#34;&gt;類比計算機 (Analog Computer)&lt;/h4&gt;
&lt;p&gt;由各種運算放大器綜合使用，可算出任意微分方程式&lt;/p&gt;
</description>
        </item>
        <item>
        <title>STM32 Timer / Counter 介紹</title>
        <link>https://roykesydon.github.io/Blog/p/stm32-timer-/-counter-%E4%BB%8B%E7%B4%B9/</link>
        <pubDate>Thu, 04 May 2023 01:32:54 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/stm32-timer-/-counter-%E4%BB%8B%E7%B4%B9/</guid>
        <description>&lt;h2 id=&#34;簡介&#34;&gt;簡介&lt;/h2&gt;
&lt;p&gt;Timer 和 Counter 的差別是 Timer 是定期的數數&lt;/p&gt;
&lt;h2 id=&#34;timing-functions&#34;&gt;Timing functions&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;定期對 CPU 發送 interrupt&lt;/li&gt;
&lt;li&gt;產生準確時間的 delay&lt;/li&gt;
&lt;li&gt;產生 pulses 或 periodic waveforms
&lt;ul&gt;
&lt;li&gt;PWM&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;量測 duration&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;stm32-timer--counter&#34;&gt;STM32 Timer / Counter&lt;/h2&gt;
&lt;p&gt;從 Basic 到 Advanced，追加更多功能&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Basic TImer (Simple Timer)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;16 bit auto-reload register&lt;/li&gt;
&lt;li&gt;programmable pre-scaler&lt;/li&gt;
&lt;li&gt;可以 output 到 DAC&lt;/li&gt;
&lt;li&gt;update event
&lt;ul&gt;
&lt;li&gt;CNT=ARR(up-count)&lt;/li&gt;
&lt;li&gt;CNT=0 (down-count)&lt;/li&gt;
&lt;li&gt;reset CNT to 0 or ARR&lt;/li&gt;
&lt;li&gt;set UIF flag in status register&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;update event interrupt
&lt;ul&gt;
&lt;li&gt;如果 enabled (UIE=1)&lt;/li&gt;
&lt;li&gt;UIF 被設置的時候發送訊號&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/embedding/stm32-timer/rm-fig-367.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;
&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/embedding/stm32-timer/rm-fig-370.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$T_{EVENT}=Prescale \times Count \times T_{CK \_ INT} \\
=(PSC+1)\times(ARR+1)\times T_{CK \_ INT}$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$T_{EVENT}$ 是兩次事件發生的間隔時間&lt;/li&gt;
&lt;li&gt;PSC 是設定 (數值 - 1)，所以 Prescale 是 1 的話，要設 0&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Control register&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CEN
&lt;ul&gt;
&lt;li&gt;是否啟用 counter&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;UDIS
&lt;ul&gt;
&lt;li&gt;是否啟用 update event&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;URS
&lt;ul&gt;
&lt;li&gt;設定產生 update event 的 source&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;OPM
&lt;ul&gt;
&lt;li&gt;是否只算一次 counter 就停&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;ARPE
&lt;ul&gt;
&lt;li&gt;關於中途改 ARR 的 reload 設定&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;UIF
&lt;ul&gt;
&lt;li&gt;interrupt&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;General Purpose Timer&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/embedding/stm32-timer/rm-fig-284.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;16-bit or 32-bit auto-reload register&lt;/li&gt;
&lt;li&gt;use for a variety of puposes
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;measuring lengths of input signals (Input Capture)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Input Capture
&lt;ul&gt;
&lt;li&gt;測量 pulse width (高電位的時間) 或 period (一個週長)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;generating output waveforms (Output Compare and PWM Generation)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;one pulse mode output&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Up to 4 independent channel&lt;/li&gt;
&lt;li&gt;Interrupt / DMA generation
&lt;ul&gt;
&lt;li&gt;event
&lt;ul&gt;
&lt;li&gt;counter overflow / underflow&lt;/li&gt;
&lt;li&gt;counter initialization&lt;/li&gt;
&lt;li&gt;trigger event&lt;/li&gt;
&lt;li&gt;input capture&lt;/li&gt;
&lt;li&gt;output compare&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Advanced Control Timer&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;16-bit auto-reload register&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;特殊 timer&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;low power timer
&lt;ul&gt;
&lt;li&gt;可以用在比如睡眠狀態&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;補充&#34;&gt;補充&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;24 bits system timer (SysTick)&lt;/li&gt;
&lt;li&gt;reload
&lt;ul&gt;
&lt;li&gt;在 overflow 時回到 register 設定的數值&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;stm32-timer-差異&#34;&gt;STM32 Timer 差異&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;可以去 Datasheet 找每個 Timer 的功能&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Counter resolution&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;16/32 bit&lt;/li&gt;
&lt;li&gt;決定能從 0 數到多少個&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Counter Type&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;決定能往上數或往下數或都可以&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Prescaler factor&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;可以把進來的數字先除以某個數，減緩速度&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;DMA request generation&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;能否用 DMA access 記憶體&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Capture / Compare channels&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一個 Timer 可能可以發多個訊號出去，並且經過多個 Compare register，比對不同 event&lt;/li&gt;
&lt;li&gt;functions
&lt;ul&gt;
&lt;li&gt;Compare
&lt;ul&gt;
&lt;li&gt;和比對 register，比到了就送 event&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Capture
&lt;ul&gt;
&lt;li&gt;紀錄下 channel 的值&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Complementary output&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;有些馬達控制需要反向波，就要這個&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Max interface clock (MHz) and Max timer clock (MHz)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;進去和出來的速度&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;system-clock---clock-tree&#34;&gt;System Clock - Clock tree&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Timer 源頭就是 clock&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;有四種來源幫忙驅動 system clock (SYSCLK)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;HSI16 (high speed internal)
&lt;ul&gt;
&lt;li&gt;16 MHz RC oscillator clock&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;MSI (multispeed internal)
&lt;ul&gt;
&lt;li&gt;RC oscillator clock&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;HSE (high speed external)
&lt;ul&gt;
&lt;li&gt;oscillator clock, from 4 to 48 MHz&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;PLL clock&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SYSCLK 往下接到 AHB，再接到 APB1、APB2&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;flash-read-access-latency&#34;&gt;Flash Read Access Latency&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;調整 clock 也要調整這部分&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;register&#34;&gt;Register&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;TIMx_CR1
&lt;ul&gt;
&lt;li&gt;control register&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;TIMx_PSC
&lt;ul&gt;
&lt;li&gt;設定 prescale&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;TIMx_ARR
&lt;ul&gt;
&lt;li&gt;auto-reload register&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Self-Instruct 論文閱讀</title>
        <link>https://roykesydon.github.io/Blog/p/self-instruct-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</link>
        <pubDate>Sun, 30 Apr 2023 00:00:12 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/self-instruct-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</guid>
        <description>&lt;p&gt;paper: &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2212.10560&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Self-Instruct: Aligning Language Model with Self Generated Instructions&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;大型 &amp;ldquo;instruction-tuned&amp;rdquo; 語言模型 (經過微調好回應 instruction) 已經展現出在新任務上 zero-shot 的能力。&lt;/p&gt;
&lt;p&gt;然而他們嚴重依賴人工編寫的指令，在數量、多樣性和創造力上都受到了限制，阻礙了模型的通用性。&lt;/p&gt;
&lt;p&gt;作者介紹了 Self-Instruct 這個框架，可以透過自己生成的指令，來增強預訓練模型遵循指令的能力。&lt;/p&gt;
&lt;p&gt;將作者的方法應用在 GPT3，在 SuperNaturalInstructions 獲得了比原始模型高 33% 的改進，與使用 private user data 和 human annotations 的 $InstructGPT_{001}$ 性能相當。&lt;/p&gt;
&lt;p&gt;為了進一步評估，我們為新任務整理一組專家編寫的指令，並通過人工評估，顯示出使用 Self-Instruction 調整 GPT3 的性能大大優於使用現有公共指令資料集，只比 $InstructGPT_{001}$ 落後 5% 的差距。&lt;/p&gt;
&lt;p&gt;Self-Instruct 提供一個幾乎 annotation-free 的方法，align 預訓練模型和 instructions，而且作者釋出了他們的大型合成資料集，以促進未來對 instruction tuning 的研究。&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;最近的 NLP 文獻見證了「建構可以遵循自然語言指令的模型方面」的大量活動。&lt;/p&gt;
&lt;p&gt;這些發展由兩個關鍵部分組成：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;大型預訓練語言模型 (LM)&lt;/li&gt;
&lt;li&gt;人工編寫的指令資料&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;PromptSource 和 SuperNaturalInstructions 是最近兩個著名的資料集。
他們透過大量手動註釋來收集指令，以建造 T0 和 T$k$-Instruct。&lt;/p&gt;
&lt;p&gt;然而這過程代價高昂，而且由於大多數人往往生成的都是流行的 NLP 任務，使其未能涵蓋真正多樣的任務，也不能涵蓋各種描述任務的不同方式，因此多樣性受侷限。&lt;/p&gt;
&lt;p&gt;鑒於這些限制，想要繼續提升 instruction-tuned models 的品質，需要幫 supervising instruction-tuned models 發展替代方案。&lt;/p&gt;
&lt;p&gt;本文介紹了 Self-Instruct，這是一種 semi-automated 的過程，用模型自身的 instructional signals 對 pretrained LM 進行 instruction-tuning。&lt;/p&gt;
&lt;p&gt;整個流程是一種 iterative bootstrapping algorithm，從手動編寫的 limited seed set 引導生成。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/gpt/self-instruct/fig1.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;在第一階段，模型要幫新任務生成指令。
利用現有的指令集合，創建更廣泛的指令，好定義 (通常是新的) 任務。&lt;/p&gt;
&lt;p&gt;對於新生成的指令集，框架為他們創建 input-output instances，稍後可以透過 supervising 用於 instruction tuning。&lt;/p&gt;
&lt;p&gt;最後，透過各種手段，在低品質和重複的指令加到 task pool 前，把他們修剪掉。&lt;/p&gt;
&lt;p&gt;可以重複這個流程非常多次，直到獲得大量任務。&lt;/p&gt;
&lt;p&gt;該模型的跌代過程中產生了大約 52K 個指令，與大約 85K 個 instance inputs 和 target outputs 配對 (有些相同的指令會對應多種輸入輸出)。&lt;/p&gt;
&lt;p&gt;作者觀察到生成的資料提供了各種有創意的任務，其中超過 50% 的任務和 seed instructions 的 ROUGE-L overlap 小於 0.3。&lt;/p&gt;
&lt;p&gt;基於上述結果，作者通過微調 GPT3 (和生成指令資料是同個模型) 建構了 $GPT3_{SELF-INST}$。&lt;/p&gt;
&lt;p&gt;SuperNI 的結果表明，$GPT3_{SELF-INST}$ 性能大大優於 GPT3 (原始模型)，高了 33.1%，幾乎和 $InstructGPT_{001}$ 的性能相當。&lt;/p&gt;
&lt;p&gt;此外，作者在新創建的的指令集上進行人工評估，$GPT3_{SELF-INST}$ 顯示出廣泛的指令遵循能力，優於在其他公開可用指令數據集上訓練的模型，只比 InstrcutGPT001 落後 5%。&lt;/p&gt;
&lt;p&gt;本文貢獻：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Self-Instruct：一種用最少的人工標記數據引導指令遵循能力的作法&lt;/li&gt;
&lt;li&gt;通過大量的 instruction-tuning 實驗，證明了有效性。&lt;/li&gt;
&lt;li&gt;發布了一個包含 52K 指令的大型綜合資料集，還有一組手動編寫的新任務，用於建構和評估未來的 instruction-following models。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;related-work&#34;&gt;Related Work&lt;/h2&gt;
&lt;h3 id=&#34;instruction-following-language-models&#34;&gt;Instruction-following language models&lt;/h3&gt;
&lt;p&gt;一系列工作顯示，使用 annotated &amp;ldquo;instructional&amp;rdquo; data，可以使普通語言模型遵循一般語言的指令。&lt;/p&gt;
&lt;p&gt;也顯示出 &amp;ldquo;instructional&amp;rdquo; data 的大小和多樣性直接影響模型的泛化能力。&lt;/p&gt;
&lt;p&gt;本文的工作目的在減少對人工註釋者的依賴。&lt;/p&gt;
&lt;h3 id=&#34;language-models-for-data-generation-and-augmentation&#34;&gt;Language models for data generation and augmentation&lt;/h3&gt;
&lt;p&gt;許多工作依賴生成式 LM 來生成數據或做 augmentation。&lt;/p&gt;
&lt;p&gt;雖然作者的工作可被視為一種 augmentation，但和這些工作的差別在於不限於特定任務。&lt;/p&gt;
&lt;p&gt;Self-Instruct 的一個明顯動機是引導出新的任務定義，而這些任務可能還未被 NLP 的研究者定義過。&lt;/p&gt;
&lt;h3 id=&#34;self-training&#34;&gt;Self-training&lt;/h3&gt;
&lt;p&gt;一種典型的 self-training 框架透過經過訓練的模型，幫 unlabeled 資料進行 label，然後用這些資料改進模型。&lt;/p&gt;
&lt;p&gt;雖然 Self-Instruct 和 self-training 有一些相似之處，但多數 self-training 的方法都假設了一個特定的目標任務。&lt;/p&gt;
&lt;p&gt;相比之下，Self-Instruct 從頭開始生出各種任務。&lt;/p&gt;
&lt;h3 id=&#34;knowledge-distillation&#34;&gt;Knowledge distillation&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;這邊我想不太通為什麼可以和 Knowledge distillation 扯上關係&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Knowledge distillation 通常涉及知識從較大模型到較小模型的轉移&lt;/p&gt;
&lt;p&gt;Self-Instruct 也可以看做是 Knowledge distillation 的一種形式，但區別如下&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;distillation 的來源和目標是相同的，即模型的知識被 distill 到他自己&lt;/li&gt;
&lt;li&gt;distill 的內容以 instruction task 的形式出現&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;method&#34;&gt;Method&lt;/h2&gt;
&lt;p&gt;標記大規模指令資料對人類來說可能具有挑戰性，因為他需要&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;創意，好提出新任務&lt;/li&gt;
&lt;li&gt;為每個任務編寫 labeled instances 的專業知識&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;defining-instruction-data&#34;&gt;Defining Instruction Data&lt;/h3&gt;
&lt;p&gt;我們要生成的指令資料集包含 {$I_t$}，每個指令用自然語言定義了任務 $t$。&lt;/p&gt;
&lt;p&gt;每個任務都有一個或多個 input-output instances ($X_t,Y_t$)。&lt;/p&gt;
&lt;p&gt;給定 task instruction $I_t$，還有 instance x，模型 M 要生出 y：&lt;/p&gt;
&lt;p&gt;$M(I_t,x)=y, for (x,y) \in (X_t,Y_t)$&lt;/p&gt;
&lt;p&gt;值得注意的是，instance input 和 instruction 沒有嚴格分界。&lt;/p&gt;
&lt;p&gt;比如 Instruction:&amp;ldquo;write an essay about school safety&amp;rdquo; x:&amp;quot;&amp;quot;，可以被改為 Instruction:&amp;ldquo;write an essay about the following topic&amp;rdquo; x:&amp;ldquo;school safety&amp;rdquo;&lt;/p&gt;
&lt;h3 id=&#34;automatic-instruction-data-generation&#34;&gt;Automatic Instruction Data Generation&lt;/h3&gt;
&lt;p&gt;生成指令資料的 pipeline 分成四個步驟：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;指令生成&lt;/li&gt;
&lt;li&gt;辨識指令是否是分類任務&lt;/li&gt;
&lt;li&gt;用 input-first 或 output-first 做 instance generation&lt;/li&gt;
&lt;li&gt;過濾掉低品質的資料&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;instruction-generation&#34;&gt;Instruction Generation&lt;/h4&gt;
&lt;p&gt;Self-Instruct 是基於一個發現，也就是大型語言模型可以透過 context 中的現有指令，生出新穎的指令。&lt;/p&gt;
&lt;p&gt;為作者提供了一種從一小組人類編寫的指令中，使指令資料增長的做法。&lt;/p&gt;
&lt;p&gt;作者用他們編寫的 175 個任務 (每個任務 1 個 instruction 和 1 個 instance) 初始化 task pool。&lt;/p&gt;
&lt;p&gt;在每一個 step，作者從裡面 sample 8 個 instructions，作為 in-context 的範例。在這 8 個指令中，有 6 條來自人工編寫的任務，另外兩條來自前面步驟中模型生成的任務，以促進多樣性。&lt;/p&gt;
&lt;h4 id=&#34;classification-task-identification&#34;&gt;Classification Task Identification&lt;/h4&gt;
&lt;p&gt;因為對於分類和非分類的任務，作者會採取兩種做法，所以作者使用來自 seed taks 的 12 條分類指令和 19 條非分類指令，讓 GPT3 透過 few-shot 來判別。&lt;/p&gt;
&lt;h4 id=&#34;instance-generation&#34;&gt;Instance Generation&lt;/h4&gt;
&lt;p&gt;給予指令和他們的任務類別，作者獨立地為每條指令生成 instance。&lt;/p&gt;
&lt;p&gt;這具備挑戰性，原因在於他需要模型瞭解目標任務是什麼，根據指令找出需要那些額外的輸入內容，並生成他們。 (模型要根據 instruction 生出 instance input)&lt;/p&gt;
&lt;p&gt;作者發現，在 prompt 中放入其他包含 instruction-input-output 的任務範例的時候，模型可以實現這點。&lt;/p&gt;
&lt;p&gt;一種自然的方法是 Input-first Approach，可以要求語言模型先根據指令提出 input，再生出相應的 output。&lt;/p&gt;
&lt;p&gt;然而，這種方法在分類任務上，可能會偏向於生成某種 label。所以，對於分類任務，作者採用 Output-first Approach，先生成可能的 label，在每個 label 上再生成輸入。&lt;/p&gt;
&lt;h4 id=&#34;filtering-and-postprocessing&#34;&gt;Filtering and Postprocessing&lt;/h4&gt;
&lt;p&gt;為了鼓勵多樣性，只有當新的指令和任何現有的指令的 ROUGE-L overlapping 小於 0.7 的時候，才會被添加到 task pool。&lt;/p&gt;
&lt;p&gt;還排除了一些包含了通常不能被 LM 處理的關鍵字 (e.g. images, pictures, graphs) 的指令。&lt;/p&gt;
&lt;p&gt;在為每個指令生成新的 instance 的時候，會過濾掉完全相同或者是輸入相同但輸出不同的 instance。&lt;/p&gt;
&lt;h3 id=&#34;finetuning-the-lm-to-follow-instructions&#34;&gt;Finetuning the LM to Follow Instructions&lt;/h3&gt;
&lt;p&gt;在創建大規模指令資料後，用這些資料對原始語言模型進行 fine-tune。&lt;/p&gt;
&lt;p&gt;為此，將 instruction 和 instance input 連接起來，作為 prompt，然後訓練模型透過標準的監督式學習進行微調。&lt;/p&gt;
&lt;p&gt;為了讓模型對不同的格式 robust，使用多個模板將指令和輸入 encode 在一起。&lt;/p&gt;
&lt;p&gt;例如，指令可以有或沒有 Task: 前墜、輸入可以有或沒有 Input: 前墜，或是中間可以有不同數量的換行之類的。&lt;/p&gt;
&lt;h2 id=&#34;self-instruct-data-from-gpt3&#34;&gt;Self-Instruct Data from GPT3&lt;/h2&gt;
&lt;p&gt;作者透過 OpenAI API 訪問最大的 GPT3 (davinci)&lt;/p&gt;
&lt;h3 id=&#34;statistics&#34;&gt;Statistics&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/gpt/self-instruct/table1.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;diversity&#34;&gt;Diversity&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/gpt/self-instruct/fig2.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;quality&#34;&gt;Quality&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/gpt/self-instruct/table2.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;experimental-results&#34;&gt;Experimental Results&lt;/h2&gt;
&lt;h3 id=&#34;gpt3_self-inst-fine-tuning-gpt3-on-its-own-instruction-data&#34;&gt;$GPT3_{SELF-INST}$: fine-tuning GPT3 on its own instruction data&lt;/h3&gt;
&lt;p&gt;使用生出來的指令資料，對 GPT3 進行微調。&lt;/p&gt;
&lt;p&gt;微調是透過 OpenAI finetuning API&lt;/p&gt;
&lt;h3 id=&#34;baselines&#34;&gt;Baselines&lt;/h3&gt;
&lt;h4 id=&#34;off-the-shelf-language-models&#34;&gt;Off-the-shelf language models&lt;/h4&gt;
&lt;p&gt;T5-LM 和 GPT3 是普通 LM baselines (只有 pre-training，沒有額外 fine-tune)&lt;/p&gt;
&lt;p&gt;這些 baseline 將表明現成的 LM 在預訓練後，能夠立刻自然地遵循指令的程度。&lt;/p&gt;
&lt;h4 id=&#34;publicly-available-instruction-tuned-models&#34;&gt;Publicly-available instruction-tuned models&lt;/h4&gt;
&lt;p&gt;T0 和 $T_k$-Instruct 是兩個 instruction-tuned models。&lt;/p&gt;
&lt;p&gt;兩者都是從 T5 進行微調的，對這兩種模型，都使用具有 11B 參數的最大版本。&lt;/p&gt;
&lt;h4 id=&#34;instruction-tuned-gpt3-models&#34;&gt;Instruction-tuned GPT3 models&lt;/h4&gt;
&lt;p&gt;作者評估了 InstructGPT，它是 OpenAI 基於 GPT3 開發的。&lt;/p&gt;
&lt;p&gt;對於 SuperNI 的實驗，只與 text-davinci-001 engine 進行比較，因為更新的 engine 用最新的用戶資料，而且很可能已經看過 SuperNI。&lt;/p&gt;
&lt;p&gt;對於新編寫的指令，評估時則包含了 001、002 和 003，以確保完整性。&lt;/p&gt;
&lt;p&gt;為了進一步比較 Self-Instruct 在其他公開可用的指令訓練集資料，使用 PromptSource 和 SuperNI 的資料微調 GPT3，這些資料用於訓練 T0 和 $T_k$-Instruct 模型。&lt;/p&gt;
&lt;p&gt;分別簡稱為 T0 訓練和 SuperNI 訓練。&lt;/p&gt;
&lt;h3 id=&#34;experiment-1-zero-shot-generalization-on-superni-benchmark&#34;&gt;Experiment 1: Zero-Shot Generalization on SUPERNI benchmark&lt;/h3&gt;
&lt;p&gt;首先以 zero-shot 的方式評估典型 NLP 任務遵循指令的能力。&lt;/p&gt;
&lt;h4 id=&#34;results&#34;&gt;Results&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/gpt/self-instruct/table3.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;experiment-2-generalization-to-user-oriented-instructions-on-novel-tasks&#34;&gt;Experiment 2: Generalization to User-oriented Instructions on Novel Tasks&lt;/h3&gt;
&lt;p&gt;盡管 SuperNI 在現有的 NLP 任務具有全面性，多數的這些任務是初於研究理由提出的，而且偏向分類。&lt;/p&gt;
&lt;p&gt;為了更好的獲取指令遵循模型的實用價值，作者中的一部分人策劃了一組面向用戶應用的新指令集。&lt;/p&gt;
&lt;p&gt;他們先針對 Large LM 可能可以應用到的領域進行 brainstorm，並且制定與每個領域相關的 instruction 和 instance。&lt;/p&gt;
&lt;p&gt;總共創建了 252 條指令，每條指令有 1 個 instance。&lt;/p&gt;
&lt;h4 id=&#34;human-evaluation-setup&#34;&gt;Human evaluation setup&lt;/h4&gt;
&lt;p&gt;評估模型在這些不同任務的測試集上的表現極具挑戰性，因為不同的任務需要不同的專業知識。&lt;/p&gt;
&lt;p&gt;為了獲得更忠實的評價，作者請了 instructions 的作者對模型的預測結果進行評估。&lt;/p&gt;
&lt;p&gt;實施一個 four-level rating system：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Rating A
&lt;ul&gt;
&lt;li&gt;回覆有效且令人滿意&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Rating B
&lt;ul&gt;
&lt;li&gt;回覆可接受，但存在可以改進的地方&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Rating C
&lt;ul&gt;
&lt;li&gt;回覆相關，但在內容上有重大錯誤&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Rating D
&lt;ul&gt;
&lt;li&gt;回覆不相關或無效，包含重複輸入的部分，完全無關的輸出。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;results-1&#34;&gt;Results&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/gpt/self-instruct/fig5.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;如果把 Rating B 以上視為有效，$GPT_{SELF-INST}$ 只和 $InstructGPT_{001}$ 相差 5%&lt;/p&gt;
&lt;h2 id=&#34;discussion-and-limitation&#34;&gt;Discussion and Limitation&lt;/h2&gt;
&lt;h3 id=&#34;why-does-self-instruct-work&#34;&gt;Why does SELF-INSTRUCT work?&lt;/h3&gt;
&lt;p&gt;值得反思的是，在最近成功的 instruction-tuning LMs 中，高品質的 human feedback 扮演的角色。&lt;/p&gt;
&lt;p&gt;這裡有兩個極端的假設：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Human feedback 是 instruction-tuning 中必要且不可或缺的角色，因為 LM 需要了解在預訓練過程中沒完全了解到的問題。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Human feedback 是 instruction-tuning 一個可選的方向，因為 LM 在預訓練就已經很熟悉指令了。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;雖然現實可能介於這兩個極端之間，作者推測可能更傾向於第二種假設，尤其是對於較大的模型。&lt;/p&gt;
&lt;p&gt;第二種，也是人類直覺，是 Self- Instruct 的關鍵動機，而且也從成功的結果獲得支持。&lt;/p&gt;
&lt;h3 id=&#34;broader-impact&#34;&gt;Broader Impact&lt;/h3&gt;
&lt;p&gt;除了本文的直接關注點外，作者相信 Self-Instruct 可能有助於揭露各種 instruction tuning 模型 &amp;ldquo;幕後&amp;rdquo; 發生的事情。&lt;/p&gt;
&lt;p&gt;不幸的是，由於他們的資料集尚未發布，這種業界模型仍處於 API 牆之後。&lt;/p&gt;
&lt;p&gt;人們對其結構以及為何能展現令人印象深刻的能力知之甚少。&lt;/p&gt;
&lt;h3 id=&#34;limitations-of-self-instruct&#34;&gt;Limitations of Self-Instruct&lt;/h3&gt;
&lt;h4 id=&#34;tail-phenomena&#34;&gt;Tail phenomena&lt;/h4&gt;
&lt;p&gt;Self-Instruct 依賴於 LM，繼承 LM 的所有限制。&lt;/p&gt;
&lt;p&gt;最近的研究顯示出 tail phenomena 對 LM 的成功構成嚴峻的挑戰。&lt;/p&gt;
&lt;p&gt;換句話說，LM 的最大收益出現於語言中最頻繁出現的部分 (語言分佈的頭部)，而低頻率出現的上下文中獲得的收益最小。&lt;/p&gt;
&lt;p&gt;同樣的，在這項工作背景下，如果 Self-Instruct 大部分的收益偏向預訓練 corpus 中頻繁出現的任務或指令，那也不令人感到意外。&lt;/p&gt;
&lt;p&gt;因此，該方法在不常見和有創意的指令下，可能會顯現出脆弱性。&lt;/p&gt;
&lt;h4 id=&#34;dependence-on-large-models&#34;&gt;Dependence on large models&lt;/h4&gt;
&lt;p&gt;因為 Self-Instruct 依賴於從 LM 中提取初的 inductive bias，因此它可能適合 larger model。&lt;/p&gt;
&lt;p&gt;如果這是對的，這會對那些沒有大量計算資源的人造成阻礙。&lt;/p&gt;
&lt;h4 id=&#34;reinforcing-lm-biases&#34;&gt;Reinforcing LM biases&lt;/h4&gt;
&lt;p&gt;作者擔心這種迭代作法可能會產生意料之外的結果，比如將有問題的社會偏見放大。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>STM32 GPIO 介紹</title>
        <link>https://roykesydon.github.io/Blog/p/stm32-gpio-%E4%BB%8B%E7%B4%B9/</link>
        <pubDate>Wed, 26 Apr 2023 01:32:54 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/stm32-gpio-%E4%BB%8B%E7%B4%B9/</guid>
        <description>&lt;h2 id=&#34;memory-map&#34;&gt;Memory Map&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;CPU 對 I/O 操作方法&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Port I/O
&lt;ul&gt;
&lt;li&gt;用特殊 CPU 指令&lt;/li&gt;
&lt;li&gt;I/O 設備和記憶體不共享地址空間&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Memory-Mapped I/O
&lt;ul&gt;
&lt;li&gt;I/O 設備和記憶體共享地址空間&lt;/li&gt;
&lt;li&gt;像一般控制記憶體&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;這塊記憶體具有四個責任&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Command&lt;/li&gt;
&lt;li&gt;Status&lt;/li&gt;
&lt;li&gt;Output Data&lt;/li&gt;
&lt;li&gt;Input Data&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;gpio-結構&#34;&gt;GPIO 結構&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/embedding/stm32-gpio/gpio-structure.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GPIO mode
&lt;ul&gt;
&lt;li&gt;Open-Drain
&lt;ul&gt;
&lt;li&gt;由外部電壓決定輸出電壓&lt;/li&gt;
&lt;li&gt;Output Register 是 0 會啟用 N-MOS，1 的話靠外部電壓推
&lt;ul&gt;
&lt;li&gt;好處是外部電壓可以自己決定&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Push-Pull
&lt;ul&gt;
&lt;li&gt;由內部電壓決定輸出電壓&lt;/li&gt;
&lt;li&gt;Output Register 是 0 或 1 會決定啟用 N-MOS 或是 P-MOS&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;有關-register&#34;&gt;有關 Register&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Clock enable register
&lt;ul&gt;
&lt;li&gt;AHB2 peripheral clock enable regisetr (RCC_AHB2ENR)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Control register
&lt;ul&gt;
&lt;li&gt;GPIO port mode register&lt;/li&gt;
&lt;li&gt;GPIO port output type register&lt;/li&gt;
&lt;li&gt;GPIO port output speed register&lt;/li&gt;
&lt;li&gt;GPIO port pull-up/pull-down register&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Data register
&lt;ul&gt;
&lt;li&gt;Output&lt;/li&gt;
&lt;li&gt;Input&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;使用-gpio&#34;&gt;使用 GPIO&lt;/h2&gt;
&lt;p&gt;先去 Memory map 找 Boudary address&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/embedding/stm32-gpio/gpio-structure.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;根據 table 確認要設置的數值&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/embedding/stm32-gpio/table-39-1.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/embedding/stm32-gpio/table-39-2.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;設定 RCC enable&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/embedding/stm32-gpio/rcc-en.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;把上面說的各種 Control register 設定好&lt;/p&gt;
&lt;p&gt;比如 PUPDR
&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/embedding/stm32-gpio/PUPDR.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;BSRR&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;修改 ODR 會一次改到整個 GPIO port，若只要改某個 pin，可以用 BSRR&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Delay&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CPU 4 MHz
&lt;ul&gt;
&lt;li&gt;1 cycle = 0.25$\mu$S&lt;/li&gt;
&lt;li&gt;可以查每個組合語言指令要幾個 cycle&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;機械按鈕會有 Bouncing&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Debounce
&lt;ul&gt;
&lt;li&gt;Hardware method
&lt;ul&gt;
&lt;li&gt;加上濾波電容&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Software method
&lt;ul&gt;
&lt;li&gt;讀取後等待一段時間才再次讀取&lt;/li&gt;
&lt;li&gt;連續讀取 N 次，看數值是否穩定改變&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;7-segment&#34;&gt;7-Segment&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;COM 分共陽、共陰&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;8 個七段顯示器就要吃掉 8 * 8 個 GPIO 接腳，可以每次只顯示一個，那只需要 8 個 GPIO 接腳，快速閃過&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;也可用 Max 7219 控制，他有三個輸入 DIN、LOAD、CLK&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DIN 輸入資料&lt;/li&gt;
&lt;li&gt;CLK 上升的時候採樣，最多 10 MHz&lt;/li&gt;
&lt;li&gt;LOAD(CS) 採用最後輸進去的 16 bits
&lt;ul&gt;
&lt;li&gt;最早的是 MSB&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>重構 Refactoring</title>
        <link>https://roykesydon.github.io/Blog/p/%E9%87%8D%E6%A7%8B-refactoring/</link>
        <pubDate>Tue, 25 Apr 2023 14:26:17 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/%E9%87%8D%E6%A7%8B-refactoring/</guid>
        <description>&lt;h2 id=&#34;重構&#34;&gt;重構&lt;/h2&gt;
&lt;p&gt;在不改變軟體行為的情況下，對軟體內部構造進行改善&lt;/p&gt;
&lt;h2 id=&#34;code-smell&#34;&gt;Code Smell&lt;/h2&gt;
&lt;p&gt;也稱 Bad Smell，代表程式碼中需要重構的部分&lt;/p&gt;
&lt;h3 id=&#34;duplicated-code&#34;&gt;Duplicated Code&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;重複程式碼
&lt;ul&gt;
&lt;li&gt;在同個 Class
&lt;ul&gt;
&lt;li&gt;Extract Method&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;在不同 Class
&lt;ul&gt;
&lt;li&gt;Extract Class&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;long-method&#34;&gt;Long Method&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;用 Extract Method 拆解過長的 function&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;long-parameter-list&#34;&gt;Long Parameter List&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Preserve Whole Object
&lt;ul&gt;
&lt;li&gt;把來自同一物件的資料直接該物件取代&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Introduce Parameter Object
&lt;ul&gt;
&lt;li&gt;把相關的資料包成一個 Object&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;large-class&#34;&gt;Large Class&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;一個 Class 有太多 fields / methods / lines&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;magic-number&#34;&gt;Magic Number&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;特殊數值直接用數字表示，日後修改每個地方都要改&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;lack-of-comments&#34;&gt;Lack of Comments&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;加註解的好時機：寫程式前寫上&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;switch-statements&#34;&gt;Switch Statements&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;可利用「多型 (Polymorphism)」解決&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;divergent-change&#34;&gt;Divergent Change&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;一個類別有太多改變的原因&lt;/li&gt;
&lt;li&gt;盡量讓其遵守 SRP&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;shotgun-surgery&#34;&gt;Shotgun Surgery&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;某個責任被分散到大量的 Class 身上，使修改其時要大量修改&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;feature-envy&#34;&gt;Feature Envy&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;存取別的 Object 的 Data 的情形比自己的還頻繁&lt;/li&gt;
&lt;li&gt;這方法可能應該屬於另一個 Object&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;data-clumps&#34;&gt;Data Clumps&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;常一起出現的資料群應該被單獨抽成一個 Class&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;primitive-obsession&#34;&gt;Primitive Obsession&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;過度使用基本類別，造成 Shotgun Surgery&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;message-chains&#34;&gt;Message Chains&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Client 請求 A 物件，A 物件又請求 B 物件&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;lazy-class&#34;&gt;Lazy Class&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;把冗員類別移除&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;temporary-field&#34;&gt;Temporary Field&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Instance variable 只有在特殊情形才被使用，應該改為區域變數或參數&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;inappropriate-intimacy&#34;&gt;Inappropriate Intimacy&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Classes 間頻繁讀取對方資料&lt;/li&gt;
&lt;li&gt;理解程式要同時看懂兩者&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;alternative-classes-with-different-interfaces&#34;&gt;Alternative Classes with Different Interfaces&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;兩個 Class 具有功能相同、命名不同的 function&lt;/li&gt;
&lt;li&gt;可汲取共同部分為 Super Class 來解決&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Relative Position 介紹 &#43; 論文閱讀</title>
        <link>https://roykesydon.github.io/Blog/p/relative-position-%E4%BB%8B%E7%B4%B9--%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</link>
        <pubDate>Mon, 24 Apr 2023 01:08:46 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/relative-position-%E4%BB%8B%E7%B4%B9--%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</guid>
        <description>&lt;h2 id=&#34;說明&#34;&gt;說明&lt;/h2&gt;
&lt;p&gt;本文寫於 &lt;a class=&#34;link&#34; href=&#34;https://roykesydon.github.io/Blog/p/swin-transformer-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Swin Transformer 論文閱讀&lt;/a&gt; 之後，當時對 Relatvie position 的理解不夠清楚，本文將會做解釋，並附上原論文的筆記。&lt;/p&gt;
&lt;p&gt;以下將會先用長度為 3 的序列作為示範。&lt;/p&gt;
&lt;h3 id=&#34;absolute-position-encodings&#34;&gt;Absolute Position Encodings&lt;/h3&gt;
&lt;p&gt;Absolute Position Encodings 的做法是把用某種方式生成或可學習的向量加在輸入，第一個位置用 $w_1$，第二個位置用 $w_2$，第三個位置用 $w_3$。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/relative-position/abs-pos.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;relative-position-encodings&#34;&gt;Relative Position Encodings&lt;/h3&gt;
&lt;p&gt;Relative Position Encodings 顧名思義，就是改用相對位置來做這些向量。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/relative-position/rel-pos.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;上圖中，Position Encoding 的部分從 3 個向量變成 3*3 個向量，因為現在會以每個 token 為基準，生出 3 個相對位置向量。&lt;/p&gt;
&lt;p&gt;我們以 $w_0$，代表處於原點，$w_x$ 代表往右 $x$ 格，$w_{-x}$ 代表往左 $x$ 格，其中 $x$ 是正整數。&lt;/p&gt;
&lt;p&gt;第一個 row 有 $w_0$、$w_1$、$w_2$，意思是以第 0 個向量 (I) 為基準，他的位置是 $w_0$，對第 0 個向量來說，第 1 個向量 (like) 是 $w_1$，第 2 個向量 (cat) 是 $w_2$。&lt;/p&gt;
&lt;p&gt;輪流以 $n$ 個 token 為基準，就會生出 n*n 個相對位置向量，而不是原先的 n 個絕對位置向量。&lt;/p&gt;
&lt;p&gt;其中 $w_i$ 和 $w_j$ 如果 $i=j$，他們會共用同樣的 weight，上圖是以相同顏色表示。&lt;/p&gt;
&lt;p&gt;如果序列長度是 $n$，就會有 $2n-1$ 個向量要學。&lt;/p&gt;
&lt;p&gt;n*n 這個數量使其適合加入到 self-attention，原始論文的加入方式可以參考下方論文筆記，這邊晚點會介紹後續衍生的簡化版。&lt;/p&gt;
&lt;h3 id=&#34;swin-transformer-如何導入-relative-position-encodings&#34;&gt;Swin Transformer 如何導入 Relative Position Encodings&lt;/h3&gt;
&lt;p&gt;Swin Transformer 是借鑒許多 CNN 架構，為了 CV 而經過修改的 vision transformer。&lt;/p&gt;
&lt;p&gt;其中一個重點是，他會在一小區塊的特徵圖上做 self-attention，而且是用 Relative Position Encodings。&lt;/p&gt;
&lt;p&gt;和剛剛的差別在於，現在要在二維空間做 Relative Position Encodings。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/relative-position/rel-pos-2d-1.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;假設有一張 2*2 的 feature map，我們先設定好 feature map 各個 token 的絕對位置座標。&lt;/p&gt;
&lt;p&gt;然後我們輪流把 feature map 的每一個 token 作為基準點，把 feature map 的每個 token 的座標減去基準點的座標，就可以得到相對位置座標。&lt;/p&gt;
&lt;p&gt;如果我們把四個相對位置座標各別攤平 (按照左上 -&amp;gt; 右上 -&amp;gt; 左下 -&amp;gt; 右下的順序)，並且從上到下排好，他會看起來如下圖。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/relative-position/rel-pos-2d-2.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;此時我們幾乎完成了相對位置的表，和剛剛序列一樣生出了 n*n 個相對位置。&lt;/p&gt;
&lt;p&gt;我們接下來要做的事情是把這個表給編號，把 (0, 0) 都編成某個數字，把 (1, 0) 都編成某個數字。&lt;/p&gt;
&lt;p&gt;在此之前，先考慮總共會有幾種可能的相對座標，對於邊長 $M$ 的 feature map (這裡 M=2)，因為兩軸可能的數字皆有 (2M-1) 種，共會有 (2M-1)*(2M-1) 種可能性，這裡等於 9。&lt;/p&gt;
&lt;p&gt;所以我們等等會把所有座標編為 0~8。&lt;/p&gt;
&lt;p&gt;想從座標生出編號 0~8 可以考慮把座標兩軸的數字相加，但由於有負數的存在，要先把兩軸的數字都變成非負整數，所以先把兩軸的座標都各別加 M-1。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/relative-position/rel-pos-2d-3.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;此時如果相加，會使 (2, 1) 和 (1, 2) 都對應到數字 3，所以我們先把 row 座標乘上 2M-1 再相加，此時就可以獲得一個 n*n 的 index table ，對應一組相對位置向量。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/relative-position/rel-pos-2d-4.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;Swin Transformer 是用簡化版的作法來引入相對位置，公式如下&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$Attention(Q,K,V)=SoftMax(QK^T/\sqrt{d}+B)V$
&lt;ul&gt;
&lt;li&gt;$B$ 是 relative position bias，$B \in R^{M^2 * M^2}$&lt;/li&gt;
&lt;li&gt;$a_{ij}$ 是純量，不是向量，和原始論文不同&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;論文出處&#34;&gt;論文出處&lt;/h2&gt;
&lt;p&gt;paper: &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/pdf/1803.02155.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Self-Attention with Relative Position Representations&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;依賴於 attention 機制的 Transformer 在機器翻譯方面取得 SOTA，但在結構中沒有相對或絕對的位置資訊，他需要在輸入中添加絕對位置的資訊。&lt;/p&gt;
&lt;p&gt;因此本文提出一種替代方案，拓展 self-attention ，考慮相對位置的表示，並在一些任務中獲得更好的結果。&lt;/p&gt;
&lt;p&gt;值得一題的事，作者觀察到結合相對和絕對位置不會進一步提高翻譯品質。&lt;/p&gt;
&lt;p&gt;該機制可以拓展到任意 graph-labeled 的輸入&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Non-recurrent models 不一定按順序考慮輸入元素，因此可能需要明確的 position encoding 才才能用序列順序。&lt;/p&gt;
&lt;p&gt;一種常見的方法是使用與輸入元素結合的 position encoding，以向模型傳達位置資訊。&lt;/p&gt;
&lt;p&gt;可以是 deterministic function，或是 learned representations。&lt;/p&gt;
&lt;p&gt;CNN 可以捕捉 kernel 的相對位置資訊，但被證明仍受益於 position encoding。&lt;/p&gt;
&lt;p&gt;對於既不使用卷積也不使用遞歸的 Transformer，結合位置信息的 representation 是一個特別重要的考慮因素，因為該模型在其他方面對序列排序完全不變。&lt;/p&gt;
&lt;p&gt;本文提出一種將相對位置合併到 Transformer 的 self-attention 的做法，即使完全換掉絕對位置編碼，也使兩個機器翻譯任務的品質有顯著提高。&lt;/p&gt;
&lt;h2 id=&#34;background&#34;&gt;Background&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;原始 self-attention&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$z_i=\displaystyle\sum_{j=1}^n\alpha_{ij}(x_jW^V)$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$\alpha_{ij}=\frac{\text{exp } e_{ij}}{\sum_{k=1}^n\text{exp } e_{ik}}$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$e_{ij}=\frac{(x_iW^Q)(x_jW^K)^T}{\sqrt{d_z}}$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;proposed-architecture&#34;&gt;Proposed Architecture&lt;/h2&gt;
&lt;h3 id=&#34;relation-aware-self-attention&#34;&gt;Relation-aware Self-Attention&lt;/h3&gt;
&lt;p&gt;有兩個要引入 relative position 的地方，而且都是向量&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$z_i = \displaystyle\sum_{j=1}^n \alpha_{ij}(x_jW^V+a_{ij}^V)$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$e_{ij}=\frac{x_iW^Q(x_jW^K+a_{ij}^K)^T}{\sqrt{d_z}}$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/relative-position/fig1.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;relative-position-representations&#34;&gt;Relative Position Representations&lt;/h3&gt;
&lt;p&gt;可以引入 clip，把線性序列中，高於長度 k 的修剪成最大值&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$a_{ij}^K=w_{clip(j-i,k)}^K$&lt;/li&gt;
&lt;li&gt;$a_{ij}^V=w_{clip(j-i,k)}^V$&lt;/li&gt;
&lt;li&gt;$clip(x,k)=max(-k,min(k,x))$&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;experiments&#34;&gt;Experiments&lt;/h2&gt;
&lt;h3 id=&#34;model-variations&#34;&gt;Model Variations&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;clipping 的實驗
&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/relative-position/table2.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;V 和 K 的 ablation study
&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/relative-position/table3.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Swin Transformer 論文閱讀</title>
        <link>https://roykesydon.github.io/Blog/p/swin-transformer-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</link>
        <pubDate>Fri, 14 Apr 2023 01:08:46 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/swin-transformer-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</guid>
        <description>&lt;p&gt;paper: &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2103.14030&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Swin Transformer: Hierarchical Vision Transformer using Shifted Windows&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;本文提出一個新的 vision Transformer，稱作 Swin Transformer，可以被用作 computer vision 中的 general-purpose backbone。&lt;/p&gt;
&lt;p&gt;把 Transformer 從 language 移到 vision 具備挑戰性，比如同一個 visual entity 在大小上具備很大的 variance。還有 high resolution 下 pixel 和 word 的數量差異太大。&lt;/p&gt;
&lt;p&gt;為了解決這些差異，作者提出 hierachical Transformer，用 shifted windows 來算出 representation。&lt;/p&gt;
&lt;p&gt;shifted windowing 透過把 self-attention 限制在 non-overlapping 的 local window 和允許 cross-windows connection 來提高效率。&lt;/p&gt;
&lt;p&gt;這種 hierarchical architecture 可以靈活地在各種 scale 下擴展 model，還可以對圖像大小有線性的計算時間複雜度。&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/Swin-Transformer/fig1.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;ViT 把圖片打成 patch，每個 patch 是 16*16，feature maps 由 single low resolution 的輸入生成，而且由於自注意力始終都是在全局上計算的 (patch 和 patch 間做自注意力)，所以時間複雜度是 quadratic computation complexity。&lt;/p&gt;
&lt;p&gt;Swin Transformer 從小 patch 開始，並在更深的 Transformer layers 合併相鄰的 patches。&lt;/p&gt;
&lt;p&gt;有了這些 hierarchical feature maps，可以用在像是 FPN 或是 U-Net。&lt;/p&gt;
&lt;p&gt;一個 Swin Transformer 的關鍵設計因素是 shifted window。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/Swin-Transformer/fig2.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;透過 bridge 不同 layer 的 windows 來提供他們連接。&lt;/p&gt;
&lt;h2 id=&#34;method&#34;&gt;Method&lt;/h2&gt;
&lt;h3 id=&#34;overall-architecture&#34;&gt;Overall Architecture&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/Swin-Transformer/fig3.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Patch Merging
&lt;ul&gt;
&lt;li&gt;原本特徵圖是 H * W * C&lt;/li&gt;
&lt;li&gt;以上下 stride=2 行走，會得到四張 H/2 * W/2 * C&lt;/li&gt;
&lt;li&gt;concatenate 起來，變成 H/2 * W/2 * 4C&lt;/li&gt;
&lt;li&gt;做 linear，變成 H/2 * W/2 * 2C&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;swin-transformer-block&#34;&gt;Swin Transformer block&lt;/h4&gt;
&lt;p&gt;Swin Transformer 是透過把 Transformer block 中的 multi-head self attention(MSA) 換成基於 shifted windows 的 module 構成。&lt;/p&gt;
&lt;h3 id=&#34;shifted-window-based-self-attention&#34;&gt;Shifted Window based Self-Attention&lt;/h3&gt;
&lt;p&gt;標準的 Transformer 架構會算 global self-attention，計算所有 token 間彼此的關係，導致 quadratic complexity，使其不適用於需要大量 token 的許多 CV 問題&lt;/p&gt;
&lt;h4 id=&#34;self-attention-in-non-overlapped-windows&#34;&gt;Self-attention in non-overlapped windows&lt;/h4&gt;
&lt;p&gt;原來的圖片會以 non-overlapping 的方式切割。&lt;/p&gt;
&lt;p&gt;假設每個 windows 有 M * M 個 patches，然後一張圖像有 h * w 塊 patches，計算複雜度如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\Omega(MSA)=4hwC^2+2(hw)^2C$&lt;/li&gt;
&lt;li&gt;$\Omega(W-MSA)=4hwC^2+2M^2hwC$&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;shifted-window-partitioning-in-successive-blocks&#34;&gt;Shifted window partitioning in successive blocks&lt;/h4&gt;
&lt;p&gt;window-based self-attention module 缺乏了 windows 間彼此的連接，會限制模型能力。&lt;/p&gt;
&lt;p&gt;作者提出了一種 shifted window 的方法，保持 non-overlapping windows 的高效計算，同時引入 windows 間的連接。&lt;/p&gt;
&lt;p&gt;再兩個連續的 windows 間，會移動 $(⌊ \frac{M}{2} ⌋, ⌊ \frac{M}{2} ⌋)$&lt;/p&gt;
&lt;h4 id=&#34;efficient-batch-computation-for-shifted-configuration&#34;&gt;Efficient batch computation for shifted configuration&lt;/h4&gt;
&lt;p&gt;shifted window 有個問題是，會導致更多的 windows，從 $⌈ \frac{h}{M} ⌉ * ⌈ \frac{w}{M} ⌉$ 到 $(⌈ \frac{h}{M} ⌉+1) * (⌈ \frac{w}{M} ⌉+1)$，而且有些 window 會小於 M*M。&lt;/p&gt;
&lt;p&gt;這樣會導致無法把這些給壓成一個 batch 快速計算。&lt;/p&gt;
&lt;p&gt;一種 naive 的解法就是直接在外面加 zero padding，但會增加計算量，當 windows 數量較少時，計算量會變很可觀 (從 2 * 2 個 windows 變成 3 * 3 個 windows，增加了 2.25 倍)&lt;/p&gt;
&lt;p&gt;作者提出另外一種巧妙的做法，把一些部分挪移。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/Swin-Transformer/fig4.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;但現在有些 window 裡有多個不該相互做 attention 的部分，所以要用 mask 的方式計算。&lt;/p&gt;
&lt;p&gt;不同 windows，做 self-attention 後，把不相干的部分做的 attention 減去一個很大的數值，最後再過 softmax。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/Swin-Transformer/mask.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;上圖來自作者在 github 提供的可視化&lt;/p&gt;
&lt;p&gt;最後再把它挪回原本的位置。&lt;/p&gt;
&lt;h4 id=&#34;relative-position-bias&#34;&gt;Relative position bias&lt;/h4&gt;
&lt;p&gt;參考這個: &lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/qq_37541097/article/details/121119988&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.csdn.net/qq_37541097/article/details/121119988&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;architecture-variants&#34;&gt;Architecture Variants&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;window size 預設是 M = 7&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;query dimension of each head 是 d = 32&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;expansion layer of each MLP is $\alpha$ = 4&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;C 是 first stage 的 hidden layers 的 channel numbers&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Swin-T&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;C = 96&lt;/li&gt;
&lt;li&gt;layer numbers = {2, 2, 6, 2}&lt;/li&gt;
&lt;li&gt;大小和計算量是 Base 的大約 0.25 倍&lt;/li&gt;
&lt;li&gt;complexity 接近 ResNet-50&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Swin-S&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;C = 96&lt;/li&gt;
&lt;li&gt;layer numbers = {2, 2, 18, 2}&lt;/li&gt;
&lt;li&gt;大小和計算量是 Base 的大約 0.5 倍&lt;/li&gt;
&lt;li&gt;complexity 接近 ResNet-101&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Swin-B&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;C = 128&lt;/li&gt;
&lt;li&gt;layer numbers = {2, 2, 18, 2}&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Swin-L&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;C = 192&lt;/li&gt;
&lt;li&gt;layer numbers = {2, 2, 18, 2}&lt;/li&gt;
&lt;li&gt;大小和計算量是 Base 的大約 2 倍&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;experiments&#34;&gt;Experiments&lt;/h2&gt;
&lt;h3 id=&#34;image-classification-on-imagenet-1k&#34;&gt;Image Classification on ImageNet-1K&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/Swin-Transformer/table1.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;object-detection-on-coco&#34;&gt;Object Detection on COCO&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/Swin-Transformer/table2.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;semantic-segmentation-on-ade20k&#34;&gt;Semantic Segmentation on ADE20K&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/Swin-Transformer/table3.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;ablation-study&#34;&gt;Ablation Study&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/Swin-Transformer/table4.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;基於 self-attention 的 shifted window 是 Swin Transformer 關鍵部分，被顯示出他在 CV 領域有效率且有效，並期望未來把它應用在 NLP。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>電路學 - II</title>
        <link>https://roykesydon.github.io/Blog/p/%E9%9B%BB%E8%B7%AF%E5%AD%B8-ii/</link>
        <pubDate>Mon, 10 Apr 2023 00:00:54 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/%E9%9B%BB%E8%B7%AF%E5%AD%B8-ii/</guid>
        <description>&lt;h2 id=&#34;分析方法&#34;&gt;分析方法&lt;/h2&gt;
&lt;h3 id=&#34;節點分析-nodal-analysis&#34;&gt;節點分析 (Nodal Analysis)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;解節點電壓
&lt;ol&gt;
&lt;li&gt;選取一個節點做為參考節點 (reference node) 或已知節點 (datum node)，其他節點的電壓相對於它
&lt;ul&gt;
&lt;li&gt;假設它電位為 0，稱為 ground&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;把 KCL 用在剩下的 n-1 個參考節點 (假設電流方向，可以隨便假設，只要一致，不要兩端電流都流入同個電阻)&lt;/li&gt;
&lt;li&gt;求解聯立方程式，得到各節點電壓&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;包含電壓源的節點分析-nodal-analysis-with-voltage-sources&#34;&gt;包含電壓源的節點分析 (Nodal Analysis with Voltage Sources)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;如果電壓源連接於兩個非參考節點間，可以把電壓源和這兩個節點和與其並聯的元件看做一個超節點 (supernode) 或廣義節點 (generalized node)，解決無法知道流過電壓源的電流的問題
&lt;ul&gt;
&lt;li&gt;超節點的屬性
&lt;ul&gt;
&lt;li&gt;超節點內部的電壓源提供限制方程式&lt;/li&gt;
&lt;li&gt;超節點本身沒電壓&lt;/li&gt;
&lt;li&gt;超節點要同時用 KCL 和 KVL&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;網目分析-mesh-analysis&#34;&gt;網目分析 (Mesh Analysis)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;只能適用平面電路 (planer circuit)，不能用在非平面電路 (nonplaner circuit)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在一個平面上沒有交互連接的分支&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;網目 (Mesh)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;不包含子迴路的單一迴路&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;網目電流 (mesh current)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;流經網目的電流&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;決定網目電流步驟&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在 n 個網目中，指定 n 個網目電流&lt;/li&gt;
&lt;li&gt;對 n 個網目個別應用 KVL，把歐姆定律應用在網目電流上，以表示電壓&lt;/li&gt;
&lt;li&gt;求解 n 個聯立方程式，計算網目電流&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;包含電流源的網目分析-mesh-analysis-with-current-sources&#34;&gt;包含電流源的網目分析 (Mesh Analysis with Current Sources)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;如果有兩個 Mesh 共用同一個電流源，會形成超網目 (supermesh)，把公用的電流源還有串聯的元件給移除掉&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;視察法&#34;&gt;視察法&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;待補&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;節點分析-vs-網目分析&#34;&gt;節點分析 vs 網目分析&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;節點比網目少選節點分析，反之也是&lt;/li&gt;
&lt;li&gt;要求電壓節點，求電流網目&lt;/li&gt;
&lt;li&gt;可以用一種驗證另一種的結果&lt;/li&gt;
&lt;li&gt;有些特殊問題只能用其中一種方法&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;直流電晶體電路&#34;&gt;直流電晶體電路&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;電子產品中的基本元件有三端主動元件&amp;ndash;電晶體 (transistor)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;種類
&lt;ul&gt;
&lt;li&gt;雙極性接面電晶體 (biopolar junction transistor, BJT)
&lt;ul&gt;
&lt;li&gt;本節只討論這種&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;場效電晶體 (field-effect transistor, FET)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;BJT 類型&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;NPN&lt;/li&gt;
&lt;li&gt;PNP&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Part&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;射極 (emitter, E)&lt;/li&gt;
&lt;li&gt;基極 (base, B)&lt;/li&gt;
&lt;li&gt;集極 (collector, C)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;工作模式&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;作用
&lt;ul&gt;
&lt;li&gt;$I_C=\alpha I_E$
&lt;ul&gt;
&lt;li&gt;$\alpha$ 是共基極電流增益 (common-base current gain)，表示射極注入的電子被基極收集的比例&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;$I_C=\beta I_B$
&lt;ul&gt;
&lt;li&gt;$\beta$ 是共射極電流增益 (common-emitter current gain)&lt;/li&gt;
&lt;li&gt;$I_E=(1+\beta) I_B$&lt;/li&gt;
&lt;li&gt;$\beta=\frac{\alpha}{1-\alpha}$&lt;/li&gt;
&lt;li&gt;因為 $\beta$ 很大，一個小的基極電流可以控制大電流的輸出，因此，雙極性電晶體可以當作放大器&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;截止&lt;/li&gt;
&lt;li&gt;飽和&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;電路理論&#34;&gt;電路理論&lt;/h2&gt;
&lt;h3 id=&#34;線性性質-linear-property&#34;&gt;線性性質 (Linear Property)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;線性&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;齊次性
&lt;ul&gt;
&lt;li&gt;輸入 ( 激發 excitation) 乘以一個常數，輸出 ( 響應 response) 也會乘以相同的常數&lt;/li&gt;
&lt;li&gt;$kiR=kv$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;可加性
&lt;ul&gt;
&lt;li&gt;輸入總和的 response 等於個別輸入的 response 的總和&lt;/li&gt;
&lt;li&gt;$v=(i_1+i_2)R=i_1R+i_2R=v_1+v_2$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;因此稱電阻是一個線性元件，因為電阻、電壓、電流的關係滿足齊次性和可加性&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果電路滿足可加性和齊次性，稱此電路為線性電路&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;線性電路是輸出與輸入為線性關係的電路&lt;/li&gt;
&lt;li&gt;組成
&lt;ul&gt;
&lt;li&gt;線性元件&lt;/li&gt;
&lt;li&gt;線性相依電源&lt;/li&gt;
&lt;li&gt;獨立電源&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;重疊-superposition&#34;&gt;重疊 (Superposition)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;有兩個或更多的獨立電源時，除了節點和網目分析，可以求各獨立源對變數的貢獻，最後相加起來，這就是重疊&lt;/li&gt;
&lt;li&gt;重疊定理
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;在一個線性電路中，跨接於元件上的電壓(流經元件的電流) = 每個獨立電源單獨作用於該元件二端的電壓(單獨流經該元件的電流)的代數和&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;注意事項&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;同一時間只考慮一個獨立電源，把其他的電壓源當作 0 V(短路)、電流源當作 0 A(開路)&lt;/li&gt;
&lt;li&gt;相依電源受電路變數控制，保持不變&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;步驟&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;保留一個獨立電源，算它的輸出(電壓或電流)&lt;/li&gt;
&lt;li&gt;對每個電源做步驟 1&lt;/li&gt;
&lt;li&gt;把每個獨立電源的貢獻相加&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;電源變換-source-transformation&#34;&gt;電源變換 (Source Transformation)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;把電阻並聯的電流源和電阻串聯的電壓源做轉換(或反過來)
&lt;ul&gt;
&lt;li&gt;電源變換條件
&lt;ul&gt;
&lt;li&gt;$V_s=i_sR$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;也是用相依電源，但也要遵守條件&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;戴維寧定理-thevenins-theorem&#34;&gt;戴維寧定理 (Thevenin&amp;rsquo;s Theorem)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;常有一種情境，電路種有一個特殊的元件是可變的，又稱負載 (load)，比如插座可能連接不同家電所組成的負載，而每當 load 改變，就要重新分析電路。戴維寧定理可以把固定的部分換成一個等效電路&lt;/li&gt;
&lt;li&gt;戴維寧定理
&lt;ul&gt;
&lt;li&gt;線性二端電路可被由電壓源 $V_{Th}$ 和電阻 $R_{Th}$ 串聯所組成的戴維寧等效電路 (Thevenin equivalent circuit) 取代
&lt;ul&gt;
&lt;li&gt;$V_{Th}$ 是二端的開路電壓&lt;/li&gt;
&lt;li&gt;$R_{Th}$ 是關閉獨立電源後，端點上的輸入或等效電阻
&lt;ul&gt;
&lt;li&gt;關閉所有獨立電源(根據 電壓/電流 來 短路/開路)，但考慮相依電源&lt;/li&gt;
&lt;li&gt;$R_{Th}$ 有可能求出負值，這代表該電路提供功率，裡面有相依電源，雖然不可能出現在被動元件上，但等效電路是主動元件&lt;/li&gt;
&lt;li&gt;假設外接一個電壓源，求外面的 v 和 i 即可算出 $R_{Th}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;諾頓定理-nortons-theorem&#34;&gt;諾頓定理 (Norton&amp;rsquo;s Theorem)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;和戴維寧定理很像，但是等效電路改成電流源和並聯的電阻，實際上，根據電源變換，可以知道諾頓定理和戴維寧定理的等效電阻相等&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$R_N=R_{Th}$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$I_N=\frac{V_{Th}}{R_{Th}}$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;計算戴維寧或諾頓等效電路，要先求 $v_{oc}$、$i_{sc}$、$R_{in}$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;求出兩個就可以算第三個&lt;/li&gt;
&lt;li&gt;$V_{Th}=v_{oc}$
&lt;ul&gt;
&lt;li&gt;$v_{oc}$ 是 a 和 b 兩端的開路電壓&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;$I_N=i_{sc}$
&lt;ul&gt;
&lt;li&gt;$i_{sc}$ 是 a 和 b 兩端的短路電流&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;$R_{Th}=\frac{v_{oc}}{i_{sc}}=R_N$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;最大功率轉移-maximum-power-transfer&#34;&gt;最大功率轉移 (Maximum Power Transfer)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;轉移到 load 的功率是
&lt;ul&gt;
&lt;li&gt;$p=i^2R_{L}=(\frac{V_{Th}}{R_{Th}+R_L})^2R_L$&lt;/li&gt;
&lt;li&gt;最大值出現在 $R_L=R_{Th}$
&lt;ul&gt;
&lt;li&gt;最大功率定理 (maximum power theorem)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;$p_{max}=\frac{V_{Th}^2}{4R_{Th}}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;電源建模-source-modeling&#34;&gt;電源建模 (Source Modeling)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;實際的電源非理想電源
&lt;ul&gt;
&lt;li&gt;電壓源有串聯的內部電阻 (internal resistance)
&lt;ul&gt;
&lt;li&gt;下面稱為 $R_s$&lt;/li&gt;
&lt;li&gt;要理想要趨近於 0&lt;/li&gt;
&lt;li&gt;若不連接 load (開路)，$v_{oc}=v_s$
&lt;ul&gt;
&lt;li&gt;$v_s$ 可以看做無負載源電壓 (unloaded source voltage)，連接 load 會使端電壓下降，這就是負載效應 (loading effect)&lt;/li&gt;
&lt;li&gt;$R_L$ 越大會越接近理想電壓&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;量測 $v_s$ 和內部電阻
&lt;ul&gt;
&lt;li&gt;量開路電壓
&lt;ul&gt;
&lt;li&gt;$v_s=v_{oc}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;load 端連接可變電阻，調到 $v_L=v_{oc}/2$&lt;/li&gt;
&lt;li&gt;此時 $R_L=R_{Th}=R_s$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;電流源有並聯的電源電阻 (source resistance)
&lt;ul&gt;
&lt;li&gt;要理想要趨近於無窮大&lt;/li&gt;
&lt;li&gt;$R_L$ 越小越接近理想電源&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;電阻量測-resistance-measurement&#34;&gt;電阻量測 (Resistance Measurement)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;惠斯登電橋 (Wheatstone bridge)
&lt;ul&gt;
&lt;li&gt;平衡電橋 (balanced bridge)&lt;/li&gt;
&lt;li&gt;非平衡電橋 (unbalanced bridge)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>STM32 UART 實驗</title>
        <link>https://roykesydon.github.io/Blog/p/stm32-uart-%E5%AF%A6%E9%A9%97/</link>
        <pubDate>Sun, 09 Apr 2023 01:32:54 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/stm32-uart-%E5%AF%A6%E9%A9%97/</guid>
        <description>&lt;h2 id=&#34;介紹&#34;&gt;介紹&lt;/h2&gt;
&lt;p&gt;試用 STM32 UART 功能&lt;/p&gt;
&lt;p&gt;會透過 RealTerm 和 STM32L476RG 溝通，並用 DMA 接收訊息&lt;/p&gt;
&lt;p&gt;根據 User manual，USART2 預設會連接 ST-LINK，要連接外部設備的話要修改 solder bridge&lt;/p&gt;
&lt;h2 id=&#34;ioc-設置&#34;&gt;ioc 設置&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Connectivity 可以設置 USART2&lt;/li&gt;
&lt;li&gt;mode 從 disable 改選 Asynchronous&lt;/li&gt;
&lt;li&gt;Parameters Settings 可以設置各種資訊
&lt;ul&gt;
&lt;li&gt;Baud Rate&lt;/li&gt;
&lt;li&gt;Word Length&lt;/li&gt;
&lt;li&gt;Parity&lt;/li&gt;
&lt;li&gt;Stop Bits&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;DMA Setting
&lt;ul&gt;
&lt;li&gt;Add 一個 RX
&lt;ul&gt;
&lt;li&gt;Mode 改成 circular，並打開 memory 的 increment address
&lt;ul&gt;
&lt;li&gt;increment address 是因為資料是用 array 存&lt;/li&gt;
&lt;li&gt;circular 是當資料滿了後，會回到 zero position&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;NVIC Setting
&lt;ul&gt;
&lt;li&gt;設置 DMA 應該就會自動設置一個 interrupt，檢查一下&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;程式碼&#34;&gt;程式碼&lt;/h2&gt;
&lt;p&gt;發送&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;uint8_t&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;myTxData&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;13&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Hello World&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\r\n&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;HAL_UART_Transmit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;huart2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;myTxData&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;13&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;接收&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;UART_HandleTypeDef&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;huart2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// generated code
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;uint8_t&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;myRxData&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;20&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;];&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;HAL_UART_Receive_DMA&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;huart2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;myRxData&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;20&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// 在 Init 後，在 main 中執行一次就好
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;interrupt&lt;/p&gt;
&lt;p&gt;在 hal_uart.c 有&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;__weak&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;HAL_UART_RxCpltCallback&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;UART_HandleTypeDef&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;huart&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;cm&#34;&gt;/* Prevent unused argument(s) compilation warning */&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;UNUSED&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;huart&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;cm&#34;&gt;/* NOTE : This function should not be modified, when the callback is needed,
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cm&#34;&gt;            the HAL_UART_RxCpltCallback can be implemented in the user file.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cm&#34;&gt;   */&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;當 DMA 滿了就會呼叫這個 function&lt;/p&gt;
&lt;h2 id=&#34;實驗&#34;&gt;實驗&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;HAL_UART_RxCpltCallback&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;UART_HandleTypeDef&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;huart&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;cm&#34;&gt;/* Prevent unused argument(s) compilation warning */&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;UNUSED&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;huart&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;cm&#34;&gt;/* NOTE : This function should not be modified, when the callback is needed,
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cm&#34;&gt;            the HAL_UART_RxCpltCallback can be implemented in the user file.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cm&#34;&gt;   */&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;HAL_UART_Transmit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;huart2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;myRxData&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;20&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;當 20 個 Bytes 儲存滿了就回傳資訊給電腦&lt;/p&gt;
&lt;h3 id=&#34;realterm&#34;&gt;RealTerm&lt;/h3&gt;
&lt;h4 id=&#34;display&#34;&gt;Display&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;勾選 Half Duplex
&lt;ul&gt;
&lt;li&gt;發送的訊息會顯示綠色，接收的是黃色&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;port&#34;&gt;Port&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;設置 Baud 和其他有的沒的&lt;/li&gt;
&lt;li&gt;選 open&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;send&#34;&gt;Send&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;EOL 可以勾選 CRLF&lt;/li&gt;
&lt;li&gt;打一些文字後按 Send ASCII&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;結果&#34;&gt;結果&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/embedding/stm32-uart/result.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/Roykesydon/STM32-Playground/tree/main/STM32-UART/uart_test&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;程式碼&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>電路學 - I</title>
        <link>https://roykesydon.github.io/Blog/p/%E9%9B%BB%E8%B7%AF%E5%AD%B8-i/</link>
        <pubDate>Sun, 09 Apr 2023 00:00:54 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/%E9%9B%BB%E8%B7%AF%E5%AD%B8-i/</guid>
        <description>&lt;h2 id=&#34;基本概念&#34;&gt;基本概念&lt;/h2&gt;
&lt;h3 id=&#34;常見名詞&#34;&gt;常見名詞&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;電路 (electric circuit)&lt;/li&gt;
&lt;li&gt;元件 (element)
&lt;ul&gt;
&lt;li&gt;電路組成的部分&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;單位系統&#34;&gt;單位系統&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;國際單位制 (International System of Units ,SI)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;電荷與電流&#34;&gt;電荷與電流&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;電荷 (electric charge)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;組成原子的基本物質&lt;/li&gt;
&lt;li&gt;庫倫 (C)&lt;/li&gt;
&lt;li&gt;電荷守恆定律 (law of conservation of charge)
&lt;ul&gt;
&lt;li&gt;電荷不能被創造、破壞，只能轉移，系統中的電荷總數不變。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;電流 (electric current)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;電荷的時間變化率&lt;/li&gt;
&lt;li&gt;電流是電荷的移動，而且有方向性&lt;/li&gt;
&lt;li&gt;安培 (A)&lt;/li&gt;
&lt;li&gt;公式
&lt;ul&gt;
&lt;li&gt;$i \triangleq \frac{dq}{dt}$&lt;/li&gt;
&lt;li&gt;$Q \triangleq \int_{t_0}^{t}i\text{ }dt$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;直流電 (direct current, dc)
&lt;ul&gt;
&lt;li&gt;恆定常數的電流&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;交流電 (alternating current, ac)
&lt;ul&gt;
&lt;li&gt;隨著時間以正弦波變化的電流&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;電壓&#34;&gt;電壓&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;電動勢 (electromotive force, emf)
&lt;ul&gt;
&lt;li&gt;驅動導體內的電子往某方向移動&lt;/li&gt;
&lt;li&gt;電壓 (voltage)、電位差 (potential difference)&lt;/li&gt;
&lt;li&gt;伏特 (V)&lt;/li&gt;
&lt;li&gt;$v_{ab}\triangleq\frac{dw}{dq}$
&lt;ul&gt;
&lt;li&gt;單位電荷從 b 移動到 a 需要做的功&lt;/li&gt;
&lt;li&gt;$w$ 是能量，單位是焦耳(J)&lt;/li&gt;
&lt;li&gt;$q$ 是電荷，單位是庫倫(C)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;壓降 (voltage drop)、壓升 (voltage rise)&lt;/li&gt;
&lt;li&gt;直流電壓 (dc voltage)、交流電壓 (ac voltage)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;功率與能量&#34;&gt;功率與能量&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;消耗或吸收能量的時間變化率，單位是瓦特(walt, W)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;公式&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$p \triangleq\frac{dw}{dt}$&lt;/li&gt;
&lt;li&gt;$p=iv$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;被動符號規則 (passive sign convention)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;電流從電壓的正極流入元件 ($p=+vi$)，表示該元件吸收功率&lt;/li&gt;
&lt;li&gt;電流從電壓的正極流出元件 ($p=-vi$)，表示該元件供應功率&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;能量守恆定律 (law of conservation of energy)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;電路中任何時刻的功率總和為 0&lt;/li&gt;
&lt;li&gt;$\sum p=0$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;電路元件&#34;&gt;電路元件&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;被動元件 (passive element)
&lt;ul&gt;
&lt;li&gt;不具備產生能量的能力&lt;/li&gt;
&lt;li&gt;電阻器 (resistor)、電容器 (capacitor)、電感器 (inductor)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;主動元件 (active element)
&lt;ul&gt;
&lt;li&gt;具備產生能量的能力&lt;/li&gt;
&lt;li&gt;發電機 (generator)、電池 (battery)、運算放大器 (operational amplifier)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;電源&#34;&gt;電源&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;電壓源、電流源
&lt;ul&gt;
&lt;li&gt;提供穩定電壓產生電流、提供穩定電流產生電壓&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;獨立電源
&lt;ul&gt;
&lt;li&gt;獨立電源提供指定電壓或電流的主動元件，與電路中其他元件無關。&lt;/li&gt;
&lt;li&gt;電池和發電機可被當作近似理想的電壓源&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;相依電源
&lt;ul&gt;
&lt;li&gt;提供的電壓或電流受另一個電流或電壓控制的主動元件&lt;/li&gt;
&lt;li&gt;類型
&lt;ul&gt;
&lt;li&gt;電壓控制電壓源 (voltage-controlled voltage source, VCVS)&lt;/li&gt;
&lt;li&gt;電流控制電壓源 (current-controlled voltage source, CCVS)&lt;/li&gt;
&lt;li&gt;電壓控制電流源 (voltage-controlled current source, VCCS)&lt;/li&gt;
&lt;li&gt;電流控制電流源 (current-controlled current source, CCCS)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;基本定律&#34;&gt;基本定律&lt;/h2&gt;
&lt;h3 id=&#34;歐姆定律-ohms-law&#34;&gt;歐姆定律 (Ohm&amp;rsquo;s Law)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;一般材料具備阻止電荷流通的特性，稱為電阻 (resistance)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;均勻截面積下，$R=\rho \frac{l}{A}$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\rho$ 是材料的電阻率 (resistivity)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;電路中抑制電流的材料稱為電阻器 (resistor)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$v=iR$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;短路 (short circuit)、開路 (open circuit)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;短路: 電壓是 0，電流可能是任意值，電阻值接近 0&lt;/li&gt;
&lt;li&gt;開路: 電壓可能是任意值，電流是 0，電阻值接近無限大&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;固定電阻、可變電阻&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;阻值可調與否&lt;/li&gt;
&lt;li&gt;常用的可變電阻是電位器 (potentiometer)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;不是所有電阻都遵守歐姆定律&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;遵守歐姆定律的稱為線性電阻 (linear resistor)，反之則為非線性電阻 (nonlinear resistor)，阻值隨電流變化&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;電導 (conductance)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;電阻 R 的倒數&lt;/li&gt;
&lt;li&gt;元件導通電流的能力&lt;/li&gt;
&lt;li&gt;$G=\frac{1}{R}=\frac{i}{v}$&lt;/li&gt;
&lt;li&gt;單位姆歐 (mho, $\mho$) 或西門子 (siemens, S)&lt;/li&gt;
&lt;li&gt;$1 S = 1 \mho = 1 A/V$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;node-branches-and-loops&#34;&gt;Node, Branches, and Loops&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;分枝 (Branch)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;任意的兩端元件，比如電壓源、電阻&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;節點 (Node)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;指連接二個或多個分支的接點&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;迴路 (Loop)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;是電路中的任一封閉路徑&lt;/li&gt;
&lt;li&gt;從一個節點開始，經過一組節點，最後回到一開始的節點，途中每個節點只經過一次&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;串聯&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;多個元件共享單一節點&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;並連&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;多個元件連接到相同的兩個節點&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;獨立迴路 (independent loop)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;至少包含一個不屬於其他獨立迴路的 branch&lt;/li&gt;
&lt;li&gt;$b=l+n-1$
&lt;ul&gt;
&lt;li&gt;b 是 branch，l 是獨立迴路，n 是 node&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;克希荷夫定律-kirchhoffs-laws&#34;&gt;克希荷夫定律 (Kirchhoff&amp;rsquo;s Laws)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Kirchhoff&amp;rsquo;s current law (KCL)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;流入任一 node 或封閉邊界的電流總和為 0
&lt;ul&gt;
&lt;li&gt;或是說流入某一節點的電流和等於流出的電流和&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;$\sum_{n=1}^{N}i_n=0$
&lt;ul&gt;
&lt;li&gt;$N$ 是連到 node 的 branch 數&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Kirchhoff&amp;rsquo;s voltage law (KVL)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一條封閉路徑(或迴路)中的電壓總和為零
&lt;ul&gt;
&lt;li&gt;或是說 voltage drop 的總和 = voltage rise 的總和&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;$\sum_{m=1}^{M}n_m=0$
&lt;ul&gt;
&lt;li&gt;$M$ 是迴路中的 branch 數&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;串並聯電阻&#34;&gt;串並聯電阻&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;串聯&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$R_{eq}=\sum_{n=1}^N R_n$
&lt;ul&gt;
&lt;li&gt;$R_{eq}$ 是等效電阻 (equivalent resistance)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;分壓定理 (principle of voltage division)
&lt;ul&gt;
&lt;li&gt;電壓和各電阻的阻值成正比，阻值越大，壓降越大&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;分壓器 (voltage divider)&lt;/li&gt;
&lt;li&gt;$v_1=\frac{R_1}{R_1+R_2}v$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;並聯&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\frac{1}{R_{eq}}=\frac{1}{R_1}+\frac{1}{R_2}+&amp;hellip;+\frac{1}{R_N}$
&lt;ul&gt;
&lt;li&gt;$R_{eq}$ 永遠小於並聯電阻中最小的電阻值&lt;/li&gt;
&lt;li&gt;$G_{eq} = G_{1}+G_2+&amp;hellip;+G_N$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;分流定理 (principle of current division)
&lt;ul&gt;
&lt;li&gt;各分支電流與電阻值成反比&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;分流器 (current divider)&lt;/li&gt;
&lt;li&gt;$i_1=\frac{R_2}{R_1+R_2}i$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;y---delta-轉換-wye-delta-transformations&#34;&gt;Y - $\Delta$ 轉換 (Wye-Delta Transformations)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;遇到電阻不是串聯也不是並聯的情況，要如何轉換&lt;/li&gt;
&lt;li&gt;有時候把 Y 型網路和 $\Delta$ 型網路相互轉換會比較好算&lt;/li&gt;
&lt;li&gt;Y 型網路 = T 型網路&lt;/li&gt;
&lt;li&gt;$\Delta$ 網路 = $\Pi$ 網路&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;delta---y-轉換-delta-to-wye-conversion&#34;&gt;$\Delta$ - Y 轉換 (Delta to Wye conversion)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Y 網路的每個電阻是 $\Delta$ 中的兩個相鄰電阻的相乘除以 $\Delta$ 中的三個電阻總和&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;y---delta-轉換-wye-to-delta-conversion&#34;&gt;Y - $\Delta$ 轉換 (Wye to Delta conversion)&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$\Delta$ 網路的每個電阻是 Y 中的兩兩電阻的相乘總和除以 Y 中的對角電阻&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;平衡&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;條件
&lt;ul&gt;
&lt;li&gt;$R_1=R_2=R_3=R_Y$&lt;/li&gt;
&lt;li&gt;$R_a=R_b=R_c=R_{\Delta}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;結果
&lt;ul&gt;
&lt;li&gt;$R_Y=\frac{R_\Delta}{3}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>STM32 GPIO 實驗</title>
        <link>https://roykesydon.github.io/Blog/p/stm32-gpio-%E5%AF%A6%E9%A9%97/</link>
        <pubDate>Sun, 02 Apr 2023 01:32:54 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/stm32-gpio-%E5%AF%A6%E9%A9%97/</guid>
        <description>&lt;h2 id=&#34;目的&#34;&gt;目的&lt;/h2&gt;
&lt;p&gt;本文會試用 GPIO output / input / interrupt&lt;/p&gt;
&lt;h2 id=&#34;gpio-架構&#34;&gt;GPIO 架構&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/embedding/stm32-gpio/gpio-structure.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;output-介紹&#34;&gt;Output 介紹&lt;/h2&gt;
&lt;p&gt;在 ioc 那邊選個 pin，選 GPIO_Output&lt;/p&gt;
&lt;p&gt;在左邊欄位 System Core 選擇 GPIO&lt;/p&gt;
&lt;p&gt;有五個欄位可以設定&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;GPIO output level&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;初始電位&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;GPIO mode&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;push pull 和 open drain
&lt;ul&gt;
&lt;li&gt;位於架構圖下方那部分，push pull 可以用 PMOS 和 NMOS 來得到高低電位，open drain 會 disable PMOS，讓你可以在外面自己接上拉電阻&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;GPIO Pull-up/Pull-down&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Maximum output speed&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;User Label&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;用完記得 ctrl+s 讓他 generate code&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cm&#34;&gt;/*Configure GPIO pin : PtPin */&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;GPIO_InitStruct&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Pin&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;RED_LED_Pin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;GPIO_InitStruct&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Mode&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;GPIO_MODE_OUTPUT_PP&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;GPIO_InitStruct&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Pull&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;GPIO_NOPULL&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;GPIO_InitStruct&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Speed&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;GPIO_SPEED_FREQ_LOW&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;HAL_GPIO_Init&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;RED_LED_GPIO_Port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;GPIO_InitStruct&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cm&#34;&gt;/*Configure GPIO pin Output Level */&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;HAL_GPIO_WritePin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;RED_LED_GPIO_Port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;RED_LED_Pin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;GPIO_PIN_RESET&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;HAL_GPIO_WritePin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;RED_LED_GPIO_Port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;RED_LED_Pin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;GPIO_PIN_RESET&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// 低電位
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;HAL_GPIO_WritePin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;RED_LED_GPIO_Port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;RED_LED_Pin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;GPIO_PIN_SET&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// 高電位
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;HAL_Delay&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;//等一秒
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;HAL_GPIO_TogglePin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;RED_LED_GPIO_Port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;RED_LED_Pin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;根據架構圖左側，你可以透過修改 BSRR 來修改 ODR，達到修改輸出的效果，請見 Reference Manuals，實際上 &lt;code&gt;HAL_GPIO_WritePin&lt;/code&gt; 也是這樣實現的&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;HAL_GPIO_WritePin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;GPIO_TypeDef&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;GPIOx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;uint16_t&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;GPIO_Pin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;GPIO_PinState&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;PinState&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;cm&#34;&gt;/* Check the parameters */&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nf&#34;&gt;assert_param&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;IS_GPIO_PIN&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;GPIO_Pin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;));&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nf&#34;&gt;assert_param&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;IS_GPIO_PIN_ACTION&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;PinState&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;));&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;PinState&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;!=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;GPIO_PIN_RESET&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;GPIOx&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;BSRR&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;uint32_t&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;GPIO_Pin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;else&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;GPIOx&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;BRR&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;uint32_t&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;GPIO_Pin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;input-介紹&#34;&gt;Input 介紹&lt;/h2&gt;
&lt;p&gt;看架構圖上方，用 Schmitt trigger 取得高低電位資料，他有 upper threshold 和 lower threshold，而不是用 single threshold&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cm&#34;&gt;/*Configure GPIO pin : PtPin */&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;GPIO_InitStruct&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Pin&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;GREEN_LED_INPUT_Pin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;GPIO_InitStruct&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Mode&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;GPIO_MODE_INPUT&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;GPIO_InitStruct&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Pull&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;GPIO_NOPULL&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;HAL_GPIO_Init&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;GREEN_LED_INPUT_GPIO_Port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;GPIO_InitStruct&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;uint8_t&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;green_led_input&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;HAL_GPIO_ReadPin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;GREEN_LED_INPUT_GPIO_Port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;GREEN_LED_INPUT_Pin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;interrupt&#34;&gt;Interrupt&lt;/h2&gt;
&lt;p&gt;ioc 選個 pin，設定 GPIO_EXTI，這邊我選 B1(PC13)，也就是開發版上的藍色按鈕&lt;/p&gt;
&lt;p&gt;可以選 GPIO mode，這邊選 Falling Edge Trigger，值得一提的是他的設計是上拉電阻，所以這樣不是放開後觸發，是按下後觸發。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/embedding/stm32-gpio/b1.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;ioc 的 System Core 的 NVIC 還要把 EXTI line[15:10] interrupts 給 enabled，然後 Code generation 打開 Generate IRQ handler，還有 Call HAL handler。&lt;/p&gt;
&lt;p&gt;在 &lt;code&gt;stm32l4xx_it.c&lt;/code&gt; 裡，
現在會有&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;EXTI15_10_IRQHandler&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;cm&#34;&gt;/* USER CODE BEGIN EXTI15_10_IRQn 0 */&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;cm&#34;&gt;/* USER CODE END EXTI15_10_IRQn 0 */&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;HAL_GPIO_EXTI_IRQHandler&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;B1_Pin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;cm&#34;&gt;/* USER CODE BEGIN EXTI15_10_IRQn 1 */&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;cm&#34;&gt;/* USER CODE END EXTI15_10_IRQn 1 */&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;這兩行各別是因為我們剛剛開的功能生的&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;HAL_GPIO_EXTI_IRQHandler&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;uint16_t&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;GPIO_Pin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;cm&#34;&gt;/* EXTI line interrupt detected */&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;__HAL_GPIO_EXTI_GET_IT&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;GPIO_Pin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;!=&lt;/span&gt; &lt;span class=&#34;mh&#34;&gt;0x00u&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nf&#34;&gt;__HAL_GPIO_EXTI_CLEAR_IT&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;GPIO_Pin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nf&#34;&gt;HAL_GPIO_EXTI_Callback&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;GPIO_Pin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;__weak&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;HAL_GPIO_EXTI_Callback&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;uint16_t&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;GPIO_Pin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;cm&#34;&gt;/* Prevent unused argument(s) compilation warning */&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;UNUSED&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;GPIO_Pin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;cm&#34;&gt;/* NOTE: This function should not be modified, when the callback is needed,
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cm&#34;&gt;           the HAL_GPIO_EXTI_Callback could be implemented in the user file
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cm&#34;&gt;   */&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;__weak 代表有同名 function 的話，就會採用沒 __weak prefix 的&lt;/p&gt;
&lt;p&gt;所以我們可以在 gpio.c 放下面的程式碼&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;#include&lt;/span&gt; &lt;span class=&#34;cpf&#34;&gt;&amp;lt;stdbool.h&amp;gt;&lt;/span&gt;&lt;span class=&#34;cp&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;HAL_GPIO_EXTI_Callback&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;uint16_t&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;GPIO_Pin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;GPIO_Pin&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;B1_Pin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;){&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;static&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;bool&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;prev_val&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;prev_val&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;){&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nf&#34;&gt;HAL_GPIO_WritePin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;RED_LED_GPIO_Port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;RED_LED_Pin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;GPIO_PIN_SET&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;prev_val&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;else&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nf&#34;&gt;HAL_GPIO_WritePin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;RED_LED_GPIO_Port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;RED_LED_Pin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;GPIO_PIN_RESET&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;prev_val&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;實驗&#34;&gt;實驗&lt;/h2&gt;
&lt;p&gt;設定兩個輸入，一個輸出，一個 interrupt&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;當按下按鈕時，切換紅色 LED 的亮滅，並且讓板子上的綠色 LED 輸出和紅色 LED 相反的結果&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;B1(PC13、藍色按鈕) 按下去的時候，會發出 interrupt，並讓 RED_LED(PC10) 輸出和上次相反的電位，讓麵包版上的紅色 LED 亮滅，正極那邊接一條杜邦線給 GREEN_LED_INPUT (PC12)，並且 LD2(PA5、板子上的綠色 LED) 會輸出和紅色 LED 相反的結果。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/embedding/stm32-gpio/result1.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/embedding/stm32-gpio/result2.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/Roykesydon/STM32-Playground/tree/main/STM32-GPIO/gpio_testing&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;程式碼&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>STM32CubeIDE 基本開發使用</title>
        <link>https://roykesydon.github.io/Blog/p/stm32cubeide-%E5%9F%BA%E6%9C%AC%E9%96%8B%E7%99%BC%E4%BD%BF%E7%94%A8/</link>
        <pubDate>Sun, 02 Apr 2023 00:32:54 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/stm32cubeide-%E5%9F%BA%E6%9C%AC%E9%96%8B%E7%99%BC%E4%BD%BF%E7%94%A8/</guid>
        <description>&lt;h2 id=&#34;使用的板子&#34;&gt;使用的板子&lt;/h2&gt;
&lt;p&gt;STM32L476RG&lt;/p&gt;
&lt;h2 id=&#34;開發文件&#34;&gt;開發文件&lt;/h2&gt;
&lt;p&gt;開發前需要先去 ST 官網，根據你的板子載四個重要文件&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Datasheet


        &lt;embed src=&#34;https://roykesydon.github.io/Blog/Blog/pdf/embedding/stm32cubeide/block-diagram.pdf&#34; type=&#34;application/pdf&#34; style=&#34;width:100%;height:50vh&#34;&gt;
    
上圖是其中的 block diagram&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Reference Manuals&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Programming Manuals&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Schematic&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/embedding/stm32cubeide/IMG_2389.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;創建-project&#34;&gt;創建 project&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;File -&amp;gt; New -&amp;gt; STM32 Project&lt;/li&gt;
&lt;li&gt;Board Selector 搜索 NUCLEO-L476RG，選取並 Next&lt;/li&gt;
&lt;li&gt;設置 Project Name，其他不動，Next&lt;/li&gt;
&lt;li&gt;Copy only the necessary library files，Finish&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;ioc&#34;&gt;ioc&lt;/h2&gt;
&lt;p&gt;專案會有個 .ioc 檔，可以透過 GUI 生成設定 pin 的程式碼&lt;/p&gt;
&lt;p&gt;建議 Project Manager 的 Code Generator 勾選 Generate peripheral initialization as a pair &amp;lsquo;.c/.h&amp;rsquo; files per peripheral，開發起來比較方便&lt;/p&gt;
&lt;h2 id=&#34;compile&#34;&gt;Compile&lt;/h2&gt;
&lt;p&gt;點選上面的 hammer&lt;/p&gt;
&lt;h2 id=&#34;clock-configuration&#34;&gt;Clock Configuration&lt;/h2&gt;
&lt;p&gt;ioc 那邊還可以設置 clock&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;External clock
&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/embedding/stm32cubeide/ex-clock.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;LSE 和 HSE 是 (Low / High Speed External)，你有 oscillator 的話可以自己弄&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/embedding/stm32cubeide/sys-peripheral.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;你可以調 sysclk 或 peripheral clock&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;programming&#34;&gt;Programming&lt;/h2&gt;
&lt;p&gt;在 USER CODE section 寫上程式碼&lt;/p&gt;
&lt;p&gt;選取的部分可以按 F3，看他是從哪邊來的，或看 macro 之類的&lt;/p&gt;
&lt;h2 id=&#34;debug&#34;&gt;DEBUG&lt;/h2&gt;
&lt;p&gt;上面有個 BUG 符號的東西，旁邊的箭頭可以用 DEBUG 的設定&lt;/p&gt;
&lt;p&gt;又建 STM32 C/C++ Application，可以 New 新設定&lt;/p&gt;
&lt;p&gt;C/C++ Application 那邊選你 compile 的 elf 檔&lt;/p&gt;
&lt;p&gt;Debugger 開啟 ST-LINK S/N，並且掃描，如果你的電腦有接上 MCU，應該會直接找到&lt;/p&gt;
</description>
        </item>
        <item>
        <title>GIT 論文閱讀</title>
        <link>https://roykesydon.github.io/Blog/p/git-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</link>
        <pubDate>Wed, 29 Mar 2023 01:08:46 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/git-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</guid>
        <description>&lt;p&gt;paper: &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2205.14100&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;GIT: A Generative Image-to-text Transformer for Vision and Language&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; ██████╗ ██╗████████╗
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;██╔════╝ ██║╚══██╔══╝
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;██║  ███╗██║   ██║   
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;██║   ██║██║   ██║   
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;╚██████╔╝██║   ██║   
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; ╚═════╝ ╚═╝   ╚═╝   
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;設計了一個 Generative Image-to-text Transformer，統一 vision-language tasks，像是 image/video captioning 或是問答。&lt;/p&gt;
&lt;p&gt;雖然 generative models 在預訓練和微調的時候是同樣的網路架構，現有的工作通常都包含複雜的架構 (uni/multi-modal encoder/decoder)，
而且依賴於外部模組，比如物件偵測或 optical character recognition (OCR)。&lt;/p&gt;
&lt;p&gt;在 GIT，我們簡化為 single language modeling task 下的一個 image encoder 和一個 text decoder。&lt;/p&gt;
&lt;p&gt;擴大了預訓練資料和模型大小以提高模型性能。&lt;/p&gt;
&lt;p&gt;在許多具有挑戰性的 benchmarks 上取得 SOTA。&lt;/p&gt;
&lt;p&gt;比如首次在 TextCpas 上超越人類的表現。&lt;/p&gt;
&lt;p&gt;提出了一種 generation-based image classification and scene text recognition 的新方案。&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;近年來在 vision-language（VL）預訓練方面取得了巨大進展，特別是基於 image-text pairs 的大規模數據，例如 CLIP、Florence 和 SimVLM。&lt;/p&gt;
&lt;p&gt;學習到的 representation 很好的提高了下游任務的性能，比如 image captioning、visual question answering 和 image-text retrieval。&lt;/p&gt;
&lt;p&gt;在預訓練過程中，Masked Language Modeling (MLM) 和 Image-Text Matching (ITM) 被廣泛使用。&lt;/p&gt;
&lt;p&gt;然而這些 loss 和下游任務不同，必須做 task-specific adaptation。&lt;/p&gt;
&lt;p&gt;比如， image captioning 要移除 ITM，VQA 需要額外隨機初始的 MLP。&lt;/p&gt;
&lt;p&gt;為了減少這種差異，最近的研究試圖為預訓練模型設計 unified generative models 來預訓練，因為大多數 VL 的問題可以轉化為生成問題。&lt;/p&gt;
&lt;p&gt;這些方法通常利用 multi-modal encoder 和 text decoder，並精心設計 text input 和 text target。&lt;/p&gt;
&lt;p&gt;為了進一步推動這方向的研究，作者設計了一個簡單的 Generative Image-to-text Transformer，稱作 GIT，只包含一個 image encoder 和 text decoder。&lt;/p&gt;
&lt;p&gt;預訓練任務只是把輸入的圖像映射到相關聯的文字描述。&lt;/p&gt;
&lt;p&gt;盡管他很簡單，但還是在眾多具有挑戰性的 benchmark 取得 SOTA。&lt;/p&gt;
&lt;p&gt;image encoder 是 Swin-like vision transformer，在大量的 image-text pairs 上做 pretrain，基於 contrastive task。&lt;/p&gt;
&lt;p&gt;這消除了現有許多方法中對 object detector 的依賴。&lt;/p&gt;
&lt;p&gt;為了將其擴展到影片領域，我們把多個 frame 的特徵 concatenate，作為 video 表示。&lt;/p&gt;
&lt;p&gt;text decoder 是一個用來預測相關聯文字的 transformer。&lt;/p&gt;
&lt;p&gt;整個網路都是基於 language modeling task 來訓練。&lt;/p&gt;
&lt;p&gt;對於 VQA，input question 被看作 text prefix，並以 auto-regressive 的方法生出答案。&lt;/p&gt;
&lt;p&gt;此外，作者提出了一種 generation-based 的 ImageNet classification 新方案，預測標籤直接根據作者的生成模型，而不用預先定義詞彙表。&lt;/p&gt;
&lt;p&gt;我們的作法很簡單，但在擴大預訓練資料和模型大小後，成果驚人。&lt;/p&gt;
&lt;p&gt;主要貢獻如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;我們展示了 GIT，僅由一個 image encoder 和一個 text decoder 組成，透過 language modeling task，在 0.8 billion image-text pairs 上 pretrain。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在 image/video captioning 和 QA 上，沒有基於 object detectors，object tags 和 OCR，就在多個任務上取得 SOTA。證明簡單的網路架構也可以透過 scaling 取得強大的性能。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;我們證明 GIT 雖然 pretrain 在 image-text pairs，也能在 video tasks 上取得 SOTA，不需要 video dedicated encoders。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;我們提出了一種新的 generation-based image classification 方案，在 ImageNet-1K 上，取得不錯的性能。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;related-work&#34;&gt;Related Work&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/microsoft-GIT/table1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/microsoft-GIT/fig1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;在 VL pre-training 中，多 multi-task pre-training 被廣泛使用，賦予網路多種或增強的能力。&lt;/p&gt;
&lt;p&gt;比如，MLM 和 ITM 是廣泛採用的預訓練任務，最近也有研究加入 image-text contrastive loss。&lt;/p&gt;
&lt;p&gt;由於多數 VL 任務都可以表示成 text generation task，所以可以訓練一個生成模型來支持各種下游任務。&lt;/p&gt;
&lt;p&gt;輸入和輸出文本通常都會經過精心設計，以預訓練這樣的生成模型。&lt;/p&gt;
&lt;p&gt;對於 image representation，Faster RCNN 被大多數現有方法用來提取區域特徵。&lt;/p&gt;
&lt;p&gt;同時，也很容易以 end-to-end 的方法訓練整個網路。&lt;/p&gt;
&lt;p&gt;除了 feature map，object tags，也很常被用來方便 transformer 理解上下文，特別是 novel objects。&lt;/p&gt;
&lt;p&gt;對於與場景文本相關的任務，調用 OCR 以生成場景文本作為附加網路輸入。&lt;/p&gt;
&lt;p&gt;對於 text prediction，常用 transformer network，結合 cross-attention module 來融合 image tokens。&lt;/p&gt;
&lt;p&gt;或者只是單純 concatenate text tokens 和 image tokens，然後用 self-attention。&lt;/p&gt;
&lt;p&gt;在本文中，我們有 9 個不同的 benchmark，3 種不同模型大小和 3 種不同預訓練資料規模。&lt;/p&gt;
&lt;h2 id=&#34;generative-image-to-text-transformer&#34;&gt;Generative Image-to-text Transformer&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/microsoft-GIT/fig2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;network-architecture&#34;&gt;Network Architecture&lt;/h3&gt;
&lt;p&gt;image encoder 基於 contrastive pre-trained model。&lt;/p&gt;
&lt;p&gt;輸入是原始圖像，輸出是 compact 2D feature map，被 flatten 成 list of features。&lt;/p&gt;
&lt;p&gt;透過一個額外的 linear layer 和一個 layernorm layer，image features 被 project 到 D dimensions，也就是 text encoder 的 input。&lt;/p&gt;
&lt;p&gt;作者使用做 contrastive tasks pretraining 的 image encoder，因為最近的研究表明這種 image encoder 有更好的性能。&lt;/p&gt;
&lt;p&gt;在後面的章節，還觀察到 VL performence 明顯地隨著更強的 image encoder 而有所提升。
這和 object detection-based 的方法觀察到的結果一致。&lt;/p&gt;
&lt;p&gt;CoCa 的 concurrent work 統一了 contrastive task 和 the generation task，作為一個預訓練階段。&lt;/p&gt;
&lt;p&gt;作者的方法相當於是按順序分離兩個任務:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;用 contrastive task 訓練 image encoder&lt;/li&gt;
&lt;li&gt;用 generation task pretrain image encoder 和 text decoder&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;text decoder 是一個用於預測文本描述的 transformer module，由多個 transformer block 組成，每個 transformer block 由一個 self-attention layer 和 feed-forward layer 組成。&lt;/p&gt;
&lt;p&gt;text 被 tokenize 和 embed 到 D dimensions，並添加 positional encoding 和 layernorm layer。&lt;/p&gt;
&lt;p&gt;image features 和 text embeddings 被 concatenate 起來作為 transformer module 的輸入。&lt;/p&gt;
&lt;p&gt;text 以 [BOS] 開始，並以 auto regressive 的方式 decode，直到 [EOS] 或 maximum steps。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/microsoft-GIT/fig3.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;attention mask 根據上圖設計，使的 text token 只能依賴於前面的 text token 和 image token，而 image token 可以互相做 attention。&lt;/p&gt;
&lt;p&gt;這和 unidirectional attention mask 不同，unidirectional attention mask 並非每個 image token 都可以依賴於其他的 Image token。&lt;/p&gt;
&lt;p&gt;作者很好地初始化 image encoder，卻隨機初始化 text decoder。&lt;/p&gt;
&lt;p&gt;這種設計動機是基於[MiniVLM: A Smaller and Faster Vision-Language Model]，該研究隨機初始化顯示出與 BERT 初始化相似地性能。&lt;/p&gt;
&lt;p&gt;原因可能在於 BERT 地初始化無法理解圖像信號，這對於 VL 任務至關重要。&lt;/p&gt;
&lt;p&gt;[Flamingo: a Visual Language Model for Few-Shot Learning] 採用了類似的 image encoder + text decoder，但是他們的 decoder 經過 pretrain，並且有 freeze，好保留大型語言模型的泛化能力。&lt;/p&gt;
&lt;p&gt;GIT 的所有參數都會更新，以更好地適應 VL 的任務。&lt;/p&gt;
&lt;p&gt;另一種架構是 cross-attention-based 的 decoder，用於 incorporate image signals，而不是 concatenation 再用 self-attention。&lt;/p&gt;
&lt;p&gt;根據實驗，large-scale 的 pre-training，self-attention-based 會有更好的性能，小規模的則是 cross-attention-based。&lt;/p&gt;
&lt;p&gt;一個合理的解釋是，經過充分訓練，decoder 可以很好地處理圖像和文本，而且 image token 可以為了 text generation 更好地更新。&lt;/p&gt;
&lt;p&gt;而 cross-attention 讓 image token 沒辦法 attend 彼此。&lt;/p&gt;
&lt;h3 id=&#34;pre-training&#34;&gt;Pre-training&lt;/h3&gt;
&lt;p&gt;訓練採用 language modeling (LM) loss。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/microsoft-GIT/for1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$I$ 是 image&lt;/li&gt;
&lt;li&gt;$y_i,i \in $ { $ 1,&amp;hellip;,N $ } 是文字 token，$y_0$ 是 [BOS]，$y_{N+1}$ 是 [EOS]&lt;/li&gt;
&lt;li&gt;CE 是有 0.1 label smoothing 的 cross-entropy&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;另一種選擇是 MLM，在每個 epoch 中預測 15% 的輸入 token，要預測所有 token 至少需要 1 / 0.15 = 6.7 個 epochs，對於 LM，每個 epoch 都可以預測所有 token，對於大規模預訓練資料來說效率更高。&lt;/p&gt;
&lt;p&gt;ablation studies 顯示出 LM 可以在有限的 epoch 內實現更好的性能。
在大規模訓練中，由於計算資訊的限制，只有兩個 epoch，所以選擇 LM。
與此同時，大部分最近的 large-scale language model 也是基於 LM。&lt;/p&gt;
&lt;p&gt;如果沒有圖像輸入，該模型將簡化為 decoder-only 的語言模型，架構類似於 GPT-3。&lt;/p&gt;
&lt;p&gt;因此，這種設計還可以利用 text-only 的資料來提升 scaled-up decoder 的能力，把這保留給未來的工作。&lt;/p&gt;
&lt;h3 id=&#34;fine-tuning&#34;&gt;Fine-tuning&lt;/h3&gt;
&lt;p&gt;對於 image captioning，由於訓練數據格式和預訓練相同，所以用同樣的 LM task 來微調 GIT。
對於 visual question answering，問題和 GT 在微調的時候被看做 special caption，但 LM loss 僅用於答案和 [EOS]。&lt;/p&gt;
&lt;p&gt;推理過程中，question 被當作 caption 的 prefix，完成的部分是預測。&lt;/p&gt;
&lt;p&gt;VQAv2 現有的工作收集候選答案，再重構成分類問題，預測一次。
作者的工作有更多挑戰，因為是生成式的，需要生出至少兩個正確的 token，答案和 [EOS]。&lt;/p&gt;
&lt;p&gt;然而考慮到自由形式答案的好處，作者選擇了生成方法。&lt;/p&gt;
&lt;p&gt;由於生成模型的難度，VQAv2 比現有的判別工作略差。&lt;/p&gt;
&lt;p&gt;對於和 scene-text related VQA 任務，現有方法通常利用 OCR 生成 5 個 scene text 並用 dynamic pointer network 決定當前輸出應該是 OCR 還是 general text。&lt;/p&gt;
&lt;p&gt;但由於作者的方法不依賴於 OCR，因此也不依賴於 dynamic pointer network。&lt;/p&gt;
&lt;p&gt;根據實驗，作者發現模型透過大規模預訓練資料學會如何閱讀場景文本，並且作者的模型不是專門為了影片領域設計的，但可以透過簡單的架構更改就取得具有競爭力或甚至 SOTA 的成果，也就是作者可以從每個影片採樣多個 frame，並透過 image encoder 獨立地為每個 frame 編碼。
最後添加一個 learnable temporal embedding (初始化為 0)，並 concatenate sampled frames 的特徵。&lt;/p&gt;
&lt;p&gt;作者還用於圖片分類，把 class name 用於 caption。&lt;/p&gt;
&lt;p&gt;這和現有工作不一樣，現有工作通常先定義詞彙表，並用線性層預測每個類別的可能性。&lt;/p&gt;
&lt;p&gt;當新數據和新類別被添加到現有數據的時候，這種新一代的方案是有益的，因為這樣可以在不引入新參數的情況下對新數據進行訓練。&lt;/p&gt;
&lt;h2 id=&#34;experiments&#34;&gt;Experiments&lt;/h2&gt;
&lt;h3 id=&#34;setting&#34;&gt;Setting&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;收集 0.8B 的 image-text pairs 來預訓練。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;image encoder 是根據  pre-trained contrastive model 初始化的。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;hidden dimension (D) = 768&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;text decoder 有 6 個 randomly-initialized transformer blocks&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;共有 0.7b 的參數&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;image decoder 和 text encoder 的 learning rate 各別是 1e-5 和 5e-5，都 cosine decay 到 0&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;推論階段 beam size 是 4，length penalty 是 0.6。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Supplementary materials 展示了小模型變體 (GITB and GITL) 和更大模型 (GIT2) 的結果&lt;/p&gt;
&lt;h3 id=&#34;results-on-image-classification&#34;&gt;Results on Image Classification&lt;/h3&gt;
&lt;p&gt;輸出必須與類別名稱完全匹配，甚至考慮多或少的空格。&lt;/p&gt;
&lt;p&gt;由於不知道詞彙表，精確匹被準確度只有 1.93%，如果預測包含 GT 就對，那有 40.88%。&lt;/p&gt;
&lt;p&gt;通過微調每個類別只有 1 shot 或 5 shot，準確度會顯著提高，
表明只用少量訓練樣本，也可以輕鬆適應下游任務。&lt;/p&gt;
&lt;p&gt;與 Flamingo 相比，GIT 實現更高的準確度。&lt;/p&gt;
&lt;p&gt;Flamingo 在沒有參數更新的情況下進行小樣本學習，但需要額外的網路輸入，可能會增加推理成本。&lt;/p&gt;
&lt;p&gt;相比之下，GIT 透過一次 lightweight fine-tuning，推理過程中不需要這些 training shot。&lt;/p&gt;
&lt;h3 id=&#34;analysis&#34;&gt;Analysis&lt;/h3&gt;
&lt;h4 id=&#34;model-and-data-scaling&#34;&gt;Model and data scaling&lt;/h4&gt;
&lt;p&gt;對於網路架構，作者的模型被稱作 Huge，把 image encoder 換成 CLIP 的 ViT-B/16 和 ViT-L/14 的則是 Base 和 Large。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/microsoft-GIT/fig4.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;可以看出較大的 image encoder 帶來的好處，但根據實驗，
作者發現很難有效地擴展 text decoder，原因可能是 LM 很難用 limited amount of text 來訓練。&lt;/p&gt;
&lt;p&gt;另一個可能的原因是 image encoder 負責 object recognition，而 decoder 負責以 NLP 的方法組織 object terms。
後一項任務可能很容易，因為大多數描述都遵循相似的模式，比如 Object + verb + subject，所以只要一個 small decoder，較大的 decoder 可能會增加學習難度。&lt;/p&gt;
&lt;p&gt;Flamingo 的研究顯示更大的 Decoder 可以提高性能，但是他們的 decoder 有 pretrain 過，而且在 VL 預訓練的時候 frozen，避開了如何有效訓練 decoder 的問題。&lt;/p&gt;
&lt;p&gt;LEMON 的 transformer 可以擴展到 32 層，可能是因為他們使用 MLM 而不是 LM，後者可能更加困難。&lt;/p&gt;
&lt;h4 id=&#34;scene-text-in-pre-training-data&#34;&gt;Scene text in pre-training data&lt;/h4&gt;
&lt;p&gt;為了瞭解 scene text comprehension 的能力，作者檢查了 pretrain data 有多少 image-text pairs 有 scene text。&lt;/p&gt;
&lt;p&gt;作者用 Microsoft Azure OCR API4 對一些資料做 OCR，然後把 OCR 結果和 associated text 做比對，只有包含長度超過 5 個字元的 OCR 結果才會算比對。
有 15% 的 CC12M 和 31% 的下載圖像(500K) 包含 scene text 描述。
由於任務是訓練預測 text，網路逐漸學會閱讀 scene text。&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;h3 id=&#34;limitations&#34;&gt;Limitations&lt;/h3&gt;
&lt;p&gt;根據實驗，目前不清楚如何控制生成的 caption 以及如何在不更新參數的情況下執行 in-context learning，把這留給未來的工作。&lt;/p&gt;
&lt;h3 id=&#34;societal-impact&#34;&gt;Societal impact&lt;/h3&gt;
&lt;p&gt;該模型在大規模數據集上預訓練，不能保證數據不含 toxic language，可能會 poison output。&lt;/p&gt;
&lt;h2 id=&#34;其他&#34;&gt;其他&lt;/h2&gt;
&lt;h3 id=&#34;a3-network&#34;&gt;A.3 Network&lt;/h3&gt;
&lt;p&gt;講超參數&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/microsoft-GIT/model.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>RoBERTa 論文閱讀</title>
        <link>https://roykesydon.github.io/Blog/p/roberta-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</link>
        <pubDate>Wed, 22 Mar 2023 01:08:46 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/roberta-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</guid>
        <description>&lt;p&gt;paper: &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/1907.11692&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;RoBERTa: A Robustly Optimized BERT Pretraining Approach&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;██████╗  ██████╗ ██████╗ ███████╗██████╗ ████████╗ █████╗
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;██╔══██╗██╔═══██╗██╔══██╗██╔════╝██╔══██╗╚══██╔══╝██╔══██╗
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;██████╔╝██║   ██║██████╔╝█████╗  ██████╔╝   ██║   ███████║
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;██╔══██╗██║   ██║██╔══██╗██╔══╝  ██╔══██╗   ██║   ██╔══██║
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;██║  ██║╚██████╔╝██████╔╝███████╗██║  ██║   ██║   ██║  ██║
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;╚═╝  ╚═╝ ╚═════╝ ╚═════╝ ╚══════╝╚═╝  ╚═╝   ╚═╝   ╚═╝  ╚═╝
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;發現 BERT 訓練不足，並且作者的模型在 4/9 的 GLUE 任務, RACE 和 SQuAD 取得 SOTA。&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;自監督的訓練方法帶來了顯著的性能提升，但要確定這一堆方法中的哪些方面貢獻最大，具備挑戰性。&lt;/p&gt;
&lt;p&gt;訓練的計算量是昂貴的，使 fine-tune 受限，而且通常都是用不同大小的 private training data，使評估模型更加困難。&lt;/p&gt;
&lt;p&gt;作者提出了對 BERT 預訓練的 replication study，包括對超參數的調整，以及對訓練集大小的仔細評估。&lt;/p&gt;
&lt;p&gt;作者發現 BERT 訓練不足，並提出了一種改進方法，稱為 RoBERTa，可以達到或超過所有 post-BERT 的方法。&lt;/p&gt;
&lt;p&gt;修改如下:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;訓練模型的時間更長，batch 更大，用更多 data&lt;/li&gt;
&lt;li&gt;移除 next sentence prediction objective&lt;/li&gt;
&lt;li&gt;訓練更長的序列&lt;/li&gt;
&lt;li&gt;動態地改變用於訓練資料的 masking pattern&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;貢獻:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;提出一組重要的 BERT 設計選擇和訓練策略&lt;/li&gt;
&lt;li&gt;使用了新的 dataset，叫做 CCNEWS，並證明用更多的資料來預訓練，可以提高下游任務的表現&lt;/li&gt;
&lt;li&gt;訓練表明，在正確的設計選擇下，pretrained masked language model 和其他最近的方法比，具有競爭力&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;background&#34;&gt;Background&lt;/h2&gt;
&lt;p&gt;對 BERT 做回顧&lt;/p&gt;
&lt;h3 id=&#34;architecture&#34;&gt;Architecture&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;L layers&lt;/li&gt;
&lt;li&gt;A self-attention heads&lt;/li&gt;
&lt;li&gt;H hidden dimension&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;training-objectives&#34;&gt;Training Objectives&lt;/h3&gt;
&lt;p&gt;預訓練的時候，BERT 有兩個目標: masked language modeling 和 next sentence prediction&lt;/p&gt;
&lt;h4 id=&#34;masked-language-model-mlm&#34;&gt;Masked Language Model (MLM)&lt;/h4&gt;
&lt;p&gt;BERT 隨機選擇 15% 的 token 進行可能的替換&lt;/p&gt;
&lt;p&gt;80% 換成 [MASK]，10% 保持不變，10% 被選為一個隨便的 vocabulary token&lt;/p&gt;
&lt;h4 id=&#34;next-sentence-prediction-nsp&#34;&gt;Next Sentence Prediction (NSP)&lt;/h4&gt;
&lt;p&gt;分類第二句是不是下一句，是二元分類。&lt;/p&gt;
&lt;p&gt;正例由提取連續的句子產生，負例由不同的片段配對產生。&lt;/p&gt;
&lt;p&gt;正例和負例以相等機率產生。&lt;/p&gt;
&lt;h4 id=&#34;optimization&#34;&gt;Optimization&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Adam&lt;/li&gt;
&lt;li&gt;$\beta_1$ = 0.9, $\beta_2$ = 0.999, $\epsilon$ = 1e-6&lt;/li&gt;
&lt;li&gt;$L_2$ weight decay of 0.01&lt;/li&gt;
&lt;li&gt;Learning rate 前 10,000 step warm up 到 1e-4，然後 linear decay&lt;/li&gt;
&lt;li&gt;全部的 layer 和 attention weight 都 dropout 0.1&lt;/li&gt;
&lt;li&gt;GELU 激活函數&lt;/li&gt;
&lt;li&gt;1,000,000 次 update，batch size 256，序列長度 512&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;data&#34;&gt;Data&lt;/h4&gt;
&lt;p&gt;BERT 在 BookCorpus 和 English Wikipedia 混和的資料集上訓練，共有 16GB 的未壓縮文本&lt;/p&gt;
&lt;h2 id=&#34;experimental-setup&#34;&gt;Experimental Setup&lt;/h2&gt;
&lt;p&gt;描述對於 BERT 的 replication study 的實驗設置&lt;/p&gt;
&lt;h3 id=&#34;implementation&#34;&gt;Implementation&lt;/h3&gt;
&lt;p&gt;作者用 FAIRSEQ 重新實現了 BERT。&lt;/p&gt;
&lt;p&gt;主要遵循 [Background-Optimization] 中的 BERT 原始超參數，但 peak learning rate 和 warmup step 除外，他們針對每個設置單獨調整。&lt;/p&gt;
&lt;p&gt;作者發現訓練對 Adam epsilon 非常敏感。&lt;/p&gt;
&lt;p&gt;作者發現設置 $\beta_2$ = 0.98，在大 batch size 的情況下，可以提高訓練時的穩定性。&lt;/p&gt;
&lt;p&gt;用最多 512 個 token 預訓練。&lt;/p&gt;
&lt;p&gt;作者不會隨機注入短序列，也不會為前 90% 的更新縮短輸入的長度。&lt;/p&gt;
&lt;p&gt;作者只訓練 full-length 的 sequences。&lt;/p&gt;
&lt;h3 id=&#34;data-1&#34;&gt;Data&lt;/h3&gt;
&lt;p&gt;BERT-style 的預訓練仰賴大量文本。&lt;/p&gt;
&lt;p&gt;已有研究證明增加數據量可以提高 end-task 的性能。&lt;/p&gt;
&lt;p&gt;已有一些研究，用比原始 BERT 更多樣更大的數據集，但不是所有的數據集都有公開。&lt;/p&gt;
&lt;p&gt;本研究用了五個不同大小和領域的英文文本，共有超過 160 GB 的未壓縮文本。&lt;/p&gt;
&lt;p&gt;使用以下數據集:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;BookCorpus + English Wikipedia
&lt;ul&gt;
&lt;li&gt;BERT 原本使用的。&lt;/li&gt;
&lt;li&gt;16 GB&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;CC-News
&lt;ul&gt;
&lt;li&gt;作者從 CommonCrawl News dataset 的英文部分中蒐集，包含了 2016 年 9 月到 2019 年 2 月的 6300 萬篇英文新聞。&lt;/li&gt;
&lt;li&gt;過濾後有 76 GB&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;OpenWebText
&lt;ul&gt;
&lt;li&gt;WebText 的開源重建版，從 Reddit 上至少有 3 個 upvotes 的 shared URLs 提取出的 Web 內容。&lt;/li&gt;
&lt;li&gt;38 GB&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Stories
&lt;ul&gt;
&lt;li&gt;包含 CommonCrawl data 的一個子集合，經過過濾，以匹配 story-like style of Winograd schemas&lt;/li&gt;
&lt;li&gt;31 GB&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;evaluation&#34;&gt;Evaluation&lt;/h3&gt;
&lt;p&gt;使用以下三個 benchmarks 評估預訓練模型&lt;/p&gt;
&lt;h4 id=&#34;glue&#34;&gt;GLUE&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The General Language Understanding Evaluation&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;用於評估自然語言理解的 9 個數據集的集合，任務被定義為 single-sentence 分類或 sentence-pair 分類任務。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;finetune 的流程遵循原始 BERT paper&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;squad&#34;&gt;SQuAD&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The Stanford Question Answering Dataset&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;提供一段 context 以及一個問題&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;具有兩個版本 V1.1 和 V2.0&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;V1.1
&lt;ul&gt;
&lt;li&gt;context 總是包含一個答案&lt;/li&gt;
&lt;li&gt;評估 V1.1 的時候，作者採用和 BERT 相同的 span prediction method&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;V2.0
&lt;ul&gt;
&lt;li&gt;一些問題在提供的 context 中沒有回答，使任務更有挑戰性&lt;/li&gt;
&lt;li&gt;評估 V2.0 的時候，作者會用一個額外的二元分類器預測問題是否可以回答，在評估的時候，只預測被分類為可回答的&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;race&#34;&gt;RACE&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;The ReAding Comprehension from Examinations&lt;/li&gt;
&lt;li&gt;大型閱讀理解數據集，有超過 28,000 篇文章 以及將近 100,000 個問題&lt;/li&gt;
&lt;li&gt;從中國的英文考試蒐集的，這些考試是為國中生和高中生設計的&lt;/li&gt;
&lt;li&gt;每篇文章都與多個問題相關聯&lt;/li&gt;
&lt;li&gt;對每個問題，要從四個選項中選出一個對的&lt;/li&gt;
&lt;li&gt;context 比起其他閱讀理解的數據集要長，而且要推理的問題比例很大&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;training-procedure-analysis&#34;&gt;Training Procedure Analysis&lt;/h2&gt;
&lt;p&gt;探討哪些選擇對成功預訓練 BERT 很重要。&lt;/p&gt;
&lt;p&gt;作者把架構固定，也就是訓練和$BERT_{BASE}$ (L=12, H=768, A=12, 110M params)一樣架構的 BERT models&lt;/p&gt;
&lt;h3 id=&#34;static-vs-dynamic-masking&#34;&gt;Static vs. Dynamic Masking&lt;/h3&gt;
&lt;p&gt;BERT 在 preprocessing 的時候處理 masking，產生單個 static mask。
作者為了避免在每個 epoch 都對每個 instance 用相同的 mask，將數據複製了 10 次，在 40 個 epochs 裡，以 10 種不同的方式 mask。所以一次訓練過程中，相同的 mask 會出現四次。&lt;/p&gt;
&lt;p&gt;作者會以上述策略和 Dynamic masking 進行比較，Dynamic masking 是在每次餵 model 前，才生成 mask。&lt;/p&gt;
&lt;p&gt;作者發現 Dynamic Masking 相比 static，要不是差不多，就是略好，基於結果和效率的優勢考量，其他實驗中都用 dynamic masking。&lt;/p&gt;
&lt;h3 id=&#34;model-input-format-and-next-sentence-prediction&#34;&gt;Model Input Format and Next Sentence Prediction&lt;/h3&gt;
&lt;p&gt;原始的 BERT 預訓練中，兩個句子要不是同一個文件的連續句子(p = 0.5)，不然就是不同的 document 做採樣&lt;/p&gt;
&lt;p&gt;以往有研究指出移除 NSP 會損害性能，但也有研究質疑必要性，所以本文比較了幾種替代訓練格式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SEGMENT-PAIR+NSP
&lt;ul&gt;
&lt;li&gt;最原始的方法，每個 segment 可以有多個自然句子&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;SENTENCE-PAIR+NSP
&lt;ul&gt;
&lt;li&gt;只包含一對句子，由於輸入明顯少於 512 token，所以會增加 batch size 讓 token 總數和前者差不多&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;FULL-SENTENCES
&lt;ul&gt;
&lt;li&gt;包含從一個或多個文件中連續採樣的完整句子，可能會跨越文件邊界，在文件邊界間會加個額外的分隔符&lt;/li&gt;
&lt;li&gt;移除了 NSP&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;DOC-SENTENCES
&lt;ul&gt;
&lt;li&gt;和 FULL-SENTENCES 差不多，但不能跨越 document，在 document 尾巴的部分會容易少於 512，所以會動態增加 batch size，讓 token 總數和 FULL-SENTENCES 差不多&lt;/li&gt;
&lt;li&gt;移除了 NSP&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/RoBERTa/table2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;發現 DOC-SENTENCES 是最棒的，但由於 DOC-SENTENCES 會讓 batch sizes 大小可變，所以其他實驗會用 FULL-SENTENCES，比較好和其他相關工作比較。&lt;/p&gt;
&lt;h3 id=&#34;training-with-large-batches&#34;&gt;Training with large batches&lt;/h3&gt;
&lt;p&gt;根據過去神經網路機器翻譯的工作，當 learning rate 適當增加的時候，用非常大的的 mini-bathces 可以提高 optimization 的速度和 end-task 性能。&lt;/p&gt;
&lt;p&gt;最近的研究也顯示 BERT 適用於 large batch training。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/RoBERTa/table3.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;text-encoding&#34;&gt;Text Encoding&lt;/h3&gt;
&lt;p&gt;Byte-Pair Encoding (BPE) 是一種介於字符級別和詞級別表示之間的混合表示方法，它允許處理自然語言語料庫中常見的大詞彙量。&lt;/p&gt;
&lt;p&gt;BPE 不依賴於完整的單詞，而是依靠 subwords units，通過對訓練語料進行統計分析來提取這些 subwords units。&lt;/p&gt;
&lt;p&gt;BPE 詞彙表的大小通常在 10K-100K 的 subword units。&lt;/p&gt;
&lt;p&gt;在 &amp;ldquo;Language Models are Unsupervised Multitask Learners&amp;rdquo; 文中，提到了一種巧妙的 BPE 實現，不是用 unicode characters，而是用 bytes 作為 base subword units。可以生出 50K 大小的詞彙表，而且不用引入任何的 &amp;ldquo;unknown&amp;rdquo;。&lt;/p&gt;
&lt;p&gt;原始的 BERT 用 character-level BPE vocabulary，大小為 30K。&lt;/p&gt;
&lt;p&gt;本文考慮用 50K byte-level BPE vocabulary，而不對輸入做額外的 preprocessing 或 tokenization，&amp;ldquo;Language Models are Unsupervised Multitask Learners&amp;rdquo; 的研究顯示這些 Encoding 的方法在最終效能上並無太大差別，只在某些任務上 end-task performance 表現稍差。&lt;/p&gt;
&lt;p&gt;但作者相信 universal encoding scheme 的優勢超過了輕微的性能下降，其他實驗也會用這種邊碼方式。&lt;/p&gt;
&lt;h2 id=&#34;roberta&#34;&gt;RoBERTa&lt;/h2&gt;
&lt;p&gt;整理上面說的改進。&lt;/p&gt;
&lt;p&gt;RoBERTa 用以下配置:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;dynamic masking&lt;/li&gt;
&lt;li&gt;FULL-SENTENCES without NSP loss&lt;/li&gt;
&lt;li&gt;large mini-batches&lt;/li&gt;
&lt;li&gt;larger byte-level BPE&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;此外，還調查了兩個之前的工作沒強調的重要因素:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;用於預訓練的 data&lt;/li&gt;
&lt;li&gt;訓練過 data 的次數&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;為了把這些因素的重要性和其他模型選擇分隔開，先按照 $BERT_{LARGE}$ (L = 24, H = 1024, A = 16, 355M parameters) 訓練 RoBERTa。&lt;/p&gt;
&lt;p&gt;作者在 BOOKCORPUS plus WIKIPEDIA dataset 進行了 100K step 的預訓練。&lt;/p&gt;
&lt;p&gt;在控制 training data 的情況下， RoBERTa 比 $BERT_{LARGE}$ 的結果有大幅度的改進，重申了前面設計選擇的重要性。&lt;/p&gt;
&lt;p&gt;接下來，結合之前說的額外 dataset，並用相同的步數(100K) 訓練 RoBERTa，觀察到下游任務的性能進一步提高，驗證了數據大小和多樣性的重要性。&lt;/p&gt;
&lt;p&gt;最後，對 RoBERTa 做更長時間的預訓練，將步數提高到 300K 和 500K，再次觀察到下游任務性能顯著提升。&lt;/p&gt;
&lt;p&gt;作者也注意到，即使是他們訓練時間最長的模型，也不會 overfit 他們的數據。&lt;/p&gt;
&lt;p&gt;本文的其他部分在三個 benchmark 評估好壞: GLUE、SQuaD 和 RACE&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/RoBERTa/table4.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;glue-results&#34;&gt;GLUE Results&lt;/h3&gt;
&lt;p&gt;雖然很多 GLUE 排行榜的提交都是 depend on multi-task finetuning，但作者的 submission 是 depends only on single-task finetuning。&lt;/p&gt;
&lt;p&gt;此外，對於 RTE、STS 和 MRPC，從 MNLI 的模型微調會比 baseline 的 RoBERTa 有幫助許多。&lt;/p&gt;
&lt;p&gt;在第一個設置 (single-task, dev) 中，RoBERTa 在所有 9 個 GLUE 任務 dev set 上都取得了最先進的結果。&lt;/p&gt;
&lt;p&gt;在第二個設置 (ensembles, test) 中，作者將 RoBERTa 提交到 GLUE 排行榜，並在 9 個任務中的 4 個上取得了 SOTA 和迄今為止的最高平均分。&lt;/p&gt;
&lt;p&gt;這令人興奮的地方在於，與多數 top submissions 不同，RoBERTa 不是 depend on multi-tasking finetuning&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/RoBERTa/table5.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;在預訓練 BERT 模型時，作者仔細評估了許多設計決策。&lt;/p&gt;
&lt;p&gt;作者發現，通過對模型進行更長時間的訓練、使用更大的批次處理更多的數據、去除 NSP、訓練更長的序列、dynamic masking，可以顯著提高性能。&lt;/p&gt;
&lt;p&gt;作者改進的預訓練程序，我們稱之為 RoBERTa，在 GLUE、RACE 和 SQuAD 上實現了 SOTA，而無需為 GLUE 進行多任務微調或為 SQuAD 提供額外的數據。&lt;/p&gt;
&lt;p&gt;這些結果說明了這些以前被忽視的設計決策的重要性，並表明 BERT 的預訓練目標與最近提出的替代方案相比仍然具有競爭力。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>ARM 組合語言介紹</title>
        <link>https://roykesydon.github.io/Blog/p/arm-%E7%B5%84%E5%90%88%E8%AA%9E%E8%A8%80%E4%BB%8B%E7%B4%B9/</link>
        <pubDate>Tue, 21 Mar 2023 01:32:54 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/arm-%E7%B5%84%E5%90%88%E8%AA%9E%E8%A8%80%E4%BB%8B%E7%B4%B9/</guid>
        <description>&lt;h2 id=&#34;開發環境&#34;&gt;開發環境&lt;/h2&gt;
&lt;h3 id=&#34;ide&#34;&gt;IDE&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;SW4STM32
&lt;ul&gt;
&lt;li&gt;支援 STM32&lt;/li&gt;
&lt;li&gt;GCC C/C++ compiler&lt;/li&gt;
&lt;li&gt;GDB-based debugger&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;板子&#34;&gt;板子&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;STM32 Bucleo Board
&lt;ul&gt;
&lt;li&gt;Cortex-M4&lt;/li&gt;
&lt;li&gt;ST-LINK
&lt;ul&gt;
&lt;li&gt;debugger&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Memories
&lt;ul&gt;
&lt;li&gt;1MB Flash&lt;/li&gt;
&lt;li&gt;128KB SRAM&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;debug-interface&#34;&gt;Debug Interface&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;JTAG
&lt;ul&gt;
&lt;li&gt;Joint Test Action Group&lt;/li&gt;
&lt;li&gt;standard ASICs hardware debug interface&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;SWD
&lt;ul&gt;
&lt;li&gt;Serial Wire Debug&lt;/li&gt;
&lt;li&gt;只從 JTAG 用 5 wires&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;bootup-code&#34;&gt;Bootup Code&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Reset&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Boot Loader&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;0x00000000 的程式&lt;/li&gt;
&lt;li&gt;把 CPU 重置&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Reset handler&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ststem initialization&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;C startup code&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Application(main)&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;memory-map&#34;&gt;Memory map&lt;/h2&gt;
&lt;p&gt;見官網 memory map&lt;/p&gt;
&lt;p&gt;只用到 SRAM 的 128KB(SRAM)，還有 Code 的 1MB(Flash)&lt;/p&gt;
&lt;h2 id=&#34;sections&#34;&gt;Sections&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;.data
&lt;ul&gt;
&lt;li&gt;儲存資料&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;.text
&lt;ul&gt;
&lt;li&gt;儲存程式碼&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;同 section 會放在一塊是為了設定 read-only 方便，比如 .text 的要靠硬體實現 read-only&lt;/p&gt;
&lt;h2 id=&#34;重要的額外文件&#34;&gt;重要的額外文件&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Linker Script
&lt;ul&gt;
&lt;li&gt;定義了不同 section 該存放的地方，以及 memory 相關定義&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;MEMORY
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    RAM (xrw)		: ORIGIN = 0x20000000, LENGTH = 96K
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    ROM (rx)		: ORIGIN = 0x8000000, LENGTH = 1024K
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;SECTIONS
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;/* The program code and other data into ROM memory */
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;.text :
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    . = ALIGN(8);
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    *(.text)           /* .text sections (code) */
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    *(.text*)          /* .text* sections (code) */
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    *(.glue_7)         /* glue arm to thumb code */
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    *(.glue_7t)        /* glue thumb to arm code */
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    *(.eh_frame)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    KEEP (*(.init))
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    KEEP (*(.fini))
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    . = ALIGN(8);
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    _etext = .;        /* define a global symbols at end of code */
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;} &amp;gt;ROM
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;.data : 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    . = ALIGN(8);
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    _sdata = .;        /* create a global symbol at data start */
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    *(.data)           /* .data sections */
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    *(.data*)          /* .data* sections */
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    . = ALIGN(8);
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    _edata = .;        /* define a global symbol at data end */
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;} &amp;gt;RAM AT&amp;gt; ROM
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;Make File
&lt;ul&gt;
&lt;li&gt;描述如何編譯和連接的規則&lt;/li&gt;
&lt;li&gt;把 startup 的 .s檔加進去&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;startup_stm32.s
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;編譯好後擺在 binary 頭的地方&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;vector table&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;/******************************************************************************
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;*
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;* The STM32L476RGTx vector table.  Note that the proper constructs
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;* must be placed on this to ensure that it ends up at physical address
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;* 0x0000.0000.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;*
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;******************************************************************************/
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;.section .isr_vector,&amp;#34;a&amp;#34;,%progbits
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;.type g_pfnVectors, %object
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;.size g_pfnVectors, .-g_pfnVectors
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;g_pfnVectors:
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;.word _estack
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;.word Reset_Handler
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;.word NMI_Handler
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;.word HardFault_Handler
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;.word	MemManage_Handler
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;.word	BusFault_Handler
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;.word	UsageFault_Handler
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;.word	0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;.word	0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;.word	0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;.word	0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;.word	SVC_Handler
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;Reset_Handler
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Reset_Handler:
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    ldr   r0, =_estack
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    mov   sp, r0          /* set stack pointer */
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    /* Copy the data segment initializers from flash to SRAM */
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    ldr r0, =_sdata
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    ldr r1, =_edata
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    ldr r2, =_sidata
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    movs r3, #0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    b LoopCopyDataInit
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;LoopCopyDataInit:
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    adds r4, r0, r3
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    cmp r4, r1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    bcc CopyDataInit
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    /* Zero fill the bss segment. */
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    ldr r2, =_sbss
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    ldr r4, =_ebss
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    movs r3, #0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    b LoopFillZerobss
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;LoopFillZerobss:
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    cmp r2, r4
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    bcc FillZerobss
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    /* Call the clock system intitialization function.*/
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    bl  SystemInit
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    /* Call static constructors */
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    bl __libc_init_array
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    /* Call the application&amp;#39;s entry point.*/
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    bl main
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;arm-register&#34;&gt;ARM Register&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ARM 的可存取暫存器為 R0-R15&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;r13: Stack Pointer&lt;/li&gt;
&lt;li&gt;r14: Link Register&lt;/li&gt;
&lt;li&gt;r15: Program Counter&lt;/li&gt;
&lt;li&gt;r0~r7 是 low register r8~r15 是 high register&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;狀態暫存器&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CPSR (Current Processor Status Register)
&lt;ul&gt;
&lt;li&gt;用來儲存各種狀態，包含 condition flag，比如 negative, zero, carry, overflow
&lt;ul&gt;
&lt;li&gt;carry: 無符號加法操作是否溢出&lt;/li&gt;
&lt;li&gt;overflow: 有符號加法操作是否溢出&lt;/li&gt;
&lt;li&gt;當兩個都為 1 或都為 0 代表運算沒問題&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;有多種模式，有些模式有自己獨立的 r 暫存器，並有 SPSR，用來在中斷發生時，把 CPSR 的資訊 copy 過去&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Special-purpose registers&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;APSR, IPSR, EPSR&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;assembly-syntax&#34;&gt;Assembly syntax&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;UAL: Unified Assembler Language&lt;/li&gt;
&lt;li&gt;自己去翻 instruction set&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;instructions-class&#34;&gt;Instructions class&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Branch instructions
&lt;ul&gt;
&lt;li&gt;B, BL, BX,&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Data-processing instructions
&lt;ul&gt;
&lt;li&gt;MOV, ADD, SUB, MUL,&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Load and store instructions
&lt;ul&gt;
&lt;li&gt;LDR, STR,&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Status register access instructions
&lt;ul&gt;
&lt;li&gt;MSR, MRS,&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Miscellaneous instructions
&lt;ul&gt;
&lt;li&gt;Memory Barrier instructions&lt;/li&gt;
&lt;li&gt;Exception-Related instructions&lt;/li&gt;
&lt;li&gt;Pseudo instructions&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;examples&#34;&gt;examples&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;MOVS R0, #0x12&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;R0=0x12&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;MOVS R1, #`A` &lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;R1=A(ASCII)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;NVIC_IRQ_SETEN  EQU  0xE000E100&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;宣告常數 NVIC_IRQ_SETEN，賦值 0xE000E100&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;LDR R0,=NVIC_IRQ_SETEN&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;放 0xE000E100 進 R0&lt;/li&gt;
&lt;li&gt;這不能改成 &lt;code&gt;MOVS R0, #0xE000E100 &lt;/code&gt;，因為每個 instruction 只有 32 個 bits，這勢必塞不下，必須從記憶體 load 進來&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;NVIC_IRQ0_ENABLE  EQU  0x1&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;宣告常數 NVIC_IRQ0_ENABLE，賦值 0x1&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;MOVS R1, #NVIC_IRQ0_ENABLE&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;R1=0x1&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;STR R1, [R0]&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;把 0x1 存到 0xE000E100，這裡可以 enable external interrupt IRQ#0&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;LDR rn [pc, #offset to literal pool]&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;load register n with one word from the address [pc + offset]&lt;/li&gt;
&lt;li&gt;最後的形式&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;operand2&#34;&gt;Operand2&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;共有 12 bits
&lt;ul&gt;
&lt;li&gt;設計成 4 bits for rotate, 8 bits for Immediate&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;arm-instrcution-formats&#34;&gt;ARM instrcution formats&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;ADD vs ADDS
&lt;ul&gt;
&lt;li&gt;有 S 代表會去更新 status&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;cond
&lt;ul&gt;
&lt;li&gt;根據之前的執行情況，判斷指令要不要執行&lt;/li&gt;
&lt;li&gt;suffix&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;reverse-ordering-operations&#34;&gt;Reverse Ordering Operations&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;REV (Byte-Reverse Word)
&lt;ul&gt;
&lt;li&gt;把 4 個 Byte 全數反轉，用在一個是 Little-Endian 一個是 Big-Endian 的情況&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;load-and-store-instructions&#34;&gt;Load and Store Instructions&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;examples
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;LDR r0, [r1]&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;r0 = [r1]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;LDM r0, {r1, r2}&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;r1 = [r0]&lt;/li&gt;
&lt;li&gt;r2 = [r0+4]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;STM r0, {r1, r2}&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;[r0] = r1&lt;/li&gt;
&lt;li&gt;[r0+4] = r2&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;status-register-access-instructions&#34;&gt;Status Register Access Instructions&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;一般來說不太會用到，因為用 suffix 就可以看條件&lt;/li&gt;
&lt;li&gt;MRS: Register = Status Register
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;MRS r0, IPSR&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;MSR: Status Register = Register
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;MSR APSR, r0&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;if-then-else&#34;&gt;If-Then-Else&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;用 CMP 和 conditional branches&lt;/li&gt;
&lt;li&gt;Example
&lt;ul&gt;
&lt;li&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  CMP R0, #10   ;compare r0 to 10
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  BLE incr_counter ; if less or equal, then branch to incr_counter
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;branch-instructinos&#34;&gt;Branch Instructinos&lt;/h3&gt;
&lt;p&gt;能跳的距離受限於 operand 長度&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;B-Branch
&lt;ul&gt;
&lt;li&gt;能跳 PC 的 +/- 2046 bytes&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;BL-Branch and Link
&lt;ul&gt;
&lt;li&gt;能跳 PC 的 +/- 254 bytes&lt;/li&gt;
&lt;li&gt;Branch to subroutine 的時候，會把下一行指令放到 Link register&lt;/li&gt;
&lt;li&gt;沒有 push 到 stack，所以要特別小心，register 是共用的，
可能要視情況自己放到 stack
&lt;ul&gt;
&lt;li&gt;比如要進兩層 function，可以用 &lt;code&gt;push {r4-r6, LR}&lt;/code&gt; 和 &lt;code&gt;POP {R4-R6, PC}&lt;/code&gt; 這種做法來保留參數&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;BX-Branch and exchange
&lt;ul&gt;
&lt;li&gt;return&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;stack-memory-access&#34;&gt;Stack memory access&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;PUSH&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SP = SP - N*4&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;POP&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SP = SP + N*4&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ascending/Descending&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;stack 往哪個方向長&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Empty/Full&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;stack 指向下一個空的位置，還是最後一個 item&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;預設且常見的是 fully descending&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;STM 和 LDM 可以透過 suffix 來存到 stack&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;example
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;STMFD r13!, {r4-r7}&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;把 r4 到 r7 push 到 stack&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;memory-barrier-instructions&#34;&gt;Memory Barrier Instructions&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;DMB, SDB, ISB&lt;/li&gt;
&lt;li&gt;在下個指令前 sync memory data&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;function-call-and-parameter-passing&#34;&gt;Function Call and Parameter Passing&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;caller 和 callee 誰負責 backup 和 restore
&lt;ul&gt;
&lt;li&gt;caller 負責
&lt;ul&gt;
&lt;li&gt;不管 callee 怎樣亂搞都行&lt;/li&gt;
&lt;li&gt;但不知道 callee 要用哪些參數，全 backup 可能多此一舉&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;怎麼傳遞參數給 callee
&lt;ul&gt;
&lt;li&gt;常放在 stack，但這樣要透過 memory，相較 register 慢&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;怎麼 return value 給 caller
&lt;ul&gt;
&lt;li&gt;和上個問題差不多&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;arm-procedure-call-standard&#34;&gt;ARM Procedure Call Standard&lt;/h3&gt;
&lt;p&gt;又稱 APCS，講不同的 register 的一種使用規範&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;r0-r3 用來當參數和回傳&lt;/li&gt;
&lt;li&gt;r4-r11 用來 local variable，callee 使用前可以先 backup&lt;/li&gt;
&lt;li&gt;r12-r15 特殊用途，沒事別亂動&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>PatentSBERTa 論文閱讀</title>
        <link>https://roykesydon.github.io/Blog/p/patentsberta-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</link>
        <pubDate>Wed, 15 Mar 2023 15:08:46 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/patentsberta-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</guid>
        <description>&lt;p&gt;paper: &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2103.11933&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PatentSBERTa: A Deep NLP based Hybrid Model for Patent Distance and Classification using Augmented SBERT&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;本研究提供了一個計算  patent-to-patent (p2p) technological similarity 的有效方法。&lt;/p&gt;
&lt;p&gt;並提出一個 hybrid framework，用於把 p2p 相似性的結果應用於 semantic search 和 automated patent classification。&lt;/p&gt;
&lt;p&gt;把 Sentence-BERT (SBERT) 用在 claims 上來作 embeddings。&lt;/p&gt;
&lt;p&gt;為了進一步提升 embedding 的品質，使用基於 SBERT 和 RoBERT 的 transformer model，然後再用 augmented approach 在  in-domain supervised patent claims data(相對於 out-domain) 來 fine-tune SBERT。&lt;/p&gt;
&lt;p&gt;用 KNN(Nearest Neighbors) 來根據 p2p similarity 分類模型。&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;傳統上的 p2p 相似度是基於關鍵字、技術類別等 metadata 決定的，但近期 semantic-based 的方法也越來越受歡迎。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;目前遇到的問題
&lt;ol&gt;
&lt;li&gt;BERT 用來計算 p2p 相似性的成本很高&lt;/li&gt;
&lt;li&gt;基於 generic text 的 pre-trained model 在遇到特定領域的專業術語時可能會遇到侷限。&lt;/li&gt;
&lt;li&gt;在專利做 multi-label classification (MLC) 是個挑戰&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;貢獻
&lt;ol&gt;
&lt;li&gt;提供一個快速高效的框架，利用 Transformer 架構計算 p2p 相似度&lt;/li&gt;
&lt;li&gt;透過 augmented SBERT，將 transformer model fine-tune 到 domain-specific language&lt;/li&gt;
&lt;li&gt;提出一個基於 Transformer 和 傳統 ML 模型的混和架構，可以打敗 multi-label 和 multi-class 的專利分類 SOTA 模型&lt;/li&gt;
&lt;li&gt;用簡單的 KNN 進行專利分類，提供了一種簡單的方法來檢查、理解和解釋模型的預測結果&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;data&#34;&gt;Data&lt;/h2&gt;
&lt;h3 id=&#34;dataset-description&#34;&gt;Dataset Description&lt;/h3&gt;
&lt;p&gt;本研究使用 PatentsView dataset，PatentsView 平台建立在一個定期更新的 database 上。&lt;/p&gt;
&lt;p&gt;dataset 已用於之前類似的研究，比如 DeepPatent、PatentBERT。&lt;/p&gt;
&lt;p&gt;本研究使用了 2013-2017 的所有專利，這些專利至少要在 BigQuery 上有一條 claim。&lt;/p&gt;
&lt;p&gt;本研究的 record 有 1,492,294 項專利，並用 8% 作為測試集。&lt;/p&gt;
&lt;p&gt;此外，本研究刪除了有重複專利 ID 和 claim text 的 record。&lt;/p&gt;
&lt;h3 id=&#34;textual-data-patent-claims&#34;&gt;Textual Data: Patent Claims&lt;/h3&gt;
&lt;p&gt;本研究使用 claim 作為輸入。&lt;/p&gt;
&lt;p&gt;claim 被認為是準備專利文件的初始框架，其他文件都是根據 claim 準備的，
因此，claim 比其他文件包含更全面和準確的訊息。&lt;/p&gt;
&lt;p&gt;claim 具有層次結構，first claim 被視為該架構的主幹。&lt;/p&gt;
&lt;p&gt;本研究僅使用 first claim，但在以後的研究中，希望根據 tree structure 組合所有 claim，並計算 semantic similarity，並做多標籤分類。&lt;/p&gt;
&lt;p&gt;在研究樣本中， claim 平均有 17 個。&lt;/p&gt;
&lt;p&gt;claim 的平均長度是 162，本研究中，BERT 的 max_seq_length 是 510。&lt;/p&gt;
&lt;h3 id=&#34;patent-classification-cpc-classes&#34;&gt;Patent Classification: CPC Classes&lt;/h3&gt;
&lt;p&gt;CPC系統和IPC（國際專利分類）系統是最常用的兩種分類系統，CPC 是 IPC 系統的更具體和詳細的版本。&lt;/p&gt;
&lt;p&gt;CPC 具有用於分類的層次結構，包括 Section、Class、Subclass 和 Group，
在子類級別，CPC 有 667 個標籤。&lt;/p&gt;
&lt;p&gt;在數據集中我們有 663 個標籤，其中 159 個在數據集中的樣本少於 350 個，這種標籤分佈導致了 KNN 不好處理，一般來說，隨著 instance 數量的增加，我們可以提高模型的準確性。&lt;/p&gt;
&lt;h2 id=&#34;method-and-experimental-setup&#34;&gt;Method and experimental setup&lt;/h2&gt;
&lt;p&gt;Pretrained Language Models (LMs) 在 NLP 中變得十分流行。&lt;/p&gt;
&lt;p&gt;在 pairwise sentence semantic similarity，SBERT 和 BERT 是兩種具有顯著不同效果的方法。&lt;/p&gt;
&lt;p&gt;BERT 通常可以取得更好的性能，但在實際應用上來說太慢了。&lt;/p&gt;
&lt;p&gt;SBERT 在實際應用上表現還行，但需要 in-domain training data 並且 finetune。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/PatentSBERTa/Bi_vs_Cross-Encoder.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/PatentSBERTa/approach.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;上圖是 Augmented SBERT In-domain approach。&lt;/p&gt;
&lt;p&gt;in-domain sentence pairs 透過 cross-encoder 來標記，假設有 n 個 in-domain sentences，會有 $C_2^n$ 組可能的組合。&lt;/p&gt;
&lt;p&gt;使用所有可能的組合並不會提高性能，所以要有正確的採樣策略，才可提升性能的同時也減少計算開銷。&lt;/p&gt;
&lt;p&gt;上圖那種結合 cross-encoder 和 bi-encoder 的作法被稱為 Augmented SBERT (AugSBERT)，
涉及以下三個步驟:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;用資料集 Fine-tune RoBERTa 以生出 cross-encoder&lt;/li&gt;
&lt;li&gt;用 cross-encoder 來把未標記的資料標記，同時基於某種特定的採樣策略，從 652,653 種可能的組合中挑選 3432 組&lt;/li&gt;
&lt;li&gt;把資料集 + 額外的 3432 組資料一起拿來訓練 SBERT&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;results&#34;&gt;Results&lt;/h2&gt;
&lt;h3 id=&#34;p2p-similarity-and-semantic-search&#34;&gt;P2P similarity and semantic search&lt;/h3&gt;
&lt;p&gt;Patent Semantic Search (PSS) 是專利分析的基礎部分。&lt;/p&gt;
&lt;p&gt;Transformer 模型等語義相似性的解法是一種新解法，可以用來解決基於關鍵字的搜尋方法中， query terms 和專利內容不匹配的問題。&lt;/p&gt;
&lt;p&gt;為了評估模型的準確性，未來的研究中，作者希望通過 Mean Reciprocal Rank (MRR) 來評估分類結果。&lt;/p&gt;
&lt;h3 id=&#34;cpc-prediction&#34;&gt;CPC Prediction&lt;/h3&gt;
&lt;p&gt;Top-N 準確度等於 GT 與預測有最高概率的任何 N 個預測匹配的頻率，
所以 Top-5 就是最高的五個分類中一個就有中。&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;本文使用  augmented SBERT  獲得 SOTA 的專利文本 embedding。&lt;/p&gt;
&lt;p&gt;介紹了一種 augmented 的方法，把 SBERT 微調到適合 patent claims 的 domain。&lt;/p&gt;
&lt;p&gt;SBERT 的一個主要優點是可以有效率地獲得 embedding distance，使我們能夠為大的專利資料集建構 p2p similarity。&lt;/p&gt;
&lt;p&gt;雖然基於文本的 p2p similarity 的有用性已經在各種應用方面得到證明，但本文進一步證明作者的 transformer-based p2p similarity 可以被用在 SOTA 的專利分類。&lt;/p&gt;
&lt;p&gt;而且使用簡單的 KNN 方法，檢查他們可以使模型決策具備 understandable 和 explainable。&lt;/p&gt;
&lt;h2 id=&#34;limitations--future-research&#34;&gt;Limitations &amp;amp; Future Research&lt;/h2&gt;
&lt;p&gt;未來希望用 Annoy(Approximate Nearest Neighbor Oh Yeah!) 來測試更大樣本的模型並比較結果。&lt;/p&gt;
&lt;p&gt;Annoy(Approximate Nearest Neighbor Oh Yeah!) 是想尋找近似相似而不是精確相似的句子。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Actor-Critic</title>
        <link>https://roykesydon.github.io/Blog/p/actor-critic/</link>
        <pubDate>Tue, 14 Mar 2023 16:21:23 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/actor-critic/</guid>
        <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;結合 policy-based 和 value-based&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A3C
&lt;ul&gt;
&lt;li&gt;Actor-Critic 最知名的方法&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Advantage Actor-Critic 是 A2C&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;advantage-actor-critic&#34;&gt;Advantage Actor-Critic&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Review: Policy gradient&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\triangledown \overline{R_{\theta}}\approx \frac{1}{N}\displaystyle\sum_{n=1}^{N}\displaystyle\sum_{t=1}^{T_n}(\displaystyle\sum_{t^{&amp;rsquo;}=t}^{T_n}\gamma^{t^{&amp;rsquo;}-t}r_{t^{&amp;rsquo;}}^n-b)\triangledown log p_{\theta}(a_t^n|s_t^n)$
&lt;ul&gt;
&lt;li&gt;$G_t^n=\displaystyle\sum_{t^{&amp;rsquo;}=t}^{T_n}\gamma^{t^{&amp;rsquo;}-t}r_{t^{&amp;rsquo;}}^n-b$
&lt;ul&gt;
&lt;li&gt;G very unstable，因為給同樣的 state 作同樣的 action 不一定會得到同樣的結果，G 是個 random variable&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;想要改獲得期望值，取代掉 sample 的值(G 的部分)，可以用 Q-Learning&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$E[G_t^n]=Q^{\pi_\theta}(s_t^n,a_t^n)$
&lt;ul&gt;
&lt;li&gt;Q function 這樣定義&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;所以我們可以把 G 的部分改用 Q 替換掉，就可以把 Actor 和 Critic 結合起來&lt;/li&gt;
&lt;li&gt;baseline 的部分也可以用 value function 替換掉&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;但用 $Q^{\pi}(s_t^n,a_t^n)-V^{\pi}(s_t^n)$ 要一次 estimate 兩個 network&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;可以把 Q 以 V 來表示，那只需要估測 V
&lt;ul&gt;
&lt;li&gt;$Q^{\pi}(s_t^n,a_t^n)=E[r_t^n+V^{\pi}(s_{t+1}^n)]$&lt;/li&gt;
&lt;li&gt;雖然有隨機性(獲得的 reward 和跳到什麼 state 不一定)，但先不管期望值 $Q^{\pi}(s_t^n,a_t^n)=r_t^n+V^{\pi}(s_{t+1}^n)$&lt;/li&gt;
&lt;li&gt;現在雖然多個一個 r，有一些 variance，但也比 G 好&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$\triangledown \overline{R_{\theta}}\approx \frac{1}{N}\displaystyle\sum_{n=1}^{N}\displaystyle\sum_{t=1}^{T_n}(r_t^n+V^{\pi}(s_{t+1}^n)-V^{\pi}(s_t^n))\triangledown log p_{\theta}(a_t^n|s_t^n)$&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/drl/actor-critic/A2C.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;tips&#34;&gt;Tips&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;actor $\pi(s)$ 和 critic $V^{\pi}(s)$ 的權重可以共享&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;前面幾個 layer 可以 share&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;對 $\pi$ 的 output 下 constrain，讓他的 entropy 不要太小，達到 exploration 的效果&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;asynchronous-advantage-actor-critic&#34;&gt;Asynchronous Advantage Actor-Critic&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;一開始有個 global network，開一堆 worker，每次工作前，把 global network 的參數 copy 過去&lt;/li&gt;
&lt;li&gt;個別去和環境作互動，更新的梯度施加在 global network 上&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;pathwise-derivative-policy-gradient&#34;&gt;Pathwise Derivative Policy Gradient&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;可以當作是 Q-Learning 解 continuous action 的一種方法&lt;/li&gt;
&lt;li&gt;訓練一個 actor，目標是生出的 a 餵給 Q 後，可以讓 Q function 的輸出越大越好
&lt;ul&gt;
&lt;li&gt;只會調 actor 的參數，會 fix Q 的&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;就是個 GAN&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/drl/actor-critic/pathwise.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;在每個 episode&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;對於每個 time step t
&lt;ul&gt;
&lt;li&gt;⚠️給 state $s_t$，根據 $\pi$ 執行 action $a_t$ (epsilon greedy)⚠️&lt;/li&gt;
&lt;li&gt;獲得 reward $r_t$，到達 $s_{t+1}$&lt;/li&gt;
&lt;li&gt;把 {$s_t,a_t,r_t,s_{t+1}$} 存到 buffer&lt;/li&gt;
&lt;li&gt;從 buffer sample {$s_t,a_t,r_t,s_{t+1}$}(通常是一個 batch)&lt;/li&gt;
&lt;li&gt;⚠️Target $y=r_i+\hat{Q}(s_{i+1},\hat{\pi}(s_{i+1}))$⚠️&lt;/li&gt;
&lt;li&gt;Update Q 的參數，好讓 $Q(s_i,a_i)$ 更接近 y(regression)&lt;/li&gt;
&lt;li&gt;⚠️Update $\pi$ 的參數，讓 $Q(s_i,\pi(s_i))$ 最大化⚠️&lt;/li&gt;
&lt;li&gt;每 C 步 reset $\hat{Q}=Q$&lt;/li&gt;
&lt;li&gt;⚠️每 C 步 reset $\hat{\pi}=\pi$⚠️&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;⚠️ 是和 Q-Learning 不一樣的地方&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Database Normalization</title>
        <link>https://roykesydon.github.io/Blog/p/database-normalization/</link>
        <pubDate>Tue, 14 Mar 2023 10:26:17 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/database-normalization/</guid>
        <description>&lt;h2 id=&#34;normalization-目的&#34;&gt;Normalization 目的&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;避免 redundent information&lt;/li&gt;
&lt;li&gt;更容易 understand、enhance、extend&lt;/li&gt;
&lt;li&gt;避免 anomalies&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;隨著 1NF ~ 5NF，有更多的 safety guarantee&lt;/p&gt;
&lt;h2 id=&#34;1nf&#34;&gt;1NF&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;違反條件
&lt;ul&gt;
&lt;li&gt;用 row order 傳達資訊&lt;/li&gt;
&lt;li&gt;mixing data types in single column
&lt;ul&gt;
&lt;li&gt;但 relational database 不會讓你這樣做&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;存在沒有 primary key 的 table&lt;/li&gt;
&lt;li&gt;repeating groups
&lt;ul&gt;
&lt;li&gt;同一個 column 有多個數值，或是在同一個 row 存多個同類型的數值。&lt;/li&gt;
&lt;li&gt;ex :
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;player&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;item&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;roy&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;1 item_1, 4 item_2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;star&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;4 item_4&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;player&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;item_type1&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;quantity1&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;item_type2&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;quantity2&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;roy&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;item1&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;1&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;item2&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;star&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;item_4&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;4&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;2nf&#34;&gt;2NF&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;所有的 non-key attribute 都要 depend on 整個 PK
&lt;ul&gt;
&lt;li&gt;非正式定義，有點細微差異&lt;/li&gt;
&lt;li&gt;functional dependency
&lt;ul&gt;
&lt;li&gt;ex: {player_id, item_type} -&amp;gt; {item_Quantity}&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;3nf&#34;&gt;3NF&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;transitive dependency
&lt;ul&gt;
&lt;li&gt;{A} -&amp;gt; {B} -&amp;gt; {C}&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;所有 non-key attribute 都要 depend on the whole key，不能 depend on 其他 non-key attribute&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;boyce-codd-normal-form&#34;&gt;Boyce-Codd Normal Form&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;所有 attribute 都要 depend on the whole key，不能 depend on 其他 non-key attribute&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;4nf&#34;&gt;4NF&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;multivalued dependency
&lt;ul&gt;
&lt;li&gt;不像 functional dependency，箭頭後方的那項可以有多個 value&lt;/li&gt;
&lt;li&gt;{Model} $\twoheadrightarrow$ {Color}&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;一個 table 中的所有 multivalued dependency 必須依賴於 key&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;5nf&#34;&gt;5NF&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;沒有 Join Dependency
&lt;ul&gt;
&lt;li&gt;table 不能表示成其他 table join 起來的結果&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Sentence-BERT 論文閱讀</title>
        <link>https://roykesydon.github.io/Blog/p/sentence-bert-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</link>
        <pubDate>Sun, 12 Mar 2023 10:08:46 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/sentence-bert-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</guid>
        <description>&lt;p&gt;paper: &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/1908.10084&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;BERT 和 RoBERTa 在 semantic textual similarity (STS) 上太花時間，因為他需要將兩個句子都輸入網路，並且兩兩比對。&lt;/p&gt;
&lt;p&gt;Sentence-BERT(SBERT) 對預訓練的 BERT 作了一些修改，透過 siamese 和 triplet network 的結構來生出有意義的 embeddings，使其最後可以透過 cosine-similarity 比較相似度。&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;SBERT 使 BERT 可以用於某些迄今為止不適用於 BERT 的任務，比如 large-scale semantic similarity comparison、clustering 還有 information retrieval via semantic search。&lt;/p&gt;
&lt;p&gt;以往的相關研究是把單個句子輸入 BERT，最後 average BERT output layer，或是使用第一個 output，但這樣會產生糟糕的 sentence embeddings。&lt;/p&gt;
&lt;p&gt;SentEval 是一個 evaluation toolkit for sentence embeddings&lt;/p&gt;
&lt;h2 id=&#34;related-work&#34;&gt;Related Work&lt;/h2&gt;
&lt;p&gt;BERT 透過輸入兩個句子，以 [SEP] 隔開，可以在 STS 取得 SOTA。&lt;/p&gt;
&lt;p&gt;但這樣無法計算獨立的 sentence embedding，所以過往的研究人員把單個句子輸入 BERT，最後 average BERT output layer，或是使用第一個 output。&lt;/p&gt;
&lt;h2 id=&#34;model&#34;&gt;Model&lt;/h2&gt;
&lt;p&gt;SBERT 在 BERT / RoBERTa 的輸出中添加了 pooling，作者嘗試了三種策略，CLS-token 的輸出、所以輸出向量的平均、max-over-time of the output vectors，默認是 MEAN。&lt;/p&gt;
&lt;p&gt;實驗以下結構和目標函數:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Classification Objective Function&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/SBERT/COF-1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/SBERT/COF-2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Regression Objective Function&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;用 mean squared-error loss&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/SBERT/ROF.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;
&lt;p&gt;Triplet Objective Function&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/SBERT/TOF.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;training-details&#34;&gt;Training Details&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Dataset
&lt;ul&gt;
&lt;li&gt;SNLI 結合 Multi-Genre NLI
&lt;ul&gt;
&lt;li&gt;SNLI: 570,000 個 句子 pair，有三類，contradiction, eintailment, and neutral&lt;/li&gt;
&lt;li&gt;MultiNLI: 430,000 個句子 pair&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;3-way softmax Classification Objective Function&lt;/li&gt;
&lt;li&gt;1-epoch&lt;/li&gt;
&lt;li&gt;batch-size: 16&lt;/li&gt;
&lt;li&gt;Adam&lt;/li&gt;
&lt;li&gt;lr: 2e-5&lt;/li&gt;
&lt;li&gt;warm-up: 超過 10% of the training data&lt;/li&gt;
&lt;li&gt;默認 pooling 策略: MEAN&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;evaluation&#34;&gt;Evaluation&lt;/h2&gt;
&lt;p&gt;學習一個複雜的回歸函數分析 STS 常是 SOTA，但是由於他是 pair-wise，遇到 combinatorial explosion，不好拓展。&lt;/p&gt;
&lt;p&gt;本文用 cosine-similarity 比較兩個 embeddings 的相似度，也用 negative Manhatten 和 negative Euclidean distances，但得到差不多的結果。&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;用 BERT 生出的 embeddings 不適合常見的相似度測量方法，比如 cosine-similarity。&lt;/p&gt;
&lt;p&gt;本文提出 SBERT 改進，在 siamese / triplet 網路架構中微調 BERT。&lt;/p&gt;
&lt;p&gt;用 RoBERTa 替換掉 BERT 並沒有什麼顯著改進。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>軟體設計原則</title>
        <link>https://roykesydon.github.io/Blog/p/%E8%BB%9F%E9%AB%94%E8%A8%AD%E8%A8%88%E5%8E%9F%E5%89%87/</link>
        <pubDate>Wed, 08 Mar 2023 14:26:17 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/%E8%BB%9F%E9%AB%94%E8%A8%AD%E8%A8%88%E5%8E%9F%E5%89%87/</guid>
        <description>&lt;h2 id=&#34;uml-類別圖&#34;&gt;UML 類別圖&lt;/h2&gt;
&lt;h3 id=&#34;relationship&#34;&gt;Relationship&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Dependency
&lt;ul&gt;
&lt;li&gt;&amp;ldquo;uses-a&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Association
&lt;ul&gt;
&lt;li&gt;&amp;ldquo;knows-a&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Composition
&lt;ul&gt;
&lt;li&gt;&amp;ldquo;has-a&amp;rdquo;&lt;/li&gt;
&lt;li&gt;child 的存在依賴於 parent，若刪除 parent，child 也會隨之刪除&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Aggregation
&lt;ul&gt;
&lt;li&gt;&amp;ldquo;has-a&amp;rdquo;&lt;/li&gt;
&lt;li&gt;child 的存在獨立於 parent，若刪除 parent，child 不會隨之刪除&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Inheritance
&lt;ul&gt;
&lt;li&gt;&amp;ldquo;is-a&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Implementation
&lt;ul&gt;
&lt;li&gt;&amp;ldquo;can-do&amp;rdquo;&lt;/li&gt;
&lt;li&gt;實現 interface&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;other-features&#34;&gt;other features&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Navigation
&lt;ul&gt;
&lt;li&gt;當兩個 class 都可以看到對方，就用沒箭頭的關聯線，否則有箭頭&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Role Name
&lt;ul&gt;
&lt;li&gt;類別中的 Attribute&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Multiplicity
&lt;ul&gt;
&lt;li&gt;關聯端點上可以寫數量，代表物件個數&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Self-Association
&lt;ul&gt;
&lt;li&gt;同個類別的物件彼此有關係&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;軟體設計原則&#34;&gt;軟體設計原則&lt;/h2&gt;
&lt;h3 id=&#34;encapsulate-what-varies&#34;&gt;Encapsulate What Varies&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;把經常改變的程式碼封裝起來，使日後修改時不會影響其他區塊的程式碼&lt;/li&gt;
&lt;li&gt;實際使用的情境，可以把常改變的東西放在 interface 後，使日後改變實作時不影響呼叫該 interface 的程式碼&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;favor-composition-over-inheritance&#34;&gt;Favor Composition over Inheritance&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Composition(組合)在很多情境可以取代掉 Inheritance(繼承)，甚至實現 Polymorphism(多型)&lt;/li&gt;
&lt;li&gt;只有當 is-a 的情境出現，才用繼承比較好&lt;/li&gt;
&lt;li&gt;Composition 使用起來更有彈性&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;solid-設計原則&#34;&gt;SOLID 設計原則&lt;/h2&gt;
&lt;h3 id=&#34;single-responsibility-principle-srp&#34;&gt;Single Responsibility Principle, SRP&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;單一職責原則&lt;/li&gt;
&lt;li&gt;A class should have only one reason to change.&lt;/li&gt;
&lt;li&gt;可以把一個複雜的 module 拆成多個&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;open-close-principle-ocp&#34;&gt;Open-Close Principle, OCP&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;開放封閉原則&lt;/li&gt;
&lt;li&gt;You should be able to extend the behavior of a system without having to modify that system.&lt;/li&gt;
&lt;li&gt;要可以擴充，同時不修改到原系統&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;liskovsubstitution-principle-lsp&#34;&gt;LiskovSubstitution Principle, LSP&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;里氏替換原則&lt;/li&gt;
&lt;li&gt;父類別有的功能，子類別必須遵從，父類別的部分要可以直接替換成子類別&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;interface-segregation-principle-isp&#34;&gt;Interface Segregation Principle, ISP&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;介面隔離原則&lt;/li&gt;
&lt;li&gt;No client should be forced to depend on methods it does not use&lt;/li&gt;
&lt;li&gt;以 interface 來說，不該讓 module 實現它不需要的功能，可以把 interface 拆小&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;dependency-inversion-principle-dip&#34;&gt;Dependency Inversion Principle, DIP&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;反向依賴原則&lt;/li&gt;
&lt;li&gt;高階模組不應該依賴低階模組，兩者都應依賴抽象層&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>PatentBERT 論文閱讀</title>
        <link>https://roykesydon.github.io/Blog/p/patentbert-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</link>
        <pubDate>Thu, 02 Mar 2023 16:08:46 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/patentbert-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</guid>
        <description>&lt;p&gt;paper: &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/1906.02124&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PatentBERT: Patent Classification with Fine-Tuning a pre-trained BERT Model&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;abstract&#34;&gt;Abstract&lt;/h1&gt;
&lt;p&gt;把 fine-tune BERT 應用在專利分類上，當應用於超過 200 萬件專利的資料集時，該方法超越了結合 word-embedding 的 CNN 的 SOTA 作法。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;貢獻:
&lt;ol&gt;
&lt;li&gt;一個用預訓練的 BERT 去 fine-tune 的 SOTA 方法&lt;/li&gt;
&lt;li&gt;一個叫做 USPTO-3M 的大型資料集，屬於 CPC subclass level，並提供 SQL 語句讓後續的研究者使用&lt;/li&gt;
&lt;li&gt;與傳統觀念相反，只需要 claim 就足以完成分類任務&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;專利分類是一個 multi-label 的分類任務。&lt;/p&gt;
&lt;p&gt;由於標籤的數量可能很大，所以是個具有挑戰性的任務。&lt;/p&gt;
&lt;p&gt;作者準備了一個基於 CPC 的新資料集，有超過三百萬項美國專利。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CPC
&lt;ul&gt;
&lt;li&gt;Cooperative Patent Classification&lt;/li&gt;
&lt;li&gt;是 IPC 更具體和詳細的版本&lt;/li&gt;
&lt;li&gt;可預見將取代 IPC 成為新的標準
&lt;ul&gt;
&lt;li&gt;只是由於 CLEP-IP 競賽，大部分論文都基於 IPC
&lt;ul&gt;
&lt;li&gt;資料集包含 1978 到 2009 提交的專利&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;IPC
&lt;ul&gt;
&lt;li&gt;International Patent Classification&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;此外，作者的 dataset 基於 patent claims&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;patent claims
&lt;ul&gt;
&lt;li&gt;重要性在過往被低估&lt;/li&gt;
&lt;li&gt;在起草專利申請時，專利業者會先起草 patent claims&lt;/li&gt;
&lt;li&gt;專利文件的其餘部分由 claim 做延伸&lt;/li&gt;
&lt;li&gt;在專利法中，claims 定義了專利發明的界線，確定了專利權範圍&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;為使模型更簡單，只關注 patent claims，並且僅用第一項 claim。&lt;/p&gt;
&lt;h1 id=&#34;相關工作&#34;&gt;相關工作&lt;/h1&gt;
&lt;p&gt;過往有些研究只顯示了 precision，但沒有 F1 value 或 recall，難以公平比較。&lt;/p&gt;
&lt;p&gt;以 DeepPatent&lt;/p&gt;
&lt;h1 id=&#34;data&#34;&gt;Data&lt;/h1&gt;
&lt;p&gt;過往資料基於 CLEF-IP 或 patent offices。&lt;/p&gt;
&lt;p&gt;作者發現在 BigQuery 用 Google Patents Public Datasets 更容易。&lt;/p&gt;
&lt;p&gt;而且可用 SQL statements，作者認為比共享傳統資料集更好，原因如下:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Seperation of concerns
&lt;ul&gt;
&lt;li&gt;如果資料包含前處理或後處理，其他研究人員需要不同操作時會很頭痛。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Clarity and flexibility
&lt;ul&gt;
&lt;li&gt;SQL statement 精確且容易根據不同條件進行修改。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在和 DeepPatent 比較的時候，可以的話，會用 USPTO2M 進行測試，如果不行，才會合併來自 USPTO-3M 的資料，比如 USPTO-2M 沒有 claims 的情況。&lt;/p&gt;
&lt;p&gt;為了比較 claim 如何影響性能，將合併兩個資料集。&lt;/p&gt;
&lt;h1 id=&#34;method--experimental-setup&#34;&gt;Method &amp;amp; Experimental Setup&lt;/h1&gt;
&lt;p&gt;用 BERT-Base 就可以打敗 DeepPatent。&lt;/p&gt;
&lt;p&gt;遵循 BERT Project 中給的 fine-tune 範例。&lt;/p&gt;
&lt;p&gt;為了 multilabel，用 sigmoid cross entropy with logits function 而不是用 softmax。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/PatentBERT/result.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h1 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;專利分類作為具有挑戰性的任務，幾十年來一直沒有令人滿意的表現。&lt;/p&gt;
&lt;p&gt;本文提出一個基於 fine-tune BERT 的方法，性能優於 DeepPatent。&lt;/p&gt;
&lt;p&gt;並且結果表明只用 patent claim 就可以完成分類任務。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>線性代數 - II</title>
        <link>https://roykesydon.github.io/Blog/p/%E7%B7%9A%E6%80%A7%E4%BB%A3%E6%95%B8-ii/</link>
        <pubDate>Tue, 21 Feb 2023 15:42:47 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/%E7%B7%9A%E6%80%A7%E4%BB%A3%E6%95%B8-ii/</guid>
        <description>&lt;h1 id=&#34;linear-equation&#34;&gt;linear equation&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;$a_1x_1+a_2x_2+&amp;hellip;+a_nx_n = b$
&lt;ul&gt;
&lt;li&gt;$a$ 是 coefficient&lt;/li&gt;
&lt;li&gt;$x$ 是 variables&lt;/li&gt;
&lt;li&gt;$b$ 是 constant term&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;systems-of-linear-equations&#34;&gt;Systems of linear equations&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;m equations, n variables&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$a_{11}x_1+a_{12}x_2+&amp;hellip;+a_{1n}x_n = b_1\\
a_{21}x_1+a_{22}x_2+&amp;hellip;+a_{2n}x_n = b_2\\
&amp;hellip;\\
a_{m1}x_1+a_{m2}x_2+&amp;hellip;+a_{mn}x_n = b_m$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;solution&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$[s_1~s_2~&amp;hellip;~s_n]^T$ 是一組解，代換到 $x_1$~$x_n$ 後滿足所有 equation 的向量&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;所有 Systems of linear equations 都有&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;no solution&lt;/li&gt;
&lt;li&gt;exactly one solution&lt;/li&gt;
&lt;li&gt;infinitely many solutions&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;consistent/inconsistent&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果有一組以上的解就是 consistent&lt;/li&gt;
&lt;li&gt;無解就是 inconsistent&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;equivalent&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果兩組 Systems of linear equations 的 solution set 一樣，稱為 equivalent&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;elementary row operations&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;不會影響 solution set&lt;/li&gt;
&lt;li&gt;types
&lt;ul&gt;
&lt;li&gt;Interchange
&lt;ul&gt;
&lt;li&gt;兩 row 互換&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Scaling
&lt;ul&gt;
&lt;li&gt;某 row 乘某個 nonzero scalar&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Row addition
&lt;ul&gt;
&lt;li&gt;把某 row 乘某個 scalar 後加到某 row&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;property
&lt;ul&gt;
&lt;li&gt;所有 elementary row operations 都是 reversible&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;用來求解&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;coefficient matrix&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$a_{11}x_1+a_{12}x_2+&amp;hellip;+a_{1n}x_n = b_1\\
a_{21}x_1+a_{22}x_2+&amp;hellip;+a_{2n}x_n = b_2\\
&amp;hellip;\\
a_{m1}x_1+a_{m2}x_2+&amp;hellip;+a_{mn}x_n = b_m$
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;可以拆為 $Ax=b$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$A=\begin{bmatrix}
a_{11}&amp;amp; a_{12}&amp;amp;&amp;hellip;&amp;amp; a_{1n} \\
a_{21}&amp;amp; a_{22}&amp;amp;&amp;hellip;&amp;amp; a_{2n} \\
&amp;hellip;&amp;amp; &amp;hellip;&amp;amp;&amp;hellip;&amp;amp; &amp;hellip; \\
a_{m1}&amp;amp; a_{m2}&amp;amp;&amp;hellip;&amp;amp; a_{mn}
\end{bmatrix}$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A 就是 coefficient matrix&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$x=\begin{bmatrix}
x_1\\
x_2\\
&amp;hellip;\\
x_n
\end{bmatrix}$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$x$ 是 variable vector&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$[A|b]=\begin{bmatrix}
a_{11}&amp;amp; a_{12}&amp;amp;&amp;hellip;&amp;amp; a_{1n} &amp;amp; b_1 \\
a_{21}&amp;amp; a_{22}&amp;amp;&amp;hellip;&amp;amp; a_{2n} &amp;amp; b_2\\
&amp;hellip;&amp;amp; &amp;hellip;&amp;amp;&amp;hellip;&amp;amp; &amp;hellip; &amp;amp; &amp;hellip;\\
a_{m1}&amp;amp; a_{m2}&amp;amp;&amp;hellip;&amp;amp; a_{mn} &amp;amp; b_m
\end{bmatrix}$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;叫做 augmented matrix&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>線性代數 - I</title>
        <link>https://roykesydon.github.io/Blog/p/%E7%B7%9A%E6%80%A7%E4%BB%A3%E6%95%B8-i/</link>
        <pubDate>Tue, 21 Feb 2023 14:42:47 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/%E7%B7%9A%E6%80%A7%E4%BB%A3%E6%95%B8-i/</guid>
        <description>&lt;h1 id=&#34;matrix&#34;&gt;matrix&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;a rectangular array of scalars&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;size&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;m by n&lt;/li&gt;
&lt;li&gt;叫做 square if m = n&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;equal&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;兩個矩陣的 size 和每個 entry 都一樣&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;submatrix&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;從一個大矩陣刪掉 rows 或 columns&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;addition&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;兩個大小相同的矩陣，每個對應位置的 entry 兩兩相加&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;scalar multiplication&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一個矩陣的所有 entry 乘以某個 scalar&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;zero matrix&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;所有 entry 都是 0，該矩陣常以 $O_{n \times m}$ 來表示&lt;/li&gt;
&lt;li&gt;性質
&lt;ul&gt;
&lt;li&gt;$A = O + A$&lt;/li&gt;
&lt;li&gt;$0 \cdot A = O $&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;subtraction&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$A-B=A+(-B)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;transpose&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$A^T$ 的 $(i,j)$-entry 是 $A$ 的 $(j,i)$-entry&lt;/li&gt;
&lt;li&gt;Properties
&lt;ul&gt;
&lt;li&gt;$(A+B)^T=A^T+B^T$&lt;/li&gt;
&lt;li&gt;$(sA)^T=sA^T$&lt;/li&gt;
&lt;li&gt;$(A^T)^T=A$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;vectors&#34;&gt;vectors&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;type&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;row vector
&lt;ul&gt;
&lt;li&gt;只有 1 row 的 matrix&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;column vector
&lt;ul&gt;
&lt;li&gt;只有 1 column 的 matrix&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;components&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the entries of a vector&lt;/li&gt;
&lt;li&gt;用 the $i$ th component 代表 $v_i$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;addition, scalar multiplication&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;和 matrix 一樣&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;矩陣表示&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一個矩陣常被表示為
&lt;ul&gt;
&lt;li&gt;a stack of row vectors&lt;/li&gt;
&lt;li&gt;a cross list of column vectors&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;linear-combination&#34;&gt;linear combination&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$c_1u_1+c_2u_2+&amp;hellip;+c_ku_k$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;scalars&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$c_1,c_2,&amp;hellip;,c_k$&lt;/li&gt;
&lt;li&gt;又被稱作 linear combination 的 coefficients&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;vectors&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$u_1,u_2,&amp;hellip;,u_k$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果 $u,v$ 非平行二維向量，則二維空間中所有向量皆是 $u,v$ 的 linear combination，且是 unique 的&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;standard-vectors&#34;&gt;standard vectors&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$e_1 = \begin{bmatrix}
1 \\
0 \\
&amp;hellip; \\
0
\end{bmatrix}
,e_2 = \begin{bmatrix}
0 \\
1 \\
&amp;hellip; \\
0
\end{bmatrix},&amp;hellip;,
e_n = \begin{bmatrix}
0 \\
0 \\
&amp;hellip; \\
1
\end{bmatrix}$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$R^n$ 的任何一個向量都可以被 standard vectors 表示成 uniquely linearly combined&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;矩陣向量乘法&#34;&gt;矩陣向量乘法&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;$Av=v_1a_1+v_2a_2+&amp;hellip;+v_na_n$&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;identity-matrix&#34;&gt;Identity Matrix&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;對整數 n，$n \times n$ identity matrix
&lt;ul&gt;
&lt;li&gt;$I_n$&lt;/li&gt;
&lt;li&gt;每個 columns 是 standard vectors $e_1, e_2, &amp;hellip;, e_n$ in $R^n$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;stochastic-matrix&#34;&gt;Stochastic Matrix&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;對整數 n，$n \times n$ stochastic matrix&lt;/li&gt;
&lt;li&gt;所有 entry 都必須非負&lt;/li&gt;
&lt;li&gt;每個 column 的 entry 總和必須是 unity (相加為 1)&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Process Scheduling</title>
        <link>https://roykesydon.github.io/Blog/p/process-scheduling/</link>
        <pubDate>Mon, 20 Feb 2023 21:12:52 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/process-scheduling/</guid>
        <description>&lt;h1 id=&#34;process-scheduling&#34;&gt;Process Scheduling&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;可能時機&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;running -&amp;gt; waiting&lt;/li&gt;
&lt;li&gt;running -&amp;gt; ready&lt;/li&gt;
&lt;li&gt;waiting -&amp;gt; ready&lt;/li&gt;
&lt;li&gt;running -&amp;gt; terminate&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Process Scheduler&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Preemptive scheduler (Time slice)
&lt;ul&gt;
&lt;li&gt;可以被搶占&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Non-Preemptive scheduler
&lt;ul&gt;
&lt;li&gt;又稱 cooperative scheduling&lt;/li&gt;
&lt;li&gt;只可能出現在時機 1 或 4&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Classification fo Processes(related to scheduling)&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Interactive Processes (50 - 150 ms)&lt;/li&gt;
&lt;li&gt;Batch Processes&lt;/li&gt;
&lt;li&gt;Real time Processes
&lt;ul&gt;
&lt;li&gt;Hard&lt;/li&gt;
&lt;li&gt;Soft&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Classification of Processes(related to CPU usage)&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;CPU Bound&lt;/li&gt;
&lt;li&gt;I/O Bound&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;standard-scheduling-algorithm&#34;&gt;Standard Scheduling Algorithm&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;FCFS&lt;/li&gt;
&lt;li&gt;SJF&lt;/li&gt;
&lt;li&gt;SRTF&lt;/li&gt;
&lt;li&gt;Priority Based&lt;/li&gt;
&lt;li&gt;Highest Response Ratio Next&lt;/li&gt;
&lt;li&gt;Round Robin&lt;/li&gt;
&lt;li&gt;Virtual RR&lt;/li&gt;
&lt;li&gt;Multi-Level Queue Scheduler&lt;/li&gt;
&lt;li&gt;Multi-Level Feed Back Queue Scheduler&lt;/li&gt;
&lt;li&gt;Rotating Staircase Deadline Scheduler&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;unix-svr3-scheduler&#34;&gt;UNIX SVR3 Scheduler&lt;/h1&gt;
&lt;p&gt;有 32 個 runqueue，每個 runqueue 負責 4 個 priority values&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;128 Priority values&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;0-49: Kernel&lt;/li&gt;
&lt;li&gt;50-127: User&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$Priority_j=Base_j+CPU_j(i)+nice_j$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Base: 0-127&lt;/li&gt;
&lt;li&gt;$CPU_j(i) = DR * CPU_j(i-1)$
&lt;ul&gt;
&lt;li&gt;DR = $\frac{1}{2}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;nice: -20 ~ +19
&lt;ul&gt;
&lt;li&gt;可以用 nice 和 renice 改 process nice value&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;schedtool&#34;&gt;Schedtool&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Query &amp;amp; set per process scheduling parameters&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Scheduling Policy
&lt;ul&gt;
&lt;li&gt;Real time
&lt;ol&gt;
&lt;li&gt;SCHED_RR&lt;/li&gt;
&lt;li&gt;SCHED_FIFO&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Conventional
&lt;ol&gt;
&lt;li&gt;SCHED_NORMAL (default)&lt;/li&gt;
&lt;li&gt;SCHED_BATCH (CPU intensive)&lt;/li&gt;
&lt;li&gt;SCHED_ISO (unused)&lt;/li&gt;
&lt;li&gt;SCHED_IDLEPRIO (low pri jobs)&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Nice Value (-20 to +19)&lt;/li&gt;
&lt;li&gt;Static Priority (1-99)&lt;/li&gt;
&lt;li&gt;CPU affinity
&lt;ul&gt;
&lt;li&gt;process 想運行在某個指定的 CPU 上，不被轉移到其他 CPU，才不會降低指定 CPU 的 cache 命中率
&lt;ul&gt;
&lt;li&gt;soft CPU affinity&lt;/li&gt;
&lt;li&gt;hard CPU affinity&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;cpus_allowed
&lt;ul&gt;
&lt;li&gt;一個用來指定 CPU 的 mask&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  schedtool &amp;lt;PID&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Q-learning</title>
        <link>https://roykesydon.github.io/Blog/p/q-learning/</link>
        <pubDate>Mon, 20 Feb 2023 16:21:23 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/q-learning/</guid>
        <description>&lt;h2 id=&#34;rl-方法&#34;&gt;RL 方法&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Policy-based
&lt;ul&gt;
&lt;li&gt;learn 做事的 actor&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Value-based
&lt;ul&gt;
&lt;li&gt;不直接 learn policy，而是 Learn critic，負責批評&lt;/li&gt;
&lt;li&gt;Q-learning 屬於這種&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;critic&#34;&gt;Critic&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;不直接決定 action&lt;/li&gt;
&lt;li&gt;給予 actor $\pi$，評估 actor $\pi$ 有多好&lt;/li&gt;
&lt;li&gt;critic 的 output 依賴於 actor 的表現&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;state-value-function&#34;&gt;State Value Function&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;State value function $V^{\pi}(s)$
&lt;ul&gt;
&lt;li&gt;用 actor $\pi$，看到 s 後玩到結束，cumulated reward expectation 是多少&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;評估方法&#34;&gt;評估方法&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Monte-Carlo(MC) based approach&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;critic 看 $\pi$ 玩遊戲&lt;/li&gt;
&lt;li&gt;訓練一個 network，看到不同的 state ，輸出 cumulated reward(直到遊戲結束，以下稱為 $G_a$)，解 regression 問題&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Temporal-difference(TD) approach&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MC 的方法至少要玩到遊戲結束才可以 update network，但有些遊戲超長
&lt;ul&gt;
&lt;li&gt;TD 只需要 {$s_t,a_t,r_t,s_{t+1}$}&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;$V^{\pi}(s_t)=V^{\pi}(s_{t+1})+r_t$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;MS v.s. TD&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MC
&lt;ul&gt;
&lt;li&gt;Larger variance
&lt;ul&gt;
&lt;li&gt;每次的輸出差異很大&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;TD
&lt;ul&gt;
&lt;li&gt;smaller variance
&lt;ul&gt;
&lt;li&gt;相較 $G_a$ 較小，因為這邊的 random variable 是 r，但 $G_a$ 是由很多 r 組合而成&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;V 可能估得不準確
&lt;ul&gt;
&lt;li&gt;那 learn 出來的結果自然也不准&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;較常見&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;another-critic&#34;&gt;Another Critic&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;State-action value function $Q^\pi(s,a)$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;又叫 Q function&lt;/li&gt;
&lt;li&gt;當用 actor $\pi$ 時，在 state s 採取 a 這個 action 後的 cumulated reward expectation
&lt;ul&gt;
&lt;li&gt;有一個要注意的地方是，actor 看到 s 不一定會採取 a&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/drl/q-learning/q-function.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/drl/q-learning/how-to-use-q.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;只要有 Q function，就可以找到&amp;quot;更好的&amp;quot; policy，再替換掉原本的 policy
&lt;ul&gt;
&lt;li&gt;&amp;ldquo;更好的&amp;quot;定義
&lt;ul&gt;
&lt;li&gt;$V^{\pi^{&amp;rsquo;}} \ge V^{\pi}(s), \text{for all state s}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;$\pi^{&amp;rsquo;}(s)=arg \underset{a}{max}Q^{\pi}(s,a)$
&lt;ul&gt;
&lt;li&gt;$\pi^{&amp;rsquo;}$ 沒有多餘的參數，就單純靠 Q function 推出來&lt;/li&gt;
&lt;li&gt;這邊如果 a 是 continuous 的會有問題，等等解決&lt;/li&gt;
&lt;li&gt;這樣就可以達到&amp;quot;更好的&amp;quot;policy，不過就不列證明了&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;basic-tip&#34;&gt;Basic Tip&lt;/h2&gt;
&lt;h3 id=&#34;target-network&#34;&gt;Target network&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;在 training 的時候，把其中一個 Q 固定住，不然要學的 target 是不固定的，會不好 train&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/drl/q-learning/target-network.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;exploration&#34;&gt;Exploration&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;policy 完全 depend on Q function&lt;/li&gt;
&lt;li&gt;如果 action 總是固定，這不是好的 data collection 方法，要在 s 採取 a 過，才比較好估計 Q(s, a)，如果 Q function 是 table 就根本不可能估出來，network 也會有一樣的問題，只是沒那麼嚴重。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;解法&#34;&gt;解法&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Epsilon Greedy
&lt;ul&gt;
&lt;li&gt;$a=\begin{cases}
arg \underset{a}{max}Q(s,a), &amp;amp; \text{with probability } 1-\varepsilon \\
random, &amp;amp; otherwise
\end{cases}$&lt;/li&gt;
&lt;li&gt;通常 $\varepsilon$ 會隨時間遞減，因為你一開始 train 的時候不知道怎麼比較好&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Boltzmann Exploration
&lt;ul&gt;
&lt;li&gt;$P(a|s)=\frac{exp(Q(s,a))}{\sum_a exp(Q(s,a))}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;replay-buffer&#34;&gt;Replay Buffer&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;把一堆的 {$s_t,a_t,r_t,s_{t+1}$} 存放在一個 buffer&lt;/li&gt;
&lt;li&gt;{$s_t,a_t,r_t,s_{t+1}$} 簡稱為 exp&lt;/li&gt;
&lt;li&gt;裡面的 exp 可能來自於不同的 policy&lt;/li&gt;
&lt;li&gt;在 buffer 裝滿的時候才把舊的資料丟掉&lt;/li&gt;
&lt;li&gt;每次從 buffer 隨機挑一個 batch 出來，update Q function&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;好處&#34;&gt;好處&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;跟環境作互動很花時間，這樣可以減少跟環境作互動的次數&lt;/li&gt;
&lt;li&gt;本來就希望 batch 裡的 data 越 diverse 越好，不會希望 batch 裡的 data 都是同性質的&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;issue&#34;&gt;issue&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;我們要觀察 $\pi$ 的 value，混雜了一些不是 $\pi$ 的 exp 到底有沒有關係?
&lt;ul&gt;
&lt;li&gt;理論上沒問題，但李老師沒解釋&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;typical-q-learning-演算法&#34;&gt;Typical Q-learning 演算法&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;初始化 Q-fucntion Q，target Q-function $\hat{Q}=Q$&lt;/li&gt;
&lt;li&gt;在每個 episode
&lt;ul&gt;
&lt;li&gt;對於每個 time step t
&lt;ul&gt;
&lt;li&gt;給 state $s_t$，根據 Q 執行 action $a_t$ (epsilon greedy)&lt;/li&gt;
&lt;li&gt;獲得 reward $r_t$，到達 $s_{t+1}$&lt;/li&gt;
&lt;li&gt;把 {$s_t,a_t,r_t,s_{t+1}$} 存到 buffer&lt;/li&gt;
&lt;li&gt;從 buffer sample {$s_t,a_t,r_t,s_{t+1}$}(通常是一個 batch)&lt;/li&gt;
&lt;li&gt;Target $y=r_i+\underset{a}{max}\hat{Q}(s_{i+1},a)$&lt;/li&gt;
&lt;li&gt;Update Q 的參數，好讓 $Q(s_i,a_i)$ 更接近 y(regression)&lt;/li&gt;
&lt;li&gt;每 C 步 reset $\hat{Q}=Q$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;adveanced-tip&#34;&gt;Adveanced Tip&lt;/h2&gt;
&lt;h3 id=&#34;double-dqn&#34;&gt;Double DQN&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Q Value 往往被高估
&lt;ul&gt;
&lt;li&gt;我們的目的是要讓 $Q(s_t, a_t)$ 和 $r_t+\underset{a}{max}Q(s_{t+1},a)$ 越接近越好(後者就是 target)&lt;/li&gt;
&lt;li&gt;target 常常不小心設太高，因為如果有 action 被高估了，就會選那個當 target&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Double DQN: 兩個函式 $Q$ 和 $Q^{&amp;rsquo;}$
&lt;ul&gt;
&lt;li&gt;把 target 換成  $r_t+Q^{&amp;rsquo;}(s_{t+1},arg \underset{a}{max}Q(s_{t+1},a))$&lt;/li&gt;
&lt;li&gt;選 action 交給 $Q$，實際算交給 $Q^{&amp;rsquo;}$
&lt;ul&gt;
&lt;li&gt;如果 $Q$ 選了高估的 action，$Q^{&amp;rsquo;}$ 有可能修正回來&lt;/li&gt;
&lt;li&gt;如果 $Q^{&amp;rsquo;}$ 高估，$Q$ 不一定會選到&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;$Q^{&amp;rsquo;}$ 是 target network(固定不動)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;dueling-dqn&#34;&gt;Dueling DQN&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;改變 network 架構&lt;/li&gt;
&lt;li&gt;分成兩條 path
&lt;ul&gt;
&lt;li&gt;第一條算 scalar&lt;/li&gt;
&lt;li&gt;第二條算 vector，每個 action 都有個 value&lt;/li&gt;
&lt;li&gt;把 scalar 加到每一個維度&lt;/li&gt;
&lt;li&gt;只更改到 V(s) 的時候，會全部的 action 都改到，可能會是一個比較有效率的方式，不用 sample 所有的 action
&lt;ul&gt;
&lt;li&gt;但有可能模型不管 V(s)，直接設 0，只改 A&lt;/li&gt;
&lt;li&gt;所以會對 A 下 constrain，讓 network 傾向於改 V
&lt;ul&gt;
&lt;li&gt;比如同個 state 下的所有 action 要生出 A(s,a) 總和為 0
&lt;ul&gt;
&lt;li&gt;在 A 的輸出加個 normalization 即可辦到，這個 normalization 就是把每個維度都減掉平均&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/drl/q-learning/dueling-dqn.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;prioritized-replay&#34;&gt;Prioritized Replay&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;原本是 uniform 的從 buffer sample data&lt;/li&gt;
&lt;li&gt;改讓 「有更大的 TD error」的 data 有更高的機率被 sample
&lt;ul&gt;
&lt;li&gt;TD error 就是 $Q(s_t, a_t)$ 和 target 的差距&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;實際在做的時候有額外的細節，不會只改 sampling 的 process，還要改 update 參數的方法&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;multi-step&#34;&gt;Multi-step&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Balance between MC 和 TD&lt;/li&gt;
&lt;li&gt;TD 只需要存 {$s_t,a_t,r_t,s_{t+1}$}&lt;/li&gt;
&lt;li&gt;改存 {$s_t,a_t,r_t,&amp;hellip;,s_{t+N},a_{t+N},r_{t+N}, s_{t+N+1}$}&lt;/li&gt;
&lt;li&gt;我們的目的是要讓 $Q(s_t, a_t)$ 和 $\displaystyle\sum_{t^{&amp;rsquo;}=t}^{t+N} r_{t^{&amp;rsquo;}}+\hat{Q}(s_{t+N+1},a_{t+N+1})$ 越接近越好(後者就是 target)
&lt;ul&gt;
&lt;li&gt;$a_{t+N+1}=arg\underset{a}{max}\hat{Q}(s_{t+N+1},a)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;同時有 MC 和 TD 的好處和壞處
&lt;ul&gt;
&lt;li&gt;估測的影響比較輕微&lt;/li&gt;
&lt;li&gt;r 比較多項，variance 比較大&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;noisy-net&#34;&gt;Noisy Net&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;improve exploration&lt;/li&gt;
&lt;li&gt;Noise on Action
&lt;ul&gt;
&lt;li&gt;Epsilon Greedy(之前的回顧)
&lt;ul&gt;
&lt;li&gt;$f_X(x) = \begin{cases}
arg \underset{a}{max}Q(s,a), &amp;amp; \text{with probability }1-\varepsilon \\
random, &amp;amp; ,otherwise
\end{cases}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;給同樣的 state，採取的 action 不一定一樣&lt;/li&gt;
&lt;li&gt;沒有真實的 policy 會這樣運作&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Noise on Parameters
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$a = arg \underset{a}{max}\tilde{Q}(s,a)$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在每個 episode 剛開始的時候，在 Q-function 的參數上面加上 gaussian noise&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;給同樣的 state，採取同樣的 action&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;叫做 state-dependent exploration&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;explore in a consistent way&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;distributional-q-function&#34;&gt;Distributional Q-function&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Q-function 生出的東西是 cumulated reward 的期望值
&lt;ul&gt;
&lt;li&gt;所以我們是在對 distribution 取 mean，但不同的 distribution 也可能有同樣的 mean&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;想做的事情是 model distribution&lt;/li&gt;
&lt;li&gt;如果有做這個，就比較不會有 over estimate reward 的結果，反而容易 under estimate，使 double 比較沒用
&lt;ul&gt;
&lt;li&gt;output 的 range 不可能無限寬，超過邊界的 reward 會被丟掉&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;rainbow&#34;&gt;Rainbow&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;綜合一堆方法&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;continuous-actions&#34;&gt;Continuous actions&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Q learning 不容易處理 continuous action&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;solution&#34;&gt;Solution&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;sample n 個可能的 a，都丟 Q function 看誰最大&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;gradient descent&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;把 a 當作 parameter，要找一組 a 去 maximize Q function
&lt;ul&gt;
&lt;li&gt;運算量大，要 iterative 的 update a&lt;/li&gt;
&lt;li&gt;不一定可以找到 global 的最佳解&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;特別設計 Q network，讓解 optimization 的問題變容易&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;範例
&lt;ul&gt;
&lt;li&gt;Q network 輸出 $\mu(s)$、$\Sigma(s)$、$V(s)$，個別是 vector、matrix、scalar&lt;/li&gt;
&lt;li&gt;a 是 continuous 的 Action，是一個 vector，每個維度都是實數&lt;/li&gt;
&lt;li&gt;$\Sigma(s)$ 是 positive definite 的，實作的時候會把 $\Sigma$ 和它的 transpose 相乘&lt;/li&gt;
&lt;li&gt;$Q(s,a)=-(a-\mu(s))^T\Sigma(s)(a-\mu(s))+V(s)$&lt;/li&gt;
&lt;li&gt;$(a-\mu(s))^T\Sigma(s)(a-\mu(s))$ 這項必為正，所以 $a=\mu(s)$ 的時候就是最佳解&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;不要用 Q-learning&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>Proximal Policy Optimization(PPO)</title>
        <link>https://roykesydon.github.io/Blog/p/proximal-policy-optimizationppo/</link>
        <pubDate>Mon, 20 Feb 2023 12:35:56 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/proximal-policy-optimizationppo/</guid>
        <description>&lt;h1 id=&#34;onoff-policy&#34;&gt;On/Off-policy&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;On-policy
&lt;ul&gt;
&lt;li&gt;學習的 agent 和與環境互動的 agent 是同一個&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Off-policy
&lt;ul&gt;
&lt;li&gt;學習的 agent 和與環境互動的 agent 是不同個&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;想從-on-policy-轉-off-policy&#34;&gt;想從 On-policy 轉 Off-policy&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;On-policy 每次都要重新蒐集資料，很花時間&lt;/li&gt;
&lt;li&gt;由另一個 $\pi_{\theta^{&amp;rsquo;}}$ 去 train $\theta$，$\theta^{&amp;rsquo;}$是固定的，所以我們可以 re-use sample data&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;importance-sampling&#34;&gt;Importance Sampling&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;是一個 general 的想法，不限於 RL&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$E_{x \text{\textasciitilde} p}[f(x)]\approx \frac{1}{N}\displaystyle\sum_{i=1}^N f(x^i)$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$x^i$ is sampled from p(x)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;我們遇到的問題是沒辦法從 p 來 sample data，只能透過 q(x) 去 sample $x^i$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;可以把上式改寫成 $E_{x \text{\textasciitilde} p}[f(x)]=E_{x \text{\textasciitilde} q}[f(x)\frac{p(x)}{q(x)}]$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;issue&#34;&gt;Issue&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;雖然理論上 q 可以任意選，只要不要 q(x) 是 0 的時候 p(x) 不是 0，實作上 p 和 q 不能差太多，不然會有問題&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;這兩項的 Variance 不一樣，如果 p 除以 q 差距很大，右邊的 Variance 會很大，如果 sample 不夠多次就會有問題&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/drl/ppo/importance-sample-issue.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;轉換&#34;&gt;轉換&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;原本&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\triangledown \overline{R_{\theta}}=E_{\tau \text{\textasciitilde}p_{\theta}(\tau)}[R(\tau)\triangledown log p_{\theta} (\tau)]$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;改為&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\triangledown \overline{R_{\theta}}=E_{\tau \text{\textasciitilde}p_{\theta^{&amp;rsquo;}}(\tau)}[\frac{p_{\theta}(\tau)}{p_{\theta^{&amp;rsquo;}}(\tau)}R(\tau)\triangledown log p_{\theta} (\tau)]$&lt;/li&gt;
&lt;li&gt;從 $\theta^{&amp;rsquo;}$ sample 資料&lt;/li&gt;
&lt;li&gt;更新 $\theta$ 多次&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;advantage-function&#34;&gt;Advantage function&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;原本&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$E_{(s_t,a_t)\text{\textasciitilde}\pi_{\theta}}[A^{\theta}(s_t,a_t)\triangledown log p_\theta(a_t^n|s_t^n)]$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;改為&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$E_{(s_t,a_t)\text{\textasciitilde}\pi_{\theta^{&amp;rsquo;}}}[\frac{P_\theta(s_t,a_t)}{P_{\theta^{&amp;rsquo;}}(s_t,a_t)}A^{\theta^{&amp;rsquo;}}(s_t,a_t)\triangledown log p_\theta(a_t^n|s_t^n)]$&lt;/li&gt;
&lt;li&gt;要注意 Advantage 的結果要由 $\theta^{&amp;rsquo;}$ 得出，是 $\theta^{&amp;rsquo;}$在和環境互動&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;新的 objective function&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$J^{\theta^{&amp;rsquo;}}(\theta)=E_{(s_t,a_t)\text{\textasciitilde}\pi_{\theta^{&amp;rsquo;}}}[\frac{p_\theta(a_t|s_t)}{p_{\theta^{&amp;rsquo;}}(a_t|s_t)}A^{\theta^{&amp;rsquo;}}(s_t,a_t)]$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;ppo&#34;&gt;PPO&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;確保 $\theta$ 和 $\theta^{&amp;rsquo;}$ 不會差太多&lt;/li&gt;
&lt;li&gt;$J_{PPO}^{\theta^{&amp;rsquo;}}(\theta)=J^{\theta^{&amp;rsquo;}}(\theta)-\beta KL(\theta, \theta^{&amp;rsquo;})$&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;前身-trpo&#34;&gt;前身 TRPO&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Trust Region Policy Optimization&lt;/li&gt;
&lt;li&gt;$J_{TRPO}^{\theta^{&amp;rsquo;}}(\theta)=E_{(s_t,a_t)\text{\textasciitilde}\pi_{\theta^{&amp;rsquo;}}}[\frac{p_\theta(a_t|s_t)}{p_{\theta^{&amp;rsquo;}}(a_t|s_t)}A^{\theta^{&amp;rsquo;}}(s_t,a_t)], KL(\theta, \theta^{&amp;rsquo;})&amp;lt;\delta$&lt;/li&gt;
&lt;li&gt;constrain 很難處理&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;kl-divergence&#34;&gt;KL divergence&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;這邊不是 $\theta$ 和 $\theta^{&amp;rsquo;}$ 參數上的距離，而是 behavior 的距離
&lt;ul&gt;
&lt;li&gt;參數上的距離是指這兩個參數有多像&lt;/li&gt;
&lt;li&gt;是給同樣的 state 生出 action 的 distribution 要像&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;algorithm&#34;&gt;algorithm&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;初始參數 $\theta^0$&lt;/li&gt;
&lt;li&gt;每個 iteration
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;用 $\theta^k$ 和環境互動，蒐集{$s_t,a_t$}，並計算 advantage $A^{\theta^k}(s_t,a_t)$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;找出 theta 最佳化 $J_{PPO}(\theta)$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$J_{PPO}^{\theta^{k}}(\theta)=J^{\theta^{k}}(\theta)-\beta KL(\theta, \theta^{k})$&lt;/li&gt;
&lt;li&gt;可以更新很多次&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;動態調整 $\beta$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Adaptive KL Penalty&lt;/li&gt;
&lt;li&gt;設可接受的 KL 數值範圍&lt;/li&gt;
&lt;li&gt;if $KL(\theta,\theta^k)&amp;gt;KL_{max},\text{increase} \beta$&lt;/li&gt;
&lt;li&gt;if $KL(\theta,\theta^k)&amp;lt;KL_{min},\text{decrease} \beta$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ppo2&#34;&gt;PPO2&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;PPO&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$J_{PPO}^{\theta^{k}}(\theta)=J^{\theta^{k}}(\theta)-\beta KL(\theta, \theta^{k})$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;PPO2&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$J_{PPO2}^{\theta^{k}}(\theta)\approx \displaystyle\sum_{(s_t,a_t)}min(\frac{p_{\theta}(a_t|s_t)}{p_{\theta^k}(a_t|s_t)}A^{\theta^k}(s_t,a_t), \\
clip(\frac{p_{\theta}(a_t|s_t)}{p_{\theta^k}(a_t|s_t)}, 1-\varepsilon, 1+\varepsilon)A^{\theta^k}(s_t,a_t))$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/drl/ppo/ppo2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Policy Gradient</title>
        <link>https://roykesydon.github.io/Blog/p/policy-gradient/</link>
        <pubDate>Sun, 19 Feb 2023 17:16:14 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/policy-gradient/</guid>
        <description>&lt;h1 id=&#34;basic-components&#34;&gt;Basic Components&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Actor
&lt;ul&gt;
&lt;li&gt;Policy $\pi$ is a network with parameter $\theta$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Env&lt;/li&gt;
&lt;li&gt;Reward Function&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;trajectory&#34;&gt;Trajectory&lt;/h1&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/drl/policy-gradient/aer.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在一場遊戲，把 env 輸出的 s 和 actor 輸出的 a 串起來，是一個 Trajectory&lt;/li&gt;
&lt;li&gt;Trajectory $\tau$ = {$s_1,a_1,s_2,a_2,&amp;hellip;,s_T,a_T$}&lt;/li&gt;
&lt;li&gt;$p_{\theta}(\tau)=p(s_1)\displaystyle\prod_{t=1}^Tp_{\theta}(a_t|s_t)p(s_{t+1}|s_t,a_t)$&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;update&#34;&gt;Update&lt;/h1&gt;
&lt;p&gt;$\theta \leftarrow \theta + \eta \triangledown \overline{R}_{\theta}$&lt;/p&gt;
&lt;p&gt;$\triangledown \overline{R_{\theta}} = \displaystyle\sum_{\tau} R(\tau) \triangledown p_{\theta} (\tau) \\
=\frac{1}{N}\displaystyle\sum_{n=1}^{N}\displaystyle\sum_{t=1}^{T_n}R(\tau^n)\triangledown log p_{\theta} (a_t^n|s_t^n)$&lt;/p&gt;
&lt;h1 id=&#34;實作&#34;&gt;實作&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;常見公式
&lt;ul&gt;
&lt;li&gt;$\triangledown f(x)=f(x)\triangledown logf(x)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;用當前模型蒐集一堆 Trajectory&lt;/li&gt;
&lt;li&gt;更新模型&lt;/li&gt;
&lt;li&gt;回到第一步&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;細節
&lt;ul&gt;
&lt;li&gt;做一個分類問題，把 state 當作分類器的 Input，把 action 當作分類器的 ground truth 作訓練&lt;/li&gt;
&lt;li&gt;在實作分類問題的時候，objective function 都會寫成 minimize cross entropy，就是 maximize log likelihood&lt;/li&gt;
&lt;li&gt;RL 和一般分類的區別是，要記得在 loss 前面乘上 $R(\tau^n)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;tip&#34;&gt;Tip&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;Add a Baseline
&lt;ul&gt;
&lt;li&gt;$R(\tau^n)$ 有可能永遠都為正
&lt;ul&gt;
&lt;li&gt;此時等於告訴 Model 說，今天不管是什麼 action，都要提高它的機率。不一定會有問題，因為雖然都是正的，但正的量有大有小，可能某些 action 上升的幅度會更大。因為我們是在做 sampling，不一定會 sample 到某些 action，本來想的情況是所有的 trajectory 都會出現才沒問題。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;解法: 希望 reward 不要總是正的
&lt;ul&gt;
&lt;li&gt;$\triangledown \overline{R_{\theta}}\approx \frac{1}{N}\displaystyle\sum_{n=1}^{N}\displaystyle\sum_{t=1}^{T_n}(R(\tau^n)-b)\triangledown log p_{\theta}(a_t^n|s_t^n)$&lt;/li&gt;
&lt;li&gt;$b \approx E[R(\tau)]$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Assign Suitable Credit
&lt;ul&gt;
&lt;li&gt;原本整場遊戲的所有 action 都會乘上 $R(\tau)$，但這不太公平，因為就算結果是好的，不代表所有 action 都是對的，反之亦然。在理想的情況下，如果 sample 夠多，就可以解決這問題。&lt;/li&gt;
&lt;li&gt;解法
&lt;ol&gt;
&lt;li&gt;只計算從這個 action 後的 reward 總和
&lt;ul&gt;
&lt;li&gt;因為前面的 reward 和你做了什麼沒關係&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;接續解法 1，把比較未來的 reward 做 discount
&lt;ul&gt;
&lt;li&gt;乘某個小於 1 的 $\gamma^{t^{&amp;rsquo;}-t}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;advantage-function&#34;&gt;Advantage function&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;base 可以是 state-dependent，可以根據 network 得出，以後再說&lt;/li&gt;
&lt;li&gt;$(Reward-b)$ 可以合起來看做 Advantage function $A^{\theta}(s_t,a_t)$
&lt;ul&gt;
&lt;li&gt;這邊 Reward 不管你是什麼形式，有沒有 discount。&lt;/li&gt;
&lt;li&gt;它的意義是，這個 action 相較於其他的 action 有多好，而不是絕對好&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;這個 A 通常可以由某個類神經網路估計，那個類神經網路叫做 critic，以後講 Actor-Critic 的時候再說&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>MAE 論文</title>
        <link>https://roykesydon.github.io/Blog/p/mae-%E8%AB%96%E6%96%87/</link>
        <pubDate>Wed, 15 Feb 2023 16:08:46 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/mae-%E8%AB%96%E6%96%87/</guid>
        <description>&lt;p&gt;paper: &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2111.06377&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Masked Autoencoders Are Scalable Vision Learners&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;abstract&#34;&gt;Abstract&lt;/h1&gt;
&lt;p&gt;這篇論文顯示出 MAE 是 CV 中的 scalable self-supervised learners。&lt;/p&gt;
&lt;p&gt;MAE 的方法很簡單&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;隨機蓋住輸入影像的一些 patch&lt;/li&gt;
&lt;li&gt;重建 missing pixels&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;具備兩個核心設計&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;非對稱的 encoder-decoder 架構，encoder 只作用於可見的 patch 子集合(沒有 mask tokens)，lightweight decoder 則根據 latent representation 和 make tokens 來重建圖片。&lt;/li&gt;
&lt;li&gt;當遮住高比例(比如 75%)的影像時，會得到一個 nontrivial 和 meaningful 的 self-supervisory task&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;結合這兩點設計，可以有效地訓練大模型。
以 ViT-Huge 用 ImageNet-1K 訓練(訓練集一百多萬張照片)可達到 87.8% 的準確度。&lt;/p&gt;
&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/MAE/intro.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/MAE/valid-example.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/MAE/valid-example-2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;在 CV 中，常需要大量 labeled images。
NLP 中，自監督預訓練處理了需要大量標註資料的問題。
masked autoencoders 是一種更 general 的 denoising autoencoders 的形式。
BERT 非常成功，autoencoding methods 在 CV 的研究卻落後 NLP，作者思考是什麼讓 masked autoencoding 在 CV 和 NLP 產生不同。
有以下觀點&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;直到前陣子，CV 中的 CNN 是主流，但卷積層不好引入 mask tokens 或 positional embedding 這些 indicator。但這些可以透過 ViT 來解決，不應成為問題。&lt;/li&gt;
&lt;li&gt;語言和視覺的 Information density 不同，語言是 highly semantic 和 information-dense，使填字本身不是很簡單的事情，但影像含有大量冗餘的訊息，缺失的部分比較好從相鄰的 patch 重建，比如直接插值，所以作者用一種簡單的策略，隨機 mask 很大一部分的 patch，創造一個具有挑戰性的自監督任務，強迫模型關注 global 的資訊。&lt;/li&gt;
&lt;li&gt;關於 decoder，CV 還原 pixel，pixel 屬於 lower semantic level，NLP 還原 word，word 的 semantic information 較高。作者發現，雖然在 BERT 中，可以用簡單的 decoder 還原(一個 MLP)，但 CV 中 decoder 的設計就很重要。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;基於以上觀點，作者提出 MAE，隨機遮住大量的 patch，並在 pixel space 重建失去的 patch。而且是非對稱 encoder-decoder 架構，encoder 只會看到可見的 patch，但 docoder 除了 latent representation，還會看到 mask tokens。這種設計在非常高的掩蓋率(比如 75%)下不但可以提高準確度，還可以讓 encoder 只處理較少比例(比如 25%)的 patch，將訓練時間減少 3 倍或更多，使 MAE 可以輕鬆擴展成更大的模型。&lt;/p&gt;
&lt;p&gt;在這樣的架構下，用 MAE 的 pre-training，可以訓練非常吃 data 的模型，比如 ViT-Large/-Huge，而只使用 ImageNet-1K。&lt;/p&gt;
&lt;p&gt;用 ImageNet-1K 在 vanilla ViT-Huge 上 fine-tune 可達到 87.8% 準確度，比以往只使用 ImageNet-1K 的結果都高。&lt;/p&gt;
&lt;p&gt;在 obejct detection、instance segmentation、semantic segmentation 上做 transfer learning 都達到不錯的效果，可以打敗用監督式預訓練模型的對手。&lt;/p&gt;
&lt;h1 id=&#34;相關工作&#34;&gt;相關工作&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Autoencoding
&lt;ul&gt;
&lt;li&gt;MAE 是一種 denoising autoencoding 的形式，但和 DAE 還是差別很大。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Masked image encoding
&lt;ul&gt;
&lt;li&gt;iGPT、ViT、BEiT&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;approach&#34;&gt;Approach&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Masking&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;和 ViT 一樣，把圖片切成多個 patch，對於 patch 均勻隨機地採樣保留，剩下地遮住&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;MAE encoder&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ViT&lt;/li&gt;
&lt;li&gt;也有 positional embedding&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;MAE decoder&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Transformer block&lt;/li&gt;
&lt;li&gt;輸入
&lt;ul&gt;
&lt;li&gt;encoded visible patches&lt;/li&gt;
&lt;li&gt;mask tokens
&lt;ul&gt;
&lt;li&gt;shared, learned vector&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;都會加入 positional embedding&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;用相較 encoder 輕量的解碼器，所有的 patch 由這個輕量的 decoder 處理，減少預訓練時間&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Reconstruction target&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;decoder 的最後一層是 linear projection，之後再 reshape 成你要的  patch&lt;/li&gt;
&lt;li&gt;loss function
&lt;ul&gt;
&lt;li&gt;mean squared error(MSE)&lt;/li&gt;
&lt;li&gt;只算 masked patched 的 MSE，像 BERT&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Simple implementation&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;先取得一系列 token(patch 做 linear projection + positional embedding)&lt;/li&gt;
&lt;li&gt;randomly shuffle，根據比例移除尾端一部份&lt;/li&gt;
&lt;li&gt;encoding 後，尾端接上 mask tokens，並且 unshuffle&lt;/li&gt;
&lt;li&gt;加上 positional embedding 後，給 decoder&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;imagenet-experiments&#34;&gt;ImageNet Experiments&lt;/h1&gt;
&lt;p&gt;在 ImageNet-1K 上做自監督的預訓練，然後做&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;end-to-end fine-tuning
&lt;ul&gt;
&lt;li&gt;所有參數都可改&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;linear probing
&lt;ul&gt;
&lt;li&gt;只改最後一層線性層&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/MAE/vit-mae.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/MAE/result.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/MAE/ratio-result.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;optimal masking ratio 意外地高，相比 BERT 只有 15%&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/MAE/fine-tune-blocks.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h1 id=&#34;討論和結論&#34;&gt;討論和結論&lt;/h1&gt;
&lt;p&gt;在 CV 實用的預訓練做法主流是監督式的，CV 中自監督的做法可能正跟著 NLP 的軌跡走。&lt;/p&gt;
&lt;p&gt;要仔細處理圖像和語言的區別，作者去除圖片中很可能不構成 semantic segment 的部分，而不是移除某個 object。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>ViT 論文</title>
        <link>https://roykesydon.github.io/Blog/p/vit-%E8%AB%96%E6%96%87/</link>
        <pubDate>Sun, 12 Feb 2023 00:27:55 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/vit-%E8%AB%96%E6%96%87/</guid>
        <description>&lt;p&gt;paper: &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2010.11929&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;abstract&#34;&gt;Abstract&lt;/h1&gt;
&lt;p&gt;在 CV 領域 transformer 表現有限，目前 attention 常常是和卷積神經網路一起用，或是用來把一些卷積層換成 self-attention，但整體架構不變。這篇論文想展現一個純 Transformer 可以直接在影像分類上表現很好。如果用大量資料作預訓練，再遷移到中小型的資料集，可以和 SOTA 的 CNN 表現得一樣好，還需要較少的訓練資源作訓練。&lt;/p&gt;
&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;self-attention-based 架構，特別是 Transformer，已經是 NLP 的重要選擇。主流的作法是在大型文字資料集上作訓練，再針對小型任務資料集作 fine-tune。由於 Transformer 的計算效率高，還有可擴展性，可以 train 一些很大的 model，隨著 model 和資料集增大，目前還沒看出飽和的現象。&lt;/p&gt;
&lt;p&gt;然而在 CV，CNN 還是主流，一些工作嘗試用 self-attention 結合 CNN-like 的架構，比如把 feature map 當 transformer 的輸入，因為原始 pixel 太多，或甚至把卷積層全換成 self-attention，雖然後者理論上效率很高(原論文中有另外 cite 兩篇作法)，但因為他們做法特殊，在現代硬體上很難加速，所以無法很有效地擴展。在 large-scale 的影像識別上， ResNet-like 的架構還是 SOTA。&lt;/p&gt;
&lt;p&gt;該實驗直接把一個標準的 Transformer 作用於圖片上，只作最少的修改。把影像分成多個 patch，並把它們變成一系列的 linear embedding，當作 NLP 中的 tokens(words) 來處理。&lt;/p&gt;
&lt;p&gt;當在中型大小的資料集(e.g. ImageNet)上訓練，如果沒有 strong regularization，ViT 會略輸同等大小的 ResNets&lt;/p&gt;
&lt;p&gt;這篇論文在更大的資料集(14M-300M 的影像)上訓練，就打敗了 inductive bias。在大量資料上作預訓練就很讚。&lt;/p&gt;
&lt;h1 id=&#34;related-work&#34;&gt;Related Work&lt;/h1&gt;
&lt;p&gt;大型的 Transformer-based 模型常常是先在大資料集上預訓練然後根據任務 fine-tune，比如 BERT 和 GPT。&lt;/p&gt;
&lt;p&gt;要把 self-attention 用在 CV 上，最簡單的做法就是把每個 Pixel 當一個元素，但 self-attention 是平方複雜度，在現實的圖片很難應用。一個應用 Transformer 的做法是只把 self-attention 用在 local neighborhood，另外一個是用 Sparse Transformer，還有一堆特殊的方法，雖然表現不錯，但要用硬體加速起來不容易。&lt;/p&gt;
&lt;p&gt;另一個有關的模型是 iGPT，在 reduce image resolution 和 color space 後把 transformer 應用在 image pixels 上。它用非監督式訓練後，再 fine-tune 或做 linear probing(只更新最後的 linear layer) 分類任務，表現很好。&lt;/p&gt;
&lt;p&gt;已經有類似的工作了，抽取 patches of size 2 * 2，最後再接 full self-attention，基本上和 ViT 非常像，這篇論文進一步證明了作大規模的預訓練可以讓 Transformer 和 SOTA 的 CNN 相比，而且 ViT 因為 patch 比較大，可以處理 medium-resolution 的圖片。這問題是可預期的，因為 Transformer 缺少了一些 inductive biases。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;inductive biases
&lt;ul&gt;
&lt;li&gt;一些假設&lt;/li&gt;
&lt;li&gt;比如 CNN 常有四個假設
&lt;ul&gt;
&lt;li&gt;locality&lt;/li&gt;
&lt;li&gt;translation invariance with pooling layers
&lt;ul&gt;
&lt;li&gt;平移不變性&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;translation equivariance
&lt;ul&gt;
&lt;li&gt;f(g(x)) = g(f(x))&lt;/li&gt;
&lt;li&gt;卷積和平移的先後順序沒差&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;method&#34;&gt;Method&lt;/h1&gt;
&lt;p&gt;模型盡可能類似原始 Transformer，這樣可以把一些 NLP 上成功的 Transformer 架構拿來用，還可以用一些很有效率的 implementation&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/ViT/ViT.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/ViT/ViT-process.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;embedding 維度是 768 = 16 * 16 * 3
position embedding 的做法是 standard learnable 1D positional embeddings，就是 BERT 的做法，簡單來說就是生出一張可以訓練的表，(序列長度, embedding size)，作者也有嘗試其他方法，但發現成效差不多，比如 2D positional embedding，概念就是從生出(序列長度, embedding size)變成生出 2 個(sqrt(序列長度), embedding size)。&lt;/p&gt;
&lt;p&gt;[class] 的概念是 NLP 出來的，ResNet-like 的架構常見的做法也有通過 globally average-pooling (GAP)來生出向量，再接上分類器做預測。實驗發現直接在 transformer 的輸出做 GAP 和 [class] 都可以達到不錯的效果。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/ViT/ViT-gap.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/ViT/ViT-dataset.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/ViT/ViT-acc.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h1 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;拿標準的 Transformer 來作 Image recognition，和以往用 self-attention 在 CV 的方法不一樣，除了一開始的 initial patch extraction，沒有引入其他影像特有的 inductive biases。直接把圖片當成是一系列的 patch，然後直接用 Transformer encoder 當一般 NLP 任務處理。在很多影像分類訓練集上表現得更好還在 pre-train 上相對便宜。&lt;/p&gt;
&lt;p&gt;還有一些值得挑戰的地方，比如把 ViT 應用在其他 CV 任務，比如 detection 和 segmentation。另一個挑戰是探索自監督預訓練的方法。這篇論文其實有實驗自監督，表現 OK，但和監督式還是有很大的落差。擴大 ViT 可能有更好的結果。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>機率論 - IV</title>
        <link>https://roykesydon.github.io/Blog/p/%E6%A9%9F%E7%8E%87%E8%AB%96-iv/</link>
        <pubDate>Sun, 05 Feb 2023 15:18:41 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/%E6%A9%9F%E7%8E%87%E8%AB%96-iv/</guid>
        <description>&lt;h1 id=&#34;隨機變數之和&#34;&gt;隨機變數之和&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Z=X+Y&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$p_Z(z)=\displaystyle\sum_{x=-\infty}^{\infty}p_{X,Y}(x,z-x)\\
=\displaystyle\sum_{y=-\infty}^{\infty}p_{X,Y}(z-y,y)$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$f_Z(z)=\int_{-\infty}^{\infty}f_{X,Y}(x,z-x)dx\\
=\int_{-\infty}^{\infty}f_{X,Y}(z-y,y)dy$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果 X, Y 獨立&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;離散&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$p_Z(z)=\displaystyle\sum_{x=-\infty}^{\infty}p_{X}(x)\cdot p_Y(z-x)\\
=\displaystyle\sum_{y=-\infty}^{\infty}p_{X}(z-y)\cdot p_Y(y)$
&lt;ul&gt;
&lt;li&gt;這兩個等式是 discrete convolution&lt;/li&gt;
&lt;li&gt;$=p_X(z) * p_Y(z)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;連續&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$f_Z(z)=\int_{-\infty}^{\infty}f_{X}(x) f_Y(z-x) dx\\
=\int_{-\infty}^{\infty}f_{X}(z-y) f_Y(y) dy$
&lt;ul&gt;
&lt;li&gt;這兩個等式是 continuous convolution&lt;/li&gt;
&lt;li&gt;$=f_X(z) * f_Y(z)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果有 n 個獨立隨機變數&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$X=X_1+X_2+&amp;hellip;+X_n$
&lt;ul&gt;
&lt;li&gt;如果 $X_1,&amp;hellip;,X_n$ 獨立
&lt;ul&gt;
&lt;li&gt;$p_X(x)=p_{X_1}(x) * p_{X_2}(x) * p_{X_3}(x) * &amp;hellip; * p_{X_n}(x)$
&lt;ul&gt;
&lt;li&gt;連續做 convolution&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;$f_X(x)=f_{X_1}(x) * f_{X_2}(x) * f_{X_3}(x) * &amp;hellip; * f_{X_n}(x)$
&lt;ul&gt;
&lt;li&gt;連續做 convolution&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;mgf&#34;&gt;MGF&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;moment generating function&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;convolution 很難算&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;流程&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果有多個連續 convolution 也適用下面流程，全部一次一起相乘&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;給定 $p_{X_1}(x), p_{X_2}(x)$，目標是求 $p_{X_1}(x) * p{X_2}(x)$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;轉換到 MGF&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$\phi_{X_1}(s)=E \lbrack e^{sX_1} \rbrack\\
= \displaystyle\sum_{x=-\infty}^{\infty}e^{sx}\cdot p_{X_1}(x)$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$\phi_{X_2}(s)=E \lbrack e^{sX_2} \rbrack$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;相乘
$\phi_{X_1}(s) \cdot \phi_{X_2}(s)$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;逆轉換&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;查表&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$\phi_X(s)$ 定義&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\phi_X(s)=E \lbrack e^{sX} \rbrack = \begin{cases}
\displaystyle\sum_{x=-\infty}^{\infty} e^{sx} \cdot p_{X}(x) &amp;amp; 離散, \\
\int_{-\infty}^{\infty} e^{sx} \cdot f_{X}(x)dx &amp;amp; 連續
\end{cases}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;性質&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Y = aX + b
&lt;ul&gt;
&lt;li&gt;$\phi_Y(s) = e^{sb} \cdot \phi_X(as) $&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;常見離散機率分佈的 MGF&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$X$~$Bernoulli(p)$
&lt;ul&gt;
&lt;li&gt;$\phi_X(s)=1-p+pe^s$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;$X$~$BIN(n, p)$
&lt;ul&gt;
&lt;li&gt;作 n 次實驗成功次數等於個實驗室成功次數的總和&lt;/li&gt;
&lt;li&gt;$X = X_1 + X_2 + &amp;hellip; + X_n, X_i 獨立, Xi$~$Bernoulli(p)$&lt;/li&gt;
&lt;li&gt;$\phi_{X_i}(s)=1-p+pe^s$&lt;/li&gt;
&lt;li&gt;$\phi_{X}(s)=\lbrack 1-p+pe^s \rbrack ^n$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;$X$~$Geometric(p)$
&lt;ul&gt;
&lt;li&gt;自行推導&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;$X$~$Pascal(k,p)$
&lt;ul&gt;
&lt;li&gt;看到第 k 次成功，花的總實驗室次數等於第 1 號成功花多少次 + 第 2 號 +&amp;hellip;+ 第 k 號&lt;/li&gt;
&lt;li&gt;$X = X_1 + X_2 + &amp;hellip; + X_n, X_i 獨立, Xi$~$Gemetric(p)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;$X$~$Exponential(\lambda)$
&lt;ul&gt;
&lt;li&gt;自行推導&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;$X$~$Erlang(n,\lambda)$
&lt;ul&gt;
&lt;li&gt;$X = X_1 + X_2 + &amp;hellip; + X_n, X_i 獨立, Xi$~$Exponential(\lambda)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;多個隨機變數之和&#34;&gt;多個隨機變數之和&lt;/h1&gt;
&lt;h2 id=&#34;獨立隨機變數之和&#34;&gt;獨立隨機變數之和&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;$X_1, X_2, &amp;hellip;$獨立，且各自有一模一樣的機率分佈
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;{ $X_i$ } $I.I.D.$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Independently and Identically Distributed&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$X = X_1+X_2+&amp;hellip;+X_n$，n 為常數，請問 X 的機率分佈&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$p_X(x)=p_{X_1}(x) * p_{X_1}(x) * p_{X_1}(x) * &amp;hellip; * p_{X_1}(x)$&lt;/li&gt;
&lt;li&gt;$f_X(x)=f_{X_1}(x) * f_{X_1}(x) * f_{X_1}(x) * &amp;hellip; * f_{X_1}(x)$
&lt;ul&gt;
&lt;li&gt;因為他們機率分佈一模一樣，所以底下都是 $X_1$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;$\phi_X(s)=\lbrack \phi_{X_1}(s) \rbrack ^n$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;e.g. 假設壽司理想重量是 13g，抓飯量是常態分佈，期望值是 14，標準差是 3，每天要作 100 個，每天飯量的機率分佈是?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$X_i$ : 第 i 個壽司的飯量，{ $X_i$ } I.I.D.&lt;/li&gt;
&lt;li&gt;$X_i$~$N(14,9)\\
\Rightarrow \phi_{X_i}(s)=\phi_{X_1}(s)\\
=e^{\mu S + \frac{\sigma^2}{2}s^2} = e^{14 s + \frac{9}{2}s^2}$&lt;/li&gt;
&lt;li&gt;$X=X_1+X_2+&amp;hellip;+X_{100}$&lt;/li&gt;
&lt;li&gt;$\phi_X(s)=\lbrack \phi_{X_1}(s) \rbrack^{100}\\
=e^{1400 s + \frac{900}{2}s^2}$
&lt;ul&gt;
&lt;li&gt;這個東西是 $X$~$N(1400,900)$ 的 MGF，所以可以逆推回來機率分佈&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;隨機變數之獨立隨機變數和&#34;&gt;隨機變數之獨立隨機變數和&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$X_1,X_2,&amp;hellip;I.I.D.$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$X = X_1 + X_2 + &amp;hellip; + X_N$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;N 本身也是隨機變數，其機率分佈已知&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$\phi_X(s)=\phi_N(ln(\phi_{X_1}(s)))$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;中央極限定理&#34;&gt;中央極限定理&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;central limit theorem(CLT)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;若 $X_1,X_2,&amp;hellip;,X_n$ 為 $I.I.D.$，當 n 趨近於無窮大時&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$X=X_1+X_2+&amp;hellip;+X_n$~$N(\mu_{X_1+X_2&amp;hellip;+X_n}, \sigma^2_{X_1+X_2+&amp;hellip;+X_n})$&lt;/li&gt;
&lt;li&gt;$\mu_{X_1+X_2+&amp;hellip;+X_n}=\mu_{X_1}+\mu_{X_2}+&amp;hellip;+\mu_{X_n}=n\mu_{X_1}$&lt;/li&gt;
&lt;li&gt;$\sigma^2_{X_1+X_2+&amp;hellip;+X_n}=\sigma^2_{X_1}+\sigma^2_{X_2}+&amp;hellip;+\sigma^2_{X_n}=n\sigma^2_{X_1}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;應用&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;要處理多個獨立的隨機變數的和時，可以用 CLT 將其機率分佈近似為常態分佈後計算機率
&lt;ul&gt;
&lt;li&gt;比如雜訊常當作常態分佈&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;如果某機率分佈等於多個獨立隨機變數的和，此機率分佈可以用常態分佈近似，再算機率
&lt;ul&gt;
&lt;li&gt;e.g. $X$~$BIN(100,0.3)$
&lt;ul&gt;
&lt;li&gt;$X=X_1+X_2+&amp;hellip;+X_100$&lt;/li&gt;
&lt;li&gt;{$X_i$} $I.I.D., X_i$~$Bernoulli(0.3)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;範例&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;天團粉絲有 0.2 的機率買 CD，共有100萬個粉絲，發售 CD 超過 200800 張的機率為何
&lt;ul&gt;
&lt;li&gt;$X$~$BIN(1000000,0.2)$&lt;/li&gt;
&lt;li&gt;$P(X&amp;gt;200800)=\displaystyle\sum_{x=200801}^{10^6}(\overset{1000000}{x})0.2^x0.8^{10^6-x}$
&lt;ul&gt;
&lt;li&gt;$(\overset{1000000}{x})=\frac{1000000!}{200801!799199!}$&lt;/li&gt;
&lt;li&gt;算不出來&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;$X=X_1+X_2+&amp;hellip;+X_{1000000}, X_i$~$Bernoulli(0.2)\\
\Rightarrow \mu_{X_1}=0.2, \sigma_{X_1}^2=0.16$&lt;/li&gt;
&lt;li&gt;By CLT $\Rightarrow X$~$N(200000,160000)$
&lt;ul&gt;
&lt;li&gt;$P(X&amp;gt;200800)\\
=P(\frac{X-200000}{400} &amp;gt; \frac{200800-200000}{400})\\
=P(Z&amp;gt;2)
=Q(2)
\approx0.023$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;de-moivre---laplace-formula&#34;&gt;De Moivre - Laplace Formula&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;如果是離散的隨機變數和，可以算的更精確&lt;/li&gt;
&lt;li&gt;$P(k_1 \le X \le k_2) \approx \Phi(\frac{k_2+0.5-n\mu_{X_1}}{\sqrt{n}\sigma_{X_1}}) - \Phi(\frac{k_1-0.5-n\mu_{X_1}}{\sqrt{n}\sigma_{X_1}})$&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>機率論 - III</title>
        <link>https://roykesydon.github.io/Blog/p/%E6%A9%9F%E7%8E%87%E8%AB%96-iii/</link>
        <pubDate>Thu, 02 Feb 2023 15:18:41 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/%E6%A9%9F%E7%8E%87%E8%AB%96-iii/</guid>
        <description>&lt;h1 id=&#34;隨機變數的函數&#34;&gt;隨機變數的函數&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;隨機變數 X 的任意函數 g(x) 也是一個隨機變數，常被稱為 Derived Random Variable&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;求-gx-的機率分佈&#34;&gt;求 g(x) 的機率分佈&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;X 是離散
&lt;ul&gt;
&lt;li&gt;直接推 g(X) 的 PMF
&lt;ul&gt;
&lt;li&gt;X 是離散隨機變數，Y = g(X) 也是離散隨機變數&lt;/li&gt;
&lt;li&gt;$p_{g(X)}(y) = \displaystyle\sum_{會讓g(x)=y 的所有x}p_X(x)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;X 是連續
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;先推 g(x) 的 CDF，再微分得 PDF&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;先算 g(X) 的 CDF
&lt;ul&gt;
&lt;li&gt;$F_{g(X)}(y)=P\lbrack g(X) \le y \rbrack$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;若 g(X) 可以微分，再對 y 微分得 PDF
&lt;ul&gt;
&lt;li&gt;$f_{g(X)}(y)=\frac{d}{dy}F_{g(X)}(y)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;e.g. 若 Y=3X+2，請問 Y 的 PDF 與 $f_X(x) 的關係?$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$F_Y(y)=P(Y \le y)\\
=P(3X+2 \le y)\\
=P(X \le \frac{y-2}{3})\\
=F_X(\frac{y-2}{3})$&lt;/li&gt;
&lt;li&gt;$f_Y(y)=\frac{d}{dy}F_Y(y)\\
=\frac{d}{dy}F_X(\frac{y-2}{3})\\
=\frac{dF_X(\frac{y-2}{3})}{d(\frac{y-2}{3})} \cdot \frac{d \frac{y-2}{3}}{dy}\\
=f_X(\frac{y-2}{3}) \cdot \frac{1}{3}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;若 Y=aX+b&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$f_Y(y)=\frac{1}{|a|}f_X(\frac{y-b}{a})$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;條件機率分佈&#34;&gt;條件機率分佈&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;若 X 是離散隨機變數，PMF 是 $p_X(x)$，某事件 B 已發生
&lt;ul&gt;
&lt;li&gt;PMF: $p_{X|B}(x)= x = \begin{cases}
x \in B: &amp;amp; \frac{p_X(x)}{p(B)}, \
x \notin B: &amp;amp; 0
\end{cases}$&lt;/li&gt;
&lt;li&gt;CDF: $F_{X|B}(x)\\
=\displaystyle\sum_{u \le x}p_{X|B}(u)\\
=\displaystyle\sum_{u \le x, u \in B} \frac{p_X(u)}{P(B)}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;若 X 是連續隨機變數，某事件 B 已發生
&lt;ul&gt;
&lt;li&gt;PDF: $f_{X|B}(x)\\
=\begin{cases}
x \in B: &amp;amp; \frac{f_X(x)}{P(B)}, \
x \notin B: &amp;amp; 0
\end{cases}$&lt;/li&gt;
&lt;li&gt;CDF: $F_{X|B}(x)\\
=\int_{-\infty \le u \le x, u \in B} \frac{f_X(u)}{P(B)} du$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;條件期望值-conditional-excpectation&#34;&gt;條件期望值 Conditional Excpectation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$E \lbrack X|B \rbrack\\
=\begin{cases}
\displaystyle\sum_{x=-\infty}^{\infty} x \cdot p_{X|B}(x) &amp;amp; 離散, \\
\int_{-\infty}^{\infty} x \cdot f_{X|B}(x)dx &amp;amp; 連續
\end{cases}$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$E \lbrack g(X)|B \rbrack\\
=\begin{cases}
\displaystyle\sum_{x=-\infty}^{\infty} g(x) \cdot p_{X|B}(x) &amp;amp; 離散, \\
\int_{-\infty}^{\infty} g(x) \cdot f_{X|B}(x)dx &amp;amp; 連續
\end{cases}$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$Var(X|B) = E\lbrack X^2 | B \rbrack - (\mu_{X|B})^2$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;失憶性-memoryless&#34;&gt;失憶性 Memoryless&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Geometric 和 Exponential 機率分佈都有失憶性&lt;/li&gt;
&lt;li&gt;不管事情已經進行多久，對於事情之後的進行一點影響都沒有&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;聯合機率分佈&#34;&gt;聯合機率分佈&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;joint probability distribution&lt;/li&gt;
&lt;li&gt;同時考慮多個隨機變數的機率分佈&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;joint-pmf&#34;&gt;Joint PMF&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;X, Y 皆為離散，聯合PMF&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$p_{X,Y}(x,y)=P(X=x, Y=y)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;性質&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$0 \le p_{X,Y}(x,y) \le 1$&lt;/li&gt;
&lt;li&gt;$\Sigma^{\infty}&lt;em&gt;{x=-\infty}\Sigma^{\infty}&lt;/em&gt;{y=-\infty}
p_{X,Y}(x,y)=1$&lt;/li&gt;
&lt;li&gt;X, Y 獨立
&lt;ul&gt;
&lt;li&gt;$P_{X,Y}(x,y)\\
=P(X=x,Y=y)\\
=P_X(x)P_Y(y)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;對任何事件 B
&lt;ul&gt;
&lt;li&gt;$P(B)=\Sigma_{(x,y)\in B}P_{X,Y}(x,y)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;joint-cdf&#34;&gt;Joint CDF&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$F_{X,Y}(x,y)=P(X \le x, Y \le y)$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;性質&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$0 \le F_{X,Y}(x, y) \le 1$&lt;/li&gt;
&lt;li&gt;若 $x_1 \le x_2$ 且 $y_1 \le y_2$，則 $F_{X,Y}(x_1,y_1) \le F_{X,Y} (x_2, y_2)$&lt;/li&gt;
&lt;li&gt;$F_{X,Y}(x, \infty) = F_X(x)$&lt;/li&gt;
&lt;li&gt;$F_{X,Y}(\infty, y) = F_Y(y)$&lt;/li&gt;
&lt;li&gt;$F_{X,Y}(\infty, \infty) = 1$&lt;/li&gt;
&lt;li&gt;$F_{X,Y}(x, -\infty)\\
= P(X \le x, Y \le -\infty)\\
\le P(Y \le -\infty) \\
= 0$&lt;/li&gt;
&lt;li&gt;$F_{X,Y}(-\infty, y) = 0$&lt;/li&gt;
&lt;li&gt;$P(x_1 &amp;lt; X \le x_2, y_1 &amp;lt; Y \le y_2)\\
=F_{X,Y}(x_2,y_2)-F_{X,Y}(x_2,y_1)-F_{X,Y}(x_1,y_2)+F_{X,Y}(x_1,y_1)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;joint-pdf&#34;&gt;Joint PDF&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$f_{X,Y}(x,y)= \frac{\partial^2F_{X,Y}(x,y)}{\partial x \partial y}$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$F_{X,Y}(x,y) = \int_{-\infty}^{x} \int_{-\infty}^{y} f_{X,Y}(u,v)dv du$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;性質&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$f_{X,Y}(x,y) \ge 0$&lt;/li&gt;
&lt;li&gt;$\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}f_{X,Y}(x,y)dxdy=1$&lt;/li&gt;
&lt;li&gt;如果 X,Y 獨立
&lt;ul&gt;
&lt;li&gt;$f_{X,Y}(x,y)=f_X(x) \cdot f_Y(y)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;對任何事件 B
&lt;ul&gt;
&lt;li&gt;$P(B)=\int\int_{(x,y)\in B}f_{X,Y}(x,y)dxdy$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;邊際-pmf&#34;&gt;邊際 PMF&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Marginal PMF&lt;/li&gt;
&lt;li&gt;已知聯合 PMF : $p_{X,Y}(x,y)$，求 $p_X(x), p_Y(y)$，稱為邊際 PMF
&lt;ul&gt;
&lt;li&gt;$p_X(x)=\displaystyle\sum_{y=-\infty}^{\infty}P_{X,Y}(x,y)$&lt;/li&gt;
&lt;li&gt;$p_Y(y)=\displaystyle\sum_{x=-\infty}^{\infty}P_{X,Y}(x,y)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;已知聯合 PDF : $p_{X,Y}(x,y)$，求 $f_X(x), f_Y(y)$，稱為邊際 PDF
&lt;ul&gt;
&lt;li&gt;$f_X(x)=\int_{-\infty}^{\infty}f_{X,Y}(x,y)dy$&lt;/li&gt;
&lt;li&gt;$f_Y(y)=\int_{-\infty}^{\infty}f_{X,Y}(x,y)dx$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;雙變數期望值&#34;&gt;雙變數期望值&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;聯合 PMF 下的期望值&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$E\lbrack h(X,Y) \rbrack = \displaystyle\sum_{x=-\infty}^{\infty}\displaystyle\sum_{y=-\infty}^{\infty}h(x,y)\cdot p_{X,Y}(x,y)$
&lt;ul&gt;
&lt;li&gt;h(X,Y) 也可以只和 X 有關，比如它可以是 $x^2$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;聯合 PDF 下的期望值&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$E\lbrack h(X,Y) \rbrack = \int_{-\infty}^{\infty}\int_{-\infty}^{\infty}h(x,y)\cdot f_{X,Y}(x,y) dxdy$&lt;/li&gt;
&lt;li&gt;e.g. 已知 $f_{X,Y}(x,y)=\begin{cases}
0.5, &amp;amp; \text{if } 0 \le y \le x \le 2, \\
0, &amp;amp; otherwise
\end{cases}$
&lt;ul&gt;
&lt;li&gt;$E \lbrack X + Y \rbrack \\
= \int_{-\infty}^{\infty}\int_{-\infty}^{\infty}(x+y)\cdot f_{X,Y}(x,y) dxdy\\
= \int_{0}^{2}\int_{y}^{2}(x+y)\cdot 0.5 dxdy$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;期望值性質&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$E\lbrack \alpha h_1(X,Y)+ \beta h_2(X,Y) \rbrack\\
=\alpha E\lbrack  h_1(X,Y)\rbrack + \beta E\lbrack  h_2(X,Y) \rbrack$&lt;/li&gt;
&lt;li&gt;若 X,Y 獨立
&lt;ul&gt;
&lt;li&gt;$E\lbrack g(X)h(Y) \rbrack = E \lbrack g(X) \rbrack \cdot E \lbrack h(Y) \rbrack$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Variance 性質&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$Var(X+Y)=Var(X)+Var(Y)+2 \cdot Cov(X,Y)$
&lt;ul&gt;
&lt;li&gt;$Cov(X,Y)=E\lbrack (X-\mu_X)(Y -\mu_Y) \rbrack$
&lt;ul&gt;
&lt;li&gt;如果 X, Y 獨立
&lt;ul&gt;
&lt;li&gt;$2E\lbrack (X-\mu_X)(Y -\mu_Y) \rbrack \\
= 2E\lbrack (X-\mu_X) \rbrack  E\lbrack (Y -\mu_Y) \rbrack \\
= 0$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>機率論 - II</title>
        <link>https://roykesydon.github.io/Blog/p/%E6%A9%9F%E7%8E%87%E8%AB%96-ii/</link>
        <pubDate>Wed, 01 Feb 2023 15:18:41 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/%E6%A9%9F%E7%8E%87%E8%AB%96-ii/</guid>
        <description>&lt;h1 id=&#34;機率密度函數-pdf&#34;&gt;機率密度函數 PDF&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;probability density function&lt;/li&gt;
&lt;li&gt;PMF 在 連續R.V. 上，假如 $X\text{\textasciitilde}[0,1)$，$p_X(0.7)$ = 0，因為有無窮多個數字&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;公式&#34;&gt;公式&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;$f_X(x)=\lim\limits_{\Delta x \rightarrow 0} \frac{P(x \le X \le x + \Delta x)}{\Delta x} \\
= \lim\limits_{\Delta x \rightarrow 0} \frac{F_X(x+\Delta x) - F_X(x)}{\Delta x} \\
= F^{\prime}_X(x)
$&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;和-cdf-的關係&#34;&gt;和 CDF 的關係&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;$CDF: F_X(x) = PDF: f_X(x)$
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$\int^x_{-\infty}$ 可以從 PDF 轉到 CDF&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$\frac{d}{dx} 可以從 CDF 轉到 PDF$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;跟機率的關係&#34;&gt;跟機率的關係&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;$P(a &amp;lt; X \le b) = F_X(b) - F_X(a) \\
= \int^b_{-\infty} f_X(x)dx - \int^a_{-\infty} f_X(x)dx \\
= \int^a_b f_X(x)dx$&lt;/li&gt;
&lt;li&gt;$f_X(x)=\lim\limits_{\Delta x \rightarrow 0} \frac{P(x \le X \le x + \Delta x)}{\Delta x}$
&lt;ul&gt;
&lt;li&gt;當 $\Delta x$ 很小時
&lt;ul&gt;
&lt;li&gt;$P(x \le X \le x + \Delta x) \approx f_X(x) \cdot \Delta x$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;性質&#34;&gt;性質&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;$f_X(x) = F^{\prime}_X(x)$&lt;/li&gt;
&lt;li&gt;$F_X(x)=\int^x_{-\infty}f_X(u)du$&lt;/li&gt;
&lt;li&gt;$P(a \le X \le b)=\int^b_a f_X(x) dx$&lt;/li&gt;
&lt;li&gt;$\int^{\infty}_{-\infty}f_X(x)dx=1$&lt;/li&gt;
&lt;li&gt;$f_X(x) \ge 0$&lt;/li&gt;
&lt;li&gt;$f_X(x)$ 可以比 1 大&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;連續機率分佈&#34;&gt;連續機率分佈&lt;/h1&gt;
&lt;h2 id=&#34;uniform-機率分佈&#34;&gt;Uniform 機率分佈&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;$X \text{\textasciitilde}UNIF(a,b)$&lt;/li&gt;
&lt;li&gt;PDF
&lt;ul&gt;
&lt;li&gt;$f_X(x) = \begin{cases}
\frac{1}{b-a} &amp;amp; ,a \le x \le b \\
0 &amp;amp; ,otherwise
\end{cases}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;CDF
&lt;ul&gt;
&lt;li&gt;$F_X(x) = \begin{cases}
0 &amp;amp; ,x \le a \\
\frac{x-a}{b-a} &amp;amp; ,a &amp;lt; x \le b\\
1 &amp;amp; ,x &amp;gt; b
\end{cases}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;exponential-機率分佈&#34;&gt;Exponential 機率分佈&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;有失憶性(memoryless)，常被用來 model 有這種性質的事情&lt;/li&gt;
&lt;li&gt;$X \text{\textasciitilde}Exponential(\lambda)$&lt;/li&gt;
&lt;li&gt;PDF
&lt;ul&gt;
&lt;li&gt;$f_X(x) = \begin{cases}
\lambda e^{-\lambda x} &amp;amp; ,x \ge 0 \\
0 &amp;amp; ,otherwise
\end{cases}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;CDF
&lt;ul&gt;
&lt;li&gt;$F_X(x) = 1-e^{-\lambda x}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;erlang-機率分佈&#34;&gt;Erlang 機率分佈&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Gamma Distribution&lt;/li&gt;
&lt;li&gt;$X \text{\textasciitilde}Erlang(n,\lambda)$&lt;/li&gt;
&lt;li&gt;PDF
&lt;ul&gt;
&lt;li&gt;$f_X(x) = \begin{cases}
\frac{1}{(n-1)!}\lambda^n x^{n-1} e^{-\lambda x} &amp;amp; ,x \ge 0 \\
0 &amp;amp; ,otherwise
\end{cases}$
&lt;ul&gt;
&lt;li&gt;$f_X(x)=(\lambda e^{-\lambda x}) * (\lambda e^{-\lambda x}) * &amp;hellip; * (\lambda e^{-\lambda x})$
&lt;ul&gt;
&lt;li&gt;自己和自己做 n 次 convolution&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;CDF
&lt;ul&gt;
&lt;li&gt;$F_X(x) = \begin{cases}
1 - \Sigma^{n-1}_{k=0}\frac{(\lambda x)^k}{k!}e^{-\lambda x} &amp;amp; ,x \ge 0 \\
0 &amp;amp; ,otherwise
\end{cases}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;常見用法&#34;&gt;常見用法&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;用來 model 一件有多個關卡事情的總時間，而每個關卡所需時間是隨機的
&lt;ul&gt;
&lt;li&gt;關卡數: n&lt;/li&gt;
&lt;li&gt;每關卡所需時間之機率分佈 $Exponential(\lambda)$&lt;/li&gt;
&lt;li&gt;e.g. 打電動過三關所需時間
&lt;ul&gt;
&lt;li&gt;$Erlang(3, \lambda)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;normal-機率分佈-常態分佈&#34;&gt;Normal 機率分佈 (常態分佈)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;在自然界常出現&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;常被用做「很多隨機量的總和」的機率模型&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;又稱 Gaussian 機率分佈&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$X \text{\textasciitilde}Gaussian(\mu,\sigma)$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;PDF&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$f_X(x)=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^2}{2\sigma^2}}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;也常用 $X \text{\textasciitilde}N(\mu,\sigma^2)$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;注意 $\sigma$ 不一樣&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;CDF&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;太難算，積不出來&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;針對某組特別的 $\mu, \sigma$ 的 CDF 建表，把其他常態分佈的 CDF 和這組產生關聯&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;標準常態分佈&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$Z \text{\textasciitilde}N(0,1)$
&lt;ul&gt;
&lt;li&gt;$f_Z(z)=\frac{1}{\sqrt{2 \pi}}e^{-\frac{z^2}{2}}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;CDF 表示為 $\Phi(z)$
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$\Phi(z)=\int^z_{-\infty}\frac{1}{\sqrt{2\pi}}e^{-\frac{u^2}{2}}du$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;積不出來，以數值方法近似出來後建表給人家查
&lt;ul&gt;
&lt;li&gt;查 standard normal table&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;e.g. $F_Z(1.325)=?$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;查表 $F_Z(1.32)=0.9066$，$F_Z(1.33)=0.9082$
&lt;ul&gt;
&lt;li&gt;用內插約略得 0.9074&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;性質&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\Phi(-z) = 1 - \Phi(z)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;任意  $\mu, \sigma$ 的 CDF&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;對任何 $X \text{\textasciitilde}N(\mu,\sigma^2)$
&lt;ul&gt;
&lt;li&gt;$\frac{X-\mu}{\sigma}\text{\textasciitilde}N(0,1)$&lt;/li&gt;
&lt;li&gt;$F_X(x)=\Phi(\frac{x-\mu}{\sigma})$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;期望值&#34;&gt;期望值&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Expectation&lt;/li&gt;
&lt;li&gt;大數法則
&lt;ul&gt;
&lt;li&gt;$P(A)=\lim\limits_{N \rightarrow \infty}\frac{N_A}{N}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;基本上期望值是利用大數法則算的 mean 值，雖然平均值是 R.V.，但當實驗無窮多次時，會收斂到常數，因此以這為估算值&lt;/li&gt;
&lt;li&gt;Mean 值又稱做期望值&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;離散隨機變數&#34;&gt;離散隨機變數&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;$E\lbrack X \rbrack=\mu_X=\displaystyle\sum^{\infty}_{x=-\infty}x \cdot P_X(x)$&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;離散隨機變數的函數的期望值&#34;&gt;離散隨機變數的函數的期望值&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;對離散隨機變數 X 而言，其任意函數 g(x) 也是一隨機變數，也有期望值
&lt;ul&gt;
&lt;li&gt;$g(X)$ 的期望值定義為
&lt;ul&gt;
&lt;li&gt;$E \lbrack g(X) \rbrack=\displaystyle\sum^{\infty}_{x=-\infty}g(x)\cdot P_X(x)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;性質-1&#34;&gt;性質&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;$E\lbrack \alpha g(X) \rbrack = \alpha \cdot E \lbrack g(X) \rbrack$&lt;/li&gt;
&lt;li&gt;$E\lbrack \alpha g(X) + \beta h(X) \rbrack \\
=\alpha \cdot E \lbrack g(X) \rbrack + \beta \cdot E \lbrack h(X) \rbrack$&lt;/li&gt;
&lt;li&gt;$E\lbrack \alpha \rbrack = \alpha$&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;常見隨機變數函數的期望值&#34;&gt;常見隨機變數函數的期望值&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;$X$ 的 $n^{th} moment$
&lt;ul&gt;
&lt;li&gt;$E \lbrack X^n \rbrack = \displaystyle\sum^{\infty}_{x=-\infty}x^n \cdot P_X(x)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;X 的變異數(variance)
&lt;ul&gt;
&lt;li&gt;$E \lbrack (X-\mu_X)^2 \rbrack = \displaystyle\sum^{\infty}_{x=-\infty} (x-\mu_X)^2 \cdot P_X(x)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;變異數-variance&#34;&gt;變異數 Variance&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Variance 通常符號表示為 $\sigma^2_X=E \lbrack (X-\mu_X)^2 \rbrack$&lt;/li&gt;
&lt;li&gt;隱含隨機變數 X 多「亂」的資訊
&lt;ul&gt;
&lt;li&gt;variance 大的話，X 不見得接近 $\mu_X$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;變異數開根號是標準差(standard deviation)
&lt;ul&gt;
&lt;li&gt;$\sigma_X = \sqrt{Variance} \ge 0$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;算法&#34;&gt;算法&lt;/h4&gt;
&lt;p&gt;$\sigma^2_X=E \lbrack X^2 \rbrack - \mu^2_X\\
\Rightarrow E \lbrack X^2 \rbrack = \sigma^2_X + \mu^2_X$&lt;/p&gt;
&lt;h3 id=&#34;常見離散分佈的期望值--變異數&#34;&gt;常見離散分佈的期望值 / 變異數&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$X\text{\textasciitilde}Bernouli(p)$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$\mu_X=1 \cdot p + 0 \cdot (1-p) \\
= p$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$\sigma^2_X = E \lbrack X^2 \rbrack - \mu^2_X \\
= \displaystyle\sum^1_{x=0}x^2\cdot p_X(x)-\mu_X^2 \\
=1^2 \cdot p + 0^2 \cdot (1-p) - p^2\\
=p(1-p)$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$X$~$BIN(n,p)$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$\mu_X = np$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$\sigma^2_X = np(1-p)$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$X$~$GEO(p)$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$\mu_X = \frac{1}{p}$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$\sigma^2_X = \frac{(1-p)}{p^2}$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$X$~$PASKAL(k,p)$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$\mu_X = \frac{k}{p}$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$\sigma^2_X = \frac{k(1-p)}{p^2}$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$X$~$POI(\alpha)$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$\mu_X = \alpha$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$\sigma^2_X = \alpha$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$X$~$UNIF(a,b)$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$\mu_X = \frac{a+b}{2}$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$\sigma^2_X = \frac{1}{12}(b-a)(b-a+2)$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;連續隨機變數&#34;&gt;連續隨機變數&lt;/h2&gt;
&lt;p&gt;對連續的隨機變數 X 而言，將 X 的值以 $\Delta$ 為單位無條件捨去來近似，以隨機變數 Y 表示(當 $\Delta \rightarrow$ 0 時，$X \approx Y$)，然後再當做 PMF 處理。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$E \lbrack X \rbrack = \int^{\infty}_{-\infty}xf_X(x)dx$&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;連續隨機變數的函數的期望值&#34;&gt;連續隨機變數的函數的期望值&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;對連續隨機變數 X 而言，其任意函數 g(x) 也是一隨機變數，也有期望值
&lt;ul&gt;
&lt;li&gt;$g(X)$ 的期望值定義為
&lt;ul&gt;
&lt;li&gt;$E \lbrack g(X) \rbrack=\int^{\infty}_{-\infty}g(x)\cdot f_X(x)dx$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;性質-2&#34;&gt;性質&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;$E\lbrack \alpha g(X) \rbrack = \alpha \cdot E \lbrack g(X) \rbrack$&lt;/li&gt;
&lt;li&gt;$E\lbrack \alpha g(X) + \beta h(X) \rbrack \\
=\alpha \cdot E \lbrack g(X) \rbrack + \beta \cdot E \lbrack h(X) \rbrack$&lt;/li&gt;
&lt;li&gt;$E\lbrack \alpha \rbrack = \alpha$&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;常見隨機變數函數的期望值-1&#34;&gt;常見隨機變數函數的期望值&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;$X$ 的 $n^{th} moment$
&lt;ul&gt;
&lt;li&gt;$E \lbrack X^n \rbrack = \int^{\infty}_{-\infty}x^n \cdot f_X(x)dx$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;X 的變異數(variance)
&lt;ul&gt;
&lt;li&gt;$E \lbrack (X-\mu_X)^2 \rbrack = \int^{\infty}_{-\infty} (x-\mu_X)^2 \cdot f_X(x)dx$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;變異數-variance-1&#34;&gt;變異數 Variance&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;和離散隨機變數的資訊一樣&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;常見連續分佈之期望值變異數&#34;&gt;常見連續分佈之期望值/變異數&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$X$~$Exponential(\lambda)$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$\mu_X = \frac{1}{\lambda}$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$\sigma^2_X = \frac{1}{\lambda^2}$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$X$~$Erlang(n, \lambda)$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$\mu_X = \frac{n}{\lambda}$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$\sigma^2_X = \frac{n}{\lambda^2}$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$X$~$Gaussian(\mu,\sigma)$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$\mu_X = \mu$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$\sigma^2_X = \sigma^2$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$X$~$UNIF(a,b)$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$\mu_X = \frac{a+b}{2}$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$\sigma^2_X = \frac{1}{12}(b-a)^2$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>機率論 - I</title>
        <link>https://roykesydon.github.io/Blog/p/%E6%A9%9F%E7%8E%87%E8%AB%96-i/</link>
        <pubDate>Tue, 31 Jan 2023 15:18:41 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/%E6%A9%9F%E7%8E%87%E8%AB%96-i/</guid>
        <description>&lt;h1 id=&#34;集合論&#34;&gt;集合論&lt;/h1&gt;
&lt;h2 id=&#34;名詞&#34;&gt;名詞&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;子集合(Subset)
&lt;ul&gt;
&lt;li&gt;B 是 C 的子集(B 不能等於 C)
&lt;ul&gt;
&lt;li&gt;$B \subset C$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;補集(Complement)
&lt;ul&gt;
&lt;li&gt;C 是 A 的補集
&lt;ul&gt;
&lt;li&gt;$C=A^C$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;不相交(Disjoint)
&lt;ul&gt;
&lt;li&gt;$X \cap Y = \{\}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;互斥(Mutually Exclusive)
&lt;ul&gt;
&lt;li&gt;一群集合 $X_1, X_2, &amp;hellip;, X_n$ 中任選兩個集合 $X_i, X_j$ 都不相交，則 $X_1, X_2, &amp;hellip;, X_n$ 這群集合互斥&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;公式&#34;&gt;公式&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;De Morgan&amp;rsquo;s Law
&lt;ul&gt;
&lt;li&gt;${(A \cup B)}^C=A^C \cap B^C$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;機率名詞&#34;&gt;機率名詞&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Outcome (結果)
&lt;ul&gt;
&lt;li&gt;實驗中可能的結果&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Sample Space (樣本空間)
&lt;ul&gt;
&lt;li&gt;機率實驗所有可能的結果的集合，常以 $S$ 表示&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Event (事件)
&lt;ul&gt;
&lt;li&gt;對於實驗結果的某種敘述&lt;/li&gt;
&lt;li&gt;事件可以看做是 outcome 的集合，也是 sample space 的子集&lt;/li&gt;
&lt;li&gt;機率是一個函數，其自變數是 event，故可看做是一個映射&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;公理-axioms&#34;&gt;公理 Axioms&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;對任何事件 $A$ 而言, $P(A) \geq 0$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$P(S) = 1$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;事件 $A_1, A_2, &amp;hellip;$ 互斥 $\Rightarrow$ $P(A_1 \cup A_2 \cup A_3 \cup &amp;hellip;)$&lt;/p&gt;
&lt;p&gt;$=P(A_1)+P(A_2)+P(A_3)+&amp;hellip;$&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;衍生公式&#34;&gt;衍生公式&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Boole&amp;rsquo;s 不等式&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;對任意 $n$ 個事件 $A_1, A_2, &amp;hellip;, A_n$ 而言
&lt;ul&gt;
&lt;li&gt;$P(\cup^n_{i=1}A_i \leq \Sigma^n_{i=1}P(A_i))$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Bonferroni&amp;rsquo;s 不等式&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;對任意 $n$ 個事件 $A_1, A_2, &amp;hellip;, A_n$ 而言
&lt;ul&gt;
&lt;li&gt;$P(\cap^n_{i=1} A_i) \geq 1 - \Sigma^n_{i=1} P(A^C_i)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;條件機率&#34;&gt;條件機率&lt;/h1&gt;
&lt;h2 id=&#34;公式-1&#34;&gt;公式&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;$P(X|Y) = \frac{P(X \cap Y)}{P(Y)}$
&lt;ul&gt;
&lt;li&gt;$P(X \cap Y) = P(X|Y) * {P(Y)} = P(Y|X) * P(X)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;性質&#34;&gt;性質&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;$P(X|Y) \geq 0$&lt;/li&gt;
&lt;li&gt;$P(Y|Y) = 1$&lt;/li&gt;
&lt;li&gt;$A, B$ 互斥 $\Rightarrow P(A \cup B |Y) = \frac{P(A)}{P(Y)} + \frac{P(B)}{P(Y)} = P(A|Y)+P(B|Y)$&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;定理&#34;&gt;定理&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Total Probability 定理
&lt;ul&gt;
&lt;li&gt;若 $C_1, C_2, &amp;hellip;, C_n$ 互斥且 $C_1 \cup C_2 \cup &amp;hellip; \cup C_n = S$，則對任意事件 $A$
&lt;ul&gt;
&lt;li&gt;$P(A) = P(A|C_1)P(C_1) +  P(A|C_2)P(C_2) + &amp;hellip; + P(A|C_n)P(C_n)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Bayes&amp;rsquo; Rule 貝式定理
&lt;ul&gt;
&lt;li&gt;若 $C_1, C_2, &amp;hellip;, C_n$ 互斥且 $C_1 \cup C_2 \cup &amp;hellip; \cup C_n = S$，則對任意事件 $A$
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$P(C_j|A)=\frac{P(A|C_j) * P(C_j)}{\Sigma^n_{i=1}P(A|C_i)*P(C_i)}$&lt;/p&gt;
&lt;p&gt;$= \frac{P(C_j \cap A)}{P(A)}$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;獨立性-independence&#34;&gt;獨立性 Independence&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;若兩事件 $A, B$ 之機率滿足&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$P(A \cap B) = P(A) * P(B)$&lt;/li&gt;
&lt;li&gt;或以 $P(A|B) = P(A)$ 表示&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;則 $A, B$ 兩事件稱為機率上的獨立事件&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;若事件 $A_1, A_2, &amp;hellip; A_n$ 滿足下列條件，則稱此 $n$ 事件獨立 $(n&amp;gt;2)$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;從中任選 $m$ 事件 $A_{i_1}, A_{i_2}, &amp;hellip; A_{i_m}$ 均滿足
&lt;ul&gt;
&lt;li&gt;$P(A_{i_1} \cap A_{i_2} \cap &amp;hellip; \cap A_{i_m}) = P(A_{i_1})P(A_{i_2})&amp;hellip;P(A_{i_m}) , m=2, 3, &amp;hellip;, n$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;排列組合&#34;&gt;排列組合&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;二項式係數(binomial coefficient)
&lt;ul&gt;
&lt;li&gt;$(^n_k)$
&lt;ul&gt;
&lt;li&gt;有 $n$ 個異物，從中取出 $k$ 個&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;多項式係數(multinomial coefficient)
&lt;ul&gt;
&lt;li&gt;$\frac{n!}{n_1!n_2!&amp;hellip;n_m!}$
&lt;ul&gt;
&lt;li&gt;有 m 種異物，每次選物從中選一後放回，依序選 n 次，共有 $m^n$ 種 outcome，在所有實驗結果中，第一種出現 $n_1$ 次，以此類推，這樣的實驗結果有多少種&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;隨機變數-random-variable-rv&#34;&gt;隨機變數 Random Variable, R.V.&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;用來把 outcome 數字化的表示方式&lt;/li&gt;
&lt;li&gt;通常用大寫英文字母&lt;/li&gt;
&lt;li&gt;是將 outcome 轉成對應數字的函數
&lt;ul&gt;
&lt;li&gt;$X: S \rightarrow R$
&lt;ul&gt;
&lt;li&gt;從樣本空間映射到實數&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;隨機變數的函數，也是一個隨機變數&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;種類&#34;&gt;種類&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;離散隨機變數 (Discrete R.V.)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;值是有限個，或是「可數的」無窮多個&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;連續隨機變數 (Continuous R.V.)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;值有無窮多個，而且「不可數」&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;可數不可數&#34;&gt;可數、不可數&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;可數
&lt;ul&gt;
&lt;li&gt;包含的東西可一個個被數，總有一天會被數到
&lt;ul&gt;
&lt;li&gt;e.g. 正偶數集合&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;不可數的
&lt;ul&gt;
&lt;li&gt;不管怎麼數，裡面一定有個東西會沒數到
&lt;ul&gt;
&lt;li&gt;e.g. 0~1 之間的所有數字&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;累積分佈函數-cdf&#34;&gt;累積分佈函數 CDF&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;cumulative distribution function&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;對任一個隨機變數 $X$，定義 CDF 為&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$F_X(x) \overset{def}{=}P(X \leq x)$
&lt;ul&gt;
&lt;li&gt;永遠用 $F$ 表示&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;常見用途&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;算 X 落在某範圍的機率&lt;/li&gt;
&lt;li&gt;$P(A &amp;lt; X \le b) = F_X(b)-F_X(a)$
&lt;ul&gt;
&lt;li&gt;$P(A \le X \le b) = F_X(b)-F_X(a)+P(X=a)$&lt;/li&gt;
&lt;li&gt;$P(A &amp;lt; X &amp;lt; b) = P(A &amp;lt; X \le b^-)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;性質-1&#34;&gt;性質&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;離散隨機變數的 CDF
&lt;ul&gt;
&lt;li&gt;$F_X(x^+)=F_X(x)$&lt;/li&gt;
&lt;li&gt;$F_X(x^-)=F_X(x)-P(X=x)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;連續隨機變數的 CDF
&lt;ul&gt;
&lt;li&gt;$F_X(x^-)=F_X(x)=F_X(x^+)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;共同
&lt;ul&gt;
&lt;li&gt;$F_X(- \infty)=P(X \le - \infty)=0$&lt;/li&gt;
&lt;li&gt;$F_X(\infty)=P(X \le \infty) = 1$&lt;/li&gt;
&lt;li&gt;$0 \le F_X(x) \le 1$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;機率質量函數-pmf&#34;&gt;機率質量函數 PMF&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;probability mass function&lt;/li&gt;
&lt;li&gt;對任一個「離散」隨機變數 $X$，其 PMF 為
&lt;ul&gt;
&lt;li&gt;$p_X(x) \overset{def}{=}P(X=x)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;pmf-和-cdf-的關係&#34;&gt;PMF 和 CDF 的關係&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;對任何 $x$
&lt;ul&gt;
&lt;li&gt;$F_X(x) = \displaystyle\sum^{\lfloor x \rfloor}_{n=-\infty}p_X(n)$
&lt;ul&gt;
&lt;li&gt;$P_X(x)=F_X(x^+)-F_X(x^-)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;機率分佈probability-distribution&#34;&gt;機率分佈(Probability Distribution)&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;PMF 和 PDF 都是一種機率分佈
&lt;ul&gt;
&lt;li&gt;將總和為 1 的機率分佈在點上&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;離散機率分佈&#34;&gt;離散機率分佈&lt;/h1&gt;
&lt;h2 id=&#34;bernoulli-機率分佈&#34;&gt;Bernoulli 機率分佈&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;1 次實驗，2 種結果，在意某結果發生與否&lt;/li&gt;
&lt;li&gt;$X \text{\textasciitilde}Bernoulli(p)$&lt;/li&gt;
&lt;li&gt;PMF
&lt;ul&gt;
&lt;li&gt;$p_X(x) = \begin{cases}
p &amp;amp; ,x=1 \\
1-p &amp;amp; x=0 \\
0 &amp;amp; ,otherwise
\end{cases}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;CDF
&lt;ul&gt;
&lt;li&gt;$F_X(x) = \begin{cases}
0 &amp;amp; ,x&amp;lt;0 \\
1-p &amp;amp; 0 \leq x &amp;lt;1 \\
1 &amp;amp; ,x \geq 1
\end{cases}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;binomial-機率分佈&#34;&gt;Binomial 機率分佈&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;實驗成功機率為 p，做 n 次實驗，X 表成功次數&lt;/li&gt;
&lt;li&gt;$X \text{\textasciitilde}BIN(p)$&lt;/li&gt;
&lt;li&gt;PMF
&lt;ul&gt;
&lt;li&gt;$p_X(x) = (^n_x)p^x(1-p)^{n-x}$
&lt;ul&gt;
&lt;li&gt;成功 $x$ 次&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;CDF
&lt;ul&gt;
&lt;li&gt;$F_X(x) = \displaystyle\sum^{\lfloor x \rfloor}_{m=-\infty} (^n_m)\cdot p^m \cdot (1-p)^{n-m}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;uniform-機率分佈&#34;&gt;Uniform 機率分佈&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;1 次實驗，n 種結果，各結果機率均等，在意某結果發生否&lt;/li&gt;
&lt;li&gt;$X \text{\textasciitilde}UNIF(a,b)$&lt;/li&gt;
&lt;li&gt;PMF
&lt;ul&gt;
&lt;li&gt;$p_X(x) = \begin{cases}
\frac{1}{b-a+1} &amp;amp; ,x=a,a+1,&amp;hellip;,b \\
0 &amp;amp; ,otherwise
\end{cases}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;CDF
&lt;ul&gt;
&lt;li&gt;$F_X(x) = \begin{cases}
0 &amp;amp; ,x&amp;lt;a \\
\frac{\lfloor x \rfloor - a + 1}{b-a+1} &amp;amp; ,a \leq x&amp;lt; b\\
1 &amp;amp; ,x \geq b
\end{cases}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;geometric-機率分佈&#34;&gt;Geometric 機率分佈&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;若實驗成功機率為 p，到成功為止，做了 X 次嘗試&lt;/li&gt;
&lt;li&gt;有失憶性&lt;/li&gt;
&lt;li&gt;$X \text{\textasciitilde}Geometric(p)$&lt;/li&gt;
&lt;li&gt;PMF
&lt;ul&gt;
&lt;li&gt;$p_X(x) = \begin{cases}
(1-p)^{x-1} \cdot p &amp;amp; ,x=1, 2, 3, &amp;hellip; \\
0 &amp;amp; ,otherwise
\end{cases}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;CDF
&lt;ul&gt;
&lt;li&gt;$F_X(x) = \begin{cases}
1-(1-p)^{\lfloor x \rfloor} &amp;amp; ,x \ge 1 \\
0 &amp;amp; ,otherwise
\end{cases}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;pascal-機率分佈&#34;&gt;Pascal 機率分佈&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;若實驗成功機率為 p，到第 k 次成功為止，共做了 X 次嘗試&lt;/li&gt;
&lt;li&gt;$X \text{\textasciitilde}Pascal(k, p)$&lt;/li&gt;
&lt;li&gt;PMF
&lt;ul&gt;
&lt;li&gt;$p_X(x) = \begin{cases}
\binom{x-1}{k-1}(1-p)^{x-k} p^k &amp;amp; ,x=k, k+1, &amp;hellip; \\
0 &amp;amp; ,otherwise
\end{cases}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;CDF
&lt;ul&gt;
&lt;li&gt;$F_X(x) = P(X \le x) \\
= P(在 x 次實驗中 \ge k 次成功)\\
= P(Y \ge k), Y~BIN (x,p) \\
$
&lt;ul&gt;
&lt;li&gt;故 Pascal 又稱 Negative Binomial&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;poisson-機率分佈&#34;&gt;Poisson 機率分佈&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;已知某事發生速率為每單位時間 $\lambda$ 次，觀察時間為 $T$ 時間單位，$X$ 為該觀察時間內發生該事的總次數。&lt;/li&gt;
&lt;li&gt;$X \text{\textasciitilde}POI(\lambda T)$
&lt;ul&gt;
&lt;li&gt;有時候也會以 $\mu$ 來表示 $\lambda T$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;PMF
&lt;ul&gt;
&lt;li&gt;$p_X(x) = e^{-\lambda T} \cdot \frac{(\lambda T)^x}{x!}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;CDF
&lt;ul&gt;
&lt;li&gt;$F_X(x) = \begin{cases}
\displaystyle\sum^{\lfloor x \rfloor}_{n=-\infty}e^{-\lambda T} \cdot \frac{(\lambda T)^n}{n!} &amp;amp; ,x = 0,1,2,&amp;hellip; \\
0 &amp;amp; ,otherwise
\end{cases}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>IPC -- Inter-Process Communication</title>
        <link>https://roykesydon.github.io/Blog/p/ipc--inter-process-communication/</link>
        <pubDate>Sat, 28 Jan 2023 15:31:50 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/ipc--inter-process-communication/</guid>
        <description>&lt;h1 id=&#34;share-information-between-processes&#34;&gt;Share information between processes&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;透過硬碟上的文件溝通
&lt;ul&gt;
&lt;li&gt;超慢&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;透過 kernel buffer
&lt;ul&gt;
&lt;li&gt;滿快的，但這樣要一直在 user mode 和 kernel mode 來回切換，因為kernel buffer 在 kernel space&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;透過 shared memory region
&lt;ul&gt;
&lt;li&gt;shared memory region 在 user space&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;mechanisms&#34;&gt;Mechanisms&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Signals&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Communication&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Data transfer
&lt;ul&gt;
&lt;li&gt;Byte Stream
&lt;ul&gt;
&lt;li&gt;Pipes&lt;/li&gt;
&lt;li&gt;FIFOs(Named Pipes)&lt;/li&gt;
&lt;li&gt;stream sockets&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Message Passing
&lt;ul&gt;
&lt;li&gt;SystemV MsgQ&lt;/li&gt;
&lt;li&gt;POSIX MsgQ&lt;/li&gt;
&lt;li&gt;datagram sockets&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Shared Memory
&lt;ul&gt;
&lt;li&gt;SystemV S.M&lt;/li&gt;
&lt;li&gt;POSIX S.M&lt;/li&gt;
&lt;li&gt;Memory Mapping
&lt;ul&gt;
&lt;li&gt;anonymous memory mapping&lt;/li&gt;
&lt;li&gt;memory mapped file&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Synchronization&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;pipes&#34;&gt;Pipes&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Related processes
&lt;ul&gt;
&lt;li&gt;parent-child&lt;/li&gt;
&lt;li&gt;sibling&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Executing on same machine&lt;/li&gt;
&lt;li&gt;用法
&lt;ul&gt;
&lt;li&gt;cmd1 | cmd2
&lt;ul&gt;
&lt;li&gt;cmd1 不是輸出到 stdout，而是由 kernel 維護的 buffer，也就是 pipe&lt;/li&gt;
&lt;li&gt;cmd 不是從 stdin 獲取輸入，而是從 pipe 獲取&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;cmd1 | cmd2 | &amp;hellip; | cmdn&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;named-pipes--fifos&#34;&gt;Named Pipes / FIFOs&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Related / Unrelated processes&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Executing on same machine&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;creat a FIFO&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;commands
&lt;ul&gt;
&lt;li&gt;mkfifo&lt;/li&gt;
&lt;li&gt;mknod&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;嘗試寫入或讀取 FIFO 時，會被 redirect 到 pipe&lt;/p&gt;
&lt;h1 id=&#34;signal-handling&#34;&gt;Signal Handling&lt;/h1&gt;
&lt;h2 id=&#34;signal&#34;&gt;Signal&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Used by OS to notify running process some event has occured without the process needing to pull for that event&lt;/li&gt;
&lt;li&gt;process 收到 signal 後會先停止執行並執行 signal handler&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;A process did something
&lt;ul&gt;
&lt;li&gt;SIGSEGV(11), SIGFPE(8), SIGILL(4), SIGPIPE(13)&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;A process wants to tell another process something
&lt;ul&gt;
&lt;li&gt;SIGCHILD(17)
&lt;ul&gt;
&lt;li&gt;child process terminated&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;User sends sig to foreground processes
&lt;ul&gt;
&lt;li&gt;Ctrl + C SIGINT(2)&lt;/li&gt;
&lt;li&gt;Ctrl + \ SIGQUIT(3)&lt;/li&gt;
&lt;li&gt;Ctrl + Z SIGTSTP(20)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;disposition&#34;&gt;disposition&lt;/h3&gt;
&lt;p&gt;決定 process 遇到 signal 時該怎麼處理&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Term
&lt;ul&gt;
&lt;li&gt;teminate process&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Ign
&lt;ul&gt;
&lt;li&gt;ignore&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Core
&lt;ul&gt;
&lt;li&gt;terminate the process and dump core&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Stop
&lt;ul&gt;
&lt;li&gt;stop the process&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Cont
&lt;ul&gt;
&lt;li&gt;continue the process if it is stopped&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;signal-cant-not-be-caught&#34;&gt;Signal can&amp;rsquo;t not be caught&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;SIGKILL(9)&lt;/li&gt;
&lt;li&gt;SIGSTOP(19)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;commands&#34;&gt;Commands&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;trap&lt;/p&gt;
&lt;p&gt;可以 handle signal&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;kill&#34;&gt;kill&lt;/h2&gt;
&lt;p&gt;kill - L 可以看到 standard signal 和 real-time signal&lt;/p&gt;
&lt;p&gt;standard signal 開頭是 SIG，realt-time signal 是 SIGRT&lt;/p&gt;
</description>
        </item>
        <item>
        <title>InstructGPT</title>
        <link>https://roykesydon.github.io/Blog/p/instructgpt/</link>
        <pubDate>Fri, 27 Jan 2023 17:39:12 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/instructgpt/</guid>
        <description>&lt;p&gt;paper: &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2203.02155&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Training language models to follow instructions with human feedback&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;abstract&#34;&gt;Abstract&lt;/h1&gt;
&lt;p&gt;把語言模型變大不代表他們會更好地遵循用戶的意圖。&lt;/p&gt;
&lt;p&gt;大的語言模型有可能會生成 untruthful, toxic, not helpful 的答案。&lt;/p&gt;
&lt;p&gt;該論文透過 fine-tuning with human feedback 來解決這問題。&lt;/p&gt;
&lt;p&gt;一開始準備一系列人工標註的 prompts，然後用這 dataset 對 GPT-3 做 fine-tune。&lt;/p&gt;
&lt;p&gt;接下來再蒐集一個 dataset，存放 rankings of model outputs，由人工判斷輸出好壞，再用 RL 把剛剛 fine-tune 過的 model 繼續 fine-tune。&lt;/p&gt;
&lt;p&gt;最後有 1.3B 參數的 InstructGPT 表現的結果比 175B 參數的 GPT-3 還好。&lt;/p&gt;
&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Large language models(LMs) 可以透過 &amp;ldquo;prompt&amp;rdquo; 來執行各種 NLP 任務。&lt;/p&gt;
&lt;p&gt;但這些模型也常有一些非目的性的行為，諸如捏造事實等等。&lt;/p&gt;
&lt;p&gt;原因是出在目標函數上，多數 LMs 的目標函數是根據網路上的文本生出下一個字詞。&lt;/p&gt;
&lt;p&gt;這和「根據使用者指令生出安全且有幫助的答案不同」。&lt;/p&gt;
&lt;p&gt;上述的差異使語言模型的目標是 misaligned。&lt;/p&gt;
&lt;p&gt;作者的目標是生出 helpful、 honest(沒有誤導性資訊)、harmless 的 model。&lt;/p&gt;
&lt;p&gt;具體作法，使用 reinforcement learning from human feedback(RLHF)。&lt;/p&gt;
&lt;h2 id=&#34;訓練步驟&#34;&gt;訓練步驟&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/gpt/instruct-gpt-train-step.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;結果&#34;&gt;結果&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Labelers 明顯偏好 InstructGPT 的答案，勝過 GPT-3 的答案&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;InstructGPT 的答案在 truthfulness 勝過 GPT-3 的答案&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;InstructGPT 的答案在 toxicity 上小勝 GPT-3 的答案，但在 bias 上沒有&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;methods&#34;&gt;Methods&lt;/h1&gt;
&lt;h2 id=&#34;dataset&#34;&gt;Dataset&lt;/h2&gt;
&lt;p&gt;標註人員寫很多 prompts&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Plain:
&lt;ul&gt;
&lt;li&gt;隨便寫任意任務&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Few-shot:
&lt;ul&gt;
&lt;li&gt;想個 instruction，並寫 multiple query/response pairs for that instruction&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;User-based:
&lt;ul&gt;
&lt;li&gt;根據一些申請使用 OpenAI API 的用戶，提出有關的 prompts&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;然後根據這個訓練初步模型，並把這個初步模型放到他們的 Playground 給用戶使用。&lt;/p&gt;
&lt;p&gt;再把用戶問的問題蒐集回來，並做篩選。&lt;/p&gt;
&lt;p&gt;訓練 SFT 的模型用 13k training prompts&lt;/p&gt;
&lt;p&gt;訓練 RM 的模型用 33k training prompts&lt;/p&gt;
&lt;p&gt;訓練 PPO 的模型用 31k training prompts&lt;/p&gt;
&lt;h2 id=&#34;model&#34;&gt;Model&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Supervised fine-tuning(SFT)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;拿 GPT-3 去訓練 16 個 epochs&lt;/li&gt;
&lt;li&gt;跑一個 epoch 就發現 overfitting，但發現訓練更多 epoches 對後面的 RM 有用，而且這個 model 也只是過渡產品&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Reward modeling(RM)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;把 SFT 後面的 unembedding layer 去除掉，接上線性層，最後輸出一個 scalar reward&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;用 6B RMs&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;這模型會吃 prompt 和 response&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;人工標記的是排序，不是分數&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;對每個 prompt 生出 9 個答案&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;原本是 4 個，但排 9 個花的時間可能不會到 4 個的兩倍，因為主要心力會花在讀 prompt。但標註訊息會多很多，因為都是兩兩比較。&lt;/li&gt;
&lt;li&gt;而且在 loss 中最多只要丟入 RM 9 次，因為可以重用&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Pairwise Ranking Loss&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;對一個 prompt(假設是 x)，取出一對回覆(假設是 $y_w$ 和 $y_l$)，算出 RM(x, $y_w$) 和 RM(x, $y_l$)，假設 $y_w$ 比 $y_l$ 排序高，讓 RM(x, $y_w$) - RM(x, $y_l$) 的數值越大越好&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/gpt/instruct-gpt-reward-loss.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Reinforcement learning(RL)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;PPO&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/gpt/instruct-gpt-rl-loss.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\beta$ 那項是 KL divergence&lt;/li&gt;
&lt;li&gt;$\gamma$ 那項是不想要讓這 model 太專注在微調的任務，而失去原本在其他 NLP 任務也表現很好的功能。
&lt;ul&gt;
&lt;li&gt;$D_{pretrain}$ 是 pretraining distribution&lt;/li&gt;
&lt;li&gt;如果 $\gamma$ 為 0，在該實驗中叫做 PPO，否則，稱為 PPO-ptx&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;result&#34;&gt;Result&lt;/h1&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/gpt/instruct-gpt-result.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Bayesian Optimization</title>
        <link>https://roykesydon.github.io/Blog/p/bayesian-optimization/</link>
        <pubDate>Thu, 26 Jan 2023 01:36:53 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/bayesian-optimization/</guid>
        <description>&lt;h1 id=&#34;介紹&#34;&gt;介紹&lt;/h1&gt;
&lt;p&gt;一種用於自動化找超參數的方法，用在採樣昂貴而且是黑盒子的情況&lt;/p&gt;
&lt;h1 id=&#34;流程&#34;&gt;流程&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;取樣一些資料點&lt;/li&gt;
&lt;li&gt;生出一個 Surrogate Model(可採用 Gaussian Process)&lt;/li&gt;
&lt;li&gt;反覆做以下事情
&lt;ul&gt;
&lt;li&gt;用 Acquisition Function 挑選下一個要採樣的點&lt;/li&gt;
&lt;li&gt;重新評估 Surrogate Model&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;gaussian-process&#34;&gt;Gaussian Process&lt;/h2&gt;
&lt;p&gt;最終的 prediction 是一個 distribution 而不是單一個數字
生成方法需借助 kernel function，常用 RBF(Radial Basis Function)&lt;/p&gt;
&lt;p&gt;$K(x, x^{&amp;rsquo;}|\tau)=\sigma^2exp(-\frac{1}{2}(\frac{x-x^{&amp;rsquo;}}{l})^2)$&lt;/p&gt;
&lt;p&gt;$\sigma$ 和 $l$ 是兩個可以調整的超參數&lt;/p&gt;
&lt;h2 id=&#34;acquisition-function&#34;&gt;Acquisition Function&lt;/h2&gt;
&lt;p&gt;可用超參數來調節 exploitation 和 exploitation&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;UCB(Upper confidence bound)&lt;/li&gt;
&lt;li&gt;PI(probability of improvement)&lt;/li&gt;
&lt;li&gt;EI(Expected improvement)&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>IO Redirection</title>
        <link>https://roykesydon.github.io/Blog/p/io-redirection/</link>
        <pubDate>Sat, 21 Jan 2023 02:20:43 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/io-redirection/</guid>
        <description>&lt;h1 id=&#34;ppfdt&#34;&gt;PPFDT&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;per process file descriptor table&lt;/li&gt;
&lt;li&gt;每個 process 都有&lt;/li&gt;
&lt;li&gt;存放 file descriptors
&lt;ul&gt;
&lt;li&gt;file descriptors 是一個唯一的整數，用來識別作業系統上的 open file&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;0, 1, 2 是 Standard input / ouput / error&lt;/li&gt;
&lt;li&gt;大小受限於 OPEN_MAX，亦即能同時間能開的最多檔案數&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;redirection&#34;&gt;Redirection&lt;/h1&gt;
&lt;h2 id=&#34;input-redirection&#34;&gt;Input redirection&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;$ wc &amp;lt; /etc/passwd
&lt;ul&gt;
&lt;li&gt;把 wc 的 PPFDT 的 stdin 改成 /etc/passwd&lt;/li&gt;
&lt;li&gt;如果是 $ wc /etc/passwd，則是在 PPFDT 追加 /etc/passwd&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ouput-redirection&#34;&gt;Ouput redirection&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;$ wc &amp;gt; f1
&lt;ul&gt;
&lt;li&gt;把 wc 的 PPFDT 的 stdout 改成 f1&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;input--output-redirection&#34;&gt;Input &amp;amp; output redirection&lt;/h2&gt;
&lt;p&gt;兩個可以同時用&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$ cat &amp;lt; f1 &amp;gt; f2&lt;/li&gt;
&lt;li&gt;&amp;gt;&amp;gt; 可以 append&lt;/li&gt;
&lt;li&gt;$ &amp;lt; f1 cat &amp;gt; f2
&lt;ul&gt;
&lt;li&gt;可以亂換位置&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;error-redirection&#34;&gt;Error redirection&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;$ find / -name f1 2&amp;gt; error 1&amp;gt; outputs
&lt;ul&gt;
&lt;li&gt;這樣就會把那些 Permission denied 的給到 errors，成功的給到 outputs&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2&amp;gt;/dev/null
&lt;ul&gt;
&lt;li&gt;/dev/null 會把丟進來的東西都丟棄&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;copy-descripter&#34;&gt;Copy Descripter&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;這兩者等價
&lt;ul&gt;
&lt;li&gt;$ cat f1 1&amp;gt;op_err 2&amp;gt;op_err&lt;/li&gt;
&lt;li&gt;$ cat f1 1&amp;gt;op_err 2&amp;gt;&amp;amp;1
&lt;ul&gt;
&lt;li&gt;make 2 a copy of 1&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Process Management</title>
        <link>https://roykesydon.github.io/Blog/p/process-management/</link>
        <pubDate>Sat, 21 Jan 2023 00:08:25 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/process-management/</guid>
        <description>&lt;h1 id=&#34;compile-c&#34;&gt;Compile C&lt;/h1&gt;
&lt;h2 id=&#34;4-steps&#34;&gt;4-steps&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;pre-processing&lt;/li&gt;
&lt;li&gt;compilation&lt;/li&gt;
&lt;li&gt;assembly&lt;/li&gt;
&lt;li&gt;linking&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;types-of-object-files&#34;&gt;Types of Object Files&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Executable object file&lt;/li&gt;
&lt;li&gt;Relocatable object file&lt;/li&gt;
&lt;li&gt;Shared object file&lt;/li&gt;
&lt;li&gt;Core file&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;formats-of-object-files&#34;&gt;Formats of Object Files&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;a.out
&lt;ul&gt;
&lt;li&gt;initial version of UNIX&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;COFF
&lt;ul&gt;
&lt;li&gt;SVR3 UNIX&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;PE
&lt;ul&gt;
&lt;li&gt;Win. NT&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;ELF
&lt;ul&gt;
&lt;li&gt;SVR4 Linux&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;elf-format-of-a-program&#34;&gt;ELF format of a program&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;ELF Header&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Program Header Table&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;.text&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;.rodata&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;.data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;.bss&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;.symtab&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;.rel.text&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;.rel.data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;.debug&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;.line&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;.strtab&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Section Header Table&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;可參考: &lt;a class=&#34;link&#34; href=&#34;http://ccckmit.wikidot.com/lk:elf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;http://ccckmit.wikidot.com/lk:elf&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;process&#34;&gt;Process&lt;/h1&gt;
&lt;p&gt;Instance of a program running on a computer&lt;/p&gt;
&lt;h2 id=&#34;process-control-block&#34;&gt;Process Control Block&lt;/h2&gt;
&lt;p&gt;task_struct&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Process Identification
&lt;ul&gt;
&lt;li&gt;PID, PPID, SID, UID, EUID..&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Process State Information&lt;/li&gt;
&lt;li&gt;Process Control Information&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>Shell</title>
        <link>https://roykesydon.github.io/Blog/p/shell/</link>
        <pubDate>Thu, 19 Jan 2023 23:00:02 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/shell/</guid>
        <description>&lt;h1 id=&#34;features&#34;&gt;Features&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Process control&lt;/li&gt;
&lt;li&gt;Variables&lt;/li&gt;
&lt;li&gt;Flow control&lt;/li&gt;
&lt;li&gt;Functions&lt;/li&gt;
&lt;li&gt;File &amp;amp; cmd name completions&lt;/li&gt;
&lt;li&gt;Cmd line editng&lt;/li&gt;
&lt;li&gt;Cmd history&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;command-mode&#34;&gt;Command Mode&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Interactive&lt;/li&gt;
&lt;li&gt;Non- Interactive&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;command-type&#34;&gt;Command Type&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;internal / Builtin command&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;指令的程式碼是 shell 的一部分
&lt;ul&gt;
&lt;li&gt;e.g., cd, exit&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;不會產生 child process&lt;/li&gt;
&lt;li&gt;有些 internal command，比如 echo, pwd，會 internal 和 external 都有實作&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;external command&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;指令的程式碼在硬碟上的某個 binary file
&lt;ul&gt;
&lt;li&gt;e.g., clear, ls&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;會產生 child process&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;common-commands&#34;&gt;Common Commands&lt;/h1&gt;
&lt;p&gt;比較實用或常用的&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;grep&lt;/p&gt;
&lt;p&gt;找字詞&lt;/p&gt;
&lt;p&gt;grep &amp;lt;string/pattern&amp;gt; &lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;-i 大小寫不敏感&lt;/li&gt;
&lt;li&gt;-v 不包含關鍵字的&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;cut
找 column&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;-f 找哪些 column&lt;/li&gt;
&lt;li&gt;-d 分隔符是什麼&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;比較兩個檔案&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;comm&lt;/p&gt;
&lt;p&gt;顯示 file1 獨有的列、 file2 獨有的列、file1 和 file2 共有的列&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;cmp, diff&lt;/p&gt;
&lt;p&gt;回傳不一樣的列資訊&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;unset&lt;/p&gt;
&lt;p&gt;把指定的變數移除掉&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;tee&lt;/p&gt;
&lt;p&gt;吃 stdin 輸出到 stdout 和其他檔案&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;less&lt;/p&gt;
&lt;p&gt;讀檔案用&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;expansions&#34;&gt;Expansions&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;White space&lt;/li&gt;
&lt;li&gt;Control Operators
&lt;ul&gt;
&lt;li&gt;;
&lt;ul&gt;
&lt;li&gt;讓指令接著執行&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&amp;amp;
&lt;ul&gt;
&lt;li&gt;放在結尾，讓指令在背景執行&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&amp;amp;&amp;amp;
&lt;ul&gt;
&lt;li&gt;logical AND&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;||
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;logical OR&lt;/p&gt;
&lt;p&gt;前面失敗才會跑後面&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;#
&lt;ul&gt;
&lt;li&gt;註解用&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;\
&lt;ul&gt;
&lt;li&gt;escape special characters&lt;/li&gt;
&lt;li&gt;放結尾好換行繼續輸入&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;$?
&lt;ul&gt;
&lt;li&gt;一個特別的變數，有上個指令的 exit code&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Shell variables
&lt;ul&gt;
&lt;li&gt;User defined&lt;/li&gt;
&lt;li&gt;Env var&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Shell history&lt;/li&gt;
&lt;li&gt;File Globing
&lt;ul&gt;
&lt;li&gt;*, ?, [], -, !&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>GPT 三部曲</title>
        <link>https://roykesydon.github.io/Blog/p/gpt-%E4%B8%89%E9%83%A8%E6%9B%B2/</link>
        <pubDate>Thu, 19 Jan 2023 01:50:07 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/gpt-%E4%B8%89%E9%83%A8%E6%9B%B2/</guid>
        <description>&lt;p&gt;GPT 本質上就是 Transformer 的 decoder&lt;/p&gt;
&lt;h1 id=&#34;gpt-1&#34;&gt;GPT-1&lt;/h1&gt;
&lt;p&gt;paper: &lt;a class=&#34;link&#34; href=&#34;https://www.semanticscholar.org/paper/Improving-Language-Understanding-by-Generative-Radford-Narasimhan/cd18800a0fe0b668a1cc19f2ec95b5003d0a5035&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Improving Language Understanding by Generative Pre-Training&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;用 semi-supervised，後來被歸為 self-supervised&lt;/p&gt;
&lt;h2 id=&#34;unsupervised-pre-training&#34;&gt;Unsupervised pre-training&lt;/h2&gt;
&lt;p&gt;$L_1(U)=\sum_i logP(u_i|u_{i-k},&amp;hellip;,u_{i-1};\theta)$&lt;/p&gt;
&lt;p&gt;$U= \{ u_1,&amp;hellip;,u_n \}$&lt;/p&gt;
&lt;p&gt;$U$ 是一系列未標記的文本 token&lt;/p&gt;
&lt;p&gt;$k$ 是窗口大小&lt;/p&gt;
&lt;h3 id=&#34;模型大致架構&#34;&gt;模型大致架構&lt;/h3&gt;
&lt;p&gt;$h_0=UW_e+W_p$&lt;/p&gt;
&lt;p&gt;$h_1=transformer \_ block(h_{i-1})\forall i \in[1,n]$&lt;/p&gt;
&lt;p&gt;$P(u)=softmax(h_nW^T_e)$&lt;/p&gt;
&lt;p&gt;$U=\{u_{-k},&amp;hellip;,u_{-1}\}$&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;supervised-fine-tuning&#34;&gt;Supervised fine-tuning&lt;/h2&gt;
&lt;p&gt;$P(y|x^1,&amp;hellip;,x^m)=softmax(h^m_lW_y)$&lt;/p&gt;
&lt;p&gt;$L2(C)=\sum_{(x,y)}log P(y|x^1,&amp;hellip;,x^m)$&lt;/p&gt;
&lt;p&gt;$L_3(C)=L_2(C)+\lambda*L_1(C)$&lt;/p&gt;
&lt;p&gt;$C$ 是 labeled 的資料集，微調基本上就是在後面加上線性層&lt;/p&gt;
&lt;p&gt;作者最大化 likelihood 的時候是用 $L_3$ 而非單純的 $L_2$&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;微調應用範例&#34;&gt;微調應用範例&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/gpt/gpt-1-tasks.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;資料集&#34;&gt;資料集&lt;/h2&gt;
&lt;p&gt;用 BooksCorpus 訓練出來的&lt;/p&gt;
&lt;p&gt;有超過 7000 本未出版的書&lt;/p&gt;
&lt;h2 id=&#34;模型結構&#34;&gt;模型結構&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;12 層 transformer 的 decoder&lt;/li&gt;
&lt;li&gt;768 維 word embedding&lt;/li&gt;
&lt;li&gt;12 個 attention heads&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;和-bert-base-比較&#34;&gt;和 BERT BASE 比較&lt;/h2&gt;
&lt;p&gt;BERT 論文比較晚出，但 BASE 的模型架構和 GPT 有相似之處，&lt;/p&gt;
&lt;p&gt;BASE 是 12 層的 decoder，word embedding 和 attention head 的維度或數量和 GPT-1 相同&lt;/p&gt;
&lt;h1 id=&#34;gpt-2&#34;&gt;GPT-2&lt;/h1&gt;
&lt;p&gt;paper: &lt;a class=&#34;link&#34; href=&#34;https://paperswithcode.com/paper/language-models-are-unsupervised-multitask&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Language Models are Unsupervised Multitask Learner&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;GPT-2 除了用更大的的模型和更大的資料集，把重點放在 zero-shot 上，雖然在 GPT-1 的論文就有提過 zero-shot&lt;/p&gt;
&lt;h2 id=&#34;資料集-1&#34;&gt;資料集&lt;/h2&gt;
&lt;p&gt;這次做了一個叫做 WebText 的資料集，有百萬級別的網頁&lt;/p&gt;
&lt;h3 id=&#34;common-crawl&#34;&gt;Common Crawl&lt;/h3&gt;
&lt;p&gt;大型爬蟲專案，有大量網頁資料，但充斥了垃圾訊息&lt;/p&gt;
&lt;h3 id=&#34;webtext&#34;&gt;WebText&lt;/h3&gt;
&lt;p&gt;WebText 的資料來源是 reddit 上的外部連結，只要有至少三個 karma，就會被採納，由此取得品質較好的網頁資料。透過這種方法，取得了 4500 萬個連結。並用Dragnet (Peters &amp;amp; Lecocq, 2013) and Newspaper content extractors 把文字訊息從 HTML 中抓出來&lt;/p&gt;
&lt;h2 id=&#34;架構&#34;&gt;架構&lt;/h2&gt;
&lt;p&gt;和原本差不多，變成有 1.5B 參數的 Transformer decoder&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/gpt/gpt-2-models.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;zero-shot&#34;&gt;zero-shot&lt;/h2&gt;
&lt;p&gt;不需要下游任務的標記資料&lt;/p&gt;
&lt;p&gt;改把任務輸入進模型&lt;/p&gt;
&lt;h3 id=&#34;目前問題&#34;&gt;目前問題&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;現在的模型泛化能力不太好&lt;/li&gt;
&lt;li&gt;Multitask learning
在 NLP 上不太常用，NLP 現在主流還是在預訓練模型上做微調以應對下游任務
&lt;ul&gt;
&lt;li&gt;對每個下游任務都得重新訓練模型&lt;/li&gt;
&lt;li&gt;得蒐集 labeled 資料&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;結果&#34;&gt;結果&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/gpt/gpt-2-result-1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/gpt/gpt-2-result-2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h1 id=&#34;gpt-3&#34;&gt;GPT-3&lt;/h1&gt;
&lt;p&gt;paper: &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2005.14165&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Language Models are Few-Shot Learners&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;摘要&#34;&gt;摘要&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;有 175B 的參數，由於模型極大，要在子任務微調會成本很大，所以不做任何梯度更新&lt;/li&gt;
&lt;li&gt;在很多 NLP 任務有傑出的成果&lt;/li&gt;
&lt;li&gt;可以生出人類難以區分的新聞文章&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;目前有的問題&#34;&gt;目前有的問題&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;要在子任務微調，需要資料集&lt;/li&gt;
&lt;li&gt;微調後在有些子任務上表現好不代表你預訓練模型一定泛化能力高&lt;/li&gt;
&lt;li&gt;人類不需要大量 labeled 資料去完成小任務&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;評估方式&#34;&gt;評估方式&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;分為三種，few / one / zero-shot learning&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;架構-1&#34;&gt;架構&lt;/h2&gt;
&lt;p&gt;基本上 GPT-3 和 GPT-2 架構一樣&lt;/p&gt;
&lt;h3 id=&#34;相同&#34;&gt;相同&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;modified initialization&lt;/li&gt;
&lt;li&gt;pre-normalization&lt;/li&gt;
&lt;li&gt;reversible tokenization described therein&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;不同&#34;&gt;不同&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;把 Sparse Transformer 的一些修改拿過來用&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/gpt/gpt-3-models.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;GPT-3 Small 是 GPT-1 的大小
GPT-3 Medium 是 BERT Large 的大小
GPT-3 XL 和 GPT-2 相近，比較淺也比較寬&lt;/p&gt;
&lt;h4 id=&#34;batch-size-大小&#34;&gt;Batch Size 大小&lt;/h4&gt;
&lt;p&gt;模型小的時候需要小一點，透過這種額外的 noise 來避免 overfitting(不確定是不是猜想)&lt;/p&gt;
&lt;h2 id=&#34;資料集-2&#34;&gt;資料集&lt;/h2&gt;
&lt;h3 id=&#34;common-crawl-1&#34;&gt;Common Crawl&lt;/h3&gt;
&lt;p&gt;架構比 GPT-2 大很多，所以回頭考慮這個資料集&lt;/p&gt;
&lt;h4 id=&#34;三步驟&#34;&gt;三步驟&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;先過濾，透過 reddit 那個高品質的資料集，來訓練一個模型分類高品質和低品質的網頁。&lt;/li&gt;
&lt;li&gt;透過 LSH 演算法把相似的文本過濾掉&lt;/li&gt;
&lt;li&gt;把一些已知高品質的資料集也加進來&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/gpt/gpt-3-dataset.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;這是一個 Batch 裡有 60% 來自 Common Crawl(filtered) 的意思
Wikipedia 雖然總量比較少，但也有 3% 的採樣率&lt;/p&gt;
&lt;h2 id=&#34;結果-1&#34;&gt;結果&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/gpt/gpt-3-result-1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;計算量指數增長，loss 卻是線性的往下降&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/gpt/gpt-3-result-2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;paper 裡有很多任務的實驗結果，這邊就不附上了&lt;/p&gt;
&lt;h2 id=&#34;limitations&#34;&gt;Limitations&lt;/h2&gt;
&lt;p&gt;在文本生成上還是比較弱，生很長的東西，可能會重複自己說過的話、失去連貫性、自相矛盾等等&lt;/p&gt;
&lt;p&gt;在有些雙向性的任務上可能表現更差&lt;/p&gt;
&lt;h2 id=&#34;影響&#34;&gt;影響&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;可能被用來散布不實消息、垃圾郵件等等&lt;/li&gt;
&lt;li&gt;偏見&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;結論&#34;&gt;結論&lt;/h2&gt;
&lt;p&gt;在很多 NLP 任務可以做到接近 SOTA 微調模型的成果&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Linux 瑣事</title>
        <link>https://roykesydon.github.io/Blog/p/linux-%E7%91%A3%E4%BA%8B/</link>
        <pubDate>Thu, 19 Jan 2023 01:50:07 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/linux-%E7%91%A3%E4%BA%8B/</guid>
        <description>&lt;h1 id=&#34;vm&#34;&gt;VM&lt;/h1&gt;
&lt;p&gt;A software implementation of a machine&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;System VM
&lt;ul&gt;
&lt;li&gt;提供可以執行 GuestOS 的 complete system platform&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Process VM
&lt;ul&gt;
&lt;li&gt;像一個一般的 app 一樣在 hostOS 跑，支援單一個 process&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;hypervisor&#34;&gt;Hypervisor&lt;/h2&gt;
&lt;p&gt;又稱虛擬機器監視器（英語：virtual machine monitor，縮寫為VMM）
用來管理 VM&lt;/p&gt;
&lt;p&gt;允許多個 GuestOS 跑在 host computer&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Type-1&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;bare-metal hypervisors&lt;/li&gt;
&lt;li&gt;直接在硬體上執行&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Type-2&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;hosted hypervisors&lt;/li&gt;
&lt;li&gt;在 hostOS 上執行&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;directories&#34;&gt;directories&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Binary&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;e.g., bin, sbin, lib, opt
&lt;ul&gt;
&lt;li&gt;bin: 有關 user 的指令&lt;/li&gt;
&lt;li&gt;sbin: 管理員會用的指令&lt;/li&gt;
&lt;li&gt;opt: optional software，多數機器中這是空的&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Configuration&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;e.g., boot, etc,&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Data&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;e.g., home, root, srv, media, mnt, temp&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In memory
字面上的意思，不在 hard disk，在 memory&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;e.g., dev, proc, sys&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;System Resources&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;e.g., usr&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Variable Data&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;e.g., var&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        
    </channel>
</rss>
