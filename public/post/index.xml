<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Posts on Roykesydon</title>
        <link>https://roykesydon.github.io/Blog/post/</link>
        <description>Recent content in Posts on Roykesydon</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <lastBuildDate>Fri, 16 Aug 2024 00:00:17 +0800</lastBuildDate><atom:link href="https://roykesydon.github.io/Blog/post/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>MongoDB 筆記</title>
        <link>https://roykesydon.github.io/Blog/p/mongodb-%E7%AD%86%E8%A8%98/</link>
        <pubDate>Fri, 16 Aug 2024 00:00:17 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/mongodb-%E7%AD%86%E8%A8%98/</guid>
        <description>&lt;h2 id=&#34;mongodb&#34;&gt;MongoDB&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;以 BSON (Binary JSON) 儲存資料&lt;/li&gt;
&lt;li&gt;composite index
&lt;ul&gt;
&lt;li&gt;prefix
&lt;ul&gt;
&lt;li&gt;如果有一個 index 是 (a, b)，那麼 (a) 也是有效的 index&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;explain
&lt;ul&gt;
&lt;li&gt;用來看 query 的 execution plan&lt;/li&gt;
&lt;li&gt;cursor
&lt;ul&gt;
&lt;li&gt;BasicCursor
&lt;ul&gt;
&lt;li&gt;會 scan 整個 collection，是個警訊&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;掃描的文件數量
&lt;ul&gt;
&lt;li&gt;nscanned
&lt;ul&gt;
&lt;li&gt;掃描的 index 數量&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;nscannedObjects
&lt;ul&gt;
&lt;li&gt;掃描的 document 數量&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;n
&lt;ul&gt;
&lt;li&gt;回傳的 document 數量&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;nscanned &amp;gt;= nscannedObjects &amp;gt;= n&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;scanAndOrder
&lt;ul&gt;
&lt;li&gt;是否需要把文件都放在 memory 並排序&lt;/li&gt;
&lt;li&gt;還會一次性回傳資料&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;hint
&lt;ul&gt;
&lt;li&gt;強制使用某個 index&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;optimizer 挑選索引
&lt;ul&gt;
&lt;li&gt;第一階段 - 挑選最佳索引
&lt;ul&gt;
&lt;li&gt;最佳索引
&lt;ul&gt;
&lt;li&gt;包含所有的 filter 和 sort 的欄位&lt;/li&gt;
&lt;li&gt;range filter 和 sort 的欄位必須在 equality filter 的後面
&lt;ul&gt;
&lt;li&gt;sort 的欄位必須在 range filter 的後面&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;如果有多個最佳索引就會隨便選一個&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;第二階段 - 透過實驗挑選索引
&lt;ul&gt;
&lt;li&gt;沒有最佳索引就會實驗判斷要選哪個，看看誰先找到指定數量的文件&lt;/li&gt;
&lt;li&gt;換句話說，如果有多個索引，optimizer 會選 nscanned 最小的&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;MMAPv1
&lt;ul&gt;
&lt;li&gt;Mongo 一開始用的 storage engine&lt;/li&gt;
&lt;li&gt;_id 直接對應到 diskloc，也就是 disk 的偏移量
&lt;ul&gt;
&lt;li&gt;查找速度驚人，但是更新就要維護偏移量很費時&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;採用 database-level lock，Mongo 後來也只更新成 collection-level lock&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;WiredTiger
&lt;ul&gt;
&lt;li&gt;MongoDB 收購的 storage engine&lt;/li&gt;
&lt;li&gt;Document-level locking&lt;/li&gt;
&lt;li&gt;可以做到 compression&lt;/li&gt;
&lt;li&gt;5.2 之前
&lt;ul&gt;
&lt;li&gt;_id 會先被用來尋找 recordid，再用 recordid 去獲取 document&lt;/li&gt;
&lt;li&gt;recordid 是 clustered index&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;5.3
&lt;ul&gt;
&lt;li&gt;_id 變成 clustered index&lt;/li&gt;
&lt;li&gt;之前 recordid 只有 64 位，但現在 _id 作為 primary key 有 12 bytes
&lt;ul&gt;
&lt;li&gt;對 secondary index 造成更大的負擔&lt;/li&gt;
&lt;li&gt;Mongo 想達成跨機器和 shard 的唯一性&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>System Design</title>
        <link>https://roykesydon.github.io/Blog/p/system-design/</link>
        <pubDate>Sat, 03 Aug 2024 00:08:46 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/system-design/</guid>
        <description>&lt;h2 id=&#34;estimation&#34;&gt;Estimation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;要評估的指標
&lt;ul&gt;
&lt;li&gt;latency&lt;/li&gt;
&lt;li&gt;throughput&lt;/li&gt;
&lt;li&gt;capacity&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Database 估計
&lt;ul&gt;
&lt;li&gt;沒特別指定的話，可以預估 single relational database 可以處理 read &amp;amp; write 10K per second&lt;/li&gt;
&lt;li&gt;single relational database 的容量可以抓 3 TB&lt;/li&gt;
&lt;li&gt;redis 可以抓 100K，但是受限於 memory，可能抓 30GB&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;可以問的問題類型
&lt;ul&gt;
&lt;li&gt;總共有多少用戶？&lt;/li&gt;
&lt;li&gt;有多少活躍用戶？&lt;/li&gt;
&lt;li&gt;每個用戶平均每天使用多久？&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;network&#34;&gt;Network&lt;/h2&gt;
&lt;h3 id=&#34;load-balancer&#34;&gt;Load Balancer&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;type
&lt;ul&gt;
&lt;li&gt;application load balancer (ALB)
&lt;ul&gt;
&lt;li&gt;OSI layer 7 (Application layer)&lt;/li&gt;
&lt;li&gt;可以根據 request header, URL, query string 來做 routing&lt;/li&gt;
&lt;li&gt;可以 validate / terminate SSL&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;network load balancer (NLB)
&lt;ul&gt;
&lt;li&gt;OSI layer 4 (Transport layer)&lt;/li&gt;
&lt;li&gt;可以根據 protocol (TCP, UDP, IP..), destination port etc 來做 routing&lt;/li&gt;
&lt;li&gt;一般來說預設會 pass through SSL&lt;/li&gt;
&lt;li&gt;比較適合應付高流量&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;strategy
&lt;ul&gt;
&lt;li&gt;round robin
&lt;ul&gt;
&lt;li&gt;輪流&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;least connection&lt;/li&gt;
&lt;li&gt;resource-based
&lt;ul&gt;
&lt;li&gt;考慮每個 instance 的資源使用情況&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;weighted variants of the above
&lt;ul&gt;
&lt;li&gt;可以把上面說的各種情況多加入 weight 的考量&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;random&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;優點
&lt;ul&gt;
&lt;li&gt;resilience
&lt;ul&gt;
&lt;li&gt;可以關注到某個 instance down 了，自動把 request 轉到其他 instance&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;scalability
&lt;ul&gt;
&lt;li&gt;後面的 instance 可以 horizontal scale&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;和 API Gateway 的差異
&lt;ul&gt;
&lt;li&gt;API Gateway 除了 load balancing 會有更多的功能，例如 rate limiting, authentication, authorization, request validation, caching, logging etc&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;cdn-content-delivery-network&#34;&gt;CDN (Content Delivery Network)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;把靜態資源放到離使用者地理上比較近的地方，加速存取速度
&lt;ul&gt;
&lt;li&gt;html, css, js, image&amp;hellip;&lt;/li&gt;
&lt;li&gt;這些資料不該頻繁改變&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;本質上是靜態資源的 cache&lt;/li&gt;
&lt;li&gt;types
&lt;ul&gt;
&lt;li&gt;push
&lt;ul&gt;
&lt;li&gt;把新的資料推到 CDN&lt;/li&gt;
&lt;li&gt;如果靜態資源很多，開銷會很大&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;pull
&lt;ul&gt;
&lt;li&gt;lazy&lt;/li&gt;
&lt;li&gt;當有 request 進來時，且 CDN 沒有該資源，才會去 origin server 拉資源&lt;/li&gt;
&lt;li&gt;第一個 user 會比較慢&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;maintain-consistency&#34;&gt;Maintain consistency&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;確保 unique
&lt;ul&gt;
&lt;li&gt;bloom filter
&lt;ul&gt;
&lt;li&gt;因為存在 service 的 memory，有最高的 throughput，但是可能會有 false positive&lt;/li&gt;
&lt;li&gt;不好讓多個 service 共用&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;queue--messaging&#34;&gt;Queue / Messaging&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;如果系統是 synchronous，可能會有 scalability 的問題
&lt;ul&gt;
&lt;li&gt;會被最慢的 component 所限制 (ex: payment service)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;role
&lt;ul&gt;
&lt;li&gt;producer
&lt;ul&gt;
&lt;li&gt;產生 message&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;consumer
&lt;ul&gt;
&lt;li&gt;處理 message&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;優點
&lt;ul&gt;
&lt;li&gt;buffer&lt;/li&gt;
&lt;li&gt;應對 request spike&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;缺點
&lt;ul&gt;
&lt;li&gt;現在無法知道 message 被處理的情況，sychronous 可以直接得知成功與否&lt;/li&gt;
&lt;li&gt;增加 latency&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;model
&lt;ul&gt;
&lt;li&gt;message queue
&lt;ul&gt;
&lt;li&gt;讓 queue 分配 message 給某個 consumer&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;publisher / subscriber (pub/sub)
&lt;ul&gt;
&lt;li&gt;可能會有某個 event 想被 publish 給多個 consumer (subscribers)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;protocol--sendreceive-data&#34;&gt;Protocol &amp;amp; Send/Receive data&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;TCP&lt;/li&gt;
&lt;li&gt;UDP&lt;/li&gt;
&lt;li&gt;http&lt;/li&gt;
&lt;li&gt;websocket
&lt;ul&gt;
&lt;li&gt;duplex (two-way) communication&lt;/li&gt;
&lt;li&gt;只會建立一次 TCP connection&lt;/li&gt;
&lt;li&gt;load balancer 可以會遇到問題&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;long polling
&lt;ul&gt;
&lt;li&gt;client 送 request 給 server，server 不會立刻 close connection，而是等待有新資料或 timeout 才回應&lt;/li&gt;
&lt;li&gt;某些不能用 websocket 的情況下，可以用 long polling 來模擬&lt;/li&gt;
&lt;li&gt;但是在一些框架或語言可能不好實作&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;gRPC
&lt;ul&gt;
&lt;li&gt;RPC
&lt;ul&gt;
&lt;li&gt;remote procedure call&lt;/li&gt;
&lt;li&gt;把一些 service 包裝成像 local function 一樣，就可以像調用本地函式一樣使用 remote 的服務&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;google 開發的 RPC 框架&lt;/li&gt;
&lt;li&gt;用 protobuf 作為 IDL (Interface Definition Language)
&lt;ul&gt;
&lt;li&gt;binary protocol
&lt;ul&gt;
&lt;li&gt;非 readable，需要 encode / decode&lt;/li&gt;
&lt;li&gt;但比 json 小&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;.proto file
&lt;ul&gt;
&lt;li&gt;定義 message 的格式&lt;/li&gt;
&lt;li&gt;描述了 interface 長怎樣&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;protoc
&lt;ul&gt;
&lt;li&gt;用來 compile .proto file，根據指定的程式語言，產生 client / server code
&lt;ul&gt;
&lt;li&gt;server 再實作 interface&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;用 http/2 來傳輸&lt;/li&gt;
&lt;li&gt;不能用在 browser&lt;/li&gt;
&lt;li&gt;適合用在內部服務之間的溝通&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;GraphQL&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;流程&#34;&gt;流程&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;User perspective
&lt;ul&gt;
&lt;li&gt;描述身為 user 期待看到什麼東西&lt;/li&gt;
&lt;li&gt;這裡可以先簡單介紹這個 app 的大概邏輯，之後 marketplace 再針對不同 role 探討資料和使用情境&lt;/li&gt;
&lt;li&gt;也可以詢問使用的平台&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Marketplace
&lt;ul&gt;
&lt;li&gt;詢問要支援的用戶數量，以及活躍用戶數量&lt;/li&gt;
&lt;li&gt;如果有多種用戶，也要分開討論
&lt;ul&gt;
&lt;li&gt;ex: 叫車服務會有司機和乘客&lt;/li&gt;
&lt;li&gt;有更多角色後，可以開始根據角色討論他們的 perspective&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;取得一些數字
&lt;ul&gt;
&lt;li&gt;考慮 sotrage 以及 throughput&lt;/li&gt;
&lt;li&gt;叫車服務範例
&lt;ul&gt;
&lt;li&gt;乘客總數量、活躍乘客數、每月乘客需求趟數&lt;/li&gt;
&lt;li&gt;司機總數量、活躍司機數、單趟平均時間&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;throuput
&lt;ul&gt;
&lt;li&gt;活躍用戶&lt;/li&gt;
&lt;li&gt;refresh rate&lt;/li&gt;
&lt;li&gt;每個 user 平均打開 app 的次數&lt;/li&gt;
&lt;li&gt;平均打開 app 會用多久&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Rough design
&lt;ul&gt;
&lt;li&gt;探討資料的傳遞
&lt;ul&gt;
&lt;li&gt;根據不同 role 去講他們應該傳送什麼資料，用什麼協定，request 的頻率 (request per second)
&lt;ul&gt;
&lt;li&gt;討論的時候可以用 average，但是會有 peak time，可以考慮 X2, X4, X10&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;探討資料的儲存
&lt;ul&gt;
&lt;li&gt;要準備一些前提，比如假設單一資料庫每秒可以 insert 5K 筆資料&lt;/li&gt;
&lt;li&gt;可以討論不同的 sharding
&lt;ul&gt;
&lt;li&gt;考慮怎樣存可以讓大小減少&lt;/li&gt;
&lt;li&gt;評估這樣分是否可能導致 sharding uneven&lt;/li&gt;
&lt;li&gt;怎樣的切法可以讓 query 盡量不要跨 shard&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;每個階段也可以探討 throughput&lt;/li&gt;
&lt;li&gt;開始根據情境設計不同的 service 來表達他們的交互&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tips&#34;&gt;Tips&lt;/h2&gt;
&lt;h3 id=&#34;查找&#34;&gt;查找&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;能不能用地理資訊來做 hashing&lt;/li&gt;
&lt;li&gt;能不能用 geo index&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;工具--技術&#34;&gt;工具 &amp;amp; 技術&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;headless browser
&lt;ul&gt;
&lt;li&gt;沒有 user interface 的 browser&lt;/li&gt;
&lt;li&gt;但是依然有 rendering engine 和 js interpreter。可以用來得到最終的 html&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Cyclic redundancy check (CRC)
&lt;ul&gt;
&lt;li&gt;一般用在檢查封包是否有錯誤，但是我們也可以用來檢查某個檔案是否有被修改，好做 sync&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;CQRS (Command Query Responsibility Segregation)
&lt;ul&gt;
&lt;li&gt;把 read 和 write 分開&lt;/li&gt;
&lt;li&gt;一個 storage 針對 read 做 optimize，另一個 storage 針對 write 做 optimize&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;unique-id&#34;&gt;Unique ID&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;UUID 是 random 且 human-readable（不會有相近的 char，比如 0 和 O）
&lt;ul&gt;
&lt;li&gt;但是太長&lt;/li&gt;
&lt;li&gt;可以用不同的 encoding 壓縮長度
&lt;ul&gt;
&lt;li&gt;因為 UUID 用的 charactor 是 0-9, a-f，所以可以用有更多種 charactor 的 encoding 來壓縮&lt;/li&gt;
&lt;li&gt;BASE62
&lt;ul&gt;
&lt;li&gt;包含 0-9, a-z, A-Z&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;BASE58
&lt;ul&gt;
&lt;li&gt;BASE62 但不包含容易混淆的 0, O, I, l&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;BASE64
&lt;ul&gt;
&lt;li&gt;BASE62 但多了 +, /&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;other&#34;&gt;Other&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;每個 Phase 可以多和 interviewer 討論，確認走在正確的方向上&lt;/li&gt;
&lt;li&gt;面對面試官給的數字可以嘗試為了好算向上抓一些&lt;/li&gt;
&lt;li&gt;延遲任務
&lt;ul&gt;
&lt;li&gt;如果遇到因為某些原因需要晚點才能做某個任務，可以用 queue 來處理&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Cache 除了用專門的 cache database 做，Server 自身也可以用 memory 來 cache&lt;/li&gt;
&lt;li&gt;對於先搶先贏的系統不一定要追求公平，只要達成目標即可&lt;/li&gt;
&lt;li&gt;對於搶票機制可以做 pre-populate，事先在 database 生好指定數量的票，這樣就可以只 lock 某個 row，不用 lock 整個 table&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Database ACID</title>
        <link>https://roykesydon.github.io/Blog/p/database-acid/</link>
        <pubDate>Sun, 21 Jul 2024 00:00:17 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/database-acid/</guid>
        <description>&lt;h2 id=&#34;transaction&#34;&gt;Transaction&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;一個或多個操作的集合&lt;/li&gt;
&lt;li&gt;一個 transaction 要不全部執行，要不全部不執行&lt;/li&gt;
&lt;li&gt;就算在程式中沒顯式的寫 transaction，資料庫也會自動幫你包 transaction&lt;/li&gt;
&lt;li&gt;lifespan
&lt;ul&gt;
&lt;li&gt;begin&lt;/li&gt;
&lt;li&gt;commit&lt;/li&gt;
&lt;li&gt;rollback&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;atomicity&#34;&gt;Atomicity&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;一個 transaction 要不全部執行，要不全部不執行&lt;/li&gt;
&lt;li&gt;在 commit 前不管因為任何理由失敗，都該 rollback&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;consistency&#34;&gt;Consistency&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;符合當初制定的規則 (ex: 設置的 foreign key 指向的資料一定要存在)
&lt;ul&gt;
&lt;li&gt;referential integrity
&lt;ul&gt;
&lt;li&gt;保證 primary key 和 foreign key 之間的關係&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Eventual consistency
&lt;ul&gt;
&lt;li&gt;最後一定會 consistent&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;isolation&#34;&gt;Isolation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;一個 transaction 的執行不應該影響其他 transaction&lt;/li&gt;
&lt;li&gt;read phenomena
&lt;ul&gt;
&lt;li&gt;dirty read
&lt;ul&gt;
&lt;li&gt;一個 transaction 讀到了另一個 transaction 已經寫了但還沒 commit 的資料。這個資料有可能被 commit 也有可能被 rollback&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;non-repeatable read
&lt;ul&gt;
&lt;li&gt;一個 transaction 兩次讀取同個資料時，得到的資料不一樣因是因為有其他 transaction 更新了這個資料（已經 commit 了）&lt;/li&gt;
&lt;li&gt;和 dirty read 不同的是，這個資料是已經 commit 的&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;phantom read
&lt;ul&gt;
&lt;li&gt;也是第一次和第二次讀取的資料不一樣，第二次發現多了額外的資料，這次是因為有其他 transaction 寫入了新的資料（並且 commit 了）&lt;/li&gt;
&lt;li&gt;之所以要和 non-repeatable read 分開，是因為他這裡沒辦法簡單的靠鎖起來已經讀過的資料，因為你沒辦法鎖你本來看不到的資料&lt;/li&gt;
&lt;li&gt;系統設計遇到這問題可以考慮用 pre-populate 的方式，把所有可能的資料都先創好，就可以個別鎖住&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;lost update
&lt;ul&gt;
&lt;li&gt;我更新了某筆資料，但是在 commit 之前，有其他 transaction 也更新了這筆資料，並且 commit。我再去讀取這筆資料時，發現我更新的資料就被覆蓋了&lt;/li&gt;
&lt;li&gt;double booking problem
&lt;ul&gt;
&lt;li&gt;當兩個 transaction 同時搶更新同個資源就有可能遇到該問題&lt;/li&gt;
&lt;li&gt;example
&lt;ul&gt;
&lt;li&gt;兩個 transaction 都先 select 再 update&lt;/li&gt;
&lt;li&gt;他們兩個 select 都先看到有空位，然後一前一後更新，就會造成 double booking&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Isoaltion level
&lt;ul&gt;
&lt;li&gt;為了解決 read phenomena，資料庫提供了不同的隔離等級&lt;/li&gt;
&lt;li&gt;不會影響自身 transaction 前面所 write 的資料&lt;/li&gt;
&lt;li&gt;read uncommitted
&lt;ul&gt;
&lt;li&gt;No isolation&lt;/li&gt;
&lt;li&gt;可以看到其他 transaction 還沒 commit 的資料&lt;/li&gt;
&lt;li&gt;所有的 read phenomena 都有可能發生&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;read committed
&lt;ul&gt;
&lt;li&gt;只能看到其他 transaction commit 的資料&lt;/li&gt;
&lt;li&gt;許多資料庫的預設隔離等級&lt;/li&gt;
&lt;li&gt;除了 dirty read 之外，其他 read phenomena 都有可能發生&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;repeatable read
&lt;ul&gt;
&lt;li&gt;確保同一筆資料在同一個 transaction 中讀取時，結果是一樣的&lt;/li&gt;
&lt;li&gt;phantom read 還是有可能發生&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;snapshot
&lt;ul&gt;
&lt;li&gt;保證 transaction 得到的資料是一致的&lt;/li&gt;
&lt;li&gt;只會看到 transaction 開始時的 snapshot&lt;/li&gt;
&lt;li&gt;read phenomena 都不會發生&lt;/li&gt;
&lt;li&gt;好像不是所有資料庫都有這個隔離等級，也有些 repeatable read 就是用 snapshot 來實現的
&lt;ul&gt;
&lt;li&gt;比如 PostgreSQL 就是用 snapshot 來實現 repeatable read&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;但這不代表不會遇到問題，請參考 double booking problem&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;serializable
&lt;ul&gt;
&lt;li&gt;最高隔離等級&lt;/li&gt;
&lt;li&gt;保證所有 concurrent transaction 執行起來會和依序執行的效果一樣
&lt;ul&gt;
&lt;li&gt;如果 transaction 不會彼此影響，還是有可能會讓 transaction 並行執行&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;read phenomena 都不會發生&lt;/li&gt;
&lt;li&gt;和要求 exclusive lock 相比，有可能實現方法是遇到衝突會 fail&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;durability&#34;&gt;Durability&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;一旦 transaction 完成，資料應該要 persistent
&lt;ul&gt;
&lt;li&gt;完成的 transaction 會被記在 non-volatile storage&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;durability technique
&lt;ul&gt;
&lt;li&gt;Write ahead log (WAL)
&lt;ul&gt;
&lt;li&gt;先寫 log (寫你做了什麼操作，但不去真的改 disk 上對應的資料)，有空再修改
&lt;ul&gt;
&lt;li&gt;這樣一些修改就可以改在 memory，如果 crash 了，可以用 log 來 recover&lt;/li&gt;
&lt;li&gt;而且考量硬碟限制，如果你想修改的資料遠小於硬碟可寫的最小單位，會很浪費&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Asynchronous snapshot
&lt;ul&gt;
&lt;li&gt;在後台把 snapshot 寫到 disk&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Database 一般筆記</title>
        <link>https://roykesydon.github.io/Blog/p/database-%E4%B8%80%E8%88%AC%E7%AD%86%E8%A8%98/</link>
        <pubDate>Sun, 21 Jul 2024 00:00:17 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/database-%E4%B8%80%E8%88%AC%E7%AD%86%E8%A8%98/</guid>
        <description>&lt;h2 id=&#34;database-internal&#34;&gt;Database internal&lt;/h2&gt;
&lt;h3 id=&#34;storage-concept&#34;&gt;Storage concept&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Table&lt;/li&gt;
&lt;li&gt;Row_id
&lt;ul&gt;
&lt;li&gt;多數 database 會維護自己的 row_id&lt;/li&gt;
&lt;li&gt;也叫做 tuple id&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Page
&lt;ul&gt;
&lt;li&gt;多個 row 會被存在一個 page&lt;/li&gt;
&lt;li&gt;讀取不會只讀一個 row，而是一個或多個 page&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;IO
&lt;ul&gt;
&lt;li&gt;IO operation 指的是存取 disk 的操作&lt;/li&gt;
&lt;li&gt;一個 IO 可能會獲得多個 page，也可能只是用 cache 的資料&lt;/li&gt;
&lt;li&gt;Database 常常會利用 cache 來減少 IO
&lt;ul&gt;
&lt;li&gt;因此有些 query 很快，可能是因為有快取資料可用&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Heap data structure
&lt;ul&gt;
&lt;li&gt;儲存整個 table 的資料&lt;/li&gt;
&lt;li&gt;有些 database 會用 clustered index 來儲存，就不會有 heap&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Index data structure (b-tree)
&lt;ul&gt;
&lt;li&gt;一個有 pointer 來指向 heap 的資料結構
&lt;ul&gt;
&lt;li&gt;較流行的是 b-tree&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;可以對一個或多個 column 做 index&lt;/li&gt;
&lt;li&gt;index 可以告訴你要查詢的資料在哪個 page&lt;/li&gt;
&lt;li&gt;index 也會被儲存在 page&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;row-oriented-vs-column-oriented&#34;&gt;Row-oriented vs Column-oriented&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Row-oriented database (row store)
&lt;ul&gt;
&lt;li&gt;每個 row 接著下個 row 來儲存&lt;/li&gt;
&lt;li&gt;每次 IO 會獲得多個 row，每個都有所有的 column&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Col-oriented database (column store)
&lt;ul&gt;
&lt;li&gt;每個 column 接著下個 column 來儲存&lt;/li&gt;
&lt;li&gt;比較好壓縮，也比較好做 aggregation，所以在一些分析資料的軟體會用到&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;data-structure&#34;&gt;Data structure&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;B-tree
&lt;ul&gt;
&lt;li&gt;Balanced data structure for fast search&lt;/li&gt;
&lt;li&gt;限制
&lt;ul&gt;
&lt;li&gt;node 中的 element 同時存了 key 和 value&lt;/li&gt;
&lt;li&gt;range query 效率很差，因為要各別 random access&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;B+Tree
&lt;ul&gt;
&lt;li&gt;B-tree 的變形，和 B-tree 很像，不過 internal node 只存放 key，只有 leaf node 會存放 value
&lt;ul&gt;
&lt;li&gt;internal node 因為現在只需要儲存 key，element size 比較小，所以可以存放更多 element&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;leaf node 會用 linked list 串起來
&lt;ul&gt;
&lt;li&gt;適合 range query&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;通常一個 node 是一個 DBMS page&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;LSM-tree
&lt;ul&gt;
&lt;li&gt;Log-Structured Merge-Tree&lt;/li&gt;
&lt;li&gt;都加在尾端，不會覆蓋原本的資料，對 SSD 有利&lt;/li&gt;
&lt;li&gt;B-Tree 為了平衡會頻繁修改&lt;/li&gt;
&lt;li&gt;有利於 insert&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;fragmentation&#34;&gt;Fragmentation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;這裡是以 database 為出發點去看 fragmentation&lt;/li&gt;
&lt;li&gt;Internal fragmentation
&lt;ul&gt;
&lt;li&gt;一個 Page 中有很多空間是空的&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;External fragmentation
&lt;ul&gt;
&lt;li&gt;多個 Page 存放不是連續的。剩下的空間夠儲存新的資料，但是因為不連續，所以不能用&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;database-cursor&#34;&gt;Database cursor&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;當資料庫有很大的結果集時，不可能一次把所有資料用網路傳給 client，用戶也沒有 memory 來存放所有資料&lt;/li&gt;
&lt;li&gt;Server side / client side cursor
&lt;ul&gt;
&lt;li&gt;Server side
&lt;ul&gt;
&lt;li&gt;一次只傳一部分資料給 client&lt;/li&gt;
&lt;li&gt;但是要多次往返可能最後總時間會比較久&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Client side
&lt;ul&gt;
&lt;li&gt;一次把所有資料傳給 client&lt;/li&gt;
&lt;li&gt;client 自己分批處理&lt;/li&gt;
&lt;li&gt;對 network bandwidth 要求較大&lt;/li&gt;
&lt;li&gt;可能沒有足夠的 memory&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;partitioning&#34;&gt;Partitioning&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;把大 table 分成多個小 table&lt;/li&gt;
&lt;li&gt;Vertical vs Horizontal
&lt;ul&gt;
&lt;li&gt;Vertical
&lt;ul&gt;
&lt;li&gt;根據 columns 拆成多個 partition&lt;/li&gt;
&lt;li&gt;可以把不太常用又大的 column (比如 blob) 放到另外一個 partition
&lt;ul&gt;
&lt;li&gt;可以把他放在較慢的 disk，保留其他常存取的 column 在 SSD&lt;/li&gt;
&lt;li&gt;也可以讓比較不常用的資料比較不容易進入 cache&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Horizontal
&lt;ul&gt;
&lt;li&gt;把 rows 拆成多個 partition&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;優點
&lt;ul&gt;
&lt;li&gt;用 single query 存取單一 partition 的速度更快&lt;/li&gt;
&lt;li&gt;對某些 sequential scan 有幫助&lt;/li&gt;
&lt;li&gt;可以把舊資料放在比較便宜的設備&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;缺點
&lt;ul&gt;
&lt;li&gt;如果要從一個 partition 移動資料到另一個 partition，效率很慢&lt;/li&gt;
&lt;li&gt;對於效率很差的 query，可能會需要 scan 所有 partition，此時比掃描整個沒做 partition 的 table 還要慢&lt;/li&gt;
&lt;li&gt;partition 可能會 unbalance&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;database-indexing&#34;&gt;Database indexing&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;如果需要搜索的欄位沒做 index，那麼就會需要 scan 整個 table，直到找到
&lt;ul&gt;
&lt;li&gt;如果要求欄位做 &lt;code&gt;like&lt;/code&gt; 之類的，那麼依然需要 scan 整個 table&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;搜索方法
&lt;ul&gt;
&lt;li&gt;table scan
&lt;ul&gt;
&lt;li&gt;如果掃描的範圍過大，Database 可能就會選擇該方法&lt;/li&gt;
&lt;li&gt;通常會用 parallel 的方式搜尋，所以還是會快一些&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;index scan&lt;/li&gt;
&lt;li&gt;Index-only scan
&lt;ul&gt;
&lt;li&gt;也叫 covering index&lt;/li&gt;
&lt;li&gt;需要的欄位在 index 裡面就有了，在這種情況不用去 heap 取，可以加速很多&lt;/li&gt;
&lt;li&gt;但也要小心使 index 變得過大。如果 memory 不夠，又會用到 disk，拖垮效率&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;non-key column
&lt;ul&gt;
&lt;li&gt;可以用 include 把一些常常需要一起帶入的資訊放到 index 裡面&lt;/li&gt;
&lt;li&gt;可以促成 index-only scan&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;composite index
&lt;ul&gt;
&lt;li&gt;把多個 col 作為 key 做 index&lt;/li&gt;
&lt;li&gt;在 PostgreSQL ，如果有一個 index 是 (a, b)，用靠左的 index 可以做 index scan，但是用靠右的就不行&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;clustered-index&#34;&gt;Clustered index&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;也叫做 Index-Organized Table
&lt;ul&gt;
&lt;li&gt;資料圍繞 index 來組織&lt;/li&gt;
&lt;li&gt;這也是為什麼 clustered index 只能有一個&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;沒特別指定的話，primary key 一般是 clustered index&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;primary-key-vs-secondary-key&#34;&gt;Primary key vs Secondary key&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;primary key
&lt;ul&gt;
&lt;li&gt;clusering
&lt;ul&gt;
&lt;li&gt;把 table 圍繞 primary key 來組織，但也有些 Database 不是這樣設計，比如 PostgreSQL&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;需要維持 order，但是如果我要根據 PK 取得小範圍內的資料，和不顧排序相比，就可能不用多次 IO&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Secondary key
&lt;ul&gt;
&lt;li&gt;不在乎原本 table 的 order，而是根據自訂的 key 來排序&lt;/li&gt;
&lt;li&gt;但是會有另外一個結構去放 index，可以找到 row_id&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;設計差異
&lt;ul&gt;
&lt;li&gt;PostgreSQL 的 index 都指向 row，不管是 primary 還是 secondary
&lt;ul&gt;
&lt;li&gt;這樣 secondary index 就可以直接取資料，不用再跳一層 primary key&lt;/li&gt;
&lt;li&gt;但是如果更新 row，會更新 row id，連帶影響要更新所有 secondary index，不管修改的欄位有沒有在這 index&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;MySQL 的 secondary index 指向 primary key，primary key 指向 row
&lt;ul&gt;
&lt;li&gt;這樣 secondary index 就要先找到 primary key，再找到 row&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;distributed-database&#34;&gt;Distributed database&lt;/h2&gt;
&lt;h3 id=&#34;sharding&#34;&gt;Sharding&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;把 table 拆成多個 table，分散在不同的 database&lt;/li&gt;
&lt;li&gt;分散式會帶來很多問題，比如要怎麼做 transaction 和 join?&lt;/li&gt;
&lt;li&gt;Horizontal partitioning vs sharding
&lt;ul&gt;
&lt;li&gt;Horizontal partitioning
&lt;ul&gt;
&lt;li&gt;一個 table 拆成多個 table，但是還是在同一個 database&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;和 Horizontal partitioning 的差別
&lt;ul&gt;
&lt;li&gt;table 現在會分到不同的 database server&lt;/li&gt;
&lt;li&gt;做 partition，client 不用管資料具體在哪個 partition，交給 DBMS 去處理。但是 sharding 就要 client 自己去處理&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;database-replication&#34;&gt;Database replication&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;透過 redundancy 來提高 reliability, tolerance, accessibility&lt;/li&gt;
&lt;li&gt;Master / Backup replication
&lt;ul&gt;
&lt;li&gt;也叫 master-slave replication&lt;/li&gt;
&lt;li&gt;只有一個 master / leader，有一或多個 backup / standby&lt;/li&gt;
&lt;li&gt;一寫多讀&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Multi-master replication
&lt;ul&gt;
&lt;li&gt;多個 master，可以同時寫入&lt;/li&gt;
&lt;li&gt;需要處理 conflict&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Sychronous vs Asynchronous replication
&lt;ul&gt;
&lt;li&gt;Synchronous
&lt;ul&gt;
&lt;li&gt;transaction 會被 blocked，直到所有的 backup 都寫入&lt;/li&gt;
&lt;li&gt;有些 database 可以設定 First N 或是 any 完成就好&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Asynchronous
&lt;ul&gt;
&lt;li&gt;transaction 被寫入 master 後就算完成&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;concurrency-control&#34;&gt;Concurrency control&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;strategy
&lt;ul&gt;
&lt;li&gt;pessimistic
&lt;ul&gt;
&lt;li&gt;用各種 lock 來保證 isolation&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;optimistic
&lt;ul&gt;
&lt;li&gt;不用 lock，真的有 transaction 衝突時就 fail&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Lock
&lt;ul&gt;
&lt;li&gt;shared vs exclusive
&lt;ul&gt;
&lt;li&gt;shared lock 可以被多個 transaction 同時持有
&lt;ul&gt;
&lt;li&gt;用在讀取，所以可以多個 transaction 同時讀取&lt;/li&gt;
&lt;li&gt;在有 shared lock  的條件下，其他 transaction 也可以設置 shared lock&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;exclusive lock 只能被一個 transaction 持有
&lt;ul&gt;
&lt;li&gt;他人不能讀取或寫入&lt;/li&gt;
&lt;li&gt;PostgreSQL 有一個 &lt;code&gt;SELECT ... FOR UPDATE&lt;/code&gt; 來取得 exclusive lock&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;當涉及的資料持有其中一種 lock 時，其他 transaction 都不能設置另外一種 lock&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Deadlock
&lt;ul&gt;
&lt;li&gt;多個 transaction 互相等待對方釋放 lock&lt;/li&gt;
&lt;li&gt;多數 DBMS 會檢查 deadlock，並讓最後一個造成 deadlock 的 transaction rollback&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Two-phase locking (2PL)
&lt;ul&gt;
&lt;li&gt;DBMS 為了實現 isolation 需要保證 conflict serializability (CSR)，2PL 可以保證這一點&lt;/li&gt;
&lt;li&gt;two-phase
&lt;ul&gt;
&lt;li&gt;growing phase
&lt;ul&gt;
&lt;li&gt;取得 lock&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;shrinking phase
&lt;ul&gt;
&lt;li&gt;釋放 lock&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;強調一個 transaction 不能釋放 lock 後就再也無法取得&lt;/li&gt;
&lt;li&gt;有可能造成 deadlock&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;database-engine&#34;&gt;Database Engine&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;也叫 storage engine 或 embedded database&lt;/li&gt;
&lt;li&gt;負責處理 CRUD 的 library&lt;/li&gt;
&lt;li&gt;DBMS 基於 engine 來提供更多功能&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;orm&#34;&gt;ORM&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Eager vs Lazy loading
&lt;ul&gt;
&lt;li&gt;Eager
&lt;ul&gt;
&lt;li&gt;一次把所有相關的資料都讀取出來&lt;/li&gt;
&lt;li&gt;如果 Teacher 有很多 Student，可能會一次把所有 Student 都讀取出來&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Lazy
&lt;ul&gt;
&lt;li&gt;只有在需要的時候才讀取&lt;/li&gt;
&lt;li&gt;但是可能會有很多次 IO&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Open session in view (OSIV)
&lt;ul&gt;
&lt;li&gt;一個 request 一個 database session&lt;/li&gt;
&lt;li&gt;可以配合 lazy loading 來用&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;N+1 problem
&lt;ul&gt;
&lt;li&gt;一個 query 取得所有資料，然後再用每個資料的 id 來取得相關資料&lt;/li&gt;
&lt;li&gt;這樣就會有 N+1 次 IO
&lt;ul&gt;
&lt;li&gt;第一次是從主表拿清單&lt;/li&gt;
&lt;li&gt;接下來 N 次是從子表拿資料&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tips&#34;&gt;Tips&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;盡量不要使用 offset
&lt;ul&gt;
&lt;li&gt;最 naive 的實現 pagination 的做法就是用 offset + limit。但是 offset 代表讀取並丟掉前面幾筆資料，所以他會多讀一堆沒用的資料&lt;/li&gt;
&lt;li&gt;可以讓用戶那邊保存 id，where 設置 id 要大於多少來規避 offset&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Connection pool
&lt;ul&gt;
&lt;li&gt;維護一定數量的連接，避免每次都要建立連接&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Idempotency key
&lt;ul&gt;
&lt;li&gt;用來確保一個 request 只會被執行一次&lt;/li&gt;
&lt;li&gt;會生成一個唯一的 key，並且在 request 中帶上這個 key。執行操作後會把這個 key 存起來，下次再收到這個 key 時就不會再執行操作&lt;/li&gt;
&lt;li&gt;可以用 ULID 而不用 UUID，因為 ULID 前面的 bit 有時間戳，可以用來排序
&lt;ul&gt;
&lt;li&gt;輸入的資料集中在相近的 page，還都加在尾端，可以減少 IO (相較隨機的 UUID)
&lt;ul&gt;
&lt;li&gt;不用被迫頻繁存取 disk。而且 UUID 的隨機性拉一堆 page 會導致 buffer 更容易被塞滿，而得強制寫入 disk&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;consistent hashing
&lt;ul&gt;
&lt;li&gt;把 hash function 的結果分散在一個 hash ring 上
&lt;ul&gt;
&lt;li&gt;根據 hash function 的結果，看自己落在哪段範圍，配給指定的 server&lt;/li&gt;
&lt;li&gt;這樣的好處是追加或是移除 server 時，只會影響一台 server 的資料&lt;/li&gt;
&lt;li&gt;也可以追加到負載比較高的 server 附近&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;write amplification
&lt;ul&gt;
&lt;li&gt;寫入資料時，發現 disk 寫入的資料比你預期寫入的資料多很多&lt;/li&gt;
&lt;li&gt;分很多不同 level，通常是在說 SSD 造成的&lt;/li&gt;
&lt;li&gt;想更新的時候，更新的 page 會被標記為不能使用。會有另外一隻非同步程式定期處理這種
&lt;ul&gt;
&lt;li&gt;但是他會把整個 block 寫到新的地方，再把原地方設為 free，就為了那些不能再被使用的空間搬整個 block&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Azure Devops 筆記</title>
        <link>https://roykesydon.github.io/Blog/p/azure-devops-%E7%AD%86%E8%A8%98/</link>
        <pubDate>Sat, 20 Jul 2024 00:00:17 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/azure-devops-%E7%AD%86%E8%A8%98/</guid>
        <description>&lt;h2 id=&#34;pipeline&#34;&gt;Pipeline&lt;/h2&gt;
&lt;h3 id=&#34;名詞&#34;&gt;名詞&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Artifact
&lt;ul&gt;
&lt;li&gt;你需要用到的檔案，可能是 build 出來的檔案，或是跑測試用的專案&lt;/li&gt;
&lt;li&gt;ex: .jar, .war&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;type&#34;&gt;Type&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Build pipeline&lt;/li&gt;
&lt;li&gt;Release pipeline&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;azure-pipelinesyml&#34;&gt;azure-pipelines.yml&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;可以 create pipeline，在專案中加入該檔案，Azure DevOps 會自動偵測並執行&lt;/li&gt;
&lt;li&gt;用於 build pipeline&lt;/li&gt;
&lt;li&gt;trigger
&lt;ul&gt;
&lt;li&gt;指定哪些 branch 有 push 時，要執行 pipeline&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;variables&#34;&gt;Variables&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;可以設定變數，用在 yaml 中&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;task&#34;&gt;Task&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;可以搜尋各種 task 來完成任務
&lt;ul&gt;
&lt;li&gt;copy files&lt;/li&gt;
&lt;li&gt;publish build artifacts&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;release-pipeline&#34;&gt;Release pipeline&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;把 build 出來的 artifact，部署到指定的環境&lt;/li&gt;
&lt;li&gt;artifact 上方的閃電，可以設置當有新的 artifact 時，自動觸發 release&lt;/li&gt;
&lt;li&gt;create release
&lt;ul&gt;
&lt;li&gt;執行 CI/CD&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;agent-pool&#34;&gt;Agent pool&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;可以加入自己的 agent，也就是自己的 server&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;board&#34;&gt;Board&lt;/h2&gt;
&lt;h3 id=&#34;work-item&#34;&gt;Work item&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Epic
&lt;ul&gt;
&lt;li&gt;一個非常 high level 的需求&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Issue
&lt;ul&gt;
&lt;li&gt;把 Epic 拆成小的需求&lt;/li&gt;
&lt;li&gt;在敏捷也可以稱為 User Story&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Task
&lt;ul&gt;
&lt;li&gt;再把 Issue 拆成更小的需求&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;backlog&#34;&gt;Backlog&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;PO 創建的 Issue，會在 Backlog 中&lt;/li&gt;
&lt;li&gt;可以把 Issue 拖拉到 sprint 中&lt;/li&gt;
&lt;li&gt;可以結合 git repo，把 commit 或 branch 關聯到 Issue&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;sprint&#34;&gt;Sprint&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;在這可以新增 sprint&lt;/li&gt;
&lt;li&gt;也有 task board，列出所有 task
&lt;ul&gt;
&lt;li&gt;可以設置 task 的狀態以及指派人員&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Web Security</title>
        <link>https://roykesydon.github.io/Blog/p/web-security/</link>
        <pubDate>Fri, 28 Jun 2024 00:00:17 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/web-security/</guid>
        <description>&lt;h2 id=&#34;file-uploaded-vulnerability&#34;&gt;File Uploaded Vulnerability&lt;/h2&gt;
&lt;h3 id=&#34;防禦方法&#34;&gt;防禦方法&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;不要允許使用者上傳任何可執行的檔案&lt;/li&gt;
&lt;li&gt;檢查 file type 和 file extension
&lt;ul&gt;
&lt;li&gt;file type 指的是 header 的 Content-Type&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;用某些套件分析檔案，並重新創建和重新命名檔案&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;code-execution-vulnerability&#34;&gt;Code Execution Vulnerability&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;允許攻擊者執行 OS command&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;防禦方法-1&#34;&gt;防禦方法&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;不要使用危險的 function&lt;/li&gt;
&lt;li&gt;透過 filter 檢查輸入
&lt;ul&gt;
&lt;li&gt;比如利用 regex&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;file-inclusion-vulnerability&#34;&gt;File Inclusion Vulnerability&lt;/h2&gt;
&lt;h3 id=&#34;lfi-local-file-inclusion-vulnerability&#34;&gt;LFI (Local File Inclusion) Vulnerability&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;攻擊者可以讀取伺服器上的任何檔案（包含 /var/www 外的檔案）&lt;/li&gt;
&lt;li&gt;透過輸入讀其他檔案的時候沒有檢查檔案路徑&lt;/li&gt;
&lt;li&gt;可以用來讀 /proc/self/environ，可能會存在一些可以透過 request 修改的變數。植入PHP 程式碼便有可能被執行&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;rfi-remote-file-inclusion-vulnerability&#34;&gt;RFI (Remote File Inclusion) Vulnerability&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;和 LFI 類似，但是檔案來自外部&lt;/li&gt;
&lt;li&gt;可以在當前 server 執行其他 server 的 php 程式碼&lt;/li&gt;
&lt;li&gt;可以在其他 server 以 .txt 存 php file&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;防禦方法-2&#34;&gt;防禦方法&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;避免 remote file inclusion
&lt;ul&gt;
&lt;li&gt;php 的話可以關掉 allow_url_fopen 和 allow_url_include&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;避免 local file inclusion
&lt;ul&gt;
&lt;li&gt;用 static file inclusion，不要透過變數去取得檔案位置&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;sql-injection&#34;&gt;SQL Injection&lt;/h2&gt;
&lt;h3 id=&#34;防禦方法-3&#34;&gt;防禦方法&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;使用 prepared statement&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;xss-cross-site-scripting&#34;&gt;XSS (Cross Site Scripting)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;允許攻擊者在網頁上執行 javascript code&lt;/li&gt;
&lt;li&gt;執行在 client 端，不是 server 端&lt;/li&gt;
&lt;li&gt;Main types
&lt;ul&gt;
&lt;li&gt;Reflected XSS
&lt;ul&gt;
&lt;li&gt;用 URL 攻擊&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Persistent/Stored XSS
&lt;ul&gt;
&lt;li&gt;攻擊的程式碼存在 database 或是某個 page&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;DOM-based XSS
&lt;ul&gt;
&lt;li&gt;利用前面的方法，透過開發者不當操作 DOM 來攻擊&lt;/li&gt;
&lt;li&gt;ex: 攻擊者透過 .innerHTML 放入 script tag&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;exploitation&#34;&gt;Exploitation&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;BeEF Framework
&lt;ul&gt;
&lt;li&gt;可以把目標 hook 到 beef&lt;/li&gt;
&lt;li&gt;可以透過 beef 對被 hook 的目標做各種操作&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;防禦方法-4&#34;&gt;防禦方法&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;盡量避免讓 user 的輸入直接顯示在網頁上&lt;/li&gt;
&lt;li&gt;在 insert 到網頁前，escape 所有不信任的輸入
&lt;ul&gt;
&lt;li&gt;把這些 character 轉換成 HTML 用的格式
&lt;ul&gt;
&lt;li&gt;ex: &lt;code&gt;&amp;lt;&lt;/code&gt; -&amp;gt; &lt;code&gt;&amp;amp;lt;&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;csrf-cross-site-request-forgery&#34;&gt;CSRF (Cross Site Request Forgery)&lt;/h2&gt;
&lt;h3 id=&#34;防禦方法-5&#34;&gt;防禦方法&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Anti CSRF token
&lt;ul&gt;
&lt;li&gt;生表單的時候也生一個 token，並記住，request 要帶上這個 token&lt;/li&gt;
&lt;li&gt;unpredictable&lt;/li&gt;
&lt;li&gt;can&amp;rsquo;t be reused&lt;/li&gt;
&lt;li&gt;前後端分離
&lt;ul&gt;
&lt;li&gt;後端生
&lt;ul&gt;
&lt;li&gt;CORS 不要接受所有來源，讓前端取得 token&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;前端生
&lt;ul&gt;
&lt;li&gt;要發 request 的時候把 cookie 改成和 token 一樣的值&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;backdoor&#34;&gt;Backdoor&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;msfvenom&lt;/li&gt;
&lt;li&gt;msfconsole&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;anti-virus&#34;&gt;Anti-Virus&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Principle
&lt;ul&gt;
&lt;li&gt;Static Analysis
&lt;ul&gt;
&lt;li&gt;和已知的 malware 比對&lt;/li&gt;
&lt;li&gt;可以利用 packers, encoders, abfuscators 來讓程式更加獨特&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Dynamic(Heuristic) Analysis
&lt;ul&gt;
&lt;li&gt;在 sandbox 中執行，看他的行為&lt;/li&gt;
&lt;li&gt;要幫程式增加安全的操作&lt;/li&gt;
&lt;li&gt;延遲 Payload 執行的時間&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Software Development Model</title>
        <link>https://roykesydon.github.io/Blog/p/software-development-model/</link>
        <pubDate>Thu, 27 Jun 2024 02:00:17 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/software-development-model/</guid>
        <description>&lt;h2 id=&#34;terms&#34;&gt;Terms&lt;/h2&gt;
&lt;h3 id=&#34;incremental-vs-iterative&#34;&gt;Incremental vs Iterative&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Incremental
&lt;ul&gt;
&lt;li&gt;隨時間一步一步完成&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Iterative
&lt;ul&gt;
&lt;li&gt;建立 prototype，然後不斷改進&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;model-type&#34;&gt;Model type&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Linear/Predictive
&lt;ul&gt;
&lt;li&gt;有類似的專案經驗&lt;/li&gt;
&lt;li&gt;有明確的流程&lt;/li&gt;
&lt;li&gt;沒什麼可以改動的空間&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Flexible/Adaptive
&lt;ul&gt;
&lt;li&gt;專案屬於 new idea&lt;/li&gt;
&lt;li&gt;專案很有可能隨時間改變&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;waterfall-model&#34;&gt;Waterfall Model&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;像瀑布一樣，一個階段完成後才能進行下一個階段&lt;/li&gt;
&lt;li&gt;Requirement -&amp;gt; Design -&amp;gt; Implementation -&amp;gt; Testing -&amp;gt; Deployment -&amp;gt; Maintenance&lt;/li&gt;
&lt;li&gt;非常 predictive，沒有彈性&lt;/li&gt;
&lt;li&gt;如果在 Testing 發現重大問題，可能要從 Requirement 重新開始&lt;/li&gt;
&lt;li&gt;隨著進度推進，fix 成本增長很快&lt;/li&gt;
&lt;li&gt;每一步都得考慮周密&lt;/li&gt;
&lt;li&gt;用戶很晚才能看到結果&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;incremental-model&#34;&gt;Incremental Model&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;在整個開發過程中多次完成軟體開發過程&lt;/li&gt;
&lt;li&gt;每個子開發過程都有明確的目標&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;agile&#34;&gt;Agile&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;一種思維方法，不是模型&lt;/li&gt;
&lt;li&gt;Manifesto
&lt;ul&gt;
&lt;li&gt;Individuals and interactions over processes and tools
&lt;ul&gt;
&lt;li&gt;如果一組人決定要用一組新的工具，那他們應該有更高的優先權&lt;/li&gt;
&lt;li&gt;過往的做法可能偏向使用過的工具&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Working software over comprehensive documentation
&lt;ul&gt;
&lt;li&gt;document 很重要，但是只有大量的 document 沒辦法讓客戶給出反饋&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Customer collaboration over contract negotiation
&lt;ul&gt;
&lt;li&gt;強調和客戶的合作，而不是只在意合同上的項目&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Responding to change over following a plan&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;瀑布式開發的缺點
&lt;ul&gt;
&lt;li&gt;現在的技術環境變化太快，Agile 希望在開發過程中能夠快速適應
&lt;ul&gt;
&lt;li&gt;傳統的開發方法考量到金錢損失，不太可能辦到。但透過小的 increment，可以在每個 increment 中朝正確的方向前進&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;軟體系統不可能被 100% 預測&lt;/li&gt;
&lt;li&gt;系統可能不符合用戶要求&lt;/li&gt;
&lt;li&gt;市場變化很快，Agile 可以在短時間內推出最小可行產品，先行推向市場&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;kanban&#34;&gt;Kanban&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;會存在多張卡片&lt;/li&gt;
&lt;li&gt;可以直觀看到某個欄位是否堆積大量工作&lt;/li&gt;
&lt;li&gt;Properties
&lt;ul&gt;
&lt;li&gt;Visualize workflow&lt;/li&gt;
&lt;li&gt;Limit work in progress&lt;/li&gt;
&lt;li&gt;Manage flow&lt;/li&gt;
&lt;li&gt;Make process policies explicit&lt;/li&gt;
&lt;li&gt;Improve collaboratively&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Principles
&lt;ul&gt;
&lt;li&gt;Start with what you do now&lt;/li&gt;
&lt;li&gt;Agree to pursue incremental, evolutionary change
&lt;ul&gt;
&lt;li&gt;並非試著立刻改變所有事情&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Respect the current process, roles, responsibilities &amp;amp; titles&lt;/li&gt;
&lt;li&gt;Encourage acts of leadership at all levels
&lt;ul&gt;
&lt;li&gt;這裡的 leadership 不一定指領導他人，也可以是激勵他人&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;欄位
&lt;ul&gt;
&lt;li&gt;Backlog&lt;/li&gt;
&lt;li&gt;Analyze&lt;/li&gt;
&lt;li&gt;Develop&lt;/li&gt;
&lt;li&gt;Test&lt;/li&gt;
&lt;li&gt;Release&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;scrum&#34;&gt;Scrum&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;可以利用 back-to-back testing 來確認沒有弄壞之前 sprint 的功能&lt;/li&gt;
&lt;li&gt;roles
&lt;ul&gt;
&lt;li&gt;Product Owner
&lt;ul&gt;
&lt;li&gt;決定要用什麼方式完成什麼事&lt;/li&gt;
&lt;li&gt;與外部世界溝通的人，和利害關係人溝通&lt;/li&gt;
&lt;li&gt;目標
&lt;ul&gt;
&lt;li&gt;最大化產品價值
&lt;ul&gt;
&lt;li&gt;價低成本、提高收益&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;職責
&lt;ul&gt;
&lt;li&gt;維護 open, healthy product backlog&lt;/li&gt;
&lt;li&gt;回答產品相關問題&lt;/li&gt;
&lt;li&gt;管理預算、release schedule&lt;/li&gt;
&lt;li&gt;確保團隊價值，找出問題&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Scrum Master
&lt;ul&gt;
&lt;li&gt;確保團隊遵守 Scrum 的規則，促成會議、解決衝突&lt;/li&gt;
&lt;li&gt;Servant Leader
&lt;ul&gt;
&lt;li&gt;有一點領導，但和大家平等。促成團隊工作而不是指揮別人&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;目標
&lt;ul&gt;
&lt;li&gt;促成 Daily Standup&lt;/li&gt;
&lt;li&gt;移除障礙&lt;/li&gt;
&lt;li&gt;確保大家的心情&lt;/li&gt;
&lt;li&gt;確保 Scurm values&lt;/li&gt;
&lt;li&gt;團隊的調解人&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Dev Team
&lt;ul&gt;
&lt;li&gt;包含工程師、設計師等等&lt;/li&gt;
&lt;li&gt;目標
&lt;ul&gt;
&lt;li&gt;和 Product Owner 合作，create user stories&lt;/li&gt;
&lt;li&gt;寫 code 和測試，確保符合預期&lt;/li&gt;
&lt;li&gt;research, design, prototype&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;流程
&lt;ul&gt;
&lt;li&gt;product backlog
&lt;ul&gt;
&lt;li&gt;待完成的事情&lt;/li&gt;
&lt;li&gt;可能的欄位
&lt;ul&gt;
&lt;li&gt;優先度&lt;/li&gt;
&lt;li&gt;預計花費時間&lt;/li&gt;
&lt;li&gt;誰來執行&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;spring planning meeting
&lt;ul&gt;
&lt;li&gt;決定要在這個 sprint 完成的事情&lt;/li&gt;
&lt;li&gt;時間點會是 sprint 的第一天&lt;/li&gt;
&lt;li&gt;目標
&lt;ul&gt;
&lt;li&gt;把 product backlog 轉換成 sprint backlog&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;職責
&lt;ul&gt;
&lt;li&gt;Scrum Master
&lt;ul&gt;
&lt;li&gt;促成會議&lt;/li&gt;
&lt;li&gt;確保和準備會議地點&lt;/li&gt;
&lt;li&gt;確保會議有在持續推進，好達成 timebox
&lt;ul&gt;
&lt;li&gt;如果有講太久的部分，可能稍後再排單獨會議&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;確保一切都和 sprint goal 一致&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Product Owner
&lt;ul&gt;
&lt;li&gt;準備好 product backlog&lt;/li&gt;
&lt;li&gt;澄清 product backlog 的細節&lt;/li&gt;
&lt;li&gt;要準備好描述 acceptance criteria
&lt;ul&gt;
&lt;li&gt;比如搜索速度要多快？&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Dev Team
&lt;ul&gt;
&lt;li&gt;協助判斷哪些任務可達成且符合 sprint goal&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;sprint backlog
&lt;ul&gt;
&lt;li&gt;這個 sprint 要完成的事情&lt;/li&gt;
&lt;li&gt;開發人員去自己選擇要做的事情&lt;/li&gt;
&lt;li&gt;然後就會花 1-4 週完成一個 sprint&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Daily Scrum (Daily standup)
&lt;ul&gt;
&lt;li&gt;不該花太久，比如最多 15 分鐘&lt;/li&gt;
&lt;li&gt;職責
&lt;ul&gt;
&lt;li&gt;Scrum Master
&lt;ul&gt;
&lt;li&gt;確保會議的進行，確保 timebox&lt;/li&gt;
&lt;li&gt;紀錄關於目前障礙的筆記，規劃時間移除&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Dev Team
&lt;ul&gt;
&lt;li&gt;回答問題
&lt;ul&gt;
&lt;li&gt;做了什麼&lt;/li&gt;
&lt;li&gt;計畫做什麼&lt;/li&gt;
&lt;li&gt;遇到什麼問題&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;sprint review
&lt;ul&gt;
&lt;li&gt;找 stakeholders 來看看這個 sprint 的成果&lt;/li&gt;
&lt;li&gt;秀出 product increment
&lt;ul&gt;
&lt;li&gt;product increment 意味著他本身就是一個完成的產品，經過測試且準備 release&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;任務
&lt;ul&gt;
&lt;li&gt;review sprint result
&lt;ul&gt;
&lt;li&gt;回顧那些任務做得好和不好
&lt;ul&gt;
&lt;li&gt;如果有事情沒完成，要解釋為什麼推遲&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;這個 sprint 有沒有達到目標&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Discuss and demonstrate work
&lt;ul&gt;
&lt;li&gt;product owner 全程記錄筆記&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Update status of the project&lt;/li&gt;
&lt;li&gt;Collaborate on the plan ahead&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;sprint retrospective
&lt;ul&gt;
&lt;li&gt;團隊討論這個 sprint 的問題，並且改進&lt;/li&gt;
&lt;li&gt;常見方法
&lt;ul&gt;
&lt;li&gt;start-stop-continue
&lt;ul&gt;
&lt;li&gt;每個人說出一個想開始做的事情，一個想停止做的事情，一個想繼續做的事情&lt;/li&gt;
&lt;li&gt;可以保持匿名&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;3-5-3-structure&#34;&gt;3-5-3 Structure&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;3 artifacts
&lt;ul&gt;
&lt;li&gt;Sprint Backlog&lt;/li&gt;
&lt;li&gt;Product Backlog&lt;/li&gt;
&lt;li&gt;Product Increment&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;5 events
&lt;ul&gt;
&lt;li&gt;Sprint Planning&lt;/li&gt;
&lt;li&gt;Daily Scrum&lt;/li&gt;
&lt;li&gt;The Sprint&lt;/li&gt;
&lt;li&gt;Sprint Review&lt;/li&gt;
&lt;li&gt;Sprint Retrospective&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;3 roles
&lt;ul&gt;
&lt;li&gt;Product Owner&lt;/li&gt;
&lt;li&gt;Scrum Master&lt;/li&gt;
&lt;li&gt;Dev Team&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;可以再加上
&lt;ul&gt;
&lt;li&gt;5 values
&lt;ul&gt;
&lt;li&gt;Focus&lt;/li&gt;
&lt;li&gt;Respect&lt;/li&gt;
&lt;li&gt;Commitment&lt;/li&gt;
&lt;li&gt;Courage&lt;/li&gt;
&lt;li&gt;Openness&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;3 pillars
&lt;ul&gt;
&lt;li&gt;Transparency&lt;/li&gt;
&lt;li&gt;Inspection&lt;/li&gt;
&lt;li&gt;Adaptation&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Testing</title>
        <link>https://roykesydon.github.io/Blog/p/testing/</link>
        <pubDate>Thu, 27 Jun 2024 00:01:17 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/testing/</guid>
        <description>&lt;h2 id=&#34;通用術語&#34;&gt;通用術語&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Test data
&lt;ul&gt;
&lt;li&gt;用來測試系統的輸入&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Test case
&lt;ul&gt;
&lt;li&gt;包含測試步驟, 預期結果, 測試資料&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Oracle
&lt;ul&gt;
&lt;li&gt;理想的結果&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Bug
&lt;ul&gt;
&lt;li&gt;error 或是偏離預期的行為&lt;/li&gt;
&lt;li&gt;用詞
&lt;ul&gt;
&lt;li&gt;failure
&lt;ul&gt;
&lt;li&gt;偏離預期的 event&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;error
&lt;ul&gt;
&lt;li&gt;導致 failure 的 code part&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;fault
&lt;ul&gt;
&lt;li&gt;outcome&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Verification
&lt;ul&gt;
&lt;li&gt;確認系統是否符合 specifcation&lt;/li&gt;
&lt;li&gt;這裡出問題是工程師的錯&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Validation
&lt;ul&gt;
&lt;li&gt;確認系統是否符合使用者需求&lt;/li&gt;
&lt;li&gt;這裡出問題代表產品目標有錯&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Stub
&lt;ul&gt;
&lt;li&gt;用來代替其他 component 的 template，會回傳 hard-coded value&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Mock
&lt;ul&gt;
&lt;li&gt;用來代替其他 component 的 template，會回傳預先設定的值，而且會檢查調用的次數&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Driver
&lt;ul&gt;
&lt;li&gt;用來執行 commands 還有初始化變數的 template&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;test-coverage&#34;&gt;Test coverage&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;line coverage
&lt;ul&gt;
&lt;li&gt;根據程式碼實際執行的程式碼行數來計算&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;branch coverage
&lt;ul&gt;
&lt;li&gt;檢查程式碼是不是不同的可能都跑過
&lt;ul&gt;
&lt;li&gt;考慮 if, switch&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;testing-types&#34;&gt;Testing Types&lt;/h2&gt;
&lt;h3 id=&#34;unit-testing&#34;&gt;Unit Testing&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;專注在測試 smallest unit of software&lt;/li&gt;
&lt;li&gt;要 isolate unit，避免其他 unit 影響測試結果
&lt;ul&gt;
&lt;li&gt;用 dummy value&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;integration-testing&#34;&gt;Integration Testing&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;專注在測試 communication 和 architecture&lt;/li&gt;
&lt;li&gt;type
&lt;ul&gt;
&lt;li&gt;non-incremental
&lt;ul&gt;
&lt;li&gt;一次測試所有 component，測試整個應用程式&lt;/li&gt;
&lt;li&gt;Big Bang Testing&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;incremental
&lt;ul&gt;
&lt;li&gt;每次新增一個 module，做一些測試，反覆執行&lt;/li&gt;
&lt;li&gt;Top-Down Testing
&lt;ul&gt;
&lt;li&gt;從最上層開始，下面調用的部分用 stub 代替&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Bottom-Up Testing
&lt;ul&gt;
&lt;li&gt;從最底層開始，上面呼叫的部分用 driver 代替&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Back-to-Back Testing
&lt;ul&gt;
&lt;li&gt;把已知良好的版本和新版本比較&lt;/li&gt;
&lt;li&gt;如果 output 一樣，就代表新版本舊的功能是正確的&lt;/li&gt;
&lt;li&gt;可以是 incremental testing 的一部分&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;black-box-vs-white-box-testing&#34;&gt;Black Box vs White Box Testing&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Black Box Testing
&lt;ul&gt;
&lt;li&gt;不需要知道內部結構&lt;/li&gt;
&lt;li&gt;用 input 和 output 來測試&lt;/li&gt;
&lt;li&gt;Boundary Value
&lt;ul&gt;
&lt;li&gt;測試高低邊界值，過了就假設中間都過了&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Cause-Effect Graph
&lt;ul&gt;
&lt;li&gt;一種設計 Test Case 的方法&lt;/li&gt;
&lt;li&gt;又稱為 fishbone diagram&lt;/li&gt;
&lt;li&gt;不同的 cause 會導致不同的 effect&lt;/li&gt;
&lt;li&gt;最後會有一個 table 來表示所有可能輸入的組合會對應到什麼結果&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Pair-wise Testing
&lt;ul&gt;
&lt;li&gt;測試多個參數的可能組合&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;State-based Testing
&lt;ul&gt;
&lt;li&gt;測試不同狀態下的輸入，確認 state 改變的情形&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;White Box Testing
&lt;ul&gt;
&lt;li&gt;知道內部原理，嘗試測試程式碼本身&lt;/li&gt;
&lt;li&gt;Control Flow Testing
&lt;ul&gt;
&lt;li&gt;寫涵蓋所有 branch condition 的 test case&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Data Flow Testing
&lt;ul&gt;
&lt;li&gt;test case 要涵蓋所有的變數，包含 declaration 和 use&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Kubernetes 筆記</title>
        <link>https://roykesydon.github.io/Blog/p/kubernetes-%E7%AD%86%E8%A8%98/</link>
        <pubDate>Fri, 14 Jun 2024 00:00:17 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/kubernetes-%E7%AD%86%E8%A8%98/</guid>
        <description>&lt;h2 id=&#34;基礎概念&#34;&gt;基礎概念&lt;/h2&gt;
&lt;h3 id=&#34;container-runtime&#34;&gt;Container runtime&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;CRI (Container Runtime Interface)
&lt;ul&gt;
&lt;li&gt;Kubernetes 用來和 container runtime 互動的 interface&lt;/li&gt;
&lt;li&gt;任何可以實現 CRI 的 container runtime 都可以用在 Kubernetes，比如 containerd&lt;/li&gt;
&lt;li&gt;以前有幫 Docker 特別實現一個 CRI，叫做 Docker shim&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;OCI (Open Container Initiative)
&lt;ul&gt;
&lt;li&gt;一個開放的 container image 和 runtime 的標準&lt;/li&gt;
&lt;li&gt;他定義了 container image 和 container runtime 的格式&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;containerd
&lt;ul&gt;
&lt;li&gt;一個 container runtime，docker 底下所使用的 container runtime，現在已經與 docker 單獨出來開發維護&lt;/li&gt;
&lt;li&gt;他實現了 CRI，所以可以用在 Kubernetes&lt;/li&gt;
&lt;li&gt;CLI
&lt;ul&gt;
&lt;li&gt;ctr
&lt;ul&gt;
&lt;li&gt;如果你只裝 containerd，沒有裝 docker，就可以用這個來操作 containerd&lt;/li&gt;
&lt;li&gt;能用的指令比較少&lt;/li&gt;
&lt;li&gt;For Debugging&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;nerdctl
&lt;ul&gt;
&lt;li&gt;docker-like 的 CLI&lt;/li&gt;
&lt;li&gt;很多指令可以把 docker 的指令換成 nerdctl 的指令&lt;/li&gt;
&lt;li&gt;For general purpose&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;crictl
&lt;ul&gt;
&lt;li&gt;用來操作符合 CRI 的 container runtime 的 CLI&lt;/li&gt;
&lt;li&gt;For Debugging&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;node&#34;&gt;Node&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Kubernetes 集群中的一台機器&lt;/li&gt;
&lt;li&gt;過去叫做 Minion&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;cluster&#34;&gt;Cluster&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;由多個 Node 組成的集群&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;node-type&#34;&gt;Node Type&lt;/h4&gt;
&lt;h5 id=&#34;master&#34;&gt;Master&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;控制整個集群的 Node&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;worker&#34;&gt;Worker&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;其他非 Master 的 Node 叫做 Worker Node&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id=&#34;master-vs-worker&#34;&gt;Master vs Worker&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Master
&lt;ul&gt;
&lt;li&gt;擁有的 Component
&lt;ul&gt;
&lt;li&gt;API Server&lt;/li&gt;
&lt;li&gt;etcd&lt;/li&gt;
&lt;li&gt;Controller&lt;/li&gt;
&lt;li&gt;Scheduler&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Worker
&lt;ul&gt;
&lt;li&gt;擁有的 Component
&lt;ul&gt;
&lt;li&gt;Container Runtime&lt;/li&gt;
&lt;li&gt;Kubelet&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;component&#34;&gt;Component&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;安裝 Kubernetes，實際上是安裝以下幾個 Component
&lt;ul&gt;
&lt;li&gt;API Server
&lt;ul&gt;
&lt;li&gt;front-end of the Kubernetes&lt;/li&gt;
&lt;li&gt;kubectl 是在和這裡溝通&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;etcd
&lt;ul&gt;
&lt;li&gt;distributed key-value store&lt;/li&gt;
&lt;li&gt;會實現 lock mechanism，確保沒有 conflict&lt;/li&gt;
&lt;li&gt;預設聽 2379 port&lt;/li&gt;
&lt;li&gt;command line client
&lt;ul&gt;
&lt;li&gt;etcdctl&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;kubelet
&lt;ul&gt;
&lt;li&gt;在每個 node 上運行的 agent&lt;/li&gt;
&lt;li&gt;負責確保 container 在 node 上如期運行&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Container Runtime
&lt;ul&gt;
&lt;li&gt;用來 run container 的 underlying software&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Controller Manager
&lt;ul&gt;
&lt;li&gt;當 node、container、endpoint 掛掉的時候，他要負責監控和回應&lt;/li&gt;
&lt;li&gt;底下有許多種的 Controller，負責監控還有作出應對處理&lt;/li&gt;
&lt;li&gt;type
&lt;ul&gt;
&lt;li&gt;Replication Controller
&lt;ul&gt;
&lt;li&gt;確保指定數量的 Pod 在任何時間都在運行&lt;/li&gt;
&lt;li&gt;load balancing &amp;amp; scaling&lt;/li&gt;
&lt;li&gt;後來被 ReplicaSet 取代&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Node Controller
&lt;ul&gt;
&lt;li&gt;確保 node 在運行&lt;/li&gt;
&lt;li&gt;設定固定間隔監測 node 的健康狀態&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Scheduler
&lt;ul&gt;
&lt;li&gt;負責處理 node 間的 distributing work&lt;/li&gt;
&lt;li&gt;會尋找新創的 container，並分配到 node&lt;/li&gt;
&lt;li&gt;嘗試幫每個 pod 挑選最適合的 node&lt;/li&gt;
&lt;li&gt;two phase
&lt;ul&gt;
&lt;li&gt;Filter
&lt;ul&gt;
&lt;li&gt;檢查 node 是否符合 pod 的需求&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Rank
&lt;ul&gt;
&lt;li&gt;給 node 一個分數，選擇最高分的 node&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;pod&#34;&gt;Pod&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Kubernetes 的最小單位&lt;/li&gt;
&lt;li&gt;一個 Pod 封裝一個應用程式，可能包含一個或多個 container&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;replicaset&#34;&gt;ReplicaSet&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;新版本的 Replication Controller&lt;/li&gt;
&lt;li&gt;yaml
&lt;ul&gt;
&lt;li&gt;spec
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;template&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;指定要創建的 Pod 的 template&lt;/li&gt;
&lt;li&gt;把 pod 的 metadata 和 spec 都放在這裡&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;replicas&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;指定要創建的 Pod 的數量&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;selector&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;指定要選擇的 Pod&lt;/li&gt;
&lt;li&gt;需要這個是因為 ReplicaSet 也可以管理那些不是他創建的 Pod&lt;/li&gt;
&lt;li&gt;&lt;code&gt;matchLabels&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;指定要選擇的 Pod 的 label&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;command
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;kubectl scale --replicas=3 -f &amp;lt;file&amp;gt;&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;scale up/down replicas&lt;/li&gt;
&lt;li&gt;這樣不會修改檔案，所以檔案的如果原本是 2，檔案依然會寫 2，只是 replicas 會變成 3&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kubectl scale --replicas=3 replicaset &amp;lt;name&amp;gt;&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;scale up/down replicas&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kubectl edit replicaset &amp;lt;name&amp;gt;&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;想要 scale up/down replicas 也可以用這個，他會立刻生效&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;簡寫
&lt;ul&gt;
&lt;li&gt;rs&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;deployment&#34;&gt;Deployment&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;管理 ReplicaSet 和 Replica Controller&lt;/li&gt;
&lt;li&gt;yaml 和 ReplicaSet 很像，把 kind 從 ReplicaSet 改成 Deployment 就好
&lt;ul&gt;
&lt;li&gt;會自動創建 ReplicaSet&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;使用情境
&lt;ol&gt;
&lt;li&gt;Rolling update&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;想要更新每個 Pod，但不是同時更新，而是一個一個更新，確保不會有 downtime&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;Rollback&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;如果更新失敗，可以回到之前的版本&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;Pause and Resume&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;當需要做 multiple changes，不想要一下指令就馬上做，可以先 pause，等所有指令下完再 resume&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;rollout
&lt;ul&gt;
&lt;li&gt;創建 Deployment 的時候，會自動創建一個 rollout&lt;/li&gt;
&lt;li&gt;創建一個 rollout 的時候，會自動創建一個 Deployment revision&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Deployment Strategy
&lt;ul&gt;
&lt;li&gt;Recreate
&lt;ul&gt;
&lt;li&gt;先刪除所有舊的 Pod，再創建新的 Pod&lt;/li&gt;
&lt;li&gt;中間會有 Application downtime&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Rolling Update
&lt;ul&gt;
&lt;li&gt;一個一個更新 Pod&lt;/li&gt;
&lt;li&gt;這個是預設的 strategy&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;command
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;kubectl rollout status deployment &amp;lt;name&amp;gt;&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;查看 rollout 的狀態&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kubectl rollout history deployment &amp;lt;name&amp;gt;&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;查看 rollout 的 history (revision)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kubectl rollout undo deployment &amp;lt;name&amp;gt;&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;回到上一個 revision&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;簡寫
&lt;ul&gt;
&lt;li&gt;deploy&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;service&#34;&gt;Service&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;讓不同 group 的 Pod 互相通信&lt;/li&gt;
&lt;li&gt;像一個 virtaul server，可以連接到一個或多個 Pod&lt;/li&gt;
&lt;li&gt;每個 Node 都有一個 kube-proxy，他會檢查有沒有新的 service，並維護 iptables&lt;/li&gt;
&lt;li&gt;type
&lt;ul&gt;
&lt;li&gt;NodePort
&lt;ul&gt;
&lt;li&gt;會在每個 node 上開一個 port，讓外部可以連進來&lt;/li&gt;
&lt;li&gt;default valid port range: 30000-32767&lt;/li&gt;
&lt;li&gt;yaml
&lt;ul&gt;
&lt;li&gt;spec
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;type&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ports&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;port&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;service 的 port&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;targetPort&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;pod 的 port&lt;/li&gt;
&lt;li&gt;如果不設置，會用 &lt;code&gt;port&lt;/code&gt; 的值&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;nodePort&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;如果不設置，會從 default port range 選一個&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;selector&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;指定要連接的 Pod&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;預設會用 load balancing，策略是 Random，像是一個內建的 load balancer&lt;/li&gt;
&lt;li&gt;如果有在同個 cluster 跨 node 的情況，不需要其他設定，就可以創建一個跨 node 的 service，會幫他們都設同一個 nodePort&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;ClusterIP
&lt;ul&gt;
&lt;li&gt;只有在 cluster 內部可以連進來&lt;/li&gt;
&lt;li&gt;用來幫某一組的 pod 提供一個統一的界面並做轉發&lt;/li&gt;
&lt;li&gt;不能依賴 internal IP，因為每個 pod 都有可能會 down 或 up&lt;/li&gt;
&lt;li&gt;yaml
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;spec&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;type&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ports&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;port&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;targetPort&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;selector&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;service 可以用 cluster IP 或是 service name 來連接&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;LoadBalancer
&lt;ul&gt;
&lt;li&gt;會在 cloud provider 上開一個 load balancer&lt;/li&gt;
&lt;li&gt;nodePort 的 load balancer 是在 node 內部的，現在是要幫多個 node 做 load balancing&lt;/li&gt;
&lt;li&gt;這只有在 cloud provider 上才有&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;name 很重要，因為其他的 Pod 會用這個 name 來連接 (就像 domain name)&lt;/li&gt;
&lt;li&gt;簡寫
&lt;ul&gt;
&lt;li&gt;svc&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;yaml&#34;&gt;YAML&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Kubernetes 的配置文件&lt;/li&gt;
&lt;li&gt;root level properties
&lt;ul&gt;
&lt;li&gt;apiVersion
&lt;ul&gt;
&lt;li&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;kind&lt;/th&gt;
&lt;th&gt;apiVersion&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Pod&lt;/td&gt;
&lt;td&gt;v1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Service&lt;/td&gt;
&lt;td&gt;v1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ReplicaSet&lt;/td&gt;
&lt;td&gt;apps/v1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Deployment&lt;/td&gt;
&lt;td&gt;apps/v1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;kind
&lt;ul&gt;
&lt;li&gt;Pod, Service, ReplicaSet, Deployment&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;metadata
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;name&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;labels&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;可以加入任何 key-value pair&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;spec
&lt;ul&gt;
&lt;li&gt;specification section&lt;/li&gt;
&lt;li&gt;pod
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;containers&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;name&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;image&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;env&lt;/code&gt;: list of environment variables
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;name&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;value&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;tool&#34;&gt;Tool&lt;/h2&gt;
&lt;h3 id=&#34;kubectl&#34;&gt;kubectl&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;kubectl&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;用來 deploy、inspect、manage application on a Kubernetes cluster&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;commands
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;kubectl run &amp;lt;name&amp;gt; --image=&amp;lt;image&amp;gt;&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;創建一個 Pod&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kubectl get pods&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;查看所有 Podllll&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-o wide&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;顯示更多資訊&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;column
&lt;ul&gt;
&lt;li&gt;READY
&lt;ul&gt;
&lt;li&gt;&lt;!-- raw HTML omitted --&gt;/&lt;!-- raw HTML omitted --&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;也可以用 &lt;code&gt;kubectl get all&lt;/code&gt; 來查看 Pod、Service、ReplicaSet、Deployment&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kubectl describe pod &amp;lt;name&amp;gt;&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;查看 Pod 的詳細資訊&lt;/li&gt;
&lt;li&gt;欄位
&lt;ul&gt;
&lt;li&gt;Node
&lt;ul&gt;
&lt;li&gt;Pod 在哪個 Node 上運行，包含了 Node 的 IP&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;IP
&lt;ul&gt;
&lt;li&gt;Pod 的 IP&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kubectl delete pod &amp;lt;name&amp;gt;&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;刪除 Pod&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kubectl create -f &amp;lt;file&amp;gt;&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;根據 YAML file 創建 resource&lt;/li&gt;
&lt;li&gt;如果 resource 已經存在，會報錯&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kubectl apply -f &amp;lt;file&amp;gt;&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;根據 YAML file 創建 resource&lt;/li&gt;
&lt;li&gt;如果 resource 已經存在，會更新 resource&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kubectl replace -f &amp;lt;file&amp;gt;&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;根據 YAML file 創建 resource&lt;/li&gt;
&lt;li&gt;如果 resource 已經存在，會刪除舊的 resource，並創建新的 resource&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kubectl edit replicaset &amp;lt;name&amp;gt;&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;可以直接編輯 Replica Set 的 yaml 檔，但他不是一開始創建用的檔案，而是 Kubernetes 在 memory 暫時生成的&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;kubectl set image deployment &amp;lt;name&amp;gt; &amp;lt;container-name&amp;gt;=&amp;lt;new-image&amp;gt;&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;更新 Deployment 的 image&lt;/li&gt;
&lt;li&gt;注意這裡是 Container name，不是 Pod name&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--record=true&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;會記錄每次的操作&lt;/li&gt;
&lt;li&gt;用在 rollout 的時候，可以看到每次的操作，不然會顯示 &lt;!-- raw HTML omitted --&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;minikube&#34;&gt;minikube&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;用來在 local machine 上建立一個 single-node cluster&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;kubeadm&#34;&gt;kubeadm&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;用來在多個 node 上建立 cluster&lt;/li&gt;
&lt;li&gt;在多個 node 上安裝 Kubernetes
&lt;ul&gt;
&lt;li&gt;流程
&lt;ol&gt;
&lt;li&gt;安裝 container runtime&lt;/li&gt;
&lt;li&gt;安裝 kubeadm&lt;/li&gt;
&lt;li&gt;初始化 master node&lt;/li&gt;
&lt;li&gt;建立 pod network&lt;/li&gt;
&lt;li&gt;加入 worker node&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;networking&#34;&gt;Networking&lt;/h2&gt;
&lt;h3 id=&#34;cluster-networking&#34;&gt;Cluster Networking&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;每個 Pod 都有自己的 IP&lt;/li&gt;
&lt;li&gt;兩個不同屬於同一個 cluster 的 Pod 可能會有相同的 IP&lt;/li&gt;
&lt;li&gt;Kubernetes 要求所有的 Pod 要可以在不用 NAT 的情況下互相通信
&lt;ul&gt;
&lt;li&gt;所有的 container 和 node 都要可以在沒有 NAT 的情況下互相通信&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;可以用 Calico 等方案實現
&lt;ul&gt;
&lt;li&gt;他會把每個 node network 都設成不同的，底下的 pod IP 自然就不會重複&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Angular 筆記</title>
        <link>https://roykesydon.github.io/Blog/p/angular-%E7%AD%86%E8%A8%98/</link>
        <pubDate>Fri, 24 May 2024 00:00:17 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/angular-%E7%AD%86%E8%A8%98/</guid>
        <description>&lt;h2 id=&#34;基礎概念&#34;&gt;基礎概念&lt;/h2&gt;
&lt;h3 id=&#34;module&#34;&gt;Module&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;把相關的 Component、Directive、Pipe、Service 等打包在一起的容器&lt;/li&gt;
&lt;li&gt;Lazy Loading&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;component&#34;&gt;Component&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Angular 應用程式的基本組成單位&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;pipe&#34;&gt;Pipe&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;用來轉換資料的工具，可以把字串格式化、日期格式化等&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;directive&#34;&gt;Directive&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;用來修改 DOM 元素的外觀或行為
&lt;ul&gt;
&lt;li&gt;比如說 ngIf、ngFor、ngStyle、ngClass&lt;/li&gt;
&lt;li&gt;類型
&lt;ul&gt;
&lt;li&gt;Structural Directive: 修改 DOM 的結構
&lt;ul&gt;
&lt;li&gt;可以搭配
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ng-container&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;不會產生額外的 DOM 元素，可以用在想要用 ngIf 和 ngFor 但不想產生額外元素的情況&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;*ngFor&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;let item of items; index as i&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Attribute Directive: 修改 DOM 的屬性&lt;/li&gt;
&lt;li&gt;Component Directive: 包含 template 的 directive&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;service&#34;&gt;Service&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;負責 API 請求、資料處理等工作&lt;/li&gt;
&lt;li&gt;Dependency Injection&lt;/li&gt;
&lt;li&gt;@Injectable
&lt;ul&gt;
&lt;li&gt;providedIn
&lt;ul&gt;
&lt;li&gt;root: 全域共用&lt;/li&gt;
&lt;li&gt;也可以在 component 的 providers 中設定要注入的 service&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;router&#34;&gt;Router&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;負責處理 URL 路由&lt;/li&gt;
&lt;li&gt;routes
&lt;ul&gt;
&lt;li&gt;path&lt;/li&gt;
&lt;li&gt;component&lt;/li&gt;
&lt;li&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;guard
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ng g guard &amp;lt;guard-name&amp;gt;&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;h2 id=&#34;canactivate&#34;&gt;CanActivate&lt;/h2&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;cli-command&#34;&gt;CLI Command&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ng new my-app&lt;/code&gt;: 建立新的 Angular 專案&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ng serve&lt;/code&gt;: 啟動開發伺服器&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ng build&lt;/code&gt;: 打包專案&lt;/li&gt;
&lt;li&gt;generate
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ng generate module my-module&lt;/code&gt;: 建立新的 Module&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ng generate component my-component&lt;/code&gt;: 建立新的 Component
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--module=app&lt;/code&gt;: 指定 Component 所屬的 Module&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ng generate service my-service&lt;/code&gt;: 建立新的 Service&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ng generate pipe my-pipe&lt;/code&gt;: 建立新的 Pipe&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ng generate directive my-directive&lt;/code&gt;: 建立新的 Directive&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;module-1&#34;&gt;Module&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;NgModule
&lt;ul&gt;
&lt;li&gt;declarations: 定義同一 Module 中的 Component、Directive、Pipe&lt;/li&gt;
&lt;li&gt;imports: 匯入其他 Module&lt;/li&gt;
&lt;li&gt;providers: 定義 Service&lt;/li&gt;
&lt;li&gt;bootstrap: 定義啟動的 Component&lt;/li&gt;
&lt;li&gt;exports: 定義要匯出的 Component、Directive、Pipe&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;component-1&#34;&gt;Component&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;包含元素
&lt;ul&gt;
&lt;li&gt;Template&lt;/li&gt;
&lt;li&gt;TypeScript Class
&lt;ul&gt;
&lt;li&gt;.spec.ts: 測試檔&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Selector: 定義 Component 的名稱&lt;/li&gt;
&lt;li&gt;CSS Style&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;standalone
&lt;ul&gt;
&lt;li&gt;新版 Angular 預設 app 使用 Standalone 模式，使 component 不再需要透過 NgModule 管理&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lifecycle-hooks&#34;&gt;Lifecycle Hooks&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;ngOnChanges
&lt;ul&gt;
&lt;li&gt;當 Angular 重新綁定輸入屬性時調用&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;ngOnInit
&lt;ul&gt;
&lt;li&gt;當 Angular 初始化指令/元件時調用&lt;/li&gt;
&lt;li&gt;在第一輪 ngOnChanges 後調用&lt;/li&gt;
&lt;li&gt;只調用一次&lt;/li&gt;
&lt;li&gt;使用場景
&lt;ul&gt;
&lt;li&gt;初始化資料（需要根據 @Input 變數）&lt;/li&gt;
&lt;li&gt;fetch data from API&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;ngDoCheck
&lt;ul&gt;
&lt;li&gt;在 ngOnChange 和 ngOnInit 之後調用&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;ngAfterContentInit
&lt;ul&gt;
&lt;li&gt;在 Angular 把 ng-content 投影到 view 後調用&lt;/li&gt;
&lt;li&gt;在第一個 ngDoCheck 之後調用&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;ngAfterContentChecked
&lt;ul&gt;
&lt;li&gt;在 ng-content 的內容變更後調用&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;ngAfterViewInit
&lt;ul&gt;
&lt;li&gt;在 Angular 初始化完 view 後調用&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;ngAfterViewChecked
&lt;ul&gt;
&lt;li&gt;在每次做完 view 的變更檢查後調用&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;ngOnDestroy
&lt;ul&gt;
&lt;li&gt;在 Angular 銷毀 directive/component 前調用&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;component-check&#34;&gt;Component check&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;操作
&lt;ul&gt;
&lt;li&gt;update child component input binding&lt;/li&gt;
&lt;li&gt;update DOM interpolation&lt;/li&gt;
&lt;li&gt;update query list&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;sharing-data&#34;&gt;Sharing Data&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;@Input
&lt;ul&gt;
&lt;li&gt;父元件傳遞資料給子元件&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;@Output
&lt;ul&gt;
&lt;li&gt;子元件傳遞資料給父元件&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;binding&#34;&gt;Binding&lt;/h2&gt;
&lt;h3 id=&#34;property-binding&#34;&gt;Property Binding&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;用來設定 HTML 元素的屬性&lt;/li&gt;
&lt;li&gt;用中括號 &lt;code&gt;[]&lt;/code&gt; 包住屬性名稱&lt;/li&gt;
&lt;li&gt;ex: &lt;code&gt;&amp;lt;img [src]=&amp;quot;imageUrl&amp;quot;&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;event-binding&#34;&gt;Event Binding&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;用來設定 HTML 元素的事件&lt;/li&gt;
&lt;li&gt;用小括號 &lt;code&gt;()&lt;/code&gt; 包住事件名稱&lt;/li&gt;
&lt;li&gt;ex: &lt;code&gt;&amp;lt;button (click)=&amp;quot;onClick()&amp;quot;&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;$event&lt;/code&gt;: 可以取得事件物件&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;two-way-binding&#34;&gt;Two-way Binding&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;把屬性和事件綁定在一起&lt;/li&gt;
&lt;li&gt;用中括號和小括號 &lt;code&gt;[(ngModel)]&lt;/code&gt; 包住屬性名稱&lt;/li&gt;
&lt;li&gt;ex: &lt;code&gt;&amp;lt;input [(ngModel)]=&amp;quot;name&amp;quot;&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Spring Boot 筆記</title>
        <link>https://roykesydon.github.io/Blog/p/spring-boot-%E7%AD%86%E8%A8%98/</link>
        <pubDate>Mon, 06 May 2024 00:00:17 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/spring-boot-%E7%AD%86%E8%A8%98/</guid>
        <description>&lt;h2 id=&#34;maven&#34;&gt;Maven&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;專案管理工具&lt;/li&gt;
&lt;li&gt;會先檢查 maven local repository 有沒有需要的 dependency，沒有的話就會去 maven central repository (remote repository) 下載&lt;/li&gt;
&lt;li&gt;pom.xml
&lt;ul&gt;
&lt;li&gt;project cooridnate
&lt;ul&gt;
&lt;li&gt;groupId&lt;/li&gt;
&lt;li&gt;artifactId&lt;/li&gt;
&lt;li&gt;version&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;plugin
&lt;ul&gt;
&lt;li&gt;和 dependency 的差別是，是用來執行某種 task 的&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;mvnw
&lt;ul&gt;
&lt;li&gt;maven wrapper&lt;/li&gt;
&lt;li&gt;在沒有安裝 maven 的環境下，會下載正確的 maven 版本&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;spring&#34;&gt;Spring&lt;/h2&gt;
&lt;h3 id=&#34;ioc&#34;&gt;IoC&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Invocation of Constructor
&lt;ul&gt;
&lt;li&gt;把物件交給 Spring 管理&lt;/li&gt;
&lt;li&gt;loose coupling&lt;/li&gt;
&lt;li&gt;Dependency Injection&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Bean
&lt;ul&gt;
&lt;li&gt;給 Spring 管理的物件&lt;/li&gt;
&lt;li&gt;創建方法
&lt;ul&gt;
&lt;li&gt;@Component
&lt;ul&gt;
&lt;li&gt;創建出的 Bean 名字是 class 的開頭轉小寫&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;注入方法
&lt;ul&gt;
&lt;li&gt;@Autowired
&lt;ul&gt;
&lt;li&gt;種類
&lt;ul&gt;
&lt;li&gt;field injection
&lt;ul&gt;
&lt;li&gt;不太推薦，不利於 unit test&lt;/li&gt;
&lt;li&gt;spring boot 會先建立所有 component，在逐一注入，使元件可能短暫處於初始化不完整狀態&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;constructor injection
&lt;ul&gt;
&lt;li&gt;最推薦&lt;/li&gt;
&lt;li&gt;建立 bean 時就注入&lt;/li&gt;
&lt;li&gt;確保 component 被使用時是處於完整的狀態&lt;/li&gt;
&lt;li&gt;有利於 unit test，因為可以把設計好的 mock bean 從 constructor 傳入&lt;/li&gt;
&lt;li&gt;spring 建議使用 constructor injection&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;setter injection
&lt;ul&gt;
&lt;li&gt;用 setter 來注入&lt;/li&gt;
&lt;li&gt;創好 component 後，再注入&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;限制
&lt;ol&gt;
&lt;li&gt;該 Class 也得是 Bean&lt;/li&gt;
&lt;li&gt;會根據類型注入 bean
&lt;ul&gt;
&lt;li&gt;如果同時有多個同類型的 bean，會報錯，可以用 @Qualifier 指定要注入的 bean 名稱&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;@Qualifier
&lt;ul&gt;
&lt;li&gt;指定要注入的 bean 名稱&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;@Primary
&lt;ul&gt;
&lt;li&gt;如果有多個同類型的 bean，會優先注入這個 bean&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Cycle life
&lt;ul&gt;
&lt;li&gt;@PostConstruct
&lt;ul&gt;
&lt;li&gt;創建 bean 後，就會執行這個方法&lt;/li&gt;
&lt;li&gt;限制
&lt;ul&gt;
&lt;li&gt;必須是 public void&lt;/li&gt;
&lt;li&gt;不能有參數&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;@PreDestroy
&lt;ul&gt;
&lt;li&gt;bean 被銷毀前執行&lt;/li&gt;
&lt;li&gt;限制
&lt;ul&gt;
&lt;li&gt;必須是 public void&lt;/li&gt;
&lt;li&gt;不能有參數&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Lazy Initialization
&lt;ul&gt;
&lt;li&gt;本來 beans 不管有沒有用都會被創建&lt;/li&gt;
&lt;li&gt;@Lazy
&lt;ul&gt;
&lt;li&gt;只有在要使用時才會初始化&lt;/li&gt;
&lt;li&gt;缺點是用 @RestController 的話，第一次 request 才會創建&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;可以在 application.properties 裡設定 spring.main.lazy-initialization=true，讓所有 beans 都變成 lazy initialization&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;aop&#34;&gt;AOP&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Aspect Oriented Programming&lt;/li&gt;
&lt;li&gt;透過 Aspect 統一處理不同方法的共同邏輯&lt;/li&gt;
&lt;li&gt;要導入 aop 的 starter&lt;/li&gt;
&lt;li&gt;只有 Bean 才能設置 @Aspect&lt;/li&gt;
&lt;li&gt;Annotation
&lt;ul&gt;
&lt;li&gt;@Aspect
&lt;ul&gt;
&lt;li&gt;這個 class 是一個切面&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;@Before
&lt;ul&gt;
&lt;li&gt;加上切入點，就可以在切入點 (Pointcut) 的方法執行前執行&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;@After
&lt;ul&gt;
&lt;li&gt;在方法之後執行&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;@Around
&lt;ul&gt;
&lt;li&gt;在方法之前和之後都執行&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;常用的功能都已經被封裝好了，開發較少用到 AOP&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;run-app&#34;&gt;Run app&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;use &lt;code&gt;java -jar&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;mvn clean package&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;java -jar target/xxx.jar&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;use &lt;code&gt;mvn spring-boot:run&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;mvn spring-boot:run&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;特性&#34;&gt;特性&lt;/h2&gt;
&lt;h3 id=&#34;starter&#34;&gt;Starter&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#using.build-systems.starters&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Spring Boot Starters&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;官方的 starter 命名是 &lt;code&gt;spring-boot-starter-*&lt;/code&gt;
第三方的 starter 命名是 &lt;code&gt;*-spring-boot-starter&lt;/code&gt;&lt;/p&gt;
&lt;h3 id=&#34;外部化配置&#34;&gt;外部化配置&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;application.properties&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;重新啟動 jar 時會自動載入，不用改配置要重新 build jar&lt;/li&gt;
&lt;li&gt;集中管理&lt;/li&gt;
&lt;li&gt;@Value
&lt;ul&gt;
&lt;li&gt;可以注入到變數中&lt;/li&gt;
&lt;li&gt;可以用 &lt;code&gt;:&lt;/code&gt; 來設定預設值&lt;/li&gt;
&lt;li&gt;限制
&lt;ul&gt;
&lt;li&gt;只能在 Bean 和 Configuration 中使用&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;YAML
&lt;ul&gt;
&lt;li&gt;application.properties 寫多後，沒有層級辨識度&lt;/li&gt;
&lt;li&gt;application.yml&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;profiles
&lt;ul&gt;
&lt;li&gt;可以根據不同的環境來設定不同的配置 (dev, test, prod)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;application-{profile}.properties&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;application-{profile}.yml&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;spring.profiles.active&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;指定啟用的 profile&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;jar
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;-Dspring.profiles.active=dev&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;指定配置文件
&lt;ul&gt;
&lt;li&gt;cli
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--spring.config.location&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Config 資料夾
&lt;ul&gt;
&lt;li&gt;可以在 jar 目錄下建立 config 資料夾，放配置文件，不用輸入額外的 args&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;大致分類
&lt;ul&gt;
&lt;li&gt;core
&lt;ul&gt;
&lt;li&gt;logging&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;web&lt;/li&gt;
&lt;li&gt;security&lt;/li&gt;
&lt;li&gt;data&lt;/li&gt;
&lt;li&gt;actuator&lt;/li&gt;
&lt;li&gt;integration&lt;/li&gt;
&lt;li&gt;devtools&lt;/li&gt;
&lt;li&gt;test&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;dependency-management&#34;&gt;Dependency Management&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;parent 寫了版本號，故 dependency 可以不用寫版本號&lt;/li&gt;
&lt;li&gt;真的要指定的話，可以利用 maven 的就近原則&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;auto-configuration&#34;&gt;Auto Configuration&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Component Scan
&lt;ul&gt;
&lt;li&gt;Spring Boot 會掃描主程式所在的 package 以及子 package&lt;/li&gt;
&lt;li&gt;也可以在主程式上加以下註解來指定掃描的 package
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;@SpringBootApplication(scanBasePackages = &amp;quot;com.example&amp;quot;)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;所有 starter 都有 &lt;code&gt;spring-boot-starter&lt;/code&gt;，&lt;code&gt;spring-boot-starter&lt;/code&gt; 又有 &lt;code&gt;spring-boot-autoconfigure&lt;/code&gt;，這個就是自動配置的地方&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;spring boot 默認掃描不到 spring-boot-autoconfigure 的所有配置類 (因為預設只掃描 Main Application Class 的 package)，但是 @SpringBootApplication 的 @EnableAutoConfiguration 會預設掃描 spring-boot-autoconfigure 的所有配置類
&lt;ul&gt;
&lt;li&gt;它們再依據 conditional annotation 來決定是否要啟用這個配置類&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;common-annotations&#34;&gt;Common Annotations&lt;/h2&gt;
&lt;p&gt;Spring Boot 放棄了 XML 配置，改用 Annotation 配置&lt;/p&gt;
&lt;h3 id=&#34;component-registration&#34;&gt;Component registration&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;@Configuration, @SpringBootConfiguration
&lt;ul&gt;
&lt;li&gt;@Bean
&lt;ul&gt;
&lt;li&gt;有時候可能會想用第三方套件，此時可能不能修改套件的 code，這時候就可以用 @Configuration 來註冊 bean&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;@Controller, @Service, @Repository, @Component
&lt;ul&gt;
&lt;li&gt;三層式架構
&lt;ul&gt;
&lt;li&gt;@Controller
&lt;ul&gt;
&lt;li&gt;用來處理請求&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;@Service
&lt;ul&gt;
&lt;li&gt;用來處理業務邏輯&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;@Repository
&lt;ul&gt;
&lt;li&gt;用來處理資料庫操作&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;@SpringBootApplication
&lt;ul&gt;
&lt;li&gt;由以下組成
&lt;ul&gt;
&lt;li&gt;@SpringBootConfiguration&lt;/li&gt;
&lt;li&gt;@EnableAutoConfiguration&lt;/li&gt;
&lt;li&gt;@ComponentScan&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Web
&lt;ul&gt;
&lt;li&gt;@RestController
&lt;ul&gt;
&lt;li&gt;@Controller + @ResponseBody&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;@RequestMapping
&lt;ul&gt;
&lt;li&gt;設置 route&lt;/li&gt;
&lt;li&gt;Method
&lt;ul&gt;
&lt;li&gt;@GetMapping&lt;/li&gt;
&lt;li&gt;@PostMapping&lt;/li&gt;
&lt;li&gt;@PutMapping&lt;/li&gt;
&lt;li&gt;@DeleteMapping&lt;/li&gt;
&lt;li&gt;@PatchMapping&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;取得參數
&lt;ul&gt;
&lt;li&gt;@RequestParam
&lt;ul&gt;
&lt;li&gt;取得 url 中的參數&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;@RequestBody
&lt;ul&gt;
&lt;li&gt;取得 request body&lt;/li&gt;
&lt;li&gt;根據欄位名字調用對應的 setter&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;@RequestHeader
&lt;ul&gt;
&lt;li&gt;取得 header&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;@PathVariable
&lt;ul&gt;
&lt;li&gt;取得 route 中的參數&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;@Scope
&lt;ul&gt;
&lt;li&gt;mode
&lt;ul&gt;
&lt;li&gt;singleton
&lt;ul&gt;
&lt;li&gt;預設，共用一個 instance&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;prototype
&lt;ul&gt;
&lt;li&gt;每次注入都創建新的 instance&lt;/li&gt;
&lt;li&gt;可以用 proxy.mode = ScopedProxyMode.TARGET_CLASS，會變成每次調用 method 都創建新的 instance&lt;/li&gt;
&lt;li&gt;prototype 的元件生出後，spring 不會再管理，要自己管理生命週期，相當於 new 出物件的替代作法&lt;/li&gt;
&lt;li&gt;預設是 lazy initialization&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;request
&lt;ul&gt;
&lt;li&gt;每個 request 都有一個獨立的 instance&lt;/li&gt;
&lt;li&gt;request 指的是 HTTP request，從進入 controller 到離開 controller&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;session
&lt;ul&gt;
&lt;li&gt;每個 session 都有一個獨立的 instance&lt;/li&gt;
&lt;li&gt;session 指的是 HTTP session，從進入 controller 到離開 controller&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;conditional-annotations&#34;&gt;Conditional Annotations&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;條件成立則觸發指定行為&lt;/li&gt;
&lt;li&gt;ConditionalOn&lt;!-- raw HTML omitted --&gt;
&lt;ul&gt;
&lt;li&gt;example
&lt;ul&gt;
&lt;li&gt;ConditionalOnClass
&lt;ul&gt;
&lt;li&gt;如果 classpath 有指定的 class 才會觸發&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;ConditionalOnMissingClass
&lt;ul&gt;
&lt;li&gt;如果 classpath 沒有指定的 class 才會觸發&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;ConditionalOnBean
&lt;ul&gt;
&lt;li&gt;如果容器中有指定的 bean 才會觸發&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;ConditionalOnMissingBean
&lt;ul&gt;
&lt;li&gt;如果容器中沒有指定的 bean 才會觸發&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Scenario
&lt;ul&gt;
&lt;li&gt;如果有某個 dependency，則創建某個 bean&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;property-binding&#34;&gt;Property Binding&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;把任意 Bean 的 property 與配置文件 (application.properties) 中的 property 綁定&lt;/li&gt;
&lt;li&gt;annotations
&lt;ul&gt;
&lt;li&gt;@ConfigurationProperties
&lt;ul&gt;
&lt;li&gt;prefix&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;@EnableConfigurationProperties
&lt;ul&gt;
&lt;li&gt;如果 class 只有 @ConfigurationProperties，沒有 @Component，需要加這個 annotation&lt;/li&gt;
&lt;li&gt;用在第三方 package 上，因為默認掃不到第三方的 @component&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;java-json-data-binding&#34;&gt;Java JSON Data Binding&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;在 Java POJO 和 JSON 之間轉換&lt;/li&gt;
&lt;li&gt;Spring 用 Jackson 來做轉換
&lt;ul&gt;
&lt;li&gt;Jackson 會 call getter, setter 來轉換&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;alias
&lt;ul&gt;
&lt;li&gt;mapping&lt;/li&gt;
&lt;li&gt;marshalling&lt;/li&gt;
&lt;li&gt;serialization&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;輔助工具&#34;&gt;輔助工具&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Spring boot devtools
&lt;ul&gt;
&lt;li&gt;Hot reload&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Spring Boot Actuator
&lt;ul&gt;
&lt;li&gt;公開用來 monitor 的 endpoint&lt;/li&gt;
&lt;li&gt;endpoints
&lt;ul&gt;
&lt;li&gt;都有固定前綴 /actuator&lt;/li&gt;
&lt;li&gt;/health
&lt;ul&gt;
&lt;li&gt;查看應用程式的 status&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;/info
&lt;ul&gt;
&lt;li&gt;查看應用程式的 info&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;/beans
&lt;ul&gt;
&lt;li&gt;查看所有 bean&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;logging&#34;&gt;Logging&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Logging 選擇&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Logging API
&lt;ul&gt;
&lt;li&gt;JCL&lt;/li&gt;
&lt;li&gt;SLF4J (Simple Logging Facade for Java)&lt;/li&gt;
&lt;li&gt;jboss-logging&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Logging implementation
&lt;ul&gt;
&lt;li&gt;Logback&lt;/li&gt;
&lt;li&gt;Log4j2&lt;/li&gt;
&lt;li&gt;JUL (java.util.logging)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Spring Boot 預設使用 Logback 和 SLF4J&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;spring-boot-starter 引用了 spring-boot-starter-logging&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;log-format&#34;&gt;Log Format&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Default example
&lt;ul&gt;
&lt;li&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;2024-05-06T19:21:40.751+08:00  INFO 22932 --- [demo] [           main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port 8080 (http) with context path &amp;#39;&amp;#39;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;時間, 日誌等級, pid, 分割符, thread, logger, message&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;log-level&#34;&gt;Log Level&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Type (由低到高)
&lt;ul&gt;
&lt;li&gt;ALL&lt;/li&gt;
&lt;li&gt;TRACE
&lt;ul&gt;
&lt;li&gt;一般不用&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;DEBUG&lt;/li&gt;
&lt;li&gt;INFO&lt;/li&gt;
&lt;li&gt;WARN&lt;/li&gt;
&lt;li&gt;ERROR&lt;/li&gt;
&lt;li&gt;FATAL&lt;/li&gt;
&lt;li&gt;OFF&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;會 print 出比設定的等級高的 log&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;log-configuration&#34;&gt;Log Configuration&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;logging.level.*&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;設定不同 package 的 log 等級&lt;/li&gt;
&lt;li&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;logging.level.com.example=DEBUG
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;logging.group.&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;把多個 package 放在一組，可以統一設定&lt;/li&gt;
&lt;li&gt;預設有 web, sql 組&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;logging.file&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;.name
&lt;ul&gt;
&lt;li&gt;檔名&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;歸檔 and 切割&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;歸檔
&lt;ul&gt;
&lt;li&gt;每天單獨存&lt;/li&gt;
&lt;li&gt;.logback.rolllingpolicy.file-name-pattern&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;切割
&lt;ul&gt;
&lt;li&gt;超過指定大小就切割&lt;/li&gt;
&lt;li&gt;.logback.rolllingpolicy.max-file-size&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;filter&#34;&gt;Filter&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;實做 javax.servlet.Filter，就能註冊為 spring 的 filter&lt;/li&gt;
&lt;li&gt;OncePerRequestFilter
&lt;ul&gt;
&lt;li&gt;保證一次 request 只會執行一次&lt;/li&gt;
&lt;li&gt;doFilterInternal
&lt;ul&gt;
&lt;li&gt;chain.doFilter(request, response)
&lt;ul&gt;
&lt;li&gt;這行之後代表後面的 filter 都執行完了&lt;/li&gt;
&lt;li&gt;如果只有一個 filter，就代表 controller 執行完了&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;shouldNotFilter
&lt;ul&gt;
&lt;li&gt;可以設定不要執行的 url pattern&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;註冊-filter&#34;&gt;註冊 Filter&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;流程&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;設定 @Configuration&lt;/li&gt;
&lt;li&gt;加到 Bean
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;option&amp;gt;&lt;/code&gt; setUrlPatterns
&lt;ul&gt;
&lt;li&gt;只有符合 url pattern 的 request 才會經過這個 filter&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;option&amp;gt;&lt;/code&gt; setOrder
&lt;ul&gt;
&lt;li&gt;決定 filter 的順序&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果 filter 要取得 request 和 response 的內容，可以用 ContentCachingRequestWrapper 和 ContentCachingResponseWrapper 重新包裝&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;因為原本的作法是用 stream 讀取資料，只能讀一次&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;@WebFilter&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;屬於 Java servlet 而非 Spring
&lt;ul&gt;
&lt;li&gt;要在 application 補上 @ServletComponentScan&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;可以直接註冊 filter&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;spring-security&#34;&gt;Spring Security&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;名詞
&lt;ul&gt;
&lt;li&gt;Authentication
&lt;ul&gt;
&lt;li&gt;認證
&lt;ul&gt;
&lt;li&gt;檢查是不是系統的使用者，以及是哪個使用者&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Authorization
&lt;ul&gt;
&lt;li&gt;授權
&lt;ul&gt;
&lt;li&gt;檢查使用者有沒有權限做某件事&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;流程&#34;&gt;流程&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;filter chain&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;example
&lt;ul&gt;
&lt;li&gt;UsernamePasswordAuthenticationFilter
&lt;ul&gt;
&lt;li&gt;檢查使用者名稱和密碼&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;ExceptionTranslationFilter
&lt;ul&gt;
&lt;li&gt;處理例外&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;FilterSecurityInterceptor
&lt;ul&gt;
&lt;li&gt;檢查授權&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;authorizeHttpRequests
&lt;ul&gt;
&lt;li&gt;設定哪些 request 需要什麼權限&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;example: JWT 驗證流程&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;先透過 filter chain 經過 JWT filter&lt;/li&gt;
&lt;li&gt;透過 UserDetailsService 取得使用者資訊&lt;/li&gt;
&lt;li&gt;驗證使用者資訊&lt;/li&gt;
&lt;li&gt;更新 SecurityContextHolder
&lt;ul&gt;
&lt;li&gt;用來判斷使用者是否已經通過 authentication&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;configuration&#34;&gt;Configuration&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;@EnableWebSecurity
&lt;ul&gt;
&lt;li&gt;啟用 web security&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;example
&lt;ul&gt;
&lt;li&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nd&#34;&gt;@Configuration&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nd&#34;&gt;@EnableWebSecurity&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;SecurityConfig&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nd&#34;&gt;@Bean&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;SecurityFilterChain&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;securityFilterChain&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;HttpSecurity&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;http&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;throws&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Exception&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;http&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;authorizeHttpRequests&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;requests&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;o&#34;&gt;((&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;AuthorizeHttpRequestsConfigurer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;AuthorizedUrl&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;requests&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;anyRequest&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()).&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;authenticated&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;o&#34;&gt;});&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;http&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;httpBasic&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Customizer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;withDefaults&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;());&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;SecurityFilterChain&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;http&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;build&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;把 Spring Boot 預設實作的 fitler chain 的 @Order 拿掉，這是決定誰的優先序高&lt;/li&gt;
&lt;li&gt;也把 formLogin 拿掉，就不會有登入頁面&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;userdetails&#34;&gt;UserDetails&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;實現 UserDetailsService 的 Bean 可以被用來取得 UserDetails&lt;/li&gt;
&lt;li&gt;implements UserDetails
&lt;ul&gt;
&lt;li&gt;getAuthorities&lt;/li&gt;
&lt;li&gt;getUsername&lt;/li&gt;
&lt;li&gt;getPassword&lt;/li&gt;
&lt;li&gt;isAccountNonExpired&lt;/li&gt;
&lt;li&gt;isAccountNonLocked&lt;/li&gt;
&lt;li&gt;isCredentialsNonExpired&lt;/li&gt;
&lt;li&gt;isEnabled&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;securitycontextholder&#34;&gt;SecurityContextHolder&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;用來存放 authentication&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;commandlinerunner&#34;&gt;CommandLineRunner&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;用來在 Spring Boot 啟動後執行一些任務&lt;/li&gt;
&lt;li&gt;會在所有 bean 創建完後執行&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;jpa&#34;&gt;JPA&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Jakarta Persistence API&lt;/li&gt;
&lt;li&gt;以前叫 Java Persistence API&lt;/li&gt;
&lt;li&gt;只是一個 specifcation，提供一組 interface，需要實作
&lt;ul&gt;
&lt;li&gt;包含了 Entity, EntityManager, Query, Transaction..&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;DataSource
&lt;ul&gt;
&lt;li&gt;用來連接資料庫&lt;/li&gt;
&lt;li&gt;定義了連接資料庫的 info&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;EntityManager
&lt;ul&gt;
&lt;li&gt;用來創建 query 的主要 component&lt;/li&gt;
&lt;li&gt;需要 DataSource&lt;/li&gt;
&lt;li&gt;EntityManager vs JpaRepositroy
&lt;ul&gt;
&lt;li&gt;EntityManager
&lt;ul&gt;
&lt;li&gt;low-level control and flexibility&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;JpaRepository
&lt;ul&gt;
&lt;li&gt;high-level abstraction&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;JPQL
&lt;ul&gt;
&lt;li&gt;基於 Entity name 和 fields 的 query language&lt;/li&gt;
&lt;li&gt;不是基於資料庫的 column 或 table name，是基於 Entity 的名字，要注意區別&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Data access object (DAO)
&lt;ul&gt;
&lt;li&gt;common pattern&lt;/li&gt;
&lt;li&gt;需要 JPA Entity Manager&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Config
&lt;ul&gt;
&lt;li&gt;spring.jpa.hibernate.ddl-auto
&lt;ul&gt;
&lt;li&gt;create
&lt;ul&gt;
&lt;li&gt;每次都會重新創建新的 table&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;update
&lt;ul&gt;
&lt;li&gt;只會更新 table，不會刪除&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;create-drop
&lt;ul&gt;
&lt;li&gt;創建 table，然後刪除&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;validate
&lt;ul&gt;
&lt;li&gt;只會檢查 table 是否存在，不會創建&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Annotation
&lt;ul&gt;
&lt;li&gt;@Entity, @Table
&lt;ul&gt;
&lt;li&gt;也要記得寫 getter, setter&lt;/li&gt;
&lt;li&gt;@Entity 需要 public 或 protected 的無參數建構子&lt;/li&gt;
&lt;li&gt;@Table
&lt;ul&gt;
&lt;li&gt;可選，可以設定 table 名稱&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;@Transient
&lt;ul&gt;
&lt;li&gt;不會被序列化，不會被存到資料庫&lt;/li&gt;
&lt;li&gt;可用在可以單獨計算的欄位，比如用資料庫的生日可以算出年齡&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;@Transactional
&lt;ul&gt;
&lt;li&gt;用在 method 上，代表這個 method 是一個 transaction&lt;/li&gt;
&lt;li&gt;propagation
&lt;ul&gt;
&lt;li&gt;用在 method 上，被別的 transaction 調用應該怎麼處理，講 transaction 的傳播&lt;/li&gt;
&lt;li&gt;REQUIRED
&lt;ul&gt;
&lt;li&gt;如果有外層 transaction 就用，沒有就創建一個&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;REQUIRES_NEW
&lt;ul&gt;
&lt;li&gt;無論有沒有外層 transaction，都創建一個新的，不受影響&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;NESTED
&lt;ul&gt;
&lt;li&gt;嵌套 transaction，如果外層 transaction rollback，內層也會 rollback&lt;/li&gt;
&lt;li&gt;如果自己 rollback，外層不受影響&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;@Column
&lt;ul&gt;
&lt;li&gt;可以設定欄位名稱&lt;/li&gt;
&lt;li&gt;這是可選的，沒有的話就是用變數名稱&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;@Id
&lt;ul&gt;
&lt;li&gt;Primary key&lt;/li&gt;
&lt;li&gt;@GeneratedValue
&lt;ul&gt;
&lt;li&gt;strategy
&lt;ul&gt;
&lt;li&gt;AUTO
&lt;ul&gt;
&lt;li&gt;根據資料庫自動選擇&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;IDENTITY
&lt;ul&gt;
&lt;li&gt;用資料庫的 identity column&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;SEQUENCE
&lt;ul&gt;
&lt;li&gt;用資料庫的 sequence&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Table
&lt;ul&gt;
&lt;li&gt;用 underlying table 來確保唯一性&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;UUID
&lt;ul&gt;
&lt;li&gt;用 UUID 來確保唯一性&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;@OneToMany, @ManyToOne
&lt;ul&gt;
&lt;li&gt;用來設定關聯&lt;/li&gt;
&lt;li&gt;cascade
&lt;ul&gt;
&lt;li&gt;設定當 parent 被刪除時，child 要怎麼處理
&lt;ul&gt;
&lt;li&gt;CascadeType.ALL
&lt;ul&gt;
&lt;li&gt;parent 被刪除時，child 也會被刪除&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;CascadeType.PERSIST
&lt;ul&gt;
&lt;li&gt;parent 被刪除時，child 不會被刪除&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Spring Data JPA
&lt;ul&gt;
&lt;li&gt;用特定語法，只需要定好 interface，不用 implement&lt;/li&gt;
&lt;li&gt;extends JpaRepository&amp;lt;Entity, ID&amp;gt;
&lt;ul&gt;
&lt;li&gt;第一個參數是 entity&lt;/li&gt;
&lt;li&gt;第二個參數是 primary key 的型態&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;示範
&lt;ul&gt;
&lt;li&gt;findByXxx
&lt;ul&gt;
&lt;li&gt;用 XXX 的欄位來查詢&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;findByXXXLike
&lt;ul&gt;
&lt;li&gt;用 XXX 的欄位來模糊查詢&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;jparepository&#34;&gt;JpaRepository&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;@Repository
&lt;ul&gt;
&lt;li&gt;用來標記 DAO&lt;/li&gt;
&lt;li&gt;extends JpaRepository&amp;lt;Entity, ID&amp;gt;
&lt;ul&gt;
&lt;li&gt;第一個參數是 entity&lt;/li&gt;
&lt;li&gt;第二個參數是 entity 的 id 的型態&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;可以自定義方法
&lt;ul&gt;
&lt;li&gt;遵循命名規則，他會自己轉 SQL&lt;/li&gt;
&lt;li&gt;也可以用 @Query 來自定義 SQL
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;?0&amp;gt;&lt;/code&gt; 代表第一個參數，以此類推&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;hibernate&#34;&gt;Hibernate&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;用來儲存 java object 到資料庫的框架&lt;/li&gt;
&lt;li&gt;ORM
&lt;ul&gt;
&lt;li&gt;Object Relational Mapping&lt;/li&gt;
&lt;li&gt;用物件來操作資料庫&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;一種 JPA 的實作&lt;/li&gt;
&lt;li&gt;背後用 JDBC 來操作資料庫&lt;/li&gt;
&lt;li&gt;Spring Boot 預設用 Hibernate 來實作 JPA&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;validation&#34;&gt;Validation&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;field validation&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;@NotEmpty&lt;/li&gt;
&lt;li&gt;@Min&lt;/li&gt;
&lt;li&gt;@Max&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;@Valid&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;用在 controller 上，才會自動檢查參數&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;exception&#34;&gt;Exception&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;RuntimeException
&lt;ul&gt;
&lt;li&gt;繼承這個，可以設置 status, message, timestamp&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;@ExceptionHandler
&lt;ul&gt;
&lt;li&gt;放在 Controller 中的 exception handler method 上，可以處理底下 method 丟出的 exception&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;@ControllerAdvice
&lt;ul&gt;
&lt;li&gt;類似 interceptor/filter&lt;/li&gt;
&lt;li&gt;可以 pre-process request, post-process response&lt;/li&gt;
&lt;li&gt;可以用在 global exception handler&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;testing&#34;&gt;Testing&lt;/h2&gt;
&lt;h3 id=&#34;integration-test&#34;&gt;Integration Test&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;在 test class 前面的 annotation
&lt;ul&gt;
&lt;li&gt;@RunWith(SpringRunner.class)&lt;/li&gt;
&lt;li&gt;@SpringBootTest&lt;/li&gt;
&lt;li&gt;@AutoConfigureMockMvc
&lt;ul&gt;
&lt;li&gt;測試開始時會在容器中創建 MockMvc&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;在 test method 前面加的 annotation
&lt;ul&gt;
&lt;li&gt;@Test&lt;/li&gt;
&lt;li&gt;@Before, @After
&lt;ul&gt;
&lt;li&gt;在每個測試前後執行，可以用來清空資料庫和設置 header&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;mockmvc&#34;&gt;MockMvc&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;用來模擬 HTTP request&lt;/li&gt;
&lt;li&gt;example
&lt;ul&gt;
&lt;li&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nd&#34;&gt;@Autowired&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kd&#34;&gt;private&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;MockMvc&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mockMvc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nd&#34;&gt;@Test&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kd&#34;&gt;public&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;test&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;throws&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;Exception&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;mockMvc&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;perform&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;get&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;/hello&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;andExpect&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;status&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;().&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;isOk&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;())&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;andExpect&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;content&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;().&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;string&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;Hello World&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;));&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;其他&#34;&gt;其他&lt;/h2&gt;
&lt;h3 id=&#34;lombok&#34;&gt;Lombok&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;@Getter, @Setter
&lt;ul&gt;
&lt;li&gt;生成 getter, setter&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;@ToString
&lt;ul&gt;
&lt;li&gt;印出所有變數&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;@EqualsAndHashCode
&lt;ul&gt;
&lt;li&gt;生成 equals, hashCode&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Args
&lt;ul&gt;
&lt;li&gt;@NoArgsConstructor
&lt;ul&gt;
&lt;li&gt;生成無參數建構子&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;@AllArgsConstructor
&lt;ul&gt;
&lt;li&gt;生成所有參數建構子&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;@RequiredArgsConstructor
&lt;ul&gt;
&lt;li&gt;只幫 final 變數生成建構子&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;@Data
&lt;ul&gt;
&lt;li&gt;同時用 @Getter, @Setter, @ToString, @EqualsAndHashCode, @RequiredArgsConstructor&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;@Value
&lt;ul&gt;
&lt;li&gt;把所有變數都設成 final&lt;/li&gt;
&lt;li&gt;同時用 @Getter, @ToString, @EqualsAndHashCode, @RequiredArgsConstructor&lt;/li&gt;
&lt;li&gt;和 Spring boot 的 @Value 撞名&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;@Builder
&lt;ul&gt;
&lt;li&gt;生成 builder pattern&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;@Slf4j
&lt;ul&gt;
&lt;li&gt;生成 log 變數&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;jackson&#34;&gt;Jackson&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;ObjectMapper
&lt;ul&gt;
&lt;li&gt;用來轉換物件和 JSON&lt;/li&gt;
&lt;li&gt;readValue
&lt;ul&gt;
&lt;li&gt;把 JSON 轉成物件&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;用 getter, setter 來判斷欄位&lt;/li&gt;
&lt;li&gt;Annotation
&lt;ul&gt;
&lt;li&gt;@JsonIgnore
&lt;ul&gt;
&lt;li&gt;不轉換&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;@JsonProperty
&lt;ul&gt;
&lt;li&gt;指定欄位名字&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;@JsonUnwrapped
&lt;ul&gt;
&lt;li&gt;把物件的欄位展開，從巢狀變成平面&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;@JsonInclude
&lt;ul&gt;
&lt;li&gt;設定要不要轉換 null&lt;/li&gt;
&lt;li&gt;如果設定為 Include.NON_NULL，給 null 的話，就不會轉換&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;@JsonFormat
&lt;ul&gt;
&lt;li&gt;設定日期格式&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>MemAE 論文閱讀</title>
        <link>https://roykesydon.github.io/Blog/p/memae-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</link>
        <pubDate>Tue, 30 Apr 2024 00:00:55 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/memae-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</guid>
        <description>&lt;p&gt;paper: &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/1904.02639&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Memorizing Normality to Detect Anomaly: Memory-augmented Deep Autoencoder for Unsupervised Anomaly Detection&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;autoencoder 在收到異常輸入的時，預期會生出較高的 reconstruction error。但是這個假設實際上並不總是發生。他有可能「泛化」的很好，導致異常的也可以正常重建。&lt;/p&gt;
&lt;p&gt;為了緩解這個問題，本文幫 auto-encoder 加上一個 memory 的機制。&lt;/p&gt;
&lt;p&gt;訓練階段，memory 要學習生成 normal data 的 prototypical elements。&lt;/p&gt;
&lt;p&gt;測試階段，learned memory 會被固定住，然後要根據 few selected memory 進行重建。&lt;/p&gt;
&lt;p&gt;對於異常輸入，這個重建出的東西就會比較像是 normal sample。這樣 reconstruction error 就會被增強。&lt;/p&gt;
&lt;p&gt;MemAE 是 free of assumption，所以可以用在各種不同的任務上。&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;AE 有可能「泛化」的很好，導致對於異常輸入也可以正常重建。如果 anomolies 和 normal pattern 有共享某些 composition pattern，或是 decoder 強到連 abnormal encoding 都可以重建，就可能發生這樣的狀況。&lt;/p&gt;
&lt;p&gt;MemAE 多了一個 memory module，從 encoder 出來的東西會被視作 query，用來把 memory 中最相關的元素取出，然後作 aggregation。&lt;/p&gt;
&lt;p&gt;作者還進一步提出了一個不同的 hard shrinkage operator，可以生出 sparsity of  memory addressing weight。&lt;/p&gt;
&lt;p&gt;在訓練階段，會把 memory content 連同 encoder 和 decoder 一起訓練，透過 sparse addressing strategy，MemAE 可以有效地利用有限的 memory slot 來製造出 prototypical normal patterns，來製造出夠低的 reconstruction error。&lt;/p&gt;
&lt;p&gt;在測試階段，memory content 會被固定住，然後根據 few selected memory 來重建。因為 memory module 並不是基於某種特定資料的假設，所以可以用在各種不同的任務上。&lt;/p&gt;
&lt;h2 id=&#34;memory-augmented-autoencoder&#34;&gt;Memory-augmented Autoencoder&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/MemAE/fig2.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;memory-module-with-attention-based-sparse-addressing&#34;&gt;Memory Module with Attention-based Sparse Addressing&lt;/h3&gt;
&lt;h4 id=&#34;attention-for-memory-addressing&#34;&gt;Attention for Memory Addressing&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;attention weight $w_i$
&lt;ul&gt;
&lt;li&gt;$w_i=\frac{exp(d(z,m_i))}{\sum^{N}_{j=1}exp(d(z,m_j))}$&lt;/li&gt;
&lt;li&gt;$d(\cdot, \cdot)$ 是 similarity measurement，這裡是 cosine similarity
&lt;ul&gt;
&lt;li&gt;$d(z,m_i)=\frac{zm_i^T}{||z|| \text{ } ||m_i||}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;hard-shrinkage-for-sparse-addressing&#34;&gt;Hard Shrinkage for Sparse Addressing&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;hard shrinkage
&lt;ul&gt;
&lt;li&gt;$\hat{w}_i=h(w_i;\lambda)=\begin{cases} w_i &amp;amp; \text{if } w_i&amp;gt;\lambda \\ 0 &amp;amp; \text{otherwise} \end{cases}$
&lt;ul&gt;
&lt;li&gt;這東西不好做 backpropagation&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;改良版
&lt;ul&gt;
&lt;li&gt;$\hat{w}_i=\frac{max(w_i-\lambda,0)}{|w_i-\lambda|+\epsilon}$
&lt;ul&gt;
&lt;li&gt;$max(\cdot, 0)$ 就是 ReLU&lt;/li&gt;
&lt;li&gt;根據實驗，把 $\lambda$ 設在 [1/N, 3/N] 會得到還不錯的結果&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;shrinkage 後會再 normalize
&lt;ul&gt;
&lt;li&gt;$\hat{w}_i=\hat{w}_i/||\hat{w}||_1$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Sparse addressing 有助於鼓勵模型用更少但相關的 memory item 來表示 query。&lt;/p&gt;
&lt;p&gt;鼓勵 memory addressing 的 sparsity 是有益的，因為 memory M 被訓練來適應 sparse w。&lt;/p&gt;
&lt;p&gt;鼓勵 sparsity 也可以緩解異常樣本可以被很好的重建的問題。&lt;/p&gt;
&lt;h3 id=&#34;training&#34;&gt;Training&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;分成兩個 loss
&lt;ul&gt;
&lt;li&gt;Reconstruction error
&lt;ul&gt;
&lt;li&gt;$R(x^t, \hat{x}^t)=||x^t-\hat{x}^t||^2_2$
&lt;ul&gt;
&lt;li&gt;$l2-norm$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;entropy of $\hat{w}^t$
&lt;ul&gt;
&lt;li&gt;用來進一步提升 sparsity&lt;/li&gt;
&lt;li&gt;$E(\hat{w}^t)=\sum^{T}_{i=1}-\hat{w}_i \cdot log(\hat{w}_i)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Combine
&lt;ul&gt;
&lt;li&gt;$L(\theta_e, \theta_d, M)=\frac{1}{T}\sum^{T}_{t=1}(R(x^t, \hat{x}^t)+\alpha E(\hat{w}^t))$
&lt;ul&gt;
&lt;li&gt;根據實驗，$\alpha$ 設成 0.0002&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>磁碟管理</title>
        <link>https://roykesydon.github.io/Blog/p/%E7%A3%81%E7%A2%9F%E7%AE%A1%E7%90%86/</link>
        <pubDate>Wed, 24 Apr 2024 00:00:43 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/%E7%A3%81%E7%A2%9F%E7%AE%A1%E7%90%86/</guid>
        <description>&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;有關名詞&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;扇區: 最小的儲存單位&lt;/li&gt;
&lt;li&gt;block: 一次讀取的最小單位，是多個連續的扇區&lt;/li&gt;
&lt;li&gt;inode
&lt;ul&gt;
&lt;li&gt;OS 用來記錄檔案的 metadata&lt;/li&gt;
&lt;li&gt;每個文件的 inode number 是唯一的&lt;/li&gt;
&lt;li&gt;可以用 &lt;code&gt;ls -li&lt;/code&gt; 來看 inode number
&lt;ul&gt;
&lt;li&gt;inode data
&lt;ul&gt;
&lt;li&gt;檔案的大小&lt;/li&gt;
&lt;li&gt;擁有者&lt;/li&gt;
&lt;li&gt;擁有者的 group&lt;/li&gt;
&lt;li&gt;權限&lt;/li&gt;
&lt;li&gt;修改時間&lt;/li&gt;
&lt;li&gt;文件的實體指針，指向 block&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;格式化分區&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;主分區&lt;/li&gt;
&lt;li&gt;擴展分區
&lt;ul&gt;
&lt;li&gt;邏輯分區&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;默認分區 1~4 給主分區和擴展分區，邏輯分區從 5 開始
&lt;ul&gt;
&lt;li&gt;/dev/sda1、/dev/sda2 這種就是分區&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;fdisk&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;小於 2TB 的磁碟，可以用 fdisk，但是大於 2TB 的磁碟，要用 parted，且要用 GPT&lt;/li&gt;
&lt;li&gt;&lt;code&gt;fdisk -l&lt;/code&gt; 列出所有分區&lt;/li&gt;
&lt;li&gt;&lt;code&gt;fdisk /dev/sda&lt;/code&gt; 進入 fdisk
&lt;ul&gt;
&lt;li&gt;n 新增分區
&lt;ul&gt;
&lt;li&gt;再設置 sector 的起始位置和結束位置&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;d 刪除分區&lt;/li&gt;
&lt;li&gt;t 更改分區的 system id&lt;/li&gt;
&lt;li&gt;w 寫入並且離開&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;parted&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;parted /dev/sda&lt;/code&gt; 進入 parted
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;mklabel gpt&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;可以把 disk 轉成 GPT&lt;/li&gt;
&lt;li&gt;GPT 區分主分區和邏輯分區&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mkpart primary &amp;lt;start&amp;gt; &amp;lt;end&amp;gt;&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;創建一個 primary partition，從 start 到 end (MB)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;軟硬連結&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;軟連結
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ln -s &amp;lt;source&amp;gt; &amp;lt;destination&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;如果刪除軟連結的檔案的話，不會影響原本的檔案&lt;/li&gt;
&lt;li&gt;源文件刪除後，軟連結失效&lt;/li&gt;
&lt;li&gt;支持資料夾&lt;/li&gt;
&lt;li&gt;支持跨文件系統&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;硬連結
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ln &amp;lt;source&amp;gt; &amp;lt;destination&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;一般情況，inode 和檔案名稱是一對一的關係&lt;/li&gt;
&lt;li&gt;軟連結 inode 號碼是不一樣的，代表是兩個個體，硬連結 inode 號碼是一樣的&lt;/li&gt;
&lt;li&gt;刪除硬連結對源文件沒有影響&lt;/li&gt;
&lt;li&gt;刪除源文件對硬連結沒有影響
&lt;ul&gt;
&lt;li&gt;但是如果刪除所有硬連結，文件的連結數變成 0，則文件會被刪除&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;不能對資料夾使用&lt;/li&gt;
&lt;li&gt;不能跨文件系統&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;mkfs&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;對分區進行格式化文件系統&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;fsck&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;file system check&lt;/li&gt;
&lt;li&gt;檢查和修復文件系統&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;lsblk&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;lsblk -f&lt;/code&gt; 列出所有分區的文件系統&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;vfs&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;virtual file system&lt;/li&gt;
&lt;li&gt;linux 可能有多種文件系統，在上面有一層 vfs，讓所有文件系統都可以通過一個統一的接口來訪問&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Mount&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;設備要 mount 才可以使用，給設備提供一個出入口&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mount&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;-l&lt;/code&gt; 列出所有已經 mount 的設備&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-t&lt;/code&gt; 指定文件系統，不指定的話，會自動判斷&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-o&lt;/code&gt; 一些有關於 mount 的參數
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;async&lt;/code&gt; 非同步讀寫，效率高，但是喪失安全性&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sync&lt;/code&gt; 同步讀寫，效率低，但是讀寫安全&lt;/li&gt;
&lt;li&gt;&lt;code&gt;atime/noatime&lt;/code&gt; 是否要紀錄文件的訪問時間&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-r&lt;/code&gt; read-only&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;LVM&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;logical volume manager&lt;/li&gt;
&lt;li&gt;把一個或多個硬碟在邏輯上進行合併，可以動態調整大小&lt;/li&gt;
&lt;li&gt;硬盤的多個分區，由 LVM 統一管理為 volume group&lt;/li&gt;
&lt;li&gt;名詞
&lt;ul&gt;
&lt;li&gt;PP: physical partition&lt;/li&gt;
&lt;li&gt;PV: physical volume
&lt;ul&gt;
&lt;li&gt;通常一個 PV 對應一個 PP&lt;/li&gt;
&lt;li&gt;PE: physical extends
&lt;ul&gt;
&lt;li&gt;PV 中可以分配的最小單位，同一個 VG 中，所有 PV 的 PE 大小都是一樣的&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;VG: volume group
&lt;ul&gt;
&lt;li&gt;創建在 PV 上，可以劃分成多個 PV&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;LV: logical volume
&lt;ul&gt;
&lt;li&gt;創建在 VG 上，可以動態擴容的分區&lt;/li&gt;
&lt;li&gt;LE: logical extends
&lt;ul&gt;
&lt;li&gt;LV 中的基本單位，一個 LE 對應一個 PE&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;創建
&lt;ul&gt;
&lt;li&gt;PP 階段
&lt;ul&gt;
&lt;li&gt;用 fdisk 格式化，修改 system id 為 8e (預設是 83)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;PV 階段
&lt;ul&gt;
&lt;li&gt;用 pvcreate, pvdisplay 把 linux 分區轉成 PV&lt;/li&gt;
&lt;li&gt;指令
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;pvcreate /dev/sda /dev/sdb&lt;/code&gt;: 把 sda 和 sdb 轉成 PV
&lt;ul&gt;
&lt;li&gt;適用硬碟和分區&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;pvs&lt;/code&gt;: 查看 PV&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;VG 階段
&lt;ul&gt;
&lt;li&gt;用 vgcreate, vgdisplay 創建 VG&lt;/li&gt;
&lt;li&gt;指令
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;vgcreate vg1 /dev/sda /dev/sdb&lt;/code&gt;: 創建 VG vg1，用 sda 和 sdb&lt;/li&gt;
&lt;li&gt;&lt;code&gt;vgs&lt;/code&gt;: 查看 VG&lt;/li&gt;
&lt;li&gt;&lt;code&gt;vgextend vg1 /dev/sdc&lt;/code&gt;: 把 sdc 加入 vg1&lt;/li&gt;
&lt;li&gt;&lt;code&gt;vgdisplay&lt;/code&gt;: 查看 VG&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;LV 階段
&lt;ul&gt;
&lt;li&gt;用 lvcreate, lvdisplay 創建 LV&lt;/li&gt;
&lt;li&gt;把 VG 分成多個 LV&lt;/li&gt;
&lt;li&gt;也要幫 LV 創建文件系統&lt;/li&gt;
&lt;li&gt;指令
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;lvs&lt;/code&gt;: 查看 LV&lt;/li&gt;
&lt;li&gt;&lt;code&gt;lvextend -L +1000G /dev/vg1/lv1&lt;/code&gt;: 把 lv1 增加 1000G
&lt;ul&gt;
&lt;li&gt;ex4 可以不用 umount&lt;/li&gt;
&lt;li&gt;還要 &lt;code&gt;resize2fs /dev/vg1/lv1&lt;/code&gt; 來調整文件系統大小
&lt;ul&gt;
&lt;li&gt;可以用 &lt;code&gt;df -h&lt;/code&gt; 來檢查&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>ReALM 論文閱讀</title>
        <link>https://roykesydon.github.io/Blog/p/realm-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</link>
        <pubDate>Thu, 18 Apr 2024 00:08:46 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/realm-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</guid>
        <description>&lt;p&gt;paper: &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2403.20329&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ReALM: Reference Resolution As Language Modeling&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;Reference resolution 是一個重要的問題，對於理解和充分處理不同類型的 context 很重要。&lt;/p&gt;
&lt;p&gt;Context 包含 previous turns 和 non-conversational entities，比如使用者螢幕上的 entity，或是在背景執行的 entity。&lt;/p&gt;
&lt;p&gt;LLM 雖然在各種任務都很強大，但對於 reference resolution 的使用，特別是 non-conversational entities 方面，依然沒有充分利用。&lt;/p&gt;
&lt;p&gt;本文將展示如何引用 LLM 創建一個系統來處理不同類型的 reference，方法是展示如何把 reference resolution 轉換成 language modeling problem。
盡管螢幕上的 entity 傳統上不利於簡化成 text-only modality。&lt;/p&gt;
&lt;p&gt;對於 GPT-4，本文最小的模型實現了和 GPT-4 相當的性能，而更大的模型則大幅領先。&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;人類的語言很長包含 ambiguous reference，比如「這個」、「那個」等等，這些 reference 需要根據 context 來解決。&lt;/p&gt;
&lt;p&gt;能夠能夠理解 context 對 conversational assistant 來說很重要。&lt;/p&gt;
&lt;p&gt;讓使用者能夠對螢幕上看到的內容發出查詢是確保語音助理可以提供 hands-free 體驗的第一步。&lt;/p&gt;
&lt;hr&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Speaker&lt;/th&gt;
&lt;th&gt;Dialogue&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;User&lt;/td&gt;
&lt;td&gt;Show me pharmacies near me&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Agent&lt;/td&gt;
&lt;td&gt;Here is a list I found.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Agent&lt;/td&gt;
&lt;td&gt;&amp;hellip; (list presented)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;User&lt;/td&gt;
&lt;td&gt;Call the one on Rainbow Rd.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;User&lt;/td&gt;
&lt;td&gt;Call the bottom one.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;User&lt;/td&gt;
&lt;td&gt;Call this number (present onscreen)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Table 1:  Sample Interactions between a user and an
agent.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;以 Table 1 為例，如果沒有理解 context 的能力，agent 不可能完成查詢。&lt;/p&gt;
&lt;p&gt;照理來說，處理用戶的查詢需要多種類型的 context，Conversational context 和 on-screen context 就是兩個主要的例子。&lt;/p&gt;
&lt;p&gt;最近的 LLM 通常可以實現 End-to-End 的體驗，甚至可能可以消除包含 reference resolution 的多階段 piepline。&lt;/p&gt;
&lt;p&gt;但是在一些實際案例中，pipeline 有他的價值，考慮以下情境：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;在運算能力有限的設備上運作 (例如手機)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;由於功耗和延遲需求，單一大型 End-to-End 模型可能不適用。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;需要與 API 整合的情境&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;雖然存在可以用 LLM 編寫呼叫 API 的方法，但依然需要超大的模型還有對現有 pipeline 的徹底處理。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;使用 focused model 可以允許現有的 reference resolution module 替換成更新的版本，而且由於系統是模組化的，可以改進能力和可解釋性。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;對於本文所考慮的任務，reference resolution 不只限定於 conversational context，還包含 on-screen entities，這些 entities 是使用者可以感知到的一部份，但是還未出現在對話歷史紀錄中。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;因此，盡管一些 LLM 可以 implicit 地處理 reference resolution，但是傳統的 NLP 任務 (比如 reference resolution) 仍然有價值。&lt;/p&gt;
&lt;p&gt;因此本文提倡用較小的語言模型，但針對 reference resolution 進行了專門且明確的 fine-tuning。&lt;/p&gt;
&lt;p&gt;然而這種語音助理會遇到最大的挑戰就是要怎麼讓 LM 「看」到螢幕。而且還要以有利於 LM 解析的方式對螢幕上的 entity 進行編碼，然後編碼還得足夠一致，讓 LM 可以成功執行 reference resolution。&lt;/p&gt;
&lt;p&gt;本文建議使用使用 parsed entity 及其位置來重件螢幕，以產生螢幕的純文字表示。&lt;/p&gt;
&lt;p&gt;然後螢幕上屬於 entity 的部分會被標記，以便 LM 能夠了解實體出現的位置及他們周圍的文字。&lt;/p&gt;
&lt;p&gt;據作者所知，這是第一個目標是從螢幕 encode context 的 LLM 工作。&lt;/p&gt;
&lt;h2 id=&#34;related-work-and-motivation&#34;&gt;Related Work and Motivation&lt;/h2&gt;
&lt;p&gt;解析螢幕上的 reference 是一個目前探索比較不足的領域。&lt;/p&gt;
&lt;p&gt;螢幕上的東西通常更加結構化和高度文字化，使的可以利用更輕的模型來轉換成文字。但雖然容易解析，分布和那種大型育訓練的基於圖像的系統不同，因為他們多半都用自然的現實圖片。&lt;/p&gt;
&lt;p&gt;此外那些模型的訓練成本通常都非常高，而且在這種大量文字的情境也表現不佳。
常用於文字理解的方法又常常依賴多個模組，比如 bounding box detection 和 OCR。&lt;/p&gt;
&lt;p&gt;聯合視覺 + 文字的模型在計算成本也更加昂貴。&lt;/p&gt;
&lt;p&gt;對於螢幕上的參考有一些相關工作，被用作本文的 baseline。&lt;/p&gt;
&lt;p&gt;然後他們有些缺點，在本文解決了這些缺點。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;他們的方法依賴專用的 「Category Module」來處理 type-based reference，每次建立新類型，都需要手動加入 Entity&lt;/li&gt;
&lt;li&gt;此類 Module 將每種類別視為不同的，忽略了他們的相似性&lt;/li&gt;
&lt;li&gt;依賴手工製作的規則，往往需要大量特徵工程，而且不 robust&lt;/li&gt;
&lt;li&gt;不考慮語意相似性，也沒法對現實的理解和常識進行推理&lt;/li&gt;
&lt;li&gt;這些方法會獨立地判斷實體和 Query 的關聯性，而不考慮其他所有的實體，查詢既不考慮整個螢幕也不考慮其他實體&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;task&#34;&gt;Task&lt;/h2&gt;
&lt;p&gt;作者提了三種和使用者相關的 Entity:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;On-screen Entities&lt;/li&gt;
&lt;li&gt;Conversational Entities
&lt;ul&gt;
&lt;li&gt;可能是來自上一輪的對話，也可能是 virtual assistant 產生的&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Background Entities
&lt;ul&gt;
&lt;li&gt;來自後台 process 的相關實體，使用者不一定在螢幕上看的到，比如背景的音樂&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;本文將 reference resolution 作為 LLM 的 multiple choice task，預期輸出是用戶螢幕上顯示的其中一個 Entity。&lt;/p&gt;
&lt;p&gt;答案也可能是「None of these」。&lt;/p&gt;
&lt;h2 id=&#34;datasets&#34;&gt;Datasets&lt;/h2&gt;
&lt;p&gt;每筆資料包含使用者查詢和 Entity list，還有與對應使用者查詢相關的 ground truth entity。&lt;/p&gt;
&lt;p&gt;每個實體又包含與其相關的訊息，比如與實體關聯的名稱和其他文字描述訊息。&lt;/p&gt;
&lt;p&gt;對於存在 on-screen context 的資料，context 以 Entity 的邊界框，圍繞它的物件清單還有周圍物件的屬性 (比如類型、文字內容、位置) 來提供&lt;/p&gt;
&lt;hr&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Dataset&lt;/th&gt;
&lt;th&gt;Train Set&lt;/th&gt;
&lt;th&gt;Test Set&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Conversational&lt;/td&gt;
&lt;td&gt;2.3k&lt;/td&gt;
&lt;td&gt;1.2k&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Synthetic&lt;/td&gt;
&lt;td&gt;3.9k&lt;/td&gt;
&lt;td&gt;1.1k&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;On-screen&lt;/td&gt;
&lt;td&gt;10.1k&lt;/td&gt;
&lt;td&gt;1.9k&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Table 2: Dataset Sizes (Train Set and Test Set)&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;conversational-data&#34;&gt;Conversational Data&lt;/h3&gt;
&lt;p&gt;收集使用者和 agent 的相關資料。&lt;/p&gt;
&lt;p&gt;評分者會看到帶有所提供 Entity 清單的截圖，並要求提供引用清單中任意挑選的 Entity 的 Query。&lt;/p&gt;
&lt;p&gt;比如，可能會給使用者看企業清單，使用者可能會說「Call the one on Main Street」。&lt;/p&gt;
&lt;h3 id=&#34;synthetic-data&#34;&gt;Synthetic Data&lt;/h3&gt;
&lt;p&gt;透過 template 去合成資料。&lt;/p&gt;
&lt;p&gt;有兩種 template:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Base Template
&lt;ul&gt;
&lt;li&gt;包含 mentions, entities, possible slots&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Language Template
&lt;ul&gt;
&lt;li&gt;除了 Base 還會新增不同變體的 query&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;on-screen-data&#34;&gt;On-screen Data&lt;/h3&gt;
&lt;p&gt;從存在電話、電子郵件和實際地址的各種網頁蒐集的。&lt;/p&gt;
&lt;p&gt;進行兩階段的 annotation：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;根據螢幕 extract query
&lt;ul&gt;
&lt;li&gt;評分者會收到一張帶有綠色方框和紅色方框的截圖，要把綠方框方類為電話、電子郵件或地址等等&lt;/li&gt;
&lt;li&gt;然後要為綠框提供三個獨特的 query&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;根據 query 識別 entity 和 mention
&lt;ul&gt;
&lt;li&gt;前面蒐集的 query 會被一一展示給評分者，並帶有相應的截圖，但沒有 bounding box，還會提供所有 screen entity list&lt;/li&gt;
&lt;li&gt;評分者要評估 query 是否包含給定的 visual entity，還有聽起來自不自然&lt;/li&gt;
&lt;li&gt;此外，評分者還要從清單中選出 query 提及的 entity，還要標記它們在 query 的哪裡&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;models&#34;&gt;Models&lt;/h2&gt;
&lt;h3 id=&#34;marrs&#34;&gt;MARRS&lt;/h3&gt;
&lt;p&gt;這個是 baseline，非 LLM，和前人的方法去做比較。&lt;/p&gt;
&lt;p&gt;前人的方法著重於螢幕上的 entity，MARRS 也傾向於 conversational 和 background entities。&lt;/p&gt;
&lt;p&gt;要注意的是，和其他通用的 LLM 相比，作者的 baseline 是專門為了 reference resolution 而設計的。&lt;/p&gt;
&lt;h3 id=&#34;chatgpt&#34;&gt;ChatGPT&lt;/h3&gt;
&lt;p&gt;作者考慮 GPT-3.5 和 GPT-4 作為另外一個 baseline。&lt;/p&gt;
&lt;p&gt;對於 GPT-3.5，輸入只包含 prompt。&lt;/p&gt;
&lt;p&gt;對於 GPT-4，因為他可以接受圖片的 context，所以為系統提供了螢幕截圖，發現可以有效提高其效能。&lt;/p&gt;
&lt;h3 id=&#34;our-approach&#34;&gt;Our Approach&lt;/h3&gt;
&lt;p&gt;作者遵循以下 pipeline 來微調模型 (FLAN-T5)&lt;/p&gt;
&lt;p&gt;向模型提供解析後的輸入，並用來微調。&lt;/p&gt;
&lt;p&gt;和 Baseline 不同，作者沒有在 FLAN-T5 上進行大規模的超參數搜索，而是堅持使用預設的參數。&lt;/p&gt;
&lt;h4 id=&#34;conversational-references&#34;&gt;Conversational References&lt;/h4&gt;
&lt;p&gt;作者假設 conversational references 有兩種：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Type-based
&lt;ul&gt;
&lt;li&gt;這種非常依賴要將 query 和 entity type 結合，好進行識別&lt;/li&gt;
&lt;li&gt;比如「打給他」，可以知道要的是電話號碼，而不是地址&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Descriptive
&lt;ul&gt;
&lt;li&gt;傾向於用唯一的實體屬性來標記他，比如「時代廣場的那個」&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;referenece 通常會同時依賴 type 和描述，比如「play the one from Abbey Road」和「directions to the one on Abbey Road」。&lt;/p&gt;
&lt;h4 id=&#34;onscreen-references&#34;&gt;Onscreen References&lt;/h4&gt;
&lt;p&gt;作者假設存在能夠解析螢幕文字以提取 Entity 的上游資料偵測器。&lt;/p&gt;
&lt;p&gt;為了以僅涉及文字的方式將其編碼到 LM 中，使用 Algorithm 2。&lt;/p&gt;
&lt;p&gt;直觀上，假設所有實體和周圍物件的位置都可以用它們各自的邊界框的中心來表示。&lt;/p&gt;
&lt;p&gt;然後從上到下對這些中心進行排序，並用 stable sort 從左到右排序。&lt;/p&gt;
&lt;p&gt;然後，所有在一個 margin 內的物件都會被視作在 same line，並用 tab 隔開。&lt;/p&gt;
&lt;p&gt;在 margin 下方外面的會被放在下一行，然後不斷重複。&lt;/p&gt;
&lt;h2 id=&#34;results&#34;&gt;Results&lt;/h2&gt;
&lt;hr&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Model&lt;/th&gt;
&lt;th&gt;Conv&lt;/th&gt;
&lt;th&gt;Synth&lt;/th&gt;
&lt;th&gt;Screen&lt;/th&gt;
&lt;th&gt;Unseen&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;MARRS&lt;/td&gt;
&lt;td&gt;92.1&lt;/td&gt;
&lt;td&gt;99.4&lt;/td&gt;
&lt;td&gt;83.5&lt;/td&gt;
&lt;td&gt;84.5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;GPT-3.5&lt;/td&gt;
&lt;td&gt;84.1&lt;/td&gt;
&lt;td&gt;34.2&lt;/td&gt;
&lt;td&gt;74.1&lt;/td&gt;
&lt;td&gt;67.5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;GPT-4&lt;/td&gt;
&lt;td&gt;97.0&lt;/td&gt;
&lt;td&gt;58.7&lt;/td&gt;
&lt;td&gt;90.1&lt;/td&gt;
&lt;td&gt;98.4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ReALM-80M&lt;/td&gt;
&lt;td&gt;96.7&lt;/td&gt;
&lt;td&gt;99.5&lt;/td&gt;
&lt;td&gt;88.9&lt;/td&gt;
&lt;td&gt;99.3&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ReALM-250M&lt;/td&gt;
&lt;td&gt;97.8&lt;/td&gt;
&lt;td&gt;99.8&lt;/td&gt;
&lt;td&gt;90.6&lt;/td&gt;
&lt;td&gt;97.2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ReALM-1B&lt;/td&gt;
&lt;td&gt;97.9&lt;/td&gt;
&lt;td&gt;99.7&lt;/td&gt;
&lt;td&gt;91.4&lt;/td&gt;
&lt;td&gt;94.8&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ReALM-3B&lt;/td&gt;
&lt;td&gt;97.9&lt;/td&gt;
&lt;td&gt;99.8&lt;/td&gt;
&lt;td&gt;93.0&lt;/td&gt;
&lt;td&gt;97.8&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Table 3:&lt;/p&gt;
&lt;p&gt;預測正確的標準是要正確預測所有相關實體，不然就是錯的&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;作者發現它們的方法贏 MARRS 和 GPT-3.5。
GPT-3.5 的餐數量還多出了幾個數量級。&lt;/p&gt;
&lt;p&gt;盡管模型相較 GPT-4 輕的多，但是性能大致相同。&lt;/p&gt;
&lt;p&gt;而且作者採用文字編碼的方法能夠讓模型和 GPT-4 幾乎同等效能，後者還提供了螢幕截圖。&lt;/p&gt;
&lt;p&gt;隨著模型加大，提升也很明顯，特別是 Screen，暗示任務本質上更加複雜。&lt;/p&gt;
&lt;h3 id=&#34;analysis&#34;&gt;Analysis&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;$GPT-4 \approx ReALM &amp;raquo; MARRS$ for new use-cases
&lt;ul&gt;
&lt;li&gt;測試了 zero-shot learning 的能力，Table 3 最後一個 column 就是在比較從未見過的資料集。&lt;/li&gt;
&lt;li&gt;作者發現對於測試集，所有 LLM-based 的方法都贏過 Fine-tuned Model&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;ReaLM &amp;gt; GPT-4 for domain-specific queries
&lt;ul&gt;
&lt;li&gt;作者發現 ReALM 因為有對 user requests 做 fine-tuning，所以更能理解 domain-specific questions，如下表 (Table 4)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;User Request: Can you make it brighter?
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;---
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Entities Shown to User:
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;1. Type: Settings
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;2. Type: UserEntity | homeAutomationAccessoryName
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;---
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;GPT-4 Prediction: 1 Ground Truth: 1, 2
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;Table 4&lt;/p&gt;
&lt;hr&gt;
</description>
        </item>
        <item>
        <title>SimSID 論文閱讀</title>
        <link>https://roykesydon.github.io/Blog/p/simsid-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</link>
        <pubDate>Sat, 13 Apr 2024 00:27:55 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/simsid-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</guid>
        <description>&lt;p&gt;paper: &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2403.08689&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Exploiting Structural Consistency of Chest Anatomy for Unsupervised Anomaly Detection in Radiography Images&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;個人前言&#34;&gt;個人前言&lt;/h2&gt;
&lt;p&gt;這篇文章提出了許多在 SQUID 論文有出現過的的內容，特別是有關於放射線成像的描述等等，建議先看過 SQUID，重複的論點不再提及。&lt;/p&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;提出一種簡單的 Space-aware Memory，用於修復放射線成像的異常。&lt;/p&gt;
&lt;p&gt;將異常檢定制定為 image reconstruction task，用 space-aware memory matrix 和 in-painting block 組成。&lt;/p&gt;
&lt;h2 id=&#34;related-work&#34;&gt;Related Work&lt;/h2&gt;
&lt;h3 id=&#34;our-previous-work&#34;&gt;Our Previous Work&lt;/h3&gt;
&lt;p&gt;相對於 SQUID，本文有以下四點改進：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;引入了新的符號、公式和圖表，以及詳細的方法說明及學習目標&lt;/li&gt;
&lt;li&gt;刪除 Memory Queue 和 Masked shortcut，簡化框架，還提高了效能&lt;/li&gt;
&lt;li&gt;在三種放射線成像任務勝過其他 21 種 SOTA 方法&lt;/li&gt;
&lt;li&gt;研究了 SimSID 對於 desease-free (訓練集中對異常資料的容忍) 的穩健性&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;simsid&#34;&gt;SimSID&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/SimSID/fig2.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;developing-space-aware-and-hierarchical-memory&#34;&gt;Developing Space-aware and Hierarchical Memory&lt;/h3&gt;
&lt;h4 id=&#34;space-aware-memory&#34;&gt;Space-aware memory&lt;/h4&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;$\hat{z}_{i,j}$ (augmented feature)&lt;/p&gt;
&lt;p&gt;$=\displaystyle\sum^N_{k=1}G(s^{k})M^k_{i,j}$&lt;/p&gt;
&lt;p&gt;$s^k$ 是做內積算出來的相似度&lt;/p&gt;
&lt;p&gt;$G(\cdot)$ 是 Gumbel-softmax (用 SQUID 的 Gumbel Shrinkage)&lt;/p&gt;
&lt;p&gt;$Memory Matrix$ 被拆成多個 block，才有 $M_{i,j}$&lt;/p&gt;
&lt;h4 id=&#34;hierarchical-memory&#34;&gt;Hierarchical memory&lt;/h4&gt;
&lt;p&gt;在 encoder 最深處使用一個 memory matrix (in-painting block) 不足以重建具有細節的高品質圖像。&lt;/p&gt;
&lt;p&gt;為了捕捉不同尺度的 anatomic patterns，提出在 generator 的多個 level 放置 space-aware memory。&lt;/p&gt;
&lt;p&gt;研究發現，太多的 memory 會導致過度的 information filtering，還會 degrade 模型，導致他只會保留最具代表性的 normal pattern，而不是所有需要的 pattern。&lt;/p&gt;
&lt;p&gt;這個問題可以透過添加 skip connection 來解決。&lt;/p&gt;
&lt;p&gt;從經驗發現三個 memory matrix 就已足夠。&lt;/p&gt;
&lt;h2 id=&#34;results&#34;&gt;Results&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/SimSID/fig7.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;benchmarking-simsid-on-three-public-datasets&#34;&gt;Benchmarking SimSID on Three Public Datasets&lt;/h3&gt;
&lt;p&gt;對於正常的情況， SimSID 可以在 memory 中找到相似的匹配，然後順利重建。&lt;/p&gt;
&lt;p&gt;對於異常，將偽造的正常特徵強加到異常特徵，就會產生矛盾。&lt;/p&gt;
&lt;p&gt;圖 7 繪製 Discriminator 的 heatmap 來指示出重建效果不佳的部分。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>🦑SQUID🦑 論文閱讀</title>
        <link>https://roykesydon.github.io/Blog/p/squid-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</link>
        <pubDate>Sun, 31 Mar 2024 00:27:55 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/squid-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</guid>
        <description>&lt;p&gt;paper: &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2111.13495&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;SQUID: Deep Feature In-Painting for Unsupervised Anomaly Detection&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;Radiography imaging protocols (放射線成像協定) 會專注於特定的身體區域，因此會在患者間產生大量相似的照片。&lt;/p&gt;
&lt;p&gt;為了利用這種 structed information，作者提出了 Space-aware Memory Queues for In-painting and Detecting anomalies from radiography images (SQUID)，它可以把固有的人體結構分類為反覆出現的 pattern。&lt;/p&gt;
&lt;p&gt;在推理狀態下，它可以識別圖片中的異常情況。&lt;/p&gt;
&lt;p&gt;比較兩個 chest X-ray benchmark，SQUID 在非監督異常檢測上超越了 13 種 SOTA 方法至少 5 個百分點。&lt;/p&gt;
&lt;p&gt;作者還創建了一個新的資料集 (DigitAnatomy)，該資料集結合了胸腔解剖學中的 spatial correlation 和 consistent shape 這兩個特性。&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;放射線成像和一般圖片的差別
&lt;ul&gt;
&lt;li&gt;一般的 photographic imaging 和 radiography imaging 是不同的。一般的圖片物體，我們會假設 translation invariance (平移不變性)，無論貓在左右，都是貓。但是在放射線成像中，結構的相對位置和方向是辨別正常和異常的重要特徵。&lt;/li&gt;
&lt;li&gt;而且由於 radiography imaging protocols 以相當一致的方向評估患者，成像在不同的設備製造商、設施位置還有患者的情況下，都具有很大的相似性。像這樣反覆出現且一致的結構，有助於分析問題，是放射線成像的優勢。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;有多項研究證明了許多先驗知識在增強深度學習模型性能上的優勢，比如添加 location features、修改目標函數還有約束相對於照片中 landmarks 的相對座標。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;想解決的問題&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;多達 80% 的臨床錯誤是由於放射科醫生漏掉異常而造成。&lt;/li&gt;
&lt;li&gt;本文想回答一個關鍵問題：有沒有辦法利用 anatomical patterns 的 consistency 和 spatial information，在沒有手動標註的情況下，加強深度學習模型的異常檢測能力？非監督的異常檢測只用健康的圖片進行訓練，不用疾病診斷或任何 label。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SQUID 解決辦法&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;本文不像先前的異常檢測方法，本文把 task 制定為 in-painting task (圖像修復)，好利用放射線成像的外觀、位置、布局。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;作者提出了 SQUID，在訓練過程中，模型可以透過空間中經常出現的 anoatomical patterns 來動態維護一個 visual pattern dictionary。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;由於解剖學的 consistency，健康成像中的身體區域會呈現類似的 visual pattern，使 unique pattern 的數量是可控的。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在推理階段，由於 dictionary 不存在 anomaly pattern，因此如果存在異常，產生的放射線成像會和現實有所差距。因此，模型可以透過區分修復任務的品質來識別異常。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;實驗假設&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;異常檢測的成功基於兩個假設
&lt;ul&gt;
&lt;li&gt;資料中很少異常圖片&lt;/li&gt;
&lt;li&gt;異常和正常有顯著不同&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;實驗&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在兩個大規模、公開的放射線成像資料集上實驗
&lt;ul&gt;
&lt;li&gt;ZhangLab
&lt;ul&gt;
&lt;li&gt;在非監督方面贏 SOTA 超過 5 個百分點&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Stanford CheXpert
&lt;ul&gt;
&lt;li&gt;比最近的 13 種方法提高 10 個百分點&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;新資料集&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;創建了 DigitAnatomy 資料集，闡明胸腔解剖結構的 spatial correlation 和 consistent shape。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;貢獻總結&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在胸腔放射線成像的新非監督 SOTA 異常檢測方法&lt;/li&gt;
&lt;li&gt;新的綜合資料集&lt;/li&gt;
&lt;li&gt;發明新方法打敗主流非監督異常檢測方法&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;related-work&#34;&gt;Related Work&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Anomaly detection in natural imaging
&lt;ul&gt;
&lt;li&gt;識別偏離正常資料分佈的罕見事件&lt;/li&gt;
&lt;li&gt;由於異常樣本的缺乏，後來的工作都制定為非監督學習問題&lt;/li&gt;
&lt;li&gt;大致分為兩類
&lt;ul&gt;
&lt;li&gt;reconstruction-based
&lt;ul&gt;
&lt;li&gt;恢復原始輸入並分析重建誤差&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;density-based
&lt;ul&gt;
&lt;li&gt;透過估計正常資料的分佈來預測異常&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;不過這些方法都沒辦法解釋可能的異常，本文透過維護 visual pattern memory 來解決這個問題&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Anomaly detection in medical imaging
&lt;ul&gt;
&lt;li&gt;基於監督學習的方法多半用於檢測特定種類的異常，比如腫瘤&lt;/li&gt;
&lt;li&gt;最近提出了一些無監督方法來檢測一般異常，和 GAN 有關，但是這些方法需要有關於異常種類的強大先驗知識和假設才能使增強有效&lt;/li&gt;
&lt;li&gt;和一般的照片不同，Radiography imaging protocols 生成具一致性的圖片，異常的變化比較微妙 (subtle)，檢測起來更具挑戰，作者利用放射線成像的特性，大大提高檢測性能。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Memory networks
&lt;ul&gt;
&lt;li&gt;過往有一些有關於把 Memory modules 納入神經網路的研究，其中有採用到 Memory Matrix。本文克服了 Memory matrix 的侷限性，並提出一種有效且高效率的的 memory queue。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;squid&#34;&gt;SQUID&lt;/h2&gt;
&lt;h3 id=&#34;overview&#34;&gt;Overview&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/SQUID/fig2.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Feature extraction&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;把圖片切成 N x N 個 non-overlapping patches，然後餵入一個 encoder 做特徵提取，這裡是用 CNN 提取，但要用其他 backbone 也可以&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Image reconstruction&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;這裡會用 teacher 和 student generator
&lt;ul&gt;
&lt;li&gt;teacher
&lt;ul&gt;
&lt;li&gt;直接用 encoder 的 feature 重建圖片&lt;/li&gt;
&lt;li&gt;本質上是 auto-encoder&lt;/li&gt;
&lt;li&gt;作為 regularizer 來避免 student generator 重複生成相同的正常圖片&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;student
&lt;ul&gt;
&lt;li&gt;使用 in-painting block 增強後的 feature 來重建，最後會被用在 discrimination&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;兩個 generator 會在每個 up-sampling level 用 knowledge distillation paradigm 來結合&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Anomaly discrimination&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在 adversarial learning 後，使用 discriminator 來區分正常和異常&lt;/li&gt;
&lt;li&gt;用 2 個 generator 來生成圖片，再用 discriminator 來區分，只有 student generator 會接收 discriminator 的梯度&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;inventing-memory-queue-as-dictionary&#34;&gt;Inventing Memory Queue as Dictionary&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Motivation
&lt;ul&gt;
&lt;li&gt;Memory Matrix 被廣泛採用
&lt;ul&gt;
&lt;li&gt;Feature 會透過在 Memory matrix 做加權平均來強化&lt;/li&gt;
&lt;li&gt;缺點
&lt;ul&gt;
&lt;li&gt;這樣的增強方法是對整張圖片的提出的特徵做的，丟棄了圖片中的 spatial information。導致他無法感知到放射線成像中的一致性結構&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Space-aware memory
&lt;ul&gt;
&lt;li&gt;為了利用空間資訊，作者只將 patch 而不是整張圖片傳遞到 model，讓 patch 只能存取 Memory matrix 中對應到的區段，作者把這種策略稱為 Space-aware memory，而且還可以加快速度，因為不用存取整個 Memory matrix&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Memory queue
&lt;ul&gt;
&lt;li&gt;在 learning-based Memory matrix 中，normal patterns 是由 matrix 中的 learned basis 組合而成，但組合出來的東西和現實照片的特徵總會有分佈差距，使後續的影像生成變得困難&lt;/li&gt;
&lt;li&gt;作者提出 memory queue，用來在訓練期間儲存真實的影像 feature，從而呈現和影像特徵相同的分佈。它在訓練期間會把先前看到的特徵直接複製到 queue&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Gumbel shrinkage
&lt;ul&gt;
&lt;li&gt;控制 memory matrix 中 activated pattern 的數量是有利的，但如果用 hard shrinkage threashold 會無法處理找不到合適 entry 的情況。一種自然的解法是讓梯度流過前 k 個相似的 entry，其餘的不更新。但這樣又會導致未啟動的 entry 無法接收任何梯度並更新，因此提出了 Gumbel shrinkage schema
&lt;ul&gt;
&lt;li&gt;$w&amp;rsquo; = sg(hs(w,topk(w)) - \phi(w)) + \phi(w)$
&lt;ul&gt;
&lt;li&gt;$w$ 代表 feature 和 entry 的相似度&lt;/li&gt;
&lt;li&gt;$sg(\cdot)$ 代表 stop-gradient，不計算輸入的梯度&lt;/li&gt;
&lt;li&gt;$hs(\cdot, t)$ 代表 hard shrinkage，有個 threshold $t$&lt;/li&gt;
&lt;li&gt;$\phi(\cdot)$ 代表 softmax&lt;/li&gt;
&lt;li&gt;這樣保留了 top k 作為 w 的最終結果，又用 softmax 對所有 entry 進行更新&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;formulating-anomaly-detection-as-in-painting&#34;&gt;Formulating Anomaly Detection as In-painting&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/SQUID/fig5.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Motivation&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Image in-painting 最初是用來恢復具有 neighboring context 的圖片區塊，因此根據此直覺，想把異常圖片修復成正常圖片來實現檢測&lt;/li&gt;
&lt;li&gt;在修復像素的時候，特別是用深度網路，容易有 boundary artifacts，在 pixel 級別的修復中，這些 boundary artifacts 會導致大量誤報
&lt;ul&gt;
&lt;li&gt;artifact 中翻好像是「偽影」，就是重建的時候會呈現有點像棋盤的效應&lt;/li&gt;
&lt;li&gt;作者選擇在 feature level 進行 in-painting，避開這問題&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In-painting block&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;會先把每個 patch $F_{1,1}$ ~ $F_{w,h}$ 都先找到最接近的 normal patterns $N_{1,1}$ ~ $N_{w,h}$&lt;/li&gt;
&lt;li&gt;因為 N 是之前訓練資料中提取的特徵組成的，不受當前輸入影像的影響。為了導入輸入圖片的特徵，作者把 F 和 N 用 transformer block 來結合
&lt;ul&gt;
&lt;li&gt;對於每個 patch $F_{i,j}$，會把其當作中心，用相鄰的 8 個 N patch 來重新定義 $F_{i,j}$，把這 8 個 N patch 作為 key 和 value，$F_{i,j}$ 作為 query&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;最後會在 in-painting block 的前後做 point-wise convolution (1x1)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Masked shortcut&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;實驗結果表明，直接做 residual connection 會降低修復的性能，作者採用 random binary mask 在 training 期間 gate shortcut feature
&lt;ul&gt;
&lt;li&gt;$F&amp;rsquo;=(1-\delta)\cdot F + \delta \cdot inpaint(F)$
&lt;ul&gt;
&lt;li&gt;$\delta$~$Bernoulli(\rho)$
&lt;ul&gt;
&lt;li&gt;$\rho$ gating probability&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;獲得 F&amp;rsquo; 後，原始的 F 會被更新進 memory&lt;/li&gt;
&lt;li&gt;在推論階段，會 disable shortcut，使 $F&amp;rsquo;=inpaint(F)$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;anomaly-discrimination&#34;&gt;Anomaly Discrimination&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Discriminator 評估圖片現不現實，不現實表示異常&lt;/li&gt;
&lt;li&gt;因為 Generator 只在正常圖片訓練，所以 Memory Queue 也只有 normal pattern&lt;/li&gt;
&lt;li&gt;稍微總結
&lt;ul&gt;
&lt;li&gt;in-painting block 會把 patch 強化為相似的 normal feature&lt;/li&gt;
&lt;li&gt;student generator 會根據 &amp;ldquo;normal&amp;rdquo; feature 重建出 &amp;ldquo;normal&amp;rdquo; image&lt;/li&gt;
&lt;li&gt;如果沒有異常的話，那 input 和重建的 image 在語意上應該相差很小&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;異常分數 $A$ 的算法
&lt;ul&gt;
&lt;li&gt;$A=\phi(\frac{D(G_s(E(I)))-\mu}{\sigma})$
&lt;ul&gt;
&lt;li&gt;$\phi(\cdot)$ 是 sigmoid function&lt;/li&gt;
&lt;li&gt;$\mu$ 和 $\sigma$ 是根據 training samples 算出的異常分數的平均值和標準差&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;loss-function&#34;&gt;Loss Function&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Generator
&lt;ul&gt;
&lt;li&gt;$\mathcal L_t = (I-G_t (E(I)))^2$&lt;/li&gt;
&lt;li&gt;$\mathcal L_s = (I-G_s (E(I)))^2$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Knowledge distillation
&lt;ul&gt;
&lt;li&gt;$\mathcal L_{dist} = \sum_{l}^{i=1} (F^i_t-F^i_s)^2$
&lt;ul&gt;
&lt;li&gt;$l$ 是 levels of features&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Adversarial loss
&lt;ul&gt;
&lt;li&gt;類似 DCGAN&lt;/li&gt;
&lt;li&gt;$\mathcal L_{gen} = log(1-D(G_s(E(I))))$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Discriminator
&lt;ul&gt;
&lt;li&gt;$\mathcal L_{dis} = log(D(I)) + log(1-D(G_s(E(I))))$&lt;/li&gt;
&lt;li&gt;把 real image 機率拉高，把 fake image 機率拉低&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Total loss
&lt;ul&gt;
&lt;li&gt;minimize generative loss
&lt;ul&gt;
&lt;li&gt;$\lambda_t \mathcal L_t + \lambda_s \mathcal L_s + \lambda_{dist} \mathcal L_{dist} + \lambda_{gen} \mathcal L_{gen}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;maximize discriminative loss
&lt;ul&gt;
&lt;li&gt;$\lambda_{dis} \mathcal L_{dis}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;experiments&#34;&gt;Experiments&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/SQUID/table1.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;new-benchmark&#34;&gt;New Benchmark&lt;/h3&gt;
&lt;p&gt;提出一個新資料集 - DigitAnatomy。。如果包含正確順序的阿拉伯數字 1~9 則視為正常，異常包括缺失、亂序、翻轉和 zero digit。&lt;/p&gt;
&lt;p&gt;該資料集對於放射線成像尤其有利，原因如下:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;spatial correlation and consistent shape&lt;/li&gt;
&lt;li&gt;放射線成像要標記需要專業知識，但數字容易 debug&lt;/li&gt;
&lt;li&gt;該資料集很容易就可以獲得模擬異常的 ground truth&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;public-benchmarks&#34;&gt;Public Benchmarks&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;ZhangLab Chest X-ray
&lt;ul&gt;
&lt;li&gt;包含健康和肺炎的影像&lt;/li&gt;
&lt;li&gt;訓練集
&lt;ul&gt;
&lt;li&gt;1349 張正常&lt;/li&gt;
&lt;li&gt;3883 張異常&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;測試集
&lt;ul&gt;
&lt;li&gt;234 張正常&lt;/li&gt;
&lt;li&gt;390 張異常&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;作者從訓練集隨機挑 200 張做為調整超參數的 validation set&lt;/li&gt;
&lt;li&gt;影像都調整為 128x128&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Stanford CheXpert
&lt;ul&gt;
&lt;li&gt;對 front-view PA 影像進行評估，共有 12 種異常&lt;/li&gt;
&lt;li&gt;有 5249 張正常和 23671 張異常用作訓練
&lt;ul&gt;
&lt;li&gt;使用和 ZhangLab 相同的超參數&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;用訓練集的 250 張正常和 250 張異常進行測試&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;baselines-and-metrics&#34;&gt;Baselines and Metrics&lt;/h3&gt;
&lt;p&gt;考慮 13 個主要的 baseline&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;經典 UAD (unsupervised anomaly detection)
&lt;ul&gt;
&lt;li&gt;Auto-encoder、VAE&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;醫學影像的 SOTA
&lt;ul&gt;
&lt;li&gt;Ganomaly、f-AnoGAN、IF、SALAD&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;最近的 UAD
&lt;ul&gt;
&lt;li&gt;MemAE、CutPaste、M-KD、PANDA、PaDiM、IGD&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;除非有特別註明，不然都是從頭獨立訓練至少三次&lt;/p&gt;
&lt;h2 id=&#34;results&#34;&gt;Results&lt;/h2&gt;
&lt;h3 id=&#34;interpreting-squid-on-digitanatomy&#34;&gt;Interpreting SQUID on DigitAnatomy&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/SQUID/fig6.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;作者在 DigitAnatomy 的實驗中，故意注入異常到正常圖片中，測試模型是否可以重建正常圖片。&lt;/p&gt;
&lt;p&gt;SQUID 重建出的圖片比其他 baseline 有更多有意義的訊息，主要歸功於 space-aware memory，其產生獨特的 pattern，而且和空間訊息相關聯。&lt;/p&gt;
&lt;p&gt;一旦出現異常，in-painting block 會從字典中找出前 k 個相近的，把異常特徵增強到其對應的正常特徵，其他方法不具備此能力，所以他們重建出有缺陷的圖像。&lt;/p&gt;
&lt;p&gt;GAN 傾向於重建訓練樣本平均得到的影像。
MemAE 受益於 Memory matrix，表現較好，但對於缺失數字的異常效果不佳。&lt;/p&gt;
&lt;h3 id=&#34;benchmarking-squid-on-chest-radiography&#34;&gt;Benchmarking SQUID on Chest Radiography&lt;/h3&gt;
&lt;h4 id=&#34;limitation&#34;&gt;Limitation&lt;/h4&gt;
&lt;p&gt;作者發現目前的 SQUID 沒辦法在像素層級精確定位異常。這可以理解，因為 SQUID 是一種非監督方法，不需要標註。&lt;/p&gt;
&lt;p&gt;那些像素級別的異常檢測會遭遇放大雜訊的影響，但是由於 SQUID 是在特徵層級進行的，比像素級別更加 robust。&lt;/p&gt;
&lt;h3 id=&#34;ablating-key-properties-in-squid&#34;&gt;Ablating Key Properties in SQUID&lt;/h3&gt;
&lt;h4 id=&#34;component-study&#34;&gt;Component study&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/SQUID/table2.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;hyper-parameter-robustness&#34;&gt;Hyper-parameter robustness&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/SQUID/fig9.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;disease-free-training-requirement&#34;&gt;Disease-free training requirement?&lt;/h4&gt;
&lt;p&gt;用於醫學異常檢測的非監督方法並不常見，因為所謂的 UAD 方法並不是「非監督」的，因為他們必須只在無疾病影像上作訓練。&lt;/p&gt;
&lt;p&gt;在實踐中，要獲得健康圖片需要 manual annotation。&lt;/p&gt;
&lt;p&gt;在訓練集中考慮 disease-free 從 100% - 50% 的情況，把 SQUID 的 robust 和另外三個 baseline 進行比較。&lt;/p&gt;
&lt;p&gt;SQUID 的 memory queue 可以自動忽略少數的 anatomical patterns。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/SQUID/fig10.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>論文閱讀：A Framework for Extended Reality System Development in Manufacturing</title>
        <link>https://roykesydon.github.io/Blog/p/%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80a-framework-for-extended-reality-system-development-in-manufacturing/</link>
        <pubDate>Sat, 30 Mar 2024 00:00:01 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80a-framework-for-extended-reality-system-development-in-manufacturing/</guid>
        <description>&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;本文想在 manufacturing context 下開發一個 XR (extended reality) 架構，想用 XR 整合並改善傳統工作流程。&lt;/p&gt;
&lt;p&gt;該框架包含五個 iterative phase:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Requirement analysis&lt;/li&gt;
&lt;li&gt;Solution selection&lt;/li&gt;
&lt;li&gt;data preparation&lt;/li&gt;
&lt;li&gt;system implementation&lt;/li&gt;
&lt;li&gt;system evaluation&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;此實驗也強調了 user-centered 的方法在開發有關製造業的 XR 系統的重要性。&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;作者認為 XR 系統的整合對製造業的轉型很重要，有助於實現 Industry 4.0。&lt;/p&gt;
&lt;p&gt;盡管研究顯示 XR 在製造業中有巨大潛力，但工程師在日常生活中用 XR 的系統很少，顯示出整合 XR 到製造業是困難且具備挑戰性的。&lt;/p&gt;
&lt;p&gt;本研究想開發一個系統框架，支援未來 XR 系統在製造業的開發，而不是只停留在「wow effect」&lt;/p&gt;
&lt;h2 id=&#34;frame-of-reference&#34;&gt;Frame of reference&lt;/h2&gt;
&lt;h3 id=&#34;extended-reality-classification&#34;&gt;Extended Reality Classification&lt;/h3&gt;
&lt;p&gt;透過電腦實現的現實增強技術可以追溯到 1960s，在近年演變成多種子集，也因此產生不同術語，使人困惑。&lt;/p&gt;
&lt;p&gt;本文說的 XR 被用作總稱，代指所有以電腦為媒介的 Reality Technologies。&lt;/p&gt;
&lt;p&gt;區分不同系統的 XR 十分重要，這樣才能針對製造業中任何一個特定的應用作出正確的決策。&lt;/p&gt;
&lt;p&gt;一種常見的方法是 reality-virtuality continuum，把現實世界和虛擬世界放在兩端，根據靠近哪端進行區分。&lt;/p&gt;
&lt;p&gt;左端是現實世界，右端是虛擬世界。從左到右出現 augmented reality(AR)、mixed reality(MR) 和 virtual reality(VR)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Augmented Reality (AR)
&lt;ul&gt;
&lt;li&gt;最廣泛的定義，有以下三個特徵
&lt;ul&gt;
&lt;li&gt;結合虛擬與現實&lt;/li&gt;
&lt;li&gt;要可以 real-time 的互動&lt;/li&gt;
&lt;li&gt;顯示在 3D 空間&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;用戶要依然可以看到周遭環境，並與之互動，同時獲得諸如文字或圖片的增強體驗&lt;/li&gt;
&lt;li&gt;可透過 smart glass 或手機實現&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Mixed Reality (MR)
&lt;ul&gt;
&lt;li&gt;可以定義為把現實世界和虛擬世界中的東西呈現在一起的應用程式，也就是 reality-virtuality continuum 上的任何位置&lt;/li&gt;
&lt;li&gt;MR 比 AR 更進一步，不只希望虛擬物體疊加在現實世界上，還希望使用者可以像對待真實物體一樣和他們互動&lt;/li&gt;
&lt;li&gt;為了實現 MR，需要一台整合了電腦、半透明玻璃、和感測器的耳機&lt;/li&gt;
&lt;li&gt;某種意義上是更具沉浸感的 AR&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Virtual Reality (VR)
&lt;ul&gt;
&lt;li&gt;使用者完全沉浸在虛擬世界中，無法看到現實世界
&lt;ul&gt;
&lt;li&gt;有三種典型設定：獨立耳機、CAVE (房間是大型投影幕)、連接到電腦的頭戴式顯示器
&lt;ul&gt;
&lt;li&gt;最後一種已佔據主導地位&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;hardware-parameters-for-extended-reality&#34;&gt;Hardware parameters for extended reality&lt;/h3&gt;
&lt;p&gt;深入了解硬體參數也很重要，會影響可用性&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Field of View (FOV)
&lt;ul&gt;
&lt;li&gt;人類的 binocular FOV 大約是 114 度，XR 使用的螢幕具有類似的視野才會是理想的，確保用戶有無縫體驗&lt;/li&gt;
&lt;li&gt;通常 AR 和 VR 的 FOV 會小的多，只有 30-60 度，每次呈現有限的虛擬內容，當需要渲染大型虛擬物件時就會有問題
&lt;ul&gt;
&lt;li&gt;由於 AR 和 MR 並不排斥現實世界，所以如果內容尺寸適當，不影響使用者感知&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;現今的 VR 頭戴裝置 FOV 大得多，落在 90-110 度之間
&lt;ul&gt;
&lt;li&gt;一些先進的模型甚至聲稱到 200 度，超過人類的 FOV&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;具有較小 FOV 的耳機會因為「tunnel vision effect」而分散用戶的注意力&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Frame per Second (FPS)
&lt;ul&gt;
&lt;li&gt;對於 MR 或 AR，30-60 FPS 就足夠了，VR 則建議爭取到 90&lt;/li&gt;
&lt;li&gt;由於使用者沉浸在電腦生成的內容，FPS 太低會導致 motion jitter，導致用戶產生 motion sickness&lt;/li&gt;
&lt;li&gt;FPS 不單由硬體決定，也由軟體決定&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;software-for-extended-reality&#34;&gt;Software for extended reality&lt;/h3&gt;
&lt;p&gt;作者將其分為兩大類，基於「開放開發平台的方法」和基於「已有商業軟體的擴展方法」。開放式開發平台的優點是開發過程完全受控，可以根據個人需求訂製，但需要軟體工程方面的專業知識。&lt;/p&gt;
&lt;p&gt;當今製造業使用的成熟商業軟體也在擴大對 XR 功能的支援，因此，現有用戶可以毫不費力創建 XR 體驗。然而，使用此類軟體來探索 XR 新功能的自由度有限，因為它依賴軟體供應商的更新。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Open development platform
&lt;ul&gt;
&lt;li&gt;兩大主要平台是 Unity3D 和 Unreal Engine 4&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Established commercial software
&lt;ul&gt;
&lt;li&gt;範例
&lt;ul&gt;
&lt;li&gt;Siemens 的 Plant Simulation&lt;/li&gt;
&lt;li&gt;雖然缺乏更高程度的客製化自由度，但節省了創建通用功能的時間和成本&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;research-approach&#34;&gt;Research Approach&lt;/h2&gt;
&lt;p&gt;本文為了開發一個可以提高未來 XR 系統的可用性和接受度的框架，選擇了六個案例。&lt;/p&gt;
&lt;p&gt;它們各自採用了代表了不同公司製造活動的四個階段：design、training、operation、disruptive&lt;/p&gt;
&lt;h2 id=&#34;framework-development&#34;&gt;Framework development&lt;/h2&gt;
&lt;p&gt;XR 系統整合框架的開發採用了 SDLC，也被稱作 application development life cycle，常被用在開發各種 IT 系統。
描述了系統設計人員和開發人員為了確保開發品質，需要遵循的多個階段活動。&lt;/p&gt;
&lt;p&gt;多年來，基於 SLDC 方法開發了各種模型和方法，比如瀑布式開發或是 Scrum。&lt;/p&gt;
&lt;p&gt;本研究中採用的 SDLC 階段如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Identifying problems&lt;/li&gt;
&lt;li&gt;Analyzing the needs&lt;/li&gt;
&lt;li&gt;Designing the system&lt;/li&gt;
&lt;li&gt;Developing and documenting&lt;/li&gt;
&lt;li&gt;Testing the system&lt;/li&gt;
&lt;li&gt;Implementing and maintenance&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;case-1&#34;&gt;Case 1&lt;/h3&gt;
&lt;h4 id=&#34;background&#34;&gt;Background&lt;/h4&gt;
&lt;p&gt;要訓練人員維護機器&lt;/p&gt;
&lt;h4 id=&#34;resarch-process&#34;&gt;Resarch Process&lt;/h4&gt;
&lt;p&gt;有公司進行了案例研究，開發了一種支援小型工具箱維護任務的 AR 系統&lt;/p&gt;
&lt;h4 id=&#34;result-and-conclusion&#34;&gt;Result and conclusion&lt;/h4&gt;
&lt;p&gt;文本教學容易被忽略，以吸引人的物件符號改進。
最後問卷持正面態度。
但還是有一些可改進的點，比如需要連接電腦，在實際工廠車間並不方便。&lt;/p&gt;
&lt;h3 id=&#34;case-2--case-6&#34;&gt;Case 2 ~ Case 6&lt;/h3&gt;
&lt;p&gt;時間問題暫不補&lt;/p&gt;
&lt;h2 id=&#34;the-proposed-framework&#34;&gt;The proposed framework&lt;/h2&gt;
&lt;p&gt;針對上一節 SDLC 的案例總結和整合，結合了以使用者為中心的 XR 系統開發五步驟框架。&lt;/p&gt;
&lt;h3 id=&#34;step-1-understanding-the-requirements&#34;&gt;Step 1: Understanding the requirements&lt;/h3&gt;
&lt;p&gt;聽起來很顯而易見，但實踐中常被跳過或淡化，導致不令人滿意的結果。
而且製造環境比一般用例場景更加複雜。&lt;/p&gt;
&lt;p&gt;全面了解需求是成功開發 XR 系統的重要第一步。
以使用者為中心的設計方法中，採用的比如 observation、stakeholder workshop、contextual inquiry、storyboard、prototyping adopted 都被證明在是別需求方面是有效的。&lt;/p&gt;
&lt;p&gt;應該要可以回答以下問題：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What actions are taken?&lt;/li&gt;
&lt;li&gt;What support are used?&lt;/li&gt;
&lt;li&gt;What outcome are achieved?&lt;/li&gt;
&lt;li&gt;What main drawbacks are there?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;回答上述問題後，就可以開發 storyboards 和 prototypes 了。&lt;/p&gt;
&lt;p&gt;此外，不只是開發者和負責人，最終用戶也要可以參與評估和回饋，直到最終的需求被解決。&lt;/p&gt;
&lt;h3 id=&#34;step-2-solution-selection&#34;&gt;Step 2: Solution selection&lt;/h3&gt;
&lt;p&gt;通常是根據公司現有硬軟體來選擇，而不是根據哪種解決方案最能滿足要求，使選方案是個困難的決定。&lt;/p&gt;
&lt;h3 id=&#34;step-3-data-preparation&#34;&gt;Step 3: Data preparation&lt;/h3&gt;
&lt;h3 id=&#34;step-4-system-implementation&#34;&gt;Step 4: System implementation&lt;/h3&gt;
&lt;h3 id=&#34;step-5-system-evaluation&#34;&gt;Step 5: System evaluation&lt;/h3&gt;
&lt;h3 id=&#34;iteration&#34;&gt;Iteration&lt;/h3&gt;
&lt;p&gt;在完成所以提出的步驟後可以迭代，以小量的改進進行迭代，直到達成特定需求。&lt;/p&gt;
&lt;h2 id=&#34;framework-validation&#34;&gt;Framework validation&lt;/h2&gt;
&lt;p&gt;該框架被用於一個真實案例，用來評估適用性。
此外，他還與六項先前的研究進行驗證，這些研究部分與提出的框架一致。&lt;/p&gt;
&lt;h3 id=&#34;the-empicial-case&#34;&gt;The empicial case&lt;/h3&gt;
&lt;p&gt;本文的框架被用於開發 VR 工具，好支援汽車公司的產品設計審查。&lt;/p&gt;
&lt;h4 id=&#34;requirement-analysis&#34;&gt;Requirement analysis&lt;/h4&gt;
&lt;p&gt;是一家分布全球的汽車公司，研發中心在瑞典，工廠在中國。&lt;/p&gt;
&lt;p&gt;具體任務是對用於點焊的新型 fixtures 進行 design review。&lt;/p&gt;
&lt;p&gt;目前的做法依賴 CAD 軟體分布在不同地點的不同團隊之間來傳達理念。&lt;/p&gt;
&lt;p&gt;他還需要一個或多個原型，在最終安裝前進行驗證。&lt;/p&gt;
&lt;p&gt;主要缺點是，和原型實體相關的溝通十分冗長。&lt;/p&gt;
&lt;p&gt;此外，最終使用者 ( operators of fixtures) 缺發 CAD 設計的專業知識，導致他們無法參與設計。&lt;/p&gt;
&lt;p&gt;因此，提出了具體要求：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;適用於所有 stakeholder 的虛擬工具，可以直觀地視覺化新產品設計，並和新產品設計互動&lt;/li&gt;
&lt;li&gt;多個 stakeholder 可以從不同的地點參與同一個 virtual session&lt;/li&gt;
&lt;li&gt;所有 stakeholder 都可以口頭交流&lt;/li&gt;
&lt;li&gt;virtual session 可以用圖像或影片形式記錄&lt;/li&gt;
&lt;li&gt;每個 stakeholder 都要有個人化虛擬代表&lt;/li&gt;
&lt;li&gt;要有主持人、與會者和觀眾等角色相關功能&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;solution-selection&#34;&gt;Solution selection&lt;/h4&gt;
&lt;p&gt;選 VR 和 Unity3D&lt;/p&gt;
&lt;h4 id=&#34;data-preparation&#34;&gt;Data preparation&lt;/h4&gt;
&lt;h4 id=&#34;system-implementation&#34;&gt;System implementation&lt;/h4&gt;
&lt;h4 id=&#34;system-evaluation&#34;&gt;System evaluation&lt;/h4&gt;
&lt;p&gt;進行兩次迭代開發，評估 VR 系統是否可以補充或甚至取代現有作法的可行性&lt;/p&gt;
&lt;h4 id=&#34;outcome&#34;&gt;Outcome&lt;/h4&gt;
&lt;p&gt;開發了一個可以支援最多 20 個使用者從任何有網路的地方連線加入的應用程式。&lt;/p&gt;
&lt;h3 id=&#34;external-validation&#34;&gt;External Validation&lt;/h3&gt;
&lt;p&gt;作者挑了七篇有關的 XR 整合到製造業的研究，他們都採取了類似的方法，部分與提出的框架一致。&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;本文第一個貢獻是根據案例結果提出的框架，由五個迭代階段組成：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Requirement analysis&lt;/li&gt;
&lt;li&gt;Solution selection&lt;/li&gt;
&lt;li&gt;Data preparation&lt;/li&gt;
&lt;li&gt;System implementation&lt;/li&gt;
&lt;li&gt;System evaluation&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;通過一個實際案例以及七項先前的研究進行了驗證，這些研究與提出的框架部分一致。&lt;/p&gt;
&lt;p&gt;該研究還會工業從業者提供了知識，有利他們採用 XR 技術做為 工業 4.0 的一部分。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>MRL 論文閱讀</title>
        <link>https://roykesydon.github.io/Blog/p/mrl-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</link>
        <pubDate>Mon, 26 Feb 2024 00:08:46 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/mrl-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</guid>
        <description>&lt;p&gt;paper: &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2205.13147&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Matryoshka Representation Learning&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;想設計 flexible 的 representation 好適應不同的下游任務&lt;/p&gt;
&lt;p&gt;MRL 根據不同的 granularities 來 encode 資訊，並允許一個 single embedding 來適應下游任務的運算限制&lt;/p&gt;
&lt;p&gt;MRL 學習從 coarse-to-fine 的 representation，至少和獨立訓練低維度的 representation 有一樣的準確度&lt;/p&gt;
&lt;p&gt;在相同精準度下，MRL 的 embedding 縮小 14 倍&lt;/p&gt;
&lt;p&gt;在 ImageNet-1K 和 4K 上進行大規模檢索時，實際速度提升 14 倍&lt;/p&gt;
&lt;p&gt;long-tail few-shot learning 的準確度提高 2%，並且和原有 representation 一樣 robust&lt;/p&gt;
&lt;p&gt;最後，作者證明 MRL 可以無縫地擴展到各種模式的網路規模資料集，包含 Vision, Vision + Language, 和 Language&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;deep representation 的 deployment 有兩個步驟：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;昂貴的 forward-pass 計算 representation&lt;/li&gt;
&lt;li&gt;representations 在下游的利用 (比如檢索)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在 web-scale 上，這種利用的成本蓋過了特徵計算成本&lt;/p&gt;
&lt;p&gt;常見的做法的 representation 的剛性迫使多個任務中使用高維嵌入向量&lt;/p&gt;
&lt;p&gt;人類對自然世界的感知是由粗到細的粒度&lt;/p&gt;
&lt;p&gt;然而，或許是基於梯度訓練的 inductive-bias，深度學習傾向於將「資訊」擴散到整個表示向量中&lt;/p&gt;
&lt;p&gt;通常透過訓練多個低維模型、聯合優化不同容量的子網路、事後壓縮，在現有的 fixed representation 上實現彈性&lt;/p&gt;
&lt;p&gt;這些技術中的每一種都難以滿足自適應大規模部屬的要求，基於開銷 / 維護考量等等&lt;/p&gt;
&lt;p&gt;MRL 以 nested 的方式來學習 O(log(d)) 個相同的高維向量、但不同 capacity 的 representation，因此被稱為 Matryoshka&lt;/p&gt;
&lt;p&gt;Matryoshka Representation 提高了大規模分類和檢索的效率，而不會顯著失去準確度&lt;/p&gt;
&lt;p&gt;本文重點關注在機器學習系統的兩個關鍵模組：大規模分類和檢索&lt;/p&gt;
&lt;p&gt;在分類上，作者使用 variable-size representations 結合 adaptive cascades 來顯著減少實現特定精度所需嵌入的平均維度&lt;/p&gt;
&lt;p&gt;例如，在 ImageNet-1K 上，MRL + Adaptive classification 在和 baseline 同精準度的情況下將 representation 縮小 14 倍&lt;/p&gt;
&lt;p&gt;對於檢索，先用 query embedding 一開始的 few dimensions 來減少 retrieval candidates，然後再用更多的 dimensions 來 re-rank retrieved set&lt;/p&gt;
&lt;p&gt;MRL 的檢索精確度和 single-shot retrieval 相當&lt;/p&gt;
&lt;p&gt;主要貢獻如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;提出了 MRL 來獲得 filexible 的 representation for adaptive deployment&lt;/li&gt;
&lt;li&gt;使用 MRL 進行大規模分類和檢索，速度提高 14 倍而且一樣準確&lt;/li&gt;
&lt;li&gt;可以在跨 modalities 還有可接受 web-scale 資料的情況下無縫調整 MRL&lt;/li&gt;
&lt;li&gt;在其他下游任務的背景下進一步分析 MRL 的表示&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;related-work&#34;&gt;Related Work&lt;/h2&gt;
&lt;h3 id=&#34;efficient-classification-and-retrieval&#34;&gt;Efficient Classification and Retrieval&lt;/h3&gt;
&lt;p&gt;在推理過程中，分類和檢索的效率可以從兩個方面研究：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;深度特徵的高但恆定的成本&lt;/li&gt;
&lt;li&gt;隨著標籤空間和數據大小而變化的搜索成本&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;第一個問題可以透過不同的演算法設計高效的神經網路來解決&lt;/p&gt;
&lt;p&gt;但是，伴隨著強大的 featurizer，多數 scale 相關的問題出在 標籤數量(L)、資料大小(N)、或是表示維度(d) 這種 linear dependence 上&lt;/p&gt;
&lt;p&gt;讓 RAM, disk 和 CPU 都同時有巨大的壓力&lt;/p&gt;
&lt;p&gt;標籤數量在計算和 RAM 方面已經得到了很好的研究，可以透過 Approximate Nearest Neighbor Search (ANNS) 或 leveraging the underlying hierarchy 來解決&lt;/p&gt;
&lt;p&gt;在表示大小方面，降維、Hash 和特徵選擇等技術常用於緩解 O(d) 的增長規模，但代價是精確度的顯著降低&lt;/p&gt;
&lt;p&gt;ANNS 使用戶可以從資料庫中取得和請求最相似的文件或圖片&lt;/p&gt;
&lt;p&gt;廣泛採用的 HNSW 可以讓 O(d log(N))  和準確搜索 O(dN) 一樣精準，但代價是需要在 RAM 和 disk 承擔 graph-based index 的開銷&lt;/p&gt;
&lt;p&gt;MRL 解決對 d 的線性依賴問題，低維度的 Mayryoshka representations 和獨立訓練的 representations 一樣準確，而不需要多次昂貴的前向傳遞&lt;/p&gt;
&lt;h2 id=&#34;matryoshka-representation-learning&#34;&gt;Matryoshka Representation Learning&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/MRL/fig1.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;有分兩種訓練方法：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Matryoshka Representation Learning (MRL)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在後面接 9 層 MLP，不是串聯，是並聯&lt;/li&gt;
&lt;li&gt;比如 mlp(768,8)&amp;hellip;., mlp(768,2048)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Efficient Matryoshka Representation Learning (MRL-E)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在後面只接 1 層，然後取前面維度得到一個向量，以此類推&lt;/li&gt;
&lt;li&gt;比如 mlp(768, 2048)，可能取前 16 維當一個向量，然後再取前 64 維當一個向量&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>REALM 論文閱讀</title>
        <link>https://roykesydon.github.io/Blog/p/realm-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</link>
        <pubDate>Fri, 05 Jan 2024 00:00:13 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/realm-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</guid>
        <description>&lt;p&gt;paper: &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2002.08909&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;REALM: Retrieval-Augmented Language Model Pre-Training&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;為了用更加模組化和可解釋的方式獲取知識，作者用 latent knowledge retriever 來加強語言模型的預訓練，latent knowledge retriever 允許模型檢索 large corpus 的 document，並在預訓練、微調和推理時使用。&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/REALM/fig1.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;在諸如 BERT 的語言模型中，學到的 world knowledge 隱式地儲存在神經網路的參數中，使其很難確定儲存了哪些知識以及儲存在何處。而且儲存空間受網路大小限制，但訓練更大的網路可能非常昂貴&lt;/p&gt;
&lt;p&gt;本文為了以更加可解釋和模組化的方式獲取知識，提出了一個新穎的框架，Retrieval-Augmented Language Model (REALM) 預訓練，透過 learned textual knowledge retriever 來加強預訓練&lt;/p&gt;
&lt;p&gt;和把知識儲存在參數中的模型相比，該方法顯示地揭示 world knowledge 扮演的角色，做法是要求模型在推理過程中決定哪些知識來 retrieve，並用在推理階段&lt;/p&gt;
&lt;p&gt;在每次預測前，語言模型使用 retriever 在 large corpus 搜索文件，並用這些文件幫助預測&lt;/p&gt;
&lt;p&gt;End to End 的學習需要考慮整個檢索步驟，好進行反向傳播&lt;/p&gt;
&lt;p&gt;REALM 有個關鍵直覺，就是訓練 retriever 的時候用的是 unsupervised text 的 performance-based signal：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一個可以提高語言模型複雜性的檢索是有幫助，且該被獎勵的&lt;/li&gt;
&lt;li&gt;資訊不足的檢索應該受到懲罰&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;比如圖 Fig.1 找到的文件就該獲得獎勵&lt;/p&gt;
&lt;p&gt;作者將 retrieve-then-predict 的方法建模並視作 latent variable language model 並優化 marginal likelihood&lt;/p&gt;
&lt;p&gt;但在預訓練期間要訓練大規模的 retrieval module 成為問題，因為 Retriever 得為每個預訓練步驟考慮數百萬個候選文檔，而且必須根據決策反向傳播。為了解決這問題，作者建構了 retriever，以便快取和非同步更新每個文件的計算，並將最佳文件的選擇表示為 Maximum Inner Product Search (MIPS)&lt;/p&gt;
&lt;p&gt;透過在 Open-QA 任務上使用 REALM 預訓練的 model 來 finetune 進行評估，OpenQA 是最 knowledge-intensive 的任務之一&lt;/p&gt;
&lt;p&gt;作者挑了三個流行的 Open-QA benchmark，比如 NaturalQuestions-Open、WebQuestions、CuratedTrec，並和 SOTA Open-QA model 比較&lt;/p&gt;
&lt;p&gt;在三個基準都取得了 SOTA 的結果，absolute accuracy 明顯高於先前系統 4-16%&lt;/p&gt;
&lt;p&gt;也展示了 REALM 的 qualitative benefit，比如可解釋性和模組化&lt;/p&gt;
&lt;h2 id=&#34;background&#34;&gt;Background&lt;/h2&gt;
&lt;h3 id=&#34;open-domain-question-answering-open-qa&#34;&gt;Open-domain question answering (Open-QA)&lt;/h3&gt;
&lt;p&gt;OpenQA 的 open 是指模型不會接收到包含答案的預提供文件，和傳統的閱讀理解不同&lt;/p&gt;
&lt;h2 id=&#34;approach&#34;&gt;Approach&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/REALM/fig2.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;realms-generative-process&#34;&gt;REALM’s generative process&lt;/h3&gt;
&lt;p&gt;預訓練做 masked language modeling，微調的任務是 Open-QA&lt;/p&gt;
&lt;h3 id=&#34;model-architecture&#34;&gt;Model architecture&lt;/h3&gt;
&lt;p&gt;neural knowledge retriever 是 $p(z|x)$&lt;/p&gt;
&lt;p&gt;knowledge-augmented encoder 是 $p(y|z,x)$&lt;/p&gt;
&lt;h4 id=&#34;knowledge-retriever&#34;&gt;Knowledge Retriever&lt;/h4&gt;
&lt;p&gt;$p(z|x)=\frac{\text{exp }f(x,z)}{\sum_{z&amp;rsquo;}\text{exp }f(x,z&amp;rsquo;)}$&lt;/p&gt;
&lt;p&gt;$f(x,z) = Embed_{input}(x)^T Embed_{doc}(z)$&lt;/p&gt;
&lt;p&gt;$join_{BERT}(x)=[CLS]x[SEP]$&lt;/p&gt;
&lt;p&gt;$join_{BERT}(x_1, x_2)=[CLS]x_1[SEP]x_2[SEP]$&lt;/p&gt;
&lt;p&gt;$Embed_{input}(x)=W_{input}BERT_{CLS}(join_{BERT}(x))$&lt;/p&gt;
&lt;p&gt;$Embed_{doc}(z)=W_{doc}BERT_{CLS}(join_{BERT}(z_{title}, z_{body}))$&lt;/p&gt;
&lt;h4 id=&#34;knowledge-augmented-encoder&#34;&gt;Knowledge-Augmented Encoder&lt;/h4&gt;
&lt;p&gt;Finetune:&lt;/p&gt;
&lt;p&gt;$p(y|z,x) \propto \displaystyle\sum_{s\in S(z,y)}exp(MLP([h_{START(s)};h_{END(s)}]))$&lt;/p&gt;
&lt;p&gt;$h_{START(s)}=BERT_{START(s)}(join_{BERT}(x,z_{body}))$&lt;/p&gt;
&lt;p&gt;$h_{END(s)}=BERT_{END(s)}(join_{BERT}(x,z_{body}))$&lt;/p&gt;
&lt;h3 id=&#34;training&#34;&gt;Training&lt;/h3&gt;
&lt;p&gt;關鍵的計算挑戰是 $p(y|x)=\sum_{z\in Z}p(y|x,z)p(z,x)$，涉及到 Z knowledge corpus 中的 所有 document z，因此只取機率 $p(z|x)$ 最高的 top k 文件來求和，考量到多數文件的機率應該為 0，這是合理的&lt;/p&gt;
&lt;p&gt;但是依然需要一個有效的方法來尋找前 k 個文件&lt;/p&gt;
&lt;p&gt;前面的 $f(x,z)$ 是一個內積，可以用  Maximum Inner Product Search (MIPS) 演算法來尋找近似前 k 個文檔&lt;/p&gt;
&lt;p&gt;為了用 MIPS，要先用一種 embedding 函式來幫 z encode，但是如果更新了這個函式，資料結構和 $p(z|x)$ 又會不一致&lt;/p&gt;
&lt;p&gt;因此，每次對 embedding 函式更新後，search index 都會變 &amp;ldquo;stale&amp;rdquo; (陳舊)&lt;/p&gt;
&lt;p&gt;每隔數百個訓練步驟非同步重新 embed 和 index 所有 document 來刷新 index&lt;/p&gt;
&lt;p&gt;MIPS 的 index 在刷新之前會有點 stale，但它只用於挑選前 k 個文件&lt;/p&gt;
&lt;p&gt;結果證明，只要在恰當的刷新率下，還是可以穩定 optimize&lt;/p&gt;
&lt;h4 id=&#34;what-does-the-retriever-learn&#34;&gt;What does the retriever learn?&lt;/h4&gt;
&lt;p&gt;這裡展示了它如何獎勵提高預測準確性的檢索&lt;/p&gt;
&lt;p&gt;$\triangledown \text{log }p(y|x)=\displaystyle\sum_{z\in Z}r(z)\triangledown f(x,z)$&lt;/p&gt;
&lt;p&gt;$r(z)=[\frac{p(y|z,x)}{p(y|x)}-1]p(z|x)$&lt;/p&gt;
&lt;p&gt;如果 $r(z)$ 是正的，會讓 f(x,z) 提高，否則減低&lt;/p&gt;
&lt;p&gt;$r(z)$ 只有在 $p(y|z,x)&amp;gt;p(y|x)$ 的情況下才會是正的&lt;/p&gt;
&lt;p&gt;$p(y|x)$ 是 $p(y|x,z)$ 在隨機取樣的情況下的期望值&lt;/p&gt;
&lt;p&gt;只要文檔 z 好過預期，就會持續正面更新&lt;/p&gt;
&lt;h3 id=&#34;injecting-inductive-biases-into-pre-training&#34;&gt;Injecting inductive biases into pre-training&lt;/h3&gt;
&lt;p&gt;在發展 REALM 的過程中，作者發現幾個額外策略，可以進一步引導模型進行有意義的檢索&lt;/p&gt;
&lt;h4 id=&#34;salient-span-masking&#34;&gt;Salient span masking&lt;/h4&gt;
&lt;p&gt;有一些 MLM span 只需要 local context，但作者想專注於 world knowledge&lt;/p&gt;
&lt;p&gt;所以作者會 mask 一些 salient span，比如「英國」、「1969 年 7 月」&lt;/p&gt;
&lt;p&gt;作者用在 CoNLL-2003 上訓練的 BERT-based tagger，來找出 named entities，並用正規表達式來找出日期&lt;/p&gt;
&lt;p&gt;結果表明這顯著優於其他 mask 策略&lt;/p&gt;
&lt;h4 id=&#34;null-document&#34;&gt;Null document&lt;/h4&gt;
&lt;p&gt;雖然 Salient span masking 表現很好，但不是所有 mask 都需要 world knowledge&lt;/p&gt;
&lt;p&gt;透過向前 top k 文檔中多加一個空的文檔，允許在不需要檢索有空白選項&lt;/p&gt;
&lt;h4 id=&#34;prohibiting-trivial-retrievals&#34;&gt;Prohibiting trivial retrievals&lt;/h4&gt;
&lt;p&gt;如果 mask 的句子來自文件 z，可以透過查看 z 中 x 的 unmasked 版本來輕鬆預測 y，使 p(z|x) 出現較大的梯度，如果這種情況太頻繁，會使 retriever 最終學會的東西偏向 exact match，而不會捕獲其他形式的相關性&lt;/p&gt;
&lt;p&gt;因此，在預訓練期間排除了 trivial candidate&lt;/p&gt;
&lt;h4 id=&#34;initialization&#34;&gt;Initialization&lt;/h4&gt;
&lt;p&gt;在訓練開始時，如果 input 和 document 各自的 Embedding function 沒有良好的效能，會使檢索到的 z 和 x 無關&lt;/p&gt;
&lt;p&gt;會導致模型學習忽略檢索到的文件，檢索器就不會收到有意義的梯度，也無法改進&lt;/p&gt;
&lt;p&gt;為了避免 cold-start problem，作者採用 warm-start 方案，先以  Inverse Cloze Task (ICT) 這種簡單的目標來處理兩個 embedding function，給定一個句子，訓練模型檢索句子來自的文檔&lt;/p&gt;
&lt;h2 id=&#34;experiments&#34;&gt;Experiments&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/REALM/table1.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/REALM/table2.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;open-qa-benchmarks&#34;&gt;Open-QA Benchmarks&lt;/h3&gt;
&lt;p&gt;本文將重點放在問題作者不知道答案的資料集，比較能反映現實中的問題&lt;/p&gt;
&lt;h4 id=&#34;naturalquestions-open&#34;&gt;NaturalQuestions-Open&lt;/h4&gt;
&lt;p&gt;由自然發生的 google 查詢和答案組成，每個答案還帶有 answer type&lt;/p&gt;
&lt;p&gt;本文只用屬於 &amp;ldquo;short answer type&amp;rdquo; 的問題，最多有 5 個 token&lt;/p&gt;
&lt;h4 id=&#34;webquestions&#34;&gt;WebQuestions&lt;/h4&gt;
&lt;p&gt;從 Google Suggest API 收集的&lt;/p&gt;
&lt;h4 id=&#34;curatedtrec&#34;&gt;CuratedTrec&lt;/h4&gt;
&lt;p&gt;從 MSNSearch 和 AskJeeves 等網站上真實使用者查詢中提取的問答&lt;/p&gt;
&lt;h3 id=&#34;approaches-compared&#34;&gt;Approaches compared&lt;/h3&gt;
&lt;h4 id=&#34;retrieval-based-open-qa&#34;&gt;Retrieval-based Open-QA&lt;/h4&gt;
&lt;p&gt;最近的一些方法提出用 MIPS index 來實現可訓練的檢索&lt;/p&gt;
&lt;p&gt;ORQA 與 REALM 類似&lt;/p&gt;
&lt;p&gt;但 REALM 提出了更新穎的模型預訓練步驟，並反向傳播到 MIPS index 中，而不用固定的 index&lt;/p&gt;
&lt;p&gt;上面指的應該是有關於非同步更新 index 的部分，還可以梯度更新&lt;/p&gt;
&lt;p&gt;值得注意的是，REALM 和 OrQA 的預訓練都是用 ICT 初始化的&lt;/p&gt;
&lt;h4 id=&#34;generation-based-open-qa&#34;&gt;Generation-based Open-QA&lt;/h4&gt;
&lt;p&gt;Open-QA 的新興替代方案是將其建模為序列預測任務，只需對問題進行編碼，然後根據編碼逐個標記編碼答案&lt;/p&gt;
&lt;p&gt;GPT2 可以透過 sequence to sequence 直接產生答案，而不需要給指定的上下文，但可能由於缺乏 finetune 而沒有競爭力&lt;/p&gt;
&lt;p&gt;同時，T5 表明，直接生成答案而不從給定上下文中明確提取是可行的方法，但他們只在提供上下文文檔的閱讀理解任務上進行實驗&lt;/p&gt;
&lt;p&gt;為了和最具競爭力的 baseline 比較，本文與針對 Open-QA finetune 的 T5 進行比較&lt;/p&gt;
&lt;h3 id=&#34;implementation-details&#34;&gt;Implementation Details&lt;/h3&gt;
&lt;h4 id=&#34;fine-tuning&#34;&gt;Fine-tuning&lt;/h4&gt;
&lt;p&gt;文件被貪婪地分割成多達 288 個 BERT wordpieces 的 chunk，產生超過 1300 萬個 retrieval candidates&lt;/p&gt;
&lt;p&gt;在微調推理過程中，考慮前五個候選者&lt;/p&gt;
&lt;h4 id=&#34;pre-training&#34;&gt;Pre-training&lt;/h4&gt;
&lt;p&gt;使用 BERT 的預設優化器在 64 個 Google Cloud TPU 上預訓練 20 萬步&lt;/p&gt;
&lt;p&gt;MIPS 在 16 個 TPU 上並行&lt;/p&gt;
&lt;h3 id=&#34;main-results&#34;&gt;Main results&lt;/h3&gt;
&lt;p&gt;REALM 在 table.1 明顯優於之前的所有方法&lt;/p&gt;
&lt;p&gt;REALM 最直接的比較是 ORQA，微調設定、超參數和訓練資料都相通&lt;/p&gt;
&lt;p&gt;REALM 對比 ORQA 的改進純粹是更好的預訓練方法&lt;/p&gt;
&lt;p&gt;而且本文表明他們的預訓練方法可以用在 single-corpus setting 或 seperate corpus setting&lt;/p&gt;
&lt;p&gt;兩者的差別在 X 和 Z 來源一不一樣&lt;/p&gt;
&lt;h3 id=&#34;analysis&#34;&gt;Analysis&lt;/h3&gt;
&lt;p&gt;table.2 展現了去除 REALM 關鍵組件後的結果&lt;/p&gt;
&lt;p&gt;還展現了 finetune 前 gold answer 出現在前五個檢索中的頻率&lt;/p&gt;
&lt;h4 id=&#34;masking-scheme&#34;&gt;Masking scheme&lt;/h4&gt;
&lt;p&gt;salient span masking 在先前標準的 BERT 訓練中尚未被證明具有影響力，但對於 REALM 至關重要&lt;/p&gt;
&lt;h4 id=&#34;mips-index-refresh-rate&#34;&gt;MIPS index refresh rate&lt;/h4&gt;
&lt;p&gt;在預訓練期間，運行並行過程來重新 embed document 和重建 MIPS index&lt;/p&gt;
&lt;p&gt;導致每大約 500 個訓練步驟刷新一次 index&lt;/p&gt;
&lt;p&gt;為了證明頻繁刷新的重要性，也和較慢刷新率比較&lt;/p&gt;
&lt;p&gt;table.2 顯示，stale index 可能會傷害模型，進一步減少這種過時性可以提供更好的最佳化&lt;/p&gt;
&lt;h2 id=&#34;discussion-and-related-work&#34;&gt;Discussion and Related Work&lt;/h2&gt;
&lt;h3 id=&#34;scalable-grounded-neural-memory&#34;&gt;Scalable grounded neural memory&lt;/h3&gt;
&lt;p&gt;document index 可以被視為一種 memory，key 是 document embedding&lt;/p&gt;
&lt;p&gt;從這角度來看，本文的工作和 product key memory 有共同的動機，它能夠在記憶體網路中實現低於線性的存取&lt;/p&gt;
&lt;p&gt;一個主要的區別是本文的記憶體是有根據的，每個 memory 都和一個文檔相關聯，而不是和 unnamed value vector 相關聯&lt;/p&gt;
&lt;p&gt;這種程度的可解釋性對 Open-QA 至關重要，在這些應用程式中，用戶需要出處才能使預測答案值得信賴&lt;/p&gt;
&lt;h2 id=&#34;future-work&#34;&gt;Future Work&lt;/h2&gt;
</description>
        </item>
        <item>
        <title>DPR 論文閱讀</title>
        <link>https://roykesydon.github.io/Blog/p/dpr-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</link>
        <pubDate>Thu, 28 Dec 2023 00:00:13 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/dpr-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</guid>
        <description>&lt;p&gt;paper: &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2004.04906&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Dense Passage Retrieval for Open-Domain Question Answering&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;Open-domain question answering 依賴有效的 passage retrieval 來選擇 candidate context，傳統上用的 sparse vector space models，有 TF-IDF、BM25 等等&lt;/p&gt;
&lt;p&gt;本文顯示出檢索實際上可以只用 dense representation，embedding 是從少量的 question 和 passage 學到的，利用簡單的 dual-encoder framework&lt;/p&gt;
&lt;p&gt;在廣泛的 open-domain QA 資料集上，本文的 dense retriever 在 top-20 passage retrieval accuracy 上比 Lucene BM25 好 9%-19%&lt;/p&gt;
&lt;p&gt;並幫助作者的 end-to-end QA system 在 multiple open-domain QA benchmarks 上取得 SOTA&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;早期閱讀理解模型提出了簡單的 two-stage framework：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;一個 context retriever 先選定一些 passage 子集合，其中某一些 passage 包含答案&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;一個 machine reader，可以徹底檢查選出的 context 並找到答案&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;盡管將 open-domain QA 簡化為 machine reading 是一個合理的策略，但是實際上經常看到嚴重的性能下降，顯示出需要改進 retrieval&lt;/p&gt;
&lt;p&gt;open-domain QA 中的 retrieval 通常用 TF-IDF 或 BM25 來實現，可以透過 inverted index 有效地 match keywords，而且把 question 和 context 表示為 high-dimensional sparse vectors&lt;/p&gt;
&lt;p&gt;相反的，Dense latent semantic encoding 在設計上和 sparse representation 是互補的&lt;/p&gt;
&lt;p&gt;例如，由完全不同的 token 組成的兩個同義詞依然可以映射到接近的向量&lt;/p&gt;
&lt;p&gt;term-based system 相較 dense retrieval system 很難將比如「壞人」和「惡棍」匹配&lt;/p&gt;
&lt;p&gt;Dense encoding 也可以透過調整 embedding function 來學習，對於 task-specific 的 representation 提供了彈性&lt;/p&gt;
&lt;p&gt;透過特殊的 in-memory data structure 和 indexing scheme，可以用 maximum inner product search (MIPS) 來快速檢索&lt;/p&gt;
&lt;p&gt;然而，人們普遍認為學習良好的 dense vector representation 需要大量的 QA labeled pair&lt;/p&gt;
&lt;p&gt;因此，在 ORQA 之前，Dense retrieval 從沒被證明過可以在 open-domain QA 上贏過 TF-IDF 或 BM25&lt;/p&gt;
&lt;p&gt;ORQA 提出了 ICT 來做額外的預訓練&lt;/p&gt;
&lt;p&gt;盡管 ORQA 證明了 dense retrieval 可以超越 BM25，在多個 open-domain QA 資料集上取得 SOTA，但他也存在兩個弱點：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;ICT 預訓練是 compute-intensive，而且不確定 regular sentence 是否能很好的替代 objective function 中的 question&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;由於 context encoder 沒有用 QA pair 進行 finetune，因此相應的 representation 可能不是最佳的&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在本文中，本文將解決一個問題 &amp;ndash; 我們是否可以只用 QA pair 來訓練更好的 dense embedding model，而不用額外的預訓練？&lt;/p&gt;
&lt;p&gt;利用現在的 standard BERT pre-trained model 以及 dual-encoder architecture，本文專注於用相對少量的 question and passage pair 來訓練 dense retriever&lt;/p&gt;
&lt;p&gt;經過一系列的 ablation study，本文的解決方案出奇的簡單&lt;/p&gt;
&lt;p&gt;embedding 可以用最大化 question 和 相關的 passage 的 inner product 來訓練&lt;/p&gt;
&lt;p&gt;作者的 Dense Passage Retrieval (DPR)  非常強大，不僅大幅優於 BM25，而且和 ORQA 相比，end-to-end QA 準確度也有大幅提升&lt;/p&gt;
&lt;p&gt;作者的貢獻有兩部分：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;作者證明在適當的設置下，只需在現有 question-passge pair 上 finetune question and passage encoder，就可以大幅超過 BM25，實驗結果也證明可能不用額外的預訓練&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;作者證明了在 open-domain QA 的背景下，更高的 retrieval accuracy 可以轉化為更高的 end-to-end QA accuracy&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;透過對 top retrived passage 使用 modern reader model，和幾個非常複雜的系統相比，作者在 open-retrieval setting 下的多個資料集取得了可比較或更好的結果&lt;/p&gt;
&lt;h2 id=&#34;background&#34;&gt;Background&lt;/h2&gt;
&lt;p&gt;本文研究的 open-domain QA 的描述如下：&lt;/p&gt;
&lt;p&gt;先給出一個事實性問題，不屬於特定主題，需要一個系統使用大量多樣化主題的 corpus 來回答&lt;/p&gt;
&lt;p&gt;更具體地說，作者假設 extractive QA setting，答案僅限於 corpus 中的一個或多個 passage 中出現的範圍&lt;/p&gt;
&lt;p&gt;假設有 D 個 documents，先把每個 document 拆成多個等長的 text passage，好做為 basic retrieval unit，最後得到 M 個 passage in corpus C&lt;/p&gt;
&lt;p&gt;每個 passage 可以被視作一個 token 序列&lt;/p&gt;
&lt;p&gt;對於 question q，則是要找到某段 passage 中的一串連續的 token 來回答&lt;/p&gt;
&lt;p&gt;值得注意的一點是，為了涵蓋盡可能廣泛的概念，corpus 的大小可能會從數百萬個文件到數十億個文件不等&lt;/p&gt;
&lt;p&gt;因此，任何 open-domain QA system 都需要一個高效的 retriever，可以在 reader 提取答案前選擇一小組相關的文本&lt;/p&gt;
&lt;h2 id=&#34;dense-passage-retriever-dpr&#34;&gt;Dense Passage Retriever (DPR)&lt;/h2&gt;
&lt;p&gt;作者的研究重點是改進 open-domain QA 的 retrieval component&lt;/p&gt;
&lt;p&gt;給定 M 個 passage，DPR 的目標是把所有 low-dimensional continuous space 的所有 passage 都給 index，使它可以有效地檢所和輸入問題相關的 top-k passage&lt;/p&gt;
&lt;p&gt;M 有可能非常大，比如本文有 21M 個 passage，而 k 通常很小，可能只有 20~100 個&lt;/p&gt;
&lt;h3 id=&#34;overview&#34;&gt;Overview&lt;/h3&gt;
&lt;p&gt;用 dense encoder $E_P(．)$ 和 $E_Q(．)$ 來分別 encode passage 和 question，在計算兩者的 inner product 來衡量相似度&lt;/p&gt;
&lt;p&gt;盡管確實存在測量 question 和 passage 之間更具表現力的模型形式，比如帶有 cross-attention 的 multi-layer networks，但是 similarity function 需要可以分解，才可以預先計算 passage 的 embedding&lt;/p&gt;
&lt;p&gt;大多數 decomposable similarity function 是 Euclidean distance (L2) 的變換&lt;/p&gt;
&lt;p&gt;比如，consine 是 unit vector 的 inner product，而 Mahalanobis distance 等同於在 transformed space 的 L2 distance&lt;/p&gt;
&lt;p&gt;由於 ablation study 表示其他相似含數的表現相當，因此選擇更簡單的內積函數，並透過學習更好的 encoder 來改善 dense passage retriever&lt;/p&gt;
&lt;h4 id=&#34;encoder&#34;&gt;Encoder&lt;/h4&gt;
&lt;p&gt;本文採用兩個獨立的 BERT，並把 [CLS] token 的 representation 當作 output&lt;/p&gt;
&lt;h4 id=&#34;inference&#34;&gt;Inference&lt;/h4&gt;
&lt;p&gt;推理階段，將 passage encoder $E_P$ 應用在所有 passage，並用 FAISS offline index&lt;/p&gt;
&lt;p&gt;FAISS 是一個非常高效的 open-source library，用在 similarity search 和 clustering of dense vectors，可以輕鬆應用在數十億個向量上&lt;/p&gt;
&lt;p&gt;在推論接段，計算 q 的 embedding，然後用 FAISS 來找到 top-k passages&lt;/p&gt;
&lt;h3 id=&#34;training&#34;&gt;Training&lt;/h3&gt;
&lt;p&gt;每一個 training instance 都包含問題 q，還有一個正 (相關) passage，以及 n 個負 (不相關) passages&lt;/p&gt;
&lt;h4 id=&#34;positive-and-negative-passages&#34;&gt;Positive and negative passages&lt;/h4&gt;
&lt;p&gt;對於檢索問題，正例通常明確可用，而反例則通常要從非常大的 pool 中選擇&lt;/p&gt;
&lt;p&gt;正例可能會在 QA 資料集給出，或是可以從答案找到，其他的段落預設情況下都可視為不相關&lt;/p&gt;
&lt;p&gt;在實踐中，如何選擇負例常被忽視，但對於學習 high-quality encoder 可能很關鍵&lt;/p&gt;
&lt;p&gt;考慮三種負例：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;隨機
&lt;ul&gt;
&lt;li&gt;Corpus 中隨機選擇&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;BM25
&lt;ul&gt;
&lt;li&gt;BM25 返回的 passage 不含答案，但包含最多 question token&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Gold
&lt;ul&gt;
&lt;li&gt;positive 和 question 配對&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;第 2 和 3 種是在說拿其他問題的正例當負例&lt;/p&gt;
&lt;h4 id=&#34;in-batch-negatives&#34;&gt;In-batch negatives&lt;/h4&gt;
&lt;p&gt;有 B 訓練實體，每個問題有 B-1 個 negative passage，只有 i = j 時，$(q_i, p_j)$ 是正例，其他都是負例&lt;/p&gt;
&lt;p&gt;in-batch negative 的技巧已被用在 full batch setting 和 mini-batch setting&lt;/p&gt;
&lt;p&gt;已被證明是學習 dual-encoder 的有效策略，可以增加訓練範例的數量&lt;/p&gt;
&lt;h2 id=&#34;experimental-setup&#34;&gt;Experimental Setup&lt;/h2&gt;
&lt;h3 id=&#34;wikipedia-data-pre-processing&#34;&gt;Wikipedia Data Pre-processing&lt;/h3&gt;
&lt;p&gt;用 DrQA 提供的預處理程式碼從 Wikipedia dump 中提取文章中乾淨的文字部分&lt;/p&gt;
&lt;p&gt;此步驟將刪除 semi-structured data，比如表格和 info-boxes&lt;/p&gt;
&lt;p&gt;接著將每天文章分成多個不相交的文字區塊，每個文字區塊由 100 個單字組成，作為 basic retrieval unit，最後會有 21,015,324 個 passage&lt;/p&gt;
&lt;p&gt;每個 passage 也帶有標題以及 [SEP]&lt;/p&gt;
&lt;h3 id=&#34;selection-of-positive-passages&#34;&gt;Selection of positive passages&lt;/h3&gt;
&lt;p&gt;由於 TREC, WebQuestions 和 TriviaQA 中只有 question-answer pair，因此使用 BM25 把包含答案最多的 passage 當作正例&lt;/p&gt;
&lt;p&gt;如果檢索到的前 100 篇文章中沒有答案，則該問題會被丟棄&lt;/p&gt;
&lt;h2 id=&#34;experiments-passage-retrieval&#34;&gt;Experiments: Passage Retrieval&lt;/h2&gt;
&lt;h3 id=&#34;main-results&#34;&gt;Main Results&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/DPR/table2.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;SQuAD 表現較差有可能是因為 passage 和 question 存在高度詞彙重疊，給 BM25 帶來優勢，而且資料僅從 500 多篇 wiki 文章中蒐集，因此訓練範例的分佈存在極大的 bias&lt;/p&gt;
&lt;p&gt;當用多個資料集訓練時，TREC（裡面最小的資料集）獲益最多&lt;/p&gt;
&lt;h3 id=&#34;ablation-study-on-model-training&#34;&gt;Ablation Study on Model Training&lt;/h3&gt;
&lt;h4 id=&#34;sample-efficiency&#34;&gt;Sample efficiency&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/DPR/fig1.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h4 id=&#34;in-batch-negative-training&#34;&gt;In-batch negative training&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/DPR/table3.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;in-batch negative 可以顯著改善結果，還簡單且節省記憶體，可以重複使用 batch 中已經有的負例&lt;/p&gt;
&lt;p&gt;它會產生更多 pair，從而增加訓練資料的數量&lt;/p&gt;
&lt;h4 id=&#34;impact-of-gold-passages&#34;&gt;Impact of gold passages&lt;/h4&gt;
&lt;p&gt;做了 distant supervision，只有很小的影響，降低了 1 個點&lt;/p&gt;
&lt;h4 id=&#34;similarity-and-loss&#34;&gt;Similarity and loss&lt;/h4&gt;
&lt;p&gt;L2 和 inner product 的表現相當，兩個都比 cosine 好&lt;/p&gt;
&lt;p&gt;有一種流行的 ranking loss 叫做 triplet loss，但是在本文中，作者發現它的表現不會對結果產生太大影響&lt;/p&gt;
&lt;h4 id=&#34;cross-dataset-generalization&#34;&gt;Cross-dataset generalization&lt;/h4&gt;
&lt;p&gt;為了測試泛化能力，只在 Natural Questions 上訓練，在較小的 WebQuestions 和 CuratedTREC 上測試，發現泛化能力很好，輸給 SOTA finetune model 3~5 個點，但仍大大優於 BM25 baseline&lt;/p&gt;
&lt;h2 id=&#34;experiments-question-answering&#34;&gt;Experiments: Question Answering&lt;/h2&gt;
&lt;h3 id=&#34;result&#34;&gt;Result&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/DPR/table4.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;related-work&#34;&gt;Related Work&lt;/h2&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;證明了 dense retrieval 可以 outperform 甚至可能取代傳統的 sparse retrieval&lt;/p&gt;
&lt;p&gt;雖然簡單的 dual-encoder framework 可以達到很棒的效果，但作者顯示出要成功訓練也有一些關鍵因素&lt;/p&gt;
&lt;p&gt;此外，根據 empirical analysis 和 ablation study，更複雜的 model framework 或 similarity function 不一定能提供額外價值&lt;/p&gt;
&lt;p&gt;由於檢索性能的提高，在多個 open-domain QA benchmarks 上取得了 SOTA&lt;/p&gt;
</description>
        </item>
        <item>
        <title>ORQA 論文閱讀</title>
        <link>https://roykesydon.github.io/Blog/p/orqa-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</link>
        <pubDate>Mon, 25 Dec 2023 00:00:13 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/orqa-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</guid>
        <description>&lt;p&gt;paper: &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/1906.00300&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Latent Retrieval for Weakly Supervised Open Domain Question Answering&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;最近的工作常依賴於兩個假設，一個是對 supporting evidence 做 strong supervision，另一個是假設 blackbox information retrieval (IR) system 可以找到所有的 evidence candidates&lt;/p&gt;
&lt;p&gt;作者認為兩者都不是最理想的，因為 gold evidence 不總是可用，而且 QA 和 IR 有著根本上的不同&lt;/p&gt;
&lt;p&gt;作者首次證明，在沒有任何 IR 的情況下，可以從 question-answer pair 中共同學習 retriver 和 reader&lt;/p&gt;
&lt;p&gt;在這種 setting 下，來自 Wikipedia 的 evidence retrieval 被視作 latent variable&lt;/p&gt;
&lt;p&gt;由於 learn from scratch 不切實際，因此用 Inverse Cloze Task (ICT) 來預訓練 retriever&lt;/p&gt;
&lt;p&gt;作者對五個 QA 資料集進行評估&lt;/p&gt;
&lt;p&gt;在提問者已經知道答案的情況下，傳統的 IR 系統（比如 BM25）已足夠&lt;/p&gt;
&lt;p&gt;在使用者真正尋求答案的資料集上，作者顯示出 learned retrival 的重要性，在 exact match 上比 BM25 好 19 個點&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;由於閱讀理解系統的發展，人們對 open domain question answering (QA) 的興趣重新燃起&lt;/p&gt;
&lt;p&gt;其中 evidence 得從 open corpus 取得，而不是直接從輸入給入&lt;/p&gt;
&lt;p&gt;現有的方法需要 blackbox IR system 來完成大部分繁重的工作，即使它無法對下遊任務進行微調&lt;/p&gt;
&lt;p&gt;在 DrQA 推廣的強監督環境中，他們也假設了一個訓練在 question-answer-evidence triple 上的閱讀理解模型&lt;/p&gt;
&lt;p&gt;在某些人提出的 weakly supervised setting 中，他們假設 IR system 提供 noisy gold evidence&lt;/p&gt;
&lt;p&gt;這些方法利用 IR system 來大幅減少搜尋空間&lt;/p&gt;
&lt;p&gt;然而 QA 和 IR 有著根本性的差異&lt;/p&gt;
&lt;p&gt;雖然 IR 關心的是 lexical 和 semantic matching，但 question 的定義並不具體，而且需要更多 language understanding，因為 user 在找的是未知資訊&lt;/p&gt;
&lt;p&gt;我們應該直接 用 QA data 學習 retrieve，而不是受限於 blackbox IR system&lt;/p&gt;
&lt;p&gt;在本文中，作者介紹了第一個 OpenRetrieval Question Answering system (ORQA) 框架&lt;/p&gt;
&lt;p&gt;ORQA 學習從 open corpus retrieve evidence，並且只做 question-answer pair 的監督訓練&lt;/p&gt;
&lt;p&gt;雖然最近的工作在改進 evidence retrieval 上取得了巨大的進展，但是他們依然只是在 closed evidence set 下 rerank&lt;/p&gt;
&lt;p&gt;fully end-to-end 的挑戰是，open corpus 的 retrieval 必須被視為 latent variable，要 train from scratch 是不切實際的&lt;/p&gt;
&lt;p&gt;IR system 提供了一個合理但可能非最好的起點&lt;/p&gt;
&lt;p&gt;本文的一個關鍵是，如果用無監督 的 ICT 對 retriever 做預訓練，那 end-to-end learning 是有可能的&lt;/p&gt;
&lt;p&gt;在 ICT 中，一個句子被視作 pseudo-question，而它的 context 被視作 pseudo-evdience&lt;/p&gt;
&lt;p&gt;給定一個 pseudo-question，retriever 的目標是從 batch 中的 candidate 找出對應的 pseudo-evidence&lt;/p&gt;
&lt;p&gt;ICT pretraining 提供了強大的初始化，使 ORQA 可以簡單地優化&lt;/p&gt;
&lt;p&gt;作者在五個 QA 資料集上進行了評估，在問題作者已知答案的資料集上 (SQuAD、TriviaQA)，檢索問題類似傳統的 IR，並且 BM25 是 SOTA retrieval&lt;/p&gt;
&lt;p&gt;在問題作者不知道答案的資料集上 (Natural Questions、WebQuestions、CuratedTrec)，作者顯示出 learned retrieval 的重要性，比 BM25 在 exact match 上好 6~19 個點&lt;/p&gt;
&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;
&lt;h3 id=&#34;task&#34;&gt;Task&lt;/h3&gt;
&lt;p&gt;在 open-domain QA 中，$q$ 是 question string，而 $a$ 是 answer string&lt;/p&gt;
&lt;p&gt;與閱讀理解不同，evidence 的來源是 modeling choice，而非 task definition 的一部分&lt;/p&gt;
&lt;h3 id=&#34;formal-definitions&#34;&gt;Formal Definitions&lt;/h3&gt;
&lt;p&gt;Model 把一個 unstructured text corpus 切成 B 塊的 evidence text&lt;/p&gt;
&lt;p&gt;一個 answer derivation 是一個 pair $(b,s)$&lt;/p&gt;
&lt;p&gt;$1 \le b \le B$ 是 block 的 index&lt;/p&gt;
&lt;p&gt;$s$ 是 block $b$ 的 span&lt;/p&gt;
&lt;p&gt;scoring function $S(b,s,q)$ 用來計算 $(b,s)$ 對於 $q$ 的分數&lt;/p&gt;
&lt;p&gt;一般來說 scoring function 會被分解成 retrieval component $S_{retr}(b,q)$ 和 $S_{read}(b,s,q)$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$S(b,s,q) = S_{retr}(b,q) + S_{read}(b,s,q)$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在推論階段：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$a^* = TEXT(argmax_{b,s} S(b,s,q))$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;open-domain QA 的一個主要挑戰是 handling the scale&lt;/p&gt;
&lt;p&gt;作者在 English Wikipedia 上做實驗，包含超過 13M 個 blocks，每個 block 都有超過 2000 個可能的 spans&lt;/p&gt;
&lt;h3 id=&#34;existing-pipelined-models&#34;&gt;Existing Pipelined Models&lt;/h3&gt;
&lt;p&gt;在現有的 retrieval-based open-domain QA 模型中，blackbox IR system 先選擇一組 closed set of evidence candidates&lt;/p&gt;
&lt;p&gt;然後 DrQA 之後的多數工作都用 TF-IDF 來挑選 candidate，並專注於閱讀理解或 reranking 的部分&lt;/p&gt;
&lt;p&gt;reading component $S_{read}(b,s,q)$ 是從 gold answer 學習的&lt;/p&gt;
&lt;p&gt;在最接近我們的方法的工作中，reader 是透過 weak supervision 學習的&lt;/p&gt;
&lt;p&gt;retrieval system 會啟發式（heuristically）地刪除 spurious ambiguities，並把清理後的結果視為 gold evidence&lt;/p&gt;
&lt;h2 id=&#34;open-retrieval-question-answering-orqa&#34;&gt;Open-Retrieval Question Answering (ORQA)&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/ORQA/fig1.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;$BERT(x_1, [x_2]) = \{CLS: h_{CLS}, 1: h_1, 2: h_2,&amp;hellip;\}$&lt;/p&gt;
&lt;h3 id=&#34;retriever-component&#34;&gt;Retriever component&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;$h_q = W_q BERT(q)[CLS]$&lt;/li&gt;
&lt;li&gt;$h_b = W_b BERT(b)[CLS]$&lt;/li&gt;
&lt;li&gt;$S_{retr}(b,q) = h_q^T h_b$&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;reader-component&#34;&gt;Reader component&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;$h_{start} = BERT_R(q,b)[START(s)]$&lt;/li&gt;
&lt;li&gt;$h_{end} = BERT_R(q,b)[END(s)]$&lt;/li&gt;
&lt;li&gt;$S_{read}(b,s,q) = MLP([h_{start};h_{end}])$&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;inference--learning-challenges&#34;&gt;Inference &amp;amp; Learning Challenges&lt;/h3&gt;
&lt;p&gt;上面的模型概念很簡單&lt;/p&gt;
&lt;p&gt;但推論和學習上具有挑戰性，因為：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;open evidence corpus 有巨大的搜尋空間（超過 13M 個 blocks）&lt;/li&gt;
&lt;li&gt;要如何在空間 navigate 是 latent&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;因此標準的 teacher forcing 不能用，latent variable 也不能用，因為存在大量 spuriously ambiguous derivations（比如答案是 &amp;ldquo;seven&amp;rdquo;，很多 evidence 都會有 &amp;ldquo;seven&amp;rdquo; 這個字眼）&lt;/p&gt;
&lt;p&gt;作者透過非監督預訓練來良好地初始化 retriever 來解決這些挑戰&lt;/p&gt;
&lt;p&gt;預訓練的 retriever 使作者能夠：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;pre-encode Wikipedia blocks，從而在 finetune 階段實現動態且快速的 top-k retrieval&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;使 retrieval 可以遠離 spuriously ambiguities 並偏向 supportive evidence&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;inverse-cloze-task&#34;&gt;Inverse Cloze Task&lt;/h2&gt;
&lt;p&gt;作者提出的預訓練流程的目標是想讓 retriever 解決和 evidence retrieval for QA 相似的無監督任務&lt;/p&gt;
&lt;p&gt;直覺上，useful evidence 通常會討論問題中的 entities, events 和 relations&lt;/p&gt;
&lt;p&gt;還包含問題中不存在的額外資訊 (the answer)&lt;/p&gt;
&lt;p&gt;question-evidence pair 是 setence-context pair，句子的上下文在語意上是相關的，可以推論句子中缺少的資訊&lt;/p&gt;
&lt;p&gt;憑這種想法，作者建議使用 ICT 來預訓練 retriever&lt;/p&gt;
&lt;p&gt;在 standard cloze task 中，目標是根據上下文預測 masked-out text&lt;/p&gt;
&lt;p&gt;相反，ICT 要逆向預測，給定一個句子，預測上下文&lt;/p&gt;
&lt;p&gt;使用類似 downstream retrieval 的 discriminative objective：&lt;/p&gt;
&lt;p&gt;$P_{ICT}(b|q)=\frac{exp(S_{retr}(b,q))}{\sum_{b&amp;rsquo; \in BATCH} exp(S_{retr}(b&amp;rsquo;,q))}$&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/ORQA/fig2.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;預測哪個上下文是 query 的&lt;/p&gt;
&lt;p&gt;ICT 有個重點是，它要做的不僅僅是單字匹配，因為 evidence 中沒有 pseudo-question&lt;/p&gt;
&lt;p&gt;例如 fig.2 的 pseudo-question 完全沒有提及 zebra，但 retriever 要能夠選擇 zebra 的 context&lt;/p&gt;
&lt;p&gt;能夠從非指定的語言推論出語意是 QA 和傳統 IR 的差異&lt;/p&gt;
&lt;p&gt;然而作者也不想阻止 retriever 學習單字匹配，因為 lexical overlap 最終是一個非常有用的特徵&lt;/p&gt;
&lt;p&gt;因此，作者只在 90 % 的例子中把 sentence 從 context 中移除，鼓勵模型在需要的時候學習抽象表示，也在可用時學習 low-level word matching features&lt;/p&gt;
&lt;p&gt;ICT 預訓練實現兩個主要目標：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;儘管預訓練的句子和微調時的 question 不匹配，但作者預期 zero-shot evidence retrieval performance 足以引導 latent variable 的學習&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;pretrained evidence blocks 和 downstream evidence blocks 間沒有這種不匹配的問題&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;因此可預期 $BERT_{B}(b)$ 無須進一步訓練即可正常工作&lt;/p&gt;
&lt;p&gt;只有 question encoder 需要針對下遊資料微調&lt;/p&gt;
&lt;h2 id=&#34;inference&#34;&gt;Inference&lt;/h2&gt;
&lt;p&gt;由於 fixed block encoder 已經為 retrieval 提供了有用的 representation，可以預先計算所有 block 的 encoding&lt;/p&gt;
&lt;p&gt;因此在微調的時候不需要對大量 evidence block 重新 encode，並且可以使用比如 locality-sensitive hashing 之類的現有工具來建立索引&lt;/p&gt;
&lt;p&gt;透過 pre-compiled index，推理遵循 standard beam-search&lt;/p&gt;
&lt;p&gt;檢索 top-k evidence block，並只計算這 k 個 block 的 reader score&lt;/p&gt;
&lt;h2 id=&#34;learning&#34;&gt;Learning&lt;/h2&gt;
&lt;p&gt;這邊太複雜，建議看原文&lt;/p&gt;
&lt;h2 id=&#34;experimental-setup&#34;&gt;Experimental Setup&lt;/h2&gt;
&lt;h3 id=&#34;open-domain-qa-datasets&#34;&gt;Open Domain QA Datasets&lt;/h3&gt;
&lt;p&gt;對 5 個現有 question answering 或閱讀理解資料集進行評估&lt;/p&gt;
&lt;p&gt;並非所有資料集的原始形式都是 open-domain QA，因此作者遵循 DrQA 的做法，轉成 open format&lt;/p&gt;
&lt;p&gt;每個 example 都有一個 single question 和一「組」 reference answer&lt;/p&gt;
&lt;h4 id=&#34;natural-questions&#34;&gt;Natural Questions&lt;/h4&gt;
&lt;p&gt;包含了從 Google Search 的 aggregated queries 中的 question&lt;/p&gt;
&lt;p&gt;為了蒐集這個資料集的 open version，作者只保留 short answer 並丟棄 evidence document&lt;/p&gt;
&lt;p&gt;具有許多 token 的答案通常類似 extractive snippets 而不是 canonical answer，因此作者丟棄長度超過 5 個 token 的答案&lt;/p&gt;
&lt;h4 id=&#34;webquestions&#34;&gt;WebQuestions&lt;/h4&gt;
&lt;p&gt;包含從 Google Suggest API 抽取的問題&lt;/p&gt;
&lt;p&gt;答案是根據 Freebase 標註的，但是只保留 entities 的 string representation&lt;/p&gt;
&lt;h4 id=&#34;curatedtrec&#34;&gt;CuratedTrec&lt;/h4&gt;
&lt;p&gt;問題來自真實查詢的各種來源，比如 MSNSearch&lt;/p&gt;
&lt;h4 id=&#34;triviaqa&#34;&gt;TriviaQA&lt;/h4&gt;
&lt;p&gt;從網路上抓的 question-answer pairs&lt;/p&gt;
&lt;p&gt;作者使用 unfiltered set 並捨棄 distanly supervised evidence&lt;/p&gt;
&lt;h4 id=&#34;squad&#34;&gt;SQuAD&lt;/h4&gt;
&lt;p&gt;被設計來用作閱讀理解，而不是 open-domain QA&lt;/p&gt;
&lt;p&gt;答案範圍是從 Wikipedia 的段落中選擇的，問題由 annotators 編寫，annotators 被指示提出問題，要由給定的 context 中的 span 來回答&lt;/p&gt;
&lt;h3 id=&#34;dataset-biases&#34;&gt;Dataset Biases&lt;/h3&gt;
&lt;p&gt;在 Natural Questions、WebQuestions 和 CuratedTrec 中，提問者不知道答案，反映了真實的尋求問題的分佈&lt;/p&gt;
&lt;p&gt;但是，annotators 必須單獨找到正確的答案，因此需要 automatic tools，並可能會對這些工具的結果產生 bias&lt;/p&gt;
&lt;p&gt;在 TriviaQA 和 SQuAD 中，不需要 automatic tools，因為 annotators 是根據已知答案寫問題的&lt;/p&gt;
&lt;p&gt;然而這引入了另一組可能更成問題的 bias，就是撰寫問題並非出於資訊需求&lt;/p&gt;
&lt;p&gt;導致問題中有許多自然出現的問題中沒有的提示&lt;/p&gt;
&lt;p&gt;這在 SQuAD 中問題特別嚴重，使問題和 evidence 間人為地出現大量詞彙重疊&lt;/p&gt;
&lt;p&gt;但上述這些只是想表達資料集的屬性，而非可採取行動的批評，因為要取得大規模資料必定會遇到這些狀況，目前還不清楚如何在合理的成本下收集公正的資料集&lt;/p&gt;
&lt;h3 id=&#34;implementation-details&#34;&gt;Implementation Details&lt;/h3&gt;
&lt;h4 id=&#34;evidence-corpus&#34;&gt;Evidence Corpus&lt;/h4&gt;
&lt;p&gt;corpus 被分成最多 288 個單字的 chunk，並且保留 sentence boundaries&lt;/p&gt;
&lt;p&gt;導致有超過 13M 個 blocks&lt;/p&gt;
&lt;h2 id=&#34;main-results&#34;&gt;Main Results&lt;/h2&gt;
&lt;h3 id=&#34;baselines&#34;&gt;Baselines&lt;/h3&gt;
&lt;h4 id=&#34;bm25&#34;&gt;BM25&lt;/h4&gt;
&lt;p&gt;BM25 是事實上的非監督搜索方法 SOTA
被證明對於傳統資訊檢索任務和 QA 的 evidence retrieval 任務都是 robust&lt;/p&gt;
&lt;h4 id=&#34;language-models&#34;&gt;Language Models&lt;/h4&gt;
&lt;p&gt;非監督的 neural retrieval 對於傳統 IR 來說很難改進，但這裡視作比較的 baseline&lt;/p&gt;
&lt;p&gt;作者對 LM 進行實驗，並且這已被證明是 SOTA unsupervised representation&lt;/p&gt;
&lt;p&gt;我們與兩種廣泛使用的 128-dimensional representation 進行比較：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;NNLM
&lt;ul&gt;
&lt;li&gt;context-independent embedding&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;ELMO
&lt;ul&gt;
&lt;li&gt;context-dependent bidirectional LSTM&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;就像 ICT 一樣，使用 alternate encoder 來預先計算 encoded evidence blocks 還有初始化經過 finetune 的 question encoding&lt;/p&gt;
&lt;p&gt;根據現有的 IR 文獻，還有 LM 沒有顯著優化 retrieval 的直覺，作者並不期望這些成為強大的 baseline，但是他們證明了將文本編碼為 128 維的難度&lt;/p&gt;
&lt;h3 id=&#34;results&#34;&gt;Results&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/ORQA/table5.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;在提問者已經知道答案的資料集中&lt;/p&gt;
&lt;p&gt;證實壓縮到 128維的向量無法與 BM25 精確表示 evidence 中每個單字的能力相符&lt;/p&gt;
&lt;p&gt;SQuAD 的 dev 和 test 間的顯著下降反映了資料集中的某個特性 - 10 萬個問題僅源自 536 個文件&lt;/p&gt;
&lt;p&gt;因此，SQuAD 的好的檢索目標，會和訓練範例高度相關，違反了 IID 假設，使其不適合學習檢索&lt;/p&gt;
&lt;p&gt;因此，作者強烈建議對 end-to-end open-domain QA models 有興趣的人不再使用 SQuAD 進行訓練和評估&lt;/p&gt;
&lt;h2 id=&#34;analysis&#34;&gt;Analysis&lt;/h2&gt;
&lt;h3 id=&#34;strongly-supervised-comparison&#34;&gt;Strongly supervised comparison&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/ORQA/table6.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;為了證實作者的 BM25 Baseline 是 SOTA，提供了和 DrQA 的比較&lt;/p&gt;
&lt;p&gt;DrQA 的 reader 是 DocReader，用 TF-IDF 取得 top k documents&lt;/p&gt;
&lt;p&gt;還包括基於 TF-IDF retrieval 的 distant supervision&lt;/p&gt;
&lt;p&gt;BERTserini 的 reader 是一個基於 base BERT（類似作者的 reader），並用 BM25 搜索 top-k 個段落（像作者的 BM25 baseline）&lt;/p&gt;
&lt;p&gt;主要區別在 BERTserini 使用 Wikipedia 中的真實段落，而不是任意 block，從而由於長度不均導致更多 evidence blocks&lt;/p&gt;
&lt;p&gt;為了和這些強監督系統進行比較，作者在 SQuAD 上預訓練 reader&lt;/p&gt;
&lt;h3 id=&#34;masking-rate-in-the-inverse-cloze-task&#34;&gt;Masking Rate in the Inverse Cloze Task&lt;/h3&gt;
&lt;p&gt;pseudo-query 在 90% 的時間裡都從 evidence block 遮蔽&lt;/p&gt;
&lt;p&gt;如果總是屏蔽 pseudo-query，那麼 retriever 永遠不會知道 n-gram overlap 是一個強大的 retrieval signal，導致損失 10 個點&lt;/p&gt;
&lt;p&gt;如果從不屏蔽，問題就會簡化為記憶，導致不能很好地推廣到問題&lt;/p&gt;
&lt;h3 id=&#34;example-predictions&#34;&gt;Example Predictions&lt;/h3&gt;
&lt;p&gt;發現 ORQA 在具有高度詞彙重疊的文本更加 robust&lt;/p&gt;
&lt;p&gt;但是由於 128 維向量的資訊有限&lt;/p&gt;
&lt;p&gt;很難精確地表示極為具體的概念，比如準確日期&lt;/p&gt;
</description>
        </item>
        <item>
        <title>DrQA 論文閱讀</title>
        <link>https://roykesydon.github.io/Blog/p/drqa-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</link>
        <pubDate>Mon, 25 Dec 2023 00:00:12 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/drqa-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</guid>
        <description>&lt;p&gt;paper: &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/1704.00051&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Reading Wikipedia to Answer Open-Domain Questions&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;本文提出以 Wikipedia 為知識來源來解決 open-domain question answering 問題&lt;/p&gt;
&lt;p&gt;任何問題的答案都是 Wikipedia 中的一段文字&lt;/p&gt;
&lt;p&gt;這項挑戰結合了文件檢索和理解文字的能力&lt;/p&gt;
&lt;p&gt;本文的作法基於一個 search component，由 bigram hashing 和 TF-IDF matching 構成，並結合 RNN&lt;/p&gt;
&lt;p&gt;對多個 QA 資料集做的實驗表明：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;這兩個 components 對於現有的對應模塊具有高度競爭力&lt;/li&gt;
&lt;li&gt;在他們的組合上使用 distant supervision 十分有效&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;要把 wikipedia 當作知識來源，回答任何一個問題，都必須先從超過 5 百萬篇文章中找出少數相關的文章，並仔細掃描以找出答案。&lt;/p&gt;
&lt;p&gt;本文將這稱為 machine reading at scale (MRS)&lt;/p&gt;
&lt;p&gt;本文把 wikipedia 當作一個文章的集合，並且不依賴內部的 graph structure&lt;/p&gt;
&lt;p&gt;因此該方法是通用的，可以套到諸如新聞、網路論壇等等的資料集上&lt;/p&gt;
&lt;p&gt;本文開發了 DrQA，強大的維基百科問答系統，由以下部分組成：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Document Retriever
&lt;ul&gt;
&lt;li&gt;一個用 bigram hashing 和 TF-IDF matching 的 module&lt;/li&gt;
&lt;li&gt;用於在給定問題的情況下，返回有效相關文章的子集&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Document Reader
&lt;ul&gt;
&lt;li&gt;RNN，用來 detect 文章中答案的位置&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;實驗表明 Document Retriever 的性能優於 Wikipedia 的內部搜尋引擎，Document Reader 在 SQuAD 上達到 SOTA&lt;/p&gt;
&lt;p&gt;此外，與 single task training 相比，作者表明 multitask learning 和 distant supervision 有助於提高模型的性能&lt;/p&gt;
&lt;h2 id=&#34;related-work&#34;&gt;Related Work&lt;/h2&gt;
&lt;p&gt;隨著 Knowledge Base (KB) 的發展，QA 出現了許多創新，但是 KB 具備固有限制（incompleteness, fixed schema），促使研究人員轉回從 raw text 中提取答案&lt;/p&gt;
&lt;p&gt;有些工作嘗試利用 multitask learning 來組合多個 QA 資料集，目標是：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;透過 task transfer 來實現跨資料集的改進&lt;/li&gt;
&lt;li&gt;提供一個單一通用的系統，可以回答不同種類的問題，因為資料來源中不可避免地存在不同的資料分布&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;本文的工作在先 retrive 再 read 的 setting 下，沒有利用 KB，取得了正面成果&lt;/p&gt;
&lt;h2 id=&#34;drqa&#34;&gt;DrQA&lt;/h2&gt;
&lt;p&gt;由兩個 Components 組成：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Document Retriever
&lt;ul&gt;
&lt;li&gt;用來尋找相關文章&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Document Reader
&lt;ul&gt;
&lt;li&gt;用於從單一文件或一小部分文件提取答案&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;document-retriever&#34;&gt;Document Retriever&lt;/h3&gt;
&lt;p&gt;遵循經典的 QA System，先用高效的 （非機器學習）的 document retrieval system 縮小搜索範圍，並專注於比較可能有關的文章&lt;/p&gt;
&lt;p&gt;與基於 ElasticSearch 的 Wikipedia Search API 相比，簡單的 inverted index lookup 和 term vector model scoring 表現的十分好&lt;/p&gt;
&lt;p&gt;文章和問題被表示為 TF-IDF weighted bag-of-words vectors&lt;/p&gt;
&lt;p&gt;作者考慮透過考慮 local word order 和 n-gram features 來進一步改善&lt;/p&gt;
&lt;p&gt;表現最佳的系統用 bigram counts，並利用 hashing 映射到 $2^{24}$ bins 來保持 speed 和 memory efficiency，用的是 unsigned murmur3 hash&lt;/p&gt;
&lt;p&gt;Document Retriever 作為模型的第一部分，設定為對任何問題返回 5 個相關的文章&lt;/p&gt;
&lt;p&gt;這些文章再交由 Document Reader 來處理&lt;/p&gt;
&lt;h3 id=&#34;document-reader&#34;&gt;Document Reader&lt;/h3&gt;
&lt;h4 id=&#34;paragraph-encoding&#34;&gt;Paragraph encoding&lt;/h4&gt;
&lt;p&gt;$p_i$ 是段落 $p$ 中的 token，期望 $p_i$ 可以被 encode 成帶有周圍資訊的向量&lt;/p&gt;
&lt;p&gt;採用的是 multi-layer bidirectional LSTM&lt;/p&gt;
&lt;p&gt;特徵向量 $p_i$ 由以下部分組成：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Word embedding&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;用 300 維的 Glove word embedding，固定大部分預訓練的 word embedding，只 finetune 最常見的 1000 個 question words，例如 what, how, which&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Exact match&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;採用三個簡單的 binary features，用來表示 $p_i$ 是否與問題中的 question word $q$ 精確匹配，無論是原始形式、小寫，還是 lemma form&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Token features&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;作者添加了一些 manual feature 好反應 $p_i$ 在 context 中的屬性，比如 part-of-speech (POS)、named entity recognition (NER) tags 和它的 (normalized) term frequency (TF)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Aligned question embedding&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$f_{align}(p_i)=\sum_j a_{i,j}E(q_j)$
&lt;ul&gt;
&lt;li&gt;$E$ 是 word embedding&lt;/li&gt;
&lt;li&gt;$a_{i,j}$ 是 attention score，計算 $p_i$ 和每個 $q_j$ 之間的 similarity&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;question-encoding&#34;&gt;Question encoding&lt;/h4&gt;
&lt;p&gt;這個比較簡單，只是在 word embedding 上加上一層 RNN，並把 hidden units 重新結合成一個向量&lt;/p&gt;
&lt;h4 id=&#34;prediction&#34;&gt;Prediction&lt;/h4&gt;
&lt;p&gt;把 $\{p_1,&amp;hellip;,p_m\}$ 和 $q$ 作為 input，並個別單獨訓練兩個分類器預測開頭和結尾的位置&lt;/p&gt;
&lt;p&gt;具體來說，作者用 bilinear term 來計算每個 $p_i$ 和 $q$ 之間的相似度，並計算每個 $p_i$ 是開頭的機率和結尾的機率&lt;/p&gt;
&lt;p&gt;最後選擇最佳範圍，從 token $i$ 到 token $i&#39;$&lt;/p&gt;
&lt;p&gt;$i \le i&amp;rsquo; \le i+15$&lt;/p&gt;
&lt;p&gt;並且使 $P_{start}(i) \times P_{end}(i&amp;rsquo;)$ 最大化&lt;/p&gt;
&lt;h2 id=&#34;data&#34;&gt;Data&lt;/h2&gt;
&lt;p&gt;本文的工作依賴三種資料：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Wikipedia
&lt;ul&gt;
&lt;li&gt;尋找答案的來源&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;SQuAD
&lt;ul&gt;
&lt;li&gt;用來訓練和評估模型&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;另外三個 QA 資料集 (WebQuestions, CuratedTREC, WikiMovies)
&lt;ul&gt;
&lt;li&gt;用來測試模型在 Open-domain QA 上的泛化能力，並評估模型從 multitask learning 和 distant supervision 中獲益的程度&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;wikipedia-knowledge-source&#34;&gt;Wikipedia (Knowledge Source)&lt;/h3&gt;
&lt;p&gt;用 2016-12-21 dump2 的 English Wikipedia&lt;/p&gt;
&lt;p&gt;對於每頁，只提取文本，並刪除結構化的資料（lists and figures）&lt;/p&gt;
&lt;p&gt;丟棄 disambiguation pages, list, index 和 outline pages，保留了 5,075,182 篇文章&lt;/p&gt;
&lt;h3 id=&#34;squad&#34;&gt;SQuAD&lt;/h3&gt;
&lt;p&gt;使用兩個 evaluation metrics：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Exact string match (EM)&lt;/li&gt;
&lt;li&gt;F1 score&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;為了評估 open-domain QA 的能力，作者只有使用 SQuAD 的 QA pairs，要求系統在無法存取相關段落的情況下發現正確的 answer span&lt;/p&gt;
&lt;p&gt;不像標準的 SQuAD setting 會給出相關段落&lt;/p&gt;
&lt;h3 id=&#34;open-domain-qa-evaluation-resources&#34;&gt;Open-domain QA Evaluation Resources&lt;/h3&gt;
&lt;p&gt;SQuAD 是目前可用的最大的 general purpose QA 資料集之一&lt;/p&gt;
&lt;p&gt;收集過程包括向每個 human annotator 展示一個段落，並寫一個問題&lt;/p&gt;
&lt;p&gt;因此，distribution 非常特定&lt;/p&gt;
&lt;p&gt;作者建議在其他 open-domain QA 資料集上評估系統，他們以不同的方式建構&lt;/p&gt;
&lt;h4 id=&#34;curatedtrec&#34;&gt;CuratedTREC&lt;/h4&gt;
&lt;p&gt;使用大版本，包含 TREC 1999, 2000, 2001 和 2002 的 2180 個問題&lt;/p&gt;
&lt;h4 id=&#34;webquestions&#34;&gt;WebQuestions&lt;/h4&gt;
&lt;p&gt;這資料集旨在回答 Freebase KB 的問題&lt;/p&gt;
&lt;p&gt;透過 Google Suggest API 抓問題，再用 Amazon Mechanical Turk 來獲取答案&lt;/p&gt;
&lt;p&gt;作者用 entity names 把每個 answer 轉成答案，以便不引入 Freebase IDs&lt;/p&gt;
&lt;h4 id=&#34;wikimovies&#34;&gt;WikiMovies&lt;/h4&gt;
&lt;p&gt;包含對電影領域的 96k 個問答對&lt;/p&gt;
&lt;h3 id=&#34;distantly-supervised-data&#34;&gt;Distantly Supervised Data&lt;/h3&gt;
&lt;p&gt;上面說的資料集除了 SQuAD 都沒有相關段落，因此不能直接訓練 Document Reader&lt;/p&gt;
&lt;p&gt;追隨之前已有的利用 distant supervision (DS) 來做 relation extraction 的工作，作者用一個程式自動把段落和此類訓練範例做相關聯&lt;/p&gt;
&lt;p&gt;對每個問答對使用以下過程來建立訓練集：&lt;/p&gt;
&lt;p&gt;首先，對問題用 Document Retriever 找到前 5 個相關的段落&lt;/p&gt;
&lt;p&gt;與已知答案沒有 exact match 的段落都被直接丟棄&lt;/p&gt;
&lt;p&gt;短於 25 個字元或長於 1500 個字元的段落也被丟棄&lt;/p&gt;
&lt;p&gt;如果在問題中找到 named entity，不包含該 named entity 的段落也被丟棄&lt;/p&gt;
&lt;p&gt;對於每個 retrived page 的每個段落，使用 question 和 20 token window 間的 unigram  和 bigram overlap 來計算相似度，保留重疊度最高的前五個段落&lt;/p&gt;
&lt;p&gt;將找到的每個 pair 加入到 DS 訓練集中&lt;/p&gt;
&lt;p&gt;大約一半的 DS 範例來自 SQuAD 以外的頁面&lt;/p&gt;
&lt;h2 id=&#34;experiments&#34;&gt;Experiments&lt;/h2&gt;
&lt;h3 id=&#34;finding-relevant-articles&#34;&gt;Finding Relevant Articles&lt;/h3&gt;
&lt;p&gt;先檢查 Retriever 在所有 QA 資料集上的性能&lt;/p&gt;
&lt;p&gt;計算 ration 是根據特定的問題，考慮這些問題對應的文本在前 5 個相關文章中的比例&lt;/p&gt;
&lt;p&gt;結果表明，比 Wikipedia Search 還更好，尤其是使用 bigram hashing 的情況下&lt;/p&gt;
&lt;h3 id=&#34;reader-evaluation-on-squad&#34;&gt;Reader Evaluation on SQuAD&lt;/h3&gt;
&lt;h4 id=&#34;implementation-details&#34;&gt;Implementation details&lt;/h4&gt;
&lt;p&gt;使用 h=128 的 3 層雙向 LSTM，來做 paragraph encoding 和 question encoding&lt;/p&gt;
&lt;p&gt;使用 Stanford CoreNLP 來做 tokenization 並生成 lemma, part-of-speech 和 named entity tags&lt;/p&gt;
&lt;p&gt;Optimizer 使用 Adamax&lt;/p&gt;
&lt;p&gt;Dropout rate 為 0.3&lt;/p&gt;
&lt;h4 id=&#34;result-and-analysis&#34;&gt;Result and analysis&lt;/h4&gt;
&lt;p&gt;作者的系統可以在 SQuAD 上達到 SOTA&lt;/p&gt;
&lt;p&gt;做了 ablation study，結果表明所有功能都會影響性能&lt;/p&gt;
&lt;p&gt;有趣的是，單獨沒有 $f_{alignd}$ 或 $f_{exact_match}$ 對性能不會有極大的影響，但兩個都沒有就會急遽下降&lt;/p&gt;
&lt;h3 id=&#34;full-wikipedia-question-answering&#34;&gt;Full Wikipedia Question Answering&lt;/h3&gt;
&lt;p&gt;比較三個版本的 DrQA：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;SQuAD
&lt;ul&gt;
&lt;li&gt;只在 SQuAD 上訓練，並用於所有評估資料集&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Fine-tune (DS)
&lt;ul&gt;
&lt;li&gt;先在 SQuAD 上預訓練，在用 DS 訓練集對每個資料集進行微調&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Multitask (DS)
&lt;ul&gt;
&lt;li&gt;在 SQuAD 和 DS 訓練集上聯合訓練&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;results&#34;&gt;Results&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/DrQA/table6.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;兩個明顯的 angles of attack：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;把多個段落直接納入 Document Reader 的訓練，因為他目前獨立訓練每個段落&lt;/li&gt;
&lt;li&gt;實作一個 end-to-end training 的 pipeline，可以在一個模型中結合 Document Retriever 和 Document Reader&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>LangChain 筆記</title>
        <link>https://roykesydon.github.io/Blog/p/langchain-%E7%AD%86%E8%A8%98/</link>
        <pubDate>Mon, 18 Dec 2023 00:08:46 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/langchain-%E7%AD%86%E8%A8%98/</guid>
        <description>&lt;h2 id=&#34;介紹&#34;&gt;介紹&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ChatGPT 的缺陷&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;沒有一定時間後的資料 (當時)&lt;/li&gt;
&lt;li&gt;沒有辦法連結外部私人資料 (e.g. Google Drive)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;LangChain 的優點&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Integration
&lt;ul&gt;
&lt;li&gt;可以連結外部資料&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Agency
&lt;ul&gt;
&lt;li&gt;讓 LLM 可以和環境互動，做出決策&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;components&#34;&gt;Components&lt;/h2&gt;
&lt;h3 id=&#34;結構&#34;&gt;結構&lt;/h3&gt;
&lt;h4 id=&#34;schema&#34;&gt;Schema&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;對話
&lt;ul&gt;
&lt;li&gt;System: 對話的 context&lt;/li&gt;
&lt;li&gt;Human: 你的詢問&lt;/li&gt;
&lt;li&gt;AI: AI 的回答&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;document&#34;&gt;Document&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;儲存一段文字以集 metadata 的結構&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;embedding&#34;&gt;Embedding&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;OpenAIEmbeddings
&lt;ul&gt;
&lt;li&gt;可以把文字轉換成向量，預設是 1536 維&lt;/li&gt;
&lt;li&gt;但是有最大長度限制&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;文字處理&#34;&gt;文字處理&lt;/h3&gt;
&lt;h4 id=&#34;output-parser&#34;&gt;Output Parser&lt;/h4&gt;
&lt;p&gt;讓模型重生你想要的格式，並轉換成你想要的結構，比如 json&lt;/p&gt;
&lt;h3 id=&#34;資料儲存&#34;&gt;資料儲存&lt;/h3&gt;
&lt;h4 id=&#34;indexes&#34;&gt;Indexes&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Document_loaders&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;可以從不同的來源獲得資料&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;text_splitter&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;把大量的文字切成多個 chunks&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;retriever&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;用來找到相近的文件&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;VectorStores&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Chroma
&lt;ul&gt;
&lt;li&gt;local storage&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;交互&#34;&gt;交互&lt;/h3&gt;
&lt;h4 id=&#34;prompttemplate&#34;&gt;PromptTemplate&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;用來往 String Template 填入變數&lt;/li&gt;
&lt;li&gt;有些 Component 會和這個用法組合，所以不適合直接換成 f-string&lt;/li&gt;
&lt;li&gt;FewShotPromptTemplate
&lt;ul&gt;
&lt;li&gt;可以用自己準備的一些例子結合 PromptTemplate 來做 Few-shot learning&lt;/li&gt;
&lt;li&gt;可以透過 FAISS 來找到最相近的例子&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;chain&#34;&gt;Chain&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;用在有多個有序的問題的情況&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;multi-step workflow&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;VectorDBQA&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;可以用在搜索 local 的向量資料庫&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Instruction 結合 context 的模式 (Summarize)&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;模式&lt;/th&gt;
&lt;th&gt;Stuffing&lt;/th&gt;
&lt;th&gt;Map Reduce&lt;/th&gt;
&lt;th&gt;Refine&lt;/th&gt;
&lt;th&gt;Map-Rerank&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;說明&lt;/td&gt;
&lt;td&gt;直接把 context 和 query 結合&lt;/td&gt;
&lt;td&gt;把 Document 切成多塊 ，把每塊交給 LLM，轉換成 summary，反覆從這些 summary 生 summary&lt;/td&gt;
&lt;td&gt;每次切一小塊，並且和先前的結果做 summary&lt;/td&gt;
&lt;td&gt;讓每個 chunk 和 query 去生答案，並要模型對自己的答案評分，最後選分數高的&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;優點&lt;/td&gt;
&lt;td&gt;只需 call 一次 API、涵蓋所有資料&lt;/td&gt;
&lt;td&gt;可以餵入更大的文件、可以平行運算&lt;/td&gt;
&lt;td&gt;可以餵入更大的文件&lt;/td&gt;
&lt;td&gt;對於簡單的問題可能比較有效&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;缺點&lt;/td&gt;
&lt;td&gt;容易達到 token 上限&lt;/td&gt;
&lt;td&gt;call 多次 API、summary 的過程中會流失資訊&lt;/td&gt;
&lt;td&gt;call 多次 API、summary 的過程中會流失資訊&lt;/td&gt;
&lt;td&gt;沒有辦法結合多個 Document 的資訊&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;agent&#34;&gt;Agent&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;有些應用中，你可能不知道該遵循什麼流程來讓 LLM 完成任務，這時候你會需要讓 LLM 自行決定要採取哪些動作以及採取的順序&lt;/li&gt;
&lt;li&gt;可以動態地利用 Chain&lt;/li&gt;
&lt;li&gt;verbose=True 的時候會印出思考過程&lt;/li&gt;
&lt;li&gt;Tools
&lt;ul&gt;
&lt;li&gt;有比如 Google Search 之類的 Tool 可以結合應用&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;memory&#34;&gt;Memory&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;ConversationChain&lt;/li&gt;
&lt;li&gt;讓 Chain 和 Agent 可以保留之前的對話&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>CLIP 論文閱讀</title>
        <link>https://roykesydon.github.io/Blog/p/clip-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</link>
        <pubDate>Tue, 21 Nov 2023 01:08:46 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/clip-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</guid>
        <description>&lt;p&gt;paper: &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2103.00020&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Learning Transferable Visual Models From Natural Language Supervision&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;現有的 SOTA CV system 可以經過訓練預測一組固定的類別。
但這種監督式的方法也受限了通用性，因為需要額外的 labeled data 來擴展。&lt;/p&gt;
&lt;p&gt;直接從 raw text 學習 image 是個有前途的替代方案。&lt;/p&gt;
&lt;p&gt;本文證明了「預測哪個是圖片的 caption」這種形式的預訓練是一種高效且可擴展的方法，可以從 internet 上蒐集的 4 億對資料從頭學習到 SOTA image representation。&lt;/p&gt;
&lt;p&gt;預訓練後，透過自然語言來引導，就可以在下游任務十線 zero-shot。&lt;/p&gt;
&lt;p&gt;本文對 30 個不同的現有電腦視覺資料集進行比較，可以在多數任務和監督式學習的 baseline 競爭，而且無須任資料集來做特別的訓練。&lt;/p&gt;
&lt;p&gt;例如在 ImageNet 上做 zero-shot 可以和 ResNet-50 取得相近的準確度。&lt;/p&gt;
&lt;h2 id=&#34;introduction-and-motivating-work&#34;&gt;Introduction and Motivating Work&lt;/h2&gt;
&lt;p&gt;直接從原始文本學習的預訓練方法在過去幾年徹底改變了 NLP。&lt;/p&gt;
&lt;p&gt;Task-agnostic (與下游任務無關) objectives，比如 autoregressive 和 masked language modeling，讓模型得以隨著 compute, model capacity, 和 data 規模的增長，使能力也逐步提升。&lt;/p&gt;
&lt;p&gt;在 &amp;ldquo;text-to-text&amp;rdquo; 這種輸入輸出形式的預訓練，使模型轉移到下游任務的時候，不用特地客製化 output head，或對資料集做特別地處理。&lt;/p&gt;
&lt;p&gt;這些結果表明，現代的預訓練方法在 web-scale 的文字集合的表現已經超過了用高品質的人為標記 NLP 資料集。&lt;/p&gt;
&lt;p&gt;然而在 CV 等領域，在 ImageNet 這種人為標記的資料集上做預訓練卻依然是標準做法。&lt;/p&gt;
&lt;p&gt;直接從網路文本學習的可擴展預訓練方法或許能在 CV 帶來類似的突破。&lt;/p&gt;
&lt;p&gt;以往有一些工作嘗試利用幾乎無限量的原始文本而不是有限數量的 &amp;ldquo;gold-labels&amp;rdquo;，
但是這些方法都有一些妥協，比如都利用 softmax 來執行預測，使其沒辦法應付新類別，嚴重限制了 zero-shot 的能力。&lt;/p&gt;
&lt;p&gt;作者提了幾個弱監督學習的例子，他們利用額外的資料結合預訓練，來幫忙改善監督式學習的結果。&lt;/p&gt;
&lt;p&gt;也提了幾個和 CLIP 類似的工作 VirTex, ICMLM, ConVIRT，想利用 Transformer，從 Natural Language 中學習 image representation。&lt;/p&gt;
&lt;p&gt;這些 weakly supervised model 和最近從 NLP 學習 image representation 的方法有一個重大差異，規模。&lt;/p&gt;
&lt;p&gt;最近的一些研究，比如一些弱監督學習在數百萬到數十億張照片上訓練了多個 accelerator years。但是和 CLIP 相似的研究只在二十萬張圖片上訓練了幾天。&lt;/p&gt;
&lt;p&gt;本文將規模拉高，以縮短規模上的差距。&lt;/p&gt;
&lt;p&gt;作者在 internet 上蒐集了 4 億對圖片和文字的資料，做成新的資料集，並提出了 CLIP，ConVIRT 的簡化版本。&lt;/p&gt;
&lt;p&gt;作者在 30 幾個資料集上測試，基本上能和監督式的模型競爭。&lt;/p&gt;
&lt;p&gt;如果用 linear-probe，比公開可用的 SOTA ImageNet model 還更好。&lt;/p&gt;
&lt;h2 id=&#34;approach&#34;&gt;Approach&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/CLIP/fig1.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/CLIP/ex1.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;natural-language-supervision&#34;&gt;Natural Language Supervision&lt;/h3&gt;
&lt;p&gt;核心想法是利用 natural language 來學習 perception。&lt;/p&gt;
&lt;p&gt;作者稱這不是一個新想法，但以往相似的方法的用語多樣，他介紹了四篇文章，但把從文字和圖片中學習 image representation 的方法個別稱為：無監督、自監督、弱監督、監督式。&lt;/p&gt;
&lt;p&gt;擴展 natural language supervision 比起圖像分類簡單的多，不必定好類別，再去標註每張照片的類別。&lt;/p&gt;
&lt;p&gt;而且 natural language supervision 還有個優勢，他不只能學習 image representation，還能將其和文字相關聯，使其更好做 zero-shot 的遷移。&lt;/p&gt;
&lt;h3 id=&#34;creating-a-sufficiently-large-dataset&#34;&gt;Creating a Sufficiently Large Dataset&lt;/h3&gt;
&lt;p&gt;現有工作主要用三個資料集:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;MS-COCO&lt;/li&gt;
&lt;li&gt;Visual Genome&lt;/li&gt;
&lt;li&gt;YFCC100M&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;MS-COCO 和 Visual Genome 都是高品質的人為標記資料集，但是按照現代標準來看，它們很小，每個資料集大約有 100,000 張訓練照片。&lt;/p&gt;
&lt;p&gt;相較之下，作者舉了一個最近的研究，用了 3.5 Billion 張 Instagram 照片作為訓練資料。&lt;/p&gt;
&lt;p&gt;YFCC100M 是一個可能的替代方案，它有 100 million 張照片，但每張照片的 metadata 資料稀疏，而且良莠不齊。&lt;/p&gt;
&lt;p&gt;比如許多檔名是自動產生的，可能是時間，或是相機的參數。&lt;/p&gt;
&lt;p&gt;經過過濾，保留帶有自然語言的標題或描述的圖像，資料集縮小了 6 倍，只剩 15000 萬張照片，和 ImageNet 的大小相當。&lt;/p&gt;
&lt;p&gt;natural language supervision 的一個主要動機是網路上公開著大量這種形式的 data。
由於現有資料集沒有反映這種可能性，因此只考慮這些資料集會低估這方面研究的潛力。&lt;/p&gt;
&lt;p&gt;所以作者建立了一個新的包含 400 million pairs 的資料集，從網路上各種公開的來源蒐集的。&lt;/p&gt;
&lt;p&gt;為了盡可能涵蓋所有的 visual concepts，作者在建構資料集的時候準備了 50 萬組特定的 query，每組 query 最多包含 20,000 個 pair，來進行 class balance。&lt;/p&gt;
&lt;p&gt;產生的資料集的總字數和 GPT-2 用的 WebText 差不多。&lt;/p&gt;
&lt;p&gt;將此資料集稱為 WIT，全名是 WebImageText。&lt;/p&gt;
&lt;h3 id=&#34;selecting-an-efficient-pre-training-method&#34;&gt;Selecting an Efficient Pre-Training Method&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/CLIP/fig2.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;最先進的 CV System 需要大量的計算。&lt;/p&gt;
&lt;p&gt;作者舉了兩個計算量都非常恐怖的模型，而且他們只能預測 1000 個 ImageNet 的類別。
其中一個花了 19 個 GPU years，另一個花了 33 個 TPUv3 core-years。
乍看之下，從自然語言中學習一組開放的視覺概念似乎令人生畏。&lt;/p&gt;
&lt;p&gt;但在作者努力的過程中，他們發現訓練效率是成功擴展自然語言監督的關鍵，也根據該指標選定最終的預訓練方法。&lt;/p&gt;
&lt;p&gt;最初的方法和 VirTex 相似，從頭開始訓練一個 CNN，和 text transformer 來預測 caption。&lt;/p&gt;
&lt;p&gt;Fig.2 展示的 Transformer 語言模型的計算量是 ResNet-50 Image encoder 的兩倍。
預測 caption 比預測 caption 但採用詞袋的方式還慢三倍。&lt;/p&gt;
&lt;p&gt;這樣預測 caption 是一個困難的任務，同一張照片對應的 caption 可能出現的描述甚至有非常多種。
最近在 Contrastive representation learning 方面的研究發現 contrastive objectives 有不錯的表現。&lt;/p&gt;
&lt;p&gt;因此作者探索一種方法是，只預測文本和哪一個圖片配對，而不是預測確切的單字。&lt;/p&gt;
&lt;p&gt;因為資料集超級大，overfitting 的問題影響不大。&lt;/p&gt;
&lt;p&gt;此外，作者發現對於 encoder 的 representation，要轉換到 multi-model embedding space，只需要使用 linear projection 即可，不需要 non-linear，兩者之間差別不大。&lt;/p&gt;
&lt;p&gt;Data augmentation 只有使用 random crop，而沒有使用其他的。&lt;/p&gt;
&lt;h3 id=&#34;choosing-and-scaling-a-model&#34;&gt;Choosing and Scaling a Model&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# image_encoder - ResNet or Vision Transformer&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# text_encoder - CBOW or Text Transformer&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# I[n, h, w, c] - minibatch of aligned images&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# T[n, l] - minibatch of aligned texts&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# W_i[d_i, d_e] - learned proj of image to embed&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# W_t[d_t, d_e] - learned proj of text to embed&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# t - learned temperature parameter&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# extract feature representations of each modality&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;I_f&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;image_encoder&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;I&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;#[n, d_i]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;T_f&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;text_encoder&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;T&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;#[n, d_t]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# joint multimodal embedding [n, d_e]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;I_e&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;l2_normalize&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;I_f&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;W_i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;axis&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;T_e&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;l2_normalize&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;T_f&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;W_t&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;axis&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# scaled pairwise cosine similarities [n, n]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;logits&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dot&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;I_e&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;T_e&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;T&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;exp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# symmetric loss function&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;labels&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;np&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;arange&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;loss_i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cross_entropy_loss&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;logits&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;axis&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;loss_t&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cross_entropy_loss&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;logits&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;axis&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;loss&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;loss_i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;loss_t&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;experiments&#34;&gt;Experiments&lt;/h2&gt;
&lt;h3 id=&#34;prompt-engineering-and-ensembling&#34;&gt;Prompt Engineering and Ensembling&lt;/h3&gt;
&lt;p&gt;一種常見的問題是 polysemy，一個單字可能有多種意思，比如 &amp;ldquo;boxer&amp;rdquo; 可能是一種狗，或是拳擊手。
如果一張圖片對應一個單字就會面臨這問題。&lt;/p&gt;
&lt;p&gt;另一種是 distribution gap，比如訓練用句子，但測試用單字。
為了緩解這問題，作者發現用 prompt template &amp;ldquo;A photo of a {label}.&amp;rdquo; 比直接用 label 好。&lt;/p&gt;
&lt;p&gt;光用這個 prompt template 就提高 1.3 % 在 ImageNet 上的準確度。&lt;/p&gt;
&lt;p&gt;如果可以給其他額外訊息會更有幫助，比如對於寵物的資料集，可以用 &amp;ldquo;A photo of a {label}, a type of pet.&amp;quot;。&lt;/p&gt;
&lt;p&gt;對於 OCR 資料集，作者發現在要識別的文字或數字前後加上引號可以提高效能。&lt;/p&gt;
&lt;p&gt;再來是 prompt ensembling，作者發現用多個 prompt template 來預測，然後綜合結果，可以提高效能。
作者用了 80 個 template。在 ImageNet 上比用單一的 prompt template 提高 3.5 % 的 performance。&lt;/p&gt;
&lt;p&gt;綜合考慮 prompt engineering 和 prompt ensembling，作者在 ImageNet 上的準確度提高大概 5%。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;這裡列幾個作者用的 prompt template:
&lt;ul&gt;
&lt;li&gt;&amp;ldquo;a bad photo of a {}.&amp;rdquo;&lt;/li&gt;
&lt;li&gt;&amp;ldquo;a photo of many {}.&amp;rdquo;&lt;/li&gt;
&lt;li&gt;&amp;ldquo;a sculpture of a {}.&amp;rdquo;&lt;/li&gt;
&lt;li&gt;&amp;ldquo;a photo of the hard to see {}.&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;analysis-of-zero-shot-clip-performance&#34;&gt;Analysis of Zero-Shot CLIP Performance&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/CLIP/fig5.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;對於一般的物體分類的資料集，CLIP 表現較好。&lt;/p&gt;
&lt;p&gt;下面有些複雜、專門、抽象的任務，CLIP 則表現的很差，比如計算場景中有多少物體的 （CLEVRCounts）、衛星圖像分類（EuroSAT）或是 識別最近的汽車距離（KITTI Distance）&lt;/p&gt;
&lt;p&gt;對於這種特別難的任務，讓 CLIP 做 zero-shot 不太合理。
可能用 few-shot 的方式會比較好。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/CLIP/fig6.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;BiT 是 google 為 Transfer Learning 設計的預訓練模型，在分類問題，Few-shot learning 上有良好的表現。&lt;/p&gt;
&lt;h3 id=&#34;representation-learning&#34;&gt;Representation Learning&lt;/h3&gt;
&lt;p&gt;這節探討完全使用下游任務資料集而非 Zero-shot 或 few-shot 的情況。&lt;/p&gt;
&lt;p&gt;作者選用 linear-probe 而不是 finetune 來做下游任務的評估。&lt;/p&gt;
&lt;p&gt;因為他們的重點是開發與資料集無關的預訓練方法，finetune 有可能讓一個預訓練學習 representation 失敗的模型在微調過程中變好。
而 linear-probe 的限制可以凸顯這些失敗。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/CLIP/fig10.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;comparison-to-human-performance&#34;&gt;Comparison to Human Performance&lt;/h2&gt;
&lt;p&gt;再來是 CLIP 和人類相比的結果。
挑選了五個人在寵物資料集上比較的結果。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/CLIP/table2.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;data-overlap-analysis&#34;&gt;Data Overlap Analysis&lt;/h2&gt;
&lt;p&gt;可能會有人質疑，CLIP 的表現是因為訓練資料集和測試資料集有重疊。
但作者做了一些實驗，有些資料集完全沒有偵測到重疊。
對有重疊的做實驗，發現有重疊的對效果提升影響很小。&lt;/p&gt;
&lt;h2 id=&#34;limitations&#34;&gt;Limitations&lt;/h2&gt;
&lt;p&gt;CLIP 雖然可以和作為 Baseline 的 ResNet-50 打平手，但現在的 SOTA 遠高於該 Baseline。&lt;/p&gt;
&lt;p&gt;作者發現再繼續加大模型和資料是可以繼續提升性能的，但作者估計要達到現有的 SOTA 需要增加大概 1000 倍的計算量才能達到，使用現有的硬體是不可行的。&lt;/p&gt;
&lt;p&gt;CLIP 對細分類、抽象或更難的任務表現不好，作者相信還有許多任務是 CLIP 用 zero-shot 只能達到亂猜等級的。&lt;/p&gt;
&lt;p&gt;Zero-Shot 的 CLIP 很難泛化到 out-of-distribution 的資料，比如在 MNIST 上只能達到 88% 的準確度。
作者發現預訓練資料幾乎沒有類似 MNIST 的圖片。&lt;/p&gt;
&lt;p&gt;盡管 CLIP 可以靈活應用各種 Zero-Shot 的分類，但基本上還是從你給定的分類選擇。
和真正靈活的方法（生成 image caption）相比，是重大的限制。&lt;/p&gt;
&lt;p&gt;一個值得嘗試的簡單想法是把 contrastive objective 和 generative objective，結合。&lt;/p&gt;
&lt;p&gt;CLIP 也沒有解決深度學習資料效率低下的問題，CLIP 訓練了 32 個 epoch，如果把預訓練期間的照片以一秒一張來呈現，需要 405 年。
把 CLIP 和 self-supervision 或者和 self-training 做結合是有前途的方向。&lt;/p&gt;
&lt;p&gt;雖然作者強調 Zero-Shot Learning，但是作者還是有反覆檢查下游任務測試集的表現，來調整 CLIP。
每次都用 ImageNet 來確認，並不算真正的 zero-shot 的情況。
如果能再創一個新的資料集，專門用來評估 zero-shot 遷移的能力會更恰當。&lt;/p&gt;
&lt;p&gt;爬下來的資料有可能帶有社會偏見。&lt;/p&gt;
&lt;p&gt;有一些複雜的任務很難用文字來傳達，雖然實際的訓練樣本有用，但 CLIP 並不會針對 few-shot 最佳化。有個違反直覺的結果，可以注意到在某些情況下，few-shot 不見得比 zero-shot 好。&lt;/p&gt;
&lt;h2 id=&#34;額外應用&#34;&gt;額外應用&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;圖片生成
&lt;ul&gt;
&lt;li&gt;StyleCLIP: Text-Driven Manipulation of StyleGAN Imagery
&lt;ul&gt;
&lt;li&gt;用文字引導生成圖片&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;CLIPDraw: Exploring Text-to-Drawing Synthesis through Language-Image Encoders&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;物件偵測
&lt;ul&gt;
&lt;li&gt;Open-Vocabulary Object Detection via Vision and Language Knowledge Distillation
&lt;ul&gt;
&lt;li&gt;將基礎類別再做細分類&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;OCR
&lt;ul&gt;
&lt;li&gt;Contrastive Language-Image Forensic Search
&lt;ul&gt;
&lt;li&gt;搜索影片中有沒有文本描述的物體&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;筆記&#34;&gt;筆記&lt;/h2&gt;
&lt;p&gt;prompt engineering
prompt ensemble&lt;/p&gt;
</description>
        </item>
        <item>
        <title>MLP-Mixer 論文閱讀</title>
        <link>https://roykesydon.github.io/Blog/p/mlp-mixer-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</link>
        <pubDate>Mon, 30 Oct 2023 00:27:55 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/mlp-mixer-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</guid>
        <description>&lt;p&gt;paper: &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2107.05407&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PonderNet: Learning to Ponder&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;CNN 在  CV 領域是首選，但基於 attention 的網路也在變流行。&lt;/p&gt;
&lt;p&gt;本文證明雖然 convolution 和 attention 都可以獲得良好的 performance，但皆非必須。&lt;/p&gt;
&lt;p&gt;本文提出了 MLP-Mixer，一種純 MLP 的架構，包含兩種 layer：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;將 MLP 獨立用在 patch
&lt;ul&gt;
&lt;li&gt;mixing per-location features&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;將 MLP 用在 patches 之間。
&lt;ul&gt;
&lt;li&gt;mixing spatial information&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;本文提出了完全基於 MLP 的 MLP-Mixer ( 又簡稱 Mixer )，有競爭力卻概念和技術上都很簡單。&lt;/p&gt;
&lt;p&gt;有兩種 MLP layer：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Channel-Mixing MLP&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;用在每個 patch 上&lt;/li&gt;
&lt;li&gt;讓不同 channel 之間的資訊互相交換&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Token-Mixing MLP&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;用在所有 patch 上&lt;/li&gt;
&lt;li&gt;讓空間資訊互相交換&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;這兩者交錯出現，讓兩個輸入維度可以交互作用&lt;/p&gt;
&lt;p&gt;在極端情況下，本文的架構可以看做是一個非常特殊的 CNN，使用 1*1 卷積做 channel mixing，並用 single-channel 且 full receptive field 的 1D 卷積做 token mixing。&lt;/p&gt;
&lt;p&gt;反之則不然，因為經典的 CNN 並不是 Mixer 的特例。&lt;/p&gt;
&lt;p&gt;盡管很簡單，但 Mixer 卻取得有競爭力的結果。&lt;/p&gt;
&lt;p&gt;然而與 ViT 一樣，在一切特有的 CNN 架構下略有欠缺。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/MLP-Mixer/fig1.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;mixer-architecture&#34;&gt;Mixer Architecture&lt;/h2&gt;
&lt;p&gt;Mixer 的核心概念是想把&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;mix features at a given spatial location&lt;/li&gt;
&lt;li&gt;mix features between different spatial locations&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;給分開來&lt;/p&gt;
&lt;p&gt;所有的 patch 都是用同一個 projection matrix&lt;/p&gt;
&lt;p&gt;注意 fig1 的 MLP2，他們共享同樣的參數，這樣綁定參數可以預防 C 和 S 增加時使架構增長過快。在 seperable convolution 中，不同通道使用不同的 kernel。不過作者這樣的選擇並不影響實際的 performance。&lt;/p&gt;
&lt;p&gt;Mixer 的所有 Layer 都具備相同的輸入大小。&lt;/p&gt;
&lt;p&gt;這種「isotropic」的設計和 Transformer 或 RNN 比較像。&lt;/p&gt;
&lt;p&gt;與大多數具有 pyramidal structure 的 CNN 不同，它們在更深的層有更低的 resolution，但有更多 channel。&lt;/p&gt;
&lt;p&gt;不過上面只是探討典型的設計，也存在例外，比如 isotropic Resnet 或 pyramidal ViT。&lt;/p&gt;
&lt;p&gt;除了 MLP，Mixer 還有用到 LayerNorm 和 skip connection。&lt;/p&gt;
&lt;p&gt;但是 Mixer 沒有用到 positional encoding，因為 token-mixing MLP 本身就對位置敏感。\&lt;/p&gt;
&lt;h2 id=&#34;experiments&#34;&gt;Experiments&lt;/h2&gt;
&lt;p&gt;Mixer 用中大型資料集預訓練，然後在一系列中小資料集上評估。&lt;/p&gt;
&lt;p&gt;目標不是拿到 SOTA，而是顯示出與 SOTA 的 CNN 和 attention-based model 相比，Mixer 有競爭力。&lt;/p&gt;
&lt;h3 id=&#34;fine-tuning&#34;&gt;Fine-tuning&lt;/h3&gt;
&lt;p&gt;在 fine-tuning 時，用比預訓練時還要高的 resolution。
由於每個 patch 的 resolution 是固定的，這樣會導致有更多的 patches。&lt;/p&gt;
&lt;p&gt;對於這個問題，採用以下解法：&lt;/p&gt;
&lt;p&gt;我們原先預計吃 S 個 patch，現在我們由於輸入解析度更高，而且 patch 大小不變，所以我們得到一個比 S 還大的 $S&amp;rsquo;$。
所以我們在很多地方就需要比原先權重矩陣 W 還更大的 $W&#39;$&lt;/p&gt;
&lt;p&gt;我們要把 $S&amp;rsquo;$ 拆成 $K^2$ 個長度為 $S$ 的 sequence，K 是整數。&lt;/p&gt;
&lt;p&gt;並且我們把 $W&amp;rsquo;$ 的 shape 改成 $(W.shape[0] * K^2, W.shape[1] * K^2)$&lt;/p&gt;
&lt;p&gt;然後我們把 $W&amp;rsquo;$ 作為 block-diagonal matrix 來初始化，把 $W$ copy 好幾份，放在 main diagonal 上。&lt;/p&gt;
&lt;p&gt;所有權重都用類似的處理方法。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Diffusion 入門</title>
        <link>https://roykesydon.github.io/Blog/p/diffusion-%E5%85%A5%E9%96%80/</link>
        <pubDate>Mon, 23 Oct 2023 00:27:55 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/diffusion-%E5%85%A5%E9%96%80/</guid>
        <description>&lt;h2 id=&#34;大致概念&#34;&gt;大致概念&lt;/h2&gt;
&lt;p&gt;屬於生成式 AI，一開始用在生成圖片，後來也有應用到諸如 NLP 等領域。&lt;/p&gt;
&lt;p&gt;下文稱呼原圖為 sprite。&lt;/p&gt;
&lt;p&gt;與 AutoEncoder 有點類似，先取得一張 sprite，隨著時間推進，每次都在圖片上加一層雜訊，反覆疊加，迭代多次後，就會得到一張難以看出原圖的雜訊。&lt;/p&gt;
&lt;p&gt;從 sprite 到只能看出是一團雜訊並非是一步到位的過程。一開始沒有雜訊時可以看出原本的 sprite，一個迭代後可能可以勉強看出原本的 sprite，再幾個迭代後可能也還能看出原本的 outline，經過許多次後才會變成完全辨識不了的雜訊。&lt;/p&gt;
&lt;p&gt;我們期望模型做的事情則是從 gaussian noise 逐步推回 sprite，同樣不是一步到位，而是讓模型預測上一個時間點的雜訊，相減後再逐步推回 sprite，這過程稱為 denoise。&lt;/p&gt;
&lt;h2 id=&#34;ddpm&#34;&gt;DDPM&lt;/h2&gt;
&lt;p&gt;實現 Diffusion 可能會有點 confusing，因為他實作上和上面說的不太相同。
在訓練的時候，我們會採樣三個東西：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;訓練圖片 (sprite)&lt;/li&gt;
&lt;li&gt;雜訊&lt;/li&gt;
&lt;li&gt;時間點 (t)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;訓練階段的時候，我們會把「原始乾淨的圖片」和「雜訊」根據時間進行不同比例的相加 (混合)，t 越大，雜訊的比例越大。&lt;/p&gt;
&lt;p&gt;模型預測的目標是前面 sample 出的雜訊。&lt;/p&gt;
&lt;p&gt;這與前面說的概念相悖。按照前面的說法，對於時間點 t，應該是以一張加了 t-1 次雜訊的 sprite 作為輸入，再加上 t 所 sample 出的雜訊。&lt;/p&gt;
&lt;p&gt;現在實作卻是原始乾淨的 sprite 直接根據時間點混和某個雜訊。&lt;/p&gt;
&lt;p&gt;這背後的數學推導十分冗長，這裡不敘述，但需知道實作差異。&lt;/p&gt;
&lt;h3 id=&#34;inference&#34;&gt;Inference&lt;/h3&gt;
&lt;p&gt;在推論階段的時候，每次 denoise 後需要把圖片和額外 sample 的 noise 相加。這個 noise 和前面的 noise 一樣，都是從 mean=0, std=1 的 gaussian distribution 中 sample 出來的。&lt;/p&gt;
&lt;p&gt;不加的話似乎還容易有 Mode Collapse 的現象。
看到一個說法是，模型喜歡吃圖片加上雜訊的圖像作為圖片，在圖片上加上 noise 似乎會更符合模型預期的輸入。&lt;/p&gt;
&lt;p&gt;看了李弘毅的影片，也有基於隨機性的觀點。&lt;/p&gt;
&lt;p&gt;生成式 Model 生成文章時永遠取機率最大的，不見得有更好的效果：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;有研究是讓 Model 選機率最大的，結果容易生出反覆跳針的文章。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;也有把人類寫的文章去餵給 Model 看，從他的角度看人類寫的下一個字的機率是多少，發現人類寫的文章很常出現一下機率高一下機率低的字。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;某篇語音合成的文章需要在推論階段「啟用」dropout 才可以有好的結果。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Diffusion 也有可能成功的點是在於並非「一次到位」而是「N 次到位」。
從這樣的角度看，Diffusion 是 autoregressive 模型。&lt;/p&gt;
&lt;p&gt;類似的作法也有 Mask-Predict，大致概念是從原本都是 Mask 的情境開始，將一些信心高的預測留住，信心低的保持為 Mask，一步步預測出所有資訊。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>設計模式 Desing Pattern</title>
        <link>https://roykesydon.github.io/Blog/p/%E8%A8%AD%E8%A8%88%E6%A8%A1%E5%BC%8F-desing-pattern/</link>
        <pubDate>Tue, 10 Oct 2023 00:00:17 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/%E8%A8%AD%E8%A8%88%E6%A8%A1%E5%BC%8F-desing-pattern/</guid>
        <description>&lt;h2 id=&#34;creational-patterns&#34;&gt;Creational patterns&lt;/h2&gt;
&lt;p&gt;關於 object creation 的 patterns。&lt;/p&gt;
&lt;h3 id=&#34;factory-method&#34;&gt;Factory Method&lt;/h3&gt;
&lt;p&gt;將不同 Product 定義一個共有的 Interface，並由子類別實作，透過工廠類別來產生實體。&lt;/p&gt;
&lt;p&gt;將建立 Product 的方法獨立出來，符合 Single Responsibility Principle。
可以輕易擴充新的 Product，而不用修改原本的程式碼，符合 Open-Closed Principle。&lt;/p&gt;
&lt;h3 id=&#34;abstract-factory&#34;&gt;Abstract Factory&lt;/h3&gt;
&lt;p&gt;相比 Factory Method，現在的情境是有多個 Product，而且每次都是使用同一系列的 Product。&lt;/p&gt;
&lt;h3 id=&#34;builder&#34;&gt;Builder&lt;/h3&gt;
&lt;p&gt;對於建構一個複雜且具備多種組合的產品，可以透過建構巨大的建構函式或是覆蓋所有可能的子類別來解決。&lt;/p&gt;
&lt;p&gt;但都存在其問題，要不是大量的子類別，不然就是難以呼叫的建構函式。&lt;/p&gt;
&lt;p&gt;把建立物件的每個 component 獨立出來，並且切成多個可分開執行的 step。&lt;/p&gt;
&lt;p&gt;由 Builder 來負責生出每一個 component，Director 不是必需的，但有需要的話可以讓他幫忙調用 Builder 的 method，好在專案中重複使用。&lt;/p&gt;
&lt;h3 id=&#34;prototype&#34;&gt;Prototype&lt;/h3&gt;
&lt;p&gt;使用在想要獲得某個對象的 clone 的情境。&lt;/p&gt;
&lt;p&gt;把 clone 的責任交給對象本身，而不是交給 Client。由對象本身提供 clone method。&lt;/p&gt;
&lt;h3 id=&#34;singleton&#34;&gt;Singleton&lt;/h3&gt;
&lt;p&gt;確保某個類別只有一個 instance，並且提供一個 global access point。&lt;/p&gt;
&lt;p&gt;但是這樣違反了 Single Responsibility Principle，因為除了原本的功能外，還要負責管理自己的 instance。&lt;/p&gt;
&lt;h2 id=&#34;structural-patterns&#34;&gt;Structural patterns&lt;/h2&gt;
&lt;p&gt;探討如何組裝類別和物件成為更大的結構。&lt;/p&gt;
&lt;h3 id=&#34;adapter&#34;&gt;Adapter&lt;/h3&gt;
&lt;p&gt;轉換某個對象的 interface 到另外一種 interface，讓另外一個 Object 可以理解他。
就像 XML 要轉到 JSON。&lt;/p&gt;
&lt;h3 id=&#34;brdige&#34;&gt;Brdige&lt;/h3&gt;
&lt;p&gt;使用在需要在多個 orthogonal (independent) 的維度上擴展類別時的情境。
讓情況從難以計數的子類別數，變成多組功能聯合起來。&lt;/p&gt;
&lt;p&gt;拆成 abstraction (high-level control) 和 implementation (實際工作)，
由 abstraction 來控制 implementation，比如 GUI 來控制底下的 API&lt;/p&gt;
&lt;h3 id=&#34;composite&#34;&gt;Composite&lt;/h3&gt;
&lt;p&gt;用在某些層級結構。&lt;/p&gt;
&lt;p&gt;對於 Composite (Container)，不但實現 Component，也提供一個 list 來存放子 component。&lt;/p&gt;
&lt;p&gt;對 Composite 的操作，會被委託給子 component，不需要 client 擔心。&lt;/p&gt;
&lt;p&gt;就像指揮官只需要對高階軍官下命令。&lt;/p&gt;
&lt;h3 id=&#34;decorator&#34;&gt;Decorator&lt;/h3&gt;
&lt;p&gt;當今天有多種同類型的東西，你可以能會同時用到多種子類別所形成的組合時，就可以用 Decorator。&lt;/p&gt;
&lt;p&gt;比如多種類型的 notification，你可能同時想要 FB 和 TG 的，或是只想要其中一個。
或是多件衣服，有超級多種的穿搭。&lt;/p&gt;
&lt;p&gt;但這是一層層的感覺，具有順序性。
Decorator 和 Component 都繼承同一個 interface。
就像是 &lt;code&gt;Data data = new Encrypt(new Compress(new FileData()))&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;存在很難從 stack 中刪除特定 decorator 的缺點。&lt;/p&gt;
&lt;h3 id=&#34;facade&#34;&gt;Facade&lt;/h3&gt;
&lt;p&gt;為複雜的一堆子系統提供一個 Class，讓 client 可以使用他們關心的功能。
實際怎麼調用 client 無須知道。&lt;/p&gt;
&lt;p&gt;容易形成 god object。&lt;/p&gt;
&lt;h3 id=&#34;flyweight&#34;&gt;Flyweight&lt;/h3&gt;
&lt;p&gt;對於大量類似的物件，為求節省記憶體而誕生的 pattern。&lt;/p&gt;
&lt;p&gt;把物件的內容分成 intrinsic 和 extrinsic，intrinsic 是不會改變的 (unique)，而 extrinsic 是會改變的 (repeating)。&lt;/p&gt;
&lt;p&gt;讓 extrinsic 的東西用同一塊記憶體。&lt;/p&gt;
&lt;h3 id=&#34;proxy&#34;&gt;Proxy&lt;/h3&gt;
&lt;p&gt;用在多個服務想要調用某個重量級資源的情境下。&lt;/p&gt;
&lt;p&gt;存在多種 proxy 的應用類型，比如 cache 機制來加速資源的存取，並減少系統資源消耗。&lt;/p&gt;
&lt;h2 id=&#34;behavioral-patterns&#34;&gt;Behavioral patterns&lt;/h2&gt;
&lt;h3 id=&#34;chain-of-responsibility&#34;&gt;Chain of Responsibility&lt;/h3&gt;
&lt;p&gt;對於一系列檢查的情況，可以用這種作法，有兩種形式：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;一路檢查，檢查失敗則中斷請求。&lt;/li&gt;
&lt;li&gt;每個 Handler 自行決定要不要處理該請求，要的話則不會往下傳。
&lt;ul&gt;
&lt;li&gt;這樣可能會最後沒人處理&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;就像網頁點擊事件，一層層元素往下問。&lt;/p&gt;
&lt;h3 id=&#34;command&#34;&gt;Command&lt;/h3&gt;
&lt;p&gt;把請求獨立出來，讓該請求可以被用作參數、佇列、撤銷行為等。&lt;/p&gt;
&lt;p&gt;比如多種不同的按鈕背後都執行同一個存檔功能。存檔就可以作為 command 獨立出來。
背後再根據這個 command 實施對應的業務邏輯。&lt;/p&gt;
&lt;h3 id=&#34;iterator&#34;&gt;Iterator&lt;/h3&gt;
&lt;p&gt;用來需要遍歷集合中元素的情境，把不同種類的遍歷行為細節隱藏起來。&lt;/p&gt;
&lt;p&gt;提供多種不同的 iterator，但遵循同一種 interface，讓使用者可以根據需要選擇 iterator。
對於不關心用哪種 iterator 的使用者，也能受益於 iterator 的 interface，而不必耦合於特定的演算法。&lt;/p&gt;
&lt;h3 id=&#34;mediator&#34;&gt;Mediator&lt;/h3&gt;
&lt;p&gt;禁止多個 component 間的直接溝通，迫使他們透過 mediator 來溝通，避免複雜的關係。
所有人只能透過 notify mediator 來溝通，mediator 根據 sender 和 event，來做出相應處理。&lt;/p&gt;
&lt;h3 id=&#34;memento&#34;&gt;Memento&lt;/h3&gt;
&lt;p&gt;讓你可以儲存和復原到先前的狀態。&lt;/p&gt;
&lt;p&gt;讓要儲存的對象自己生成 snapshot。&lt;/p&gt;
&lt;p&gt;建議存在名為 momento 的 special object，這個 object 不能讓除了 producer 外的其他 object 直接存取。
其他 object 只能透過 limited interface 來取得 metadata。&lt;/p&gt;
&lt;p&gt;這些限制讓 momento 可以交給其他 object 來管理，稱為 caretaker。&lt;/p&gt;
&lt;h3 id=&#34;observer&#34;&gt;Observer&lt;/h3&gt;
&lt;p&gt;定義 subscription 機制。&lt;/p&gt;
&lt;p&gt;有 interesting state 的 object 稱為 subject，但由於他也會通知其他人，所以又稱為 publisher。追蹤它的人稱為 Subscriber。&lt;/p&gt;
&lt;h3 id=&#34;state&#34;&gt;State&lt;/h3&gt;
&lt;p&gt;用在類似 Finite-State Machine 的情況。&lt;/p&gt;
&lt;p&gt;該 pattern 把每個 state 獨立成一個 Class，把實際的行為委託給 state，而不是由 context (原始物件) 來控制。Context 只管切換 state。&lt;/p&gt;
&lt;h3 id=&#34;strategy&#34;&gt;Strategy&lt;/h3&gt;
&lt;p&gt;把不同實現方法的演算法定義為遵循同一個 interface 的類別，讓使用者可以根據需要選擇演算法。&lt;/p&gt;
&lt;h3 id=&#34;template-method&#34;&gt;Template Method&lt;/h3&gt;
&lt;p&gt;把演算法拆成多個步驟，讓子類別可以覆寫其中的步驟，但不改變演算法的結構。&lt;/p&gt;
&lt;h3 id=&#34;visitor&#34;&gt;Visitor&lt;/h3&gt;
&lt;p&gt;讓我們可以把演算法從執行他們的 object 中分離出來。&lt;/p&gt;
&lt;p&gt;假設我們要對一堆繼承 client 屬性的公司新增 sendEmail 功能，如果我們在 client 新增 sendEmail 並且 override 每個子 class，就會違反 Single Responsibility Principle 和 Open-Closed Principle。&lt;/p&gt;
&lt;p&gt;要利用 Double-Dispatch，讓 Object 本身選擇該用的演算法。&lt;/p&gt;
&lt;p&gt;雖然這樣依然會修改到子 class，但這屬於微不足道的改變，而且可以讓之後新增的一些功能不用再去修改這些子 class。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>查找相似向量</title>
        <link>https://roykesydon.github.io/Blog/p/%E6%9F%A5%E6%89%BE%E7%9B%B8%E4%BC%BC%E5%90%91%E9%87%8F/</link>
        <pubDate>Fri, 06 Oct 2023 00:27:55 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/%E6%9F%A5%E6%89%BE%E7%9B%B8%E4%BC%BC%E5%90%91%E9%87%8F/</guid>
        <description>&lt;h2 id=&#34;提高查找相似向量的速度&#34;&gt;提高查找相似向量的速度&lt;/h2&gt;
&lt;p&gt;任何非暴力搜尋的搜尋方法，都會一定程度上的降低搜索品質。
需要在搜索品質和速度進行 trade-off。&lt;/p&gt;
&lt;h3 id=&#34;k-means&#34;&gt;K-Means&lt;/h3&gt;
&lt;p&gt;可用在將向量資料庫分群，以便縮小查找相似向量的範圍。&lt;/p&gt;
&lt;p&gt;迭代計算群心，直到收斂&lt;/p&gt;
&lt;p&gt;依據離群心的遠近分類&lt;/p&gt;
&lt;h4 id=&#34;問題&#34;&gt;問題&lt;/h4&gt;
&lt;p&gt;相近的向量有可能被分到不同群&lt;/p&gt;
&lt;p&gt;可以透過「用更多類，並搜索多個最近群」來緩解問題&lt;/p&gt;
&lt;p&gt;可以找其他 ANN (Approximate Nearest Neighbors) 演算法來面對該問題&lt;/p&gt;
&lt;h3 id=&#34;位置敏感哈希-locality-sensitive-hashing-lsh&#34;&gt;位置敏感哈希 (Locality Sensitive Hashing, LSH)&lt;/h3&gt;
&lt;p&gt;讓越相似的向量越容易碰撞，找相似向量就在同個 bucket 找&lt;/p&gt;
&lt;h4 id=&#34;實現方法&#34;&gt;實現方法&lt;/h4&gt;
&lt;p&gt;此處挑一種方式舉例，此處用隨機超平面舉例。&lt;/p&gt;
&lt;p&gt;可以在空間中隨機生成多個 (n-1) 維度的超平面，將兩邊分類為 0 和 1。
距離較遠的點對被切割開的機率會比距離較近的點對還大。
用這樣的方法，會讓相近的點對生出的 Hash 值較接近。&lt;/p&gt;
&lt;h4 id=&#34;問題-1&#34;&gt;問題&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;接近的向量有可能因為機率因素被分到不同 bucket
&lt;ul&gt;
&lt;li&gt;將向量分段，每段有匹配到同個 bucket 就視作候選項&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;減少查找相似向量的記憶體開銷&#34;&gt;減少查找相似向量的記憶體開銷&lt;/h2&gt;
&lt;p&gt;大量的高維向量會造成大量的記憶體開銷&lt;/p&gt;
&lt;h3 id=&#34;k-means-1&#34;&gt;K-Means&lt;/h3&gt;
&lt;p&gt;把同一群的向量都用群心向量代替，是一種有損壓縮。&lt;/p&gt;
&lt;h4 id=&#34;問題-2&#34;&gt;問題&lt;/h4&gt;
&lt;p&gt;但這樣需要另外的空間來存取 codebook (向量對應表)，在某些情況不見得比原本的向量還省空間，甚至可能花更多。&lt;/p&gt;
&lt;p&gt;n 維的向量可能需要 $2^{\frac{n}{2}}$ 的 class 才可以較好的分類 (來源未知)&lt;/p&gt;
&lt;p&gt;可以透過把高維向量切割成多個低維子向量個別處理再合併來緩解該問題。&lt;/p&gt;
&lt;p&gt;該方法稱為 Product Quntization (PQ)&lt;/p&gt;
&lt;h2 id=&#34;其他做法&#34;&gt;其他做法&lt;/h2&gt;
&lt;h3 id=&#34;nsw&#34;&gt;NSW&lt;/h3&gt;
&lt;h4 id=&#34;六度分隔理論-six-degrees-of-separation&#34;&gt;六度分隔理論 (Six degrees of separation)&lt;/h4&gt;
&lt;p&gt;對於世界上兩個互不相識的人，只需要六個中間人就可以建立起連結。&lt;/p&gt;
&lt;h4 id=&#34;做法&#34;&gt;做法&lt;/h4&gt;
&lt;p&gt;我們想找對於某個目標向量而言最相似的向量。&lt;/p&gt;
&lt;p&gt;先隨機找一個點，找他的相鄰節點誰和目標向量最相近，並反覆此過程，直到所有相鄰節點都沒有自己離目標相近。&lt;/p&gt;
&lt;p&gt;六度分隔理論讓我們推測這過程可能很快就會結束。&lt;/p&gt;
&lt;h4 id=&#34;建立結構&#34;&gt;建立結構&lt;/h4&gt;
&lt;p&gt;我們得幫這些向量建立圖關係。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Delaunay triangulation algorithm
&lt;ul&gt;
&lt;li&gt;可以用來建立圖關係&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;但靠 Delaunay triangulation algorithm，有可能隨機的向量和目標向量距離很遠，查找很慢。&lt;/p&gt;
&lt;p&gt;NSW 的實際做法是將所有向量隨機地放回圖中，並和最近的 k 個點連接。&lt;/p&gt;
&lt;p&gt;只看較短的連接，會發現和 Delaunay triangulation algorithm 產的圖相近，可以進行細粒度的查找。
只看較長的連接，則可達到快速導航的效果。&lt;/p&gt;
&lt;h4 id=&#34;hnsw&#34;&gt;HNSW&lt;/h4&gt;
&lt;p&gt;建立一個分層結構，越上層的點越稀疏、連線越長。&lt;/p&gt;
&lt;p&gt;和 NSW 相比，讓粗粒度到細粒度的導航過程更加穩定。&lt;/p&gt;
&lt;p&gt;但占用的記憶體空間更大。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>資料結構筆記</title>
        <link>https://roykesydon.github.io/Blog/p/%E8%B3%87%E6%96%99%E7%B5%90%E6%A7%8B%E7%AD%86%E8%A8%98/</link>
        <pubDate>Tue, 29 Aug 2023 00:08:46 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/%E8%B3%87%E6%96%99%E7%B5%90%E6%A7%8B%E7%AD%86%E8%A8%98/</guid>
        <description>&lt;h2 id=&#34;union-find-dsu&#34;&gt;Union-Find (DSU)&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;不同條件下的時間複雜度
&lt;ul&gt;
&lt;li&gt;待補&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;find&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;else&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;find&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;merge&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;find&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;find&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;main&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;++&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;find&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;find&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;!=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;merge&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;trie&#34;&gt;Trie&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Node&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;   &lt;span class=&#34;k&#34;&gt;public&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cnt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;Node&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nxt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;26&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;];&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;Node&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;cnt&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;26&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;++&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nxt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;nullptr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;};&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;segment-tree-單點修改線段樹&#34;&gt;Segment Tree 單點修改線段樹&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;#define pl(x) (x * 2 + 1)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;#define pr(x) (x * 2 + 2)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;build&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;index&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;l&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;l&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;tree&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;index&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;arr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;l&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;];&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mid&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;l&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;build&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pl&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;index&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;l&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;build&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;index&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mid&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;tree&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;index&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tree&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pl&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;index&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tree&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;index&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)];&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;change&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;index&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;q&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;l&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;l&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;tree&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;index&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mid&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;l&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mid&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;q&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;change&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pl&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;index&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;q&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;l&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;else&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;change&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;index&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;q&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mid&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;tree&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;index&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tree&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pl&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;index&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tree&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;index&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)];&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;query&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;index&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ql&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;qr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;l&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ans&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ql&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;l&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;r&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;qr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;ans&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;tree&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;index&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;];&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mid&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;l&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ql&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pl&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;index&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ql&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;qr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;l&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ans&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mid&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;qr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;query&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;index&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ql&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;qr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mid&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ans&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
        </item>
        <item>
        <title>未分類演算法 &amp; 資料結構筆記</title>
        <link>https://roykesydon.github.io/Blog/p/%E6%9C%AA%E5%88%86%E9%A1%9E%E6%BC%94%E7%AE%97%E6%B3%95-%E8%B3%87%E6%96%99%E7%B5%90%E6%A7%8B%E7%AD%86%E8%A8%98/</link>
        <pubDate>Sun, 27 Aug 2023 00:09:46 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/%E6%9C%AA%E5%88%86%E9%A1%9E%E6%BC%94%E7%AE%97%E6%B3%95-%E8%B3%87%E6%96%99%E7%B5%90%E6%A7%8B%E7%AD%86%E8%A8%98/</guid>
        <description>&lt;h2 id=&#34;sorting&#34;&gt;Sorting&lt;/h2&gt;
&lt;h3 id=&#34;merge-sort&#34;&gt;Merge Sort&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;一直拆分兩邊最後再輪流 merge 起來，merge 時看兩邊開頭誰最小，依序放&lt;/li&gt;
&lt;li&gt;都是 $O(nlogn)$&lt;/li&gt;
&lt;li&gt;stable&lt;/li&gt;
&lt;li&gt;not in-place&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;quick-sort&#34;&gt;Quick sort&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;選定一個 pivot，用兩個指針從兩邊開始往中間找。當左指針找到比 pivot 大的數值，右指針找到比 pivot 小的數值後交換。直到兩個指針相遇，再把 pivot 換到中間，繼續兩邊處理&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;最差會到 $O(n^2)$，平均 $O(nlogn)$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;選 pivot&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;隨機選&lt;/li&gt;
&lt;li&gt;Median of Three
&lt;ul&gt;
&lt;li&gt;選開頭、中間和結尾的中位數&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;other&#34;&gt;Other&lt;/h2&gt;
&lt;h3 id=&#34;binary-exponentiation-快速冪&#34;&gt;Binary Exponentiation 快速冪&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;qpow&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;m&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ans&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;while&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;m&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;m&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ans&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;m&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ans&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;discretization-離散化&#34;&gt;Discretization 離散化&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;sort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;begin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;vec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;end&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;());&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;vec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;resize&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;unique&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;begin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;vec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;end&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;vec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;begin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;());&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;vec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;++&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;val&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;lower_bound&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;begin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;vec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;end&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;val&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;vec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;begin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;ternary-search-三分搜&#34;&gt;Ternary Search 三分搜&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;l&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;10000.0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;r&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;10000.0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;while&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;r&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;l&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;eps&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;ml&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;r&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;l&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;3.0&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;l&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;mr&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;r&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;l&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;2.0&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;/&lt;/span&gt; &lt;span class=&#34;mf&#34;&gt;3.0&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;l&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ml&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;l&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;ml&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;else&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;r&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
        </item>
        <item>
        <title>圖論筆記</title>
        <link>https://roykesydon.github.io/Blog/p/%E5%9C%96%E8%AB%96%E7%AD%86%E8%A8%98/</link>
        <pubDate>Sun, 27 Aug 2023 00:08:46 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/%E5%9C%96%E8%AB%96%E7%AD%86%E8%A8%98/</guid>
        <description>&lt;h2 id=&#34;floyd-warshall&#34;&gt;Floyd-Warshall&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;k&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;k&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nodeCount&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;++&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nodeCount&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;++&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;j&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;j&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;nodeCount&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;j&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;++&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;DP&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;j&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;min&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;DP&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;j&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;DP&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;DP&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;][&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;j&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;dijkstra&#34;&gt;dijkstra&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;時間複雜度 $O((V+E)*log(E))$
&lt;ul&gt;
&lt;li&gt;最差每條邊都要插入 heap&lt;/li&gt;
&lt;li&gt;要取出 V 個點&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;class&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;cmp&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;public&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;kt&#34;&gt;bool&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;operator&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;edge&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;edge&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;weight&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;weight&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;};&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;dis&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;priority_queue&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;edge&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;vector&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;edge&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;cmp&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pq&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;pq&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;push&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;({&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;});&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;while&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;!&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pq&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;empty&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;edge&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;u&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;pq&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;top&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;n&#34;&gt;pq&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;pop&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;!&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vis&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to_node&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;vis&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to_node&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;auto&lt;/span&gt; &lt;span class=&#34;nl&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;mp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to_node&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dis&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to_node&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dis&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to_node&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;weight&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;n&#34;&gt;dis&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to_node&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dis&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to_node&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;weight&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;                &lt;span class=&#34;n&#34;&gt;pq&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;push&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;({&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to_node&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dis&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to_node&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]});&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;topological-sorting&#34;&gt;Topological Sorting&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;記得確認是不是 Directed Acyclic Graph&lt;/li&gt;
&lt;li&gt;BFS 是沒有前繼節點優先，DFS 是沒有後繼節點優先&lt;/li&gt;
&lt;li&gt;用 BFS 的話就是把入度為 0 的點加入 Queue，一直維護該 Queue&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;dfs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;!&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vis&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;vis&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;auto&lt;/span&gt; &lt;span class=&#34;nl&#34;&gt;j&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;edge&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dfs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;j&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;toposort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;push_back&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;u&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;++&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;dfs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;reverse&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;toposort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;begin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(),&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;toposort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;end&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;());&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;樹的直徑&#34;&gt;樹的直徑&lt;/h2&gt;
&lt;p&gt;兩次 DFS，第一次找到離任意點最遠的點，第二次從該點出發找到離他最遠的點，這兩個點之間的距離就是樹的直徑。&lt;/p&gt;
&lt;h2 id=&#34;lowest-common-ancestor&#34;&gt;Lowest Common Ancestor&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;待補&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;eulerian-path-歐拉路徑&#34;&gt;Eulerian path 歐拉路徑&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;每條邊只能被訪問一次（一筆畫問題）&lt;/li&gt;
&lt;li&gt;條件
&lt;ul&gt;
&lt;li&gt;除了兩個點外，其他都得為入度==出度。另外兩個點，最多有一個出度要比入度大一，最多有一個入度要比出度大一。（只能有 0 或 2 個奇點）&lt;/li&gt;
&lt;li&gt;須為連通圖
&lt;ul&gt;
&lt;li&gt;視作無向圖的時候是否可以連到每個點&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;matching&#34;&gt;Matching&lt;/h2&gt;
&lt;h3 id=&#34;hungarian-algorithm&#34;&gt;Hungarian Algorithm&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;待補&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;最小點覆蓋等等&#34;&gt;最小點覆蓋等等&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;待補&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>GraphQL 簡介</title>
        <link>https://roykesydon.github.io/Blog/p/graphql-%E7%B0%A1%E4%BB%8B/</link>
        <pubDate>Tue, 22 Aug 2023 00:00:17 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/graphql-%E7%B0%A1%E4%BB%8B/</guid>
        <description>&lt;h2 id=&#34;簡介&#34;&gt;簡介&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Meta 在 2015 年公開的 API Query Language&lt;/li&gt;
&lt;li&gt;常被用來和傳統的 REST API 比較，具備查詢更加靈活等特性&lt;/li&gt;
&lt;li&gt;有在使用的公司
&lt;ul&gt;
&lt;li&gt;Facebook&lt;/li&gt;
&lt;li&gt;GitHub&lt;/li&gt;
&lt;li&gt;Twitter&lt;/li&gt;
&lt;li&gt;&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;和-rest-api-的主要差別&#34;&gt;和 REST API 的主要差別&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Single Endpoint&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;和 REST API 對於不同 resource 需要不同 endpoint 不同，GraphQL 對於所有 resource 都是從同一個 endpoint 進行存取&lt;/li&gt;
&lt;li&gt;但 GraphQL 不能輕易地用 HTTP caching，因為現在只剩一種 URL 了&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;解決 Under-fetching 和 Over-fetching 問題&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Under-fetching&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一個 API call 沒辦法取得所有想要的資料，需要多次 API call&lt;/li&gt;
&lt;li&gt;假如要用 RESTful API 取得一個文章的作者，可能得先取得文章，再取得作者，這樣就需要兩次 API call
&lt;ul&gt;
&lt;li&gt;但 GraphQL 可以在一次 API call 中取得文章和作者，透過 nested query&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Over-fetching&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一個 API call 取得的資料比想要的還多，造成資源浪費&lt;/li&gt;
&lt;li&gt;GraphQL 可以透過 query 定義只想取得的欄位&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;使用&#34;&gt;使用&lt;/h2&gt;
&lt;p&gt;和 RESTful API 不同，需要特別架個 GraphQL server，可以考慮用 Apollo Server&lt;/p&gt;
&lt;p&gt;要定義不同 Data type 的 schema、relationship，以及寫對應不同 query 的 resolver&lt;/p&gt;
&lt;h3 id=&#34;query&#34;&gt;Query&lt;/h3&gt;
&lt;p&gt;可能會是長這樣的東西&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-graphql&#34; data-lang=&#34;graphql&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kd&#34;&gt;query&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;postQuery&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;ID&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;!)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;py&#34;&gt;post&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;py&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;py&#34;&gt;title&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;py&#34;&gt;content&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;py&#34;&gt;author&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;py&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;py&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h3 id=&#34;mutation&#34;&gt;Mutation&lt;/h3&gt;
&lt;p&gt;新增、修改、刪除資料都屬於這塊&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-graphql&#34; data-lang=&#34;graphql&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kd&#34;&gt;query&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;addPost&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$post&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;AddPostInput&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;!)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;py&#34;&gt;addPost&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;py&#34;&gt;post&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;$post&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;py&#34;&gt;title&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;py&#34;&gt;content&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;py&#34;&gt;author&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;py&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;py&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
        </item>
        <item>
        <title>DETR 論文閱讀</title>
        <link>https://roykesydon.github.io/Blog/p/detr-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</link>
        <pubDate>Thu, 10 Aug 2023 00:27:55 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/detr-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</guid>
        <description>&lt;p&gt;paper: &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2005.12872&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;End-to-End Object Detection with Transformers&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;作者把 object detection 視作一個 set prediction 問題。&lt;/p&gt;
&lt;p&gt;簡化了 pipeline，消除了許多 hand-designed components，比如 non-maximum suppression 和 anchor generation，這些 component 由我們對於任務的先驗知識構成。&lt;/p&gt;
&lt;p&gt;提出了一個新的目標函數，透過二分匹配（bipartite matching）進行預測，也用 Transformer encoder-decoder 架構。&lt;/p&gt;
&lt;p&gt;給予一組固定的 learned object query，DETR 可以推理 objects 和 globol image context 的關係，並「並行」輸出一組預測集。&lt;/p&gt;
&lt;p&gt;DETR 概念非常簡單。&lt;/p&gt;
&lt;p&gt;DETR 在 COCO 上和 Faster RCNN baseline 在準確度和 performance 上相當。&lt;/p&gt;
&lt;p&gt;DETR 可以很簡單地推廣到 Panoptic Segmentation。&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;目標檢測的目標就是集合預測。&lt;/p&gt;
&lt;p&gt;但目前都用一些很間接的方式去做，像是用 proposals, anchors 或 window centers。&lt;/p&gt;
&lt;p&gt;但是這些方法性能明顯受限於後處理步驟，比如 non-maximum suppression，因為他們會產生大量冗餘的框。&lt;/p&gt;
&lt;p&gt;為了簡化 pipeline，作者提出了一種 End-to-End 的方法，以往也有一些嘗試，但他們要不添加了其他的先驗知識，不然就是在具有挑戰性的 benchmark 上表現不好。&lt;/p&gt;
&lt;p&gt;在 COCO 上和 Faster R-CNN 的性能相當，表現和速度都差不多。&lt;/p&gt;
&lt;p&gt;DETR 在大物體表現很好，可能是歸功於 Transformer non-local 的計算能力。
雖然 DETR 在小物體上表現倒不怎麼樣。&lt;/p&gt;
&lt;p&gt;DETR 需要超長的訓練時間，但 DETR 的設計理念可以拓展到 Panoptic Segmentation。&lt;/p&gt;
&lt;h2 id=&#34;related-work&#34;&gt;Related Work&lt;/h2&gt;
&lt;h3 id=&#34;set-prediction&#34;&gt;Set Prediction&lt;/h3&gt;
&lt;p&gt;沒有規範的深度學習模型可以直接預測集合。&lt;/p&gt;
&lt;p&gt;這些任務中的一個困難點是避免 near-dulicates（相近的重複檢測框） 當前多數檢測器用 NMS 來解決此問題，如果是 direct set prediction 就不用後處理。&lt;/p&gt;
&lt;h3 id=&#34;transformers-and-parallel-decoding&#34;&gt;Transformers and Parallel Decoding&lt;/h3&gt;
&lt;p&gt;Transformer 在各種地方表現出色，但推理成本令人望而生畏。&lt;/p&gt;
&lt;h3 id=&#34;object-detection&#34;&gt;Object detection&lt;/h3&gt;
&lt;p&gt;現在多數的目標檢測方法是基於一些初始的猜測，再去做預測。&lt;/p&gt;
&lt;p&gt;比如對於 two-stage 的方法，就是對於 proposals 往下做預測。&lt;/p&gt;
&lt;p&gt;對於 single-stage，初始猜測就是 anchors。&lt;/p&gt;
&lt;h4 id=&#34;set-based-loss&#34;&gt;Set-based loss&lt;/h4&gt;
&lt;p&gt;以前的一些作法比如 Learnable NMS 或 relation networks 都可以透過 attention 來處理不同預測之間的關係。&lt;/p&gt;
&lt;p&gt;用 direct set losses，他們不需要任何後處理。&lt;/p&gt;
&lt;p&gt;但是這些方法往往用額外的 hand-crafted context feature，比如 proposal box coordinates。作者尋找減少模型中先驗知識的方案。&lt;/p&gt;
&lt;h4 id=&#34;recurrent-detectors&#34;&gt;Recurrent detectors&lt;/h4&gt;
&lt;p&gt;以往有類似的工作，但他們是用 RNN。&lt;/p&gt;
&lt;h2 id=&#34;the-detr-model&#34;&gt;The DETR model&lt;/h2&gt;
&lt;h4 id=&#34;object-detection-set-prediction-loss&#34;&gt;Object detection set prediction loss&lt;/h4&gt;
&lt;p&gt;DETE 會給 N 個固定大小的集合預測。&lt;/p&gt;
&lt;p&gt;要解二分圖匹配，本文用 scipy 的 linear_sum_assignment 處理，他背後是匈牙利演算法。&lt;/p&gt;
&lt;p&gt;其實這種方法和 proposals 和 anchors 有差不多的作用，差別在於這裡會找一對一的匹配，而不用重複。&lt;/p&gt;
&lt;p&gt;目標函數：&lt;/p&gt;
&lt;p&gt;$L_{Hungarian}(y, \text{\^{y}}) = \displaystyle\sum^{N}_{i=1} [-log \text{\^{p}} $
$_{\^{\sigma}(i)}(c_i) + \text{1}$
$_\{$
$_{c_i \neq \text{\o}}$
$_\}$
$\mathcal{L}$
$_{\text{box}} (b_i, \text{\^{b}}$
$_{\^{\sigma}}(i))]$&lt;/p&gt;
&lt;p&gt;前面是分類的 loss，後面是 bounding box 的 loss。&lt;/p&gt;
&lt;p&gt;這邊有兩個改動，第一個是分類那邊不用 log，使值和 bounding box 的 loss 比較接近。&lt;/p&gt;
&lt;p&gt;另一個是 bounding box 那邊並不是用最常見的 L1，因為 L1 對於大的目標 loss 比較高，這裡除了 L1 還選用 generalized IoU loss，它在尺度上與 loss 無關。&lt;/p&gt;
&lt;h4 id=&#34;detr-architecture&#34;&gt;DETR architecture&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/DETR/fig2.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;用 CNN 從圖片抽特徵，拉直，餵給 Transformer encoder-decoder，得到一組預測集合。&lt;/p&gt;
&lt;p&gt;這裡 encoder 有助於特徵間彼此交互。&lt;/p&gt;
&lt;p&gt;訓練的時候，預測的框和 GT 做匹配，沒匹配到的就放到 &amp;ldquo;no object&amp;rdquo; class。&lt;/p&gt;
&lt;p&gt;decoder 會餵入 object queries，這些是 learnable positional encodings。&lt;/p&gt;
&lt;h2 id=&#34;experiments&#34;&gt;Experiments&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/DETR/table1.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/DETR/table2.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;ablations&#34;&gt;Ablations&lt;/h3&gt;
&lt;h4 id=&#34;number-of-encoder-layers&#34;&gt;Number of encoder layers&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/DETR/fig3.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;作者透過改變 Encoder layer 的數量來評估 global imagelevel self-attention 的重要性。&lt;/p&gt;
&lt;p&gt;作者推論 encoder 可能對於判斷分開對象很重要，圖 3 可視化了最後一個 encoder layer 的 attention map。&lt;/p&gt;
&lt;p&gt;encoder 看似已經分離了 instance，可能簡化了 decoder 對於 object extraction 和 localization 的工作。&lt;/p&gt;
&lt;h4 id=&#34;number-of-decoder-layers&#34;&gt;Number of decoder layers&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/DETR/fig6.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;在圖 6 做了 decoder 的注意力可視化，可以注意到觀察的注意力相當局部。&lt;/p&gt;
&lt;p&gt;推論是 encoder 主要分離實體，decoder 只需要關注四肢即可提取出對象的邊界和分類。&lt;/p&gt;
&lt;h3 id=&#34;analysis&#34;&gt;Analysis&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/DETR/fig7.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;圖 7 把 100 個預測槽中的 20 個做可視化。&lt;/p&gt;
&lt;p&gt;每個預測框代表一點，可以注意到不同的槽位會專注在不同區域。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>BERT 論文閱讀</title>
        <link>https://roykesydon.github.io/Blog/p/bert-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</link>
        <pubDate>Sat, 05 Aug 2023 00:08:46 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/bert-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</guid>
        <description>&lt;p&gt;paper: &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/1810.04805&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;現在回頭寫 BERT 論文筆記感覺有點怪，之前已經寫過什麼 RoBERTa 之類的。&lt;/p&gt;
&lt;p&gt;不過現在因應實驗室讀書會要求，還是看一下論文也寫一下筆記。&lt;/p&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;本文提出了 BERT，一種基於 Transformer Bidirectional Encoder 的語言表示模型。&lt;/p&gt;
&lt;p&gt;BERT 旨在透過 unlabeled text 進行 pretrain。&lt;/p&gt;
&lt;p&gt;因此，只需要一個額外的輸出層就可以對預訓練的 BERT 進行微調，在各種任務上取得 SOTA。&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;「語言模型做預訓練」已被證明可以有效改善多種 NLP 任務。&lt;/p&gt;
&lt;p&gt;將預訓練模型應用在下游任務，有兩種策略：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Feature-based
&lt;ul&gt;
&lt;li&gt;把 pretrained 的 representations 作為額外的特徵&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Fine-tuning
&lt;ul&gt;
&lt;li&gt;根據特定任務引入額外參數，並簡單地微調所有參數&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;這兩種方法在預訓練期間共用同個 objective function，並用單向語言模型來學習 representation。&lt;/p&gt;
&lt;p&gt;作者認為當前的技術限制了預訓練的表示能力，特別是在 Fine-tuning 方法上。&lt;/p&gt;
&lt;p&gt;主要的問題在於語言模型是單向的，限制了預訓練期間可以使用的架構的選擇。這種單向的架構可能在一些任務有害，特別是對於那些需要兩個方向的 context 的任務。&lt;/p&gt;
&lt;p&gt;本文提出的 BERT 改善了現有的 Fine-tuning 方法，用 Transformer 的 Bidirectional Encoder 來訓練語言模型。&lt;/p&gt;
&lt;p&gt;BERT 透過受到 Cloze task（填空）啟發的 masked language model(MLM)，作為預訓練目標。MLM 隨機地遮蔽一些輸入的一些 token，目標是根據上下文來回推原詞，使 representation 可以融合左右兩邊的 context。&lt;/p&gt;
&lt;p&gt;除了 MLM，作者還利用 next sentence prediction（NSP）任務來訓練 BERT。&lt;/p&gt;
&lt;p&gt;本文貢獻如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;BERT 證明了雙向預訓練對 representation 的重要性。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;BERT 展現出預訓練的 representation 減少了許多針對 NLP 任務精心設計架構的需求。 BERT 是第一個基於 Fine-tuning，在大量 sentence-level 和 token-level 任務上取得 SOTA 的模型。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;BERT 推進了 11 個 NLP 任務的 SOTA。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;related-work&#34;&gt;Related Work&lt;/h2&gt;
&lt;h3 id=&#34;unsupervised-feature-based-approaches&#34;&gt;Unsupervised Feature-based Approaches&lt;/h3&gt;
&lt;p&gt;學習廣泛適用的 representation of words 一直是活躍的研究領域，甚至在非神經網路的領域也是。&lt;/p&gt;
&lt;p&gt;預訓練的 word embeddings 與從頭訓練的 embedding 相比，有顯著改進。&lt;/p&gt;
&lt;p&gt;這些方法頁被推廣到 coarser granularities，像是 sentence embedding 或是 paragraph embedding。&lt;/p&gt;
&lt;p&gt;有研究證明 cloze task 提高了生成模型的 robustness。&lt;/p&gt;
&lt;h2 id=&#34;bert&#34;&gt;BERT&lt;/h2&gt;
&lt;p&gt;框架有兩步驟：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Pre-training
&lt;ul&gt;
&lt;li&gt;在不同的預訓練任務中，用 unlabeled data 來 fine-tune。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Fine-tuning
&lt;ul&gt;
&lt;li&gt;使用預訓練的參數初始化，在利用下游任務的 labeled data 對所有參數微調。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;BERT 的一個特點是他具備跨不同任務的統一架構，預訓練架構和下游任務最終架構差異不大。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Model Architecture&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;本文表示方法&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;L: Transformer 的層數&lt;/li&gt;
&lt;li&gt;H: hidden size&lt;/li&gt;
&lt;li&gt;A: self-attention heads 的數量&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;model size&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;BASE: L=12, H=768, A=12, 110M parameters
&lt;ul&gt;
&lt;li&gt;和 GPT 相同&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;LARGE: L=24, H=1024, A=16, 340M parameters&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Input/Output Representations&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Input representation 可以在 token sequence 中明確表示單個 sentence 和一對 sentence。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;sentence 可以是連續文本的任意範圍，而不是實際的句子。&lt;/li&gt;
&lt;li&gt;sequence 是輸入的 token sequence，可以是單個 sentence 或是一對 sentence。&lt;/li&gt;
&lt;li&gt;每個 sequence 的第一個 token 始終是特殊的分類 token &amp;ndash; [CLS]&lt;/li&gt;
&lt;li&gt;對於兩個句子放在一個序列的情況，用 [SEP] 隔開&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Token Embeddings&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;作者使用 WordPiece embeddings，有 30000 個詞彙。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;learned embedding&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;對每個 token 添加這個東西，表示屬於 sentence A 還 sentence B&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;pre-training-bert&#34;&gt;Pre-training BERT&lt;/h3&gt;
&lt;h4 id=&#34;masked-lm&#34;&gt;Masked LM&lt;/h4&gt;
&lt;p&gt;直觀上，有理由相信深度的雙向模型會比單像串連起來的淺層模型更強大。&lt;/p&gt;
&lt;p&gt;不幸的是 standard condition language model 只能單向訓練，因為雙向會允許每個單詞「間接看到自己」。&lt;/p&gt;
&lt;p&gt;為了訓練 deep bidirectional representations，本文隨機遮蔽了一定比例的 tokens，並預測這些 token，這種方法稱為 masked language model，或常被稱為 cloze task。&lt;/p&gt;
&lt;p&gt;作者會用 [MASK] 做預訓練，但有個問題是 [MASK] 在 fine-tuning 期間不會出現，造成預訓練和微調之間的 mismatching，為了緩減這種情況，並不會總是用 [MASK] 替代 masked token。&lt;/p&gt;
&lt;p&gt;要替換 token 的時候，有 80% 的時間是 [MASK]，10% 是隨機 token，10% 是原本的 token。&lt;/p&gt;
&lt;h4 id=&#34;next-sentence-prediction-nsp&#34;&gt;Next Sentence Prediction (NSP)&lt;/h4&gt;
&lt;p&gt;許多重要下游任務，比如 Question Answering (QA) 和 Natural Language Inference (NLI) 是基於兩個句子間的關係。&lt;/p&gt;
&lt;p&gt;NSP 就是為了理解句子間的關係而用的。&lt;/p&gt;
&lt;p&gt;每次挑句子 A 和 B 的時候，有 50% 的機會 B 是 A 的下一個句子，有 50% 是隨機的。&lt;/p&gt;
&lt;p&gt;針對 NSP 的預訓練對 QA 和 NLI 都很有用。&lt;/p&gt;
&lt;h4 id=&#34;預訓練資料&#34;&gt;預訓練資料&lt;/h4&gt;
&lt;p&gt;用 BookCorpus 和 English Wikipedia 來訓練 BERT。&lt;/p&gt;
&lt;p&gt;對於 English Wikipedia，只提取 text passages，忽略 lists, tables, headers。&lt;/p&gt;
&lt;p&gt;為了提取長的連續序列，用 document-level 的 corpus 而不是打亂的 sentence-level corpus 非常重要。&lt;/p&gt;
&lt;h2 id=&#34;ablation-studies&#34;&gt;Ablation Studies&lt;/h2&gt;
&lt;h3 id=&#34;effect-of-pre-training-tasks&#34;&gt;Effect of Pre-training Tasks&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;No NSP
&lt;ul&gt;
&lt;li&gt;只有 MLM&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;LTR &amp;amp; No NSP
&lt;ul&gt;
&lt;li&gt;Left-to-Right&lt;/li&gt;
&lt;li&gt;只看左邊的 context&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;發現刪除 NSP 會顯著傷害對 QNLI 等資料集的性能。&lt;/p&gt;
&lt;p&gt;LTR 在所有任務上都比 MLM 差。&lt;/p&gt;
&lt;p&gt;雖然可以像 ELMo 單獨訓練 LTR 和 RTL，並且把他們結合起來&lt;/p&gt;
&lt;p&gt;但有以下缺點：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;比單向模型貴兩倍&lt;/li&gt;
&lt;li&gt;對 QA 任務不直觀，因為 RTL 無法根據問題給出答案&lt;/li&gt;
&lt;li&gt;不如深度雙向模型強大，因為其可以直接在每一層看到左右的 context&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;feature-based-approach-with-bert&#34;&gt;Feature-based Approach with BERT&lt;/h3&gt;
&lt;p&gt;作者也研究了用 feature-based 的效果，發現具備競爭力。&lt;/p&gt;
&lt;p&gt;在他的實驗中，用預訓練 Transformer 的 top 4 隱藏層的 token 串街效果最好。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>GNN 介紹</title>
        <link>https://roykesydon.github.io/Blog/p/gnn-%E4%BB%8B%E7%B4%B9/</link>
        <pubDate>Fri, 04 Aug 2023 00:27:55 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/gnn-%E4%BB%8B%E7%B4%B9/</guid>
        <description>&lt;h2 id=&#34;圖簡介&#34;&gt;圖簡介&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Graph&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;表示 Entity (nodes) 間的 relations (edges)&lt;/li&gt;
&lt;li&gt;組成
&lt;ul&gt;
&lt;li&gt;Vertex attributes (V)&lt;/li&gt;
&lt;li&gt;Edge attributes and directions (E)&lt;/li&gt;
&lt;li&gt;Global attributes (U)&lt;/li&gt;
&lt;li&gt;下文簡稱 U, V, E&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;可以表示成圖的範例&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Images
&lt;ul&gt;
&lt;li&gt;相鄰 pixel 建無向邊&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Text
&lt;ul&gt;
&lt;li&gt;詞和下一個詞建單向邊&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Molecules
&lt;ul&gt;
&lt;li&gt;分子的連接處建無向邊&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Social networks
&lt;ul&gt;
&lt;li&gt;人和人之間建無向邊&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;定義問題&#34;&gt;定義問題&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;種類
&lt;ul&gt;
&lt;li&gt;Graph-level&lt;/li&gt;
&lt;li&gt;Node-level&lt;/li&gt;
&lt;li&gt;Edge-level&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;個別講的是基於什麼東西做分類，比如對每個人（node）分類一個陣營，就算 Node-level&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;挑戰&#34;&gt;挑戰&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;儲存邊的關係
&lt;ul&gt;
&lt;li&gt;鄰接矩陣
&lt;ul&gt;
&lt;li&gt;在節點多的情況下佔用空間大，而且可能非常稀疏&lt;/li&gt;
&lt;li&gt;同一張圖，換個點的順序後鄰接矩陣看起來就會不同
&lt;ul&gt;
&lt;li&gt;難以保證這些東西餵入神經網路後輸出相同&lt;/li&gt;
&lt;li&gt;可以用兩個 list，一個儲存邊的向量，另一個是 Adjacency list，依序紀錄邊的關係&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;稀疏矩陣
&lt;ul&gt;
&lt;li&gt;難以用 GPU 運算&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;graph-neural-network&#34;&gt;Graph Neural Network&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;GNN 是對圖上所有屬性的 optimizable transformation，而且可以保持 graph symmetries (permutation invariances，把 node 排序後結果不變)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;下文用的 GNN 是 message passing neural network&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;graph-in, graph-out&lt;/li&gt;
&lt;li&gt;不改變圖的 connectivity&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;最簡單的-gnn&#34;&gt;最簡單的 GNN&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;U, V, E 個別餵給不同的 MLP，組成一個 GNN 的 layer
&lt;ul&gt;
&lt;li&gt;MLP 單獨餵入每一個點，不考慮連接訊息，保持了 graph symmetries&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;預測&#34;&gt;預測&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;假如要對每個頂點做預測，最後再加個全連接層分類&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;pooling&#34;&gt;pooling&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;假如要對一個沒有向量的頂點做預測，我們可以用 pooling，蒐集相鄰邊和全局向量的資訊&lt;/li&gt;
&lt;li&gt;對於沒有頂點資訊的圖，我們可以用 pooling layer 獲取全部點的資訊，再做分類&lt;/li&gt;
&lt;li&gt;對於沒有邊資訊的圖，我們也可以用 pooling 去從相鄰點和全局向量獲得資訊&lt;/li&gt;
&lt;li&gt;對於沒有全局向量的圖，我們可以用 pooling 去從全部的點或邊獲得資訊&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;缺陷&#34;&gt;缺陷&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;中間的 layer 沒有利用圖的訊息，都是各自進入各自的 MLP 做轉換&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;passing-messages&#34;&gt;Passing messages&lt;/h3&gt;
&lt;p&gt;在做轉換前，先做一些 pooling&lt;/p&gt;
&lt;h4 id=&#34;匯聚頂點資訊&#34;&gt;匯聚頂點資訊&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;不是單單把點向量進行轉換，而是和相鄰的點一起做 aggregation 後再做轉換
&lt;ul&gt;
&lt;li&gt;如果 aggregation 是加總，和卷積有一點像，只不過是權重一樣的版本&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;匯聚頂點和邊的資訊&#34;&gt;匯聚頂點和邊的資訊&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;可以先把頂點匯聚給邊，再把邊匯聚回頂點，反之亦然
&lt;ul&gt;
&lt;li&gt;順序不同會導致不同結果&lt;/li&gt;
&lt;li&gt;兩種方法可以一起同步做，交替更新&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;全局資訊&#34;&gt;全局資訊&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;每次 layer 只看鄰居，要傳遞到遠的點須要走很多層&lt;/li&gt;
&lt;li&gt;導入 master node (context vector)，他連接了所有的點和邊&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;相關主題&#34;&gt;相關主題&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;採樣&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;考量到計算梯度可能需要儲存過多的中間資訊，可以考慮採樣一些點，只在子圖上做計算&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Batch&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每個點鄰居各數不同，使做 batch 成為有挑戰性的問題。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Inductive Bias&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;graph symmetries&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Aggregation&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;目前沒有一個最佳選擇&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Graph Convolutional Network&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;node 是根據鄰居 node 去做某種 aggregate，事後再做更新&lt;/li&gt;
&lt;li&gt;由於每次都看鄰居，假如有 k 層，可以把圖看做解 n 個子圖，每個子圖就是基於每個點去走 k 步所形成的&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Graph Attention Network&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;用 attention 決定其它點的權重，而不像 GCN 一樣把鄰居加起來&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>I3D 論文</title>
        <link>https://roykesydon.github.io/Blog/p/i3d-%E8%AB%96%E6%96%87/</link>
        <pubDate>Sun, 23 Jul 2023 00:27:55 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/i3d-%E8%AB%96%E6%96%87/</guid>
        <description>&lt;p&gt;paper: &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/1705.07750&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;目前的動作分類資料集 (UCF-101 和 HMDB-51) 的影片非常缺乏，使辨識「良好的影像架構」變得困難，
使多數方法在現有的小規模 benchmark 的表現差不多。為此本文根據新的 Kinetics Human Action Video dataset 對 SOTA 架構進行了重新評估。&lt;/p&gt;
&lt;p&gt;Kinetics 有 400 個人類動作類別。每個類別有 400 個 clip。從 YouTube 上獲取的，而且每個 clip 來自 unique 的 youtube 影片。&lt;/p&gt;
&lt;p&gt;本文分析了當前架構在 Kinetics 上動作分類任務的表現，也評估 Kinetcis 用作預訓練的效果。&lt;/p&gt;
&lt;p&gt;本文提出了一種基於 2D ConvNet inflation 的 Two-Stream Inflated 3D ConvNet (I3D)。&lt;/p&gt;
&lt;p&gt;I3D 的擴展方法讓 ImageNet 上已經取得成功的架構可以被利用在解決影像任務上。&lt;/p&gt;
&lt;p&gt;結果表明，經過在 Kinetics 上預訓練後，I3D 在動作分類方面顯著提高了 SOTA，在 HMDB-51 上達到 80.9%，在 UCF-101 上達到 98.0%。&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;在 ImageNet 上預訓練模型的效果很好，但在影片領域，預訓練成效一直是一個未知的問題。因為流行的動作識別 benchmark 都非常小，約略只有 10k 個影片。&lt;/p&gt;
&lt;p&gt;Kinetics 有 400 個人類動作類別。每個類別有 400 個 clip，而且每個 clip 都來自一個 unique 的 Youtube 影片。&lt;/p&gt;
&lt;p&gt;本文實驗策略是在 Kinetics 上預訓練，再在 HMDB-51 和 USC-101 上微調，結果顯示出預訓練總是能提高性能，但提升多寡因架構而異。&lt;/p&gt;
&lt;p&gt;本文提出新架構，稱為「Two-Stream Inflated 3D ConvNets」(I3D)，建立在 SOTA 的影像分類架構上，並將 filters 和 pooling kernel 膨脹成 3D。&lt;/p&gt;
&lt;p&gt;基於 Inceptionv1 的 I3D 在 Knetics 上預訓練後，性能遠超過當前的 SOTA 架構。&lt;/p&gt;
&lt;p&gt;在本文的模型中，並沒有考慮更多經典方法，比如 bag-of-visual-words representation，但 Kinetics 是公開的，因此其他人可以進行後續研究。&lt;/p&gt;
&lt;h2 id=&#34;action-classification-architectures&#34;&gt;Action Classification Architectures&lt;/h2&gt;
&lt;p&gt;目前影片架構中的一些主要區別如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;卷積是 2D 還 3D 的&lt;/li&gt;
&lt;li&gt;是否只是 RGB 影片，還是包含事先計算的 optical flow&lt;/li&gt;
&lt;li&gt;對於 2D ConvNets，訊息是怎麼在 frame 之間傳遞的
&lt;ul&gt;
&lt;li&gt;這部分可以使用 temporally-recurrent layers，比如 LSTM，或是用隨時間的 feature aggregation 來完成。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在本文中，考慮了涵蓋大部分現有架構的模型子集：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;2D ConvNets
&lt;ul&gt;
&lt;li&gt;頂部有 LSTM 的 ConvNet&lt;/li&gt;
&lt;li&gt;有兩種 stream fusion 的 two-stream networks&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;3D ConvNets
&lt;ul&gt;
&lt;li&gt;C3D&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;由於參數維度較高，以及缺乏 labeled video data，以前的 3D ConvNet 相對較淺（最多 8 層）。&lt;/p&gt;
&lt;p&gt;本文發現諸如 VGG-16 和 ResNet 等很深的影像分類網路可以輕鬆擴展成 spatio-temporal feature extractors，並且他們的預訓練權重也可以提供有價值的初始化。&lt;/p&gt;
&lt;p&gt;本文也發現 two-stream 的作法依然有用。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/i3d/fig2.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;
fig2. K 是影片中的 frame 的總數，N 是相鄰 frames 的子集合。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/i3d/table1.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;上圖是本文實驗的五種架構，前四種是之前的做法，最後一種是提出的新作法。
上圖中除了 C3D 外都有用到 ImageNet 預訓練的模型。&lt;/p&gt;
&lt;p&gt;時間是根據 input 的 frame 換算出來的，fps 是 25，除了 LSTM 那個比較特別，因為 LSTM 那個是每 5 frame 取 1 frame，所以時間是 5 倍。&lt;/p&gt;
&lt;h3 id=&#34;之前的做法&#34;&gt;之前的做法&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;ConvNet+LSTM&lt;/p&gt;
&lt;p&gt;有一種做法是把每個 frame 獨立餵給 2D Conv，然後再把預測做彙整，符合 bag of words image modeling 的精神，但這樣會忽略時間結構上的資訊，比如無法判斷開門或關門。&lt;/p&gt;
&lt;p&gt;所以最好在後面加一個 recurrent layer，所以這邊就用 Inception-V1 結合 LSTM。&lt;/p&gt;
&lt;p&gt;原始的影片 stream 是 25 fps，這邊每 5 frame 採樣一次。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;3D ConvNets&lt;/p&gt;
&lt;p&gt;和一般的卷積神經網路差不多，只是具有 spatio-temporal filters。&lt;/p&gt;
&lt;p&gt;但由於額外的 kernel 維度，相比 2D Conv 會有更多參數，也使他們更難訓練。&lt;/p&gt;
&lt;p&gt;而且這樣會無法發揮 ImageNet 預訓練的好處，因此之前的工作都定義了相對淺層的架構，並且從頭訓練。&lt;/p&gt;
&lt;p&gt;benchmark 中的表現備受期待，但和 SOTA 比沒有競爭力，也因此成為本文實驗的良好候選者。&lt;/p&gt;
&lt;p&gt;本文用的是 C3D 的小變體，差異在於所有卷積層和 FC 層的後面都用了 BN。
而且在第一個 pooling layer 用的 stride 是 2，好減少記憶體的使用，比用更大的 batch，這在 BN 中非常重要。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Two-Stream Networks&lt;/p&gt;
&lt;p&gt;Roy：這裡由於比較複雜，我要改提 two-stream 的原始論文（&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/1406.2199&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Two-Stream Convolutional Networks for Action Recognition in Videos&lt;/a&gt;）說明這東西是什麼&lt;/p&gt;
&lt;p&gt;簡而言之就是分成兩個部分：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;空間資訊：&lt;/p&gt;
&lt;p&gt;用影片的一個 frame　經過卷積神經網路達成，這個 frame 用來提取影像中的物件資訊，比如打排球這動作可能辨識出排球就非常好判定，所以用某個 frame 來提取空間資訊。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;動作資訊：&lt;/p&gt;
&lt;p&gt;這邊用一連串的光流（optical flow）圖來達成，光流是物體（pixel）在兩個 frame 間的位移向量，估計方法有很多，這裡不一一舉例。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/i3d/ex-fig2.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;上圖出自 &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/1406.2199&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Two-Stream Convolutional Networks for Action Recognition in Videos&lt;/a&gt;，圖 c 就是光流，具有兩個方向，指出像素的位移，圖 d 是水平方向的視覺化，圖 e 是垂直方向的視覺化。&lt;/p&gt;
&lt;p&gt;再把這些光流圖餵給卷積神經網路，用作動作資訊的判別。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;值得一提的是他是 late fusion，而且是用加權平均，不是像一般想的把特徵結合再做其他處理。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;the-new-two-stream-inflated-3d-convnets&#34;&gt;The New: Two-Stream Inflated 3D ConvNets&lt;/h3&gt;
&lt;p&gt;作者把成功的 2D 分類模型簡單地轉換為 3D&lt;/p&gt;
&lt;h4 id=&#34;inflating&#34;&gt;Inflating&lt;/h4&gt;
&lt;p&gt;做法是把方形的 filter 改成立方體，把 N x N 的 filter 改成 N x N x N 的 filter，但這只有架構上的參考。&lt;/p&gt;
&lt;h4 id=&#34;bootstraping&#34;&gt;Bootstraping&lt;/h4&gt;
&lt;p&gt;把權重也給轉換到 3D 架構的方法。&lt;/p&gt;
&lt;p&gt;作者觀察到影像可以透過反覆複製貼上來生出一個「不會動的無聊影片」，
透過這些影片，3D 模型可以透過這種方式在 ImageNet 上 implicitly pretrain，做法就是讓 3D filter 吃無聊影片的輸出和 2D filter 吃單一 frame 的輸出相同，做法如下：&lt;/p&gt;
&lt;p&gt;我們可以沿時間維度重複 2D filter N 次，把這權重給 3D filter，同時把權重除以 N，達到這種效果。&lt;/p&gt;
&lt;h4 id=&#34;pacing-receptive-field-growth-in-space-time-and-network-depth&#34;&gt;Pacing receptive field growth in space, time and network depth&lt;/h4&gt;
&lt;p&gt;以往在圖片上對水平和垂直軸的對待是平等的，pooling kernel 和 stride 都一樣。
使感受野在兩個維度上隨著模型越來越深，慢慢平等增長。&lt;/p&gt;
&lt;p&gt;但是時間軸用對稱的感受野不一定最好，而該取決於 frame rate 和 image dimensinos。
如果時間相對於空間增長太快，可能會混淆不同對象的邊緣，影響早期的特徵檢測。如果增長太慢，可能無法很好地捕捉場景動態。&lt;/p&gt;
&lt;p&gt;實驗中，輸入影片的 fps 是 25。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/i3d/fig3.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;作者發現在前兩個 max pooling layer 不在時間軸 pooling（透過用 1 x 3 x 3 的 kernel，並且時間軸的 stride 是 1），並在其他 max pooling layer 都用 symmetric kernels 和 stride 是有幫助的。&lt;/p&gt;
&lt;p&gt;最後的 average pooling layer 是用 2 x 7 x 7 的 kernel。&lt;/p&gt;
&lt;p&gt;作者用 64 frame 訓練，但用整個影片測試。（averaging predictions temporally）&lt;/p&gt;
&lt;p&gt;我想了一下，250 / 64 除不進，但是我看 code 發現他好像寬高 224 * 224 的照片會在最後經過 Average pool 後變成 1 * 1，所以他可以直接用 1 * 1 * 1 的卷積核把輸入通道改成分類數，再把時間軸的結果平均。&lt;/p&gt;
&lt;h4 id=&#34;two-3d-streams&#34;&gt;Two 3D Streams&lt;/h4&gt;
&lt;p&gt;分別訓練兩個網路，並在測試階段對預測進行平均。&lt;/p&gt;
&lt;p&gt;這邊作者說光流的演算法某種意義上是 recurrent（例如，對於 flow fields 進行 iterative optimization），我不太懂這邊是什麼意思，我想作者用的光流演算法應該是透過某種類似 EM 演算法那種不斷迭代去逼近數值的演算法，但作者提到「或許是因為缺乏 recurrence，我們發現雙流有價值」，我不太懂為什麼需要 recurrence 效果才會好。&lt;/p&gt;
&lt;p&gt;但結論是 two-stream 依然具備價值。&lt;/p&gt;
&lt;h4 id=&#34;implementation-details&#34;&gt;Implementation Details&lt;/h4&gt;
&lt;p&gt;這邊講滿詳細的，有興趣可以去原文看。
只提一下幾點:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;光流演算法是用 TV-L1。&lt;/li&gt;
&lt;li&gt;除了類似 C3D 的 3D ConvNet 都用使用 ImageNet 預訓練的 Inception-V1 作為 base network。&lt;/li&gt;
&lt;li&gt;對於較短的影片，會重複循環以滿足模型的輸入介面&lt;/li&gt;
&lt;li&gt;測試時會在中間剪裁 224 x 224&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;the-kinetics-human-action-video-dataset&#34;&gt;The Kinetics Human Action Video Dataset&lt;/h2&gt;
&lt;p&gt;Kinetics 有 400 個人類動作類別。每個類別有 400 個 clip，而且每個 clip 都來自一個 unique 的 Youtube 影片，共有 24 萬個訓練影片。&lt;/p&gt;
&lt;p&gt;每個 clip 都大約 10 秒，而且沒有未剪的影片。&lt;/p&gt;
&lt;p&gt;測試集每個 class 包含 100 個 clip。&lt;/p&gt;
&lt;h2 id=&#34;experimental-comparison-of-architectures&#34;&gt;Experimental Comparison of Architectures&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/i3d/table2and3.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;I3D 在所有資料集上都表現最好，甚至是在 UCF-101 和 HMDB-51 這種小資料集上也是如此，這意味著 ImageNet 預訓練的好處有成功擴展到 3D ConvNet。&lt;/p&gt;
&lt;p&gt;多數模型在 UCF 上都表現得比 Kinetics 上好，顯現出資料集的難度差距。&lt;/p&gt;
&lt;p&gt;但是在 HMDB 表現得較差，原因可能是 HMDB 故意弄得很難，作者有舉例，很多 clip 在完全相同的場景會有不同的動作。&lt;/p&gt;
&lt;p&gt;作者有提到說 I3D 特徵比較好遷移的一種解釋是它具備 high temporal resolution，
I3D 在 25 fps 的影片中用 64 frames 做訓練，使它能捕捉動作的 fine-grained 時間結構。&lt;/p&gt;
&lt;h2 id=&#34;experimental-evaluation-of-features&#34;&gt;Experimental Evaluation of Features&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/i3d/table4and5.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;Kinetics 上做預訓練效果明顯比 ImageNet 好。&lt;/p&gt;
&lt;h2 id=&#34;discussion&#34;&gt;Discussion&lt;/h2&gt;
&lt;p&gt;Kinetics 上的預訓練對於遷移學習有明顯好處，但對於其他影像任務，比如影像語義分割是否有好處仍待觀察。&lt;/p&gt;
&lt;p&gt;目前對於架構沒有全面探索，比如沒有採用 action tubes 或是 attention 機制。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Redis</title>
        <link>https://roykesydon.github.io/Blog/p/redis/</link>
        <pubDate>Mon, 05 Jun 2023 00:00:17 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/redis/</guid>
        <description>&lt;h2 id=&#34;use-cases&#34;&gt;Use Cases&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Cache
&lt;ul&gt;
&lt;li&gt;把常用的資料回傳，省略長時間的 IO 操作&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Shared Session
&lt;ul&gt;
&lt;li&gt;在 stateless server 間共享 session&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Distributed lock
&lt;ul&gt;
&lt;li&gt;用在程式間想共用某種資源的時候&lt;/li&gt;
&lt;li&gt;用 &lt;code&gt;setnx&lt;/code&gt; (set if not exists)
&lt;ul&gt;
&lt;li&gt;atomic&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Rate Limiter
&lt;ul&gt;
&lt;li&gt;用 increment 和 expiration 實現&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;快取常見策略&#34;&gt;快取常見策略&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;cache aside
&lt;ul&gt;
&lt;li&gt;先問 cache，沒有的話再問 db，並把 db 回傳的資料放到 cache&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;read through
&lt;ul&gt;
&lt;li&gt;client 只能存取到 cache，如果沒資料，cache 會去 db 拿資料&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;write through
&lt;ul&gt;
&lt;li&gt;client 寫資料時，cache 會留一份資料，並把資料寫到 db&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;write behind
&lt;ul&gt;
&lt;li&gt;和 write through 很像，但是不會立即寫到 db，會等到有更多的資料時，才一次寫到 db&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;feature&#34;&gt;Feature&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;NoSQL&lt;/li&gt;
&lt;li&gt;In-memory&lt;/li&gt;
&lt;li&gt;Key-Value&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;basic-command&#34;&gt;Basic Command&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;redis-server&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;default port: 6379&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;redis-cli&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;access-data&#34;&gt;Access data&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;set &amp;lt;key&amp;gt; &amp;lt;value&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Pretty much everything stored in Redis is going to be a type of string by default&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;get &amp;lt;key&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;del &amp;lt;key&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;exists &amp;lt;key&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;keys &amp;lt;pattern&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;find keys with certain pattern&lt;/li&gt;
&lt;li&gt;&lt;code&gt;keys *&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;get all keys&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;flushall&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;get rid of everything&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;expiration&#34;&gt;Expiration&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;ttl &amp;lt;key&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;show time to live
&lt;ul&gt;
&lt;li&gt;&amp;ldquo;-1&amp;rdquo; for no expiration&lt;/li&gt;
&lt;li&gt;&amp;ldquo;-2&amp;rdquo; already expired&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;expire &amp;lt;key&amp;gt; &amp;lt;second&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;setex &amp;lt;key&amp;gt; &amp;lt;seconds&amp;gt; &amp;lt;value&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;set with expiration&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;data-structure&#34;&gt;Data Structure&lt;/h3&gt;
&lt;h4 id=&#34;list&#34;&gt;List&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;lpush/rpush &amp;lt;key&amp;gt; &amp;lt;value&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;lrange &amp;lt;key&amp;gt; &amp;lt;start index&amp;gt; &amp;lt;end index&amp;gt;&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;end index&amp;gt;&lt;/code&gt; can be -1&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;lpop/rpop &amp;lt;key&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;set&#34;&gt;Set&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;sadd &amp;lt;key&amp;gt; &amp;lt;value&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;smembers &amp;lt;key&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;srem &amp;lt;key&amp;gt; &amp;lt;value&amp;gt;&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;remove&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;hash&#34;&gt;Hash&lt;/h4&gt;
&lt;p&gt;Key-value in Key-value&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;hset &amp;lt;key&amp;gt; &amp;lt;field&amp;gt; &amp;lt;value&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;hget &amp;lt;key&amp;gt; &amp;lt;field&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;hgetall &amp;lt;key&amp;gt;&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;get everything about &lt;code&gt;&amp;lt;key&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;hdel&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;hexists &amp;lt;key&amp;gt; &amp;lt;field&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Redis doesn&amp;rsquo;t support nested hash struct&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;刪除過期-key&#34;&gt;刪除過期 key&lt;/h2&gt;
&lt;h3 id=&#34;定期刪除&#34;&gt;定期刪除&lt;/h3&gt;
&lt;p&gt;在固定間隔時間隨機抽 key 檢查並刪除&lt;/p&gt;
&lt;h3 id=&#34;惰性刪除&#34;&gt;惰性刪除&lt;/h3&gt;
&lt;p&gt;在訪問 key 的時候發現過期就刪除&lt;/p&gt;
&lt;h2 id=&#34;maxmemory-policy-eviction&#34;&gt;maxmemory-policy (Eviction)&lt;/h2&gt;
&lt;p&gt;可以設定這些 policy，在記憶體依然額滿的情況下做對應的處理&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;noeviction&lt;/li&gt;
&lt;li&gt;allkeys-lru&lt;/li&gt;
&lt;li&gt;allkeys-lfu&lt;/li&gt;
&lt;li&gt;volatile-lru&lt;/li&gt;
&lt;li&gt;volatile-lfu&lt;/li&gt;
&lt;li&gt;allkeys-random&lt;/li&gt;
&lt;li&gt;volatile-random&lt;/li&gt;
&lt;li&gt;volatile-ttl&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;快取情境問題&#34;&gt;快取情境問題&lt;/h2&gt;
&lt;h3 id=&#34;快取雪崩-cache-avalanche&#34;&gt;快取雪崩 Cache Avalanche&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;某個時刻大量 cache 失效，使資料庫需要承擔很大的流量。&lt;/li&gt;
&lt;li&gt;解法
&lt;ul&gt;
&lt;li&gt;幫 cache 加上額外的隨機過期時間&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;快取擊穿-hotspot-invalid&#34;&gt;快取擊穿 Hotspot Invalid&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;某個 hotspot 的 cache 失效，使大量請求跑到資料庫&lt;/li&gt;
&lt;li&gt;解法
&lt;ul&gt;
&lt;li&gt;讓 hotspot 永不過期&lt;/li&gt;
&lt;li&gt;查詢資料庫的部分加上 lock&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;快取穿透-cache-penetration&#34;&gt;快取穿透 Cache Penetration&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;client request 不存在的資料，因為同時不存在於 cache 和資料庫中，所以直接跑到資料庫&lt;/li&gt;
&lt;li&gt;解法
&lt;ul&gt;
&lt;li&gt;在 application 先過濾掉非法請求&lt;/li&gt;
&lt;li&gt;Bloom Filter 布隆過濾器&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;persistence&#34;&gt;Persistence&lt;/h2&gt;
&lt;h3 id=&#34;rdb&#34;&gt;RDB&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;固定時間對所有資料做快照，memory dump 出來&lt;/li&gt;
&lt;li&gt;recovery 比 AOF 快&lt;/li&gt;
&lt;li&gt;&lt;code&gt;save&lt;/code&gt;、&lt;code&gt;bgsave&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;aof&#34;&gt;AOF&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;紀錄操作流程&lt;/li&gt;
&lt;li&gt;檔案比較肥&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;rewrite&#34;&gt;Rewrite&lt;/h4&gt;
&lt;p&gt;當 AOF 太大，Redis 會生一個新文件取代舊的，用最少操作生出目前的資料&lt;/p&gt;
&lt;h3 id=&#34;混合&#34;&gt;混合&lt;/h3&gt;
&lt;p&gt;在 AOF 重寫的時候也利用 RDB
前面是 RDB，後面是 AOF&lt;/p&gt;
&lt;h2 id=&#34;availability&#34;&gt;Availability&lt;/h2&gt;
&lt;h3 id=&#34;主從同步&#34;&gt;主從同步&lt;/h3&gt;
&lt;p&gt;一主多從，把讀取壓力分擔到 slave 上&lt;/p&gt;
&lt;h3 id=&#34;哨兵模式-sentinel&#34;&gt;哨兵模式 Sentinel&lt;/h3&gt;
&lt;p&gt;會有哨兵不斷地 Ping 主從伺服器，確認是否有異常&lt;/p&gt;
&lt;p&gt;如果哨兵是集群，有哨兵檢測到異常，會判斷某伺服器主觀下線，當有一定數量的哨兵投票認為伺服器不可能用，就會變成客觀下線，進行 failover&lt;/p&gt;
&lt;h3 id=&#34;cluster&#34;&gt;Cluster&lt;/h3&gt;
&lt;p&gt;分擔寫入壓力&lt;/p&gt;
&lt;p&gt;Redis 有 16384 個 slot，透過 hash 分配 key 到不同的 slot&lt;/p&gt;
&lt;p&gt;預設會另外用 port 16379 來讓節點間溝通&lt;/p&gt;
&lt;p&gt;可以混和主從同步達到高可用&lt;/p&gt;
</description>
        </item>
        <item>
        <title>領域驅動設計 Domain-Driven Design</title>
        <link>https://roykesydon.github.io/Blog/p/%E9%A0%98%E5%9F%9F%E9%A9%85%E5%8B%95%E8%A8%AD%E8%A8%88-domain-driven-design/</link>
        <pubDate>Mon, 22 May 2023 00:00:17 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/%E9%A0%98%E5%9F%9F%E9%A9%85%E5%8B%95%E8%A8%AD%E8%A8%88-domain-driven-design/</guid>
        <description>&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;軟體要對 domain 做 Modeling，呈現出 domain 裡的核心概念，才能滿足使用者需求，因此不乏與領域專家的討論&lt;/p&gt;
&lt;p&gt;寫這篇的時候我還沒嗑完 Eric 的聖經，可能嗑完了之後會回來修改&lt;/p&gt;
&lt;h2 id=&#34;通用語言-ubiquitous-language&#34;&gt;通用語言 Ubiquitous Language&lt;/h2&gt;
&lt;p&gt;鑒於程式開發人員與領域專家熟悉知識的差異，會產生交流困難&lt;/p&gt;
&lt;p&gt;因此領域專家和開發團隊要訂定共同的語言，並且盡可能少用自己知道的術語&lt;/p&gt;
&lt;h2 id=&#34;uml&#34;&gt;UML&lt;/h2&gt;
&lt;p&gt;UML 適合用在小型模型上，它擅長表達類別間的關係，但對於抽象概念卻沒那麼好傳達&lt;/p&gt;
&lt;p&gt;因此用 UML 建構模型時，理想上要添加額外的文字，傳達一些圖所不能表達的 behavior 和 constraint&lt;/p&gt;
&lt;p&gt;並且不能一次寫過於複雜，而是分塊處理&lt;/p&gt;
&lt;h2 id=&#34;layered-architecture&#34;&gt;Layered Architecture&lt;/h2&gt;
&lt;p&gt;分為四個概念層，只會往下調用，可能會跨層&lt;/p&gt;
&lt;p&gt;可以達到關注點分離 (separation of concerns)，提高各個方面的 cohesive&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;User Interface (Presentation Layer)
&lt;ul&gt;
&lt;li&gt;呈現給 user 的 UI，User 可能是另一個系統&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Application Layer
&lt;ul&gt;
&lt;li&gt;不含 bussiness logic，指揮表達領域概念的物件來完成任務&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Domain Layer
&lt;ul&gt;
&lt;li&gt;有關 domain 的資訊都在這裡，業務邏輯在此處理&lt;/li&gt;
&lt;li&gt;表達業務概念、狀態、規則&lt;/li&gt;
&lt;li&gt;劃分出這層是 Model-Driven Design 的關鍵&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Infrastructure layer
&lt;ul&gt;
&lt;li&gt;supporting library&lt;/li&gt;
&lt;li&gt;保存業務狀態的技術細節在此實作&lt;/li&gt;
&lt;li&gt;為前三個 layer 服務&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;entity&#34;&gt;Entity&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;具備 identity&lt;/li&gt;
&lt;li&gt;identity 在 status 經過改變後依然不變&lt;/li&gt;
&lt;li&gt;追蹤 entity 需要高成本&lt;/li&gt;
&lt;li&gt;mutable&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;value-object&#34;&gt;Value Object&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;沒有 identity&lt;/li&gt;
&lt;li&gt;只關心 obejct 的 value&lt;/li&gt;
&lt;li&gt;可以輕易創建丟棄&lt;/li&gt;
&lt;li&gt;immutable (不變的)
&lt;ul&gt;
&lt;li&gt;如果想修改數值就創新的&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;可被共用&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;service&#34;&gt;Service&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;有些動作不屬於某個 Entity 或 Value Object，因為它是跨物件的&lt;/li&gt;
&lt;li&gt;Stateless
&lt;ul&gt;
&lt;li&gt;每個請求不互相影響&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;aggregate&#34;&gt;Aggregate&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;把複雜關聯的物件圈在一起考量&lt;/li&gt;
&lt;li&gt;確保 consistency 和 inveraints
&lt;ul&gt;
&lt;li&gt;consistency (一致性)
&lt;ul&gt;
&lt;li&gt;相關物件的資料一致&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;invariants (不變量)
&lt;ul&gt;
&lt;li&gt;資料改變時要維護的規則&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;aggregate-root&#34;&gt;Aggregate root&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;具備 global identity，其他內部 entity 只有 local identity&lt;/li&gt;
&lt;li&gt;通常是 entity 擔任&lt;/li&gt;
&lt;li&gt;外部只能存取它，不能存取 aggregate 的其他 entity 或 value obejct&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;factory&#34;&gt;Factory&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;若創建 aggregate、entity、value object 的過程很複雜，或是涉及專業知識，就該用 factory 包起來&lt;/li&gt;
&lt;li&gt;對於不複雜的情況，或是想控制更多細節，可以只依賴於簡單的建構函式&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;repository&#34;&gt;Repository&lt;/h2&gt;
&lt;p&gt;如果大家都直接存取資料庫的各種物件，會破壞原本精心設計的結構，破壞封裝性&lt;/p&gt;
&lt;p&gt;Repositoy 用來存取物件，封裝了資料庫操作&lt;/p&gt;
&lt;h2 id=&#34;domain-event&#34;&gt;Domain event&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Domain 中重要的事情&lt;/li&gt;
&lt;li&gt;可以用在其他物件和 aggrgate 訂閱，讓 aggregate 通知他們 domain event 的發生&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;anti-pattern&#34;&gt;Anti-Pattern&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;應該避免的情形&lt;/li&gt;
&lt;li&gt;Smart UI
&lt;ul&gt;
&lt;li&gt;超肥的萬能 UI&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Anemic Domain Model
&lt;ul&gt;
&lt;li&gt;貧血模型&lt;/li&gt;
&lt;li&gt;只有 getter 和 setter，沒有業務邏輯的模型&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;subdomain&#34;&gt;Subdomain&lt;/h2&gt;
&lt;p&gt;把 domain 切分成小塊，理想上 subdomain 和 bounded context 有 one-to-one 的關係&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Types
&lt;ul&gt;
&lt;li&gt;core subdomain
&lt;ul&gt;
&lt;li&gt;和其他競爭者相比不同的部分，最核心的業務，比如搜尋引擎中的搜尋演算法&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;generic subdomain
&lt;ul&gt;
&lt;li&gt;大家都會弄的部分，比如登入系統&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;supporting subdomain
&lt;ul&gt;
&lt;li&gt;用來輔助 core subdomain 的部分，比如篩選網頁&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;bounded-context&#34;&gt;Bounded Context&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;劃出 boundary，確保 boundary 內用的概念、規則皆一致&lt;/li&gt;
&lt;li&gt;同個名詞可能出現在不同的 context，但有不同意思&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;context-map&#34;&gt;Context Map&lt;/h2&gt;
&lt;p&gt;描述 BC 和 BC 間的關係&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;上下游 (U/D)
&lt;ul&gt;
&lt;li&gt;上游提供下游 (下游依賴上游)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Shared Kernel
&lt;ul&gt;
&lt;li&gt;兩個 BC 共用的部份&lt;/li&gt;
&lt;li&gt;違反 BC 的基本原則，是一種例外設計&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Customer-Supplier
&lt;ul&gt;
&lt;li&gt;一個子系統重度依賴另一個子系統&lt;/li&gt;
&lt;li&gt;Conformist
&lt;ul&gt;
&lt;li&gt;Customer 完全配合 Supplier&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Partnership
&lt;ul&gt;
&lt;li&gt;兩個 BC 互相合作，沒有以誰為主&lt;/li&gt;
&lt;li&gt;一起成功或一起失敗&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Anticorruption Layer (ACL)
&lt;ul&gt;
&lt;li&gt;開發系統和外部系統的中間層&lt;/li&gt;
&lt;li&gt;可能出現在調用 legacy system&lt;/li&gt;
&lt;li&gt;常用到 Facade 和 Adapter&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Open Host Service (OHS)
&lt;ul&gt;
&lt;li&gt;如果外部子系統要給一堆用戶端子系統調用，就得在所有用戶端子系統搞 ACL&lt;/li&gt;
&lt;li&gt;外部系統做為服務提供，常會搭配 Published Language (PL)
&lt;ul&gt;
&lt;li&gt;PL 是協定傳送資料的格式，比如 XML、JSON 或是 Protocol Buffer&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;pratical-ddd&#34;&gt;Pratical DDD&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The strangler migration
&lt;ul&gt;
&lt;li&gt;透過 Facade，把一些服務慢慢移植給新系統，最後取代 legacy&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>STM32 Timer / Counter 介紹</title>
        <link>https://roykesydon.github.io/Blog/p/stm32-timer-/-counter-%E4%BB%8B%E7%B4%B9/</link>
        <pubDate>Thu, 04 May 2023 01:32:54 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/stm32-timer-/-counter-%E4%BB%8B%E7%B4%B9/</guid>
        <description>&lt;h2 id=&#34;簡介&#34;&gt;簡介&lt;/h2&gt;
&lt;p&gt;Timer 和 Counter 的差別是 Timer 是定期的數數&lt;/p&gt;
&lt;h2 id=&#34;timing-functions&#34;&gt;Timing functions&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;定期對 CPU 發送 interrupt&lt;/li&gt;
&lt;li&gt;產生準確時間的 delay&lt;/li&gt;
&lt;li&gt;產生 pulses 或 periodic waveforms
&lt;ul&gt;
&lt;li&gt;PWM&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;量測 duration&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;stm32-timer--counter&#34;&gt;STM32 Timer / Counter&lt;/h2&gt;
&lt;p&gt;從 Basic 到 Advanced，追加更多功能&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Basic TImer (Simple Timer)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;16 bit auto-reload register&lt;/li&gt;
&lt;li&gt;programmable pre-scaler&lt;/li&gt;
&lt;li&gt;可以 output 到 DAC&lt;/li&gt;
&lt;li&gt;update event
&lt;ul&gt;
&lt;li&gt;CNT=ARR(up-count)&lt;/li&gt;
&lt;li&gt;CNT=0 (down-count)&lt;/li&gt;
&lt;li&gt;reset CNT to 0 or ARR&lt;/li&gt;
&lt;li&gt;set UIF flag in status register&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;update event interrupt
&lt;ul&gt;
&lt;li&gt;如果 enabled (UIE=1)&lt;/li&gt;
&lt;li&gt;UIF 被設置的時候發送訊號&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/embedding/stm32-timer/rm-fig-367.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;
&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/embedding/stm32-timer/rm-fig-370.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$T_{EVENT}=Prescale \times Count \times T_{CK \_ INT} \\
=(PSC+1)\times(ARR+1)\times T_{CK \_ INT}$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$T_{EVENT}$ 是兩次事件發生的間隔時間&lt;/li&gt;
&lt;li&gt;PSC 是設定 (數值 - 1)，所以 Prescale 是 1 的話，要設 0&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Control register&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CEN
&lt;ul&gt;
&lt;li&gt;是否啟用 counter&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;UDIS
&lt;ul&gt;
&lt;li&gt;是否啟用 update event&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;URS
&lt;ul&gt;
&lt;li&gt;設定產生 update event 的 source&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;OPM
&lt;ul&gt;
&lt;li&gt;是否只算一次 counter 就停&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;ARPE
&lt;ul&gt;
&lt;li&gt;關於中途改 ARR 的 reload 設定&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;UIF
&lt;ul&gt;
&lt;li&gt;interrupt&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;General Purpose Timer&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/embedding/stm32-timer/rm-fig-284.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;16-bit or 32-bit auto-reload register&lt;/li&gt;
&lt;li&gt;use for a variety of puposes
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;measuring lengths of input signals (Input Capture)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Input Capture
&lt;ul&gt;
&lt;li&gt;測量 pulse width (高電位的時間) 或 period (一個週長)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;generating output waveforms (Output Compare and PWM Generation)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;one pulse mode output&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Up to 4 independent channel&lt;/li&gt;
&lt;li&gt;Interrupt / DMA generation
&lt;ul&gt;
&lt;li&gt;event
&lt;ul&gt;
&lt;li&gt;counter overflow / underflow&lt;/li&gt;
&lt;li&gt;counter initialization&lt;/li&gt;
&lt;li&gt;trigger event&lt;/li&gt;
&lt;li&gt;input capture&lt;/li&gt;
&lt;li&gt;output compare&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Advanced Control Timer&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;16-bit auto-reload register&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;特殊 timer&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;low power timer
&lt;ul&gt;
&lt;li&gt;可以用在比如睡眠狀態&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;補充&#34;&gt;補充&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;24 bits system timer (SysTick)&lt;/li&gt;
&lt;li&gt;reload
&lt;ul&gt;
&lt;li&gt;在 overflow 時回到 register 設定的數值&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;stm32-timer-差異&#34;&gt;STM32 Timer 差異&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;可以去 Datasheet 找每個 Timer 的功能&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Counter resolution&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;16/32 bit&lt;/li&gt;
&lt;li&gt;決定能從 0 數到多少個&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Counter Type&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;決定能往上數或往下數或都可以&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Prescaler factor&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;可以把進來的數字先除以某個數，減緩速度&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;DMA request generation&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;能否用 DMA access 記憶體&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Capture / Compare channels&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一個 Timer 可能可以發多個訊號出去，並且經過多個 Compare register，比對不同 event&lt;/li&gt;
&lt;li&gt;functions
&lt;ul&gt;
&lt;li&gt;Compare
&lt;ul&gt;
&lt;li&gt;和比對 register，比到了就送 event&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Capture
&lt;ul&gt;
&lt;li&gt;紀錄下 channel 的值&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Complementary output&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;有些馬達控制需要反向波，就要這個&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Max interface clock (MHz) and Max timer clock (MHz)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;進去和出來的速度&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;system-clock---clock-tree&#34;&gt;System Clock - Clock tree&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Timer 源頭就是 clock&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;有四種來源幫忙驅動 system clock (SYSCLK)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;HSI16 (high speed internal)
&lt;ul&gt;
&lt;li&gt;16 MHz RC oscillator clock&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;MSI (multispeed internal)
&lt;ul&gt;
&lt;li&gt;RC oscillator clock&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;HSE (high speed external)
&lt;ul&gt;
&lt;li&gt;oscillator clock, from 4 to 48 MHz&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;PLL clock&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SYSCLK 往下接到 AHB，再接到 APB1、APB2&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;flash-read-access-latency&#34;&gt;Flash Read Access Latency&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;調整 clock 也要調整這部分&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;register&#34;&gt;Register&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;TIMx_CR1
&lt;ul&gt;
&lt;li&gt;control register&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;TIMx_PSC
&lt;ul&gt;
&lt;li&gt;設定 prescale&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;TIMx_ARR
&lt;ul&gt;
&lt;li&gt;auto-reload register&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Self-Instruct 論文閱讀</title>
        <link>https://roykesydon.github.io/Blog/p/self-instruct-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</link>
        <pubDate>Sun, 30 Apr 2023 00:00:12 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/self-instruct-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</guid>
        <description>&lt;p&gt;paper: &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2212.10560&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Self-Instruct: Aligning Language Model with Self Generated Instructions&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;大型 &amp;ldquo;instruction-tuned&amp;rdquo; 語言模型 (經過微調好回應 instruction) 已經展現出在新任務上 zero-shot 的能力。&lt;/p&gt;
&lt;p&gt;然而他們嚴重依賴人工編寫的指令，在數量、多樣性和創造力上都受到了限制，阻礙了模型的通用性。&lt;/p&gt;
&lt;p&gt;作者介紹了 Self-Instruct 這個框架，可以透過自己生成的指令，來增強預訓練模型遵循指令的能力。&lt;/p&gt;
&lt;p&gt;將作者的方法應用在 GPT3，在 SuperNaturalInstructions 獲得了比原始模型高 33% 的改進，與使用 private user data 和 human annotations 的 $InstructGPT_{001}$ 性能相當。&lt;/p&gt;
&lt;p&gt;為了進一步評估，我們為新任務整理一組專家編寫的指令，並通過人工評估，顯示出使用 Self-Instruction 調整 GPT3 的性能大大優於使用現有公共指令資料集，只比 $InstructGPT_{001}$ 落後 5% 的差距。&lt;/p&gt;
&lt;p&gt;Self-Instruct 提供一個幾乎 annotation-free 的方法，align 預訓練模型和 instructions，而且作者釋出了他們的大型合成資料集，以促進未來對 instruction tuning 的研究。&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;最近的 NLP 文獻見證了「建構可以遵循自然語言指令的模型方面」的大量活動。&lt;/p&gt;
&lt;p&gt;這些發展由兩個關鍵部分組成：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;大型預訓練語言模型 (LM)&lt;/li&gt;
&lt;li&gt;人工編寫的指令資料&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;PromptSource 和 SuperNaturalInstructions 是最近兩個著名的資料集。
他們透過大量手動註釋來收集指令，以建造 T0 和 T$k$-Instruct。&lt;/p&gt;
&lt;p&gt;然而這過程代價高昂，而且由於大多數人往往生成的都是流行的 NLP 任務，使其未能涵蓋真正多樣的任務，也不能涵蓋各種描述任務的不同方式，因此多樣性受侷限。&lt;/p&gt;
&lt;p&gt;鑒於這些限制，想要繼續提升 instruction-tuned models 的品質，需要幫 supervising instruction-tuned models 發展替代方案。&lt;/p&gt;
&lt;p&gt;本文介紹了 Self-Instruct，這是一種 semi-automated 的過程，用模型自身的 instructional signals 對 pretrained LM 進行 instruction-tuning。&lt;/p&gt;
&lt;p&gt;整個流程是一種 iterative bootstrapping algorithm，從手動編寫的 limited seed set 引導生成。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/gpt/self-instruct/fig1.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;在第一階段，模型要幫新任務生成指令。
利用現有的指令集合，創建更廣泛的指令，好定義 (通常是新的) 任務。&lt;/p&gt;
&lt;p&gt;對於新生成的指令集，框架為他們創建 input-output instances，稍後可以透過 supervising 用於 instruction tuning。&lt;/p&gt;
&lt;p&gt;最後，透過各種手段，在低品質和重複的指令加到 task pool 前，把他們修剪掉。&lt;/p&gt;
&lt;p&gt;可以重複這個流程非常多次，直到獲得大量任務。&lt;/p&gt;
&lt;p&gt;該模型的跌代過程中產生了大約 52K 個指令，與大約 85K 個 instance inputs 和 target outputs 配對 (有些相同的指令會對應多種輸入輸出)。&lt;/p&gt;
&lt;p&gt;作者觀察到生成的資料提供了各種有創意的任務，其中超過 50% 的任務和 seed instructions 的 ROUGE-L overlap 小於 0.3。&lt;/p&gt;
&lt;p&gt;基於上述結果，作者通過微調 GPT3 (和生成指令資料是同個模型) 建構了 $GPT3_{SELF-INST}$。&lt;/p&gt;
&lt;p&gt;SuperNI 的結果表明，$GPT3_{SELF-INST}$ 性能大大優於 GPT3 (原始模型)，高了 33.1%，幾乎和 $InstructGPT_{001}$ 的性能相當。&lt;/p&gt;
&lt;p&gt;此外，作者在新創建的的指令集上進行人工評估，$GPT3_{SELF-INST}$ 顯示出廣泛的指令遵循能力，優於在其他公開可用指令數據集上訓練的模型，只比 InstrcutGPT001 落後 5%。&lt;/p&gt;
&lt;p&gt;本文貢獻：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Self-Instruct：一種用最少的人工標記數據引導指令遵循能力的作法&lt;/li&gt;
&lt;li&gt;通過大量的 instruction-tuning 實驗，證明了有效性。&lt;/li&gt;
&lt;li&gt;發布了一個包含 52K 指令的大型綜合資料集，還有一組手動編寫的新任務，用於建構和評估未來的 instruction-following models。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;related-work&#34;&gt;Related Work&lt;/h2&gt;
&lt;h3 id=&#34;instruction-following-language-models&#34;&gt;Instruction-following language models&lt;/h3&gt;
&lt;p&gt;一系列工作顯示，使用 annotated &amp;ldquo;instructional&amp;rdquo; data，可以使普通語言模型遵循一般語言的指令。&lt;/p&gt;
&lt;p&gt;也顯示出 &amp;ldquo;instructional&amp;rdquo; data 的大小和多樣性直接影響模型的泛化能力。&lt;/p&gt;
&lt;p&gt;本文的工作目的在減少對人工註釋者的依賴。&lt;/p&gt;
&lt;h3 id=&#34;language-models-for-data-generation-and-augmentation&#34;&gt;Language models for data generation and augmentation&lt;/h3&gt;
&lt;p&gt;許多工作依賴生成式 LM 來生成數據或做 augmentation。&lt;/p&gt;
&lt;p&gt;雖然作者的工作可被視為一種 augmentation，但和這些工作的差別在於不限於特定任務。&lt;/p&gt;
&lt;p&gt;Self-Instruct 的一個明顯動機是引導出新的任務定義，而這些任務可能還未被 NLP 的研究者定義過。&lt;/p&gt;
&lt;h3 id=&#34;self-training&#34;&gt;Self-training&lt;/h3&gt;
&lt;p&gt;一種典型的 self-training 框架透過經過訓練的模型，幫 unlabeled 資料進行 label，然後用這些資料改進模型。&lt;/p&gt;
&lt;p&gt;雖然 Self-Instruct 和 self-training 有一些相似之處，但多數 self-training 的方法都假設了一個特定的目標任務。&lt;/p&gt;
&lt;p&gt;相比之下，Self-Instruct 從頭開始生出各種任務。&lt;/p&gt;
&lt;h3 id=&#34;knowledge-distillation&#34;&gt;Knowledge distillation&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;這邊我想不太通為什麼可以和 Knowledge distillation 扯上關係&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Knowledge distillation 通常涉及知識從較大模型到較小模型的轉移&lt;/p&gt;
&lt;p&gt;Self-Instruct 也可以看做是 Knowledge distillation 的一種形式，但區別如下&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;distillation 的來源和目標是相同的，即模型的知識被 distill 到他自己&lt;/li&gt;
&lt;li&gt;distill 的內容以 instruction task 的形式出現&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;method&#34;&gt;Method&lt;/h2&gt;
&lt;p&gt;標記大規模指令資料對人類來說可能具有挑戰性，因為他需要&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;創意，好提出新任務&lt;/li&gt;
&lt;li&gt;為每個任務編寫 labeled instances 的專業知識&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;defining-instruction-data&#34;&gt;Defining Instruction Data&lt;/h3&gt;
&lt;p&gt;我們要生成的指令資料集包含 {$I_t$}，每個指令用自然語言定義了任務 $t$。&lt;/p&gt;
&lt;p&gt;每個任務都有一個或多個 input-output instances ($X_t,Y_t$)。&lt;/p&gt;
&lt;p&gt;給定 task instruction $I_t$，還有 instance x，模型 M 要生出 y：&lt;/p&gt;
&lt;p&gt;$M(I_t,x)=y, for (x,y) \in (X_t,Y_t)$&lt;/p&gt;
&lt;p&gt;值得注意的是，instance input 和 instruction 沒有嚴格分界。&lt;/p&gt;
&lt;p&gt;比如 Instruction:&amp;ldquo;write an essay about school safety&amp;rdquo; x:&amp;quot;&amp;quot;，可以被改為 Instruction:&amp;ldquo;write an essay about the following topic&amp;rdquo; x:&amp;ldquo;school safety&amp;rdquo;&lt;/p&gt;
&lt;h3 id=&#34;automatic-instruction-data-generation&#34;&gt;Automatic Instruction Data Generation&lt;/h3&gt;
&lt;p&gt;生成指令資料的 pipeline 分成四個步驟：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;指令生成&lt;/li&gt;
&lt;li&gt;辨識指令是否是分類任務&lt;/li&gt;
&lt;li&gt;用 input-first 或 output-first 做 instance generation&lt;/li&gt;
&lt;li&gt;過濾掉低品質的資料&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;instruction-generation&#34;&gt;Instruction Generation&lt;/h4&gt;
&lt;p&gt;Self-Instruct 是基於一個發現，也就是大型語言模型可以透過 context 中的現有指令，生出新穎的指令。&lt;/p&gt;
&lt;p&gt;為作者提供了一種從一小組人類編寫的指令中，使指令資料增長的做法。&lt;/p&gt;
&lt;p&gt;作者用他們編寫的 175 個任務 (每個任務 1 個 instruction 和 1 個 instance) 初始化 task pool。&lt;/p&gt;
&lt;p&gt;在每一個 step，作者從裡面 sample 8 個 instructions，作為 in-context 的範例。在這 8 個指令中，有 6 條來自人工編寫的任務，另外兩條來自前面步驟中模型生成的任務，以促進多樣性。&lt;/p&gt;
&lt;h4 id=&#34;classification-task-identification&#34;&gt;Classification Task Identification&lt;/h4&gt;
&lt;p&gt;因為對於分類和非分類的任務，作者會採取兩種做法，所以作者使用來自 seed taks 的 12 條分類指令和 19 條非分類指令，讓 GPT3 透過 few-shot 來判別。&lt;/p&gt;
&lt;h4 id=&#34;instance-generation&#34;&gt;Instance Generation&lt;/h4&gt;
&lt;p&gt;給予指令和他們的任務類別，作者獨立地為每條指令生成 instance。&lt;/p&gt;
&lt;p&gt;這具備挑戰性，原因在於他需要模型瞭解目標任務是什麼，根據指令找出需要那些額外的輸入內容，並生成他們。 (模型要根據 instruction 生出 instance input)&lt;/p&gt;
&lt;p&gt;作者發現，在 prompt 中放入其他包含 instruction-input-output 的任務範例的時候，模型可以實現這點。&lt;/p&gt;
&lt;p&gt;一種自然的方法是 Input-first Approach，可以要求語言模型先根據指令提出 input，再生出相應的 output。&lt;/p&gt;
&lt;p&gt;然而，這種方法在分類任務上，可能會偏向於生成某種 label。所以，對於分類任務，作者採用 Output-first Approach，先生成可能的 label，在每個 label 上再生成輸入。&lt;/p&gt;
&lt;h4 id=&#34;filtering-and-postprocessing&#34;&gt;Filtering and Postprocessing&lt;/h4&gt;
&lt;p&gt;為了鼓勵多樣性，只有當新的指令和任何現有的指令的 ROUGE-L overlapping 小於 0.7 的時候，才會被添加到 task pool。&lt;/p&gt;
&lt;p&gt;還排除了一些包含了通常不能被 LM 處理的關鍵字 (e.g. images, pictures, graphs) 的指令。&lt;/p&gt;
&lt;p&gt;在為每個指令生成新的 instance 的時候，會過濾掉完全相同或者是輸入相同但輸出不同的 instance。&lt;/p&gt;
&lt;h3 id=&#34;finetuning-the-lm-to-follow-instructions&#34;&gt;Finetuning the LM to Follow Instructions&lt;/h3&gt;
&lt;p&gt;在創建大規模指令資料後，用這些資料對原始語言模型進行 fine-tune。&lt;/p&gt;
&lt;p&gt;為此，將 instruction 和 instance input 連接起來，作為 prompt，然後訓練模型透過標準的監督式學習進行微調。&lt;/p&gt;
&lt;p&gt;為了讓模型對不同的格式 robust，使用多個模板將指令和輸入 encode 在一起。&lt;/p&gt;
&lt;p&gt;例如，指令可以有或沒有 Task: 前墜、輸入可以有或沒有 Input: 前墜，或是中間可以有不同數量的換行之類的。&lt;/p&gt;
&lt;h2 id=&#34;self-instruct-data-from-gpt3&#34;&gt;Self-Instruct Data from GPT3&lt;/h2&gt;
&lt;p&gt;作者透過 OpenAI API 訪問最大的 GPT3 (davinci)&lt;/p&gt;
&lt;h3 id=&#34;statistics&#34;&gt;Statistics&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/gpt/self-instruct/table1.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;diversity&#34;&gt;Diversity&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/gpt/self-instruct/fig2.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;quality&#34;&gt;Quality&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/gpt/self-instruct/table2.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;experimental-results&#34;&gt;Experimental Results&lt;/h2&gt;
&lt;h3 id=&#34;gpt3_self-inst-fine-tuning-gpt3-on-its-own-instruction-data&#34;&gt;$GPT3_{SELF-INST}$: fine-tuning GPT3 on its own instruction data&lt;/h3&gt;
&lt;p&gt;使用生出來的指令資料，對 GPT3 進行微調。&lt;/p&gt;
&lt;p&gt;微調是透過 OpenAI finetuning API&lt;/p&gt;
&lt;h3 id=&#34;baselines&#34;&gt;Baselines&lt;/h3&gt;
&lt;h4 id=&#34;off-the-shelf-language-models&#34;&gt;Off-the-shelf language models&lt;/h4&gt;
&lt;p&gt;T5-LM 和 GPT3 是普通 LM baselines (只有 pre-training，沒有額外 fine-tune)&lt;/p&gt;
&lt;p&gt;這些 baseline 將表明現成的 LM 在預訓練後，能夠立刻自然地遵循指令的程度。&lt;/p&gt;
&lt;h4 id=&#34;publicly-available-instruction-tuned-models&#34;&gt;Publicly-available instruction-tuned models&lt;/h4&gt;
&lt;p&gt;T0 和 $T_k$-Instruct 是兩個 instruction-tuned models。&lt;/p&gt;
&lt;p&gt;兩者都是從 T5 進行微調的，對這兩種模型，都使用具有 11B 參數的最大版本。&lt;/p&gt;
&lt;h4 id=&#34;instruction-tuned-gpt3-models&#34;&gt;Instruction-tuned GPT3 models&lt;/h4&gt;
&lt;p&gt;作者評估了 InstructGPT，它是 OpenAI 基於 GPT3 開發的。&lt;/p&gt;
&lt;p&gt;對於 SuperNI 的實驗，只與 text-davinci-001 engine 進行比較，因為更新的 engine 用最新的用戶資料，而且很可能已經看過 SuperNI。&lt;/p&gt;
&lt;p&gt;對於新編寫的指令，評估時則包含了 001、002 和 003，以確保完整性。&lt;/p&gt;
&lt;p&gt;為了進一步比較 Self-Instruct 在其他公開可用的指令訓練集資料，使用 PromptSource 和 SuperNI 的資料微調 GPT3，這些資料用於訓練 T0 和 $T_k$-Instruct 模型。&lt;/p&gt;
&lt;p&gt;分別簡稱為 T0 訓練和 SuperNI 訓練。&lt;/p&gt;
&lt;h3 id=&#34;experiment-1-zero-shot-generalization-on-superni-benchmark&#34;&gt;Experiment 1: Zero-Shot Generalization on SUPERNI benchmark&lt;/h3&gt;
&lt;p&gt;首先以 zero-shot 的方式評估典型 NLP 任務遵循指令的能力。&lt;/p&gt;
&lt;h4 id=&#34;results&#34;&gt;Results&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/gpt/self-instruct/table3.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;experiment-2-generalization-to-user-oriented-instructions-on-novel-tasks&#34;&gt;Experiment 2: Generalization to User-oriented Instructions on Novel Tasks&lt;/h3&gt;
&lt;p&gt;盡管 SuperNI 在現有的 NLP 任務具有全面性，多數的這些任務是初於研究理由提出的，而且偏向分類。&lt;/p&gt;
&lt;p&gt;為了更好的獲取指令遵循模型的實用價值，作者中的一部分人策劃了一組面向用戶應用的新指令集。&lt;/p&gt;
&lt;p&gt;他們先針對 Large LM 可能可以應用到的領域進行 brainstorm，並且制定與每個領域相關的 instruction 和 instance。&lt;/p&gt;
&lt;p&gt;總共創建了 252 條指令，每條指令有 1 個 instance。&lt;/p&gt;
&lt;h4 id=&#34;human-evaluation-setup&#34;&gt;Human evaluation setup&lt;/h4&gt;
&lt;p&gt;評估模型在這些不同任務的測試集上的表現極具挑戰性，因為不同的任務需要不同的專業知識。&lt;/p&gt;
&lt;p&gt;為了獲得更忠實的評價，作者請了 instructions 的作者對模型的預測結果進行評估。&lt;/p&gt;
&lt;p&gt;實施一個 four-level rating system：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Rating A
&lt;ul&gt;
&lt;li&gt;回覆有效且令人滿意&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Rating B
&lt;ul&gt;
&lt;li&gt;回覆可接受，但存在可以改進的地方&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Rating C
&lt;ul&gt;
&lt;li&gt;回覆相關，但在內容上有重大錯誤&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Rating D
&lt;ul&gt;
&lt;li&gt;回覆不相關或無效，包含重複輸入的部分，完全無關的輸出。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;results-1&#34;&gt;Results&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/gpt/self-instruct/fig5.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;如果把 Rating B 以上視為有效，$GPT_{SELF-INST}$ 只和 $InstructGPT_{001}$ 相差 5%&lt;/p&gt;
&lt;h2 id=&#34;discussion-and-limitation&#34;&gt;Discussion and Limitation&lt;/h2&gt;
&lt;h3 id=&#34;why-does-self-instruct-work&#34;&gt;Why does SELF-INSTRUCT work?&lt;/h3&gt;
&lt;p&gt;值得反思的是，在最近成功的 instruction-tuning LMs 中，高品質的 human feedback 扮演的角色。&lt;/p&gt;
&lt;p&gt;這裡有兩個極端的假設：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Human feedback 是 instruction-tuning 中必要且不可或缺的角色，因為 LM 需要了解在預訓練過程中沒完全了解到的問題。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Human feedback 是 instruction-tuning 一個可選的方向，因為 LM 在預訓練就已經很熟悉指令了。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;雖然現實可能介於這兩個極端之間，作者推測可能更傾向於第二種假設，尤其是對於較大的模型。&lt;/p&gt;
&lt;p&gt;第二種，也是人類直覺，是 Self- Instruct 的關鍵動機，而且也從成功的結果獲得支持。&lt;/p&gt;
&lt;h3 id=&#34;broader-impact&#34;&gt;Broader Impact&lt;/h3&gt;
&lt;p&gt;除了本文的直接關注點外，作者相信 Self-Instruct 可能有助於揭露各種 instruction tuning 模型 &amp;ldquo;幕後&amp;rdquo; 發生的事情。&lt;/p&gt;
&lt;p&gt;不幸的是，由於他們的資料集尚未發布，這種業界模型仍處於 API 牆之後。&lt;/p&gt;
&lt;p&gt;人們對其結構以及為何能展現令人印象深刻的能力知之甚少。&lt;/p&gt;
&lt;h3 id=&#34;limitations-of-self-instruct&#34;&gt;Limitations of Self-Instruct&lt;/h3&gt;
&lt;h4 id=&#34;tail-phenomena&#34;&gt;Tail phenomena&lt;/h4&gt;
&lt;p&gt;Self-Instruct 依賴於 LM，繼承 LM 的所有限制。&lt;/p&gt;
&lt;p&gt;最近的研究顯示出 tail phenomena 對 LM 的成功構成嚴峻的挑戰。&lt;/p&gt;
&lt;p&gt;換句話說，LM 的最大收益出現於語言中最頻繁出現的部分 (語言分佈的頭部)，而低頻率出現的上下文中獲得的收益最小。&lt;/p&gt;
&lt;p&gt;同樣的，在這項工作背景下，如果 Self-Instruct 大部分的收益偏向預訓練 corpus 中頻繁出現的任務或指令，那也不令人感到意外。&lt;/p&gt;
&lt;p&gt;因此，該方法在不常見和有創意的指令下，可能會顯現出脆弱性。&lt;/p&gt;
&lt;h4 id=&#34;dependence-on-large-models&#34;&gt;Dependence on large models&lt;/h4&gt;
&lt;p&gt;因為 Self-Instruct 依賴於從 LM 中提取初的 inductive bias，因此它可能適合 larger model。&lt;/p&gt;
&lt;p&gt;如果這是對的，這會對那些沒有大量計算資源的人造成阻礙。&lt;/p&gt;
&lt;h4 id=&#34;reinforcing-lm-biases&#34;&gt;Reinforcing LM biases&lt;/h4&gt;
&lt;p&gt;作者擔心這種迭代作法可能會產生意料之外的結果，比如將有問題的社會偏見放大。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>STM32 GPIO 介紹</title>
        <link>https://roykesydon.github.io/Blog/p/stm32-gpio-%E4%BB%8B%E7%B4%B9/</link>
        <pubDate>Wed, 26 Apr 2023 01:32:54 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/stm32-gpio-%E4%BB%8B%E7%B4%B9/</guid>
        <description>&lt;h2 id=&#34;memory-map&#34;&gt;Memory Map&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;CPU 對 I/O 操作方法&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Port I/O
&lt;ul&gt;
&lt;li&gt;用特殊 CPU 指令&lt;/li&gt;
&lt;li&gt;I/O 設備和記憶體不共享地址空間&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Memory-Mapped I/O
&lt;ul&gt;
&lt;li&gt;I/O 設備和記憶體共享地址空間&lt;/li&gt;
&lt;li&gt;像一般控制記憶體&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;這塊記憶體具有四個責任&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Command&lt;/li&gt;
&lt;li&gt;Status&lt;/li&gt;
&lt;li&gt;Output Data&lt;/li&gt;
&lt;li&gt;Input Data&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;gpio-結構&#34;&gt;GPIO 結構&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/embedding/stm32-gpio/gpio-structure.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GPIO mode
&lt;ul&gt;
&lt;li&gt;Open-Drain
&lt;ul&gt;
&lt;li&gt;由外部電壓決定輸出電壓&lt;/li&gt;
&lt;li&gt;Output Register 是 0 會啟用 N-MOS，1 的話靠外部電壓推
&lt;ul&gt;
&lt;li&gt;好處是外部電壓可以自己決定&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Push-Pull
&lt;ul&gt;
&lt;li&gt;由內部電壓決定輸出電壓&lt;/li&gt;
&lt;li&gt;Output Register 是 0 或 1 會決定啟用 N-MOS 或是 P-MOS&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;有關-register&#34;&gt;有關 Register&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Clock enable register
&lt;ul&gt;
&lt;li&gt;AHB2 peripheral clock enable regisetr (RCC_AHB2ENR)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Control register
&lt;ul&gt;
&lt;li&gt;GPIO port mode register&lt;/li&gt;
&lt;li&gt;GPIO port output type register&lt;/li&gt;
&lt;li&gt;GPIO port output speed register&lt;/li&gt;
&lt;li&gt;GPIO port pull-up/pull-down register&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Data register
&lt;ul&gt;
&lt;li&gt;Output&lt;/li&gt;
&lt;li&gt;Input&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;使用-gpio&#34;&gt;使用 GPIO&lt;/h2&gt;
&lt;p&gt;先去 Memory map 找 Boudary address&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/embedding/stm32-gpio/gpio-structure.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;根據 table 確認要設置的數值&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/embedding/stm32-gpio/table-39-1.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/embedding/stm32-gpio/table-39-2.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;設定 RCC enable&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/embedding/stm32-gpio/rcc-en.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;把上面說的各種 Control register 設定好&lt;/p&gt;
&lt;p&gt;比如 PUPDR
&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/embedding/stm32-gpio/PUPDR.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;BSRR&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;修改 ODR 會一次改到整個 GPIO port，若只要改某個 pin，可以用 BSRR&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Delay&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CPU 4 MHz
&lt;ul&gt;
&lt;li&gt;1 cycle = 0.25$\mu$S&lt;/li&gt;
&lt;li&gt;可以查每個組合語言指令要幾個 cycle&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;機械按鈕會有 Bouncing&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Debounce
&lt;ul&gt;
&lt;li&gt;Hardware method
&lt;ul&gt;
&lt;li&gt;加上濾波電容&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Software method
&lt;ul&gt;
&lt;li&gt;讀取後等待一段時間才再次讀取&lt;/li&gt;
&lt;li&gt;連續讀取 N 次，看數值是否穩定改變&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;7-segment&#34;&gt;7-Segment&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;COM 分共陽、共陰&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;8 個七段顯示器就要吃掉 8 * 8 個 GPIO 接腳，可以每次只顯示一個，那只需要 8 個 GPIO 接腳，快速閃過&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;也可用 Max 7219 控制，他有三個輸入 DIN、LOAD、CLK&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DIN 輸入資料&lt;/li&gt;
&lt;li&gt;CLK 上升的時候採樣，最多 10 MHz&lt;/li&gt;
&lt;li&gt;LOAD(CS) 採用最後輸進去的 16 bits
&lt;ul&gt;
&lt;li&gt;最早的是 MSB&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>重構 Refactoring</title>
        <link>https://roykesydon.github.io/Blog/p/%E9%87%8D%E6%A7%8B-refactoring/</link>
        <pubDate>Tue, 25 Apr 2023 14:26:17 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/%E9%87%8D%E6%A7%8B-refactoring/</guid>
        <description>&lt;h2 id=&#34;重構&#34;&gt;重構&lt;/h2&gt;
&lt;p&gt;在不改變軟體行為的情況下，對軟體內部構造進行改善&lt;/p&gt;
&lt;h2 id=&#34;code-smell&#34;&gt;Code Smell&lt;/h2&gt;
&lt;p&gt;也稱 Bad Smell，代表程式碼中需要重構的部分&lt;/p&gt;
&lt;h3 id=&#34;duplicated-code&#34;&gt;Duplicated Code&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;重複程式碼
&lt;ul&gt;
&lt;li&gt;在同個 Class
&lt;ul&gt;
&lt;li&gt;Extract Method&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;在不同 Class
&lt;ul&gt;
&lt;li&gt;Extract Class&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;long-method&#34;&gt;Long Method&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;用 Extract Method 拆解過長的 function&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;long-parameter-list&#34;&gt;Long Parameter List&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Preserve Whole Object
&lt;ul&gt;
&lt;li&gt;把來自同一物件的資料直接該物件取代&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Introduce Parameter Object
&lt;ul&gt;
&lt;li&gt;把相關的資料包成一個 Object&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;large-class&#34;&gt;Large Class&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;一個 Class 有太多 fields / methods / lines&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;magic-number&#34;&gt;Magic Number&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;特殊數值直接用數字表示，日後修改每個地方都要改&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;lack-of-comments&#34;&gt;Lack of Comments&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;加註解的好時機：寫程式前寫上&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;switch-statements&#34;&gt;Switch Statements&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;可利用「多型 (Polymorphism)」解決&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;divergent-change&#34;&gt;Divergent Change&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;一個類別有太多改變的原因&lt;/li&gt;
&lt;li&gt;盡量讓其遵守 SRP&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;shotgun-surgery&#34;&gt;Shotgun Surgery&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;某個責任被分散到大量的 Class 身上，使修改其時要大量修改&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;feature-envy&#34;&gt;Feature Envy&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;存取別的 Object 的 Data 的情形比自己的還頻繁&lt;/li&gt;
&lt;li&gt;這方法可能應該屬於另一個 Object&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;data-clumps&#34;&gt;Data Clumps&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;常一起出現的資料群應該被單獨抽成一個 Class&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;primitive-obsession&#34;&gt;Primitive Obsession&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;過度使用基本類別，造成 Shotgun Surgery&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;message-chains&#34;&gt;Message Chains&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Client 請求 A 物件，A 物件又請求 B 物件&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;lazy-class&#34;&gt;Lazy Class&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;把冗員類別移除&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;temporary-field&#34;&gt;Temporary Field&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Instance variable 只有在特殊情形才被使用，應該改為區域變數或參數&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;inappropriate-intimacy&#34;&gt;Inappropriate Intimacy&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Classes 間頻繁讀取對方資料&lt;/li&gt;
&lt;li&gt;理解程式要同時看懂兩者&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;alternative-classes-with-different-interfaces&#34;&gt;Alternative Classes with Different Interfaces&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;兩個 Class 具有功能相同、命名不同的 function&lt;/li&gt;
&lt;li&gt;可汲取共同部分為 Super Class 來解決&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Relative Position 介紹 &#43; 論文閱讀</title>
        <link>https://roykesydon.github.io/Blog/p/relative-position-%E4%BB%8B%E7%B4%B9--%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</link>
        <pubDate>Mon, 24 Apr 2023 01:08:46 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/relative-position-%E4%BB%8B%E7%B4%B9--%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</guid>
        <description>&lt;h2 id=&#34;說明&#34;&gt;說明&lt;/h2&gt;
&lt;p&gt;本文寫於 &lt;a class=&#34;link&#34; href=&#34;https://roykesydon.github.io/Blog/p/swin-transformer-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Swin Transformer 論文閱讀&lt;/a&gt; 之後，當時對 Relatvie position 的理解不夠清楚，本文將會做解釋，並附上原論文的筆記。&lt;/p&gt;
&lt;p&gt;以下將會先用長度為 3 的序列作為示範。&lt;/p&gt;
&lt;h3 id=&#34;absolute-position-encodings&#34;&gt;Absolute Position Encodings&lt;/h3&gt;
&lt;p&gt;Absolute Position Encodings 的做法是把用某種方式生成或可學習的向量加在輸入，第一個位置用 $w_1$，第二個位置用 $w_2$，第三個位置用 $w_3$。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/relative-position/abs-pos.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;relative-position-encodings&#34;&gt;Relative Position Encodings&lt;/h3&gt;
&lt;p&gt;Relative Position Encodings 顧名思義，就是改用相對位置來做這些向量。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/relative-position/rel-pos.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;上圖中，Position Encoding 的部分從 3 個向量變成 3*3 個向量，因為現在會以每個 token 為基準，生出 3 個相對位置向量。&lt;/p&gt;
&lt;p&gt;我們以 $w_0$，代表處於原點，$w_x$ 代表往右 $x$ 格，$w_{-x}$ 代表往左 $x$ 格，其中 $x$ 是正整數。&lt;/p&gt;
&lt;p&gt;第一個 row 有 $w_0$、$w_1$、$w_2$，意思是以第 0 個向量 (I) 為基準，他的位置是 $w_0$，對第 0 個向量來說，第 1 個向量 (like) 是 $w_1$，第 2 個向量 (cat) 是 $w_2$。&lt;/p&gt;
&lt;p&gt;輪流以 $n$ 個 token 為基準，就會生出 n*n 個相對位置向量，而不是原先的 n 個絕對位置向量。&lt;/p&gt;
&lt;p&gt;其中 $w_i$ 和 $w_j$ 如果 $i=j$，他們會共用同樣的 weight，上圖是以相同顏色表示。&lt;/p&gt;
&lt;p&gt;如果序列長度是 $n$，就會有 $2n-1$ 個向量要學。&lt;/p&gt;
&lt;p&gt;n*n 這個數量使其適合加入到 self-attention，原始論文的加入方式可以參考下方論文筆記，這邊晚點會介紹後續衍生的簡化版。&lt;/p&gt;
&lt;h3 id=&#34;swin-transformer-如何導入-relative-position-encodings&#34;&gt;Swin Transformer 如何導入 Relative Position Encodings&lt;/h3&gt;
&lt;p&gt;Swin Transformer 是借鑒許多 CNN 架構，為了 CV 而經過修改的 vision transformer。&lt;/p&gt;
&lt;p&gt;其中一個重點是，他會在一小區塊的特徵圖上做 self-attention，而且是用 Relative Position Encodings。&lt;/p&gt;
&lt;p&gt;和剛剛的差別在於，現在要在二維空間做 Relative Position Encodings。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/relative-position/rel-pos-2d-1.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;假設有一張 2*2 的 feature map，我們先設定好 feature map 各個 token 的絕對位置座標。&lt;/p&gt;
&lt;p&gt;然後我們輪流把 feature map 的每一個 token 作為基準點，把 feature map 的每個 token 的座標減去基準點的座標，就可以得到相對位置座標。&lt;/p&gt;
&lt;p&gt;如果我們把四個相對位置座標各別攤平 (按照左上 -&amp;gt; 右上 -&amp;gt; 左下 -&amp;gt; 右下的順序)，並且從上到下排好，他會看起來如下圖。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/relative-position/rel-pos-2d-2.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;此時我們幾乎完成了相對位置的表，和剛剛序列一樣生出了 n*n 個相對位置。&lt;/p&gt;
&lt;p&gt;我們接下來要做的事情是把這個表給編號，把 (0, 0) 都編成某個數字，把 (1, 0) 都編成某個數字。&lt;/p&gt;
&lt;p&gt;在此之前，先考慮總共會有幾種可能的相對座標，對於邊長 $M$ 的 feature map (這裡 M=2)，因為兩軸可能的數字皆有 (2M-1) 種，共會有 (2M-1)*(2M-1) 種可能性，這裡等於 9。&lt;/p&gt;
&lt;p&gt;所以我們等等會把所有座標編為 0~8。&lt;/p&gt;
&lt;p&gt;想從座標生出編號 0~8 可以考慮把座標兩軸的數字相加，但由於有負數的存在，要先把兩軸的數字都變成非負整數，所以先把兩軸的座標都各別加 M-1。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/relative-position/rel-pos-2d-3.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;此時如果相加，會使 (2, 1) 和 (1, 2) 都對應到數字 3，所以我們先把 row 座標乘上 2M-1 再相加，此時就可以獲得一個 n*n 的 index table ，對應一組相對位置向量。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/relative-position/rel-pos-2d-4.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;Swin Transformer 是用簡化版的作法來引入相對位置，公式如下&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$Attention(Q,K,V)=SoftMax(QK^T/\sqrt{d}+B)V$
&lt;ul&gt;
&lt;li&gt;$B$ 是 relative position bias，$B \in R^{M^2 * M^2}$&lt;/li&gt;
&lt;li&gt;$a_{ij}$ 是純量，不是向量，和原始論文不同&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;論文出處&#34;&gt;論文出處&lt;/h2&gt;
&lt;p&gt;paper: &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/pdf/1803.02155.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Self-Attention with Relative Position Representations&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;依賴於 attention 機制的 Transformer 在機器翻譯方面取得 SOTA，但在結構中沒有相對或絕對的位置資訊，他需要在輸入中添加絕對位置的資訊。&lt;/p&gt;
&lt;p&gt;因此本文提出一種替代方案，拓展 self-attention ，考慮相對位置的表示，並在一些任務中獲得更好的結果。&lt;/p&gt;
&lt;p&gt;值得一題的事，作者觀察到結合相對和絕對位置不會進一步提高翻譯品質。&lt;/p&gt;
&lt;p&gt;該機制可以拓展到任意 graph-labeled 的輸入&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Non-recurrent models 不一定按順序考慮輸入元素，因此可能需要明確的 position encoding 才才能用序列順序。&lt;/p&gt;
&lt;p&gt;一種常見的方法是使用與輸入元素結合的 position encoding，以向模型傳達位置資訊。&lt;/p&gt;
&lt;p&gt;可以是 deterministic function，或是 learned representations。&lt;/p&gt;
&lt;p&gt;CNN 可以捕捉 kernel 的相對位置資訊，但被證明仍受益於 position encoding。&lt;/p&gt;
&lt;p&gt;對於既不使用卷積也不使用遞歸的 Transformer，結合位置信息的 representation 是一個特別重要的考慮因素，因為該模型在其他方面對序列排序完全不變。&lt;/p&gt;
&lt;p&gt;本文提出一種將相對位置合併到 Transformer 的 self-attention 的做法，即使完全換掉絕對位置編碼，也使兩個機器翻譯任務的品質有顯著提高。&lt;/p&gt;
&lt;h2 id=&#34;background&#34;&gt;Background&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;原始 self-attention&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$z_i=\displaystyle\sum_{j=1}^n\alpha_{ij}(x_jW^V)$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$\alpha_{ij}=\frac{\text{exp } e_{ij}}{\sum_{k=1}^n\text{exp } e_{ik}}$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$e_{ij}=\frac{(x_iW^Q)(x_jW^K)^T}{\sqrt{d_z}}$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;proposed-architecture&#34;&gt;Proposed Architecture&lt;/h2&gt;
&lt;h3 id=&#34;relation-aware-self-attention&#34;&gt;Relation-aware Self-Attention&lt;/h3&gt;
&lt;p&gt;有兩個要引入 relative position 的地方，而且都是向量&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;$z_i = \displaystyle\sum_{j=1}^n \alpha_{ij}(x_jW^V+a_{ij}^V)$&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$e_{ij}=\frac{x_iW^Q(x_jW^K+a_{ij}^K)^T}{\sqrt{d_z}}$&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/relative-position/fig1.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;relative-position-representations&#34;&gt;Relative Position Representations&lt;/h3&gt;
&lt;p&gt;可以引入 clip，把線性序列中，高於長度 k 的修剪成最大值&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$a_{ij}^K=w_{clip(j-i,k)}^K$&lt;/li&gt;
&lt;li&gt;$a_{ij}^V=w_{clip(j-i,k)}^V$&lt;/li&gt;
&lt;li&gt;$clip(x,k)=max(-k,min(k,x))$&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;experiments&#34;&gt;Experiments&lt;/h2&gt;
&lt;h3 id=&#34;model-variations&#34;&gt;Model Variations&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;clipping 的實驗
&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/relative-position/table2.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;V 和 K 的 ablation study
&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/relative-position/table3.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Swin Transformer 論文閱讀</title>
        <link>https://roykesydon.github.io/Blog/p/swin-transformer-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</link>
        <pubDate>Fri, 14 Apr 2023 01:08:46 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/swin-transformer-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</guid>
        <description>&lt;p&gt;paper: &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2103.14030&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Swin Transformer: Hierarchical Vision Transformer using Shifted Windows&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;本文提出一個新的 vision Transformer，稱作 Swin Transformer，可以被用作 computer vision 中的 general-purpose backbone。&lt;/p&gt;
&lt;p&gt;把 Transformer 從 language 移到 vision 具備挑戰性，比如同一個 visual entity 在大小上具備很大的 variance。還有 high resolution 下 pixel 和 word 的數量差異太大。&lt;/p&gt;
&lt;p&gt;為了解決這些差異，作者提出 hierachical Transformer，用 shifted windows 來算出 representation。&lt;/p&gt;
&lt;p&gt;shifted windowing 透過把 self-attention 限制在 non-overlapping 的 local window 和允許 cross-windows connection 來提高效率。&lt;/p&gt;
&lt;p&gt;這種 hierarchical architecture 可以靈活地在各種 scale 下擴展 model，還可以對圖像大小有線性的計算時間複雜度。&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/Swin-Transformer/fig1.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;ViT 把圖片打成 patch，每個 patch 是 16*16，feature maps 由 single low resolution 的輸入生成，而且由於自注意力始終都是在全局上計算的 (patch 和 patch 間做自注意力)，所以時間複雜度是 quadratic computation complexity。&lt;/p&gt;
&lt;p&gt;Swin Transformer 從小 patch 開始，並在更深的 Transformer layers 合併相鄰的 patches。&lt;/p&gt;
&lt;p&gt;有了這些 hierarchical feature maps，可以用在像是 FPN 或是 U-Net。&lt;/p&gt;
&lt;p&gt;一個 Swin Transformer 的關鍵設計因素是 shifted window。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/Swin-Transformer/fig2.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;透過 bridge 不同 layer 的 windows 來提供他們連接。&lt;/p&gt;
&lt;h2 id=&#34;method&#34;&gt;Method&lt;/h2&gt;
&lt;h3 id=&#34;overall-architecture&#34;&gt;Overall Architecture&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/Swin-Transformer/fig3.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Patch Merging
&lt;ul&gt;
&lt;li&gt;原本特徵圖是 H * W * C&lt;/li&gt;
&lt;li&gt;以上下 stride=2 行走，會得到四張 H/2 * W/2 * C&lt;/li&gt;
&lt;li&gt;concatenate 起來，變成 H/2 * W/2 * 4C&lt;/li&gt;
&lt;li&gt;做 linear，變成 H/2 * W/2 * 2C&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;swin-transformer-block&#34;&gt;Swin Transformer block&lt;/h4&gt;
&lt;p&gt;Swin Transformer 是透過把 Transformer block 中的 multi-head self attention(MSA) 換成基於 shifted windows 的 module 構成。&lt;/p&gt;
&lt;h3 id=&#34;shifted-window-based-self-attention&#34;&gt;Shifted Window based Self-Attention&lt;/h3&gt;
&lt;p&gt;標準的 Transformer 架構會算 global self-attention，計算所有 token 間彼此的關係，導致 quadratic complexity，使其不適用於需要大量 token 的許多 CV 問題&lt;/p&gt;
&lt;h4 id=&#34;self-attention-in-non-overlapped-windows&#34;&gt;Self-attention in non-overlapped windows&lt;/h4&gt;
&lt;p&gt;原來的圖片會以 non-overlapping 的方式切割。&lt;/p&gt;
&lt;p&gt;假設每個 windows 有 M * M 個 patches，然後一張圖像有 h * w 塊 patches，計算複雜度如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\Omega(MSA)=4hwC^2+2(hw)^2C$&lt;/li&gt;
&lt;li&gt;$\Omega(W-MSA)=4hwC^2+2M^2hwC$&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;shifted-window-partitioning-in-successive-blocks&#34;&gt;Shifted window partitioning in successive blocks&lt;/h4&gt;
&lt;p&gt;window-based self-attention module 缺乏了 windows 間彼此的連接，會限制模型能力。&lt;/p&gt;
&lt;p&gt;作者提出了一種 shifted window 的方法，保持 non-overlapping windows 的高效計算，同時引入 windows 間的連接。&lt;/p&gt;
&lt;p&gt;再兩個連續的 windows 間，會移動 $(⌊ \frac{M}{2} ⌋, ⌊ \frac{M}{2} ⌋)$&lt;/p&gt;
&lt;h4 id=&#34;efficient-batch-computation-for-shifted-configuration&#34;&gt;Efficient batch computation for shifted configuration&lt;/h4&gt;
&lt;p&gt;shifted window 有個問題是，會導致更多的 windows，從 $⌈ \frac{h}{M} ⌉ * ⌈ \frac{w}{M} ⌉$ 到 $(⌈ \frac{h}{M} ⌉+1) * (⌈ \frac{w}{M} ⌉+1)$，而且有些 window 會小於 M*M。&lt;/p&gt;
&lt;p&gt;這樣會導致無法把這些給壓成一個 batch 快速計算。&lt;/p&gt;
&lt;p&gt;一種 naive 的解法就是直接在外面加 zero padding，但會增加計算量，當 windows 數量較少時，計算量會變很可觀 (從 2 * 2 個 windows 變成 3 * 3 個 windows，增加了 2.25 倍)&lt;/p&gt;
&lt;p&gt;作者提出另外一種巧妙的做法，把一些部分挪移。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/Swin-Transformer/fig4.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;但現在有些 window 裡有多個不該相互做 attention 的部分，所以要用 mask 的方式計算。&lt;/p&gt;
&lt;p&gt;不同 windows，做 self-attention 後，把不相干的部分做的 attention 減去一個很大的數值，最後再過 softmax。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/Swin-Transformer/mask.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;上圖來自作者在 github 提供的可視化&lt;/p&gt;
&lt;p&gt;最後再把它挪回原本的位置。&lt;/p&gt;
&lt;h4 id=&#34;relative-position-bias&#34;&gt;Relative position bias&lt;/h4&gt;
&lt;p&gt;參考這個: &lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/qq_37541097/article/details/121119988&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;https://blog.csdn.net/qq_37541097/article/details/121119988&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;architecture-variants&#34;&gt;Architecture Variants&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;window size 預設是 M = 7&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;query dimension of each head 是 d = 32&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;expansion layer of each MLP is $\alpha$ = 4&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;C 是 first stage 的 hidden layers 的 channel numbers&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Swin-T&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;C = 96&lt;/li&gt;
&lt;li&gt;layer numbers = {2, 2, 6, 2}&lt;/li&gt;
&lt;li&gt;大小和計算量是 Base 的大約 0.25 倍&lt;/li&gt;
&lt;li&gt;complexity 接近 ResNet-50&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Swin-S&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;C = 96&lt;/li&gt;
&lt;li&gt;layer numbers = {2, 2, 18, 2}&lt;/li&gt;
&lt;li&gt;大小和計算量是 Base 的大約 0.5 倍&lt;/li&gt;
&lt;li&gt;complexity 接近 ResNet-101&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Swin-B&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;C = 128&lt;/li&gt;
&lt;li&gt;layer numbers = {2, 2, 18, 2}&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Swin-L&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;C = 192&lt;/li&gt;
&lt;li&gt;layer numbers = {2, 2, 18, 2}&lt;/li&gt;
&lt;li&gt;大小和計算量是 Base 的大約 2 倍&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;experiments&#34;&gt;Experiments&lt;/h2&gt;
&lt;h3 id=&#34;image-classification-on-imagenet-1k&#34;&gt;Image Classification on ImageNet-1K&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/Swin-Transformer/table1.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;object-detection-on-coco&#34;&gt;Object Detection on COCO&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/Swin-Transformer/table2.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;semantic-segmentation-on-ade20k&#34;&gt;Semantic Segmentation on ADE20K&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/Swin-Transformer/table3.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;ablation-study&#34;&gt;Ablation Study&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/Swin-Transformer/table4.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;基於 self-attention 的 shifted window 是 Swin Transformer 關鍵部分，被顯示出他在 CV 領域有效率且有效，並期望未來把它應用在 NLP。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>STM32 UART 實驗</title>
        <link>https://roykesydon.github.io/Blog/p/stm32-uart-%E5%AF%A6%E9%A9%97/</link>
        <pubDate>Sun, 09 Apr 2023 01:32:54 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/stm32-uart-%E5%AF%A6%E9%A9%97/</guid>
        <description>&lt;h2 id=&#34;介紹&#34;&gt;介紹&lt;/h2&gt;
&lt;p&gt;試用 STM32 UART 功能&lt;/p&gt;
&lt;p&gt;會透過 RealTerm 和 STM32L476RG 溝通，並用 DMA 接收訊息&lt;/p&gt;
&lt;p&gt;根據 User manual，USART2 預設會連接 ST-LINK，要連接外部設備的話要修改 solder bridge&lt;/p&gt;
&lt;h2 id=&#34;ioc-設置&#34;&gt;ioc 設置&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Connectivity 可以設置 USART2&lt;/li&gt;
&lt;li&gt;mode 從 disable 改選 Asynchronous&lt;/li&gt;
&lt;li&gt;Parameters Settings 可以設置各種資訊
&lt;ul&gt;
&lt;li&gt;Baud Rate&lt;/li&gt;
&lt;li&gt;Word Length&lt;/li&gt;
&lt;li&gt;Parity&lt;/li&gt;
&lt;li&gt;Stop Bits&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;DMA Setting
&lt;ul&gt;
&lt;li&gt;Add 一個 RX
&lt;ul&gt;
&lt;li&gt;Mode 改成 circular，並打開 memory 的 increment address
&lt;ul&gt;
&lt;li&gt;increment address 是因為資料是用 array 存&lt;/li&gt;
&lt;li&gt;circular 是當資料滿了後，會回到 zero position&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;NVIC Setting
&lt;ul&gt;
&lt;li&gt;設置 DMA 應該就會自動設置一個 interrupt，檢查一下&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;程式碼&#34;&gt;程式碼&lt;/h2&gt;
&lt;p&gt;發送&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;uint8_t&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;myTxData&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;13&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;Hello World&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;\r\n&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;HAL_UART_Transmit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;huart2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;myTxData&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;13&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;接收&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;UART_HandleTypeDef&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;huart2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// generated code
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;uint8_t&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;myRxData&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;20&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;];&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;HAL_UART_Receive_DMA&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;huart2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;myRxData&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;20&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// 在 Init 後，在 main 中執行一次就好
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;interrupt&lt;/p&gt;
&lt;p&gt;在 hal_uart.c 有&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;__weak&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;HAL_UART_RxCpltCallback&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;UART_HandleTypeDef&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;huart&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;cm&#34;&gt;/* Prevent unused argument(s) compilation warning */&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;UNUSED&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;huart&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;cm&#34;&gt;/* NOTE : This function should not be modified, when the callback is needed,
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cm&#34;&gt;            the HAL_UART_RxCpltCallback can be implemented in the user file.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cm&#34;&gt;   */&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;當 DMA 滿了就會呼叫這個 function&lt;/p&gt;
&lt;h2 id=&#34;實驗&#34;&gt;實驗&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;HAL_UART_RxCpltCallback&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;UART_HandleTypeDef&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;huart&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;cm&#34;&gt;/* Prevent unused argument(s) compilation warning */&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;UNUSED&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;huart&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;cm&#34;&gt;/* NOTE : This function should not be modified, when the callback is needed,
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cm&#34;&gt;            the HAL_UART_RxCpltCallback can be implemented in the user file.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cm&#34;&gt;   */&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;HAL_UART_Transmit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;huart2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;myRxData&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;20&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;當 20 個 Bytes 儲存滿了就回傳資訊給電腦&lt;/p&gt;
&lt;h3 id=&#34;realterm&#34;&gt;RealTerm&lt;/h3&gt;
&lt;h4 id=&#34;display&#34;&gt;Display&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;勾選 Half Duplex
&lt;ul&gt;
&lt;li&gt;發送的訊息會顯示綠色，接收的是黃色&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;port&#34;&gt;Port&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;設置 Baud 和其他有的沒的&lt;/li&gt;
&lt;li&gt;選 open&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;send&#34;&gt;Send&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;EOL 可以勾選 CRLF&lt;/li&gt;
&lt;li&gt;打一些文字後按 Send ASCII&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;結果&#34;&gt;結果&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/embedding/stm32-uart/result.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/Roykesydon/STM32-Playground/tree/main/STM32-UART/uart_test&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;程式碼&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>STM32 GPIO 實驗</title>
        <link>https://roykesydon.github.io/Blog/p/stm32-gpio-%E5%AF%A6%E9%A9%97/</link>
        <pubDate>Sun, 02 Apr 2023 01:32:54 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/stm32-gpio-%E5%AF%A6%E9%A9%97/</guid>
        <description>&lt;h2 id=&#34;目的&#34;&gt;目的&lt;/h2&gt;
&lt;p&gt;本文會試用 GPIO output / input / interrupt&lt;/p&gt;
&lt;h2 id=&#34;gpio-架構&#34;&gt;GPIO 架構&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/embedding/stm32-gpio/gpio-structure.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;output-介紹&#34;&gt;Output 介紹&lt;/h2&gt;
&lt;p&gt;在 ioc 那邊選個 pin，選 GPIO_Output&lt;/p&gt;
&lt;p&gt;在左邊欄位 System Core 選擇 GPIO&lt;/p&gt;
&lt;p&gt;有五個欄位可以設定&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;GPIO output level&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;初始電位&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;GPIO mode&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;push pull 和 open drain
&lt;ul&gt;
&lt;li&gt;位於架構圖下方那部分，push pull 可以用 PMOS 和 NMOS 來得到高低電位，open drain 會 disable PMOS，讓你可以在外面自己接上拉電阻&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;GPIO Pull-up/Pull-down&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Maximum output speed&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;User Label&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;用完記得 ctrl+s 讓他 generate code&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;9
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cm&#34;&gt;/*Configure GPIO pin : PtPin */&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;GPIO_InitStruct&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Pin&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;RED_LED_Pin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;GPIO_InitStruct&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Mode&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;GPIO_MODE_OUTPUT_PP&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;GPIO_InitStruct&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Pull&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;GPIO_NOPULL&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;GPIO_InitStruct&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Speed&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;GPIO_SPEED_FREQ_LOW&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;HAL_GPIO_Init&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;RED_LED_GPIO_Port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;GPIO_InitStruct&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cm&#34;&gt;/*Configure GPIO pin Output Level */&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;HAL_GPIO_WritePin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;RED_LED_GPIO_Port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;RED_LED_Pin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;GPIO_PIN_RESET&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;HAL_GPIO_WritePin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;RED_LED_GPIO_Port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;RED_LED_Pin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;GPIO_PIN_RESET&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// 低電位
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;HAL_GPIO_WritePin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;RED_LED_GPIO_Port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;RED_LED_Pin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;GPIO_PIN_SET&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// 高電位
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;HAL_Delay&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;//等一秒
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;HAL_GPIO_TogglePin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;RED_LED_GPIO_Port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;RED_LED_Pin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;根據架構圖左側，你可以透過修改 BSRR 來修改 ODR，達到修改輸出的效果，請見 Reference Manuals，實際上 &lt;code&gt;HAL_GPIO_WritePin&lt;/code&gt; 也是這樣實現的&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;HAL_GPIO_WritePin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;GPIO_TypeDef&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;GPIOx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;uint16_t&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;GPIO_Pin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;GPIO_PinState&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;PinState&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;cm&#34;&gt;/* Check the parameters */&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nf&#34;&gt;assert_param&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;IS_GPIO_PIN&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;GPIO_Pin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;));&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nf&#34;&gt;assert_param&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;IS_GPIO_PIN_ACTION&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;PinState&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;));&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;PinState&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;!=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;GPIO_PIN_RESET&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;GPIOx&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;BSRR&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;uint32_t&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;GPIO_Pin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;else&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;n&#34;&gt;GPIOx&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;BRR&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;uint32_t&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;GPIO_Pin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;input-介紹&#34;&gt;Input 介紹&lt;/h2&gt;
&lt;p&gt;看架構圖上方，用 Schmitt trigger 取得高低電位資料，他有 upper threshold 和 lower threshold，而不是用 single threshold&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cm&#34;&gt;/*Configure GPIO pin : PtPin */&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;GPIO_InitStruct&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Pin&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;GREEN_LED_INPUT_Pin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;GPIO_InitStruct&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Mode&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;GPIO_MODE_INPUT&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;GPIO_InitStruct&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Pull&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;GPIO_NOPULL&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nf&#34;&gt;HAL_GPIO_Init&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;GREEN_LED_INPUT_GPIO_Port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;GPIO_InitStruct&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;uint8_t&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;green_led_input&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;HAL_GPIO_ReadPin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;GREEN_LED_INPUT_GPIO_Port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;GREEN_LED_INPUT_Pin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;interrupt&#34;&gt;Interrupt&lt;/h2&gt;
&lt;p&gt;ioc 選個 pin，設定 GPIO_EXTI，這邊我選 B1(PC13)，也就是開發版上的藍色按鈕&lt;/p&gt;
&lt;p&gt;可以選 GPIO mode，這邊選 Falling Edge Trigger，值得一提的是他的設計是上拉電阻，所以這樣不是放開後觸發，是按下後觸發。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/embedding/stm32-gpio/b1.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;ioc 的 System Core 的 NVIC 還要把 EXTI line[15:10] interrupts 給 enabled，然後 Code generation 打開 Generate IRQ handler，還有 Call HAL handler。&lt;/p&gt;
&lt;p&gt;在 &lt;code&gt;stm32l4xx_it.c&lt;/code&gt; 裡，
現在會有&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;EXTI15_10_IRQHandler&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;cm&#34;&gt;/* USER CODE BEGIN EXTI15_10_IRQn 0 */&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;cm&#34;&gt;/* USER CODE END EXTI15_10_IRQn 0 */&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;HAL_GPIO_EXTI_IRQHandler&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;B1_Pin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;cm&#34;&gt;/* USER CODE BEGIN EXTI15_10_IRQn 1 */&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;cm&#34;&gt;/* USER CODE END EXTI15_10_IRQn 1 */&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;這兩行各別是因為我們剛剛開的功能生的&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;HAL_GPIO_EXTI_IRQHandler&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;uint16_t&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;GPIO_Pin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;cm&#34;&gt;/* EXTI line interrupt detected */&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;__HAL_GPIO_EXTI_GET_IT&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;GPIO_Pin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;!=&lt;/span&gt; &lt;span class=&#34;mh&#34;&gt;0x00u&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nf&#34;&gt;__HAL_GPIO_EXTI_CLEAR_IT&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;GPIO_Pin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nf&#34;&gt;HAL_GPIO_EXTI_Callback&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;GPIO_Pin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;__weak&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;HAL_GPIO_EXTI_Callback&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;uint16_t&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;GPIO_Pin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;cm&#34;&gt;/* Prevent unused argument(s) compilation warning */&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;nf&#34;&gt;UNUSED&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;GPIO_Pin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  &lt;span class=&#34;cm&#34;&gt;/* NOTE: This function should not be modified, when the callback is needed,
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cm&#34;&gt;           the HAL_GPIO_EXTI_Callback could be implemented in the user file
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cm&#34;&gt;   */&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;__weak 代表有同名 function 的話，就會採用沒 __weak prefix 的&lt;/p&gt;
&lt;p&gt;所以我們可以在 gpio.c 放下面的程式碼&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;#include&lt;/span&gt; &lt;span class=&#34;cpf&#34;&gt;&amp;lt;stdbool.h&amp;gt;&lt;/span&gt;&lt;span class=&#34;cp&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kt&#34;&gt;void&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;HAL_GPIO_EXTI_Callback&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;uint16_t&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;GPIO_Pin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;GPIO_Pin&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;B1_Pin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;){&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;static&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;bool&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;prev_val&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;prev_val&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;){&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nf&#34;&gt;HAL_GPIO_WritePin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;RED_LED_GPIO_Port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;RED_LED_Pin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;GPIO_PIN_SET&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;prev_val&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;k&#34;&gt;else&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;nf&#34;&gt;HAL_GPIO_WritePin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;RED_LED_GPIO_Port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;RED_LED_Pin&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;GPIO_PIN_RESET&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;            &lt;span class=&#34;n&#34;&gt;prev_val&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;        &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;實驗&#34;&gt;實驗&lt;/h2&gt;
&lt;p&gt;設定兩個輸入，一個輸出，一個 interrupt&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;當按下按鈕時，切換紅色 LED 的亮滅，並且讓板子上的綠色 LED 輸出和紅色 LED 相反的結果&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;B1(PC13、藍色按鈕) 按下去的時候，會發出 interrupt，並讓 RED_LED(PC10) 輸出和上次相反的電位，讓麵包版上的紅色 LED 亮滅，正極那邊接一條杜邦線給 GREEN_LED_INPUT (PC12)，並且 LD2(PA5、板子上的綠色 LED) 會輸出和紅色 LED 相反的結果。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/embedding/stm32-gpio/result1.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/embedding/stm32-gpio/result2.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/Roykesydon/STM32-Playground/tree/main/STM32-GPIO/gpio_testing&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;程式碼&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>STM32CubeIDE 基本開發使用</title>
        <link>https://roykesydon.github.io/Blog/p/stm32cubeide-%E5%9F%BA%E6%9C%AC%E9%96%8B%E7%99%BC%E4%BD%BF%E7%94%A8/</link>
        <pubDate>Sun, 02 Apr 2023 00:32:54 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/stm32cubeide-%E5%9F%BA%E6%9C%AC%E9%96%8B%E7%99%BC%E4%BD%BF%E7%94%A8/</guid>
        <description>&lt;h2 id=&#34;使用的板子&#34;&gt;使用的板子&lt;/h2&gt;
&lt;p&gt;STM32L476RG&lt;/p&gt;
&lt;h2 id=&#34;開發文件&#34;&gt;開發文件&lt;/h2&gt;
&lt;p&gt;開發前需要先去 ST 官網，根據你的板子載四個重要文件&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Datasheet


        &lt;embed src=&#34;https://roykesydon.github.io/Blog/Blog/pdf/embedding/stm32cubeide/block-diagram.pdf&#34; type=&#34;application/pdf&#34; style=&#34;width:100%;height:50vh&#34;&gt;
    
上圖是其中的 block diagram&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Reference Manuals&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Programming Manuals&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Schematic&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/embedding/stm32cubeide/IMG_2389.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;創建-project&#34;&gt;創建 project&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;File -&amp;gt; New -&amp;gt; STM32 Project&lt;/li&gt;
&lt;li&gt;Board Selector 搜索 NUCLEO-L476RG，選取並 Next&lt;/li&gt;
&lt;li&gt;設置 Project Name，其他不動，Next&lt;/li&gt;
&lt;li&gt;Copy only the necessary library files，Finish&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;ioc&#34;&gt;ioc&lt;/h2&gt;
&lt;p&gt;專案會有個 .ioc 檔，可以透過 GUI 生成設定 pin 的程式碼&lt;/p&gt;
&lt;p&gt;建議 Project Manager 的 Code Generator 勾選 Generate peripheral initialization as a pair &amp;lsquo;.c/.h&amp;rsquo; files per peripheral，開發起來比較方便&lt;/p&gt;
&lt;h2 id=&#34;compile&#34;&gt;Compile&lt;/h2&gt;
&lt;p&gt;點選上面的 hammer&lt;/p&gt;
&lt;h2 id=&#34;clock-configuration&#34;&gt;Clock Configuration&lt;/h2&gt;
&lt;p&gt;ioc 那邊還可以設置 clock&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;External clock
&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/embedding/stm32cubeide/ex-clock.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;LSE 和 HSE 是 (Low / High Speed External)，你有 oscillator 的話可以自己弄&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/embedding/stm32cubeide/sys-peripheral.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;你可以調 sysclk 或 peripheral clock&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;programming&#34;&gt;Programming&lt;/h2&gt;
&lt;p&gt;在 USER CODE section 寫上程式碼
這是由於生成程式碼的機制所致&lt;/p&gt;
&lt;p&gt;選取的部分可以按 F3，看他是從哪邊來的，或看 macro 之類的&lt;/p&gt;
&lt;p&gt;按下 &lt;code&gt;alt + /&lt;/code&gt; 會出現自動補全的提示&lt;/p&gt;
&lt;h2 id=&#34;debug&#34;&gt;DEBUG&lt;/h2&gt;
&lt;p&gt;上面有個 BUG 符號的東西，旁邊的箭頭可以用 DEBUG 的設定&lt;/p&gt;
&lt;p&gt;又建 STM32 C/C++ Application，可以 New 新設定&lt;/p&gt;
&lt;p&gt;C/C++ Application 那邊選你 compile 的 elf 檔&lt;/p&gt;
&lt;p&gt;Debugger 開啟 ST-LINK S/N，並且掃描，如果你的電腦有接上 MCU，應該會直接找到&lt;/p&gt;
</description>
        </item>
        <item>
        <title>GIT 論文閱讀</title>
        <link>https://roykesydon.github.io/Blog/p/git-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</link>
        <pubDate>Wed, 29 Mar 2023 01:08:46 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/git-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</guid>
        <description>&lt;p&gt;paper: &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2205.14100&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;GIT: A Generative Image-to-text Transformer for Vision and Language&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; ██████╗ ██╗████████╗
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;██╔════╝ ██║╚══██╔══╝
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;██║  ███╗██║   ██║   
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;██║   ██║██║   ██║   
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;╚██████╔╝██║   ██║   
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt; ╚═════╝ ╚═╝   ╚═╝   
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;設計了一個 Generative Image-to-text Transformer，統一 vision-language tasks，像是 image/video captioning 或是問答。&lt;/p&gt;
&lt;p&gt;雖然 generative models 在預訓練和微調的時候是同樣的網路架構，現有的工作通常都包含複雜的架構 (uni/multi-modal encoder/decoder)，
而且依賴於外部模組，比如物件偵測或 optical character recognition (OCR)。&lt;/p&gt;
&lt;p&gt;在 GIT，我們簡化為 single language modeling task 下的一個 image encoder 和一個 text decoder。&lt;/p&gt;
&lt;p&gt;擴大了預訓練資料和模型大小以提高模型性能。&lt;/p&gt;
&lt;p&gt;在許多具有挑戰性的 benchmarks 上取得 SOTA。&lt;/p&gt;
&lt;p&gt;比如首次在 TextCpas 上超越人類的表現。&lt;/p&gt;
&lt;p&gt;提出了一種 generation-based image classification and scene text recognition 的新方案。&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;近年來在 vision-language（VL）預訓練方面取得了巨大進展，特別是基於 image-text pairs 的大規模數據，例如 CLIP、Florence 和 SimVLM。&lt;/p&gt;
&lt;p&gt;學習到的 representation 很好的提高了下游任務的性能，比如 image captioning、visual question answering 和 image-text retrieval。&lt;/p&gt;
&lt;p&gt;在預訓練過程中，Masked Language Modeling (MLM) 和 Image-Text Matching (ITM) 被廣泛使用。&lt;/p&gt;
&lt;p&gt;然而這些 loss 和下游任務不同，必須做 task-specific adaptation。&lt;/p&gt;
&lt;p&gt;比如， image captioning 要移除 ITM，VQA 需要額外隨機初始的 MLP。&lt;/p&gt;
&lt;p&gt;為了減少這種差異，最近的研究試圖為預訓練模型設計 unified generative models 來預訓練，因為大多數 VL 的問題可以轉化為生成問題。&lt;/p&gt;
&lt;p&gt;這些方法通常利用 multi-modal encoder 和 text decoder，並精心設計 text input 和 text target。&lt;/p&gt;
&lt;p&gt;為了進一步推動這方向的研究，作者設計了一個簡單的 Generative Image-to-text Transformer，稱作 GIT，只包含一個 image encoder 和 text decoder。&lt;/p&gt;
&lt;p&gt;預訓練任務只是把輸入的圖像映射到相關聯的文字描述。&lt;/p&gt;
&lt;p&gt;盡管他很簡單，但還是在眾多具有挑戰性的 benchmark 取得 SOTA。&lt;/p&gt;
&lt;p&gt;image encoder 是 Swin-like vision transformer，在大量的 image-text pairs 上做 pretrain，基於 contrastive task。&lt;/p&gt;
&lt;p&gt;這消除了現有許多方法中對 object detector 的依賴。&lt;/p&gt;
&lt;p&gt;為了將其擴展到影片領域，我們把多個 frame 的特徵 concatenate，作為 video 表示。&lt;/p&gt;
&lt;p&gt;text decoder 是一個用來預測相關聯文字的 transformer。&lt;/p&gt;
&lt;p&gt;整個網路都是基於 language modeling task 來訓練。&lt;/p&gt;
&lt;p&gt;對於 VQA，input question 被看作 text prefix，並以 auto-regressive 的方法生出答案。&lt;/p&gt;
&lt;p&gt;此外，作者提出了一種 generation-based 的 ImageNet classification 新方案，預測標籤直接根據作者的生成模型，而不用預先定義詞彙表。&lt;/p&gt;
&lt;p&gt;我們的作法很簡單，但在擴大預訓練資料和模型大小後，成果驚人。&lt;/p&gt;
&lt;p&gt;主要貢獻如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;我們展示了 GIT，僅由一個 image encoder 和一個 text decoder 組成，透過 language modeling task，在 0.8 billion image-text pairs 上 pretrain。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;在 image/video captioning 和 QA 上，沒有基於 object detectors，object tags 和 OCR，就在多個任務上取得 SOTA。證明簡單的網路架構也可以透過 scaling 取得強大的性能。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;我們證明 GIT 雖然 pretrain 在 image-text pairs，也能在 video tasks 上取得 SOTA，不需要 video dedicated encoders。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;我們提出了一種新的 generation-based image classification 方案，在 ImageNet-1K 上，取得不錯的性能。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;related-work&#34;&gt;Related Work&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/microsoft-GIT/table1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/microsoft-GIT/fig1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;在 VL pre-training 中，多 multi-task pre-training 被廣泛使用，賦予網路多種或增強的能力。&lt;/p&gt;
&lt;p&gt;比如，MLM 和 ITM 是廣泛採用的預訓練任務，最近也有研究加入 image-text contrastive loss。&lt;/p&gt;
&lt;p&gt;由於多數 VL 任務都可以表示成 text generation task，所以可以訓練一個生成模型來支持各種下游任務。&lt;/p&gt;
&lt;p&gt;輸入和輸出文本通常都會經過精心設計，以預訓練這樣的生成模型。&lt;/p&gt;
&lt;p&gt;對於 image representation，Faster RCNN 被大多數現有方法用來提取區域特徵。&lt;/p&gt;
&lt;p&gt;同時，也很容易以 end-to-end 的方法訓練整個網路。&lt;/p&gt;
&lt;p&gt;除了 feature map，object tags，也很常被用來方便 transformer 理解上下文，特別是 novel objects。&lt;/p&gt;
&lt;p&gt;對於與場景文本相關的任務，調用 OCR 以生成場景文本作為附加網路輸入。&lt;/p&gt;
&lt;p&gt;對於 text prediction，常用 transformer network，結合 cross-attention module 來融合 image tokens。&lt;/p&gt;
&lt;p&gt;或者只是單純 concatenate text tokens 和 image tokens，然後用 self-attention。&lt;/p&gt;
&lt;p&gt;在本文中，我們有 9 個不同的 benchmark，3 種不同模型大小和 3 種不同預訓練資料規模。&lt;/p&gt;
&lt;h2 id=&#34;generative-image-to-text-transformer&#34;&gt;Generative Image-to-text Transformer&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/microsoft-GIT/fig2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;network-architecture&#34;&gt;Network Architecture&lt;/h3&gt;
&lt;p&gt;image encoder 基於 contrastive pre-trained model。&lt;/p&gt;
&lt;p&gt;輸入是原始圖像，輸出是 compact 2D feature map，被 flatten 成 list of features。&lt;/p&gt;
&lt;p&gt;透過一個額外的 linear layer 和一個 layernorm layer，image features 被 project 到 D dimensions，也就是 text encoder 的 input。&lt;/p&gt;
&lt;p&gt;作者使用做 contrastive tasks pretraining 的 image encoder，因為最近的研究表明這種 image encoder 有更好的性能。&lt;/p&gt;
&lt;p&gt;在後面的章節，還觀察到 VL performence 明顯地隨著更強的 image encoder 而有所提升。
這和 object detection-based 的方法觀察到的結果一致。&lt;/p&gt;
&lt;p&gt;CoCa 的 concurrent work 統一了 contrastive task 和 the generation task，作為一個預訓練階段。&lt;/p&gt;
&lt;p&gt;作者的方法相當於是按順序分離兩個任務:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;用 contrastive task 訓練 image encoder&lt;/li&gt;
&lt;li&gt;用 generation task pretrain image encoder 和 text decoder&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;text decoder 是一個用於預測文本描述的 transformer module，由多個 transformer block 組成，每個 transformer block 由一個 self-attention layer 和 feed-forward layer 組成。&lt;/p&gt;
&lt;p&gt;text 被 tokenize 和 embed 到 D dimensions，並添加 positional encoding 和 layernorm layer。&lt;/p&gt;
&lt;p&gt;image features 和 text embeddings 被 concatenate 起來作為 transformer module 的輸入。&lt;/p&gt;
&lt;p&gt;text 以 [BOS] 開始，並以 auto regressive 的方式 decode，直到 [EOS] 或 maximum steps。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/microsoft-GIT/fig3.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;attention mask 根據上圖設計，使的 text token 只能依賴於前面的 text token 和 image token，而 image token 可以互相做 attention。&lt;/p&gt;
&lt;p&gt;這和 unidirectional attention mask 不同，unidirectional attention mask 並非每個 image token 都可以依賴於其他的 Image token。&lt;/p&gt;
&lt;p&gt;作者很好地初始化 image encoder，卻隨機初始化 text decoder。&lt;/p&gt;
&lt;p&gt;這種設計動機是基於[MiniVLM: A Smaller and Faster Vision-Language Model]，該研究隨機初始化顯示出與 BERT 初始化相似地性能。&lt;/p&gt;
&lt;p&gt;原因可能在於 BERT 地初始化無法理解圖像信號，這對於 VL 任務至關重要。&lt;/p&gt;
&lt;p&gt;[Flamingo: a Visual Language Model for Few-Shot Learning] 採用了類似的 image encoder + text decoder，但是他們的 decoder 經過 pretrain，並且有 freeze，好保留大型語言模型的泛化能力。&lt;/p&gt;
&lt;p&gt;GIT 的所有參數都會更新，以更好地適應 VL 的任務。&lt;/p&gt;
&lt;p&gt;另一種架構是 cross-attention-based 的 decoder，用於 incorporate image signals，而不是 concatenation 再用 self-attention。&lt;/p&gt;
&lt;p&gt;根據實驗，large-scale 的 pre-training，self-attention-based 會有更好的性能，小規模的則是 cross-attention-based。&lt;/p&gt;
&lt;p&gt;一個合理的解釋是，經過充分訓練，decoder 可以很好地處理圖像和文本，而且 image token 可以為了 text generation 更好地更新。&lt;/p&gt;
&lt;p&gt;而 cross-attention 讓 image token 沒辦法 attend 彼此。&lt;/p&gt;
&lt;h3 id=&#34;pre-training&#34;&gt;Pre-training&lt;/h3&gt;
&lt;p&gt;訓練採用 language modeling (LM) loss。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/microsoft-GIT/for1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$I$ 是 image&lt;/li&gt;
&lt;li&gt;$y_i,i \in $ { $ 1,&amp;hellip;,N $ } 是文字 token，$y_0$ 是 [BOS]，$y_{N+1}$ 是 [EOS]&lt;/li&gt;
&lt;li&gt;CE 是有 0.1 label smoothing 的 cross-entropy&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;另一種選擇是 MLM，在每個 epoch 中預測 15% 的輸入 token，要預測所有 token 至少需要 1 / 0.15 = 6.7 個 epochs，對於 LM，每個 epoch 都可以預測所有 token，對於大規模預訓練資料來說效率更高。&lt;/p&gt;
&lt;p&gt;ablation studies 顯示出 LM 可以在有限的 epoch 內實現更好的性能。
在大規模訓練中，由於計算資訊的限制，只有兩個 epoch，所以選擇 LM。
與此同時，大部分最近的 large-scale language model 也是基於 LM。&lt;/p&gt;
&lt;p&gt;如果沒有圖像輸入，該模型將簡化為 decoder-only 的語言模型，架構類似於 GPT-3。&lt;/p&gt;
&lt;p&gt;因此，這種設計還可以利用 text-only 的資料來提升 scaled-up decoder 的能力，把這保留給未來的工作。&lt;/p&gt;
&lt;h3 id=&#34;fine-tuning&#34;&gt;Fine-tuning&lt;/h3&gt;
&lt;p&gt;對於 image captioning，由於訓練數據格式和預訓練相同，所以用同樣的 LM task 來微調 GIT。
對於 visual question answering，問題和 GT 在微調的時候被看做 special caption，但 LM loss 僅用於答案和 [EOS]。&lt;/p&gt;
&lt;p&gt;推理過程中，question 被當作 caption 的 prefix，完成的部分是預測。&lt;/p&gt;
&lt;p&gt;VQAv2 現有的工作收集候選答案，再重構成分類問題，預測一次。
作者的工作有更多挑戰，因為是生成式的，需要生出至少兩個正確的 token，答案和 [EOS]。&lt;/p&gt;
&lt;p&gt;然而考慮到自由形式答案的好處，作者選擇了生成方法。&lt;/p&gt;
&lt;p&gt;由於生成模型的難度，VQAv2 比現有的判別工作略差。&lt;/p&gt;
&lt;p&gt;對於和 scene-text related VQA 任務，現有方法通常利用 OCR 生成 5 個 scene text 並用 dynamic pointer network 決定當前輸出應該是 OCR 還是 general text。&lt;/p&gt;
&lt;p&gt;但由於作者的方法不依賴於 OCR，因此也不依賴於 dynamic pointer network。&lt;/p&gt;
&lt;p&gt;根據實驗，作者發現模型透過大規模預訓練資料學會如何閱讀場景文本，並且作者的模型不是專門為了影片領域設計的，但可以透過簡單的架構更改就取得具有競爭力或甚至 SOTA 的成果，也就是作者可以從每個影片採樣多個 frame，並透過 image encoder 獨立地為每個 frame 編碼。
最後添加一個 learnable temporal embedding (初始化為 0)，並 concatenate sampled frames 的特徵。&lt;/p&gt;
&lt;p&gt;作者還用於圖片分類，把 class name 用於 caption。&lt;/p&gt;
&lt;p&gt;這和現有工作不一樣，現有工作通常先定義詞彙表，並用線性層預測每個類別的可能性。&lt;/p&gt;
&lt;p&gt;當新數據和新類別被添加到現有數據的時候，這種新一代的方案是有益的，因為這樣可以在不引入新參數的情況下對新數據進行訓練。&lt;/p&gt;
&lt;h2 id=&#34;experiments&#34;&gt;Experiments&lt;/h2&gt;
&lt;h3 id=&#34;setting&#34;&gt;Setting&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;收集 0.8B 的 image-text pairs 來預訓練。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;image encoder 是根據  pre-trained contrastive model 初始化的。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;hidden dimension (D) = 768&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;text decoder 有 6 個 randomly-initialized transformer blocks&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;共有 0.7b 的參數&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;image decoder 和 text encoder 的 learning rate 各別是 1e-5 和 5e-5，都 cosine decay 到 0&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;推論階段 beam size 是 4，length penalty 是 0.6。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Supplementary materials 展示了小模型變體 (GITB and GITL) 和更大模型 (GIT2) 的結果&lt;/p&gt;
&lt;h3 id=&#34;results-on-image-classification&#34;&gt;Results on Image Classification&lt;/h3&gt;
&lt;p&gt;輸出必須與類別名稱完全匹配，甚至考慮多或少的空格。&lt;/p&gt;
&lt;p&gt;由於不知道詞彙表，精確匹被準確度只有 1.93%，如果預測包含 GT 就對，那有 40.88%。&lt;/p&gt;
&lt;p&gt;通過微調每個類別只有 1 shot 或 5 shot，準確度會顯著提高，
表明只用少量訓練樣本，也可以輕鬆適應下游任務。&lt;/p&gt;
&lt;p&gt;與 Flamingo 相比，GIT 實現更高的準確度。&lt;/p&gt;
&lt;p&gt;Flamingo 在沒有參數更新的情況下進行小樣本學習，但需要額外的網路輸入，可能會增加推理成本。&lt;/p&gt;
&lt;p&gt;相比之下，GIT 透過一次 lightweight fine-tuning，推理過程中不需要這些 training shot。&lt;/p&gt;
&lt;h3 id=&#34;analysis&#34;&gt;Analysis&lt;/h3&gt;
&lt;h4 id=&#34;model-and-data-scaling&#34;&gt;Model and data scaling&lt;/h4&gt;
&lt;p&gt;對於網路架構，作者的模型被稱作 Huge，把 image encoder 換成 CLIP 的 ViT-B/16 和 ViT-L/14 的則是 Base 和 Large。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/microsoft-GIT/fig4.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;可以看出較大的 image encoder 帶來的好處，但根據實驗，
作者發現很難有效地擴展 text decoder，原因可能是 LM 很難用 limited amount of text 來訓練。&lt;/p&gt;
&lt;p&gt;另一個可能的原因是 image encoder 負責 object recognition，而 decoder 負責以 NLP 的方法組織 object terms。
後一項任務可能很容易，因為大多數描述都遵循相似的模式，比如 Object + verb + subject，所以只要一個 small decoder，較大的 decoder 可能會增加學習難度。&lt;/p&gt;
&lt;p&gt;Flamingo 的研究顯示更大的 Decoder 可以提高性能，但是他們的 decoder 有 pretrain 過，而且在 VL 預訓練的時候 frozen，避開了如何有效訓練 decoder 的問題。&lt;/p&gt;
&lt;p&gt;LEMON 的 transformer 可以擴展到 32 層，可能是因為他們使用 MLM 而不是 LM，後者可能更加困難。&lt;/p&gt;
&lt;h4 id=&#34;scene-text-in-pre-training-data&#34;&gt;Scene text in pre-training data&lt;/h4&gt;
&lt;p&gt;為了瞭解 scene text comprehension 的能力，作者檢查了 pretrain data 有多少 image-text pairs 有 scene text。&lt;/p&gt;
&lt;p&gt;作者用 Microsoft Azure OCR API4 對一些資料做 OCR，然後把 OCR 結果和 associated text 做比對，只有包含長度超過 5 個字元的 OCR 結果才會算比對。
有 15% 的 CC12M 和 31% 的下載圖像(500K) 包含 scene text 描述。
由於任務是訓練預測 text，網路逐漸學會閱讀 scene text。&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;h3 id=&#34;limitations&#34;&gt;Limitations&lt;/h3&gt;
&lt;p&gt;根據實驗，目前不清楚如何控制生成的 caption 以及如何在不更新參數的情況下執行 in-context learning，把這留給未來的工作。&lt;/p&gt;
&lt;h3 id=&#34;societal-impact&#34;&gt;Societal impact&lt;/h3&gt;
&lt;p&gt;該模型在大規模數據集上預訓練，不能保證數據不含 toxic language，可能會 poison output。&lt;/p&gt;
&lt;h2 id=&#34;其他&#34;&gt;其他&lt;/h2&gt;
&lt;h3 id=&#34;a3-network&#34;&gt;A.3 Network&lt;/h3&gt;
&lt;p&gt;講超參數&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/microsoft-GIT/model.jpg&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>RoBERTa 論文閱讀</title>
        <link>https://roykesydon.github.io/Blog/p/roberta-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</link>
        <pubDate>Wed, 22 Mar 2023 01:08:46 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/roberta-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</guid>
        <description>&lt;p&gt;paper: &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/1907.11692&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;RoBERTa: A Robustly Optimized BERT Pretraining Approach&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;██████╗  ██████╗ ██████╗ ███████╗██████╗ ████████╗ █████╗
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;██╔══██╗██╔═══██╗██╔══██╗██╔════╝██╔══██╗╚══██╔══╝██╔══██╗
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;██████╔╝██║   ██║██████╔╝█████╗  ██████╔╝   ██║   ███████║
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;██╔══██╗██║   ██║██╔══██╗██╔══╝  ██╔══██╗   ██║   ██╔══██║
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;██║  ██║╚██████╔╝██████╔╝███████╗██║  ██║   ██║   ██║  ██║
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;╚═╝  ╚═╝ ╚═════╝ ╚═════╝ ╚══════╝╚═╝  ╚═╝   ╚═╝   ╚═╝  ╚═╝
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;發現 BERT 訓練不足，並且作者的模型在 4/9 的 GLUE 任務, RACE 和 SQuAD 取得 SOTA。&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;自監督的訓練方法帶來了顯著的性能提升，但要確定這一堆方法中的哪些方面貢獻最大，具備挑戰性。&lt;/p&gt;
&lt;p&gt;訓練的計算量是昂貴的，使 fine-tune 受限，而且通常都是用不同大小的 private training data，使評估模型更加困難。&lt;/p&gt;
&lt;p&gt;作者提出了對 BERT 預訓練的 replication study，包括對超參數的調整，以及對訓練集大小的仔細評估。&lt;/p&gt;
&lt;p&gt;作者發現 BERT 訓練不足，並提出了一種改進方法，稱為 RoBERTa，可以達到或超過所有 post-BERT 的方法。&lt;/p&gt;
&lt;p&gt;修改如下:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;訓練模型的時間更長，batch 更大，用更多 data&lt;/li&gt;
&lt;li&gt;移除 next sentence prediction objective&lt;/li&gt;
&lt;li&gt;訓練更長的序列&lt;/li&gt;
&lt;li&gt;動態地改變用於訓練資料的 masking pattern&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;貢獻:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;提出一組重要的 BERT 設計選擇和訓練策略&lt;/li&gt;
&lt;li&gt;使用了新的 dataset，叫做 CCNEWS，並證明用更多的資料來預訓練，可以提高下游任務的表現&lt;/li&gt;
&lt;li&gt;訓練表明，在正確的設計選擇下，pretrained masked language model 和其他最近的方法比，具有競爭力&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;background&#34;&gt;Background&lt;/h2&gt;
&lt;p&gt;對 BERT 做回顧&lt;/p&gt;
&lt;h3 id=&#34;architecture&#34;&gt;Architecture&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;L layers&lt;/li&gt;
&lt;li&gt;A self-attention heads&lt;/li&gt;
&lt;li&gt;H hidden dimension&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;training-objectives&#34;&gt;Training Objectives&lt;/h3&gt;
&lt;p&gt;預訓練的時候，BERT 有兩個目標: masked language modeling 和 next sentence prediction&lt;/p&gt;
&lt;h4 id=&#34;masked-language-model-mlm&#34;&gt;Masked Language Model (MLM)&lt;/h4&gt;
&lt;p&gt;BERT 隨機選擇 15% 的 token 進行可能的替換&lt;/p&gt;
&lt;p&gt;80% 換成 [MASK]，10% 保持不變，10% 被選為一個隨便的 vocabulary token&lt;/p&gt;
&lt;h4 id=&#34;next-sentence-prediction-nsp&#34;&gt;Next Sentence Prediction (NSP)&lt;/h4&gt;
&lt;p&gt;分類第二句是不是下一句，是二元分類。&lt;/p&gt;
&lt;p&gt;正例由提取連續的句子產生，負例由不同的片段配對產生。&lt;/p&gt;
&lt;p&gt;正例和負例以相等機率產生。&lt;/p&gt;
&lt;h4 id=&#34;optimization&#34;&gt;Optimization&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Adam&lt;/li&gt;
&lt;li&gt;$\beta_1$ = 0.9, $\beta_2$ = 0.999, $\epsilon$ = 1e-6&lt;/li&gt;
&lt;li&gt;$L_2$ weight decay of 0.01&lt;/li&gt;
&lt;li&gt;Learning rate 前 10,000 step warm up 到 1e-4，然後 linear decay&lt;/li&gt;
&lt;li&gt;全部的 layer 和 attention weight 都 dropout 0.1&lt;/li&gt;
&lt;li&gt;GELU 激活函數&lt;/li&gt;
&lt;li&gt;1,000,000 次 update，batch size 256，序列長度 512&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;data&#34;&gt;Data&lt;/h4&gt;
&lt;p&gt;BERT 在 BookCorpus 和 English Wikipedia 混和的資料集上訓練，共有 16GB 的未壓縮文本&lt;/p&gt;
&lt;h2 id=&#34;experimental-setup&#34;&gt;Experimental Setup&lt;/h2&gt;
&lt;p&gt;描述對於 BERT 的 replication study 的實驗設置&lt;/p&gt;
&lt;h3 id=&#34;implementation&#34;&gt;Implementation&lt;/h3&gt;
&lt;p&gt;作者用 FAIRSEQ 重新實現了 BERT。&lt;/p&gt;
&lt;p&gt;主要遵循 [Background-Optimization] 中的 BERT 原始超參數，但 peak learning rate 和 warmup step 除外，他們針對每個設置單獨調整。&lt;/p&gt;
&lt;p&gt;作者發現訓練對 Adam epsilon 非常敏感。&lt;/p&gt;
&lt;p&gt;作者發現設置 $\beta_2$ = 0.98，在大 batch size 的情況下，可以提高訓練時的穩定性。&lt;/p&gt;
&lt;p&gt;用最多 512 個 token 預訓練。&lt;/p&gt;
&lt;p&gt;作者不會隨機注入短序列，也不會為前 90% 的更新縮短輸入的長度。&lt;/p&gt;
&lt;p&gt;作者只訓練 full-length 的 sequences。&lt;/p&gt;
&lt;h3 id=&#34;data-1&#34;&gt;Data&lt;/h3&gt;
&lt;p&gt;BERT-style 的預訓練仰賴大量文本。&lt;/p&gt;
&lt;p&gt;已有研究證明增加數據量可以提高 end-task 的性能。&lt;/p&gt;
&lt;p&gt;已有一些研究，用比原始 BERT 更多樣更大的數據集，但不是所有的數據集都有公開。&lt;/p&gt;
&lt;p&gt;本研究用了五個不同大小和領域的英文文本，共有超過 160 GB 的未壓縮文本。&lt;/p&gt;
&lt;p&gt;使用以下數據集:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;BookCorpus + English Wikipedia
&lt;ul&gt;
&lt;li&gt;BERT 原本使用的。&lt;/li&gt;
&lt;li&gt;16 GB&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;CC-News
&lt;ul&gt;
&lt;li&gt;作者從 CommonCrawl News dataset 的英文部分中蒐集，包含了 2016 年 9 月到 2019 年 2 月的 6300 萬篇英文新聞。&lt;/li&gt;
&lt;li&gt;過濾後有 76 GB&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;OpenWebText
&lt;ul&gt;
&lt;li&gt;WebText 的開源重建版，從 Reddit 上至少有 3 個 upvotes 的 shared URLs 提取出的 Web 內容。&lt;/li&gt;
&lt;li&gt;38 GB&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Stories
&lt;ul&gt;
&lt;li&gt;包含 CommonCrawl data 的一個子集合，經過過濾，以匹配 story-like style of Winograd schemas&lt;/li&gt;
&lt;li&gt;31 GB&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;evaluation&#34;&gt;Evaluation&lt;/h3&gt;
&lt;p&gt;使用以下三個 benchmarks 評估預訓練模型&lt;/p&gt;
&lt;h4 id=&#34;glue&#34;&gt;GLUE&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The General Language Understanding Evaluation&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;用於評估自然語言理解的 9 個數據集的集合，任務被定義為 single-sentence 分類或 sentence-pair 分類任務。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;finetune 的流程遵循原始 BERT paper&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;squad&#34;&gt;SQuAD&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;The Stanford Question Answering Dataset&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;提供一段 context 以及一個問題&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;具有兩個版本 V1.1 和 V2.0&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;V1.1
&lt;ul&gt;
&lt;li&gt;context 總是包含一個答案&lt;/li&gt;
&lt;li&gt;評估 V1.1 的時候，作者採用和 BERT 相同的 span prediction method&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;V2.0
&lt;ul&gt;
&lt;li&gt;一些問題在提供的 context 中沒有回答，使任務更有挑戰性&lt;/li&gt;
&lt;li&gt;評估 V2.0 的時候，作者會用一個額外的二元分類器預測問題是否可以回答，在評估的時候，只預測被分類為可回答的&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;race&#34;&gt;RACE&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;The ReAding Comprehension from Examinations&lt;/li&gt;
&lt;li&gt;大型閱讀理解數據集，有超過 28,000 篇文章 以及將近 100,000 個問題&lt;/li&gt;
&lt;li&gt;從中國的英文考試蒐集的，這些考試是為國中生和高中生設計的&lt;/li&gt;
&lt;li&gt;每篇文章都與多個問題相關聯&lt;/li&gt;
&lt;li&gt;對每個問題，要從四個選項中選出一個對的&lt;/li&gt;
&lt;li&gt;context 比起其他閱讀理解的數據集要長，而且要推理的問題比例很大&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;training-procedure-analysis&#34;&gt;Training Procedure Analysis&lt;/h2&gt;
&lt;p&gt;探討哪些選擇對成功預訓練 BERT 很重要。&lt;/p&gt;
&lt;p&gt;作者把架構固定，也就是訓練和$BERT_{BASE}$ (L=12, H=768, A=12, 110M params)一樣架構的 BERT models&lt;/p&gt;
&lt;h3 id=&#34;static-vs-dynamic-masking&#34;&gt;Static vs. Dynamic Masking&lt;/h3&gt;
&lt;p&gt;BERT 在 preprocessing 的時候處理 masking，產生單個 static mask。
作者為了避免在每個 epoch 都對每個 instance 用相同的 mask，將數據複製了 10 次，在 40 個 epochs 裡，以 10 種不同的方式 mask。所以一次訓練過程中，相同的 mask 會出現四次。&lt;/p&gt;
&lt;p&gt;作者會以上述策略和 Dynamic masking 進行比較，Dynamic masking 是在每次餵 model 前，才生成 mask。&lt;/p&gt;
&lt;p&gt;作者發現 Dynamic Masking 相比 static，要不是差不多，就是略好，基於結果和效率的優勢考量，其他實驗中都用 dynamic masking。&lt;/p&gt;
&lt;h3 id=&#34;model-input-format-and-next-sentence-prediction&#34;&gt;Model Input Format and Next Sentence Prediction&lt;/h3&gt;
&lt;p&gt;原始的 BERT 預訓練中，兩個句子要不是同一個文件的連續句子(p = 0.5)，不然就是不同的 document 做採樣&lt;/p&gt;
&lt;p&gt;以往有研究指出移除 NSP 會損害性能，但也有研究質疑必要性，所以本文比較了幾種替代訓練格式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SEGMENT-PAIR+NSP
&lt;ul&gt;
&lt;li&gt;最原始的方法，每個 segment 可以有多個自然句子&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;SENTENCE-PAIR+NSP
&lt;ul&gt;
&lt;li&gt;只包含一對句子，由於輸入明顯少於 512 token，所以會增加 batch size 讓 token 總數和前者差不多&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;FULL-SENTENCES
&lt;ul&gt;
&lt;li&gt;包含從一個或多個文件中連續採樣的完整句子，可能會跨越文件邊界，在文件邊界間會加個額外的分隔符&lt;/li&gt;
&lt;li&gt;移除了 NSP&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;DOC-SENTENCES
&lt;ul&gt;
&lt;li&gt;和 FULL-SENTENCES 差不多，但不能跨越 document，在 document 尾巴的部分會容易少於 512，所以會動態增加 batch size，讓 token 總數和 FULL-SENTENCES 差不多&lt;/li&gt;
&lt;li&gt;移除了 NSP&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/RoBERTa/table2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;發現 DOC-SENTENCES 是最棒的，但由於 DOC-SENTENCES 會讓 batch sizes 大小可變，所以其他實驗會用 FULL-SENTENCES，比較好和其他相關工作比較。&lt;/p&gt;
&lt;h3 id=&#34;training-with-large-batches&#34;&gt;Training with large batches&lt;/h3&gt;
&lt;p&gt;根據過去神經網路機器翻譯的工作，當 learning rate 適當增加的時候，用非常大的的 mini-bathces 可以提高 optimization 的速度和 end-task 性能。&lt;/p&gt;
&lt;p&gt;最近的研究也顯示 BERT 適用於 large batch training。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/RoBERTa/table3.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;text-encoding&#34;&gt;Text Encoding&lt;/h3&gt;
&lt;p&gt;Byte-Pair Encoding (BPE) 是一種介於字符級別和詞級別表示之間的混合表示方法，它允許處理自然語言語料庫中常見的大詞彙量。&lt;/p&gt;
&lt;p&gt;BPE 不依賴於完整的單詞，而是依靠 subwords units，通過對訓練語料進行統計分析來提取這些 subwords units。&lt;/p&gt;
&lt;p&gt;BPE 詞彙表的大小通常在 10K-100K 的 subword units。&lt;/p&gt;
&lt;p&gt;在 &amp;ldquo;Language Models are Unsupervised Multitask Learners&amp;rdquo; 文中，提到了一種巧妙的 BPE 實現，不是用 unicode characters，而是用 bytes 作為 base subword units。可以生出 50K 大小的詞彙表，而且不用引入任何的 &amp;ldquo;unknown&amp;rdquo;。&lt;/p&gt;
&lt;p&gt;原始的 BERT 用 character-level BPE vocabulary，大小為 30K。&lt;/p&gt;
&lt;p&gt;本文考慮用 50K byte-level BPE vocabulary，而不對輸入做額外的 preprocessing 或 tokenization，&amp;ldquo;Language Models are Unsupervised Multitask Learners&amp;rdquo; 的研究顯示這些 Encoding 的方法在最終效能上並無太大差別，只在某些任務上 end-task performance 表現稍差。&lt;/p&gt;
&lt;p&gt;但作者相信 universal encoding scheme 的優勢超過了輕微的性能下降，其他實驗也會用這種邊碼方式。&lt;/p&gt;
&lt;h2 id=&#34;roberta&#34;&gt;RoBERTa&lt;/h2&gt;
&lt;p&gt;整理上面說的改進。&lt;/p&gt;
&lt;p&gt;RoBERTa 用以下配置:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;dynamic masking&lt;/li&gt;
&lt;li&gt;FULL-SENTENCES without NSP loss&lt;/li&gt;
&lt;li&gt;large mini-batches&lt;/li&gt;
&lt;li&gt;larger byte-level BPE&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;此外，還調查了兩個之前的工作沒強調的重要因素:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;用於預訓練的 data&lt;/li&gt;
&lt;li&gt;訓練過 data 的次數&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;為了把這些因素的重要性和其他模型選擇分隔開，先按照 $BERT_{LARGE}$ (L = 24, H = 1024, A = 16, 355M parameters) 訓練 RoBERTa。&lt;/p&gt;
&lt;p&gt;作者在 BOOKCORPUS plus WIKIPEDIA dataset 進行了 100K step 的預訓練。&lt;/p&gt;
&lt;p&gt;在控制 training data 的情況下， RoBERTa 比 $BERT_{LARGE}$ 的結果有大幅度的改進，重申了前面設計選擇的重要性。&lt;/p&gt;
&lt;p&gt;接下來，結合之前說的額外 dataset，並用相同的步數(100K) 訓練 RoBERTa，觀察到下游任務的性能進一步提高，驗證了數據大小和多樣性的重要性。&lt;/p&gt;
&lt;p&gt;最後，對 RoBERTa 做更長時間的預訓練，將步數提高到 300K 和 500K，再次觀察到下游任務性能顯著提升。&lt;/p&gt;
&lt;p&gt;作者也注意到，即使是他們訓練時間最長的模型，也不會 overfit 他們的數據。&lt;/p&gt;
&lt;p&gt;本文的其他部分在三個 benchmark 評估好壞: GLUE、SQuaD 和 RACE&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/RoBERTa/table4.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;glue-results&#34;&gt;GLUE Results&lt;/h3&gt;
&lt;p&gt;雖然很多 GLUE 排行榜的提交都是 depend on multi-task finetuning，但作者的 submission 是 depends only on single-task finetuning。&lt;/p&gt;
&lt;p&gt;此外，對於 RTE、STS 和 MRPC，從 MNLI 的模型微調會比 baseline 的 RoBERTa 有幫助許多。&lt;/p&gt;
&lt;p&gt;在第一個設置 (single-task, dev) 中，RoBERTa 在所有 9 個 GLUE 任務 dev set 上都取得了最先進的結果。&lt;/p&gt;
&lt;p&gt;在第二個設置 (ensembles, test) 中，作者將 RoBERTa 提交到 GLUE 排行榜，並在 9 個任務中的 4 個上取得了 SOTA 和迄今為止的最高平均分。&lt;/p&gt;
&lt;p&gt;這令人興奮的地方在於，與多數 top submissions 不同，RoBERTa 不是 depend on multi-tasking finetuning&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/RoBERTa/table5.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;在預訓練 BERT 模型時，作者仔細評估了許多設計決策。&lt;/p&gt;
&lt;p&gt;作者發現，通過對模型進行更長時間的訓練、使用更大的批次處理更多的數據、去除 NSP、訓練更長的序列、dynamic masking，可以顯著提高性能。&lt;/p&gt;
&lt;p&gt;作者改進的預訓練程序，我們稱之為 RoBERTa，在 GLUE、RACE 和 SQuAD 上實現了 SOTA，而無需為 GLUE 進行多任務微調或為 SQuAD 提供額外的數據。&lt;/p&gt;
&lt;p&gt;這些結果說明了這些以前被忽視的設計決策的重要性，並表明 BERT 的預訓練目標與最近提出的替代方案相比仍然具有競爭力。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>ARM 組合語言介紹</title>
        <link>https://roykesydon.github.io/Blog/p/arm-%E7%B5%84%E5%90%88%E8%AA%9E%E8%A8%80%E4%BB%8B%E7%B4%B9/</link>
        <pubDate>Tue, 21 Mar 2023 01:32:54 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/arm-%E7%B5%84%E5%90%88%E8%AA%9E%E8%A8%80%E4%BB%8B%E7%B4%B9/</guid>
        <description>&lt;h2 id=&#34;開發環境&#34;&gt;開發環境&lt;/h2&gt;
&lt;h3 id=&#34;ide&#34;&gt;IDE&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;SW4STM32
&lt;ul&gt;
&lt;li&gt;支援 STM32&lt;/li&gt;
&lt;li&gt;GCC C/C++ compiler&lt;/li&gt;
&lt;li&gt;GDB-based debugger&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;板子&#34;&gt;板子&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;STM32 Bucleo Board
&lt;ul&gt;
&lt;li&gt;Cortex-M4&lt;/li&gt;
&lt;li&gt;ST-LINK
&lt;ul&gt;
&lt;li&gt;debugger&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Memories
&lt;ul&gt;
&lt;li&gt;1MB Flash&lt;/li&gt;
&lt;li&gt;128KB SRAM&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;debug-interface&#34;&gt;Debug Interface&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;JTAG
&lt;ul&gt;
&lt;li&gt;Joint Test Action Group&lt;/li&gt;
&lt;li&gt;standard ASICs hardware debug interface&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;SWD
&lt;ul&gt;
&lt;li&gt;Serial Wire Debug&lt;/li&gt;
&lt;li&gt;只從 JTAG 用 5 wires&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;bootup-code&#34;&gt;Bootup Code&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Reset&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Boot Loader&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;0x00000000 的程式&lt;/li&gt;
&lt;li&gt;把 CPU 重置&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Reset handler&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ststem initialization&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;C startup code&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Application(main)&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;memory-map&#34;&gt;Memory map&lt;/h2&gt;
&lt;p&gt;見官網 memory map&lt;/p&gt;
&lt;p&gt;只用到 SRAM 的 128KB(SRAM)，還有 Code 的 1MB(Flash)&lt;/p&gt;
&lt;h2 id=&#34;sections&#34;&gt;Sections&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;.data
&lt;ul&gt;
&lt;li&gt;儲存資料&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;.text
&lt;ul&gt;
&lt;li&gt;儲存程式碼&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;同 section 會放在一塊是為了設定 read-only 方便，比如 .text 的要靠硬體實現 read-only&lt;/p&gt;
&lt;h2 id=&#34;重要的額外文件&#34;&gt;重要的額外文件&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Linker Script
&lt;ul&gt;
&lt;li&gt;定義了不同 section 該存放的地方，以及 memory 相關定義&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;33
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;34
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;35
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;36
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;MEMORY
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    RAM (xrw)		: ORIGIN = 0x20000000, LENGTH = 96K
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    ROM (rx)		: ORIGIN = 0x8000000, LENGTH = 1024K
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;SECTIONS
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;/* The program code and other data into ROM memory */
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;.text :
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    . = ALIGN(8);
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    *(.text)           /* .text sections (code) */
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    *(.text*)          /* .text* sections (code) */
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    *(.glue_7)         /* glue arm to thumb code */
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    *(.glue_7t)        /* glue thumb to arm code */
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    *(.eh_frame)
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    KEEP (*(.init))
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    KEEP (*(.fini))
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    . = ALIGN(8);
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    _etext = .;        /* define a global symbols at end of code */
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;} &amp;gt;ROM
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;.data : 
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;{
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    . = ALIGN(8);
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    _sdata = .;        /* create a global symbol at data start */
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    *(.data)           /* .data sections */
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    *(.data*)          /* .data* sections */
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    . = ALIGN(8);
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    _edata = .;        /* define a global symbol at data end */
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;} &amp;gt;RAM AT&amp;gt; ROM
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;li&gt;Make File
&lt;ul&gt;
&lt;li&gt;描述如何編譯和連接的規則&lt;/li&gt;
&lt;li&gt;把 startup 的 .s檔加進去&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;startup_stm32.s
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;編譯好後擺在 binary 頭的地方&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;vector table&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;/******************************************************************************
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;*
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;* The STM32L476RGTx vector table.  Note that the proper constructs
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;* must be placed on this to ensure that it ends up at physical address
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;* 0x0000.0000.
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;*
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;******************************************************************************/
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;.section .isr_vector,&amp;#34;a&amp;#34;,%progbits
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;.type g_pfnVectors, %object
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;.size g_pfnVectors, .-g_pfnVectors
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;g_pfnVectors:
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;.word _estack
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;.word Reset_Handler
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;.word NMI_Handler
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;.word HardFault_Handler
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;.word	MemManage_Handler
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;.word	BusFault_Handler
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;.word	UsageFault_Handler
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;.word	0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;.word	0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;.word	0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;.word	0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;.word	SVC_Handler
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;Reset_Handler
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt; 1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 8
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt; 9
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;10
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;11
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;12
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;13
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;14
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;15
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;16
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;17
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;18
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;19
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;20
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;21
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;22
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;23
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;24
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;25
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;26
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;27
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;28
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;29
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;30
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;31
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;32
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Reset_Handler:
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    ldr   r0, =_estack
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    mov   sp, r0          /* set stack pointer */
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    /* Copy the data segment initializers from flash to SRAM */
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    ldr r0, =_sdata
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    ldr r1, =_edata
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    ldr r2, =_sidata
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    movs r3, #0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    b LoopCopyDataInit
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;LoopCopyDataInit:
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    adds r4, r0, r3
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    cmp r4, r1
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    bcc CopyDataInit
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    /* Zero fill the bss segment. */
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    ldr r2, =_sbss
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    ldr r4, =_ebss
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    movs r3, #0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    b LoopFillZerobss
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;LoopFillZerobss:
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    cmp r2, r4
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    bcc FillZerobss
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    /* Call the clock system intitialization function.*/
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    bl  SystemInit
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    /* Call static constructors */
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    bl __libc_init_array
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    /* Call the application&amp;#39;s entry point.*/
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    bl main
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;arm-register&#34;&gt;ARM Register&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ARM 的可存取暫存器為 R0-R15&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;r13: Stack Pointer&lt;/li&gt;
&lt;li&gt;r14: Link Register&lt;/li&gt;
&lt;li&gt;r15: Program Counter&lt;/li&gt;
&lt;li&gt;r0~r7 是 low register r8~r15 是 high register&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;狀態暫存器&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CPSR (Current Processor Status Register)
&lt;ul&gt;
&lt;li&gt;用來儲存各種狀態，包含 condition flag，比如 negative, zero, carry, overflow
&lt;ul&gt;
&lt;li&gt;carry: 無符號加法操作是否溢出&lt;/li&gt;
&lt;li&gt;overflow: 有符號加法操作是否溢出&lt;/li&gt;
&lt;li&gt;當兩個都為 1 或都為 0 代表運算沒問題&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;有多種模式，有些模式有自己獨立的 r 暫存器，並有 SPSR，用來在中斷發生時，把 CPSR 的資訊 copy 過去&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Special-purpose registers&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;APSR, IPSR, EPSR&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;assembly-syntax&#34;&gt;Assembly syntax&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;UAL: Unified Assembler Language&lt;/li&gt;
&lt;li&gt;自己去翻 instruction set&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;instructions-class&#34;&gt;Instructions class&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Branch instructions
&lt;ul&gt;
&lt;li&gt;B, BL, BX,&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Data-processing instructions
&lt;ul&gt;
&lt;li&gt;MOV, ADD, SUB, MUL,&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Load and store instructions
&lt;ul&gt;
&lt;li&gt;LDR, STR,&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Status register access instructions
&lt;ul&gt;
&lt;li&gt;MSR, MRS,&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Miscellaneous instructions
&lt;ul&gt;
&lt;li&gt;Memory Barrier instructions&lt;/li&gt;
&lt;li&gt;Exception-Related instructions&lt;/li&gt;
&lt;li&gt;Pseudo instructions&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;examples&#34;&gt;examples&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;MOVS R0, #0x12&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;R0=0x12&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;MOVS R1, #`A` &lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;R1=A(ASCII)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;NVIC_IRQ_SETEN  EQU  0xE000E100&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;宣告常數 NVIC_IRQ_SETEN，賦值 0xE000E100&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;LDR R0,=NVIC_IRQ_SETEN&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;放 0xE000E100 進 R0&lt;/li&gt;
&lt;li&gt;這不能改成 &lt;code&gt;MOVS R0, #0xE000E100 &lt;/code&gt;，因為每個 instruction 只有 32 個 bits，這勢必塞不下，必須從記憶體 load 進來&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;NVIC_IRQ0_ENABLE  EQU  0x1&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;宣告常數 NVIC_IRQ0_ENABLE，賦值 0x1&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;MOVS R1, #NVIC_IRQ0_ENABLE&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;R1=0x1&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;STR R1, [R0]&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;把 0x1 存到 0xE000E100，這裡可以 enable external interrupt IRQ#0&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;LDR rn [pc, #offset to literal pool]&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;load register n with one word from the address [pc + offset]&lt;/li&gt;
&lt;li&gt;最後的形式&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;operand2&#34;&gt;Operand2&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;共有 12 bits
&lt;ul&gt;
&lt;li&gt;設計成 4 bits for rotate, 8 bits for Immediate&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;arm-instrcution-formats&#34;&gt;ARM instrcution formats&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;ADD vs ADDS
&lt;ul&gt;
&lt;li&gt;有 S 代表會去更新 status&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;cond
&lt;ul&gt;
&lt;li&gt;根據之前的執行情況，判斷指令要不要執行&lt;/li&gt;
&lt;li&gt;suffix&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;reverse-ordering-operations&#34;&gt;Reverse Ordering Operations&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;REV (Byte-Reverse Word)
&lt;ul&gt;
&lt;li&gt;把 4 個 Byte 全數反轉，用在一個是 Little-Endian 一個是 Big-Endian 的情況&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;load-and-store-instructions&#34;&gt;Load and Store Instructions&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;examples
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;LDR r0, [r1]&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;r0 = [r1]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;LDM r0, {r1, r2}&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;r1 = [r0]&lt;/li&gt;
&lt;li&gt;r2 = [r0+4]&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;STM r0, {r1, r2}&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;[r0] = r1&lt;/li&gt;
&lt;li&gt;[r0+4] = r2&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;status-register-access-instructions&#34;&gt;Status Register Access Instructions&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;一般來說不太會用到，因為用 suffix 就可以看條件&lt;/li&gt;
&lt;li&gt;MRS: Register = Status Register
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;MRS r0, IPSR&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;MSR: Status Register = Register
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;MSR APSR, r0&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;if-then-else&#34;&gt;If-Then-Else&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;用 CMP 和 conditional branches&lt;/li&gt;
&lt;li&gt;Example
&lt;ul&gt;
&lt;li&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  CMP R0, #10   ;compare r0 to 10
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  BLE incr_counter ; if less or equal, then branch to incr_counter
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;branch-instructinos&#34;&gt;Branch Instructinos&lt;/h3&gt;
&lt;p&gt;能跳的距離受限於 operand 長度&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;B-Branch
&lt;ul&gt;
&lt;li&gt;能跳 PC 的 +/- 2046 bytes&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;BL-Branch and Link
&lt;ul&gt;
&lt;li&gt;能跳 PC 的 +/- 254 bytes&lt;/li&gt;
&lt;li&gt;Branch to subroutine 的時候，會把下一行指令放到 Link register&lt;/li&gt;
&lt;li&gt;沒有 push 到 stack，所以要特別小心，register 是共用的，
可能要視情況自己放到 stack
&lt;ul&gt;
&lt;li&gt;比如要進兩層 function，可以用 &lt;code&gt;push {r4-r6, LR}&lt;/code&gt; 和 &lt;code&gt;POP {R4-R6, PC}&lt;/code&gt; 這種做法來保留參數&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;BX-Branch and exchange
&lt;ul&gt;
&lt;li&gt;return&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;stack-memory-access&#34;&gt;Stack memory access&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;PUSH&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SP = SP - N*4&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;POP&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SP = SP + N*4&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ascending/Descending&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;stack 往哪個方向長&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Empty/Full&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;stack 指向下一個空的位置，還是最後一個 item&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;預設且常見的是 fully descending&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;STM 和 LDM 可以透過 suffix 來存到 stack&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;example
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;STMFD r13!, {r4-r7}&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;把 r4 到 r7 push 到 stack&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;memory-barrier-instructions&#34;&gt;Memory Barrier Instructions&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;DMB, SDB, ISB&lt;/li&gt;
&lt;li&gt;在下個指令前 sync memory data&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;function-call-and-parameter-passing&#34;&gt;Function Call and Parameter Passing&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;caller 和 callee 誰負責 backup 和 restore
&lt;ul&gt;
&lt;li&gt;caller 負責
&lt;ul&gt;
&lt;li&gt;不管 callee 怎樣亂搞都行&lt;/li&gt;
&lt;li&gt;但不知道 callee 要用哪些參數，全 backup 可能多此一舉&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;怎麼傳遞參數給 callee
&lt;ul&gt;
&lt;li&gt;常放在 stack，但這樣要透過 memory，相較 register 慢&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;怎麼 return value 給 caller
&lt;ul&gt;
&lt;li&gt;和上個問題差不多&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;arm-procedure-call-standard&#34;&gt;ARM Procedure Call Standard&lt;/h3&gt;
&lt;p&gt;又稱 APCS，講不同的 register 的一種使用規範&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;r0-r3 用來當參數和回傳&lt;/li&gt;
&lt;li&gt;r4-r11 用來 local variable，callee 使用前可以先 backup&lt;/li&gt;
&lt;li&gt;r12-r15 特殊用途，沒事別亂動&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>PatentSBERTa 論文閱讀</title>
        <link>https://roykesydon.github.io/Blog/p/patentsberta-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</link>
        <pubDate>Wed, 15 Mar 2023 15:08:46 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/patentsberta-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</guid>
        <description>&lt;p&gt;paper: &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2103.11933&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PatentSBERTa: A Deep NLP based Hybrid Model for Patent Distance and Classification using Augmented SBERT&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;本研究提供了一個計算  patent-to-patent (p2p) technological similarity 的有效方法。&lt;/p&gt;
&lt;p&gt;並提出一個 hybrid framework，用於把 p2p 相似性的結果應用於 semantic search 和 automated patent classification。&lt;/p&gt;
&lt;p&gt;把 Sentence-BERT (SBERT) 用在 claims 上來作 embeddings。&lt;/p&gt;
&lt;p&gt;為了進一步提升 embedding 的品質，使用基於 SBERT 和 RoBERT 的 transformer model，然後再用 augmented approach 在  in-domain supervised patent claims data(相對於 out-domain) 來 fine-tune SBERT。&lt;/p&gt;
&lt;p&gt;用 KNN(Nearest Neighbors) 來根據 p2p similarity 分類模型。&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;傳統上的 p2p 相似度是基於關鍵字、技術類別等 metadata 決定的，但近期 semantic-based 的方法也越來越受歡迎。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;目前遇到的問題
&lt;ol&gt;
&lt;li&gt;BERT 用來計算 p2p 相似性的成本很高&lt;/li&gt;
&lt;li&gt;基於 generic text 的 pre-trained model 在遇到特定領域的專業術語時可能會遇到侷限。&lt;/li&gt;
&lt;li&gt;在專利做 multi-label classification (MLC) 是個挑戰&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;貢獻
&lt;ol&gt;
&lt;li&gt;提供一個快速高效的框架，利用 Transformer 架構計算 p2p 相似度&lt;/li&gt;
&lt;li&gt;透過 augmented SBERT，將 transformer model fine-tune 到 domain-specific language&lt;/li&gt;
&lt;li&gt;提出一個基於 Transformer 和 傳統 ML 模型的混和架構，可以打敗 multi-label 和 multi-class 的專利分類 SOTA 模型&lt;/li&gt;
&lt;li&gt;用簡單的 KNN 進行專利分類，提供了一種簡單的方法來檢查、理解和解釋模型的預測結果&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;data&#34;&gt;Data&lt;/h2&gt;
&lt;h3 id=&#34;dataset-description&#34;&gt;Dataset Description&lt;/h3&gt;
&lt;p&gt;本研究使用 PatentsView dataset，PatentsView 平台建立在一個定期更新的 database 上。&lt;/p&gt;
&lt;p&gt;dataset 已用於之前類似的研究，比如 DeepPatent、PatentBERT。&lt;/p&gt;
&lt;p&gt;本研究使用了 2013-2017 的所有專利，這些專利至少要在 BigQuery 上有一條 claim。&lt;/p&gt;
&lt;p&gt;本研究的 record 有 1,492,294 項專利，並用 8% 作為測試集。&lt;/p&gt;
&lt;p&gt;此外，本研究刪除了有重複專利 ID 和 claim text 的 record。&lt;/p&gt;
&lt;h3 id=&#34;textual-data-patent-claims&#34;&gt;Textual Data: Patent Claims&lt;/h3&gt;
&lt;p&gt;本研究使用 claim 作為輸入。&lt;/p&gt;
&lt;p&gt;claim 被認為是準備專利文件的初始框架，其他文件都是根據 claim 準備的，
因此，claim 比其他文件包含更全面和準確的訊息。&lt;/p&gt;
&lt;p&gt;claim 具有層次結構，first claim 被視為該架構的主幹。&lt;/p&gt;
&lt;p&gt;本研究僅使用 first claim，但在以後的研究中，希望根據 tree structure 組合所有 claim，並計算 semantic similarity，並做多標籤分類。&lt;/p&gt;
&lt;p&gt;在研究樣本中， claim 平均有 17 個。&lt;/p&gt;
&lt;p&gt;claim 的平均長度是 162，本研究中，BERT 的 max_seq_length 是 510。&lt;/p&gt;
&lt;h3 id=&#34;patent-classification-cpc-classes&#34;&gt;Patent Classification: CPC Classes&lt;/h3&gt;
&lt;p&gt;CPC系統和IPC（國際專利分類）系統是最常用的兩種分類系統，CPC 是 IPC 系統的更具體和詳細的版本。&lt;/p&gt;
&lt;p&gt;CPC 具有用於分類的層次結構，包括 Section、Class、Subclass 和 Group，
在子類級別，CPC 有 667 個標籤。&lt;/p&gt;
&lt;p&gt;在數據集中我們有 663 個標籤，其中 159 個在數據集中的樣本少於 350 個，這種標籤分佈導致了 KNN 不好處理，一般來說，隨著 instance 數量的增加，我們可以提高模型的準確性。&lt;/p&gt;
&lt;h2 id=&#34;method-and-experimental-setup&#34;&gt;Method and experimental setup&lt;/h2&gt;
&lt;p&gt;Pretrained Language Models (LMs) 在 NLP 中變得十分流行。&lt;/p&gt;
&lt;p&gt;在 pairwise sentence semantic similarity，SBERT 和 BERT 是兩種具有顯著不同效果的方法。&lt;/p&gt;
&lt;p&gt;BERT 通常可以取得更好的性能，但在實際應用上來說太慢了。&lt;/p&gt;
&lt;p&gt;SBERT 在實際應用上表現還行，但需要 in-domain training data 並且 finetune。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/PatentSBERTa/Bi_vs_Cross-Encoder.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/PatentSBERTa/approach.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;上圖是 Augmented SBERT In-domain approach。&lt;/p&gt;
&lt;p&gt;in-domain sentence pairs 透過 cross-encoder 來標記，假設有 n 個 in-domain sentences，會有 $C_2^n$ 組可能的組合。&lt;/p&gt;
&lt;p&gt;使用所有可能的組合並不會提高性能，所以要有正確的採樣策略，才可提升性能的同時也減少計算開銷。&lt;/p&gt;
&lt;p&gt;上圖那種結合 cross-encoder 和 bi-encoder 的作法被稱為 Augmented SBERT (AugSBERT)，
涉及以下三個步驟:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;用資料集 Fine-tune RoBERTa 以生出 cross-encoder&lt;/li&gt;
&lt;li&gt;用 cross-encoder 來把未標記的資料標記，同時基於某種特定的採樣策略，從 652,653 種可能的組合中挑選 3432 組&lt;/li&gt;
&lt;li&gt;把資料集 + 額外的 3432 組資料一起拿來訓練 SBERT&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;results&#34;&gt;Results&lt;/h2&gt;
&lt;h3 id=&#34;p2p-similarity-and-semantic-search&#34;&gt;P2P similarity and semantic search&lt;/h3&gt;
&lt;p&gt;Patent Semantic Search (PSS) 是專利分析的基礎部分。&lt;/p&gt;
&lt;p&gt;Transformer 模型等語義相似性的解法是一種新解法，可以用來解決基於關鍵字的搜尋方法中， query terms 和專利內容不匹配的問題。&lt;/p&gt;
&lt;p&gt;為了評估模型的準確性，未來的研究中，作者希望通過 Mean Reciprocal Rank (MRR) 來評估分類結果。&lt;/p&gt;
&lt;h3 id=&#34;cpc-prediction&#34;&gt;CPC Prediction&lt;/h3&gt;
&lt;p&gt;Top-N 準確度等於 GT 與預測有最高概率的任何 N 個預測匹配的頻率，
所以 Top-5 就是最高的五個分類中一個就有中。&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;本文使用  augmented SBERT  獲得 SOTA 的專利文本 embedding。&lt;/p&gt;
&lt;p&gt;介紹了一種 augmented 的方法，把 SBERT 微調到適合 patent claims 的 domain。&lt;/p&gt;
&lt;p&gt;SBERT 的一個主要優點是可以有效率地獲得 embedding distance，使我們能夠為大的專利資料集建構 p2p similarity。&lt;/p&gt;
&lt;p&gt;雖然基於文本的 p2p similarity 的有用性已經在各種應用方面得到證明，但本文進一步證明作者的 transformer-based p2p similarity 可以被用在 SOTA 的專利分類。&lt;/p&gt;
&lt;p&gt;而且使用簡單的 KNN 方法，檢查他們可以使模型決策具備 understandable 和 explainable。&lt;/p&gt;
&lt;h2 id=&#34;limitations--future-research&#34;&gt;Limitations &amp;amp; Future Research&lt;/h2&gt;
&lt;p&gt;未來希望用 Annoy(Approximate Nearest Neighbor Oh Yeah!) 來測試更大樣本的模型並比較結果。&lt;/p&gt;
&lt;p&gt;Annoy(Approximate Nearest Neighbor Oh Yeah!) 是想尋找近似相似而不是精確相似的句子。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Database Normalization</title>
        <link>https://roykesydon.github.io/Blog/p/database-normalization/</link>
        <pubDate>Tue, 14 Mar 2023 10:26:17 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/database-normalization/</guid>
        <description>&lt;h2 id=&#34;normalization-目的&#34;&gt;Normalization 目的&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;避免 redundent information&lt;/li&gt;
&lt;li&gt;更容易 understand、enhance、extend&lt;/li&gt;
&lt;li&gt;避免 anomalies&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;隨著 1NF ~ 5NF，有更多的 safety guarantee&lt;/p&gt;
&lt;h2 id=&#34;1nf&#34;&gt;1NF&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;違反條件
&lt;ul&gt;
&lt;li&gt;用 row order 傳達資訊&lt;/li&gt;
&lt;li&gt;mixing data types in single column
&lt;ul&gt;
&lt;li&gt;但 relational database 不會讓你這樣做&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;存在沒有 primary key 的 table&lt;/li&gt;
&lt;li&gt;repeating groups
&lt;ul&gt;
&lt;li&gt;同一個 column 有多個數值，或是在同一個 row 存多個同類型的數值。&lt;/li&gt;
&lt;li&gt;ex :
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;player&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;item&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;roy&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;1 item_1, 4 item_2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;star&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;4 item_4&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;player&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;item_type1&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;quantity1&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;item_type2&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;quantity2&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;roy&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;item1&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;1&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;item2&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;4&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;star&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;item_4&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;4&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;2nf&#34;&gt;2NF&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;所有的 non-key attribute 都要 depend on 整個 PK
&lt;ul&gt;
&lt;li&gt;非正式定義，有點細微差異&lt;/li&gt;
&lt;li&gt;functional dependency
&lt;ul&gt;
&lt;li&gt;ex: {player_id, item_type} -&amp;gt; {item_Quantity}&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;3nf&#34;&gt;3NF&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;transitive dependency
&lt;ul&gt;
&lt;li&gt;{A} -&amp;gt; {B} -&amp;gt; {C}&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;所有 non-key attribute 都要 depend on the whole key，不能 depend on 其他 non-key attribute&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;boyce-codd-normal-form&#34;&gt;Boyce-Codd Normal Form&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;所有 attribute 都要 depend on the whole key，不能 depend on 其他 non-key attribute&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;4nf&#34;&gt;4NF&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;multivalued dependency
&lt;ul&gt;
&lt;li&gt;不像 functional dependency，箭頭後方的那項可以有多個 value&lt;/li&gt;
&lt;li&gt;{Model} $\twoheadrightarrow$ {Color}&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;一個 table 中的所有 multivalued dependency 必須依賴於 key&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;5nf&#34;&gt;5NF&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;沒有 Join Dependency
&lt;ul&gt;
&lt;li&gt;table 不能表示成其他 table join 起來的結果&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Sentence-BERT 論文閱讀</title>
        <link>https://roykesydon.github.io/Blog/p/sentence-bert-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</link>
        <pubDate>Sun, 12 Mar 2023 10:08:46 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/sentence-bert-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</guid>
        <description>&lt;p&gt;paper: &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/1908.10084&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;BERT 和 RoBERTa 在 semantic textual similarity (STS) 上太花時間，因為他需要將兩個句子都輸入網路，並且兩兩比對。&lt;/p&gt;
&lt;p&gt;Sentence-BERT(SBERT) 對預訓練的 BERT 作了一些修改，透過 siamese 和 triplet network 的結構來生出有意義的 embeddings，使其最後可以透過 cosine-similarity 比較相似度。&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;SBERT 使 BERT 可以用於某些迄今為止不適用於 BERT 的任務，比如 large-scale semantic similarity comparison、clustering 還有 information retrieval via semantic search。&lt;/p&gt;
&lt;p&gt;以往的相關研究是把單個句子輸入 BERT，最後 average BERT output layer，或是使用第一個 output，但這樣會產生糟糕的 sentence embeddings。&lt;/p&gt;
&lt;p&gt;SentEval 是一個 evaluation toolkit for sentence embeddings&lt;/p&gt;
&lt;h2 id=&#34;related-work&#34;&gt;Related Work&lt;/h2&gt;
&lt;p&gt;BERT 透過輸入兩個句子，以 [SEP] 隔開，可以在 STS 取得 SOTA。&lt;/p&gt;
&lt;p&gt;但這樣無法計算獨立的 sentence embedding，所以過往的研究人員把單個句子輸入 BERT，最後 average BERT output layer，或是使用第一個 output。&lt;/p&gt;
&lt;h2 id=&#34;model&#34;&gt;Model&lt;/h2&gt;
&lt;p&gt;SBERT 在 BERT / RoBERTa 的輸出中添加了 pooling，作者嘗試了三種策略，CLS-token 的輸出、所以輸出向量的平均、max-over-time of the output vectors，默認是 MEAN。&lt;/p&gt;
&lt;p&gt;實驗以下結構和目標函數:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Classification Objective Function&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/SBERT/COF-1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/SBERT/COF-2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Regression Objective Function&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;用 mean squared-error loss&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/SBERT/ROF.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;
&lt;p&gt;Triplet Objective Function&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/SBERT/TOF.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;training-details&#34;&gt;Training Details&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Dataset
&lt;ul&gt;
&lt;li&gt;SNLI 結合 Multi-Genre NLI
&lt;ul&gt;
&lt;li&gt;SNLI: 570,000 個 句子 pair，有三類，contradiction, eintailment, and neutral&lt;/li&gt;
&lt;li&gt;MultiNLI: 430,000 個句子 pair&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;3-way softmax Classification Objective Function&lt;/li&gt;
&lt;li&gt;1-epoch&lt;/li&gt;
&lt;li&gt;batch-size: 16&lt;/li&gt;
&lt;li&gt;Adam&lt;/li&gt;
&lt;li&gt;lr: 2e-5&lt;/li&gt;
&lt;li&gt;warm-up: 超過 10% of the training data&lt;/li&gt;
&lt;li&gt;默認 pooling 策略: MEAN&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;evaluation&#34;&gt;Evaluation&lt;/h2&gt;
&lt;p&gt;學習一個複雜的回歸函數分析 STS 常是 SOTA，但是由於他是 pair-wise，遇到 combinatorial explosion，不好拓展。&lt;/p&gt;
&lt;p&gt;本文用 cosine-similarity 比較兩個 embeddings 的相似度，也用 negative Manhatten 和 negative Euclidean distances，但得到差不多的結果。&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;用 BERT 生出的 embeddings 不適合常見的相似度測量方法，比如 cosine-similarity。&lt;/p&gt;
&lt;p&gt;本文提出 SBERT 改進，在 siamese / triplet 網路架構中微調 BERT。&lt;/p&gt;
&lt;p&gt;用 RoBERTa 替換掉 BERT 並沒有什麼顯著改進。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>軟體設計 - Low Level</title>
        <link>https://roykesydon.github.io/Blog/p/%E8%BB%9F%E9%AB%94%E8%A8%AD%E8%A8%88-low-level/</link>
        <pubDate>Wed, 08 Mar 2023 14:26:17 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/%E8%BB%9F%E9%AB%94%E8%A8%AD%E8%A8%88-low-level/</guid>
        <description>&lt;h2 id=&#34;uml-類別圖&#34;&gt;UML 類別圖&lt;/h2&gt;
&lt;h3 id=&#34;relationship&#34;&gt;Relationship&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Dependency
&lt;ul&gt;
&lt;li&gt;&amp;ldquo;uses-a&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Association
&lt;ul&gt;
&lt;li&gt;&amp;ldquo;knows-a&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Composition
&lt;ul&gt;
&lt;li&gt;&amp;ldquo;has-a&amp;rdquo;&lt;/li&gt;
&lt;li&gt;child 的存在依賴於 parent，若刪除 parent，child 也會隨之刪除&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Aggregation
&lt;ul&gt;
&lt;li&gt;&amp;ldquo;has-a&amp;rdquo;&lt;/li&gt;
&lt;li&gt;child 的存在獨立於 parent，若刪除 parent，child 不會隨之刪除&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Inheritance
&lt;ul&gt;
&lt;li&gt;&amp;ldquo;is-a&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Implementation
&lt;ul&gt;
&lt;li&gt;&amp;ldquo;can-do&amp;rdquo;&lt;/li&gt;
&lt;li&gt;實現 interface&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;other-features&#34;&gt;other features&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Navigation
&lt;ul&gt;
&lt;li&gt;當兩個 class 都可以看到對方，就用沒箭頭的關聯線，否則有箭頭&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Role Name
&lt;ul&gt;
&lt;li&gt;類別中的 Attribute&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Multiplicity
&lt;ul&gt;
&lt;li&gt;關聯端點上可以寫數量，代表物件個數&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Self-Association
&lt;ul&gt;
&lt;li&gt;同個類別的物件彼此有關係&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;軟體設計原則&#34;&gt;軟體設計原則&lt;/h2&gt;
&lt;h3 id=&#34;encapsulate-what-varies&#34;&gt;Encapsulate What Varies&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;把經常改變的程式碼封裝起來，使日後修改時不會影響其他區塊的程式碼&lt;/li&gt;
&lt;li&gt;實際使用的情境，可以把常改變的東西放在 interface 後，使日後改變實作時不影響呼叫該 interface 的程式碼&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;favor-composition-over-inheritance&#34;&gt;Favor Composition over Inheritance&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Composition(組合)在很多情境可以取代掉 Inheritance(繼承)，甚至實現 Polymorphism(多型)&lt;/li&gt;
&lt;li&gt;只有當 is-a 的情境出現，才用繼承比較好&lt;/li&gt;
&lt;li&gt;Composition 使用起來更有彈性&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;solid-設計原則&#34;&gt;SOLID 設計原則&lt;/h2&gt;
&lt;h3 id=&#34;single-responsibility-principle-srp&#34;&gt;Single Responsibility Principle, SRP&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;單一職責原則&lt;/li&gt;
&lt;li&gt;A class should have only one reason to change.&lt;/li&gt;
&lt;li&gt;可以把一個複雜的 module 拆成多個&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;open-close-principle-ocp&#34;&gt;Open-Close Principle, OCP&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;開放封閉原則&lt;/li&gt;
&lt;li&gt;You should be able to extend the behavior of a system without having to modify that system.&lt;/li&gt;
&lt;li&gt;要可以擴充，同時不修改到原系統&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;liskovsubstitution-principle-lsp&#34;&gt;LiskovSubstitution Principle, LSP&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;里氏替換原則&lt;/li&gt;
&lt;li&gt;父類別有的功能，子類別必須遵從，父類別的部分要可以直接替換成子類別&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;interface-segregation-principle-isp&#34;&gt;Interface Segregation Principle, ISP&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;介面隔離原則&lt;/li&gt;
&lt;li&gt;No client should be forced to depend on methods it does not use&lt;/li&gt;
&lt;li&gt;以 interface 來說，不該讓 module 實現它不需要的功能，可以把 interface 拆小&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;dependency-inversion-principle-dip&#34;&gt;Dependency Inversion Principle, DIP&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;反向依賴原則&lt;/li&gt;
&lt;li&gt;高階模組不應該依賴低階模組，兩者都應依賴抽象層&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;modularity&#34;&gt;Modularity&lt;/h2&gt;
&lt;h3 id=&#34;coupling&#34;&gt;Coupling&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;type
&lt;ul&gt;
&lt;li&gt;Tight coupling
&lt;ul&gt;
&lt;li&gt;Content coupling
&lt;ul&gt;
&lt;li&gt;一個模組依賴另一個模組的內部運作&lt;/li&gt;
&lt;li&gt;ex: 一個模組直接存取另一個模組的變數，假設回傳的數值是公尺，如果另一個模組要修改成公分，就會影響到這個模組
&lt;ul&gt;
&lt;li&gt;可以用 getter 抽象出 getMeter()，這樣就不會直接存取變數&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Common coupling
&lt;ul&gt;
&lt;li&gt;多個模組共同存取和修改同個 global data&lt;/li&gt;
&lt;li&gt;ex: 一個模組錯誤修改會導致其他人都壞掉&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;External coupling
&lt;ul&gt;
&lt;li&gt;多個模組直接存取同個 external I/O&lt;/li&gt;
&lt;li&gt;ex: API 要改就會全部都影響到&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Medium coupling
&lt;ul&gt;
&lt;li&gt;Control coupling
&lt;ul&gt;
&lt;li&gt;一個模組影響另一個模組的內部邏輯（比如說透過參數）&lt;/li&gt;
&lt;li&gt;ex: 參數要改個寫法就會影響一堆模組&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Data-Sructure coupling
&lt;ul&gt;
&lt;li&gt;多個模組共同存取同個 data structure&lt;/li&gt;
&lt;li&gt;ex: Data structure 要改就會影響到其他模組&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Loose coupling
&lt;ul&gt;
&lt;li&gt;Data Coupling
&lt;ul&gt;
&lt;li&gt;兩個模組 share/pass 同樣的資料&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Message Coupling
&lt;ul&gt;
&lt;li&gt;多個模組間透過 message 或是 command 來溝通&lt;/li&gt;
&lt;li&gt;和 control coupling 的差別在於，並沒有去控制某個模組，只是叫他做某件事情&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;No Coupling
&lt;ul&gt;
&lt;li&gt;不是好的設計&lt;/li&gt;
&lt;li&gt;模組間沒有關聯，或是有個超巨大的模組&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;cohesion&#34;&gt;Cohesion&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;type
&lt;ul&gt;
&lt;li&gt;Weak cohesion
&lt;ul&gt;
&lt;li&gt;Coincidental cohesion
&lt;ul&gt;
&lt;li&gt;唯一的關聯是他們在同個檔案&lt;/li&gt;
&lt;li&gt;ex: single file program&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Temporal cohesion
&lt;ul&gt;
&lt;li&gt;關聯的地方是他們在同個時間點被執行&lt;/li&gt;
&lt;li&gt;ex: 「執行 shutdown  相關的活動」&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Logical cohesion
&lt;ul&gt;
&lt;li&gt;活動間可以被歸類在同個 general category&lt;/li&gt;
&lt;li&gt;ex: Backup Controller，可能有很多地方需要 Backup&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Medium cohesion
&lt;ul&gt;
&lt;li&gt;Procedureal cohesion
&lt;ul&gt;
&lt;li&gt;command 間存在執行順序&lt;/li&gt;
&lt;li&gt;ex: Clean car module 可能包含噴水、填表格、擦乾等等
&lt;ul&gt;
&lt;li&gt;但是 Clean car module 此處包含了操控財務資料的狀況&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Communicational cohesion
&lt;ul&gt;
&lt;li&gt;所有的 activities 都支援相同的 input/output&lt;/li&gt;
&lt;li&gt;ex: 提取文章的作者、提取文章的標題、提取文章的內容&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Sequential cohesion
&lt;ul&gt;
&lt;li&gt;某個 activities 的輸出是另一個 activities 的輸入，且具有順序性&lt;/li&gt;
&lt;li&gt;Procedureal cohesion 和 Communicational cohesion 的結合&lt;/li&gt;
&lt;li&gt;這個沒那麼糟糕&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Strong cohesion
&lt;ul&gt;
&lt;li&gt;Functional cohesion
&lt;ul&gt;
&lt;li&gt;Module 只支援只和一個問題相關的 activities&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Object cohesion
&lt;ul&gt;
&lt;li&gt;所有的 activities 都只會修改一個 object&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>PatentBERT 論文閱讀</title>
        <link>https://roykesydon.github.io/Blog/p/patentbert-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</link>
        <pubDate>Thu, 02 Mar 2023 16:08:46 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/patentbert-%E8%AB%96%E6%96%87%E9%96%B1%E8%AE%80/</guid>
        <description>&lt;p&gt;paper: &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/1906.02124&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PatentBERT: Patent Classification with Fine-Tuning a pre-trained BERT Model&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;abstract&#34;&gt;Abstract&lt;/h1&gt;
&lt;p&gt;把 fine-tune BERT 應用在專利分類上，當應用於超過 200 萬件專利的資料集時，該方法超越了結合 word-embedding 的 CNN 的 SOTA 作法。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;貢獻:
&lt;ol&gt;
&lt;li&gt;一個用預訓練的 BERT 去 fine-tune 的 SOTA 方法&lt;/li&gt;
&lt;li&gt;一個叫做 USPTO-3M 的大型資料集，屬於 CPC subclass level，並提供 SQL 語句讓後續的研究者使用&lt;/li&gt;
&lt;li&gt;與傳統觀念相反，只需要 claim 就足以完成分類任務&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;專利分類是一個 multi-label 的分類任務。&lt;/p&gt;
&lt;p&gt;由於標籤的數量可能很大，所以是個具有挑戰性的任務。&lt;/p&gt;
&lt;p&gt;作者準備了一個基於 CPC 的新資料集，有超過三百萬項美國專利。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CPC
&lt;ul&gt;
&lt;li&gt;Cooperative Patent Classification&lt;/li&gt;
&lt;li&gt;是 IPC 更具體和詳細的版本&lt;/li&gt;
&lt;li&gt;可預見將取代 IPC 成為新的標準
&lt;ul&gt;
&lt;li&gt;只是由於 CLEP-IP 競賽，大部分論文都基於 IPC
&lt;ul&gt;
&lt;li&gt;資料集包含 1978 到 2009 提交的專利&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;IPC
&lt;ul&gt;
&lt;li&gt;International Patent Classification&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;此外，作者的 dataset 基於 patent claims&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;patent claims
&lt;ul&gt;
&lt;li&gt;重要性在過往被低估&lt;/li&gt;
&lt;li&gt;在起草專利申請時，專利業者會先起草 patent claims&lt;/li&gt;
&lt;li&gt;專利文件的其餘部分由 claim 做延伸&lt;/li&gt;
&lt;li&gt;在專利法中，claims 定義了專利發明的界線，確定了專利權範圍&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;為使模型更簡單，只關注 patent claims，並且僅用第一項 claim。&lt;/p&gt;
&lt;h1 id=&#34;相關工作&#34;&gt;相關工作&lt;/h1&gt;
&lt;p&gt;過往有些研究只顯示了 precision，但沒有 F1 value 或 recall，難以公平比較。&lt;/p&gt;
&lt;p&gt;以 DeepPatent&lt;/p&gt;
&lt;h1 id=&#34;data&#34;&gt;Data&lt;/h1&gt;
&lt;p&gt;過往資料基於 CLEF-IP 或 patent offices。&lt;/p&gt;
&lt;p&gt;作者發現在 BigQuery 用 Google Patents Public Datasets 更容易。&lt;/p&gt;
&lt;p&gt;而且可用 SQL statements，作者認為比共享傳統資料集更好，原因如下:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Seperation of concerns
&lt;ul&gt;
&lt;li&gt;如果資料包含前處理或後處理，其他研究人員需要不同操作時會很頭痛。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Clarity and flexibility
&lt;ul&gt;
&lt;li&gt;SQL statement 精確且容易根據不同條件進行修改。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在和 DeepPatent 比較的時候，可以的話，會用 USPTO2M 進行測試，如果不行，才會合併來自 USPTO-3M 的資料，比如 USPTO-2M 沒有 claims 的情況。&lt;/p&gt;
&lt;p&gt;為了比較 claim 如何影響性能，將合併兩個資料集。&lt;/p&gt;
&lt;h1 id=&#34;method--experimental-setup&#34;&gt;Method &amp;amp; Experimental Setup&lt;/h1&gt;
&lt;p&gt;用 BERT-Base 就可以打敗 DeepPatent。&lt;/p&gt;
&lt;p&gt;遵循 BERT Project 中給的 fine-tune 範例。&lt;/p&gt;
&lt;p&gt;為了 multilabel，用 sigmoid cross entropy with logits function 而不是用 softmax。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/PatentBERT/result.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h1 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;專利分類作為具有挑戰性的任務，幾十年來一直沒有令人滿意的表現。&lt;/p&gt;
&lt;p&gt;本文提出一個基於 fine-tune BERT 的方法，性能優於 DeepPatent。&lt;/p&gt;
&lt;p&gt;並且結果表明只用 patent claim 就可以完成分類任務。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Process Scheduling</title>
        <link>https://roykesydon.github.io/Blog/p/process-scheduling/</link>
        <pubDate>Mon, 20 Feb 2023 21:12:52 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/process-scheduling/</guid>
        <description>&lt;h1 id=&#34;process-scheduling&#34;&gt;Process Scheduling&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;可能時機&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;running -&amp;gt; waiting&lt;/li&gt;
&lt;li&gt;running -&amp;gt; ready&lt;/li&gt;
&lt;li&gt;waiting -&amp;gt; ready&lt;/li&gt;
&lt;li&gt;running -&amp;gt; terminate&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Process Scheduler&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Preemptive scheduler (Time slice)
&lt;ul&gt;
&lt;li&gt;可以被搶占&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Non-Preemptive scheduler
&lt;ul&gt;
&lt;li&gt;又稱 cooperative scheduling&lt;/li&gt;
&lt;li&gt;只可能出現在時機 1 或 4&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Classification fo Processes(related to scheduling)&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Interactive Processes (50 - 150 ms)&lt;/li&gt;
&lt;li&gt;Batch Processes&lt;/li&gt;
&lt;li&gt;Real time Processes
&lt;ul&gt;
&lt;li&gt;Hard&lt;/li&gt;
&lt;li&gt;Soft&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Classification of Processes(related to CPU usage)&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;CPU Bound&lt;/li&gt;
&lt;li&gt;I/O Bound&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;standard-scheduling-algorithm&#34;&gt;Standard Scheduling Algorithm&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;FCFS&lt;/li&gt;
&lt;li&gt;SJF&lt;/li&gt;
&lt;li&gt;SRTF&lt;/li&gt;
&lt;li&gt;Priority Based&lt;/li&gt;
&lt;li&gt;Highest Response Ratio Next&lt;/li&gt;
&lt;li&gt;Round Robin&lt;/li&gt;
&lt;li&gt;Virtual RR&lt;/li&gt;
&lt;li&gt;Multi-Level Queue Scheduler&lt;/li&gt;
&lt;li&gt;Multi-Level Feed Back Queue Scheduler&lt;/li&gt;
&lt;li&gt;Rotating Staircase Deadline Scheduler&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;unix-svr3-scheduler&#34;&gt;UNIX SVR3 Scheduler&lt;/h1&gt;
&lt;p&gt;有 32 個 runqueue，每個 runqueue 負責 4 個 priority values&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;128 Priority values&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;0-49: Kernel&lt;/li&gt;
&lt;li&gt;50-127: User&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;$Priority_j=Base_j+CPU_j(i)+nice_j$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Base: 0-127&lt;/li&gt;
&lt;li&gt;$CPU_j(i) = DR * CPU_j(i-1)$
&lt;ul&gt;
&lt;li&gt;DR = $\frac{1}{2}$&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;nice: -20 ~ +19
&lt;ul&gt;
&lt;li&gt;可以用 nice 和 renice 改 process nice value&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;schedtool&#34;&gt;Schedtool&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Query &amp;amp; set per process scheduling parameters&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Scheduling Policy
&lt;ul&gt;
&lt;li&gt;Real time
&lt;ol&gt;
&lt;li&gt;SCHED_RR&lt;/li&gt;
&lt;li&gt;SCHED_FIFO&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Conventional
&lt;ol&gt;
&lt;li&gt;SCHED_NORMAL (default)&lt;/li&gt;
&lt;li&gt;SCHED_BATCH (CPU intensive)&lt;/li&gt;
&lt;li&gt;SCHED_ISO (unused)&lt;/li&gt;
&lt;li&gt;SCHED_IDLEPRIO (low pri jobs)&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Nice Value (-20 to +19)&lt;/li&gt;
&lt;li&gt;Static Priority (1-99)&lt;/li&gt;
&lt;li&gt;CPU affinity
&lt;ul&gt;
&lt;li&gt;process 想運行在某個指定的 CPU 上，不被轉移到其他 CPU，才不會降低指定 CPU 的 cache 命中率
&lt;ul&gt;
&lt;li&gt;soft CPU affinity&lt;/li&gt;
&lt;li&gt;hard CPU affinity&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;cpus_allowed
&lt;ul&gt;
&lt;li&gt;一個用來指定 CPU 的 mask&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  schedtool &amp;lt;PID&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>MAE 論文</title>
        <link>https://roykesydon.github.io/Blog/p/mae-%E8%AB%96%E6%96%87/</link>
        <pubDate>Wed, 15 Feb 2023 16:08:46 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/mae-%E8%AB%96%E6%96%87/</guid>
        <description>&lt;p&gt;paper: &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2111.06377&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Masked Autoencoders Are Scalable Vision Learners&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;abstract&#34;&gt;Abstract&lt;/h1&gt;
&lt;p&gt;這篇論文顯示出 MAE 是 CV 中的 scalable self-supervised learners。&lt;/p&gt;
&lt;p&gt;MAE 的方法很簡單&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;隨機蓋住輸入影像的一些 patch&lt;/li&gt;
&lt;li&gt;重建 missing pixels&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;具備兩個核心設計&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;非對稱的 encoder-decoder 架構，encoder 只作用於可見的 patch 子集合(沒有 mask tokens)，lightweight decoder 則根據 latent representation 和 make tokens 來重建圖片。&lt;/li&gt;
&lt;li&gt;當遮住高比例(比如 75%)的影像時，會得到一個 nontrivial 和 meaningful 的 self-supervisory task&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;結合這兩點設計，可以有效地訓練大模型。
以 ViT-Huge 用 ImageNet-1K 訓練(訓練集一百多萬張照片)可達到 87.8% 的準確度。&lt;/p&gt;
&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/MAE/intro.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/MAE/valid-example.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/MAE/valid-example-2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;在 CV 中，常需要大量 labeled images。
NLP 中，自監督預訓練處理了需要大量標註資料的問題。
masked autoencoders 是一種更 general 的 denoising autoencoders 的形式。
BERT 非常成功，autoencoding methods 在 CV 的研究卻落後 NLP，作者思考是什麼讓 masked autoencoding 在 CV 和 NLP 產生不同。
有以下觀點&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;直到前陣子，CV 中的 CNN 是主流，但卷積層不好引入 mask tokens 或 positional embedding 這些 indicator。但這些可以透過 ViT 來解決，不應成為問題。&lt;/li&gt;
&lt;li&gt;語言和視覺的 Information density 不同，語言是 highly semantic 和 information-dense，使填字本身不是很簡單的事情，但影像含有大量冗餘的訊息，缺失的部分比較好從相鄰的 patch 重建，比如直接插值，所以作者用一種簡單的策略，隨機 mask 很大一部分的 patch，創造一個具有挑戰性的自監督任務，強迫模型關注 global 的資訊。&lt;/li&gt;
&lt;li&gt;關於 decoder，CV 還原 pixel，pixel 屬於 lower semantic level，NLP 還原 word，word 的 semantic information 較高。作者發現，雖然在 BERT 中，可以用簡單的 decoder 還原(一個 MLP)，但 CV 中 decoder 的設計就很重要。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;基於以上觀點，作者提出 MAE，隨機遮住大量的 patch，並在 pixel space 重建失去的 patch。而且是非對稱 encoder-decoder 架構，encoder 只會看到可見的 patch，但 docoder 除了 latent representation，還會看到 mask tokens。這種設計在非常高的掩蓋率(比如 75%)下不但可以提高準確度，還可以讓 encoder 只處理較少比例(比如 25%)的 patch，將訓練時間減少 3 倍或更多，使 MAE 可以輕鬆擴展成更大的模型。&lt;/p&gt;
&lt;p&gt;在這樣的架構下，用 MAE 的 pre-training，可以訓練非常吃 data 的模型，比如 ViT-Large/-Huge，而只使用 ImageNet-1K。&lt;/p&gt;
&lt;p&gt;用 ImageNet-1K 在 vanilla ViT-Huge 上 fine-tune 可達到 87.8% 準確度，比以往只使用 ImageNet-1K 的結果都高。&lt;/p&gt;
&lt;p&gt;在 obejct detection、instance segmentation、semantic segmentation 上做 transfer learning 都達到不錯的效果，可以打敗用監督式預訓練模型的對手。&lt;/p&gt;
&lt;h1 id=&#34;相關工作&#34;&gt;相關工作&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Autoencoding
&lt;ul&gt;
&lt;li&gt;MAE 是一種 denoising autoencoding 的形式，但和 DAE 還是差別很大。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Masked image encoding
&lt;ul&gt;
&lt;li&gt;iGPT、ViT、BEiT&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;approach&#34;&gt;Approach&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Masking&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;和 ViT 一樣，把圖片切成多個 patch，對於 patch 均勻隨機地採樣保留，剩下地遮住&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;MAE encoder&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ViT&lt;/li&gt;
&lt;li&gt;也有 positional embedding&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;MAE decoder&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Transformer block&lt;/li&gt;
&lt;li&gt;輸入
&lt;ul&gt;
&lt;li&gt;encoded visible patches&lt;/li&gt;
&lt;li&gt;mask tokens
&lt;ul&gt;
&lt;li&gt;shared, learned vector&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;都會加入 positional embedding&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;用相較 encoder 輕量的解碼器，所有的 patch 由這個輕量的 decoder 處理，減少預訓練時間&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Reconstruction target&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;decoder 的最後一層是 linear projection，之後再 reshape 成你要的  patch&lt;/li&gt;
&lt;li&gt;loss function
&lt;ul&gt;
&lt;li&gt;mean squared error(MSE)&lt;/li&gt;
&lt;li&gt;只算 masked patched 的 MSE，像 BERT&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Simple implementation&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;先取得一系列 token(patch 做 linear projection + positional embedding)&lt;/li&gt;
&lt;li&gt;randomly shuffle，根據比例移除尾端一部份&lt;/li&gt;
&lt;li&gt;encoding 後，尾端接上 mask tokens，並且 unshuffle&lt;/li&gt;
&lt;li&gt;加上 positional embedding 後，給 decoder&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;imagenet-experiments&#34;&gt;ImageNet Experiments&lt;/h1&gt;
&lt;p&gt;在 ImageNet-1K 上做自監督的預訓練，然後做&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;end-to-end fine-tuning
&lt;ul&gt;
&lt;li&gt;所有參數都可改&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;linear probing
&lt;ul&gt;
&lt;li&gt;只改最後一層線性層&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/MAE/vit-mae.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/MAE/result.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/MAE/ratio-result.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;optimal masking ratio 意外地高，相比 BERT 只有 15%&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/MAE/fine-tune-blocks.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h1 id=&#34;討論和結論&#34;&gt;討論和結論&lt;/h1&gt;
&lt;p&gt;在 CV 實用的預訓練做法主流是監督式的，CV 中自監督的做法可能正跟著 NLP 的軌跡走。&lt;/p&gt;
&lt;p&gt;要仔細處理圖像和語言的區別，作者去除圖片中很可能不構成 semantic segment 的部分，而不是移除某個 object。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>ViT 論文</title>
        <link>https://roykesydon.github.io/Blog/p/vit-%E8%AB%96%E6%96%87/</link>
        <pubDate>Sun, 12 Feb 2023 00:27:55 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/vit-%E8%AB%96%E6%96%87/</guid>
        <description>&lt;p&gt;paper: &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2010.11929&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;abstract&#34;&gt;Abstract&lt;/h1&gt;
&lt;p&gt;在 CV 領域 transformer 表現有限，目前 attention 常常是和卷積神經網路一起用，或是用來把一些卷積層換成 self-attention，但整體架構不變。這篇論文想展現一個純 Transformer 可以直接在影像分類上表現很好。如果用大量資料作預訓練，再遷移到中小型的資料集，可以和 SOTA 的 CNN 表現得一樣好，還需要較少的訓練資源作訓練。&lt;/p&gt;
&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;self-attention-based 架構，特別是 Transformer，已經是 NLP 的重要選擇。主流的作法是在大型文字資料集上作訓練，再針對小型任務資料集作 fine-tune。由於 Transformer 的計算效率高，還有可擴展性，可以 train 一些很大的 model，隨著 model 和資料集增大，目前還沒看出飽和的現象。&lt;/p&gt;
&lt;p&gt;然而在 CV，CNN 還是主流，一些工作嘗試用 self-attention 結合 CNN-like 的架構，比如把 feature map 當 transformer 的輸入，因為原始 pixel 太多，或甚至把卷積層全換成 self-attention，雖然後者理論上效率很高(原論文中有另外 cite 兩篇作法)，但因為他們做法特殊，在現代硬體上很難加速，所以無法很有效地擴展。在 large-scale 的影像識別上， ResNet-like 的架構還是 SOTA。&lt;/p&gt;
&lt;p&gt;該實驗直接把一個標準的 Transformer 作用於圖片上，只作最少的修改。把影像分成多個 patch，並把它們變成一系列的 linear embedding，當作 NLP 中的 tokens(words) 來處理。&lt;/p&gt;
&lt;p&gt;當在中型大小的資料集(e.g. ImageNet)上訓練，如果沒有 strong regularization，ViT 會略輸同等大小的 ResNets&lt;/p&gt;
&lt;p&gt;這篇論文在更大的資料集(14M-300M 的影像)上訓練，就打敗了 inductive bias。在大量資料上作預訓練就很讚。&lt;/p&gt;
&lt;h1 id=&#34;related-work&#34;&gt;Related Work&lt;/h1&gt;
&lt;p&gt;大型的 Transformer-based 模型常常是先在大資料集上預訓練然後根據任務 fine-tune，比如 BERT 和 GPT。&lt;/p&gt;
&lt;p&gt;要把 self-attention 用在 CV 上，最簡單的做法就是把每個 Pixel 當一個元素，但 self-attention 是平方複雜度，在現實的圖片很難應用。一個應用 Transformer 的做法是只把 self-attention 用在 local neighborhood，另外一個是用 Sparse Transformer，還有一堆特殊的方法，雖然表現不錯，但要用硬體加速起來不容易。&lt;/p&gt;
&lt;p&gt;另一個有關的模型是 iGPT，在 reduce image resolution 和 color space 後把 transformer 應用在 image pixels 上。它用非監督式訓練後，再 fine-tune 或做 linear probing(只更新最後的 linear layer) 分類任務，表現很好。&lt;/p&gt;
&lt;p&gt;已經有類似的工作了，抽取 patches of size 2 * 2，最後再接 full self-attention，基本上和 ViT 非常像，這篇論文進一步證明了作大規模的預訓練可以讓 Transformer 和 SOTA 的 CNN 相比，而且 ViT 因為 patch 比較大，可以處理 medium-resolution 的圖片。這問題是可預期的，因為 Transformer 缺少了一些 inductive biases。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;inductive biases
&lt;ul&gt;
&lt;li&gt;一些假設&lt;/li&gt;
&lt;li&gt;比如 CNN 常有四個假設
&lt;ul&gt;
&lt;li&gt;locality&lt;/li&gt;
&lt;li&gt;translation invariance with pooling layers
&lt;ul&gt;
&lt;li&gt;平移不變性&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;translation equivariance
&lt;ul&gt;
&lt;li&gt;f(g(x)) = g(f(x))&lt;/li&gt;
&lt;li&gt;卷積和平移的先後順序沒差&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;method&#34;&gt;Method&lt;/h1&gt;
&lt;p&gt;模型盡可能類似原始 Transformer，這樣可以把一些 NLP 上成功的 Transformer 架構拿來用，還可以用一些很有效率的 implementation&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/ViT/ViT.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/ViT/ViT-process.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;embedding 維度是 768 = 16 * 16 * 3
position embedding 的做法是 standard learnable 1D positional embeddings，就是 BERT 的做法，簡單來說就是生出一張可以訓練的表，(序列長度, embedding size)，作者也有嘗試其他方法，但發現成效差不多，比如 2D positional embedding，概念就是從生出(序列長度, embedding size)變成生出 2 個(sqrt(序列長度), embedding size)。&lt;/p&gt;
&lt;p&gt;[class] 的概念是 NLP 出來的，ResNet-like 的架構常見的做法也有通過 globally average-pooling (GAP)來生出向量，再接上分類器做預測。實驗發現直接在 transformer 的輸出做 GAP 和 [class] 都可以達到不錯的效果。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/ViT/ViT-gap.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/ViT/ViT-dataset.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/deep-learning/ViT/ViT-acc.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h1 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;拿標準的 Transformer 來作 Image recognition，和以往用 self-attention 在 CV 的方法不一樣，除了一開始的 initial patch extraction，沒有引入其他影像特有的 inductive biases。直接把圖片當成是一系列的 patch，然後直接用 Transformer encoder 當一般 NLP 任務處理。在很多影像分類訓練集上表現得更好還在 pre-train 上相對便宜。&lt;/p&gt;
&lt;p&gt;還有一些值得挑戰的地方，比如把 ViT 應用在其他 CV 任務，比如 detection 和 segmentation。另一個挑戰是探索自監督預訓練的方法。這篇論文其實有實驗自監督，表現 OK，但和監督式還是有很大的落差。擴大 ViT 可能有更好的結果。&lt;/p&gt;
</description>
        </item>
        <item>
        <title>IPC -- Inter-Process Communication</title>
        <link>https://roykesydon.github.io/Blog/p/ipc--inter-process-communication/</link>
        <pubDate>Sat, 28 Jan 2023 15:31:50 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/ipc--inter-process-communication/</guid>
        <description>&lt;h1 id=&#34;share-information-between-processes&#34;&gt;Share information between processes&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;透過硬碟上的文件溝通
&lt;ul&gt;
&lt;li&gt;超慢&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;透過 kernel buffer
&lt;ul&gt;
&lt;li&gt;滿快的，但這樣要一直在 user mode 和 kernel mode 來回切換，因為kernel buffer 在 kernel space&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;透過 shared memory region
&lt;ul&gt;
&lt;li&gt;shared memory region 在 user space&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;mechanisms&#34;&gt;Mechanisms&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Signals&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Communication&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Data transfer
&lt;ul&gt;
&lt;li&gt;Byte Stream
&lt;ul&gt;
&lt;li&gt;Pipes&lt;/li&gt;
&lt;li&gt;FIFOs(Named Pipes)&lt;/li&gt;
&lt;li&gt;stream sockets&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Message Passing
&lt;ul&gt;
&lt;li&gt;SystemV MsgQ&lt;/li&gt;
&lt;li&gt;POSIX MsgQ&lt;/li&gt;
&lt;li&gt;datagram sockets&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Shared Memory
&lt;ul&gt;
&lt;li&gt;SystemV S.M&lt;/li&gt;
&lt;li&gt;POSIX S.M&lt;/li&gt;
&lt;li&gt;Memory Mapping
&lt;ul&gt;
&lt;li&gt;anonymous memory mapping&lt;/li&gt;
&lt;li&gt;memory mapped file&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Synchronization&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;pipes&#34;&gt;Pipes&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Related processes
&lt;ul&gt;
&lt;li&gt;parent-child&lt;/li&gt;
&lt;li&gt;sibling&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Executing on same machine&lt;/li&gt;
&lt;li&gt;用法
&lt;ul&gt;
&lt;li&gt;cmd1 | cmd2
&lt;ul&gt;
&lt;li&gt;cmd1 不是輸出到 stdout，而是由 kernel 維護的 buffer，也就是 pipe&lt;/li&gt;
&lt;li&gt;cmd 不是從 stdin 獲取輸入，而是從 pipe 獲取&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;cmd1 | cmd2 | &amp;hellip; | cmdn&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;named-pipes--fifos&#34;&gt;Named Pipes / FIFOs&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Related / Unrelated processes&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Executing on same machine&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;creat a FIFO&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;commands
&lt;ul&gt;
&lt;li&gt;mkfifo&lt;/li&gt;
&lt;li&gt;mknod&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;嘗試寫入或讀取 FIFO 時，會被 redirect 到 pipe&lt;/p&gt;
&lt;h1 id=&#34;signal-handling&#34;&gt;Signal Handling&lt;/h1&gt;
&lt;h2 id=&#34;signal&#34;&gt;Signal&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Used by OS to notify running process some event has occured without the process needing to pull for that event&lt;/li&gt;
&lt;li&gt;process 收到 signal 後會先停止執行並執行 signal handler&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;A process did something
&lt;ul&gt;
&lt;li&gt;SIGSEGV(11), SIGFPE(8), SIGILL(4), SIGPIPE(13)&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;A process wants to tell another process something
&lt;ul&gt;
&lt;li&gt;SIGCHILD(17)
&lt;ul&gt;
&lt;li&gt;child process terminated&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;User sends sig to foreground processes
&lt;ul&gt;
&lt;li&gt;Ctrl + C SIGINT(2)&lt;/li&gt;
&lt;li&gt;Ctrl + \ SIGQUIT(3)&lt;/li&gt;
&lt;li&gt;Ctrl + Z SIGTSTP(20)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;disposition&#34;&gt;disposition&lt;/h3&gt;
&lt;p&gt;決定 process 遇到 signal 時該怎麼處理&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Term
&lt;ul&gt;
&lt;li&gt;teminate process&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Ign
&lt;ul&gt;
&lt;li&gt;ignore&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Core
&lt;ul&gt;
&lt;li&gt;terminate the process and dump core&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Stop
&lt;ul&gt;
&lt;li&gt;stop the process&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Cont
&lt;ul&gt;
&lt;li&gt;continue the process if it is stopped&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;signal-cant-not-be-caught&#34;&gt;Signal can&amp;rsquo;t not be caught&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;SIGKILL(9)&lt;/li&gt;
&lt;li&gt;SIGSTOP(19)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;commands&#34;&gt;Commands&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;trap&lt;/p&gt;
&lt;p&gt;可以 handle signal&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;kill&#34;&gt;kill&lt;/h2&gt;
&lt;p&gt;kill - L 可以看到 standard signal 和 real-time signal&lt;/p&gt;
&lt;p&gt;standard signal 開頭是 SIG，realt-time signal 是 SIGRT&lt;/p&gt;
</description>
        </item>
        <item>
        <title>InstructGPT</title>
        <link>https://roykesydon.github.io/Blog/p/instructgpt/</link>
        <pubDate>Fri, 27 Jan 2023 17:39:12 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/instructgpt/</guid>
        <description>&lt;p&gt;paper: &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2203.02155&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Training language models to follow instructions with human feedback&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;abstract&#34;&gt;Abstract&lt;/h1&gt;
&lt;p&gt;把語言模型變大不代表他們會更好地遵循用戶的意圖。&lt;/p&gt;
&lt;p&gt;大的語言模型有可能會生成 untruthful, toxic, not helpful 的答案。&lt;/p&gt;
&lt;p&gt;該論文透過 fine-tuning with human feedback 來解決這問題。&lt;/p&gt;
&lt;p&gt;一開始準備一系列人工標註的 prompts，然後用這 dataset 對 GPT-3 做 fine-tune。&lt;/p&gt;
&lt;p&gt;接下來再蒐集一個 dataset，存放 rankings of model outputs，由人工判斷輸出好壞，再用 RL 把剛剛 fine-tune 過的 model 繼續 fine-tune。&lt;/p&gt;
&lt;p&gt;最後有 1.3B 參數的 InstructGPT 表現的結果比 175B 參數的 GPT-3 還好。&lt;/p&gt;
&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Large language models(LMs) 可以透過 &amp;ldquo;prompt&amp;rdquo; 來執行各種 NLP 任務。&lt;/p&gt;
&lt;p&gt;但這些模型也常有一些非目的性的行為，諸如捏造事實等等。&lt;/p&gt;
&lt;p&gt;原因是出在目標函數上，多數 LMs 的目標函數是根據網路上的文本生出下一個字詞。&lt;/p&gt;
&lt;p&gt;這和「根據使用者指令生出安全且有幫助的答案不同」。&lt;/p&gt;
&lt;p&gt;上述的差異使語言模型的目標是 misaligned。&lt;/p&gt;
&lt;p&gt;作者的目標是生出 helpful、 honest(沒有誤導性資訊)、harmless 的 model。&lt;/p&gt;
&lt;p&gt;具體作法，使用 reinforcement learning from human feedback(RLHF)。&lt;/p&gt;
&lt;h2 id=&#34;訓練步驟&#34;&gt;訓練步驟&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/gpt/instruct-gpt-train-step.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;結果&#34;&gt;結果&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Labelers 明顯偏好 InstructGPT 的答案，勝過 GPT-3 的答案&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;InstructGPT 的答案在 truthfulness 勝過 GPT-3 的答案&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;InstructGPT 的答案在 toxicity 上小勝 GPT-3 的答案，但在 bias 上沒有&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;methods&#34;&gt;Methods&lt;/h1&gt;
&lt;h2 id=&#34;dataset&#34;&gt;Dataset&lt;/h2&gt;
&lt;p&gt;標註人員寫很多 prompts&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Plain:
&lt;ul&gt;
&lt;li&gt;隨便寫任意任務&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Few-shot:
&lt;ul&gt;
&lt;li&gt;想個 instruction，並寫 multiple query/response pairs for that instruction&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;User-based:
&lt;ul&gt;
&lt;li&gt;根據一些申請使用 OpenAI API 的用戶，提出有關的 prompts&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;然後根據這個訓練初步模型，並把這個初步模型放到他們的 Playground 給用戶使用。&lt;/p&gt;
&lt;p&gt;再把用戶問的問題蒐集回來，並做篩選。&lt;/p&gt;
&lt;p&gt;訓練 SFT 的模型用 13k training prompts&lt;/p&gt;
&lt;p&gt;訓練 RM 的模型用 33k training prompts&lt;/p&gt;
&lt;p&gt;訓練 PPO 的模型用 31k training prompts&lt;/p&gt;
&lt;h2 id=&#34;model&#34;&gt;Model&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Supervised fine-tuning(SFT)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;拿 GPT-3 去訓練 16 個 epochs&lt;/li&gt;
&lt;li&gt;跑一個 epoch 就發現 overfitting，但發現訓練更多 epoches 對後面的 RM 有用，而且這個 model 也只是過渡產品&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Reward modeling(RM)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;把 SFT 後面的 unembedding layer 去除掉，接上線性層，最後輸出一個 scalar reward&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;用 6B RMs&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;這模型會吃 prompt 和 response&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;人工標記的是排序，不是分數&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;對每個 prompt 生出 9 個答案&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;原本是 4 個，但排 9 個花的時間可能不會到 4 個的兩倍，因為主要心力會花在讀 prompt。但標註訊息會多很多，因為都是兩兩比較。&lt;/li&gt;
&lt;li&gt;而且在 loss 中最多只要丟入 RM 9 次，因為可以重用&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Pairwise Ranking Loss&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;對一個 prompt(假設是 x)，取出一對回覆(假設是 $y_w$ 和 $y_l$)，算出 RM(x, $y_w$) 和 RM(x, $y_l$)，假設 $y_w$ 比 $y_l$ 排序高，讓 RM(x, $y_w$) - RM(x, $y_l$) 的數值越大越好&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/gpt/instruct-gpt-reward-loss.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Reinforcement learning(RL)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;PPO&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/gpt/instruct-gpt-rl-loss.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\beta$ 那項是 KL divergence&lt;/li&gt;
&lt;li&gt;$\gamma$ 那項是不想要讓這 model 太專注在微調的任務，而失去原本在其他 NLP 任務也表現很好的功能。
&lt;ul&gt;
&lt;li&gt;$D_{pretrain}$ 是 pretraining distribution&lt;/li&gt;
&lt;li&gt;如果 $\gamma$ 為 0，在該實驗中叫做 PPO，否則，稱為 PPO-ptx&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;result&#34;&gt;Result&lt;/h1&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/gpt/instruct-gpt-result.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Bayesian Optimization</title>
        <link>https://roykesydon.github.io/Blog/p/bayesian-optimization/</link>
        <pubDate>Thu, 26 Jan 2023 01:36:53 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/bayesian-optimization/</guid>
        <description>&lt;h1 id=&#34;介紹&#34;&gt;介紹&lt;/h1&gt;
&lt;p&gt;一種用於自動化找超參數的方法，用在採樣昂貴而且是黑盒子的情況&lt;/p&gt;
&lt;h1 id=&#34;流程&#34;&gt;流程&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;取樣一些資料點&lt;/li&gt;
&lt;li&gt;生出一個 Surrogate Model(可採用 Gaussian Process)&lt;/li&gt;
&lt;li&gt;反覆做以下事情
&lt;ul&gt;
&lt;li&gt;用 Acquisition Function 挑選下一個要採樣的點&lt;/li&gt;
&lt;li&gt;重新評估 Surrogate Model&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;gaussian-process&#34;&gt;Gaussian Process&lt;/h2&gt;
&lt;p&gt;最終的 prediction 是一個 distribution 而不是單一個數字
生成方法需借助 kernel function，常用 RBF(Radial Basis Function)&lt;/p&gt;
&lt;p&gt;$K(x, x^{&amp;rsquo;}|\tau)=\sigma^2exp(-\frac{1}{2}(\frac{x-x^{&amp;rsquo;}}{l})^2)$&lt;/p&gt;
&lt;p&gt;$\sigma$ 和 $l$ 是兩個可以調整的超參數&lt;/p&gt;
&lt;h2 id=&#34;acquisition-function&#34;&gt;Acquisition Function&lt;/h2&gt;
&lt;p&gt;可用超參數來調節 exploitation 和 exploitation&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;UCB(Upper confidence bound)&lt;/li&gt;
&lt;li&gt;PI(probability of improvement)&lt;/li&gt;
&lt;li&gt;EI(Expected improvement)&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>IO Redirection</title>
        <link>https://roykesydon.github.io/Blog/p/io-redirection/</link>
        <pubDate>Sat, 21 Jan 2023 02:20:43 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/io-redirection/</guid>
        <description>&lt;h1 id=&#34;ppfdt&#34;&gt;PPFDT&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;per process file descriptor table&lt;/li&gt;
&lt;li&gt;每個 process 都有&lt;/li&gt;
&lt;li&gt;存放 file descriptors
&lt;ul&gt;
&lt;li&gt;file descriptors 是一個唯一的整數，用來識別作業系統上的 open file&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;0, 1, 2 是 Standard input / ouput / error&lt;/li&gt;
&lt;li&gt;大小受限於 OPEN_MAX，亦即能同時間能開的最多檔案數&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;redirection&#34;&gt;Redirection&lt;/h1&gt;
&lt;h2 id=&#34;input-redirection&#34;&gt;Input redirection&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;$ wc &amp;lt; /etc/passwd
&lt;ul&gt;
&lt;li&gt;把 wc 的 PPFDT 的 stdin 改成 /etc/passwd&lt;/li&gt;
&lt;li&gt;如果是 $ wc /etc/passwd，則是在 PPFDT 追加 /etc/passwd&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ouput-redirection&#34;&gt;Ouput redirection&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;$ wc &amp;gt; f1
&lt;ul&gt;
&lt;li&gt;把 wc 的 PPFDT 的 stdout 改成 f1&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;input--output-redirection&#34;&gt;Input &amp;amp; output redirection&lt;/h2&gt;
&lt;p&gt;兩個可以同時用&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$ cat &amp;lt; f1 &amp;gt; f2&lt;/li&gt;
&lt;li&gt;&amp;gt;&amp;gt; 可以 append&lt;/li&gt;
&lt;li&gt;$ &amp;lt; f1 cat &amp;gt; f2
&lt;ul&gt;
&lt;li&gt;可以亂換位置&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;error-redirection&#34;&gt;Error redirection&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;$ find / -name f1 2&amp;gt; error 1&amp;gt; outputs
&lt;ul&gt;
&lt;li&gt;這樣就會把那些 Permission denied 的給到 errors，成功的給到 outputs&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;2&amp;gt;/dev/null
&lt;ul&gt;
&lt;li&gt;/dev/null 會把丟進來的東西都丟棄&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;copy-descripter&#34;&gt;Copy Descripter&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;這兩者等價
&lt;ul&gt;
&lt;li&gt;$ cat f1 1&amp;gt;op_err 2&amp;gt;op_err&lt;/li&gt;
&lt;li&gt;$ cat f1 1&amp;gt;op_err 2&amp;gt;&amp;amp;1
&lt;ul&gt;
&lt;li&gt;make 2 a copy of 1&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
        </item>
        <item>
        <title>Process Management</title>
        <link>https://roykesydon.github.io/Blog/p/process-management/</link>
        <pubDate>Sat, 21 Jan 2023 00:08:25 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/process-management/</guid>
        <description>&lt;h1 id=&#34;compile-c&#34;&gt;Compile C&lt;/h1&gt;
&lt;h2 id=&#34;4-steps&#34;&gt;4-steps&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;pre-processing&lt;/li&gt;
&lt;li&gt;compilation&lt;/li&gt;
&lt;li&gt;assembly&lt;/li&gt;
&lt;li&gt;linking&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;types-of-object-files&#34;&gt;Types of Object Files&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Executable object file&lt;/li&gt;
&lt;li&gt;Relocatable object file&lt;/li&gt;
&lt;li&gt;Shared object file&lt;/li&gt;
&lt;li&gt;Core file&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;formats-of-object-files&#34;&gt;Formats of Object Files&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;a.out
&lt;ul&gt;
&lt;li&gt;initial version of UNIX&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;COFF
&lt;ul&gt;
&lt;li&gt;SVR3 UNIX&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;PE
&lt;ul&gt;
&lt;li&gt;Win. NT&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;ELF
&lt;ul&gt;
&lt;li&gt;SVR4 Linux&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;elf-format-of-a-program&#34;&gt;ELF format of a program&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;ELF Header&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Program Header Table&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;.text&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;.rodata&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;.data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;.bss&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;.symtab&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;.rel.text&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;.rel.data&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;.debug&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;.line&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;.strtab&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Section Header Table&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;可參考: &lt;a class=&#34;link&#34; href=&#34;http://ccckmit.wikidot.com/lk:elf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;http://ccckmit.wikidot.com/lk:elf&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;process&#34;&gt;Process&lt;/h1&gt;
&lt;p&gt;Instance of a program running on a computer&lt;/p&gt;
&lt;h2 id=&#34;process-control-block&#34;&gt;Process Control Block&lt;/h2&gt;
&lt;p&gt;task_struct&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Process Identification
&lt;ul&gt;
&lt;li&gt;PID, PPID, SID, UID, EUID..&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Process State Information&lt;/li&gt;
&lt;li&gt;Process Control Information&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>Shell</title>
        <link>https://roykesydon.github.io/Blog/p/shell/</link>
        <pubDate>Thu, 19 Jan 2023 23:00:02 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/shell/</guid>
        <description>&lt;h1 id=&#34;features&#34;&gt;Features&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Process control&lt;/li&gt;
&lt;li&gt;Variables&lt;/li&gt;
&lt;li&gt;Flow control&lt;/li&gt;
&lt;li&gt;Functions&lt;/li&gt;
&lt;li&gt;File &amp;amp; cmd name completions&lt;/li&gt;
&lt;li&gt;Cmd line editng&lt;/li&gt;
&lt;li&gt;Cmd history&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;command-mode&#34;&gt;Command Mode&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Interactive&lt;/li&gt;
&lt;li&gt;Non- Interactive&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;command-type&#34;&gt;Command Type&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;internal / Builtin command&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;指令的程式碼是 shell 的一部分
&lt;ul&gt;
&lt;li&gt;e.g., cd, exit&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;不會產生 child process&lt;/li&gt;
&lt;li&gt;有些 internal command，比如 echo, pwd，會 internal 和 external 都有實作&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;external command&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;指令的程式碼在硬碟上的某個 binary file
&lt;ul&gt;
&lt;li&gt;e.g., clear, ls&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;會產生 child process&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;common-commands&#34;&gt;Common Commands&lt;/h1&gt;
&lt;p&gt;比較實用或常用的&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;grep&lt;/p&gt;
&lt;p&gt;找字詞&lt;/p&gt;
&lt;p&gt;grep &amp;lt;string/pattern&amp;gt; &lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;-i 大小寫不敏感&lt;/li&gt;
&lt;li&gt;-v 不包含關鍵字的&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;cut
找 column&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;-f 找哪些 column&lt;/li&gt;
&lt;li&gt;-d 分隔符是什麼&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;比較兩個檔案&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;comm&lt;/p&gt;
&lt;p&gt;顯示 file1 獨有的列、 file2 獨有的列、file1 和 file2 共有的列&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;cmp, diff&lt;/p&gt;
&lt;p&gt;回傳不一樣的列資訊&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;unset&lt;/p&gt;
&lt;p&gt;把指定的變數移除掉&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;tee&lt;/p&gt;
&lt;p&gt;吃 stdin 輸出到 stdout 和其他檔案&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;less&lt;/p&gt;
&lt;p&gt;讀檔案用&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;expansions&#34;&gt;Expansions&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;White space&lt;/li&gt;
&lt;li&gt;Control Operators
&lt;ul&gt;
&lt;li&gt;;
&lt;ul&gt;
&lt;li&gt;讓指令接著執行&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&amp;amp;
&lt;ul&gt;
&lt;li&gt;放在結尾，讓指令在背景執行&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&amp;amp;&amp;amp;
&lt;ul&gt;
&lt;li&gt;logical AND&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;||
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;logical OR&lt;/p&gt;
&lt;p&gt;前面失敗才會跑後面&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;#
&lt;ul&gt;
&lt;li&gt;註解用&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;\
&lt;ul&gt;
&lt;li&gt;escape special characters&lt;/li&gt;
&lt;li&gt;放結尾好換行繼續輸入&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;$?
&lt;ul&gt;
&lt;li&gt;一個特別的變數，有上個指令的 exit code&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Shell variables
&lt;ul&gt;
&lt;li&gt;User defined&lt;/li&gt;
&lt;li&gt;Env var&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Shell history&lt;/li&gt;
&lt;li&gt;File Globing
&lt;ul&gt;
&lt;li&gt;*, ?, [], -, !&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        <item>
        <title>GPT 三部曲</title>
        <link>https://roykesydon.github.io/Blog/p/gpt-%E4%B8%89%E9%83%A8%E6%9B%B2/</link>
        <pubDate>Thu, 19 Jan 2023 01:50:07 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/gpt-%E4%B8%89%E9%83%A8%E6%9B%B2/</guid>
        <description>&lt;p&gt;GPT 本質上就是 Transformer 的 decoder&lt;/p&gt;
&lt;h1 id=&#34;gpt-1&#34;&gt;GPT-1&lt;/h1&gt;
&lt;p&gt;paper: &lt;a class=&#34;link&#34; href=&#34;https://www.semanticscholar.org/paper/Improving-Language-Understanding-by-Generative-Radford-Narasimhan/cd18800a0fe0b668a1cc19f2ec95b5003d0a5035&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Improving Language Understanding by Generative Pre-Training&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;用 semi-supervised，後來被歸為 self-supervised&lt;/p&gt;
&lt;h2 id=&#34;unsupervised-pre-training&#34;&gt;Unsupervised pre-training&lt;/h2&gt;
&lt;p&gt;$L_1(U)=\sum_i logP(u_i|u_{i-k},&amp;hellip;,u_{i-1};\theta)$&lt;/p&gt;
&lt;p&gt;$U= \{ u_1,&amp;hellip;,u_n \}$&lt;/p&gt;
&lt;p&gt;$U$ 是一系列未標記的文本 token&lt;/p&gt;
&lt;p&gt;$k$ 是窗口大小&lt;/p&gt;
&lt;h3 id=&#34;模型大致架構&#34;&gt;模型大致架構&lt;/h3&gt;
&lt;p&gt;$h_0=UW_e+W_p$&lt;/p&gt;
&lt;p&gt;$h_1=transformer \_ block(h_{i-1})\forall i \in[1,n]$&lt;/p&gt;
&lt;p&gt;$P(u)=softmax(h_nW^T_e)$&lt;/p&gt;
&lt;p&gt;$U=\{u_{-k},&amp;hellip;,u_{-1}\}$&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;supervised-fine-tuning&#34;&gt;Supervised fine-tuning&lt;/h2&gt;
&lt;p&gt;$P(y|x^1,&amp;hellip;,x^m)=softmax(h^m_lW_y)$&lt;/p&gt;
&lt;p&gt;$L2(C)=\sum_{(x,y)}log P(y|x^1,&amp;hellip;,x^m)$&lt;/p&gt;
&lt;p&gt;$L_3(C)=L_2(C)+\lambda*L_1(C)$&lt;/p&gt;
&lt;p&gt;$C$ 是 labeled 的資料集，微調基本上就是在後面加上線性層&lt;/p&gt;
&lt;p&gt;作者最大化 likelihood 的時候是用 $L_3$ 而非單純的 $L_2$&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;微調應用範例&#34;&gt;微調應用範例&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/gpt/gpt-1-tasks.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;資料集&#34;&gt;資料集&lt;/h2&gt;
&lt;p&gt;用 BooksCorpus 訓練出來的&lt;/p&gt;
&lt;p&gt;有超過 7000 本未出版的書&lt;/p&gt;
&lt;h2 id=&#34;模型結構&#34;&gt;模型結構&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;12 層 transformer 的 decoder&lt;/li&gt;
&lt;li&gt;768 維 word embedding&lt;/li&gt;
&lt;li&gt;12 個 attention heads&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;和-bert-base-比較&#34;&gt;和 BERT BASE 比較&lt;/h2&gt;
&lt;p&gt;BERT 論文比較晚出，但 BASE 的模型架構和 GPT 有相似之處，&lt;/p&gt;
&lt;p&gt;BASE 是 12 層的 decoder，word embedding 和 attention head 的維度或數量和 GPT-1 相同&lt;/p&gt;
&lt;h1 id=&#34;gpt-2&#34;&gt;GPT-2&lt;/h1&gt;
&lt;p&gt;paper: &lt;a class=&#34;link&#34; href=&#34;https://paperswithcode.com/paper/language-models-are-unsupervised-multitask&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Language Models are Unsupervised Multitask Learner&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;GPT-2 除了用更大的的模型和更大的資料集，把重點放在 zero-shot 上，雖然在 GPT-1 的論文就有提過 zero-shot&lt;/p&gt;
&lt;h2 id=&#34;資料集-1&#34;&gt;資料集&lt;/h2&gt;
&lt;p&gt;這次做了一個叫做 WebText 的資料集，有百萬級別的網頁&lt;/p&gt;
&lt;h3 id=&#34;common-crawl&#34;&gt;Common Crawl&lt;/h3&gt;
&lt;p&gt;大型爬蟲專案，有大量網頁資料，但充斥了垃圾訊息&lt;/p&gt;
&lt;h3 id=&#34;webtext&#34;&gt;WebText&lt;/h3&gt;
&lt;p&gt;WebText 的資料來源是 reddit 上的外部連結，只要有至少三個 karma，就會被採納，由此取得品質較好的網頁資料。透過這種方法，取得了 4500 萬個連結。並用Dragnet (Peters &amp;amp; Lecocq, 2013) and Newspaper content extractors 把文字訊息從 HTML 中抓出來&lt;/p&gt;
&lt;h2 id=&#34;架構&#34;&gt;架構&lt;/h2&gt;
&lt;p&gt;和原本差不多，變成有 1.5B 參數的 Transformer decoder&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/gpt/gpt-2-models.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h2 id=&#34;zero-shot&#34;&gt;zero-shot&lt;/h2&gt;
&lt;p&gt;不需要下游任務的標記資料&lt;/p&gt;
&lt;p&gt;改把任務輸入進模型&lt;/p&gt;
&lt;h3 id=&#34;目前問題&#34;&gt;目前問題&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;現在的模型泛化能力不太好&lt;/li&gt;
&lt;li&gt;Multitask learning
在 NLP 上不太常用，NLP 現在主流還是在預訓練模型上做微調以應對下游任務
&lt;ul&gt;
&lt;li&gt;對每個下游任務都得重新訓練模型&lt;/li&gt;
&lt;li&gt;得蒐集 labeled 資料&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;結果&#34;&gt;結果&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/gpt/gpt-2-result-1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/gpt/gpt-2-result-2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;h1 id=&#34;gpt-3&#34;&gt;GPT-3&lt;/h1&gt;
&lt;p&gt;paper: &lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/abs/2005.14165&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Language Models are Few-Shot Learners&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;摘要&#34;&gt;摘要&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;有 175B 的參數，由於模型極大，要在子任務微調會成本很大，所以不做任何梯度更新&lt;/li&gt;
&lt;li&gt;在很多 NLP 任務有傑出的成果&lt;/li&gt;
&lt;li&gt;可以生出人類難以區分的新聞文章&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;目前有的問題&#34;&gt;目前有的問題&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;要在子任務微調，需要資料集&lt;/li&gt;
&lt;li&gt;微調後在有些子任務上表現好不代表你預訓練模型一定泛化能力高&lt;/li&gt;
&lt;li&gt;人類不需要大量 labeled 資料去完成小任務&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;評估方式&#34;&gt;評估方式&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;分為三種，few / one / zero-shot learning&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;架構-1&#34;&gt;架構&lt;/h2&gt;
&lt;p&gt;基本上 GPT-3 和 GPT-2 架構一樣&lt;/p&gt;
&lt;h3 id=&#34;相同&#34;&gt;相同&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;modified initialization&lt;/li&gt;
&lt;li&gt;pre-normalization&lt;/li&gt;
&lt;li&gt;reversible tokenization described therein&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;不同&#34;&gt;不同&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;把 Sparse Transformer 的一些修改拿過來用&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/gpt/gpt-3-models.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;GPT-3 Small 是 GPT-1 的大小
GPT-3 Medium 是 BERT Large 的大小
GPT-3 XL 和 GPT-2 相近，比較淺也比較寬&lt;/p&gt;
&lt;h4 id=&#34;batch-size-大小&#34;&gt;Batch Size 大小&lt;/h4&gt;
&lt;p&gt;模型小的時候需要小一點，透過這種額外的 noise 來避免 overfitting(不確定是不是猜想)&lt;/p&gt;
&lt;h2 id=&#34;資料集-2&#34;&gt;資料集&lt;/h2&gt;
&lt;h3 id=&#34;common-crawl-1&#34;&gt;Common Crawl&lt;/h3&gt;
&lt;p&gt;架構比 GPT-2 大很多，所以回頭考慮這個資料集&lt;/p&gt;
&lt;h4 id=&#34;三步驟&#34;&gt;三步驟&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;先過濾，透過 reddit 那個高品質的資料集，來訓練一個模型分類高品質和低品質的網頁。&lt;/li&gt;
&lt;li&gt;透過 LSH 演算法把相似的文本過濾掉&lt;/li&gt;
&lt;li&gt;把一些已知高品質的資料集也加進來&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/gpt/gpt-3-dataset.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;這是一個 Batch 裡有 60% 來自 Common Crawl(filtered) 的意思
Wikipedia 雖然總量比較少，但也有 3% 的採樣率&lt;/p&gt;
&lt;h2 id=&#34;結果-1&#34;&gt;結果&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/gpt/gpt-3-result-1.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;計算量指數增長，loss 卻是線性的往下降&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://roykesydon.github.io/Blog/Blog/images/gpt/gpt-3-result-2.png&#34;
	
	
	
	loading=&#34;lazy&#34;
	
	
&gt;&lt;/p&gt;
&lt;p&gt;paper 裡有很多任務的實驗結果，這邊就不附上了&lt;/p&gt;
&lt;h2 id=&#34;limitations&#34;&gt;Limitations&lt;/h2&gt;
&lt;p&gt;在文本生成上還是比較弱，生很長的東西，可能會重複自己說過的話、失去連貫性、自相矛盾等等&lt;/p&gt;
&lt;p&gt;在有些雙向性的任務上可能表現更差&lt;/p&gt;
&lt;h2 id=&#34;影響&#34;&gt;影響&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;可能被用來散布不實消息、垃圾郵件等等&lt;/li&gt;
&lt;li&gt;偏見&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;結論&#34;&gt;結論&lt;/h2&gt;
&lt;p&gt;在很多 NLP 任務可以做到接近 SOTA 微調模型的成果&lt;/p&gt;
</description>
        </item>
        <item>
        <title>Linux 瑣事</title>
        <link>https://roykesydon.github.io/Blog/p/linux-%E7%91%A3%E4%BA%8B/</link>
        <pubDate>Thu, 19 Jan 2023 01:50:07 +0800</pubDate>
        
        <guid>https://roykesydon.github.io/Blog/p/linux-%E7%91%A3%E4%BA%8B/</guid>
        <description>&lt;h1 id=&#34;vm&#34;&gt;VM&lt;/h1&gt;
&lt;p&gt;A software implementation of a machine&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;System VM
&lt;ul&gt;
&lt;li&gt;提供可以執行 GuestOS 的 complete system platform&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Process VM
&lt;ul&gt;
&lt;li&gt;像一個一般的 app 一樣在 hostOS 跑，支援單一個 process&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;hypervisor&#34;&gt;Hypervisor&lt;/h2&gt;
&lt;p&gt;又稱虛擬機器監視器（英語：virtual machine monitor，縮寫為VMM）
用來管理 VM&lt;/p&gt;
&lt;p&gt;允許多個 GuestOS 跑在 host computer&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Type-1&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;bare-metal hypervisors&lt;/li&gt;
&lt;li&gt;直接在硬體上執行&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Type-2&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;hosted hypervisors&lt;/li&gt;
&lt;li&gt;在 hostOS 上執行&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;directories&#34;&gt;directories&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Binary&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;e.g., bin, sbin, lib, opt
&lt;ul&gt;
&lt;li&gt;bin: 有關 user 的指令&lt;/li&gt;
&lt;li&gt;sbin: 管理員會用的指令&lt;/li&gt;
&lt;li&gt;opt: optional software，多數機器中這是空的&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Configuration&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;e.g., boot, etc,&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Data&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;e.g., home, root, srv, media, mnt, temp&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;In memory
字面上的意思，不在 hard disk，在 memory&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;e.g., dev, proc, sys&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;System Resources&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;e.g., usr&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Variable Data&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;e.g., var&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        
    </channel>
</rss>
